{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-acquisition",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rltk\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-orange",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decimal-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'graphics'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-landscape",
   "metadata": {},
   "source": [
    "**Arxiv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_arxiv.shape pre  deduplucation: (122, 7)\n",
      "df_arxiv.shape post deduplucation: (61, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1801.07829v2</td>\n",
       "      <td>2019-06-11T06:11:21Z</td>\n",
       "      <td>2018-01-24T01:14:04Z</td>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>Point clouds provide a flexible geometric re...</td>\n",
       "      <td>[Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/1705.01583v1</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>VNect: Real-time 3D Human Pose Estimation with...</td>\n",
       "      <td>We present the first real-time method to cap...</td>\n",
       "      <td>[Dushyant Mehta, Srinath Sridhar, Oleksandr So...</td>\n",
       "      <td>[cs.CV, cs.GR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1712.01537v1</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>O-CNN: Octree-based Convolutional Neural Netwo...</td>\n",
       "      <td>We present O-CNN, an Octree-based Convolutio...</td>\n",
       "      <td>[Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/1609.02974v1</td>\n",
       "      <td>2016-09-09T23:33:38Z</td>\n",
       "      <td>2016-09-09T23:33:38Z</td>\n",
       "      <td>Learning-Based View Synthesis for Light Field ...</td>\n",
       "      <td>With the introduction of consumer light fiel...</td>\n",
       "      <td>[Nima Khademi Kalantari, Ting-Chun Wang, Ravi ...</td>\n",
       "      <td>[cs.CV, cs.GR, I.4.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1804.02717v3</td>\n",
       "      <td>2018-07-27T03:44:10Z</td>\n",
       "      <td>2018-04-08T17:04:58Z</td>\n",
       "      <td>DeepMimic: Example-Guided Deep Reinforcement L...</td>\n",
       "      <td>A longstanding goal in character animation i...</td>\n",
       "      <td>[Xue Bin Peng, Pieter Abbeel, Sergey Levine, M...</td>\n",
       "      <td>[cs.GR, cs.AI, cs.LG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 url               updated  \\\n",
       "0  http://arxiv.org/abs/1801.07829v2  2019-06-11T06:11:21Z   \n",
       "1  http://arxiv.org/abs/1705.01583v1  2017-05-03T19:13:23Z   \n",
       "2  http://arxiv.org/abs/1712.01537v1  2017-12-05T09:25:19Z   \n",
       "3  http://arxiv.org/abs/1609.02974v1  2016-09-09T23:33:38Z   \n",
       "4  http://arxiv.org/abs/1804.02717v3  2018-07-27T03:44:10Z   \n",
       "\n",
       "              published                                              title  \\\n",
       "0  2018-01-24T01:14:04Z     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "1  2017-05-03T19:13:23Z  VNect: Real-time 3D Human Pose Estimation with...   \n",
       "2  2017-12-05T09:25:19Z  O-CNN: Octree-based Convolutional Neural Netwo...   \n",
       "3  2016-09-09T23:33:38Z  Learning-Based View Synthesis for Light Field ...   \n",
       "4  2018-04-08T17:04:58Z  DeepMimic: Example-Guided Deep Reinforcement L...   \n",
       "\n",
       "                                             summary  \\\n",
       "0    Point clouds provide a flexible geometric re...   \n",
       "1    We present the first real-time method to cap...   \n",
       "2    We present O-CNN, an Octree-based Convolutio...   \n",
       "3    With the introduction of consumer light fiel...   \n",
       "4    A longstanding goal in character animation i...   \n",
       "\n",
       "                                             authors             categories  \n",
       "0  [Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...                [cs.CV]  \n",
       "1  [Dushyant Mehta, Srinath Sridhar, Oleksandr So...         [cs.CV, cs.GR]  \n",
       "2  [Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...                [cs.CV]  \n",
       "3  [Nima Khademi Kalantari, Ting-Chun Wang, Ravi ...  [cs.CV, cs.GR, I.4.1]  \n",
       "4  [Xue Bin Peng, Pieter Abbeel, Sergey Levine, M...  [cs.GR, cs.AI, cs.LG]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arxiv = pd.read_json(f'crawler558/arxiv_crawler_{TOPIC}.jl', lines=True)\n",
    "print(f'df_arxiv.shape pre  deduplucation: {df_arxiv.shape}')\n",
    "df_arxiv = df_arxiv.drop_duplicates(subset='title')\n",
    "print(f'df_arxiv.shape post deduplucation: {df_arxiv.shape}')\n",
    "df_arxiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "determined-quarter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61 entries, 0 to 60\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          61 non-null     object\n",
      " 1   url         61 non-null     object\n",
      " 2   updated     61 non-null     object\n",
      " 3   published   61 non-null     object\n",
      " 4   title       61 non-null     object\n",
      " 5   summary     61 non-null     object\n",
      " 6   authors     61 non-null     object\n",
      " 7   categories  61 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Generate an id column for RLTK to use\n",
    "df_arxiv.reset_index(inplace=True)\n",
    "df_arxiv['index'] = df_arxiv['index'].astype('str')\n",
    "df_arxiv.rename(columns={'index':'ID'}, inplace=True)\n",
    "df_arxiv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-soundtrack",
   "metadata": {},
   "source": [
    "**Google Scholar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerous-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_gscholar.shape pre  deduplication: (605, 6)\n",
      "df_gscholar.shape post deduplication: (481, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMPL: a skinned multi-person linear model</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[M Loper, N Mahmood, J Romero, G Pons-Moll, MJ...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 34 (6), 1-16</td>\n",
       "      <td>620</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 38 (5), 1-12</td>\n",
       "      <td>536</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let there be color! joint end-to-end learning ...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[S Iizuka, E Simo-Serra, H Ishikawa]</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 35 (4), 1-11</td>\n",
       "      <td>441</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VNect: real-time 3D human pose estimation with...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[D Mehta, S Sridhar, O Sotnychenko, H Rhodin, ...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 36 (4), 1-14</td>\n",
       "      <td>400</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-CNN: octree-based convolutional neural netwo...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[PS Wang, Y Liu, YX Guo, CY Sun, X Tong]</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 36 (4), 1-11</td>\n",
       "      <td>345</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0          SMPL: a skinned multi-person linear model   \n",
       "1     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "2  Let there be color! joint end-to-end learning ...   \n",
       "3  VNect: real-time 3D human pose estimation with...   \n",
       "4  O-CNN: octree-based convolutional neural netwo...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "3  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "4  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [M Loper, N Mahmood, J Romero, G Pons-Moll, MJ...   \n",
       "1  [Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...   \n",
       "2               [S Iizuka, E Simo-Serra, H Ishikawa]   \n",
       "3  [D Mehta, S Sridhar, O Sotnychenko, H Rhodin, ...   \n",
       "4           [PS Wang, Y Liu, YX Guo, CY Sun, X Tong]   \n",
       "\n",
       "                                           journal  citations  year  \n",
       "0  ACM Transactions on Graphics (TOG) 34 (6), 1-16        620  2015  \n",
       "1  ACM Transactions on Graphics (TOG) 38 (5), 1-12        536  2019  \n",
       "2  ACM Transactions on Graphics (TOG) 35 (4), 1-11        441  2016  \n",
       "3  ACM Transactions on Graphics (TOG) 36 (4), 1-14        400  2017  \n",
       "4  ACM Transactions on Graphics (TOG) 36 (4), 1-11        345  2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gscholar = pd.read_json(f'Google_Scholar/articles_{TOPIC}.json')\n",
    "print(f'df_gscholar.shape pre  deduplication: {df_gscholar.shape}')\n",
    "df_gscholar = df_gscholar.drop_duplicates(subset='title')\n",
    "print(f'df_gscholar.shape post deduplication: {df_gscholar.shape}')\n",
    "\n",
    "# Fix the wrong URLs\n",
    "df_gscholar['url'] = df_gscholar['url'].apply(lambda x: x[27:])\n",
    "\n",
    "df_gscholar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "third-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 481 entries, 0 to 480\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         481 non-null    object\n",
      " 1   title      481 non-null    object\n",
      " 2   url        481 non-null    object\n",
      " 3   authors    481 non-null    object\n",
      " 4   journal    481 non-null    object\n",
      " 5   citations  481 non-null    object\n",
      " 6   year       481 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 26.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Generate an id column for RLTK to use\n",
    "df_gscholar.reset_index(inplace=True)\n",
    "df_gscholar['index'] = df_gscholar['index'].astype('str')\n",
    "df_gscholar.rename(columns={'index':'ID'}, inplace=True)\n",
    "\n",
    "# Also set all columns to string type\n",
    "df_gscholar['citations'] = df_gscholar['citations'].astype('str')\n",
    "df_gscholar['year'] = df_gscholar['year'].astype('str')\n",
    "df_gscholar.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-reporter",
   "metadata": {},
   "source": [
    "### Naïve Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposite-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# How many matches can be found with a naÏve identical string approach?\n",
    "arxiv_titles = df_arxiv['title']\n",
    "gscholar_titles = df_gscholar['title']\n",
    "print(len([1 for w in arxiv_titles.values if w in gscholar_titles.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protective-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged.shape: (529, 14)\n",
      "Number of match found with pd.merge: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>url_x</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors_x</th>\n",
       "      <th>categories</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>url_y</th>\n",
       "      <th>authors_y</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/abs/1801.07829v2</td>\n",
       "      <td>2019-06-11T06:11:21Z</td>\n",
       "      <td>2018-01-24T01:14:04Z</td>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>Point clouds provide a flexible geometric re...</td>\n",
       "      <td>[Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>1</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 38 (5), 1-12</td>\n",
       "      <td>536</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/abs/1705.01583v1</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>VNect: Real-time 3D Human Pose Estimation with...</td>\n",
       "      <td>We present the first real-time method to cap...</td>\n",
       "      <td>[Dushyant Mehta, Srinath Sridhar, Oleksandr So...</td>\n",
       "      <td>[cs.CV, cs.GR]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/abs/1712.01537v1</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>O-CNN: Octree-based Convolutional Neural Netwo...</td>\n",
       "      <td>We present O-CNN, an Octree-based Convolutio...</td>\n",
       "      <td>[Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_x                              url_x               updated  \\\n",
       "0    0  http://arxiv.org/abs/1801.07829v2  2019-06-11T06:11:21Z   \n",
       "1    1  http://arxiv.org/abs/1705.01583v1  2017-05-03T19:13:23Z   \n",
       "2    2  http://arxiv.org/abs/1712.01537v1  2017-12-05T09:25:19Z   \n",
       "\n",
       "              published                                              title  \\\n",
       "0  2018-01-24T01:14:04Z     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "1  2017-05-03T19:13:23Z  VNect: Real-time 3D Human Pose Estimation with...   \n",
       "2  2017-12-05T09:25:19Z  O-CNN: Octree-based Convolutional Neural Netwo...   \n",
       "\n",
       "                                             summary  \\\n",
       "0    Point clouds provide a flexible geometric re...   \n",
       "1    We present the first real-time method to cap...   \n",
       "2    We present O-CNN, an Octree-based Convolutio...   \n",
       "\n",
       "                                           authors_x      categories ID_y  \\\n",
       "0  [Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...         [cs.CV]    1   \n",
       "1  [Dushyant Mehta, Srinath Sridhar, Oleksandr So...  [cs.CV, cs.GR]  NaN   \n",
       "2  [Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...         [cs.CV]  NaN   \n",
       "\n",
       "                                               url_y  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                                           authors_y  \\\n",
       "0  [Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                                           journal citations  year  \n",
       "0  ACM Transactions on Graphics (TOG) 38 (5), 1-12       536  2019  \n",
       "1                                              NaN       NaN   NaN  \n",
       "2                                              NaN       NaN   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both datasets by \"SQL\" join\n",
    "df_merged = df_arxiv.merge(df_gscholar, on='title', how='outer')\n",
    "print(f'df_merged.shape: {df_merged.shape}')\n",
    "\n",
    "# Number of match found with pd.merge:\n",
    "print(f'Number of match found with pd.merge: {df_arxiv.shape[0] + df_gscholar.shape[0] - df_merged.shape[0]}')\n",
    "\n",
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-count",
   "metadata": {},
   "source": [
    "## RLTK Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divine-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLTK Tokenizer\n",
    "tokenizer = rltk.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-earth",
   "metadata": {},
   "source": [
    "**Arxiv Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = 'ArxivRecord'\n",
    "        \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def authors_string(self):\n",
    "        return self.raw_object['authors']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['title']\n",
    "        \n",
    "    @rltk.cached_property\n",
    "    def summary_string(self):\n",
    "        return self.raw_object['summary']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def categories_string(self):\n",
    "        return self.raw_object['categories']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def published_string(self):\n",
    "        return self.raw_object['published']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def updated_string(self):\n",
    "        return self.raw_object['updated']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def blocking_tokens(self):\n",
    "        tokens = ' '.join([self.title_string])\n",
    "        tokens = re.sub(r'\\bThe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bthe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bof\\b', '', tokens)\n",
    "        tokens = re.sub(r\"\\b's\\b\", '', tokens)\n",
    "        tokens = re.sub(r'\\band\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bI\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bA\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bin\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bfor\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bon\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bwith\\b', '', tokens)\n",
    "        return set(tokenizer.tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marked-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors_string</th>\n",
       "      <th>title_string</th>\n",
       "      <th>summary_string</th>\n",
       "      <th>categories_string</th>\n",
       "      <th>published_string</th>\n",
       "      <th>updated_string</th>\n",
       "      <th>url_string</th>\n",
       "      <th>blocking_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...</td>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>Point clouds provide a flexible geometric re...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>2018-01-24T01:14:04Z</td>\n",
       "      <td>2019-06-11T06:11:21Z</td>\n",
       "      <td>http://arxiv.org/abs/1801.07829v2</td>\n",
       "      <td>{Solomon, Bronstein, Sanjay, Yue, Wang, Point,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Dushyant Mehta, Srinath Sridhar, Oleksandr So...</td>\n",
       "      <td>VNect: Real-time 3D Human Pose Estimation with...</td>\n",
       "      <td>We present the first real-time method to cap...</td>\n",
       "      <td>[cs.CV, cs.GR]</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>2017-05-03T19:13:23Z</td>\n",
       "      <td>http://arxiv.org/abs/1705.01583v1</td>\n",
       "      <td>{Mehta, -, Theobalt, Sotnychenko, 3D, Xu, Srin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...</td>\n",
       "      <td>O-CNN: Octree-based Convolutional Neural Netwo...</td>\n",
       "      <td>We present O-CNN, an Octree-based Convolutio...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>2017-12-05T09:25:19Z</td>\n",
       "      <td>http://arxiv.org/abs/1712.01537v1</td>\n",
       "      <td>{Yu, O, -, 3D, Neural, based, Xin, Peng, Shape...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                     authors_string  \\\n",
       "0  0  [Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. S...   \n",
       "1  1  [Dushyant Mehta, Srinath Sridhar, Oleksandr So...   \n",
       "2  2  [Peng-Shuai Wang, Yang Liu, Yu-Xiao Guo, Chun-...   \n",
       "\n",
       "                                        title_string  \\\n",
       "0     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "1  VNect: Real-time 3D Human Pose Estimation with...   \n",
       "2  O-CNN: Octree-based Convolutional Neural Netwo...   \n",
       "\n",
       "                                      summary_string categories_string  \\\n",
       "0    Point clouds provide a flexible geometric re...           [cs.CV]   \n",
       "1    We present the first real-time method to cap...    [cs.CV, cs.GR]   \n",
       "2    We present O-CNN, an Octree-based Convolutio...           [cs.CV]   \n",
       "\n",
       "       published_string        updated_string  \\\n",
       "0  2018-01-24T01:14:04Z  2019-06-11T06:11:21Z   \n",
       "1  2017-05-03T19:13:23Z  2017-05-03T19:13:23Z   \n",
       "2  2017-12-05T09:25:19Z  2017-12-05T09:25:19Z   \n",
       "\n",
       "                          url_string  \\\n",
       "0  http://arxiv.org/abs/1801.07829v2   \n",
       "1  http://arxiv.org/abs/1705.01583v1   \n",
       "2  http://arxiv.org/abs/1712.01537v1   \n",
       "\n",
       "                                     blocking_tokens  \n",
       "0  {Solomon, Bronstein, Sanjay, Yue, Wang, Point,...  \n",
       "1  {Mehta, -, Theobalt, Sotnychenko, 3D, Xu, Srin...  \n",
       "2  {Yu, O, -, 3D, Neural, based, Xin, Peng, Shape...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_arxiv = rltk.Dataset(reader=rltk.DataFrameReader(df_arxiv), record_class=ArxivRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "print(type(ds_arxiv))\n",
    "ds_arxiv.generate_dataframe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-indicator",
   "metadata": {},
   "source": [
    "**Google Scholar Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "august-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GScholarRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = 'GScholarRecord'\n",
    "        \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def authors_string(self):\n",
    "        return self.raw_object['authors']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['title']\n",
    "        \n",
    "    @rltk.cached_property\n",
    "    def journal_string(self):\n",
    "        return self.raw_object['journal']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def citations_string(self):\n",
    "        return self.raw_object['citations']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def year_string(self):\n",
    "        return self.raw_object['year']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def blocking_tokens(self):\n",
    "        tokens = ' '.join([self.title_string])\n",
    "        tokens = re.sub(r'\\bThe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bthe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bof\\b', '', tokens)\n",
    "        tokens = re.sub(r\"\\b's\\b\", '', tokens)\n",
    "        tokens = re.sub(r'\\band\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bI\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bA\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bin\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bfor\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bon\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bwith\\b', '', tokens)\n",
    "        return set(tokenizer.tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "embedded-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors_string</th>\n",
       "      <th>title_string</th>\n",
       "      <th>journal_string</th>\n",
       "      <th>citations_string</th>\n",
       "      <th>year_string</th>\n",
       "      <th>url_string</th>\n",
       "      <th>blocking_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[M Loper, N Mahmood, J Romero, G Pons-Moll, MJ...</td>\n",
       "      <td>SMPL: a skinned multi-person linear model</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 34 (6), 1-16</td>\n",
       "      <td>620</td>\n",
       "      <td>2015</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{-, J, linear, a, Pons, skinned, Moll, multi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...</td>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 38 (5), 1-12</td>\n",
       "      <td>536</td>\n",
       "      <td>2019</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{Dynamic, Graph, Y, MM, JM, Solomon, Wang, Poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[S Iizuka, E Simo-Serra, H Ishikawa]</td>\n",
       "      <td>Let there be color! joint end-to-end learning ...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 35 (4), 1-11</td>\n",
       "      <td>441</td>\n",
       "      <td>2016</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{Let, -, to, be, image, there, !, local, Serra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                     authors_string  \\\n",
       "0  0  [M Loper, N Mahmood, J Romero, G Pons-Moll, MJ...   \n",
       "1  1  [Y Wang, Y Sun, Z Liu, SE Sarma, MM Bronstein,...   \n",
       "2  2               [S Iizuka, E Simo-Serra, H Ishikawa]   \n",
       "\n",
       "                                        title_string  \\\n",
       "0          SMPL: a skinned multi-person linear model   \n",
       "1     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "2  Let there be color! joint end-to-end learning ...   \n",
       "\n",
       "                                    journal_string citations_string  \\\n",
       "0  ACM Transactions on Graphics (TOG) 34 (6), 1-16              620   \n",
       "1  ACM Transactions on Graphics (TOG) 38 (5), 1-12              536   \n",
       "2  ACM Transactions on Graphics (TOG) 35 (4), 1-11              441   \n",
       "\n",
       "  year_string                                         url_string  \\\n",
       "0        2015  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1        2019  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2        2016  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                     blocking_tokens  \n",
       "0  {-, J, linear, a, Pons, skinned, Moll, multi, ...  \n",
       "1  {Dynamic, Graph, Y, MM, JM, Solomon, Wang, Poi...  \n",
       "2  {Let, -, to, be, image, there, !, local, Serra...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gscholar = rltk.Dataset(reader=rltk.DataFrameReader(df_gscholar), record_class=GScholarRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "print(type(ds_gscholar))\n",
    "ds_gscholar.generate_dataframe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-accessory",
   "metadata": {},
   "source": [
    "### Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mental-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.blocking.block.Block'>\n"
     ]
    }
   ],
   "source": [
    "# Generate blocks from tokens\n",
    "token_blocker = rltk.TokenBlockGenerator()\n",
    "blocks = token_blocker.generate(\n",
    "    token_blocker.block(ds_arxiv, property_='blocking_tokens'),\n",
    "    token_blocker.block(ds_gscholar, property_='blocking_tokens'))\n",
    "print(type(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "looking-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction Ratio: 0.43673\n"
     ]
    }
   ],
   "source": [
    "# Extract all record pairs from the block\n",
    "record_pairs = rltk.get_record_pairs(ds_arxiv, ds_gscholar, block=blocks)\n",
    "\n",
    "# Get the total number of record pairs generated\n",
    "compared_pairs = len(list(record_pairs))\n",
    "\n",
    "# Get the number of elements in each rltk.Dataset\n",
    "tally_imdb = ds_arxiv.generate_dataframe().shape[0]\n",
    "tally_tmd = ds_gscholar.generate_dataframe().shape[0]\n",
    "\n",
    "# Calculate the total number of pairs if both datasets were to be compared without any blocking (eg: a double for loop)\n",
    "tally_unblocked = tally_imdb * tally_tmd\n",
    "\n",
    "# Calculate how much smaller the blocked pairings are\n",
    "reduction_ratio = compared_pairs / tally_unblocked\n",
    "\n",
    "# Calculate the reduction ratio (the inverse of the )\n",
    "reduction_ratio = 1 - reduction_ratio\n",
    "print(f'Reduction Ratio: {reduction_ratio:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-northwest",
   "metadata": {},
   "source": [
    "### Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "social-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_title = arxiv_tuple.title_string.strip().lower()\n",
    "    gscholar_title = gscholar_tuple.title_string.strip().lower()\n",
    "    similarity = SequenceMatcher(None, arxiv_title, gscholar_title).ratio()\n",
    "\n",
    "    penalties = sum([len(arxiv_title)<=6,\n",
    "                     len(gscholar_title)<=6])\n",
    "\n",
    "    return similarity * (0.9**penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "understanding-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_author = ' '.join(arxiv_tuple.authors_string).strip().lower()\n",
    "    gscholar_author = ' '.join(gscholar_tuple.authors_string).strip().lower()\n",
    "    similarity = SequenceMatcher(None, arxiv_author, gscholar_author).ratio() \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "therapeutic-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_year = int(float(arxiv_tuple.updated_string[0:4]))\n",
    "    gscholar_year = int(float(gscholar_tuple.year_string))\n",
    "    similarity = 1 /(1 + abs(arxiv_year-gscholar_year))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "revised-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_similarity(arxiv_tuple, gscholar_tuple, match_threshold=0.75):\n",
    "    sim_title = title_similarity(arxiv_tuple, gscholar_tuple)\n",
    "    sim_author = author_similarity(arxiv_tuple, gscholar_tuple)\n",
    "    sim_year = year_similarity(arxiv_tuple, gscholar_tuple)\n",
    "\n",
    "    element_similarity = (0.70 * sim_title) + (0.15 * sim_author) + (0.15 * sim_year)\n",
    "\n",
    "    return element_similarity > match_threshold, element_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "forward-vietnam",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv samples: 61\n",
      "GScholar samples: 481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [04:18<00:00, 12.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Set_A Size</th>\n",
       "      <th>Set_B Size</th>\n",
       "      <th>Duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>11956.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11956.0</td>\n",
       "      <td>23375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>11956.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11956.0</td>\n",
       "      <td>23375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>11954.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11954.0</td>\n",
       "      <td>23371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>11833.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11833.0</td>\n",
       "      <td>23129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>11141.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11141.0</td>\n",
       "      <td>21745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>8863.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>8863.0</td>\n",
       "      <td>17190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>5253.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5253.0</td>\n",
       "      <td>9972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>4263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>919.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>1447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>278.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>121.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>60.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Matches  Set_A Size  Set_B Size  Duplicates\n",
       "0.00  11956.0        61.0     11956.0     23375.0\n",
       "0.05  11956.0        61.0     11956.0     23375.0\n",
       "0.10  11954.0        61.0     11954.0     23371.0\n",
       "0.15  11833.0        61.0     11833.0     23129.0\n",
       "0.20  11141.0        61.0     11141.0     21745.0\n",
       "0.25   8863.0        61.0      8863.0     17190.0\n",
       "0.30   5253.0        61.0      5253.0      9972.0\n",
       "0.35   2385.0        61.0      2385.0      4263.0\n",
       "0.40    919.0        60.0       919.0      1447.0\n",
       "0.45    278.0        56.0       278.0       343.0\n",
       "0.50    121.0        53.0       121.0       102.0\n",
       "0.55     78.0        53.0        78.0        38.0\n",
       "0.60     60.0        53.0        60.0        11.0\n",
       "0.65     54.0        52.0        54.0         4.0\n",
       "0.70     53.0        52.0        53.0         2.0\n",
       "0.75     52.0        52.0        52.0         0.0\n",
       "0.80     52.0        52.0        52.0         0.0\n",
       "0.85     49.0        49.0        49.0         0.0\n",
       "0.90     36.0        36.0        36.0         0.0\n",
       "0.95     33.0        33.0        33.0         0.0\n",
       "1.00      0.0         0.0         0.0         0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict matches for all pairs in the blocked data \n",
    "print(f'Arxiv samples: {df_arxiv.shape[0]}')\n",
    "print(f'GScholar samples: {df_gscholar.shape[0]}')\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "THRESHOLDS = [T/100 for T in range(0, 101, 5)]\n",
    "\n",
    "# Iterate through various thresholds to find the most matches without any duplicates\n",
    "for T in tqdm(THRESHOLDS):\n",
    "\n",
    "    # Set to store pairs of IDs matched\n",
    "    ids_matched = set()\n",
    "    \n",
    "    # Iterate through candidates on the block\n",
    "    for block_id, arxiv_id, gscholar_id in blocks.pairwise(ds_arxiv, ds_gscholar):\n",
    "        \n",
    "        # Find similarity at a given threshold\n",
    "        match , similarity = elementwise_similarity(ds_arxiv.get_record(arxiv_id),\n",
    "                                                    ds_gscholar.get_record(gscholar_id),\n",
    "                                                    match_threshold=T)\n",
    "        # If a match is found, add to the set of matches\n",
    "        if match:\n",
    "            ids_matched.add((arxiv_id, gscholar_id))\n",
    "    \n",
    "    # Count the number of unique elements derived from each source\n",
    "    set_a = set()\n",
    "    set_b = set()\n",
    "    for tp in ids_matched:\n",
    "        set_a.add(tp[0])\n",
    "        set_b.add(tp[1])\n",
    "    \n",
    "    summary_df.at[T, 'Matches'] = int(len(ids_matched))\n",
    "    summary_df.at[T, 'Set_A Size'] = int(len(set_a))\n",
    "    summary_df.at[T, 'Set_B Size'] = int(len(set_b))\n",
    "    summary_df.at[T, 'Duplicates'] = int((len(ids_matched)-len(set_a)) + (len(ids_matched)-len(set_b)))\n",
    "    \n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elder-plant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the lowest threshold which gives no duplicates\n",
    "optimal_threshold = summary_df[summary_df['Duplicates']==0].index[0]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tutorial-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv samples: 61\n",
      "GScholar samples: 481\n",
      "\n",
      "Matches: 52\n",
      "Non-Matches Arxiv: 9\n",
      "Non-Matches GScholar: 424\n"
     ]
    }
   ],
   "source": [
    "# Generate matches based on the optimal (no-duplicate) threshold\n",
    "print(f'Arxiv samples: {df_arxiv.shape[0]}')\n",
    "print(f'GScholar samples: {df_gscholar.shape[0]}')\n",
    "\n",
    "# Store tuples of matches IDs, as well as singletons witouth a match\n",
    "ids_matched = set()\n",
    "singles_arxiv = set()\n",
    "singles_gscholar = set()\n",
    "\n",
    "# Write matches (and non-matches) to a CSV\n",
    "with open(f'Matches_{TOPIC}.csv', 'w') as predictions_full:\n",
    "    for block_id, arxiv_id, gscholar_id in blocks.pairwise(ds_arxiv, ds_gscholar):\n",
    "\n",
    "        match , similarity = elementwise_similarity(ds_arxiv.get_record(arxiv_id),\n",
    "                                                    ds_gscholar.get_record(gscholar_id),\n",
    "                                                    match_threshold=optimal_threshold)\n",
    "\n",
    "        if match:\n",
    "            ids_matched.add((arxiv_id, gscholar_id))\n",
    "        else:\n",
    "            singles_arxiv.add(arxiv_id)\n",
    "            singles_gscholar.add(gscholar_id)\n",
    "    \n",
    "    # After finding all matches, write them to a csv\n",
    "    for match_pair in ids_matched:\n",
    "        predictions_full.write(f'{match_pair[0]},{match_pair[1]},1\\n')\n",
    "        # And ensure that no item in the matches is counted as a single\n",
    "        try:\n",
    "            singles_arxiv.remove(match_pair[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            singles_gscholar.remove(match_pair[1])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Then write all the singles which didn't find a match\n",
    "    NULL = None\n",
    "    for arxiv_id in singles_arxiv:\n",
    "        predictions_full.write(f'{arxiv_id},{NULL},0\\n')\n",
    "    for gscholar_id in singles_gscholar:\n",
    "        predictions_full.write(f'{NULL},{gscholar_id},0\\n')        \n",
    "        \n",
    "print()\n",
    "print(f'Matches: {len(ids_matched)}')\n",
    "print(f'Non-Matches Arxiv: {len(singles_arxiv)}')\n",
    "print(f'Non-Matches GScholar: {len(singles_gscholar)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-porter",
   "metadata": {},
   "source": [
    "### Create Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ahead-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "\n",
    "# Initliaze the graph\n",
    "g = rdflib.Graph()\n",
    "\n",
    "# Bind namespace and prefixes\n",
    "g.bind('my_ns', MYNS)\n",
    "g.bind('schema', SCHEMA)\n",
    "g.bind('rdf', RDF)\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('xsd', XSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "close-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_df.shape: (485, 3)\n",
      "predicted matches: 52  [10.72 %]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXIV_ID</th>\n",
       "      <th>GSCHOLAR_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ARXIV_ID GSCHOLAR_ID  LABEL\n",
       "0        0           1      1\n",
       "1        6          23      1\n",
       "2       45         297      1\n",
       "3       12          40      1\n",
       "4       55         447      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predictions to be used in populating the RDF\n",
    "predictions_df = pd.read_csv(f'Matches_{TOPIC}.csv', header=None, names=['ARXIV_ID', 'GSCHOLAR_ID', 'LABEL'])\n",
    "print(f'predictions_df.shape: {predictions_df.shape}')\n",
    "predicted_matches = predictions_df['LABEL'].sum()\n",
    "print(f'predicted matches: {predicted_matches}  [{100*predicted_matches/predictions_df.shape[0]:.2f} %]')\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "extreme-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 485/485 [00:04<00:00, 110.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the merged datasets\n",
    "df_merged = pd.DataFrame(columns = ['ID', 'title', 'authors', 'published', 'updated', \n",
    "                                    'abstract', 'categories', 'citations', 'arxiv_url', 'gscholar_url'],\n",
    "                         dtype='object')\n",
    "json_merged = {}\n",
    "\n",
    "NEW_ID = 0\n",
    "\n",
    "# Populate the RDF with predictions with a positive (1) label\n",
    "for idx, row in tqdm(predictions_df.iterrows(), total=predictions_df.shape[0]):\n",
    "    \n",
    "    # Populate the json object\n",
    "    json_merged[NEW_ID] = {}\n",
    "    \n",
    "    ### URI ###\n",
    "    node_uri = URIRef(str(NEW_ID))\n",
    "    g.add((node_uri, RDF.type, SCHEMA.ScholarlyArticle))\n",
    "    df_merged.at[NEW_ID, 'ID'] = NEW_ID\n",
    "    json_merged[NEW_ID]['ID'] = NEW_ID\n",
    "\n",
    "    \n",
    "    ### Title ###\n",
    "    try:\n",
    "        title_arxiv = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['title'].values[0])\n",
    "    except:\n",
    "        title_arxiv = '<___>'\n",
    "    try:\n",
    "        title_gscholar = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['title'].values[0])\n",
    "    except:\n",
    "        title_gscholar = '<___>'\n",
    "    title = title_arxiv if title_arxiv != '<___>' else title_gscholar if title_gscholar != '<___>' else None\n",
    "    g.add((node_uri, SCHEMA.headline, Literal(title, datatype=SCHEMA.Text)))\n",
    "    df_merged.at[NEW_ID, 'title'] = title\n",
    "    json_merged[NEW_ID]['title'] = title\n",
    "\n",
    "    \n",
    "    ### Author(s) ###\n",
    "    try:\n",
    "        author_arxiv = df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['authors'].values[0]\n",
    "        author_arxiv = [name.strip() for name in author_arxiv if name != '<___>']\n",
    "    except:\n",
    "        author_arxiv = '<___>'\n",
    "    try:\n",
    "        author_gscholar = df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['authors'].values[0]\n",
    "        author_gscholar = [name.strip() for name in author_gscholar if name != '<___>']\n",
    "    except:\n",
    "        author_gscholar = '<___>'\n",
    "    if author_arxiv != '<___>':\n",
    "        authors = list(set(author_arxiv))\n",
    "    else:\n",
    "        authors = list(set(author_gscholar))           \n",
    "    [g.add((node_uri, SCHEMA.author, Literal(author, datatype=SCHEMA.Person))) for author in authors]\n",
    "    df_merged.at[NEW_ID, 'authors'] = authors\n",
    "    json_merged[NEW_ID]['authors'] = authors\n",
    "                       \n",
    "    ### Published ###\n",
    "    try:\n",
    "        published = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['published'].values[0])\n",
    "        g.add((node_uri, SCHEMA.datePublished, Literal(published, datatype=SCHEMA.DateTime)))\n",
    "        df_merged.at[NEW_ID, 'published'] = published\n",
    "        json_merged[NEW_ID]['published'] = published\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "                       \n",
    "    ### Updated ###\n",
    "    try:\n",
    "        updated = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['updated'].values[0])\n",
    "        g.add((node_uri, SCHEMA.dateModified, Literal(updated, datatype=SCHEMA.DateTime)))\n",
    "        df_merged.at[NEW_ID, 'updated'] = updated\n",
    "        json_merged[NEW_ID]['updated'] = updated\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "                       \n",
    "    ### Abstract ###\n",
    "    try:\n",
    "        abstract = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['summary'].values[0]).strip()\n",
    "        g.add((node_uri, SCHEMA.abstract, Literal(abstract, datatype=SCHEMA.Text)))\n",
    "        df_merged.at[NEW_ID, 'abstract'] = abstract\n",
    "        json_merged[NEW_ID]['abstract'] = abstract\n",
    "    except:\n",
    "        pass\n",
    "       \n",
    "                       \n",
    "    ### Categories ###\n",
    "    try:\n",
    "        categories = df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['categories'].values[0]\n",
    "        categories = [name.strip() for name in categories if name != '<___>']\n",
    "        [g.add((node_uri, SCHEMA.genre, Literal(category, datatype=SCHEMA.Text))) for category in categories]\n",
    "        df_merged.at[NEW_ID, 'categories'] = categories\n",
    "        json_merged[NEW_ID]['categories'] = categories\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "                       \n",
    "    ### Journal ###\n",
    "    try:\n",
    "        journal = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['journal'].values[0])\n",
    "        g.add((node_uri, SCHEMA.publisher, Literal(journal, datatype=SCHEMA.Periodical))) #datatype=SCHEMA.Organisation\n",
    "        df_merged.at[NEW_ID, 'journal'] = journal\n",
    "        json_merged[NEW_ID]['journal'] = journal\n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "                       \n",
    "    ### Citations ###\n",
    "    try:\n",
    "        citations = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['citations'].values[0])\n",
    "        g.add((node_uri, SCHEMA.commentCount, Literal(citations, datatype=SCHEMA.Integer)))\n",
    "        df_merged.at[NEW_ID, 'citations'] = citations\n",
    "        json_merged[NEW_ID]['citations'] = citations\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "                       \n",
    "    ### Arxiv URL ###\n",
    "    try:\n",
    "        arxiv_url = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['url'].values[0])\n",
    "        g.add((node_uri, SCHEMA.url, Literal(arxiv_url, datatype=SCHEMA.URL)))\n",
    "        df_merged.at[NEW_ID, 'arxiv_url'] = arxiv_url    \n",
    "        json_merged[NEW_ID]['arxiv_url'] = arxiv_url\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "                       \n",
    "    ### Google Scholar URL ###\n",
    "    try:\n",
    "        gscholar_url = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['url'].values[0])\n",
    "        g.add((node_uri, SCHEMA.url, Literal(gscholar_url, datatype=SCHEMA.URL)))\n",
    "        df_merged.at[NEW_ID, 'gscholar_url'] = gscholar_url   \n",
    "        json_merged[NEW_ID]['gscholar_url'] = gscholar_url\n",
    "    except:\n",
    "        pass\n",
    "             \n",
    "                       \n",
    "    NEW_ID += 1\n",
    "    \n",
    "# Save to disk using turtle format\n",
    "g.serialize(f'Triples_{TOPIC}.ttl.', format=\"turtle\")\n",
    "\n",
    "# And save the merged DataFrame as CSV\n",
    "df_merged.to_csv(f'Merged_{TOPIC}.csv', index=False)\n",
    "\n",
    "# Also save as Json, just because\n",
    "with open(f'Json_{TOPIC}.json', 'w') as fout:\n",
    "    json.dump(json_merged, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "anticipated-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>citations</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>gscholar_url</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dynamic Graph CNN for Learning on Point Clouds</td>\n",
       "      <td>[Yue Wang, Sanjay E. Sarma, Justin M. Solomon,...</td>\n",
       "      <td>2018-01-24T01:14:04Z</td>\n",
       "      <td>2019-06-11T06:11:21Z</td>\n",
       "      <td>Point clouds provide a flexible geometric repr...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>536</td>\n",
       "      <td>http://arxiv.org/abs/1801.07829v2</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 38 (5), 1-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking to Listen at the Cocktail Party: A Spe...</td>\n",
       "      <td>[Avinatan Hassidim, Oran Lang, Michael Rubinst...</td>\n",
       "      <td>2018-04-10T16:28:59Z</td>\n",
       "      <td>2018-08-09T21:22:37Z</td>\n",
       "      <td>We present a joint audio-visual model for isol...</td>\n",
       "      <td>[cs.SD, cs.CV, eess.AS]</td>\n",
       "      <td>189</td>\n",
       "      <td>http://arxiv.org/abs/1804.03619v2</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>ACM Transactions on Graphics (TOG) 37 (4), 1-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Convergence of univariate non-stationary subdi...</td>\n",
       "      <td>[Carla Manni, Costanza Conti, Marie-Laurence M...</td>\n",
       "      <td>2014-10-10T10:30:14Z</td>\n",
       "      <td>2014-10-10T10:30:14Z</td>\n",
       "      <td>A new equivalence notion between non-stationar...</td>\n",
       "      <td>[math.NA]</td>\n",
       "      <td>34</td>\n",
       "      <td>http://arxiv.org/abs/1410.2729v1</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>Computer Aided Geometric Design 37, 1-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID                                              title  \\\n",
       "0  0     Dynamic Graph CNN for Learning on Point Clouds   \n",
       "1  1  Looking to Listen at the Cocktail Party: A Spe...   \n",
       "2  2  Convergence of univariate non-stationary subdi...   \n",
       "\n",
       "                                             authors             published  \\\n",
       "0  [Yue Wang, Sanjay E. Sarma, Justin M. Solomon,...  2018-01-24T01:14:04Z   \n",
       "1  [Avinatan Hassidim, Oran Lang, Michael Rubinst...  2018-04-10T16:28:59Z   \n",
       "2  [Carla Manni, Costanza Conti, Marie-Laurence M...  2014-10-10T10:30:14Z   \n",
       "\n",
       "                updated                                           abstract  \\\n",
       "0  2019-06-11T06:11:21Z  Point clouds provide a flexible geometric repr...   \n",
       "1  2018-08-09T21:22:37Z  We present a joint audio-visual model for isol...   \n",
       "2  2014-10-10T10:30:14Z  A new equivalence notion between non-stationar...   \n",
       "\n",
       "                categories citations                          arxiv_url  \\\n",
       "0                  [cs.CV]       536  http://arxiv.org/abs/1801.07829v2   \n",
       "1  [cs.SD, cs.CV, eess.AS]       189  http://arxiv.org/abs/1804.03619v2   \n",
       "2                [math.NA]        34   http://arxiv.org/abs/1410.2729v1   \n",
       "\n",
       "                                        gscholar_url  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                           journal  \n",
       "0  ACM Transactions on Graphics (TOG) 38 (5), 1-12  \n",
       "1  ACM Transactions on Graphics (TOG) 37 (4), 1-11  \n",
       "2          Computer Aided Geometric Design 37, 1-8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hundred-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 485 entries, 0 to 484\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            485 non-null    object\n",
      " 1   title         485 non-null    object\n",
      " 2   authors       485 non-null    object\n",
      " 3   published     61 non-null     object\n",
      " 4   updated       61 non-null     object\n",
      " 5   abstract      61 non-null     object\n",
      " 6   categories    61 non-null     object\n",
      " 7   citations     476 non-null    object\n",
      " 8   arxiv_url     61 non-null     object\n",
      " 9   gscholar_url  476 non-null    object\n",
      " 10  journal       476 non-null    object\n",
      "dtypes: object(11)\n",
      "memory usage: 61.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "guilty-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'ID': 0,\n",
       "  'title': 'Dynamic Graph CNN for Learning on Point Clouds',\n",
       "  'authors': ['Yue Wang',\n",
       "   'Sanjay E. Sarma',\n",
       "   'Justin M. Solomon',\n",
       "   'Yongbin Sun',\n",
       "   'Ziwei Liu',\n",
       "   'Michael M. Bronstein'],\n",
       "  'published': '2018-01-24T01:14:04Z',\n",
       "  'updated': '2019-06-11T06:11:21Z',\n",
       "  'abstract': 'Point clouds provide a flexible geometric representation suitable forcountless applications in computer graphics; they also comprise the raw outputof most 3D data acquisition devices. While hand-designed features on pointclouds have long been proposed in graphics and vision, however, the recentoverwhelming success of convolutional neural networks (CNNs) for image analysissuggests the value of adapting insight from CNN to the point cloud world. Pointclouds inherently lack topological information so designing a model to recovertopology can enrich the representation power of point clouds. To this end, wepropose a new neural network module dubbed EdgeConv suitable for CNN-basedhigh-level tasks on point clouds including classification and segmentation.EdgeConv acts on graphs dynamically computed in each layer of the network. Itis differentiable and can be plugged into existing architectures. Compared toexisting modules operating in extrinsic space or treating each pointindependently, EdgeConv has several appealing properties: It incorporates localneighborhood information; it can be stacked applied to learn global shapeproperties; and in multi-layer systems affinity in feature space capturessemantic characteristics over potentially long distances in the originalembedding. We show the performance of our model on standard benchmarksincluding ModelNet40, ShapeNetPart, and S3DIS.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 38 (5), 1-12',\n",
       "  'citations': '536',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.07829v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=335276923828215991&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 1: {'ID': 1,\n",
       "  'title': 'Looking to Listen at the Cocktail Party: A Speaker-Independent  Audio-Visual Model for Speech Separation',\n",
       "  'authors': ['Avinatan Hassidim',\n",
       "   'Oran Lang',\n",
       "   'Michael Rubinstein',\n",
       "   'Inbar Mosseri',\n",
       "   'Ariel Ephrat',\n",
       "   'William T. Freeman',\n",
       "   'Kevin Wilson',\n",
       "   'Tali Dekel'],\n",
       "  'published': '2018-04-10T16:28:59Z',\n",
       "  'updated': '2018-08-09T21:22:37Z',\n",
       "  'abstract': 'We present a joint audio-visual model for isolating a single speech signalfrom a mixture of sounds such as other speakers and background noise. Solvingthis task using only audio as input is extremely challenging and does notprovide an association of the separated speech signals with speakers in thevideo. In this paper, we present a deep network-based model that incorporatesboth visual and auditory signals to solve this task. The visual features areused to \"focus\" the audio on desired speakers in a scene and to improve thespeech separation quality. To train our joint audio-visual model, we introduceAVSpeech, a new dataset comprised of thousands of hours of video segments fromthe Web. We demonstrate the applicability of our method to classic speechseparation tasks, as well as real-world scenarios involving heated interviews,noisy bars, and screaming children, only requiring the user to specify the faceof the person in the video whose speech they want to isolate. Our method showsclear advantage over state-of-the-art audio-only speech separation in cases ofmixed speech. In addition, our model, which is speaker-independent (trainedonce, applicable to any speaker), produces better results than recentaudio-visual speech separation methods that are speaker-dependent (requiretraining a separate model for each speaker of interest).',\n",
       "  'categories': ['cs.SD', 'cs.CV', 'eess.AS'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 37 (4), 1-11',\n",
       "  'citations': '189',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.03619v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11646994797171867166&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 2: {'ID': 2,\n",
       "  'title': 'Convergence of univariate non-stationary subdivision schemes via  asymptotical similarity',\n",
       "  'authors': ['Carla Manni',\n",
       "   'Costanza Conti',\n",
       "   'Marie-Laurence Mazure',\n",
       "   'Nira Dyn'],\n",
       "  'published': '2014-10-10T10:30:14Z',\n",
       "  'updated': '2014-10-10T10:30:14Z',\n",
       "  'abstract': 'A new equivalence notion between non-stationary subdivision schemes, termedasymptotical similarity, which is weaker than asymptotical equivalence, isintroduced and studied. It is known that asymptotical equivalence between anon-stationary subdivision scheme and a convergent stationary scheme guaranteesthe convergence of the non-stationary scheme. We show that for non-stationaryschemes reproducing constants, the condition of asymptotical equivalence can berelaxed to asymptotical similarity. This result applies to a wide class ofnon-stationary schemes of importance in theory and applications.',\n",
       "  'categories': ['math.NA'],\n",
       "  'journal': 'Computer Aided Geometric Design 37, 1-8',\n",
       "  'citations': '34',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1410.2729v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6429709954009202595&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 3: {'ID': 3,\n",
       "  'title': 'HDR image reconstruction from a single exposure using deep CNNs',\n",
       "  'authors': ['Joel Kronander',\n",
       "   'Rafał K. Mantiuk',\n",
       "   'Gyorgy Denes',\n",
       "   'Jonas Unger',\n",
       "   'Gabriel Eilertsen'],\n",
       "  'published': '2017-10-20T10:48:22Z',\n",
       "  'updated': '2017-10-20T10:48:22Z',\n",
       "  'abstract': 'Camera sensors can only capture a limited range of luminance simultaneously,and in order to create high dynamic range (HDR) images a set of differentexposures are typically combined. In this paper we address the problem ofpredicting information that have been lost in saturated image areas, in orderto enable HDR reconstruction from a single exposure. We show that this problemis well-suited for deep learning algorithms, and propose a deep convolutionalneural network (CNN) that is specifically designed taking into account thechallenges in predicting HDR values. To train the CNN we gather a large datasetof HDR images, which we augment by simulating sensor saturation for a range ofcameras. To further boost robustness, we pre-train the CNN on a simulated HDRdataset created from a subset of the MIT Places database. We demonstrate thatour approach can reconstruct high-resolution visually convincing HDR results ina wide range of situations, and that it generalizes well to reconstruction ofimages captured with arbitrary and low-end cameras that use unknown cameraresponse functions and post-processing. Furthermore, we compare to existingmethods for HDR expansion, and show high quality results also for image basedlighting. Finally, we evaluate the results in a subjective experiment performedon an HDR display. This shows that the reconstructed HDR images are visuallyconvincing, with large improvements as compared to existing methods.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (6), 1-15',\n",
       "  'citations': '145',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.07480v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3967051386974868046&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 4: {'ID': 4,\n",
       "  'title': 'Learning Style Similarity for Searching Infographics',\n",
       "  'authors': ['Aaron Hertzmann',\n",
       "   'Mira Dontcheva',\n",
       "   'Babak Saleh',\n",
       "   'Zhicheng Liu'],\n",
       "  'published': '2015-05-05T22:59:32Z',\n",
       "  'updated': '2015-05-05T22:59:32Z',\n",
       "  'abstract': 'Infographics are complex graphic designs integrating text, images, charts andsketches. Despite the increasing popularity of infographics and the rapidgrowth of online design portfolios, little research investigates how we cantake advantage of these design resources. In this paper we present a method formeasuring the style similarity between infographics. Based on human perceptiondata collected from crowdsourced experiments, we use computer vision andmachine learning algorithms to learn a style similarity metric for infographicdesigns. We evaluate different visual features and learning algorithms and findthat a combination of color histograms and Histograms-of-Gradients (HoG)features is most effective in characterizing the style of infographics. Wedemonstrate our similarity metric on a preliminary image retrieval test.',\n",
       "  'categories': ['cs.GR', 'cs.CV', 'cs.HC', 'cs.IR', 'cs.MM'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 59-64',\n",
       "  'citations': '24',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.01214v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13370213878445554393&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 5: {'ID': 5,\n",
       "  'title': 'Automatic Photo Adjustment Using Deep Neural Networks',\n",
       "  'authors': ['Yizhou Yu',\n",
       "   'Hao Zhang',\n",
       "   'Baoyuan Wang',\n",
       "   'Zhicheng Yan',\n",
       "   'Sylvain Paris'],\n",
       "  'published': '2014-12-24T17:51:17Z',\n",
       "  'updated': '2015-05-16T03:49:35Z',\n",
       "  'abstract': 'Photo retouching enables photographers to invoke dramatic visual impressionsby artistically enhancing their photos through stylistic color and toneadjustments. However, it is also a time-consuming and challenging task thatrequires advanced skills beyond the abilities of casual photographers. Using anautomated algorithm is an appealing alternative to manual work but such analgorithm faces many hurdles. Many photographic styles rely on subtleadjustments that depend on the image content and even its semantics. Further,these adjustments are often spatially varying. Because of thesecharacteristics, existing automatic algorithms are still limited and cover onlya subset of these challenges. Recently, deep machine learning has shown uniqueabilities to address hard problems that resisted machine algorithms for long.This motivated us to explore the use of deep learning in the context of photoediting. In this paper, we explain how to formulate the automatic photoadjustment problem in a way suitable for this approach. We also introduce animage descriptor that accounts for the local semantics of an image. Ourexperiments demonstrate that our deep learning formulation applied using thesedescriptors successfully capture sophisticated photographic styles. Inparticular and unlike previous techniques, it can model local adjustments thatdepend on the image semantics. We show on several examples that this yieldsresults that are qualitatively and quantitatively better than previous work.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG', 'eess.IV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (2), 1-15',\n",
       "  'citations': '154',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.7725v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7788777017613081738&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 6: {'ID': 6,\n",
       "  'title': 'Latent-space Physics: Towards Learning the Temporal Evolution of Fluid  Flow',\n",
       "  'authors': ['Steffen Wiewel', 'Nils Thuerey', 'Moritz Becher'],\n",
       "  'published': '2018-02-27T19:18:43Z',\n",
       "  'updated': '2019-03-05T09:58:44Z',\n",
       "  'abstract': 'We propose a method for the data-driven inference of temporal evolutions ofphysical functions with deep learning. More specifically, we target fluidflows, i.e. Navier-Stokes problems, and we propose a novel LSTM-based approachto predict the changes of pressure fields over time. The central challenge inthis context is the high dimensionality of Eulerian space-time data sets. Wedemonstrate for the first time that dense 3D+time functions of physics systemcan be predicted within the latent spaces of neural networks, and we arrive ata neural-network based simulation algorithm with significant practicalspeed-ups. We highlight the capabilities of our method with a series of complexliquid simulations, and with a set of single-phase buoyancy simulations. With aset of trained networks, our method is more than two orders of magnitudesfaster than a traditional pressure solver. Additionally, we present and discussa series of detailed evaluations for the different components of our algorithm.',\n",
       "  'categories': ['cs.LG', 'cs.GR'],\n",
       "  'journal': 'Computer Graphics Forum 38 (2), 71-82',\n",
       "  'citations': '58',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.10123v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11807274886813048961&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 7: {'ID': 7,\n",
       "  'title': 'Complexity of hierarchical refinement for a class of admissible mesh  configurations',\n",
       "  'authors': ['Philipp Morgenstern',\n",
       "   'Carlotta Giannelli',\n",
       "   'Daniel Peterseim',\n",
       "   'Annalisa Buffa'],\n",
       "  'published': '2015-09-18T09:59:14Z',\n",
       "  'updated': '2015-09-18T09:59:14Z',\n",
       "  'abstract': 'An adaptive isogeometric method based on $d$-variate hierarchical splineconstructions can be derived by considering a refine module that preserves acertain class of admissibility between two consecutive steps of the adaptiveloop [6]. In this paper we provide a complexity estimate, i.e., an estimate onhow the number of mesh elements grows with respect to the number of elementsthat are marked for refinement by the adaptive strategy. Our estimate is in theline of the similar ones proved in the finite element context, [3,24].',\n",
       "  'categories': ['math.NA'],\n",
       "  'journal': 'Computer Aided Geometric Design 47, 83-92',\n",
       "  'citations': '22',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.05566v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8284531875455370376&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 8: {'ID': 8,\n",
       "  'title': 'A Workflow for Visual Diagnostics of Binary Classifiers using  Instance-Level Explanations',\n",
       "  'authors': ['Josua Krause',\n",
       "   'Jordan Swartz',\n",
       "   'Enrico Bertini',\n",
       "   'Yindalon Aphinyanaphongs',\n",
       "   'Aritra Dasgupta'],\n",
       "  'published': '2017-05-04T18:24:38Z',\n",
       "  'updated': '2017-10-01T22:24:17Z',\n",
       "  'abstract': 'Human-in-the-loop data analysis applications necessitate greater transparencyin machine learning models for experts to understand and trust their decisions.To this end, we propose a visual analytics workflow to help data scientists anddomain experts explore, diagnose, and understand the decisions made by a binaryclassifier. The approach leverages \"instance-level explanations\", measures oflocal feature relevance that explain single instances, and uses them to build aset of visual representations that guide the users in their investigation. Theworkflow is based on three main visual representations and steps: one based onaggregate statistics to see how data distributes across correct / incorrectdecisions; one based on explanations to understand which features are used tomake these decisions; and one based on raw data, to derive insights onpotential root causes for the observed patterns. The workflow is derived from along-term collaboration with a group of machine learning and healthcareprofessionals who used our method to make sense of machine learning models theydeveloped. The case study from this collaboration demonstrates that theproposed workflow helps experts derive useful knowledge about the model and thephenomena it describes, thus experts can generate useful hypotheses on how amodel can be improved.',\n",
       "  'categories': ['stat.ML', 'cs.AI'],\n",
       "  'journal': '2017 IEEE Conference on Visual Analytics Science and Technology (VAST), 162-172',\n",
       "  'citations': '44',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.01968v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8112720882727079109&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 9: {'ID': 9,\n",
       "  'title': 'Do Convolutional Neural Networks Learn Class Hierarchy?',\n",
       "  'authors': ['Bilal Alsallakh',\n",
       "   'Liu Ren',\n",
       "   'Xiaoming Liu',\n",
       "   'Mao Ye',\n",
       "   'Amin Jourabloo'],\n",
       "  'published': '2017-10-17T21:02:59Z',\n",
       "  'updated': '2017-10-17T21:02:59Z',\n",
       "  'abstract': 'Convolutional Neural Networks (CNNs) currently achieve state-of-the-artaccuracy in image classification. With a growing number of classes, theaccuracy usually drops as the possibilities of confusion increase.Interestingly, the class confusion patterns follow a hierarchical structureover the classes. We present visual-analytics methods to reveal and analyzethis hierarchy of similar classes in relation with CNN-internal data. We foundthat this hierarchy not only dictates the confusion patterns between theclasses, it furthermore dictates the learning behavior of CNNs. In particular,the early layers in these networks develop feature detectors that can separatehigh-level groups of classes quite well, even after a few training epochs. Incontrast, the latter layers require substantially more epochs to developspecialized feature detectors that can separate individual classes. Wedemonstrate how these insights are key to significant improvement in accuracyby designing hierarchy-aware CNNs that accelerate model convergence andalleviate overfitting. We further demonstrate how our methods help inidentifying various quality issues in the training data.',\n",
       "  'categories': ['cs.CV', 'I.4; I.5'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 152-162',\n",
       "  'citations': '85',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.06501v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2268614162512437100&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 10: {'ID': 10,\n",
       "  'title': 'Convolutional Sparse Coding for High Dynamic Range Imaging',\n",
       "  'authors': ['Felix Heide',\n",
       "   'Diego Gutierrez',\n",
       "   'Gordon Wetzstein',\n",
       "   'Ana Serrano',\n",
       "   'Belen Masia'],\n",
       "  'published': '2018-06-13T10:48:33Z',\n",
       "  'updated': '2018-06-13T10:48:33Z',\n",
       "  'abstract': 'Current HDR acquisition techniques are based on either (i) fusingmultibracketed, low dynamic range (LDR) images, (ii) modifying existinghardware and capturing different exposures simultaneously with multiplesensors, or (iii) reconstructing a single image with spatially-varying pixelexposures. In this paper, we propose a novel algorithm to recover high-qualityHDRI images from a single, coded exposure. The proposed reconstruction methodbuilds on recently-introduced ideas of convolutional sparse coding (CSC); thispaper demonstrates how to make CSC practical for HDR imaging. We demonstratethat the proposed algorithm achieves higher-quality reconstructions thanalternative methods, we evaluate optical coding schemes, analyze algorithmicparameters, and build a prototype coded HDR camera that demonstrates theutility of convolutional sparse HDRI coding with a custom hardware platform.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'eess.IV'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 153-163',\n",
       "  'citations': '58',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.04942v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16614517772020097554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 11: {'ID': 11,\n",
       "  'title': 'DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based  Character Skills',\n",
       "  'authors': ['Sergey Levine',\n",
       "   'Pieter Abbeel',\n",
       "   'Michiel van de Panne',\n",
       "   'Xue Bin Peng'],\n",
       "  'published': '2018-04-08T17:04:58Z',\n",
       "  'updated': '2018-07-27T03:44:10Z',\n",
       "  'abstract': 'A longstanding goal in character animation is to combine data-drivenspecification of behavior with a system that can execute a similar behavior ina physical simulation, thus enabling realistic responses to perturbations andenvironmental variation. We show that well-known reinforcement learning (RL)methods can be adapted to learn robust control policies capable of imitating abroad range of example motion clips, while also learning complex recoveries,adapting to changes in morphology, and accomplishing user-specified goals. Ourmethod handles keyframed motions, highly-dynamic actions such asmotion-captured flips and spins, and retargeted motions. By combining amotion-imitation objective with a task objective, we can train characters thatreact intelligently in interactive settings, e.g., by walking in a desireddirection or throwing a ball at a user-specified target. This approach thuscombines the convenience and motion quality of using motion clips to define thedesired style and appearance, with the flexibility and generality afforded byRL methods and physics-based animation. We further explore a number of methodsfor integrating multiple clips into the learning process to developmulti-skilled agents capable of performing a rich repertoire of diverse skills.We demonstrate results using multiple characters (human, Atlas robot, bipedaldinosaur, dragon) and a large variety of skills, including locomotion,acrobatics, and martial arts.',\n",
       "  'categories': ['cs.GR', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 37 (4), 1-14',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.02717v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15283892025726236675&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 12: {'ID': 12,\n",
       "  'title': 'Visual Analytics for Explainable Deep Learning',\n",
       "  'authors': ['Jaegul Choo', 'Shixia Liu'],\n",
       "  'published': '2018-04-07T07:52:04Z',\n",
       "  'updated': '2018-04-07T07:52:04Z',\n",
       "  'abstract': 'Recently, deep learning has been advancing the state of the art in artificialintelligence to a new level, and humans rely on artificial intelligencetechniques more than ever. However, even with such unprecedented advancements,the lack of explanation regarding the decisions made by deep learning modelsand absence of control over their internal processes act as major drawbacks incritical decision-making processes, such as precision medicine and lawenforcement. In response, efforts are being made to make deep learninginterpretable and controllable by humans. In this paper, we review visualanalytics, information visualization, and machine learning perspectivesrelevant to this aim, and discuss potential challenges and future researchdirections.',\n",
       "  'categories': ['cs.HC', 'cs.LG', 'stat.ML', 'I.6.9.c'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 38 (4), 84-92',\n",
       "  'citations': '58',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.02527v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9171929386321989566&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 13: {'ID': 13,\n",
       "  'title': 'Real-Time User-Guided Image Colorization with Learned Deep Priors',\n",
       "  'authors': ['Angela S. Lin',\n",
       "   'Xinyang Geng',\n",
       "   'Jun-Yan Zhu',\n",
       "   'Phillip Isola',\n",
       "   'Richard Zhang',\n",
       "   'Alexei A. Efros',\n",
       "   'Tianhe Yu'],\n",
       "  'published': '2017-05-08T17:58:11Z',\n",
       "  'updated': '2017-05-08T17:58:11Z',\n",
       "  'abstract': 'We propose a deep learning approach for user-guided image colorization. Thesystem directly maps a grayscale image, along with sparse, local user \"hints\"to an output colorization with a Convolutional Neural Network (CNN). Ratherthan using hand-defined rules, the network propagates user edits by fusinglow-level cues along with high-level semantic information, learned fromlarge-scale data. We train on a million images, with simulated user inputs. Toguide the user towards efficient input selection, the system recommends likelycolors based on the input image and current user inputs. The colorization isperformed in a single feed-forward pass, enabling real-time use. Even withrandomly simulated user inputs, we show that the proposed system helps noviceusers quickly create realistic colorizations, and offers large improvements incolorization quality with just a minute of use. In addition, we demonstratethat the framework can incorporate other user \"hints\" to the desiredcolorization, showing an application to color histogram transfer. Our code andmodels are available at https://richzhang.github.io/ideepcolor.',\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-11',\n",
       "  'citations': '165',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.02999v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2711985086398037736&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 14: {'ID': 14,\n",
       "  'title': 'Human Pose Regression by Combining Indirect Part Detection and  Contextual Information',\n",
       "  'authors': ['David Picard', 'Hedi Tabia', 'Diogo C. Luvizon'],\n",
       "  'published': '2017-10-06T09:27:44Z',\n",
       "  'updated': '2017-10-06T09:27:44Z',\n",
       "  'abstract': 'In this paper, we propose an end-to-end trainable regression approach forhuman pose estimation from still images. We use the proposed Soft-argmaxfunction to convert feature maps directly to joint coordinates, resulting in afully differentiable framework. Our method is able to learn heat mapsrepresentations indirectly, without additional steps of artificial ground truthgeneration. Consequently, contextual information can be included to the posepredictions in a seamless way. We evaluated our method on two very challengingdatasets, the Leeds Sports Poses (LSP) and the MPII Human Pose datasets,reaching the best performance among all the existing regression methods andcomparable results to the state-of-the-art detection based approaches.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Computers & Graphics 85, 15-22',\n",
       "  'citations': '47',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.02322v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13722513634620778734&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 15: {'ID': 15,\n",
       "  'title': 'Learning-Based View Synthesis for Light Field Cameras',\n",
       "  'authors': ['Nima Khademi Kalantari', 'Ravi Ramamoorthi', 'Ting-Chun Wang'],\n",
       "  'published': '2016-09-09T23:33:38Z',\n",
       "  'updated': '2016-09-09T23:33:38Z',\n",
       "  'abstract': 'With the introduction of consumer light field cameras, light field imaginghas recently become widespread. However, there is an inherent trade-off betweenthe angular and spatial resolution, and thus, these cameras often sparselysample in either spatial or angular domain. In this paper, we use machinelearning to mitigate this trade-off. Specifically, we propose a novellearning-based approach to synthesize new views from a sparse set of inputviews. We build upon existing view synthesis techniques and break down theprocess into disparity and color estimation components. We use two sequentialconvolutional neural networks to model these two components and train bothnetworks simultaneously by minimizing the error between the synthesized andground truth images. We show the performance of our approach using only fourcorner sub-aperture views from the light fields captured by the Lytro Illumcamera. Experimental results show that our approach synthesizes high-qualityimages that are superior to the state-of-the-art techniques on a variety ofchallenging real-world scenes. We believe our method could potentially decreasethe required angular resolution of consumer light field cameras, which allowstheir spatial resolution to increase.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'I.4.1'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-10',\n",
       "  'citations': '256',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.02974v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16849875977468061323&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 16: {'ID': 16,\n",
       "  'title': 'Partial Functional Correspondence',\n",
       "  'authors': ['Emanuele Rodolà',\n",
       "   'Daniel Cremers',\n",
       "   'Luca Cosmo',\n",
       "   'Michael M. Bronstein',\n",
       "   'Andrea Torsello'],\n",
       "  'published': '2015-06-17T10:47:20Z',\n",
       "  'updated': '2015-12-22T12:57:25Z',\n",
       "  'abstract': 'In this paper, we propose a method for computing partial functionalcorrespondence between non-rigid shapes. We use perturbation analysis to showhow removal of shape parts changes the Laplace-Beltrami eigenfunctions, andexploit it as a prior on the spectral representation of the correspondence.Corresponding parts are optimization variables in our problem and are used toweight the functional correspondence; we are looking for the largest and mostregular (in the Mumford-Shah sense) parts that minimize correspondencedistortion. We show that our approach can cope with very challengingcorrespondence settings.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Computer Graphics Forum 36 (1), 222-236',\n",
       "  'citations': '114',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.05274v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5825378212777391556&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 17: {'ID': 17,\n",
       "  'title': 'Visual Analytics in Deep Learning: An Interrogative Survey for the Next  Frontiers',\n",
       "  'authors': ['Duen Horng Chau',\n",
       "   'Robert Pienta',\n",
       "   'Fred Hohman',\n",
       "   'Minsuk Kahng'],\n",
       "  'published': '2018-01-21T20:13:07Z',\n",
       "  'updated': '2018-05-14T04:59:24Z',\n",
       "  'abstract': \"Deep learning has recently seen rapid development and received significantattention due to its state-of-the-art performance on previously-thought hardproblems. However, because of the internal complexity and nonlinear structureof deep neural networks, the underlying decision making processes for why thesemodels are achieving such performance are challenging and sometimes mystifyingto interpret. As deep learning spreads across domains, it is of paramountimportance that we equip users of deep learning with tools for understandingwhen a model works correctly, when it fails, and ultimately how to improve itsperformance. Standardized toolkits for building neural networks have helpeddemocratize deep learning; visual analytics systems have now been developed tosupport model explanation, interpretation, debugging, and improvement. Wepresent a survey of the role of visual analytics in deep learning research,which highlights its short yet impactful history and thoroughly summarizes thestate-of-the-art using a human-centered interrogative framework, focusing onthe Five W's and How (Why, Who, What, How, When, and Where). We conclude byhighlighting research directions and open research problems. This survey helpsresearchers and practitioners in both visual analytics and deep learning toquickly learn key aspects of this young and rapidly growing body of research,whose impact spans a diverse range of domains.\",\n",
       "  'categories': ['cs.HC',\n",
       "   'cs.AI',\n",
       "   'cs.LG',\n",
       "   'stat.ML',\n",
       "   'H.5.2; I.5.1.d; I.6.9.c; I.6.9.f; I.2.6.g'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 25 (8), 2674-2693',\n",
       "  'citations': '153',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.06889v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17948803302752343025&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 18: {'ID': 18,\n",
       "  'title': 'Exploring the Limits of Complexity: A Survey of Empirical Studies on  Graph Visualisation',\n",
       "  'authors': ['Hsiang-Yun Wu',\n",
       "   'Stephan Diehl',\n",
       "   'Daniel Archambault',\n",
       "   'Vahan Yoghourdjian',\n",
       "   'Karsten Klein',\n",
       "   'Tim Dwyer',\n",
       "   'Helen C. Purchase'],\n",
       "  'published': '2018-09-02T00:03:54Z',\n",
       "  'updated': '2018-09-02T00:03:54Z',\n",
       "  'abstract': \"For decades, researchers in information visualisation and graph drawing havefocused on developing techniques for the layout and display of very large andcomplex networks. Experiments involving human participants have also exploredthe readability of different styles of layout and representations for suchnetworks. In both bodies of literature, networks are frequently referred to asbeing 'large' or 'complex', yet these terms are relative. From a human-centred,experiment point-of-view, what constitutes 'large' (for example) depends onseveral factors, such as data complexity, visual complexity, and the technologyused. In this paper, we survey the literature on human-centred experiments tounderstand how, in practice, different features and characteristics ofnode-link diagrams affect visual complexity.\",\n",
       "  'categories': ['cs.HC'],\n",
       "  'journal': 'Visual Informatics 2 (4), 264-282',\n",
       "  'citations': '11',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.00270v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17065671282143514810&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 19: {'ID': 19,\n",
       "  'title': 'From 3D Models to 3D Prints: an Overview of the Processing Pipeline',\n",
       "  'authors': ['Marco Attene',\n",
       "   'Jonás Martìnez',\n",
       "   'Marco Livesu',\n",
       "   'Sylvain Lefebvre',\n",
       "   'Stefano Ellero'],\n",
       "  'published': '2017-05-10T15:12:14Z',\n",
       "  'updated': '2017-09-21T09:35:30Z',\n",
       "  'abstract': 'Due to the wide diffusion of 3D printing technologies, geometric algorithmsfor Additive Manufacturing are being invented at an impressive speed. Eachsingle step, in particular along the Process Planning pipeline, can now counton dozens of methods that prepare the 3D model for fabrication, while analysingand optimizing geometry and machine instructions for various objectives. Thisreport provides a classification of this huge state of the art, and elicits therelation between each single algorithm and a list of desirable objectivesduring Process Planning. The objectives themselves are listed and discussed,along with possible needs for tradeoffs. Additive Manufacturing technologiesare broadly categorized to explicitly relate classes of devices and supportedfeatures. Finally, this report offers an analysis of the state of the art whilediscussing open and challenging problems from both an academic and anindustrial perspective.',\n",
       "  'categories': ['cs.GR'],\n",
       "  'journal': 'Computer Graphics Forum 36 (2), 537-564',\n",
       "  'citations': '74',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.03811v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15259216674538466453&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 20: {'ID': 20,\n",
       "  'title': 'Notions of optimal transport theory and how to implement them on a  computer',\n",
       "  'authors': ['Bruno Levy', 'Erica Schwindt'],\n",
       "  'published': '2017-10-07T04:55:17Z',\n",
       "  'updated': '2017-10-07T04:55:17Z',\n",
       "  'abstract': 'This article gives an introduction to optimal transport, a mathematicaltheory that makes it possible to measure distances between functions (ordistances between more general objects), to interpolate between objects or toenforce mass/volume conservation in certain computational physics simulations.Optimal transport is a rich scientific domain, with active researchcommunities, both on its theoretical aspects and on more applicativeconsiderations, such as geometry processing and machine learning. This articleaims at explaining the main principles behind the theory of optimal transport,introduce the different involved notions, and more importantly, how theyrelate, to let the reader grasp an intuition of the elegant theory thatstructures them. Then we will consider a specific setting, calledsemi-discrete, where a continuous function is transported to a discrete sum ofDirac masses. Studying this specific setting naturally leads to an efficientcomputational algorithm, that uses classical notions of computational geometry,such as a generalization of Voronoi diagrams called Laguerre diagrams.',\n",
       "  'categories': ['math.AP', 'math.NA', '49M15, 35J96, 65D18'],\n",
       "  'journal': 'Computers & Graphics 72, 135-148',\n",
       "  'citations': '37',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.02634v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3949198417924923866&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 21: {'ID': 21,\n",
       "  'title': '3D Shape Segmentation via Shape Fully Convolutional Networks',\n",
       "  'authors': ['Panpan Shui',\n",
       "   'Zhengxing Sun',\n",
       "   'Fenggen Yu',\n",
       "   'Songle Chen',\n",
       "   'Yuan Gan',\n",
       "   'Pengyu Wang',\n",
       "   'Yan Zhang'],\n",
       "  'published': '2017-02-28T07:26:55Z',\n",
       "  'updated': '2018-05-26T01:45:21Z',\n",
       "  'abstract': 'We desgin a novel fully convolutional network architecture for shapes,denoted by Shape Fully Convolutional Networks (SFCN). 3D shapes are representedas graph structures in the SFCN architecture, based on novel graph convolutionand pooling operations, which are similar to convolution and pooling operationsused on images. Meanwhile, to build our SFCN architecture in the original imagesegmentation fully convolutional network (FCN) architecture, we also design andimplement a generating operation} with bridging function. This ensures that theconvolution and pooling operation we have designed can be successfully appliedin the original FCN architecture. In this paper, we also present a new shapesegmentation approach based on SFCN. Furthermore, we allow more general andchallenging input, such as mixed datasets of different categories of shapes}which can prove the ability of our generalisation. In our approach, SFCNs aretrained triangles-to-triangles by using three low-level geometric features asinput. Finally, the feature voting-based multi-label graph cuts is adopted tooptimise the segmentation results obtained by SFCN prediction. The experimentresults show that our method can effectively learn and predict mixed shapedatasets of either similar or different characteristics, and achieve excellentsegmentation results.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Computers & Graphics 70, 128-139',\n",
       "  'citations': '30',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.08675v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1865468074502931614&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 22: {'ID': 22,\n",
       "  'title': 'Deep Bilateral Learning for Real-Time Image Enhancement',\n",
       "  'authors': ['Jonathan T. Barron',\n",
       "   'Michaël Gharbi',\n",
       "   'Samuel W. Hasinoff',\n",
       "   'Frédo Durand',\n",
       "   'Jiawen Chen'],\n",
       "  'published': '2017-07-10T14:34:06Z',\n",
       "  'updated': '2017-08-22T19:26:08Z',\n",
       "  'abstract': 'Performance is a critical challenge in mobile image processing. Given areference imaging pipeline, or even human-adjusted pairs of images, we seek toreproduce the enhancements and enable real-time evaluation. For this, weintroduce a new neural network architecture inspired by bilateral gridprocessing and local affine color transforms. Using pairs of input/outputimages, we train a convolutional neural network to predict the coefficients ofa locally-affine model in bilateral space. Our architecture learns to makelocal, global, and content-dependent decisions to approximate the desired imagetransformation. At runtime, the neural network consumes a low-resolutionversion of the input image, produces a set of affine transformations inbilateral space, upsamples those transformations in an edge-preserving fashionusing a new slicing node, and then applies those upsampled transformations tothe full-resolution image. Our algorithm processes high-resolution images on asmartphone in milliseconds, provides a real-time viewfinder at 1080presolution, and matches the quality of state-of-the-art approximationtechniques on a large class of image operators. Unlike previous work, our modelis trained off-line from data and therefore does not require access to theoriginal operator at runtime. This allows our model to learn complex,scene-dependent transformations for which no reference implementation isavailable, such as the photographic edits of a human retoucher.',\n",
       "  'categories': ['cs.GR', 'cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-12',\n",
       "  'citations': '163',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.02880v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16373356176357810725&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 23: {'ID': 23,\n",
       "  'title': 'Position-Based Multi-Agent Dynamics for Real-Time Crowd Simulation (MiG  paper)',\n",
       "  'authors': ['Alan Litteneker',\n",
       "   'Demetri Terzopoulos',\n",
       "   'Tomer Weiss',\n",
       "   'Chenfanfu Jiang'],\n",
       "  'published': '2018-02-07T23:37:20Z',\n",
       "  'updated': '2018-02-20T01:58:15Z',\n",
       "  'abstract': 'Exploiting the efficiency and stability of Position-Based Dynamics (PBD), weintroduce a novel crowd simulation method that runs at interactive rates forhundreds of thousands of agents. Our method enables the detailed modeling ofper-agent behavior in a Lagrangian formulation. We model short-range andlong-range collision avoidance to simulate both sparse and dense crowds. On theparticles representing agents, we formulate a set of positional constraintsthat can be readily integrated into a standard PBD solver. We augment thetentative particle motions with planning velocities to determine the preferredvelocities of agents, and project the positions onto the constraint manifold toeliminate colliding configurations. The local short-range interaction isrepresented with collision and frictional contact between agents, as in thediscrete simulation of granular materials. We incorporate a cohesion model formodeling collective behaviors and propose a new constraint for dealing withpotential future collisions. Our new method is suitable for use in interactivegames.',\n",
       "  'categories': ['cs.GR'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '19',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.02673v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8861249093165917571&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 24: {'ID': 24,\n",
       "  'title': 'Analysis-suitable adaptive T-mesh refinement with linear complexity',\n",
       "  'authors': ['Philipp Morgenstern', 'Daniel Peterseim'],\n",
       "  'published': '2014-07-23T11:11:11Z',\n",
       "  'updated': '2014-12-13T22:51:56Z',\n",
       "  'abstract': 'We present an efficient adaptive refinement procedure that preservesanalysis-suitability of the T-mesh, this is, the linear independence of theT-spline blending functions. We prove analysis-suitability of the overlays andboundedness of their cardinalities, nestedness of the generated T-splinespaces, and linear computational complexity of the refinement procedure interms of the number of marked and generated mesh elements.',\n",
       "  'categories': ['math.NA', '65D17, 65N30, 65N50'],\n",
       "  'journal': 'Computer Aided Geometric Design 34, 50-66',\n",
       "  'citations': '44',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1407.6175v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13032291696084821209&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 25: {'ID': 25,\n",
       "  'title': 'Point Convolutional Neural Networks by Extension Operators',\n",
       "  'authors': ['Haggai Maron', 'Yaron Lipman', 'Matan Atzmon'],\n",
       "  'published': '2018-03-27T14:06:16Z',\n",
       "  'updated': '2018-03-27T14:06:16Z',\n",
       "  'abstract': 'This paper presents Point Convolutional Neural Networks (PCNN): a novelframework for applying convolutional neural networks to point clouds. Theframework consists of two operators: extension and restriction, mapping pointcloud functions to volumetric functions and vise-versa. A point cloudconvolution is defined by pull-back of the Euclidean volumetric convolution viaan extension-restriction mechanism.  The point cloud convolution is computationally efficient, invariant to theorder of points in the point cloud, robust to different samplings and varyingdensities, and translation invariant, that is the same convolution kernel isused at all points. PCNN generalizes image CNNs and allows readily adaptingtheir architectures to the point cloud setting.  Evaluation of PCNN on three central point cloud learning benchmarksconvincingly outperform competing point cloud learning methods, and the vastmajority of methods working with more informative shape representations such assurfaces and/or normals.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 37 (4), 1-12',\n",
       "  'citations': '105',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.10091v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6536237032480059688&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 26: {'ID': 26,\n",
       "  'title': 'Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse  IMUs',\n",
       "  'authors': ['Gerard Pons-Moll',\n",
       "   'Timo von Marcard',\n",
       "   'Bodo Rosenhahn',\n",
       "   'Michael J. Black'],\n",
       "  'published': '2017-03-23T11:35:41Z',\n",
       "  'updated': '2017-03-24T08:24:07Z',\n",
       "  'abstract': 'We address the problem of making human motion capture in the wild morepractical by using a small set of inertial sensors attached to the body. Sincethe problem is heavily under-constrained, previous methods either use a largenumber of sensors, which is intrusive, or they require additional video input.We take a different approach and constrain the problem by: (i) making use of arealistic statistical body model that includes anthropometric constraints and(ii) using a joint optimization framework to fit the model to orientation andacceleration measurements over multiple frames. The resulting tracker SparseInertial Poser (SIP) enables 3D human pose estimation using only 6 sensors(attached to the wrists, lower legs, back and head) and works for arbitraryhuman motions. Experiments on the recently released TNT15 dataset show that,using the same number of sensors, SIP achieves higher accuracy than the datasetbaseline without using any video data. We further demonstrate the effectivenessof SIP on newly recorded challenging motions in outdoor scenarios such asclimbing or jumping over a wall.',\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'Computer Graphics Forum 36 (2), 349-360',\n",
       "  'citations': '88',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.08014v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11065955911209965273&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 27: {'ID': 27,\n",
       "  'title': 'PCPNET: Learning Local Shape Properties from Raw Point Clouds',\n",
       "  'authors': ['Niloy J. Mitra',\n",
       "   'Maks Ovsjanikov',\n",
       "   'Paul Guerrero',\n",
       "   'Yanir Kleiman'],\n",
       "  'published': '2017-10-13T15:02:18Z',\n",
       "  'updated': '2018-06-19T13:35:22Z',\n",
       "  'abstract': 'In this paper, we propose PCPNet, a deep-learning based approach forestimating local 3D shape properties in point clouds. In contrast to themajority of prior techniques that concentrate on global or mid-levelattributes, e.g., for shape classification or semantic labeling, we suggest apatch-based learning method, in which a series of local patches at multiplescales around each point is encoded in a structured manner. Our approach isespecially well-adapted for estimating local shape properties such as normals(both unoriented and oriented) and curvature from raw point clouds in thepresence of strong noise and multi-scale features. Our main contributionsinclude both a novel multi-scale variant of the recently proposed PointNetarchitecture with emphasis on local shape information, and a series of novelapplications in which we demonstrate how learning from training data arisingfrom well-structured triangle meshes, and applying the trained model to noisypoint clouds can produce superior results compared to specializedstate-of-the-art techniques. Finally, we demonstrate the utility of ourapproach in the context of shape reconstruction, by showing how it can be usedto extract normal orientation information from point clouds.',\n",
       "  'categories': ['cs.CG'],\n",
       "  'journal': 'Computer Graphics Forum 37 (2), 75-85',\n",
       "  'citations': '83',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.04954v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10560557495650402199&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 28: {'ID': 28,\n",
       "  'title': 'Production-Level Facial Performance Capture Using Deep Convolutional  Neural Networks',\n",
       "  'authors': ['Hao Li',\n",
       "   'Timo Aila',\n",
       "   'Antti Herva',\n",
       "   'Tero Karras',\n",
       "   'Samuli Laine',\n",
       "   'Jaakko Lehtinen',\n",
       "   'Ronald Yu',\n",
       "   'Shunsuke Saito'],\n",
       "  'published': '2016-09-21T12:55:59Z',\n",
       "  'updated': '2017-06-02T13:54:51Z',\n",
       "  'abstract': \"We present a real-time deep learning framework for video-based facialperformance capture -- the dense 3D tracking of an actor's face given amonocular video. Our pipeline begins with accurately capturing a subject usinga high-end production facial capture pipeline based on multi-view stereotracking and artist-enhanced animations. With 5-10 minutes of captured footage,we train a convolutional neural network to produce high-quality output,including self-occluded regions, from a monocular video sequence of thatsubject. Since this 3D facial performance capture is fully automated, oursystem can drastically reduce the amount of labor involved in the developmentof modern narrative-driven video games or films involving realistic digitaldoubles of actors and potentially hours of animated dialogue per character. Wecompare our results with several state-of-the-art monocular real-time facialcapture techniques and demonstrate compelling animation inference inchallenging areas such as eyes and lips.\",\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '58',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.06536v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18167780940308058978&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 29: {'ID': 29,\n",
       "  'title': 'Infill Optimization for Additive Manufacturing -- Approaching Bone-like  Porous Structures',\n",
       "  'authors': ['Jun Wu', 'Ruediger Westermann', 'Niels Aage', 'Ole Sigmund'],\n",
       "  'published': '2016-08-15T19:02:30Z',\n",
       "  'updated': '2016-11-19T16:24:27Z',\n",
       "  'abstract': 'Porous structures such as trabecular bone are widely seen in nature. Thesestructures exhibit superior mechanical properties whilst being lightweight. Inthis paper, we present a method to generate bone-like porous structures aslightweight infill for additive manufacturing. Our method builds upon andextends voxel-wise topology optimization. In particular, for the purpose ofgenerating sparse yet stable structures distributed in the interior of a givenshape, we propose upper bounds on the localized material volume in theproximity of each voxel in the design domain. We then aggregate the localper-voxel constraints by their p-norm into an equivalent global constraint, inorder to facilitate an efficient optimization process. Implemented on ahigh-resolution topology optimization framework, our results demonstratemechanically optimized, detailed porous structures which mimic those found innature. We further show variants of the optimized structures subject todifferent design specifications, and analyze the optimality and robustness ofthe obtained structures.',\n",
       "  'categories': ['cs.GR'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (2), 1127-1140',\n",
       "  'citations': '150',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.04366v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18012011262134932527&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 30: {'ID': 30,\n",
       "  'title': 'A Geometric View of Optimal Transportation and Generative Model',\n",
       "  'authors': ['David Xianfeng Gu',\n",
       "   'Li Cui',\n",
       "   'Shing-Tung Yau',\n",
       "   'Kehua Su',\n",
       "   'Na Lei'],\n",
       "  'published': '2017-10-16T03:30:09Z',\n",
       "  'updated': '2017-12-19T04:28:31Z',\n",
       "  'abstract': 'In this work, we show the intrinsic relations between optimal transportationand convex geometry, especially the variational approach to solve Alexandrovproblem: constructing a convex polytope with prescribed face normals andvolumes. This leads to a geometric interpretation to generative models, andleads to a novel framework for generative models. By using the optimaltransportation view of GAN model, we show that the discriminator computes theKantorovich potential, the generator calculates the transportation map. For alarge class of transportation costs, the Kantorovich potential can give theoptimal transportation map by a close-form formula. Therefore, it is sufficientto solely optimize the discriminator. This shows the adversarial competitioncan be avoided, and the computational architecture can be simplified.Preliminary experimental results show the geometric method outperforms WGAN forapproximating probability measures with multiple clusters in low dimensionalspace.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Computer Aided Geometric Design 68, 1-21',\n",
       "  'citations': '27',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.05488v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11405228893469185376&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 31: {'ID': 31,\n",
       "  'title': 'Stereo Magnification: Learning View Synthesis using Multiplane Images',\n",
       "  'authors': ['Tinghui Zhou',\n",
       "   'John Flynn',\n",
       "   'Noah Snavely',\n",
       "   'Richard Tucker',\n",
       "   'Graham Fyffe'],\n",
       "  'published': '2018-05-24T17:58:02Z',\n",
       "  'updated': '2018-05-24T17:58:02Z',\n",
       "  'abstract': 'The view synthesis problem--generating novel views of a scene from knownimagery--has garnered recent attention due in part to compelling applicationsin virtual and augmented reality. In this paper, we explore an intriguingscenario for view synthesis: extrapolating views from imagery captured bynarrow-baseline stereo cameras, including VR cameras and now-widespreaddual-lens camera phones. We call this problem stereo magnification, and proposea learning framework that leverages a new layered representation that we callmultiplane images (MPIs). Our method also uses a massive new data source forlearning view extrapolation: online videos on YouTube. Using data mined fromsuch videos, we train a deep network that predicts an MPI from an input stereoimage pair. This inferred MPI can then be used to synthesize a range of novelviews of the scene, including views that extrapolate significantly beyond theinput baseline. We show that our method compares favorably with several recentview synthesis methods, and demonstrate applications in magnifyingnarrow-baseline stereo images.',\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 37 (4), 1-12',\n",
       "  'citations': '92',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.09817v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5477337401753867759&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 32: {'ID': 32,\n",
       "  'title': 'Recent Advances in Transient Imaging: A Computer Graphics and Vision  Perspective',\n",
       "  'authors': ['Adrian Jarabo',\n",
       "   'Diego Gutierrez',\n",
       "   'Belen Masia',\n",
       "   'Julio Marco'],\n",
       "  'published': '2016-11-03T10:11:10Z',\n",
       "  'updated': '2016-11-03T10:11:10Z',\n",
       "  'abstract': 'Transient imaging has recently made a huge impact in the computer graphicsand computer vision fields. By capturing, reconstructing, or simulating lighttransport at extreme temporal resolutions, researchers have proposed noveltechniques to show movies of light in motion, see around corners, detectobjects in highly-scattering media, or infer material properties from adistance, to name a few. The key idea is to leverage the wealth of informationin the temporal domain at the pico or nanosecond resolution, informationusually lost during the capture-time temporal integration. This paper presentsrecent advances in this field of transient imaging from a graphics and visionperspective, including capture techniques, analysis, applications andsimulation.',\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'Visual Informatics 1 (1), 65-79',\n",
       "  'citations': '48',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.00939v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13973755929537710189&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 33: {'ID': 33,\n",
       "  'title': 'Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space  Matter?',\n",
       "  'authors': ['Michiel van de Panne', 'Xue Bin Peng'],\n",
       "  'published': '2016-11-03T15:15:00Z',\n",
       "  'updated': '2016-11-03T15:15:00Z',\n",
       "  'abstract': 'The use of deep reinforcement learning allows for high-dimensional statedescriptors, but little is known about how the choice of action representationimpacts the learning difficulty and the resulting performance. We compare theimpact of four different action parameterizations (torques, muscle-activations,target joint angles, and target joint-angle velocities) in terms of learningtime, policy robustness, motion quality, and policy query rates. Our resultsare evaluated on a gait-cycle imitation task for multiple planar articulatedfigures and multiple gaits. We demonstrate that the local feedback provided byhigher-level action parameterizations can significantly impact the learning,robustness, and quality of the resulting policies.',\n",
       "  'categories': ['cs.LG', 'cs.GR', 'cs.RO'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '47',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01055v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8497884097534841322&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 34: {'ID': 34,\n",
       "  'title': 'Topologically Controlled Lossy Compression',\n",
       "  'authors': ['Julien Tierny',\n",
       "   'Melanie Plainchault',\n",
       "   'Maxime Soler',\n",
       "   'Bruno Conche'],\n",
       "  'published': '2018-02-08T07:35:43Z',\n",
       "  'updated': '2018-02-08T07:35:43Z',\n",
       "  'abstract': 'This paper presents a new algorithm for the lossy compression of scalar datadefined on 2D or 3D regular grids, with topological control. Certain techniquesallow users to control the pointwise error induced by the compression. However,in many scenarios it is desirable to control in a similar way the preservationof higher-level notions, such as topological features , in order to provideguarantees on the outcome of post-hoc data analyses. This paper presents thefirst compression technique for scalar data which supports a strictlycontrolled loss of topological features. It provides users with specificguarantees both on the preservation of the important features and on the sizeof the smaller features destroyed during compression. In particular, we presenta simple compression strategy based on a topologically adaptive quantization ofthe range. Our algorithm provides strong guarantees on the bottleneck distancebetween persistence diagrams of the input and decompressed data, specificallythose associated with extrema. A simple extension of our strategy additionallyenables a control on the pointwise error. We also show how to combine ourapproach with state-of-the-art compressors, to further improve the geometricalreconstruction. Extensive experiments, for comparable compression rates,demonstrate the superiority of our algorithm in terms of the preservation oftopological features. We show the utility of our approach by illustrating thecompatibility between the output of post-hoc topological data analysispipelines, executed on the input and decompressed data, for simulated oracquired data sets. We also provide a lightweight VTK-based C++ implementationof our approach for reproduction purposes.',\n",
       "  'categories': ['eess.IV', 'cs.CG', 'cs.CV', 'cs.GR'],\n",
       "  'journal': '2018 IEEE Pacific Visualization Symposium (PacificVis), 46-55',\n",
       "  'citations': '23',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.02731v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10087362780146888557&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 35: {'ID': 35,\n",
       "  'title': 'The State of the Art in Integrating Machine Learning into Visual  Analytics',\n",
       "  'authors': ['C. Turkay',\n",
       "   'I Díaz Blanco',\n",
       "   'W. Ribarsky',\n",
       "   'I. Nabney',\n",
       "   'W Wong',\n",
       "   'A. Endert',\n",
       "   'Fabrice Rossi'],\n",
       "  'published': '2018-02-22T09:48:56Z',\n",
       "  'updated': '2018-02-22T09:48:56Z',\n",
       "  'abstract': 'Visual analytics systems combine machine learning or other analytictechniques with interactive data visualization to promote sensemaking andanalytical reasoning. It is through such techniques that people can make senseof large, complex data. While progress has been made, the tactful combinationof machine learning and data visualization is still under-explored. Thisstate-of-the-art report presents a summary of the progress that has been madeby highlighting and synthesizing select research advances. Further, it presentsopportunities and challenges to enhance the synergy between machine learningand visual analytics for impactful future research directions.',\n",
       "  'categories': ['stat.ML', 'cs.HC', 'cs.LG'],\n",
       "  'journal': 'Computer Graphics Forum 36 (8), 458-486',\n",
       "  'citations': '94',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.07954v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11004181639325813294&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 36: {'ID': 36,\n",
       "  'title': 'Deep Video Portraits',\n",
       "  'authors': ['Justus Thies',\n",
       "   'Patrick Pérez',\n",
       "   'Christian Theobalt',\n",
       "   'Weipeng Xu',\n",
       "   'Hyeongwoo Kim',\n",
       "   'Michael Zollhöfer',\n",
       "   'Ayush Tewari',\n",
       "   'Pablo Garrido',\n",
       "   'Christian Richardt',\n",
       "   'Matthias Nießner'],\n",
       "  'published': '2018-05-29T21:31:14Z',\n",
       "  'updated': '2018-05-29T21:31:14Z',\n",
       "  'abstract': 'We present a novel approach that enables photo-realistic re-animation ofportrait videos using only an input video. In contrast to existing approachesthat are restricted to manipulations of facial expressions only, we are thefirst to transfer the full 3D head position, head rotation, face expression,eye gaze, and eye blinking from a source actor to a portrait video of a targetactor. The core of our approach is a generative neural network with a novelspace-time architecture. The network takes as input synthetic renderings of aparametric face model, based on which it predicts photo-realistic video framesfor a given target actor. The realism in this rendering-to-video transfer isachieved by careful adversarial training, and as a result, we can createmodified target videos that mimic the behavior of the synthetically-createdinput. In order to enable source-to-target video re-animation, we render asynthetic target video with the reconstructed head animation parameters from asource video, and feed it into the trained network -- thus taking full controlof the target. With the ability to freely recombine source and targetparameters, we are able to demonstrate a large variety of video rewriteapplications without explicitly modeling hair, body or background. Forinstance, we can reenact the full head using interactive user-controlledediting, and realize high-fidelity visual dubbing. To demonstrate the highquality of our output, we conduct an extensive series of experiments andevaluations, where for instance a user study shows that our video edits arehard to detect.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.GR'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 37 (4), 1-14',\n",
       "  'citations': '146',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.11714v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5990457976415123268&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 37: {'ID': 37,\n",
       "  'title': 'Data-Driven Shape Analysis and Processing',\n",
       "  'authors': ['Vladimir G. Kim',\n",
       "   'Qixing Huang',\n",
       "   'Evangelos Kalogerakis',\n",
       "   'Kai Xu'],\n",
       "  'published': '2015-02-24T04:30:43Z',\n",
       "  'updated': '2015-02-24T04:30:43Z',\n",
       "  'abstract': 'Data-driven methods play an increasingly important role in discoveringgeometric, structural, and semantic relationships between 3D shapes incollections, and applying this analysis to support intelligent modeling,editing, and visualization of geometric data. In contrast to traditionalapproaches, a key feature of data-driven approaches is that they aggregateinformation from a collection of shapes to improve the analysis and processingof individual shapes. In addition, they are able to learn models that reasonabout properties and relationships of shapes without relying on hard-codedrules or explicitly programmed instructions. We provide an overview of the mainconcepts and components of these techniques, and discuss their application toshape classification, segmentation, matching, reconstruction, modeling andexploration, as well as scene analysis and synthesis, through reviewing theliterature and relating the existing works with both qualitative and numericalcomparisons. We conclude our report with ideas that can inspire future researchin data-driven shape analysis and processing.',\n",
       "  'categories': ['cs.GR'],\n",
       "  'journal': 'Computer Graphics Forum 36 (1), 101-132',\n",
       "  'citations': '84',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.06686v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12798116767169253187&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 38: {'ID': 38,\n",
       "  'title': 'Exploring the Design Space of Immersive Urban Analytics',\n",
       "  'authors': ['Wei Chen',\n",
       "   'Yingcai Wu',\n",
       "   'Zhutian Chen',\n",
       "   'Yifang Wang',\n",
       "   'Huamin Qu',\n",
       "   'Zhigeng Pan',\n",
       "   'Xiang Gao',\n",
       "   'Tianchen Sun'],\n",
       "  'published': '2017-09-26T01:15:26Z',\n",
       "  'updated': '2017-09-26T01:15:26Z',\n",
       "  'abstract': 'Recent years have witnessed the rapid development and wide adoption ofimmersive head-mounted devices, such as HTC VIVE, Oculus Rift, and MicrosoftHoloLens. These immersive devices have the potential to significantly extendthe methodology of urban visual analytics by providing critical 3D contextinformation and creating a sense of presence. In this paper, we propose antheoretical model to characterize the visualizations in immersive urbananalytics. Further more, based on our comprehensive and concise model, wecontribute a typology of combination methods of 2D and 3D visualizations thatdistinguish between linked views, embedded views, and mixed views. We alsopropose a supporting guideline to assist users in selecting a proper view undercertain circumstances by considering visual geometry and spatial distributionof the 2D and 3D visualizations. Finally, based on existing works, possiblefuture research opportunities are explored and discussed.',\n",
       "  'categories': ['cs.GR', 'cs.HC'],\n",
       "  'journal': 'Visual Informatics 1 (2), 132-142',\n",
       "  'citations': '14',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.08774v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1394821561481395010&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 39: {'ID': 39,\n",
       "  'title': '3D Reconstruction of Incomplete Archaeological Objects Using a  Generative Adversarial Network',\n",
       "  'authors': ['Renato Hermoza', 'Ivan Sipiran'],\n",
       "  'published': '2017-11-17T00:58:53Z',\n",
       "  'updated': '2018-03-10T18:12:27Z',\n",
       "  'abstract': 'We introduce a data-driven approach to aid the repairing and conservation ofarchaeological objects: ORGAN, an object reconstruction generative adversarialnetwork (GAN). By using an encoder-decoder 3D deep neural network on a GANarchitecture, and combining two loss objectives: a completion loss and anImproved Wasserstein GAN loss, we can train a network to effectively predictthe missing geometry of damaged objects. As archaeological objects can greatlydiffer between them, the network is conditioned on a variable, which can be aculture, a region or any metadata of the object. In our results, we show thatour method can recover most of the information from damaged objects, even incases where more than half of the voxels are missing, without producing manyerrors.',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'journal': 'CGI, 5-11',\n",
       "  'citations': '9',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.06363v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9138237811434951015&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 40: {'ID': 40,\n",
       "  'title': 'Towards Better Analysis of Deep Convolutional Neural Networks',\n",
       "  'authors': ['Chongxuan Li',\n",
       "   'Jun Zhu',\n",
       "   'Zhen Li',\n",
       "   'Mengchen Liu',\n",
       "   'Jiaxin Shi',\n",
       "   'Shixia Liu'],\n",
       "  'published': '2016-04-24T15:53:22Z',\n",
       "  'updated': '2016-05-04T08:17:19Z',\n",
       "  'abstract': 'Deep convolutional neural networks (CNNs) have achieved breakthroughperformance in many pattern recognition tasks such as image classification.However, the development of high-quality deep models typically relies on asubstantial amount of trial-and-error, as there is still no clear understandingof when and why a deep model works. In this paper, we present a visualanalytics approach for better understanding, diagnosing, and refining deepCNNs. We formulate a deep CNN as a directed acyclic graph. Based on thisformulation, a hybrid visualization is developed to disclose the multiplefacets of each neuron and the interactions between them. In particular, weintroduce a hierarchical rectangle packing algorithm and a matrix reorderingalgorithm to show the derived features of a neuron cluster. We also propose abiclustering-based edge bundling method to reduce visual clutter caused by alarge number of connections between neurons. We evaluated our method on a setof CNNs and the results are generally favorable.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 91-100',\n",
       "  'citations': '233',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.07043v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8136611938600994112&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 41: {'ID': 41,\n",
       "  'title': 'Deep Fluids: A Generative Network for Parameterized Fluid Simulations',\n",
       "  'authors': ['Theodore Kim',\n",
       "   'Byungsoo Kim',\n",
       "   'Markus Gross',\n",
       "   'Barbara Solenthaler',\n",
       "   'Vinicius C. Azevedo',\n",
       "   'Nils Thuerey'],\n",
       "  'published': '2018-06-06T08:57:18Z',\n",
       "  'updated': '2019-02-01T14:44:57Z',\n",
       "  'abstract': 'This paper presents a novel generative model to synthesize fluid simulationsfrom a set of reduced parameters. A convolutional neural network is trained ona collection of discrete, parameterizable fluid simulation velocity fields. Dueto the capability of deep learning architectures to learn representativefeatures of the data, our generative model is able to accurately approximatethe training data set, while providing plausible interpolated in-betweens. Theproposed generative model is optimized for fluids by a novel loss function thatguarantees divergence-free velocity fields at all times. In addition, wedemonstrate that we can handle complex parameterizations in reduced spaces, andadvance simulations in time by integrating in the latent space with a secondnetwork. Our method models a wide variety of fluid behaviors, thus enablingapplications such as fast construction of simulations, interpolation of fluidswith different parameters, time re-sampling, latent space simulations, andcompression of fluid simulation data. Reconstructed velocity fields aregenerated up to 700x faster than re-simulating the data with the underlying CPUsolver, while achieving compression rates of up to 1300x.',\n",
       "  'categories': ['cs.LG',\n",
       "   'cs.GR',\n",
       "   'physics.comp-ph',\n",
       "   'physics.flu-dyn',\n",
       "   'stat.ML'],\n",
       "  'journal': 'Computer Graphics Forum 38 (2), 59-70',\n",
       "  'citations': '71',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.02071v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=410331522781867312&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 42: {'ID': 42,\n",
       "  'title': '3D Mesh Segmentation via Multi-branch 1D Convolutional Neural Networks',\n",
       "  'authors': ['David George', 'Gary KL Tam', 'Xianghua Xie'],\n",
       "  'published': '2017-05-31T12:10:32Z',\n",
       "  'updated': '2018-02-01T13:29:19Z',\n",
       "  'abstract': 'There is an increasing interest in applying deep learning to 3D meshsegmentation. We observe that 1) existing feature-based techniques are oftenslow or sensitive to feature resizing, 2) there are minimal comparative studiesand 3) techniques often suffer from reproducibility issue. This studycontributes in two ways. First, we propose a novel convolutional neural network(CNN) for mesh segmentation. It uses 1D data, filters and a multi-brancharchitecture for separate training of multi-scale features. Together with anovel way of computing conformal factor (CF), our technique clearlyout-performs existing work. Secondly, we publicly provide implementations ofseveral deep learning techniques, namely, neural networks (NNs), autoencoders(AEs) and CNNs, whose architectures are at least two layers deep. Thesignificance of this study is that it proposes a robust form of CF, offers anovel and accurate CNN technique, and a comprehensive study of several deeplearning techniques for baseline comparison.',\n",
       "  'categories': ['cs.GR'],\n",
       "  'journal': 'Graphical Models 96, 1-10',\n",
       "  'citations': '19',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.11050v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13136925266407564554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 43: {'ID': 43,\n",
       "  'title': 'Neural Style Transfer: A Review',\n",
       "  'authors': ['Yongcheng Jing',\n",
       "   'Jingwen Ye',\n",
       "   'Yizhou Yu',\n",
       "   'Yezhou Yang',\n",
       "   'Zunlei Feng',\n",
       "   'Mingli Song'],\n",
       "  'published': '2017-05-11T08:08:44Z',\n",
       "  'updated': '2018-10-30T09:48:05Z',\n",
       "  'abstract': 'The seminal work of Gatys et al. demonstrated the power of ConvolutionalNeural Networks (CNNs) in creating artistic imagery by separating andrecombining image content and style. This process of using CNNs to render acontent image in different styles is referred to as Neural Style Transfer(NST). Since then, NST has become a trending topic both in academic literatureand industrial applications. It is receiving increasing attention and a varietyof approaches are proposed to either improve or extend the original NSTalgorithm. In this paper, we aim to provide a comprehensive overview of thecurrent progress towards NST. We first propose a taxonomy of current algorithmsin the field of NST. Then, we present several evaluation methods and comparedifferent NST algorithms both qualitatively and quantitatively. The reviewconcludes with a discussion of various applications of NST and open problemsfor future research. A list of papers discussed in this review, correspondingcodes, pre-trained models and more comparison results are publicly available athttps://github.com/ycjing/Neural-Style-Transfer-Papers.',\n",
       "  'categories': ['cs.CV', 'cs.NE', 'eess.IV', 'stat.ML'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics',\n",
       "  'citations': '146',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.04058v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4434701562780805395&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 44: {'ID': 44,\n",
       "  'title': 'GRASS: Generative Recursive Autoencoders for Shape Structures',\n",
       "  'authors': ['Jun Li',\n",
       "   'Hao Zhang',\n",
       "   'Ersin Yumer',\n",
       "   'Leonidas Guibas',\n",
       "   'Siddhartha Chaudhuri',\n",
       "   'Kai Xu'],\n",
       "  'published': '2017-05-05T05:45:10Z',\n",
       "  'updated': '2017-05-13T04:49:23Z',\n",
       "  'abstract': 'We introduce a novel neural network architecture for encoding and synthesisof 3D shapes, particularly their structures. Our key insight is that 3D shapesare effectively characterized by their hierarchical organization of parts,which reflects fundamental intra-shape relationships such as adjacency andsymmetry. We develop a recursive neural net (RvNN) based autoencoder to map aflat, unlabeled, arbitrary part layout to a compact code. The code effectivelycaptures hierarchical structures of man-made 3D objects of varying structuralcomplexities despite being fixed-dimensional: an associated decoder maps a codeback to a full hierarchy. The learned bidirectional mapping is further tunedusing an adversarial setup to yield a generative model of plausible structures,from which novel structures can be sampled. Finally, our structure synthesisframework is augmented by a second trained module that produces fine-grainedpart geometry, conditioned on global and local structural context, leading to afull generative pipeline for 3D shapes. We demonstrate that withoutsupervision, our network learns meaningful structural hierarchies adhering toperceptual grouping principles, produces compact codes which enableapplications such as shape classification and partial matching, and supportsshape synthesis and interpolation with significant variations in topology andgeometry.',\n",
       "  'categories': ['cs.GR', 'cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-14',\n",
       "  'citations': '105',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.02090v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13132742854630822300&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 45: {'ID': 45,\n",
       "  'title': 'VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera',\n",
       "  'authors': ['Mohammad Shafiei',\n",
       "   'Oleksandr Sotnychenko',\n",
       "   'Hans-Peter Seidel',\n",
       "   'Helge Rhodin',\n",
       "   'Christian Theobalt',\n",
       "   'Weipeng Xu',\n",
       "   'Dan Casas',\n",
       "   'Srinath Sridhar',\n",
       "   'Dushyant Mehta'],\n",
       "  'published': '2017-05-03T19:13:23Z',\n",
       "  'updated': '2017-05-03T19:13:23Z',\n",
       "  'abstract': \"We present the first real-time method to capture the full global 3D skeletalpose of a human in a stable, temporally consistent manner using a single RGBcamera. Our method combines a new convolutional neural network (CNN) based poseregressor with kinematic skeleton fitting. Our novel fully-convolutional poseformulation regresses 2D and 3D joint positions jointly in real time and doesnot require tightly cropped input frames. A real-time kinematic skeletonfitting method uses the CNN output to yield temporally stable 3D global posereconstructions on the basis of a coherent kinematic skeleton. This makes ourapproach the first monocular RGB method usable in real-time applications suchas 3D character control---thus far, the only monocular methods for suchapplications employed specialized RGB-D cameras. Our method's accuracy isquantitatively on par with the best offline 3D monocular RGB pose estimationmethods. Our results are qualitatively comparable to, and sometimes betterthan, results from monocular RGB-D approaches, such as the Kinect. However, weshow that our approach is more broadly applicable than RGB-D solutions, i.e. itworks for outdoor scenes, community videos, and low quality commodity RGBcameras.\",\n",
       "  'categories': ['cs.CV', 'cs.GR'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-14',\n",
       "  'citations': '400',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.01583v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8615080294034478816&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 46: {'ID': 46,\n",
       "  'title': 'Fairy Lights in Femtoseconds: Aerial and Volumetric Graphics Rendered by  Focused Femtosecond Laser Combined with Computational Holographic Fields',\n",
       "  'authors': ['Satoshi Hasegawa',\n",
       "   'Yoshio Hayasaki',\n",
       "   'Kota Kumagai',\n",
       "   'Jun Rekimoto',\n",
       "   'Takayuki Hoshi',\n",
       "   'Yoichi Ochiai'],\n",
       "  'published': '2015-06-22T16:20:34Z',\n",
       "  'updated': '2015-06-22T16:20:34Z',\n",
       "  'abstract': 'We present a method of rendering aerial and volumetric graphics usingfemtosecond lasers. A high-intensity laser excites a physical matter to emitlight at an arbitrary 3D position. Popular applications can then be exploredespecially since plasma induced by a femtosecond laser is safer than thatgenerated by a nanosecond laser. There are two methods of rendering graphicswith a femtosecond laser in air: Producing holograms using spatial lightmodulation technology, and scanning of a laser beam by a galvano mirror. Theholograms and workspace of the system proposed here occupy a volume of up to 1cm^3; however, this size is scalable depending on the optical devices and theirsetup. This paper provides details of the principles, system setup, andexperimental evaluation, and discussions on scalability, design space, andapplications of this system. We tested two laser sources: an adjustable (30-100fs) laser which projects up to 1,000 pulses per second at energy up to 7 mJ perpulse, and a 269-fs laser which projects up to 200,000 pulses per second at anenergy up to 50 uJ per pulse. We confirmed that the spatiotemporal resolutionof volumetric displays, implemented with these laser sources, is 4,000 and200,000 dots per second. Although we focus on laser-induced plasma in air, thediscussion presented here is also applicable to other rendering principles suchas fluorescence and microbubble in solid/liquid materials.',\n",
       "  'categories': ['cs.GR', 'cs.HC', 'physics.optics'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (2), 1-14',\n",
       "  'citations': '100',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.06668v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12625788450078766124&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 47: {'ID': 47,\n",
       "  'title': 'A Simple and Correct Even-Odd Algorithm for the Point-in-Polygon Problem  for Complex Polygons',\n",
       "  'authors': ['Michael Galetzka', 'Patrick O. Glauner'],\n",
       "  'published': '2012-07-15T13:06:26Z',\n",
       "  'updated': '2017-07-22T22:23:49Z',\n",
       "  'abstract': 'Determining if a point is in a polygon or not is used by a lot ofapplications in computer graphics, computer games and geoinformatics.Implementing this check is error-prone since there are many special cases to beconsidered. This holds true in particular for complex polygons whose edgesintersect each other creating holes. In this paper we present a simple even-oddalgorithm to solve this problem for complex polygons in linear time and proveits correctness for all possible points and polygons. We furthermore provideexamples and implementation notes for this algorithm.',\n",
       "  'categories': ['cs.CG'],\n",
       "  'journal': 'VISIGRAPP (1: GRAPP), 175-178',\n",
       "  'citations': '13',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1207.3502v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13485678493044816813&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 48: {'ID': 48,\n",
       "  'title': 'LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in  Recurrent Neural Networks',\n",
       "  'authors': ['Sebastian Gehrmann',\n",
       "   'Hanspeter Pfister',\n",
       "   'Hendrik Strobelt',\n",
       "   'Alexander M. Rush'],\n",
       "  'published': '2016-06-23T20:20:39Z',\n",
       "  'updated': '2017-10-30T15:11:54Z',\n",
       "  'abstract': 'Recurrent neural networks, and in particular long short-term memory (LSTM)networks, are a remarkably effective tool for sequence modeling that learn adense black-box hidden representation of their sequential input. Researchersinterested in better understanding these models have studied the changes inhidden state representations over time and noticed some interpretable patternsbut also significant noise. In this work, we present LSTMVIS, a visual analysistool for recurrent neural networks with a focus on understanding these hiddenstate dynamics. The tool allows users to select a hypothesis input range tofocus on local state changes, to match these states changes to similar patternsin a large data set, and to align these results with structural annotationsfrom their domain. We show several use cases of the tool for analyzing specifichidden state properties on dataset containing nesting, phrase structure, andchord progressions, and demonstrate how the tool can be used to isolatepatterns for further statistical analysis. We characterize the domain, thedifferent stakeholders, and their goals and tasks.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 667-676',\n",
       "  'citations': '139',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.07461v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18279217837708246337&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 49: {'ID': 49,\n",
       "  'title': 'O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis',\n",
       "  'authors': ['Yang Liu',\n",
       "   'Chun-Yu Sun',\n",
       "   'Yu-Xiao Guo',\n",
       "   'Peng-Shuai Wang',\n",
       "   'Xin Tong'],\n",
       "  'published': '2017-12-05T09:25:19Z',\n",
       "  'updated': '2017-12-05T09:25:19Z',\n",
       "  'abstract': 'We present O-CNN, an Octree-based Convolutional Neural Network (CNN) for 3Dshape analysis. Built upon the octree representation of 3D shapes, our methodtakes the average normal vectors of a 3D model sampled in the finest leafoctants as input and performs 3D CNN operations on the octants occupied by the3D shape surface. We design a novel octree data structure to efficiently storethe octant information and CNN features into the graphics memory and executethe entire O-CNN training and evaluation on the GPU. O-CNN supports various CNNstructures and works for 3D shapes in different representations. By restrainingthe computations on the octants occupied by 3D surfaces, the memory andcomputational costs of the O-CNN grow quadratically as the depth of the octreeincreases, which makes the 3D CNN feasible for high-resolution 3D models. Wecompare the performance of the O-CNN with other existing 3D CNN solutions anddemonstrate the efficiency and efficacy of O-CNN in three shape analysis tasks,including object classification, shape retrieval, and shape segmentation.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-11',\n",
       "  'citations': '345',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.01537v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7231038537347072326&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 50: {'ID': 50,\n",
       "  'title': 'Visual Attribute Transfer through Deep Image Analogy',\n",
       "  'authors': ['Yuan Yao',\n",
       "   'Sing Bing Kang',\n",
       "   'Gang Hua',\n",
       "   'Jing Liao',\n",
       "   'Lu Yuan'],\n",
       "  'published': '2017-05-02T17:44:01Z',\n",
       "  'updated': '2017-06-06T15:16:19Z',\n",
       "  'abstract': 'We propose a new technique for visual attribute transfer across images thatmay have very different appearance but have perceptually similar semanticstructure. By visual attribute transfer, we mean transfer of visual information(such as color, tone, texture, and style) from one image to another. Forexample, one image could be that of a painting or a sketch while the other is aphoto of a real scene, and both depict the same type of scene.  Our technique finds semantically-meaningful dense correspondences between twoinput images. To accomplish this, it adapts the notion of \"image analogy\" withfeatures extracted from a Deep Convolutional Neutral Network for matching; wecall our technique Deep Image Analogy. A coarse-to-fine strategy is used tocompute the nearest-neighbor field for generating the results. We validate theeffectiveness of our proposed method in a variety of cases, includingstyle/texture transfer, color/style swap, sketch/painting to photo, and timelapse.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-15',\n",
       "  'citations': '199',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.01088v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17272239726041857760&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 51: {'ID': 51,\n",
       "  'title': 'Approximated and User Steerable tSNE for Progressive Visual Analytics',\n",
       "  'authors': ['Nicola Pezzotti',\n",
       "   'Laurens van der Maaten',\n",
       "   'Thomas Höllt',\n",
       "   'Anna Vilanova',\n",
       "   'Elmar Eisemann',\n",
       "   'Boudewijn P. F. Lelieveldt'],\n",
       "  'published': '2015-12-05T12:05:52Z',\n",
       "  'updated': '2016-06-16T09:36:40Z',\n",
       "  'abstract': 'Progressive Visual Analytics aims at improving the interactivity in existinganalytics techniques by means of visualization as well as interaction withintermediate results. One key method for data analysis is dimensionalityreduction, for example, to produce 2D embeddings that can be visualized andanalyzed efficiently. t-Distributed Stochastic Neighbor Embedding (tSNE) is awell-suited technique for the visualization of several high-dimensional data.tSNE can create meaningful intermediate results but suffers from a slowinitialization that constrains its application in Progressive Visual Analytics.We introduce a controllable tSNE approximation (A-tSNE), which trades off speedand accuracy, to enable interactive data exploration. We offer real-timevisualization techniques, including a density-based solution and a Magic Lensto inspect the degree of approximation. With this feedback, the user can decideon local refinements and steer the approximation level during the analysis. Wedemonstrate our technique with several datasets, in a real-world researchscenario and for the real-time analysis of high-dimensional streams toillustrate its effectiveness for interactive data analysis.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (7), 1739-1752',\n",
       "  'citations': '130',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.01655v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4186437419065723093&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 52: {'ID': 52,\n",
       "  'title': 'Engineering Er3+ placement and emission through chemically-synthesized  self-aligned SiC:Ox nanowire photonic crystal structures',\n",
       "  'authors': ['Vasileios Nikas',\n",
       "   'Brian Ford',\n",
       "   'Natasha Tabassum',\n",
       "   'Edward Crawford',\n",
       "   'Spyros Gallis'],\n",
       "  'published': '2017-07-18T16:50:11Z',\n",
       "  'updated': '2017-10-26T20:52:51Z',\n",
       "  'abstract': 'High precision placement and integration of color centers in a silicon-basednanosystem, such as a nanowire (NW) array, exhibiting high integrationfunctionality and high photoluminescence (PL) yield can serve as a criticalbuilding block towards the practical realization of devices in the emergingfield of quantum technologies. Herein, we report on an innovative synthesisroute for realizing ultrathin silicon carbide (SiC) NW arrays doped with andwithout oxygen (SiC:Ox), and also erbium (Er). The arrays of thedeterministically positioned NWs are grown in a self-aligned manner throughchemical-vapor-deposition (CVD). A key enabler of this synthesis route is thatSiC:Ox NW photonic crystal (PC) nanostructures are engineered with tailoredgeometry in precise locations during nanofabrication. These ultrathin NW PCstructures not only facilitate the on-demand positioning of Er3+ ions but arepivotal in engineering the emission properties of these color centers. Througha combinational and systematic micro-PL (uPL) and power-dependence PL (PDPL)spectroscopy, PC architecture geometry effects on Er3+-related 1538 nmemission, which is the telecommunication wavelength used in optical fibers,were studied. Approximately 60-fold and 30-fold enhancements for, respectively,the room-temperature Er3+ PL emission and lifetime in the NW PC sample wereobserved compared to its thin-film analog. Furthermore, the 1538 nm emission inSiC:Ox NW PC was found to be modulated linearly with the PC lattice periodicityof the structure. The observed characteristics reveal the efficientEr3+-emission extraction from the technologically-friendly SiC:Ox NW PCstructures.',\n",
       "  'categories': ['cond-mat.mes-hall'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.05738v2'},\n",
       " 53: {'ID': 53,\n",
       "  'title': 'An angular momentum conserving Affine-Particle-In-Cell method',\n",
       "  'authors': ['Joseph Teran', 'Craig Schroeder', 'Chenfanfu Jiang'],\n",
       "  'published': '2016-03-20T07:37:01Z',\n",
       "  'updated': '2016-03-20T07:37:01Z',\n",
       "  'abstract': \"We present a new technique for transferring momentum and velocity betweenparticles and grid with Particle-In-Cell (PIC) calculations which we callAffine-Particle-In-Cell (APIC). APIC represents particle velocities as locallyaffine, rather than locally constant as in traditional PIC. We show that thisrepresentation allows APIC to conserve linear and angular momentum acrosstransfers while also dramatically reducing numerical diffusion usuallyassociated with PIC. Notably, conservation is achieved with lumped mass, asopposed to the more commonly used Fluid Implicit Particle (FLIP) transferswhich require a 'full' mass matrix for exact conservation. Furthermore, unlikeFLIP, APIC retains a filtering property of the original PIC and thus does notaccumulate velocity modes on particles as FLIP does. In particular, wedemonstrate that APIC does not experience velocity instabilities that arecharacteristic of FLIP in a number of Material Point Method (MPM)hyperelasticity calculations. Lastly, we demonstrate that when combined withthe midpoint rule for implicit update of grid momentum that linear and angularmomentum are exactly conserved.\",\n",
       "  'categories': ['physics.comp-ph', 'math.NA'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.06188v1'},\n",
       " 54: {'ID': 54,\n",
       "  'title': 'Geometric algebra and singularities of ruled and developable surfaces',\n",
       "  'authors': ['Junki Tanaka', 'Toru Ohmoto'],\n",
       "  'published': '2018-08-31T03:33:21Z',\n",
       "  'updated': '2018-08-31T03:33:21Z',\n",
       "  'abstract': 'Any ruled surface in Euclidean 3-space is described as a curve of unit dualvectors in the algebra of dual quaternions (=the even Clifford algebra of type(0,3,1)). Combining this classical framework and Singularity Theory, wecharacterize local diffeomorphic types of singular ruled surfaces in terms ofgeometric invariants. In particular, using a theorem of G. Ishikawa, we showthat local topological type of singular (non-cylindrical) developable surfacesis completely determined by vanishing order of the dual torsion, thatgeneralizes an old result of D. Mond for tangent developables of non-singularspace curves. Our approach would be useful for analysis on singularitiesarising in differential line geometry related with several applications such asrobotics, vision theory and architectural geometry.',\n",
       "  'categories': ['math.DG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1808.10587v1'},\n",
       " 55: {'ID': 55,\n",
       "  'title': 'Embedding Complexity In the Data Representation Instead of In the Model:  A Case Study Using Heterogeneous Medical Data',\n",
       "  'authors': ['Diego A. Mesa',\n",
       "   'Jacek M. Bajor',\n",
       "   'Travis J. Osterman',\n",
       "   'Thomas A. Lasko'],\n",
       "  'published': '2018-02-12T18:31:24Z',\n",
       "  'updated': '2018-02-12T18:31:24Z',\n",
       "  'abstract': 'Electronic Health Records have become popular sources of data for secondaryresearch, but their use is hampered by the amount of effort it takes toovercome the sparsity, irregularity, and noise that they contain. Modernlearning architectures can remove the need for expert-driven featureengineering, but not the need for expert-driven preprocessing to abstract awaythe inherent messiness of clinical data. This preprocessing effort is often thedominant component of a typical clinical prediction project. In this work wepropose using semantic embedding methods to directly couple the raw, messyclinical data to downstream learning architectures with truly minimalpreprocessing. We examine this step from the perspective of capturing andencoding complex data dependencies in the data representation instead of in themodel, which has the nice benefit of allowing downstream processing to be donewith fast, lightweight, and simple models accessible to researchers withoutmachine learning expertise. We demonstrate with three typical clinicalprediction tasks that the highly compressed, embedded data representationscapture a large amount of useful complexity, although in some cases thecompression is not completely lossless.',\n",
       "  'categories': ['stat.AP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.04233v1'},\n",
       " 56: {'ID': 56,\n",
       "  'title': 'Smooth polyhedral surfaces',\n",
       "  'authors': ['Felix Günther', 'Helmut Pottmann', 'Caigui Jiang'],\n",
       "  'published': '2017-03-15T17:28:40Z',\n",
       "  'updated': '2017-03-15T17:28:40Z',\n",
       "  'abstract': 'Polyhedral surfaces are fundamental objects in architectural geometry andindustrial design. Whereas closeness of a given mesh to a smooth referencesurface and its suitability for numerical simulations were already studiedextensively, the aim of our work is to find and to discuss suitable assessmentsof smoothness of polyhedral surfaces that only take the geometry of thepolyhedral surface itself into account. Motivated by analogies to classicaldifferential geometry, we propose a theory of smoothness of polyhedral surfacesincluding suitable notions of normal vectors, tangent planes, asymptoticdirections, and parabolic curves that are invariant under projectivetransformations. It is remarkable that seemingly mild conditions significantlylimit the shapes of faces of a smooth polyhedral surface. Besides being oftheoretical interest, we believe that smoothness of polyhedral surfaces is ofinterest in the architectural context, where vertices and edges of polyhedralsurfaces are highly visible.',\n",
       "  'categories': ['math.MG', 'math.DG', '52B70, 53A05'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.05318v1'},\n",
       " 57: {'ID': 57,\n",
       "  'title': 'Evaluating Cartogram Effectiveness',\n",
       "  'authors': ['Sabrina Nusrat', 'Stephen G. Kobourov', 'Md. Jawaherul Alam'],\n",
       "  'published': '2015-04-09T07:58:01Z',\n",
       "  'updated': '2017-01-02T20:27:53Z',\n",
       "  'abstract': 'Cartograms are maps in which areas of geographic regions (countries, states)appear in proportion to some variable of interest (population, income).Cartograms are popular visualizations for geo-referenced data that have beenused for over a century and that make it possible to gain insight into patternsand trends in the world around us. Despite the popularity of cartograms and thelarge number of cartogram types, there are few studies evaluating theeffectiveness of cartograms in conveying information. Based on a recent tasktaxonomy for cartograms, we evaluate four major different types of cartograms:contiguous, non-contiguous, rectangular, and Dorling cartograms. Specifically,we evaluate the effectiveness of these cartograms by quantitative performanceanalysis, as well as by subjective preferences. We analyze the results of ourstudy in the context of some prevailing assumptions in the literature ofcartography and cognitive science. Finally, we make recommendations for the useof different types of cartograms for different tasks and settings.',\n",
       "  'categories': ['cs.HC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1504.02218v2'},\n",
       " 58: {'ID': 58,\n",
       "  'title': 'Hierarchical stochastic neighbor embedding as a tool for visualizing the  encoding capability of magnetic resonance fingerprinting dictionaries',\n",
       "  'authors': ['Kirsten Koolstra',\n",
       "   'Oleh Dzyubachyk',\n",
       "   'Boudewijn Lelieveldt',\n",
       "   'Andrew Webb',\n",
       "   'Peter Börnert'],\n",
       "  'published': '2019-10-07T09:48:38Z',\n",
       "  'updated': '2019-10-07T09:48:38Z',\n",
       "  'abstract': 'In Magnetic Resonance Fingerprinting (MRF) the quality of the estimatedparameter maps depends on the encoding capability of the variable flip angletrain. In this work we show how the dimensionality reduction techniqueHierarchical Stochastic Neighbor Embedding (HSNE) can be used to obtain insightinto the encoding capability of different MRF sequences. Embeddinghigh-dimensional MRF dictionaries into a lower-dimensional space andvisualizing them with colors, being a surrogate for location in low-dimensionalspace, provides a comprehensive overview of particular dictionaries and, inaddition, enables comparison of different sequences. Dictionaries for varioussequences and sequence lengths were compared to each other, and the effect oftransmit field variations on the encoding capability was assessed. Cleardifferences in encoding capability were observed between different sequences,and HSNE results accurately reflect those obtained from an MRF matchingsimulation.',\n",
       "  'categories': ['eess.IV', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.02696v1'},\n",
       " 59: {'ID': 59,\n",
       "  'title': 'Exploration of Interaction Techniques for Graph-based Modelling in  Virtual Reality',\n",
       "  'authors': ['Naz Yilmaz', 'Serhat Aras', 'Berat Bicer', 'Adrien Coppens'],\n",
       "  'published': '2020-01-03T17:06:58Z',\n",
       "  'updated': '2020-01-03T17:06:58Z',\n",
       "  'abstract': 'Editing and manipulating graph-based models within immersive environments islargely unexplored and certain design activities could benefit from using thosetechnologies. For example, in the case study of architectural modelling, the 3Dcontext of Virtual Reality naturally matches the intended output product, i.e.a 3D architectural geometry. Since both the state of the art and the state ofthe practice are lacking, we explore the field of VR-based interactivemodelling, and provide insights as to how to implement proper interactions inthat context, with broadly available devices. We consequently produce severalopen-source software prototypes for manipulating graph-based models in VR.',\n",
       "  'categories': ['cs.HC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.00892v1'},\n",
       " 60: {'ID': 60,\n",
       "  'title': 'Situational Awareness Enhanced through Social Media Analytics: A Survey  of First Responders',\n",
       "  'authors': ['David S. Ebert',\n",
       "   'Morteza Karimzadeh',\n",
       "   'Luke S. Snyder',\n",
       "   'Christina Stober'],\n",
       "  'published': '2019-09-16T16:20:10Z',\n",
       "  'updated': '2019-09-16T16:20:10Z',\n",
       "  'abstract': \"Social media data has been increasingly used to facilitate situationalawareness during events and emergencies such as natural disasters. Whileresearchers have investigated several methods to summarize, visualize or minethe data for analysis, first responders have not been able to fully leverageresearch advancements largely due to the gap between academic research anddeployed, functional systems. In this paper, we explore the opportunities andbarriers for the effective use of social media data from first responders'perspective. We present the summary of several detailed interviews with firstresponders on their use of social media for situational awareness. We furtherassess the impact of SMART-a social media visual analytics system-on firstresponder operations.\",\n",
       "  'categories': ['cs.SI', 'cs.CY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.07316v1'},\n",
       " 61: {'ID': 61,\n",
       "  'title': 'Support-free interior carving for 3D printing',\n",
       "  'authors': ['X Chen', 'Y Xie'],\n",
       "  'journal': 'Visual Informatics 1 (1), 9-15',\n",
       "  'citations': '17',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1959560352871407391&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 62: {'ID': 62,\n",
       "  'title': 'Towards Pervasive Augmented Reality: Context-Awareness in Augmented Reality',\n",
       "  'authors': ['J Grubert', 'H Regenbrecht', 'S Zollmann', 'T Langlotz'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (6), 1706-1724',\n",
       "  'citations': '105',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14878929993524501961&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 63: {'ID': 63,\n",
       "  'title': 'VISTopic: A visual analytics system for making sense of large document collections using hierarchical topic modeling',\n",
       "  'authors': ['Q Yao', 'Y Yang', 'H Qu'],\n",
       "  'journal': 'Visual Informatics 1 (1), 40-47',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16643578734165627519&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 64: {'ID': 64,\n",
       "  'title': 'Exploratory Text Analysis using Lexical Episode Plots.',\n",
       "  'authors': ['C Rohrdantz', 'M El-Assady', 'V Gold'],\n",
       "  'journal': 'EuroVis (Short Papers), 85-89',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11680873089489670950&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 65: {'ID': 65,\n",
       "  'title': 'Sonic Interactions in Virtual Reality: State of the Art, Current Challenges, and Future Directions',\n",
       "  'authors': ['NC Nilsson',\n",
       "   'M Geronazzo',\n",
       "   'S Serafin',\n",
       "   'C Erkut',\n",
       "   'R Nordahl'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 38 (2), 31-43',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14893222906997589577&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 66: {'ID': 66,\n",
       "  'title': 'Capturing the human figure through a wall',\n",
       "  'authors': ['H Mao', 'D Katabi', 'CY Hsu', 'F Durand', 'F Adib'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-13',\n",
       "  'citations': '192',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4959033703348220140&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 67: {'ID': 67,\n",
       "  'title': 'VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track',\n",
       "  'authors': ['K Varanasi',\n",
       "   'H Sarmadi',\n",
       "   'I Steiner',\n",
       "   'P Garrido',\n",
       "   'P Pérez',\n",
       "   '...',\n",
       "   'L Valgaerts'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 193-204',\n",
       "  'citations': '69',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=341442744997746321&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 68: {'ID': 68,\n",
       "  'title': 'Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers',\n",
       "  'authors': ['B Lee', 'J Suh', 'JD Williams', 'S Amershi', 'D Ren'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 61-70',\n",
       "  'citations': '97',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2926029361915677124&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 69: {'ID': 69,\n",
       "  'title': 'Learning to simplify: fully convolutional networks for rough sketch cleanup',\n",
       "  'authors': ['H Ishikawa', 'S Iizuka', 'E Simo-Serra', 'K Sasaki'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-11',\n",
       "  'citations': '113',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17507585084772522698&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 70: {'ID': 70,\n",
       "  'title': 'Interactive sketching of urban procedural models',\n",
       "  'authors': ['I Garcia-Dorado',\n",
       "   'G Nishida',\n",
       "   'A Bousseau',\n",
       "   'B Benes',\n",
       "   'DG Aliaga'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-11',\n",
       "  'citations': '90',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3747933599657530196&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 71: {'ID': 71,\n",
       "  'title': 'Computational design of walking automata',\n",
       "  'authors': ['H Pfister',\n",
       "   'B Thomaszewski',\n",
       "   'S Coros',\n",
       "   'G Bharaj',\n",
       "   'B Bickel',\n",
       "   'J Tompkin'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1769908138131420001&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 72: {'ID': 72,\n",
       "  'title': 'Terrain-adaptive locomotion skills using deep reinforcement learning',\n",
       "  'authors': ['G Berseth', 'XB Peng', 'M van de Panne'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-12',\n",
       "  'citations': '168',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14305407568176429577&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 73: {'ID': 73,\n",
       "  'title': 'Painting style transfer for head portraits using convolutional neural networks',\n",
       "  'authors': ['L Doyle', 'A Selim', 'M Elgharib'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-18',\n",
       "  'citations': '119',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9385731552957610104&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 74: {'ID': 74,\n",
       "  'title': 'Stable Topological Signatures for Points on 3D Shapes',\n",
       "  'authors': ['M Ovsjanikov', 'SY Oudot', 'M Carrière'],\n",
       "  'journal': 'Computer Graphics Forum 34 (5), 1-12',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10399584510962669100&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 75: {'ID': 75,\n",
       "  'title': 'A cti V is: Visual Exploration of Industry-Scale Deep Neural Network Models',\n",
       "  'authors': ['M Kahng', 'PY Andrews', 'A Kalro', 'DHP Chau'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 88-97',\n",
       "  'citations': '150',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=68438662327512434&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 76: {'ID': 76,\n",
       "  'title': 'Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes',\n",
       "  'authors': ['J Chen', 'A Endert', 'J Sanyal', 'ED Ragan'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 31-40',\n",
       "  'citations': '136',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14883770689173509722&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 77: {'ID': 77,\n",
       "  'title': 'Panoramic Video from Unstructured Camera Arrays',\n",
       "  'authors': ['A Sorkine‐Hornung',\n",
       "   'O Wang',\n",
       "   'P Kaufmann',\n",
       "   '...',\n",
       "   'H Zimmer',\n",
       "   'F Perazzi'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 57-68',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9788526371393985464&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 78: {'ID': 78,\n",
       "  'title': 'Position and orientation based Cosserat rods',\n",
       "  'authors': ['T Kugelstadt', 'E Schömer'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14107956451913320270&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 79: {'ID': 79,\n",
       "  'title': 'Mixed-initiative visual analytics using task-driven recommendations',\n",
       "  'authors': ['R Burtner',\n",
       "   'D Israel',\n",
       "   'K Cook',\n",
       "   'M Wolverton',\n",
       "   'A Endert',\n",
       "   'N Cramer',\n",
       "   'J Bruce'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 9-16',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13821116771711144432&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 80: {'ID': 80,\n",
       "  'title': 'Realtime style transfer for unlabeled heterogeneous human motion',\n",
       "  'authors': ['C Wang', 'J Chai', 'J Hodgins', 'S Xia'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-10',\n",
       "  'citations': '91',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17661169332718302450&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 81: {'ID': 81,\n",
       "  'title': 'Recent Trends, Applications, and Perspectives in 3D Shape Similarity Assessment',\n",
       "  'authors': ['M Bronstein', 'A Cerri', 'S Biasotti', 'A Bronstein'],\n",
       "  'journal': 'Computer Graphics Forum 35 (6), 87-119',\n",
       "  'citations': '61',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12147770530198799709&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 82: {'ID': 82,\n",
       "  'title': 'Computational design of hand-held VR controllers using haptic shape illusion',\n",
       "  'authors': ['T Narumi',\n",
       "   'Y Koyama',\n",
       "   'T Tanikawa',\n",
       "   'M Hirose',\n",
       "   'E Fujinawa',\n",
       "   'S Yoshida'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4952917874423820135&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 83: {'ID': 83,\n",
       "  'title': 'Real‐time haptic manipulation and cutting of hybrid soft tissue models by extended position‐based dynamics',\n",
       "  'authors': ['H Qin', 'J Pan', 'X Zhao', 'A Hao', 'J Bai'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (3-4), 321-335',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2776383530138179713&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 84: {'ID': 84,\n",
       "  'title': 'Fast, memory-efficient construction of voxelized shadows.',\n",
       "  'authors': ['V Kämpe', 'E Sintorn', 'U Assarsson'],\n",
       "  'journal': 'I3D, 25-30',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5827171454101480982&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 85: {'ID': 85,\n",
       "  'title': 'Nonlinearly Weighted First‐order Regression for Denoising Monte Carlo Renderings',\n",
       "  'authors': ['JA Iglesias‐Guitián',\n",
       "   'B Bitterli',\n",
       "   '...',\n",
       "   'D Adler',\n",
       "   'B Moon',\n",
       "   'K Mitchell',\n",
       "   'F Rousselle'],\n",
       "  'journal': 'Computer Graphics Forum 35 (4), 107-117',\n",
       "  'citations': '59',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2847565267471445450&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 86: {'ID': 86,\n",
       "  'title': 'Molecular visualization of computational biology data: a survey of surveys',\n",
       "  'authors': ['N Alharbi',\n",
       "   'M Alharbi',\n",
       "   'M Baaden',\n",
       "   '...',\n",
       "   'X Martinez',\n",
       "   'M Krone',\n",
       "   'A Rose'],\n",
       "  'journal': 'Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short\\xa0…',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=387707663496013785&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 87: {'ID': 87,\n",
       "  'title': 'Towards more behaviours in crowd simulation',\n",
       "  'authors': ['S Lemercier', 'JM Auberlet'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 27 (1), 24-34',\n",
       "  'citations': '17',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1253691032911844053&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 88: {'ID': 88,\n",
       "  'title': 'DeepLoco: dynamic locomotion skills using hierarchical deep reinforcement learning',\n",
       "  'authors': ['G Berseth', 'XB Peng', 'K Yin', 'M Van De Panne'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-13',\n",
       "  'citations': '248',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13276434778848772604&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 89: {'ID': 89,\n",
       "  'title': 'Isogeometric analysis with strong multipatch C1-coupling',\n",
       "  'authors': ['CL Chan', 'C Anitescu', 'T Rabczuk'],\n",
       "  'journal': 'Computer Aided Geometric Design 62, 294-310',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12636905579665550912&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 90: {'ID': 90,\n",
       "  'title': 'Shape Displays: Spatial Interaction with Dynamic Physical Form',\n",
       "  'authors': ['D Leithinger', 'H Ishii', 'S Follmer', 'A Olwal'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (5), 5-11',\n",
       "  'citations': '44',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10448264205203645742&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 91: {'ID': 91,\n",
       "  'title': 'Cyber sick but still having fun.',\n",
       "  'authors': ['A Knote', 'S von Mammen', 'S Edenhofer'],\n",
       "  'journal': 'VRST, 325-326',\n",
       "  'citations': '30',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=857759081123001859&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 92: {'ID': 92,\n",
       "  'title': 'Real-time global illumination using precomputed light field probes.',\n",
       "  'authors': ['D Nowrouzezahrai', 'M McGuire', 'M Mara', 'D Luebke'],\n",
       "  'journal': 'I3D, 2:1-2:11',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14169244115890049030&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 93: {'ID': 93,\n",
       "  'title': 'Real-time expression transfer for facial reenactment',\n",
       "  'authors': ['M Stamminger',\n",
       "   'M Zollhöfer',\n",
       "   'J Thies',\n",
       "   'M Nießner',\n",
       "   'L Valgaerts',\n",
       "   'C Theobalt'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-14',\n",
       "  'citations': '185',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=391289926406962623&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 94: {'ID': 94,\n",
       "  'title': 'Generating a multiplicity of policies for agent steering in crowd simulation',\n",
       "  'authors': ['M Kapadia', 'CD Boatright', 'NI Badler', 'JM Shapira'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (5), 483-494',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8716852820239797897&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 95: {'ID': 95,\n",
       "  'title': 'The impact of latency on perceptual judgments and motor performance in closed-loop interaction in virtual reality.',\n",
       "  'authors': ['I Senna',\n",
       "   'M Rohde',\n",
       "   'T Waltemate',\n",
       "   'MO Ernst',\n",
       "   'S Kopp',\n",
       "   '...',\n",
       "   'F Hülsmann'],\n",
       "  'journal': 'VRST, 27-35',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6399334103287270857&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 96: {'ID': 96,\n",
       "  'title': 'Matched Gk-constructions always yield Ck-continuous isogeometric elements',\n",
       "  'authors': ['D Groisser', 'J Peters'],\n",
       "  'journal': 'Computer Aided Geometric Design 34, 67-72',\n",
       "  'citations': '58',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=456062536331868077&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 97: {'ID': 97,\n",
       "  'title': 'Poisson-driven seamless completion of triangular meshes',\n",
       "  'authors': ['M Centin', 'A Signoroni', 'N Pezzotti'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 42-55',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14544432538926081938&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 98: {'ID': 98,\n",
       "  'title': '3D Skeletons: A State‐of‐the‐Art Report',\n",
       "  'authors': ['N Amenta',\n",
       "   'A Tagliasacchi',\n",
       "   'M Spagnuolo',\n",
       "   'T Delame',\n",
       "   'A Telea'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 573-597',\n",
       "  'citations': '122',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8746353882100864015&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 99: {'ID': 99,\n",
       "  'title': '3DHOP: 3D Heritage Online Presenter',\n",
       "  'authors': ['F Ponchio',\n",
       "   'M Dellepiane',\n",
       "   'M Corsini',\n",
       "   'M Callieri',\n",
       "   'R Scopigno',\n",
       "   'M Potenziani'],\n",
       "  'journal': 'Computers & Graphics 52, 129-141',\n",
       "  'citations': '131',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16075615724252585307&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 100: {'ID': 100,\n",
       "  'title': 'Shifty: A Weight-Shifting Dynamic Passive Haptic Proxy to Enhance Object Perception in Virtual Reality',\n",
       "  'authors': ['A Krüger', 'A Zenner'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (4), 1285-1294',\n",
       "  'citations': '99',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14456262205531828853&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 101: {'ID': 101,\n",
       "  'title': 'Hybrid-feature-guided lung nodule type classification on CT images',\n",
       "  'authors': ['F Hou', 'H Qin', 'A Hao', 'J Yuan', 'X Liu'],\n",
       "  'journal': 'Computers & Graphics 70, 288-299',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12905500033667732738&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 102: {'ID': 102,\n",
       "  'title': 'The asynchronous time warp for virtual reality on consumer hardware.',\n",
       "  'authors': ['JMP van Waveren'],\n",
       "  'journal': 'VRST, 37-46',\n",
       "  'citations': '36',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10831164893896090613&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 103: {'ID': 103,\n",
       "  'title': 'A Survey of Topology‐based Methods in Visualization',\n",
       "  'authors': ['M Hlawitschka',\n",
       "   'L De Floriani',\n",
       "   'C Heine',\n",
       "   '...',\n",
       "   'F Iuricich',\n",
       "   'H Leitte'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 643-667',\n",
       "  'citations': '56',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9646895231857445404&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 104: {'ID': 104,\n",
       "  'title': 'Denoising point sets via L0 minimization',\n",
       "  'authors': ['S Schaefer', 'W Wang', 'Y Sun'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 2-15',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11716916973340879036&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 105: {'ID': 105,\n",
       "  'title': 'Extraction of cylinders and estimation of their parameters from point clouds',\n",
       "  'authors': ['TT Tran', 'D Laurendeau', 'VT Cao'],\n",
       "  'journal': 'Computers & Graphics 46, 345-357',\n",
       "  'citations': '40',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7055289436763086540&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 106: {'ID': 106,\n",
       "  'title': 'Investigating the Impact of Cooperative Communication Mechanics on Player Performance in Portal 2',\n",
       "  'authors': ['L Nacke', 'Z Toups', 'D Vaddi', 'I Dolgov', 'R Wehbe'],\n",
       "  'journal': 'Proceedings of the 42nd Graphics Interface Conference, 41-48',\n",
       "  'citations': '12',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18106678230309905398&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 107: {'ID': 107,\n",
       "  'title': 'Designing a virtual environment for teacher training: Enhancing presence and empathy.',\n",
       "  'authors': ['N Magnenat-Thalmann', 'E Baka', 'A Lanitis', 'KE Stavroulia'],\n",
       "  'journal': 'CGI, 273-282',\n",
       "  'citations': '11',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9793269435772363081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 108: {'ID': 108,\n",
       "  'title': 'Dance performance evaluation using hidden Markov models',\n",
       "  'authors': ['S Laraba', 'J Tilmanne'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 27 (3-4), 321-329',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8714760691380872488&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 109: {'ID': 109,\n",
       "  'title': 'Real-time depth of field using multi-layer filtering.',\n",
       "  'authors': ['M Stamminger', 'K Selgrad', 'D Penk', 'P Wagner', 'C Reintges'],\n",
       "  'journal': 'I3D, 121-127',\n",
       "  'citations': '17',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1713424663111034276&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 110: {'ID': 110,\n",
       "  'title': 'How ideas flow across multiple social groups',\n",
       "  'authors': ['J Su',\n",
       "   'X Wang',\n",
       "   'Y Chen',\n",
       "   'J Yang',\n",
       "   'S Liu',\n",
       "   'B Guo',\n",
       "   'TQ Peng'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 51-60',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2759159515021431234&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 111: {'ID': 111,\n",
       "  'title': 'Analyzing the Training Processes of Deep Generative Models',\n",
       "  'authors': ['J Zhu', 'K Cao', 'M Liu', 'S Liu', 'J Shi'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 77-87',\n",
       "  'citations': '72',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4081657671260940362&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 112: {'ID': 112,\n",
       "  'title': 'Toward Standard Usability Questionnaires for Handheld Augmented Reality',\n",
       "  'authors': ['H Kato',\n",
       "   'T Taketomi',\n",
       "   'G Yamamoto',\n",
       "   'J Polvi',\n",
       "   'MEC Santos',\n",
       "   'C Sandor'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (5), 66-75',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16791701682094555154&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 113: {'ID': 113,\n",
       "  'title': 'Head-mounted display with mid-air tactile feedback',\n",
       "  'authors': ['I Rakkolainen',\n",
       "   'K Palovuori',\n",
       "   'J Kangas',\n",
       "   'A Sand',\n",
       "   'R Raisamo',\n",
       "   'P Isokoski'],\n",
       "  'journal': 'Proceedings of the 21st ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '36',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2205682838638069183&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 114: {'ID': 114,\n",
       "  'title': 'EgoNetCloud: Event-based egocentric dynamic network visualization',\n",
       "  'authors': ['Y Zhang', 'J Tang', 'L Shi', 'X Mu', 'Y Hu', 'Q Liu'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 65-72',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16057964119807684507&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 115: {'ID': 115,\n",
       "  'title': 'A Survey of Colormaps in Visualization',\n",
       "  'authors': ['CD Hansen', 'L Zhou'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (8), 2051-2069',\n",
       "  'citations': '74',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7782491075668546276&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 116: {'ID': 116,\n",
       "  'title': 'Linear Volumetric Focus for Light Field Cameras',\n",
       "  'authors': ['SB Williams', 'O Pizarro', 'DG Dansereau'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (2), 1-20',\n",
       "  'citations': '105',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5750160398737374633&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 117: {'ID': 117,\n",
       "  'title': 'CiteRivers: Visual Analytics of Citation Patterns',\n",
       "  'authors': ['Q Han', 'T Ertl', 'S Koch', 'F Heimerl'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 190-199',\n",
       "  'citations': '71',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10038287250704546564&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 118: {'ID': 118,\n",
       "  'title': 'Realizing a low-latency virtual reality environment for motor learning',\n",
       "  'authors': ['T Waltemate', 'M Botsch', 'T Pfeiffer', 'S Kopp', 'F Hülsmann'],\n",
       "  'journal': 'Proceedings of the 21st ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6783832693990593555&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 119: {'ID': 119,\n",
       "  'title': 'Garment capture from a photograph',\n",
       "  'authors': ['DH Han', 'HS Ko', 'MH Jeong'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (3-4), 291-300',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2222068789889247864&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 120: {'ID': 120,\n",
       "  'title': 'A machine learning approach for filtering Monte Carlo noise',\n",
       "  'authors': ['S Bako', 'NK Kalantari', 'P Sen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '106',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16239754161909763799&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 121: {'ID': 121,\n",
       "  'title': 'An Exploratory Study of Data Sketching for Visual Representation',\n",
       "  'authors': ['S Huron', 'J Walny', 'S Carpendale'],\n",
       "  'journal': 'Computer Graphics Forum 34 (3), 231-240',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7654528453082299841&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 122: {'ID': 122,\n",
       "  'title': 'Fusion4D: real-time performance capture of challenging scenes',\n",
       "  'authors': ['P Davidson',\n",
       "   'Y Degtyarev',\n",
       "   'M Dou',\n",
       "   'S Khamis',\n",
       "   'A Kowdle',\n",
       "   'SR Fanello',\n",
       "   '...'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-13',\n",
       "  'citations': '226',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7121605980326096070&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 123: {'ID': 123,\n",
       "  'title': 'SenseMap: Supporting browser-based online sensemaking through analytic provenance',\n",
       "  'authors': ['PH Nguyen',\n",
       "   'BLW Wong',\n",
       "   'K Herd',\n",
       "   'A Bardill',\n",
       "   'K Xu',\n",
       "   'B Salman'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 91-100',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11162928775378016679&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 124: {'ID': 124,\n",
       "  'title': 'Applicability of watermarking for intellectual property rights protection in a 3D printing scenario.',\n",
       "  'authors': ['B Macq', 'MM Sales', 'P Rondao-Alface'],\n",
       "  'journal': 'Web3D, 89-95',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3378117475546391658&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 125: {'ID': 125,\n",
       "  'title': 'A modular software architecture for processing of big geospatial data in the cloud',\n",
       "  'authors': ['M Krämer', 'I Senner'],\n",
       "  'journal': 'Computers & Graphics 49, 69-81',\n",
       "  'citations': '56',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11116551970185824544&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 126: {'ID': 126,\n",
       "  'title': 'MVE—An image-based reconstruction environment',\n",
       "  'authors': ['M Waechter',\n",
       "   'M Goesele',\n",
       "   'F Langguth',\n",
       "   'S Fuhrmann',\n",
       "   'N Moehrle'],\n",
       "  'journal': 'Computers & Graphics 53, 44-53',\n",
       "  'citations': '49',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4737913290048913200&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 127: {'ID': 127,\n",
       "  'title': 'Procedural voronoi foams for additive manufacturing',\n",
       "  'authors': ['J Martínez', 'S Lefebvre', 'J Dumas'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-12',\n",
       "  'citations': '86',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11071212229295140925&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 128: {'ID': 128,\n",
       "  'title': 'Combined shape and topology optimization of 3D structures',\n",
       "  'authors': ['AN Christiansen',\n",
       "   'O Sigmund',\n",
       "   'N Aage',\n",
       "   'M Nobel-Jørgensen',\n",
       "   'JA Bærentzen'],\n",
       "  'journal': 'Computers & Graphics 46, 25-35',\n",
       "  'citations': '66',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7607915932306880568&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 129: {'ID': 129,\n",
       "  'title': 'An uncertainty-driven approach to vortex analysis using oracle consensus and spatial proximity',\n",
       "  'authors': ['Q Deng',\n",
       "   'A Biswas',\n",
       "   'HW Shenk',\n",
       "   'CM Chen',\n",
       "   '...',\n",
       "   'D Thompson',\n",
       "   'W He'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 223-230',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3816626991069820408&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 130: {'ID': 130,\n",
       "  'title': 'Dimension and basis construction for analysis-suitable G1 two-patch parameterizations',\n",
       "  'authors': ['G Sangalli', 'M Kapl', 'T Takacs'],\n",
       "  'journal': 'Computer Aided Geometric Design 52, 75-89',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14918900334089111532&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 131: {'ID': 131,\n",
       "  'title': 'The Role of Explicit Knowledge: A Conceptual Model of Knowledge-Assisted Visual Analytics',\n",
       "  'authors': ['A Rind',\n",
       "   'M Wagner',\n",
       "   'W Aigner',\n",
       "   'S Miksch',\n",
       "   'A Amor-Amorós',\n",
       "   'P Federico'],\n",
       "  'journal': '2017 IEEE Conference on Visual Analytics Science and Technology (VAST), 92-103',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9369116190595659499&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 132: {'ID': 132,\n",
       "  'title': 'Using Augmented Reality to Elicit Pretend Play for Children with Autism',\n",
       "  'authors': ['G Coulouris', 'Z Bai', 'AF Blackwell'],\n",
       "  'journal': 'IEEE Transactions on Visualization & Computer Graphics, 598-610',\n",
       "  'citations': '80',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7372689225013317500&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 133: {'ID': 133,\n",
       "  'title': 'Real-time high-fidelity facial performance capture',\n",
       "  'authors': ['C Cao', 'K Zhou', 'T Beeler', 'D Bradley'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-9',\n",
       "  'citations': '170',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1905984625682048388&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 134: {'ID': 134,\n",
       "  'title': 'ColorCAT: Guided Design of Colormaps for Combined Analysis Tasks.',\n",
       "  'authors': ['F Stoffel', 'D Jäckle', 'S Mittelstädt', 'DA Keim'],\n",
       "  'journal': 'EuroVis (Short Papers), 115-119',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4800272801269109033&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 135: {'ID': 135,\n",
       "  'title': 'Urban data visualisation in a web browser.',\n",
       "  'authors': ['G Gesquière',\n",
       "   'J Gaillard',\n",
       "   'A Peytavie',\n",
       "   'A Vienne',\n",
       "   'R Baume',\n",
       "   'F Pedrinis'],\n",
       "  'journal': 'Web3D, 81-88',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15260217713735272680&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 136: {'ID': 136,\n",
       "  'title': 'Extending Dimensions in Radviz based on mean shift',\n",
       "  'authors': ['Y Zhao', 'Y Shi', 'Y Huang', 'W Huang', 'F Zhou', 'J Li'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 111-115',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13964602366702102103&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 137: {'ID': 137,\n",
       "  'title': 'Orientation analysis of 3D objects toward minimal support volume in 3D-printing',\n",
       "  'authors': ['F Massarwi', 'B Ezair', 'G Elber'],\n",
       "  'journal': 'Computers & Graphics 51, 117-124',\n",
       "  'citations': '45',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13987618857295066256&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 138: {'ID': 138,\n",
       "  'title': 'TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems',\n",
       "  'authors': ['YR Lin', 'C Shi', 'J Lu', 'S Lin', 'CY Lin', 'N Cao'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 280-289',\n",
       "  'citations': '79',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10661211343752945086&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 139: {'ID': 139,\n",
       "  'title': 'MAVE: Maze‐based immersive virtual environment for new presence and experience',\n",
       "  'authors': ['J Lee', 'K Jeong', 'J Kim'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 28 (3-4), e1756',\n",
       "  'citations': '25',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=827343090239412027&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 140: {'ID': 140,\n",
       "  'title': 'Matrix Reordering Methods for Table and Network Visualization',\n",
       "  'authors': ['N Henry Riche',\n",
       "   'B Bach',\n",
       "   'M Behrisch',\n",
       "   'T Schreck',\n",
       "   'JD Fekete'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 693-716',\n",
       "  'citations': '104',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8719022971065098345&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 141: {'ID': 141,\n",
       "  'title': 'Emotion control of unstructured dance movements',\n",
       "  'authors': ['KK Yin',\n",
       "   'E Stavrakis',\n",
       "   'Q Zeng',\n",
       "   '...',\n",
       "   'D Cohen-Or',\n",
       "   'A Aristidou',\n",
       "   'Y Chrysanthou'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3764230382847918872&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 142: {'ID': 142,\n",
       "  'title': 'Distinctive 2D and 3D features for automated large-scale scene analysis in urban areas',\n",
       "  'authors': ['B Jutzi', 'S Hinz', 'C Mallet', 'M Weinmann', 'S Urban'],\n",
       "  'journal': 'Computers & Graphics 49, 47-57',\n",
       "  'citations': '71',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18377929553053370235&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 143: {'ID': 143,\n",
       "  'title': 'Presentation-Oriented Visualization Techniques',\n",
       "  'authors': ['R Kosara'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 36 (1), 80-85',\n",
       "  'citations': '37',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5127899109189495282&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 144: {'ID': 144,\n",
       "  'title': 'Steering data quality with visual analytics: The complexity challenge',\n",
       "  'authors': ['C Shi',\n",
       "   'N Cao',\n",
       "   'Y Wu',\n",
       "   'S Hong',\n",
       "   'YS Wang',\n",
       "   'L Jiang',\n",
       "   'G Andrienko',\n",
       "   'S Liu'],\n",
       "  'journal': 'Visual Informatics 2 (4), 191-197',\n",
       "  'citations': '11',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8532678406794185297&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 145: {'ID': 145,\n",
       "  'title': 'A new basis for PHT-splines',\n",
       "  'authors': ['J Deng', 'F Chen', 'J Xu', 'H Kang'],\n",
       "  'journal': 'Graphical Models 82, 149-159',\n",
       "  'citations': '16',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16411146935793632320&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 146: {'ID': 146,\n",
       "  'title': 'Registration of multiview point clouds for application to ship fabrication',\n",
       "  'authors': ['SI Choi', 'SH Kim', 'DH Yun', 'KH Ko'],\n",
       "  'journal': 'Graphical Models 90, 1-12',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9776864463247923300&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 147: {'ID': 147,\n",
       "  'title': 'EventAction: Visual analytics for temporal event sequence recommendation',\n",
       "  'authors': ['N Spring', 'C Plaisant', 'F Du', 'B Shneiderman'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 61-70',\n",
       "  'citations': '51',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15268352982100409955&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 148: {'ID': 148,\n",
       "  'title': 'Reconstruction of Personalized 3D Face Rigs from Monocular Video',\n",
       "  'authors': ['K Varanasi',\n",
       "   'P Garrido',\n",
       "   'P Pérez',\n",
       "   'M Zollhöfer',\n",
       "   'D Casas',\n",
       "   '...',\n",
       "   'L Valgaerts'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (3), 1-15',\n",
       "  'citations': '111',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5601607972354080538&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 149: {'ID': 149,\n",
       "  'title': 'Teleportation without Spatial Disorientation Using Optical Flow Cues',\n",
       "  'authors': ['J Bhandari', 'P MacNeilage', 'E Folmer'],\n",
       "  'journal': 'Proceedings of the 44th Graphics Interface Conference, 162-167',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4122856997732278446&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 150: {'ID': 150,\n",
       "  'title': 'Dyna: a model of dynamic human shape in motion',\n",
       "  'authors': ['N Mahmood', 'MJ Black', 'J Romero', 'G Pons-Moll'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-14',\n",
       "  'citations': '175',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6443376918706558551&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 151: {'ID': 151,\n",
       "  'title': \"Characterizing Visualization Insights from Quantified Selfers' Personal Data Presentations\",\n",
       "  'authors': ['EK Choe', 'B Lee'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (4), 28-37',\n",
       "  'citations': '76',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6738129314435741955&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 152: {'ID': 152,\n",
       "  'title': 'Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths',\n",
       "  'authors': ['Z Liu',\n",
       "   'S Walker',\n",
       "   'A Wilson',\n",
       "   'Y Wang',\n",
       "   'M Hoffman',\n",
       "   'M Dontcheva'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 321-330',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13600436068446456463&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 153: {'ID': 153,\n",
       "  'title': 'Interactive reconstruction of Monte Carlo image sequences using a recurrent denoising autoencoder',\n",
       "  'authors': ['A Lefohn',\n",
       "   'C Schied',\n",
       "   '...',\n",
       "   'M Salvi',\n",
       "   'CRA Chaitanya',\n",
       "   'AS Kaplanyan'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-12',\n",
       "  'citations': '111',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12446307758832874124&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 154: {'ID': 154,\n",
       "  'title': 'SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations',\n",
       "  'authors': ['Y Zheng', 'Y Wu', 'D Weng', 'J Bao', 'Y Li', 'H Qu', 'D Liu'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 1-10',\n",
       "  'citations': '90',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15448076781010955693&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 155: {'ID': 155,\n",
       "  'title': 'Massive point cloud data management: Design, implementation and execution of a point cloud benchmark',\n",
       "  'authors': ['M Ivanova',\n",
       "   'M Horhammer',\n",
       "   '...',\n",
       "   'O Martinez-Rubi',\n",
       "   'P van Oosterom',\n",
       "   'D Geringer'],\n",
       "  'journal': 'Computers & Graphics 49, 92-125',\n",
       "  'citations': '84',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12132810184797517475&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 156: {'ID': 156,\n",
       "  'title': 'Towards browsing repositories of spatially oriented historic photographic images in 3D web environments.',\n",
       "  'authors': ['F Niebling',\n",
       "   'ME Latoschik',\n",
       "   'K Friedrichs',\n",
       "   'F Maiwald',\n",
       "   'M Wacker',\n",
       "   'J Bruschke'],\n",
       "  'journal': 'Web3D, 18:1-18:6',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14255209006355066110&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 157: {'ID': 157,\n",
       "  'title': 'Let there be color! joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification',\n",
       "  'authors': ['H Ishikawa', 'S Iizuka', 'E Simo-Serra'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-11',\n",
       "  'citations': '441',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4026508573879890478&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 158: {'ID': 158,\n",
       "  'title': 'Mesh saliency via ranking unsalient patches in a descriptor space',\n",
       "  'authors': ['S Li', 'P Tao', 'J Cao', 'L Liu', 'X Liu'],\n",
       "  'journal': 'Computers & Graphics 46, 264-274',\n",
       "  'citations': '30',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=638272102216859387&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 159: {'ID': 159,\n",
       "  'title': 'Moment shadow mapping.',\n",
       "  'authors': ['C Peters', 'R Klein'],\n",
       "  'journal': 'I3D, 7-14',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7214546627478238833&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 160: {'ID': 160,\n",
       "  'title': 'NARI: Natural Augmented Reality Interface',\n",
       "  'authors': ['R Nóbrega', 'G Jacucci', 'A Coelho', 'D Cabral'],\n",
       "  'journal': 'Proceedings of the 10th International Conference on Computer Graphics Theory\\xa0…',\n",
       "  'citations': '12',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14606928690947443930&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 161: {'ID': 161,\n",
       "  'title': 'Gaze-based interaction: A 30 year retrospective',\n",
       "  'authors': ['AT Duchowski'],\n",
       "  'journal': 'Computers & Graphics 73, 59-69',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11692354730699839144&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 162: {'ID': 162,\n",
       "  'title': 'Attribute-driven edge bundling for general graphs with applications in trail analysis',\n",
       "  'authors': ['A Telea', 'C Hurter', 'V Peysakhovich'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 39-46',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17097615402994599034&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 163: {'ID': 163,\n",
       "  'title': 'Jointly Optimized Regressors for Image Super‐resolution',\n",
       "  'authors': ['L Van Gool', 'D Dai', 'R Timofte'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 95-104',\n",
       "  'citations': '137',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12455994668994664895&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 164: {'ID': 164,\n",
       "  'title': 'BundleFusion: Real-Time Globally Consistent 3D Reconstruction Using On-the-Fly Surface Reintegration',\n",
       "  'authors': ['S Izadi', 'A Dai', 'M Zollhöfer', 'M Nießner', 'C Theobalt'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1',\n",
       "  'citations': '318',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12844178598905150834&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 165: {'ID': 165,\n",
       "  'title': 'Can twitter really save your life? A case study of visual social media analytics for situation awareness',\n",
       "  'authors': ['T Ertl',\n",
       "   'D Thom',\n",
       "   'U Bechstedt',\n",
       "   'A Platz',\n",
       "   'B Volland',\n",
       "   'J Zisgen',\n",
       "   'R Krüger'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 183-190',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17825316928322472025&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 166: {'ID': 166,\n",
       "  'title': 'Fast decompression for web-based view-dependent 3D rendering.',\n",
       "  'authors': ['F Ponchio', 'M Dellepiane'],\n",
       "  'journal': 'Web3D, 199-207',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1443115247339666113&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 167: {'ID': 167,\n",
       "  'title': 'Phasor Imaging: A Generalization of Correlation-Based Time-of-Flight Imaging',\n",
       "  'authors': ['M Gupta', 'MB Hullin', 'SK Nayar', 'J Martin'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (5), 1-18',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16471648547493406400&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 168: {'ID': 168,\n",
       "  'title': 'Diffusion Modelling Tool (DMT) for the analysis of Diffusion Weighted Imaging (DWI) Magnetic Resonance Imaging (MRI) data.',\n",
       "  'authors': ['K Nikiforaki', 'GC Manikis', 'N Papanikolaou', 'K Marias'],\n",
       "  'journal': 'CGI (Short Papers), 97-100',\n",
       "  'citations': '11',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9821074341341302817&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 169: {'ID': 169,\n",
       "  'title': 'Database‐Assisted Object Retrieval for Real‐Time 3D Reconstruction',\n",
       "  'authors': ['L Guibas', 'M Nießner', 'Y Li', 'A Dai'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 435-446',\n",
       "  'citations': '100',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5078959095625747081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 170: {'ID': 170,\n",
       "  'title': 'ChartAccent: Annotation for data-driven storytelling',\n",
       "  'authors': ['B Lee', 'M Brehmer', 'EK Choe', 'T Höllerer', 'D Ren'],\n",
       "  'journal': '2017 IEEE Pacific Visualization Symposium (PacificVis), 230-239',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9839272186231504324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 171: {'ID': 171,\n",
       "  'title': 'Ray tracing within a data parallel framework',\n",
       "  'authors': ['H Childs', 'JS Meredith', 'PA Navrátil', 'M Larsen'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 279-286',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7495072548170427790&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 172: {'ID': 172,\n",
       "  'title': 'Real-time EEG-based emotion monitoring using stable features',\n",
       "  'authors': ['L Wang', 'Z Lan', 'O Sourina', 'Y Liu'],\n",
       "  'journal': 'The Visual Computer 32 (3), 347-358',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3383804992352585143&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 173: {'ID': 173,\n",
       "  'title': 'State‐of‐the‐Art in GPU‐Based Large‐Scale Volume Visualization',\n",
       "  'authors': ['H Pfister', 'M Hadwiger', 'J Beyer'],\n",
       "  'journal': 'Computer Graphics Forum 34 (8), 13-37',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10148000910960615492&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 174: {'ID': 174,\n",
       "  'title': 'Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks',\n",
       "  'authors': ['T Madhyastha',\n",
       "   'B Bach',\n",
       "   'JD Fekete',\n",
       "   'T Dwyer',\n",
       "   'N Henry‐Riche',\n",
       "   'T Grabowski'],\n",
       "  'journal': 'Computer Graphics Forum 34 (3), 31-40',\n",
       "  'citations': '68',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11116957589183752248&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 175: {'ID': 175,\n",
       "  'title': 'Additive light field displays: realization of augmented reality with holographic optical elements',\n",
       "  'authors': ['B Lee', 'S Lee', 'J Cho', 'C Jang', 'S Moon'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-13',\n",
       "  'citations': '93',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15976834305819810898&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 176: {'ID': 176,\n",
       "  'title': 'Multi-resolution terrain rendering with GPU tessellation',\n",
       "  'authors': ['JH Han', 'HY Kang', 'CS Cho', 'H Jang'],\n",
       "  'journal': 'The Visual Computer 31 (4), 455-469',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9455159161408950654&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 177: {'ID': 177,\n",
       "  'title': 'A Taxonomy and Survey of Dynamic Graph Visualization',\n",
       "  'authors': ['S Diehl', 'D Weiskopf', 'M Burch', 'F Beck'],\n",
       "  'journal': 'Computer Graphics Forum 36 (1), 133-159',\n",
       "  'citations': '171',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12355477852375322385&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 178: {'ID': 178,\n",
       "  'title': 'Visual exploration of movement and event data with interactive time masks',\n",
       "  'authors': ['JMC Garcia',\n",
       "   'C Claramunt',\n",
       "   'N Andrienko',\n",
       "   'E Camossi',\n",
       "   'G Andrienko',\n",
       "   '...'],\n",
       "  'journal': 'Visual Informatics 1 (1), 25-39',\n",
       "  'citations': '12',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1092400714537723130&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 179: {'ID': 179,\n",
       "  'title': 'DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks',\n",
       "  'authors': ['E Eisemann',\n",
       "   'A Vilanova',\n",
       "   'N Pezzotti',\n",
       "   'T Höllt',\n",
       "   'BPF Lelieveldt',\n",
       "   'J Van Gemert'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 98-108',\n",
       "  'citations': '89',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7591033387848629831&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 180: {'ID': 180,\n",
       "  'title': 'Visual Analytics for MOOC Data',\n",
       "  'authors': ['H Qu', 'Q Chen'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (6), 69-75',\n",
       "  'citations': '44',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5404368565612835669&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 181: {'ID': 181,\n",
       "  'title': 'Automated Aesthetic Analysis of Photographic Images.',\n",
       "  'authors': ['M Gross', 'TO Aydın', 'A Smolic'],\n",
       "  'journal': 'IEEE transactions on visualization and computer graphics 21 (1), 31-42',\n",
       "  'citations': '86',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17029344306555716049&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 182: {'ID': 182,\n",
       "  'title': 'State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications',\n",
       "  'authors': ['T Beeler',\n",
       "   'P Garrido',\n",
       "   'P Pérez',\n",
       "   'M Zollhöfer',\n",
       "   'J Thies',\n",
       "   '...',\n",
       "   'D Bradley'],\n",
       "  'journal': 'Computer Graphics Forum 37 (2), 523-550',\n",
       "  'citations': '71',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4895329394395951757&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 183: {'ID': 183,\n",
       "  'title': 'Nitsche method for isogeometric analysis of Reissner–Mindlin plate with non-conforming multi-patches',\n",
       "  'authors': ['G Zhao', 'X Du', 'W Wang'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 121-136',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=822575949873177993&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 184: {'ID': 184,\n",
       "  'title': 'The Impact of Avatar Personalization and Immersion on Virtual Body Ownership, Presence, and Emotional Response',\n",
       "  'authors': ['D Roth', 'T Waltemate', 'ME Latoschik', 'D Gall', 'M Botsch'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (4), 1643-1652',\n",
       "  'citations': '75',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6160877906791624651&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 185: {'ID': 185,\n",
       "  'title': 'The Role of Uncertainty, Awareness, and Trust in Visual Analytics',\n",
       "  'authors': ['DA Keim', 'G Ellis', 'BC Kwon', 'H Senaratne', 'D Sacha'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 240-249',\n",
       "  'citations': '138',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17954086984153913604&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 186: {'ID': 186,\n",
       "  'title': 'The State of the Art in HDR Deghosting: A Survey and Evaluation',\n",
       "  'authors': ['OT Tursun', 'A Erdem', 'AO Akyüz', 'E Erdem'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 683-707',\n",
       "  'citations': '61',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4050348994012508954&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 187: {'ID': 187,\n",
       "  'title': 'Characterizing Guidance in Visual Analytics',\n",
       "  'authors': ['M Streit',\n",
       "   'D Ceneda',\n",
       "   '...',\n",
       "   'HJ Schulz',\n",
       "   'S Miksch',\n",
       "   'T Gschwandtner',\n",
       "   'T May'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 111-120',\n",
       "  'citations': '86',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17328152318838622773&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 188: {'ID': 188,\n",
       "  'title': 'FFTEB: Edge bundling of huge graphs by the Fast Fourier Transform',\n",
       "  'authors': ['A Telea', 'A Lhuillier', 'C Hurter'],\n",
       "  'journal': '2017 IEEE Pacific Visualization Symposium (PacificVis), 190-199',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7454459879704124937&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 189: {'ID': 189,\n",
       "  'title': 'Survey on sparsity in geometric modeling and processing',\n",
       "  'authors': ['L Xu',\n",
       "   'J Deng',\n",
       "   'Z Yang',\n",
       "   'R Wang',\n",
       "   'J Zhang',\n",
       "   'F Chen',\n",
       "   'L Liu'],\n",
       "  'journal': 'Graphical Models 82, 160-180',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12867817173363673523&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 190: {'ID': 190,\n",
       "  'title': 'webVis/instant3DHub: visual computing as a service infrastructure to deliver adaptive, secure and scalable user centric data visualisation.',\n",
       "  'authors': ['J Champeau',\n",
       "   'M Thöner',\n",
       "   'C Jeulin',\n",
       "   'J Behr',\n",
       "   'C Stein',\n",
       "   '...',\n",
       "   'C Mouton',\n",
       "   'S Parfouru'],\n",
       "  'journal': 'Web3D, 39-47',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15517911700683901633&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 191: {'ID': 191,\n",
       "  'title': 'Environment optimization for crowd evacuation',\n",
       "  'authors': ['P Faloutsos', 'M Usman', 'M Kapadia', 'B Haworth', 'G Berseth'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (3-4), 377-386',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8657047661095928155&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 192: {'ID': 192,\n",
       "  'title': 'A Natural Interface for Remote Operation of Underwater Robots',\n",
       "  'authors': ['PJ Sanz',\n",
       "   'B Patrão',\n",
       "   'J Dias',\n",
       "   'JC García',\n",
       "   'J Pérez',\n",
       "   'L Almeida',\n",
       "   'P Menezes'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 37 (1), 34-43',\n",
       "  'citations': '35',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4352365389777363535&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 193: {'ID': 193,\n",
       "  'title': 'SlidAR: A 3D positioning method for SLAM-based handheld augmented reality',\n",
       "  'authors': ['H Kato',\n",
       "   'A Dey',\n",
       "   'T Taketomi',\n",
       "   'G Yamamoto',\n",
       "   'J Polvi',\n",
       "   'C Sandor'],\n",
       "  'journal': 'Computers & Graphics 55, 33-43',\n",
       "  'citations': '42',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15182468261507848639&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 194: {'ID': 194,\n",
       "  'title': 'Model-driven indoor scenes modeling from a single image',\n",
       "  'authors': ['Z Liu', 'Y Zhang', 'Z Sun', 'W Wu', 'K Liu'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 25-32',\n",
       "  'citations': '16',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7609622066006089106&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 195: {'ID': 195,\n",
       "  'title': 'Penny pincher: a blazing fast, highly accurate $-family recognizer',\n",
       "  'authors': ['JJ LaViola Jr', 'EM Taranta'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 195-202',\n",
       "  'citations': '16',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12656902367737091046&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 196: {'ID': 196,\n",
       "  'title': 'Testing the rehearsal hypothesis with two FastTap interfaces',\n",
       "  'authors': ['C Gutwin', 'A Cockburn', 'B Lafreniere'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 223-231',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11634115639974613328&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 197: {'ID': 197,\n",
       "  'title': 'Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration',\n",
       "  'authors': ['S van den Elzen', 'D Holten', 'J Blaas', 'JJ van Wijk'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 1-10',\n",
       "  'citations': '103',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10462641570833677759&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 198: {'ID': 198,\n",
       "  'title': 'RAPter: rebuilding man-made scenes with regular arrangements of planes',\n",
       "  'authors': ['N Mellado', 'A Monszpart', 'GJ Brostow', 'NJ Mitra'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '101',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4673735347993717080&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 199: {'ID': 199,\n",
       "  'title': 'Visualizing the Hidden Activity of Artificial Neural Networks',\n",
       "  'authors': ['SG Fadel', 'AX Falcão', 'AC Telea', 'PE Rauber'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 101-110',\n",
       "  'citations': '162',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16786127855924369097&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 200: {'ID': 200,\n",
       "  'title': 'Diegetic cues for guiding the viewer in cinematic virtual reality',\n",
       "  'authors': ['H Hußmann', 'S Rothe', 'M Allary'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16048992621043802774&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 201: {'ID': 201,\n",
       "  'title': 'Open3D: crowd-sourced distributed curation of city models.',\n",
       "  'authors': ['NJ Mitra', 'P Guerrero', 'A Steed', 'Z Lu'],\n",
       "  'journal': 'Web3D, 87-94',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11898115044620137688&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 202: {'ID': 202,\n",
       "  'title': 'Using glTF for streaming CityGML 3D city models.',\n",
       "  'authors': ['C Nagel', 'J Bolling', 'A Schilling'],\n",
       "  'journal': 'Web3D, 109-116',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10403146233934416454&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 203: {'ID': 203,\n",
       "  'title': 'Phase-functioned neural networks for character control',\n",
       "  'authors': ['J Saito', 'T Komura', 'D Holden'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-13',\n",
       "  'citations': '184',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8592601530343805652&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 204: {'ID': 204,\n",
       "  'title': '3D Mesh Labeling via Deep Convolutional Neural Networks',\n",
       "  'authors': ['K Guo', 'X Chen', 'D Zou'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (1), 1-12',\n",
       "  'citations': '127',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4207624916198286140&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 205: {'ID': 205,\n",
       "  'title': 'Divergence-free smoothed particle hydrodynamics',\n",
       "  'authors': ['D Koschier', 'J Bender'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '67',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10695398008698152111&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 206: {'ID': 206,\n",
       "  'title': 'Fast generation of realistic virtual humans',\n",
       "  'authors': ['M Botsch', 'T Waltemate', 'ME Latoschik', 'J Achenbach'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1379203018213681005&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 207: {'ID': 207,\n",
       "  'title': 'Efficient and precise interactive hand tracking through joint, continuous optimization of pose and correspondences',\n",
       "  'authors': ['T Sharp',\n",
       "   '...',\n",
       "   'J Taylor',\n",
       "   'C Keskin',\n",
       "   'T Cashman',\n",
       "   'E Soto',\n",
       "   'L Bordeaux',\n",
       "   'B Corish'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-12',\n",
       "  'citations': '184',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4964704387385826340&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 208: {'ID': 208,\n",
       "  'title': 'Assessing Knowledge Retention of an Immersive Serious Game vs. a Traditional Education Method in Aviation Safety',\n",
       "  'authors': ['F Buttussi', 'L Chittaro'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (4), 529-538',\n",
       "  'citations': '145',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1763982911870087324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 209: {'ID': 209,\n",
       "  'title': 'Efficient maximal Poisson-disk sampling and remeshing on surfaces',\n",
       "  'authors': ['J Guo', 'X Zhang', 'X Jia', 'DM Yan'],\n",
       "  'journal': 'Computers & Graphics 46, 72-79',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6308401754835424400&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 210: {'ID': 210,\n",
       "  'title': 'Virtual cutting of deformable objects based on efficient topological operations',\n",
       "  'authors': ['S Cotin',\n",
       "   'L Untereiner',\n",
       "   'H Courtecuisse',\n",
       "   'D Cazier',\n",
       "   'CJ Paulus'],\n",
       "  'journal': 'The Visual Computer 31 (6-8), 831-841',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=329960151077409052&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 211: {'ID': 211,\n",
       "  'title': 'OSPRay-A CPU Ray Tracing Framework for Scientific Visualization',\n",
       "  'authors': ['J Jeffers',\n",
       "   'I Wald',\n",
       "   'A Knoll',\n",
       "   'GP Johnson',\n",
       "   'C Brownlee',\n",
       "   'J Amstutz',\n",
       "   '...',\n",
       "   'J Günther'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 931-940',\n",
       "  'citations': '106',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7152069103145516502&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 212: {'ID': 212,\n",
       "  'title': 'Efficient Sparse ICP',\n",
       "  'authors': ['P Mavridis', 'G Papaioannou', 'A Andreadis'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 16-26',\n",
       "  'citations': '43',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4490678920820093813&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 213: {'ID': 213,\n",
       "  'title': 'Design Challenges and Opportunities for Eco-Feedback in the Home',\n",
       "  'authors': ['L Bartram'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (4), 52-62',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14187342842599078672&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 214: {'ID': 214,\n",
       "  'title': 'Exploiting analysis history to support collaborative data analysis',\n",
       "  'authors': ['A Sarvghad', 'M Tory'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 123-130',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=577659387751399574&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 215: {'ID': 215,\n",
       "  'title': 'VIAL: a unified process for visual interactive labeling',\n",
       "  'authors': ['J Bernard', 'M Zeppelzauer', 'W Aigner', 'M Sedlmair'],\n",
       "  'journal': 'The Visual Computer 34 (9), 1189-1207',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3945546928033101410&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 216: {'ID': 216,\n",
       "  'title': 'Natural language interfaces for data analysis with visualization: considering what has and could be asked',\n",
       "  'authors': ['J Stasko', 'A Srinivasan'],\n",
       "  'journal': 'Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short\\xa0…',\n",
       "  'citations': '25',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=639411694583574437&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 217: {'ID': 217,\n",
       "  'title': 'Directional Field Synthesis, Design, and Processing',\n",
       "  'authors': ['M Campen',\n",
       "   'A Vaxman',\n",
       "   'O Diamanti',\n",
       "   '...',\n",
       "   'D Bommes',\n",
       "   'D Panozzo'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 545-572',\n",
       "  'citations': '94',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6520392681460772852&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 218: {'ID': 218,\n",
       "  'title': 'The State‐of‐the‐Art of Set Visualization',\n",
       "  'authors': ['B Alsallakh',\n",
       "   'P Rodgers',\n",
       "   'H Hauser',\n",
       "   'L Micallef',\n",
       "   'W Aigner',\n",
       "   'S Miksch'],\n",
       "  'journal': 'Computer Graphics Forum 35 (1), 234-260',\n",
       "  'citations': '63',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16710161251196480589&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 219: {'ID': 219,\n",
       "  'title': 'A Testbed Combining Visual Perception Models for Geographic Gaze Contingent Displays.',\n",
       "  'authors': ['J Krüger', 'A Çöltekin', 'K Bektas', 'AT Duchowski'],\n",
       "  'journal': 'EuroVis (Short Papers), 67-71',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7352509600180890128&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 220: {'ID': 220,\n",
       "  'title': 'VisMOOC: Visualizing video clickstream data from Massive Open Online Courses',\n",
       "  'authors': ['H Qu', 'C Shi', 'S Fu', 'Q Chen'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 159-166',\n",
       "  'citations': '91',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10065639964397472471&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 221: {'ID': 221,\n",
       "  'title': 'Anisotropic Diffusion Descriptors',\n",
       "  'authors': ['J Masci',\n",
       "   'E Rodolà',\n",
       "   'D Boscaini',\n",
       "   'MM Bronstein',\n",
       "   'D Cremers'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 431-441',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6284066548427193708&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 222: {'ID': 222,\n",
       "  'title': 'MobileFusion: Real-Time Volumetric Surface Reconstruction and Dense Tracking on Mobile Phones',\n",
       "  'authors': ['P Kohli', 'P Ondrúška', 'S Izadi'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (11), 1251-1258',\n",
       "  'citations': '92',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10711669937469931309&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 223: {'ID': 223,\n",
       "  'title': 'Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research',\n",
       "  'authors': ['J Johansson', 'C Forsell'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 579-588',\n",
       "  'citations': '84',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14492361535991500711&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 224: {'ID': 224,\n",
       "  'title': 'Real-Time RGB-D Camera Relocalization via Randomized Ferns for Keyframe Encoding',\n",
       "  'authors': ['A Criminisi', 'S Izadi', 'J Shotton', 'B Glocker'],\n",
       "  'journal': 'IEEE Transactions on Visualization & Computer Graphics, 571-583',\n",
       "  'citations': '74',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8904676321329541146&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 225: {'ID': 225,\n",
       "  'title': 'Dimension and bases for geometrically continuous splines on surfaces of arbitrary topology',\n",
       "  'authors': ['B Mourrain', 'R Vidunas', 'N Villamizar'],\n",
       "  'journal': 'Computer Aided Geometric Design 45, 108-133',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6433906547363986695&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 226: {'ID': 226,\n",
       "  'title': 'Analyzing the Evolution of the Internet.',\n",
       "  'authors': ['S Nusrat', 'C Acedo', 'T Johnson', 'SG Kobourov'],\n",
       "  'journal': 'EuroVis (Short Papers), 43-47',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5884507354356084290&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 227: {'ID': 227,\n",
       "  'title': 'Learning reduced-order feedback policies for motion skills',\n",
       "  'authors': ['KK Yin', 'K Ding', 'M van de Panne', 'L Liu'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '25',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4704443594652663343&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 228: {'ID': 228,\n",
       "  'title': 'Interactive continuous collision detection for topology changing models using dynamic clustering.',\n",
       "  'authors': ['R Ortiz', 'L He', 'D Manocha', 'A Enquobahrie'],\n",
       "  'journal': 'I3D, 47-54',\n",
       "  'citations': '16',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13866728246044059133&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 229: {'ID': 229,\n",
       "  'title': 'Timelines Revisited: A Design Space and Considerations for Expressive Storytelling',\n",
       "  'authors': ['B Lee', 'T Munzner', 'NH Riche', 'B Bach', 'M Brehmer'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (9), 2151-2164',\n",
       "  'citations': '75',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11427122124022080918&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 230: {'ID': 230,\n",
       "  'title': 'A case study on 3D geospatial applications in the web using state-of-the-art WebGL frameworks.',\n",
       "  'authors': ['M Krämer', 'R Gutbell'],\n",
       "  'journal': 'Web3D, 189-197',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15225227876282770999&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 231: {'ID': 231,\n",
       "  'title': 'SepMe: 2002 New visual separation measures',\n",
       "  'authors': ['M Aupetit', 'M Sedlmair'],\n",
       "  'journal': '2016 IEEE Pacific Visualization Symposium (PacificVis), 1-8',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7614259552456271834&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 232: {'ID': 232,\n",
       "  'title': 'Video fields: fusing multiple surveillance videos into a dynamic virtual environment.',\n",
       "  'authors': ['S Bista', 'A Varshney', 'R Du'],\n",
       "  'journal': 'Web3D, 165-172',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=849865556467540234&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 233: {'ID': 233,\n",
       "  'title': 'Effects of Different Types of Virtual Reality Display on Presence and Learning in a Safety Training Scenario',\n",
       "  'authors': ['F Buttussi', 'L Chittaro'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (2), 1063-1076',\n",
       "  'citations': '96',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5175414232221269880&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 234: {'ID': 234,\n",
       "  'title': 'Synthesizing Obama: learning lip sync from audio',\n",
       "  'authors': ['SM Seitz', 'I Kemelmacher-Shlizerman', 'S Suwajanakorn'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-13',\n",
       "  'citations': '322',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17501792064365815213&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 235: {'ID': 235,\n",
       "  'title': 'TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data',\n",
       "  'authors': ['Y Zheng',\n",
       "   'H Zeng',\n",
       "   'B Ni',\n",
       "   'J Xu',\n",
       "   'LM Ni',\n",
       "   'H Qu',\n",
       "   'M Yuan',\n",
       "   'W Wu'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 935-944',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3066371909736052559&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 236: {'ID': 236,\n",
       "  'title': 'Barehanded music: real-time hand interaction for virtual piano.',\n",
       "  'authors': ['H Liang',\n",
       "   'YJ Liu',\n",
       "   'J Luo',\n",
       "   'Q Sun',\n",
       "   'Y He',\n",
       "   'J Yuan',\n",
       "   'J Wang'],\n",
       "  'journal': 'I3D, 87-94',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7092879724535588875&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 237: {'ID': 237,\n",
       "  'title': 'Extending FABRIK with model constraints',\n",
       "  'authors': ['Y Chrysanthou', 'J Lasenby', 'A Aristidou'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 27 (1), 35-57',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13425141635076911338&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 238: {'ID': 238,\n",
       "  'title': 'Frustum-traced raster shadows: revisiting irregular z-buffers.',\n",
       "  'authors': ['C Wyman', 'AE Lefohn', 'R Hoetzlein'],\n",
       "  'journal': 'I3D, 15-23',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15074061632300564054&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 239: {'ID': 239,\n",
       "  'title': 'Optimization Integrator for Large Time Steps',\n",
       "  'authors': ['A Stomakhin', 'JM Teran', 'TF Gast', 'C Schroeder', 'C Jiang'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (10), 1103-1115',\n",
       "  'citations': '76',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7400269595641020451&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 240: {'ID': 240,\n",
       "  'title': 'SpaceTime: adaptive control of the teleported avatar for improved AR tele‐conference experience',\n",
       "  'authors': ['GJ Kim', 'KH Kim', 'D Jo'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (3-4), 259-269',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16544690064843741808&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 241: {'ID': 241,\n",
       "  'title': 'DTW-based kernel and rank-level fusion for 3D gait recognition using Kinect',\n",
       "  'authors': ['ML Gavrilova', 'F Ahmed', 'PP Paul'],\n",
       "  'journal': 'The Visual Computer 31 (6-8), 915-924',\n",
       "  'citations': '65',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2262730368040567325&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 242: {'ID': 242,\n",
       "  'title': 'Wavelet-based visualization of time-varying data on graphs',\n",
       "  'authors': ['F Petronetto', 'CT Silva', 'LG Nonato', 'F Dias', 'P Valdivia'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 1-8',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=675988547466888286&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 243: {'ID': 243,\n",
       "  'title': 'Area-preserving mesh parameterization for poly-annulus surfaces based on optimal mass transportation',\n",
       "  'authors': ['L Cui',\n",
       "   'K Qian',\n",
       "   'M Zhang',\n",
       "   'K Su',\n",
       "   'J Zhang',\n",
       "   'N Lei',\n",
       "   'XD Gu'],\n",
       "  'journal': 'Computer Aided Geometric Design 46, 76-91',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=222734331765756460&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 244: {'ID': 244,\n",
       "  'title': 'VTK-m: Accelerating the Visualization Toolkit for Massively Threaded Architectures',\n",
       "  'authors': ['J Meredith',\n",
       "   'W Usher',\n",
       "   'K Moreland',\n",
       "   'L Lo',\n",
       "   '...',\n",
       "   'C Sewell',\n",
       "   'J Kress',\n",
       "   'D Pugmire'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 36 (3), 48-58',\n",
       "  'citations': '77',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11804359071117289632&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 245: {'ID': 245,\n",
       "  'title': 'An adaptive edge-preserving image denoising technique using tetrolet transforms',\n",
       "  'authors': ['P Jain', 'V Tyagi'],\n",
       "  'journal': 'The Visual Computer 31 (5), 657-674',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16386112856283509429&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 246: {'ID': 246,\n",
       "  'title': 'Quantitative evaluation strategies for urban 3D model generation from remote sensing data',\n",
       "  'authors': ['DF Laefer', 'L Truong-Hong'],\n",
       "  'journal': 'Computers & Graphics 49, 82-91',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1538830107384310608&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 247: {'ID': 247,\n",
       "  'title': 'Iris recognition based on a novel variation of local binary pattern',\n",
       "  'authors': ['W Zhou', 'S Yuan', 'C Li'],\n",
       "  'journal': 'The Visual Computer 31 (10), 1419-1429',\n",
       "  'citations': '37',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6223040408752888061&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 248: {'ID': 248,\n",
       "  'title': 'Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization',\n",
       "  'authors': ['J Heer', 'J Hoffswell', 'A Satyanarayan', 'R Russell'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 659-668',\n",
       "  'citations': '112',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9138710501584434950&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 249: {'ID': 249,\n",
       "  'title': 'CANVAS: computer-assisted narrative animation synthesis',\n",
       "  'authors': ['M Gross', 'A Shoulson', 'M Kapadia', 'RW Sumner', 'S Frey'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6037732275318388624&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 250: {'ID': 250,\n",
       "  'title': 'CheekInput: turning your cheek into an input surface by embedded optical sensors on a head-mounted display',\n",
       "  'authors': ['K Masai',\n",
       "   'Y Sugiura',\n",
       "   'K Yamashita',\n",
       "   'T Kikuchi',\n",
       "   'M Sugimoto',\n",
       "   'BH Thomas'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=224998916586352570&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 251: {'ID': 251,\n",
       "  'title': 'TrajRank: Exploring travel behaviour on a route by trajectory ranking',\n",
       "  'authors': ['M Lu', 'Z Wang', 'X Yuan'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 311-318',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8045308807365787664&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 252: {'ID': 252,\n",
       "  'title': 'A Descriptive Framework for Temporal Data Visualizations Based on Generalized Space‐Time Cubes',\n",
       "  'authors': ['C Hurter',\n",
       "   'P Dragicevic',\n",
       "   'S Carpendale',\n",
       "   'B Bach',\n",
       "   'D Archambault'],\n",
       "  'journal': 'Computer Graphics Forum 36 (6), 36-61',\n",
       "  'citations': '81',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5873639096246499585&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 253: {'ID': 253,\n",
       "  'title': 'TickTockRay: smartwatch-based 3D pointing for smartphone-based virtual reality.',\n",
       "  'authors': ['L Tahai', 'B Woodard', 'K Pietroszek', 'D Kharlamov'],\n",
       "  'journal': 'VRST, 363-364',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12545361655403535471&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 254: {'ID': 254,\n",
       "  'title': 'A Study of Layout, Rendering, and Interaction Methods for Immersive Graph Visualization',\n",
       "  'authors': ['K Lee', 'OH Kwon', 'C Muelder', 'KL Ma'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (7), 1802-1815',\n",
       "  'citations': '96',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1887510134094422725&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 255: {'ID': 255,\n",
       "  'title': 'Velocity-based modeling of physical interactions in dense crowds',\n",
       "  'authors': ['SJ Guy',\n",
       "   'K Hillesland',\n",
       "   'AAA Gutub',\n",
       "   'B Zafar',\n",
       "   'S Kim',\n",
       "   'D Manocha'],\n",
       "  'journal': 'The Visual Computer 31 (5), 541-555',\n",
       "  'citations': '35',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14502025548359460503&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 256: {'ID': 256,\n",
       "  'title': 'VizAssist: an interactive user assistant for visual data mining',\n",
       "  'authors': ['F Bouali', 'A Guettala', 'G Venturini'],\n",
       "  'journal': 'The Visual Computer 32 (11), 1447-1463',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18138400715406009847&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 257: {'ID': 257,\n",
       "  'title': 'Analysis-suitable G1 multi-patch parametrizations for C1 isogeometric spaces',\n",
       "  'authors': ['G Sangalli', 'A Collin', 'T Takacs'],\n",
       "  'journal': 'Computer Aided Geometric Design 47, 93-113',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6701979876504332950&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 258: {'ID': 258,\n",
       "  'title': 'Planning approaches to constraint‐aware navigation in dynamic environments',\n",
       "  'authors': ['A Shoulson', 'N Badler', 'F Garcia', 'K Ninomiya', 'M Kapadia'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 26 (2), 119-139',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10424424418904818810&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 259: {'ID': 259,\n",
       "  'title': 'Ensemble of PANORAMA-based convolutional neural networks for 3D model classification and retrieval',\n",
       "  'authors': ['K Sfikas', 'T Theoharis', 'I Pratikakis'],\n",
       "  'journal': 'Computers & Graphics 71, 208-218',\n",
       "  'citations': '53',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10068532651760026035&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 260: {'ID': 260,\n",
       "  'title': 'SoftAR: Visually Manipulating Haptic Softness Perception in Spatial Augmented Reality',\n",
       "  'authors': ['K Sato', 'P Punpongsanon', 'D Iwai'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (11), 1279-1288',\n",
       "  'citations': '74',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4651984004788813985&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 261: {'ID': 261,\n",
       "  'title': 'Interaction with virtual crowd in Immersive and semi‐Immersive Virtual Reality systems',\n",
       "  'authors': ['M Kyriakou', 'X Pan', 'Y Chrysanthou'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 28 (5), e1729',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13694748530769411740&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 262: {'ID': 262,\n",
       "  'title': 'Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions',\n",
       "  'authors': ['A Thom', 'B Müller', 'M Dörk', 'J Stahnke'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 629-638',\n",
       "  'citations': '71',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16781582703713317941&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 263: {'ID': 263,\n",
       "  'title': 'FeatureInsight: Visual support for error-driven feature ideation in text classification',\n",
       "  'authors': ['B Lee',\n",
       "   'SM Drucker',\n",
       "   'S Amershi',\n",
       "   'P Simard',\n",
       "   'M Brooks',\n",
       "   'A Kapoor'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 105-112',\n",
       "  'citations': '58',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5258365575061531032&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 264: {'ID': 264,\n",
       "  'title': \"Visual Computing Challenges of Advanced Manufacturing and Industrie 4.0 [Guest editors' introduction]\",\n",
       "  'authors': ['A Stork'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (2), 21-25',\n",
       "  'citations': '30',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6919942663346983134&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 265: {'ID': 265,\n",
       "  'title': 'A VR-Based Serious Game for Studying Emotional Regulation in Adolescents',\n",
       "  'authors': ['M Alcañiz',\n",
       "   'MD Vara',\n",
       "   'M Wrzesien',\n",
       "   'B Rey',\n",
       "   'RM Baños',\n",
       "   '...',\n",
       "   'A Rodríguez'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (1), 65-73',\n",
       "  'citations': '30',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8391035401259118202&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 266: {'ID': 266,\n",
       "  'title': 'A survey on algorithms of hole filling in 3D surface reconstruction',\n",
       "  'authors': ['X Guo', 'J Xiao', 'Y Wang'],\n",
       "  'journal': 'The Visual Computer 34 (1), 93-103',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2119848911919784141&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 267: {'ID': 267,\n",
       "  'title': 'Efficient simulation of knitted cloth using persistent contacts',\n",
       "  'authors': ['J Lopez-Moreno', 'G Cirio', 'MA Otaduy'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=434119788218232199&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 268: {'ID': 268,\n",
       "  'title': 'Viewpoint Snapping to Reduce Cybersickness in Virtual Reality',\n",
       "  'authors': ['Y Farmani', 'RJ Teather'],\n",
       "  'journal': 'Proceedings of the 44th Graphics Interface Conference, 168-175',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4248282898083816504&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 269: {'ID': 269,\n",
       "  'title': 'A scalable active framework for region annotation in 3D shape collections',\n",
       "  'authors': ['A Sheffer',\n",
       "   'D Ceylan',\n",
       "   'Q Huang',\n",
       "   'M Yan',\n",
       "   'L Yi',\n",
       "   'IC Shen',\n",
       "   '...',\n",
       "   'C Lu',\n",
       "   'H Su',\n",
       "   'VG Kim'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-12',\n",
       "  'citations': '247',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5127412563215364349&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 270: {'ID': 270,\n",
       "  'title': 'JackIn head: immersive visual telepresence system with omnidirectional wearable camera for remote collaboration',\n",
       "  'authors': ['S Kasahara', 'J Rekimoto'],\n",
       "  'journal': 'Proceedings of the 21st ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '49',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9612161689187337537&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 271: {'ID': 271,\n",
       "  'title': 'Visual Analysis and Dissemination of Scientific Literature Collections with SurVis',\n",
       "  'authors': ['D Weiskopf', 'S Koch', 'F Beck'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 180-189',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17979191300271629847&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 272: {'ID': 272,\n",
       "  'title': 'Saliency‐Preserving Slicing Optimization for Effective 3D Printing',\n",
       "  'authors': ['J Tong',\n",
       "   'H Chao',\n",
       "   'Z Yang',\n",
       "   'X Tong',\n",
       "   'H Li',\n",
       "   'W Wang',\n",
       "   'L Liu',\n",
       "   'X Liu'],\n",
       "  'journal': 'Computer Graphics Forum 34 (6), 148-160',\n",
       "  'citations': '62',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1478278566218691629&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 273: {'ID': 273,\n",
       "  'title': 'ADMM⊇ projective dynamics: fast simulation of general constitutive models',\n",
       "  'authors': ['R Narain', 'GE Brown', 'M Overby'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '59',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11950333002357046625&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 274: {'ID': 274,\n",
       "  'title': 'Learning class‐specific descriptors for deformable shapes using localized spectral convolutional networks',\n",
       "  'authors': ['J Masci',\n",
       "   '...',\n",
       "   'D Boscaini',\n",
       "   'MM Bronstein',\n",
       "   'S Melzi',\n",
       "   'U Castellani'],\n",
       "  'journal': 'Computer Graphics Forum 34 (5), 13-23',\n",
       "  'citations': '154',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1162025889799820066&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 275: {'ID': 275,\n",
       "  'title': 'Pose Estimation for Augmented Reality: A Hands-On Survey',\n",
       "  'authors': ['E Marchand', 'H Uchiyama', 'F Spindler'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (12), 2633-2651',\n",
       "  'citations': '227',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8275865769344597953&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 276: {'ID': 276,\n",
       "  'title': 'Deep high dynamic range imaging of dynamic scenes',\n",
       "  'authors': ['R Ramamoorthi', 'NK Kalantari'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-12',\n",
       "  'citations': '93',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7650600112356974959&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 277: {'ID': 277,\n",
       "  'title': 'Sequential Monte Carlo instant radiosity.',\n",
       "  'authors': ['J Lehtinen', 'P Hedman', 'T Karras'],\n",
       "  'journal': 'I3D, 121-128',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6903147796997540424&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 278: {'ID': 278,\n",
       "  'title': 'The sketchy database: learning to retrieve badly drawn bunnies',\n",
       "  'authors': ['N Burnell', 'J Hays', 'P Sangkloy', 'C Ham'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-12',\n",
       "  'citations': '231',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16608199986239511494&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 279: {'ID': 279,\n",
       "  'title': 'Path patterns: analyzing and comparing real and simulated crowds.',\n",
       "  'authors': [\"C O'Sullivan\", 'H Wang', 'J Ondrej'],\n",
       "  'journal': 'I3D, 49-57',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=83669706100853471&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 280: {'ID': 280,\n",
       "  'title': 'Bridging the Gap of Domain and Visualization Experts with a Liaison.',\n",
       "  'authors': ['DA Keim', 'S Simon', 'S Mittelstädt', 'M Sedlmair'],\n",
       "  'journal': 'EuroVis (Short Papers), 127-131',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3137354175043404723&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 281: {'ID': 281,\n",
       "  'title': 'BRDF Representation and Acquisition',\n",
       "  'authors': ['GC Guarnera', 'A Ghosh', 'M Glencross', 'C Denk', 'D Guarnera'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 625-650',\n",
       "  'citations': '73',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4784777786709551450&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 282: {'ID': 282,\n",
       "  'title': 'A computational approach for obstruction-free photography',\n",
       "  'authors': ['WT Freeman', 'M Rubinstein', 'T Xue', 'C Liu'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-11',\n",
       "  'citations': '137',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16509258172690213252&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 283: {'ID': 283,\n",
       "  'title': 'Motion recognition of self and others on realistic 3D avatars',\n",
       "  'authors': ['A Shapiro',\n",
       "   'A Best',\n",
       "   'S Narang',\n",
       "   'D Manocha',\n",
       "   'A Feng',\n",
       "   'S Kang'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 28 (3-4), e1762',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6693653172710923717&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 284: {'ID': 284,\n",
       "  'title': 'Lightweighting for Web3D visualization of large-scale BIM scenes in real-time',\n",
       "  'authors': ['N Xie', 'J Jia', 'K Tang', 'X Liu'],\n",
       "  'journal': 'Graphical Models 88, 40-56',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=418865305058250168&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 285: {'ID': 285,\n",
       "  'title': 'Continuous body emotion recognition system during theater performances',\n",
       "  'authors': ['N Magnenat‐Thalmann', 'S Senecal', 'L Cuel', 'A Aristidou'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 27 (3-4), 311-320',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4939069867275960823&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 286: {'ID': 286,\n",
       "  'title': 'Upright orientation of 3D shapes with Convolutional Networks',\n",
       "  'authors': ['Z Liu', 'L Liu', 'J Zhang'],\n",
       "  'journal': 'Graphical Models 85, 22-29',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14089637690282896270&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 287: {'ID': 287,\n",
       "  'title': 'Functional thin films on surfaces',\n",
       "  'authors': ['O Vantzos',\n",
       "   'O Azencot',\n",
       "   'M Wardetzky',\n",
       "   'M Ben-Chen',\n",
       "   'M Rumpf'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18382265682611890248&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 288: {'ID': 288,\n",
       "  'title': 'More Than Telling a Story: Transforming Data into Visually Shared Stories',\n",
       "  'authors': ['B Lee', 'P Isenberg', 'S Carpendale', 'NH Riche'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (5), 84-90',\n",
       "  'citations': '121',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9629336685416548691&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 289: {'ID': 289,\n",
       "  'title': 'Unsupervised 3D shape segmentation and co-segmentation via deep learning',\n",
       "  'authors': ['C Qi', 'Z Shu', 'Y Zhang', 'S Xin', 'L Wang', 'C Hu', 'L Liu'],\n",
       "  'journal': 'Computer Aided Geometric Design 43, 39-52',\n",
       "  'citations': '57',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7869351863611195866&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 290: {'ID': 290,\n",
       "  'title': 'Social Media Visual Analytics',\n",
       "  'authors': ['L Lin', 'X Yuan', 'S Chen'],\n",
       "  'journal': 'Computer Graphics Forum 36 (3), 563-587',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15750714363188294097&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 291: {'ID': 291,\n",
       "  'title': 'Combining analytic direct illumination and stochastic shadows.',\n",
       "  'authors': ['M McGuire', 'E Heitz', 'S Hill'],\n",
       "  'journal': 'I3D, 2:1-2:11',\n",
       "  'citations': '17',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12993224793734740114&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 292: {'ID': 292,\n",
       "  'title': 'TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data',\n",
       "  'authors': ['Y Zhao', 'X Ye', 'C Ma', 'X Huang', 'J Yang', 'C Zhang'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 160-169',\n",
       "  'citations': '110',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9379564293188785700&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 293: {'ID': 293,\n",
       "  'title': 'Task Taxonomy for Cartograms.',\n",
       "  'authors': ['S Nusrat', 'SG Kobourov'],\n",
       "  'journal': 'EuroVis (Short Papers), 61-65',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13871448102221664652&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 294: {'ID': 294,\n",
       "  'title': 'Planar domain parameterization with THB-splines',\n",
       "  'authors': ['B Jüttler', 'A Falini', 'J Špeh'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 95-108',\n",
       "  'citations': '40',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8225947736923588883&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 295: {'ID': 295,\n",
       "  'title': 'Saliency in VR: How Do People Explore Virtual Environments?',\n",
       "  'authors': ['A Serrano',\n",
       "   'M Agrawala',\n",
       "   'D Gutierrez',\n",
       "   'V Sitzmann',\n",
       "   '...',\n",
       "   'A Pavel',\n",
       "   'B Masia'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (4), 1633-1642',\n",
       "  'citations': '120',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8166629312966918479&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 296: {'ID': 296,\n",
       "  'title': 'Vega-Lite: A Grammar of Interactive Graphics',\n",
       "  'authors': ['D Moritz', 'A Satyanarayan', 'K Wongsuphasawat', 'J Heer'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 341-350',\n",
       "  'citations': '233',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6294246928492755802&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 297: {'ID': 297,\n",
       "  'title': 'Elastic moduli of simple mass spring models',\n",
       "  'authors': ['H Nagahashi', 'P Szymczak', 'M Kot'],\n",
       "  'journal': 'The Visual Computer 31 (10), 1339-1350',\n",
       "  'citations': '40',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1646858044859827545&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 298: {'ID': 298,\n",
       "  'title': 'Optimized recognition with few instances based on semantic distance',\n",
       "  'authors': ['Y Wang', 'Z Miao', 'H Wu', 'M Lin'],\n",
       "  'journal': 'The Visual Computer 31 (4), 367-375',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14039398378239825510&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 299: {'ID': 299,\n",
       "  'title': 'RealFusion: An Interactive Workflow for Repurposing Real-World Objects towards Early-stage Creative Ideation',\n",
       "  'authors': ['Y Zhang', 'V Vinayak', 'K Ramani', 'C Piya'],\n",
       "  'journal': 'Proceedings of the 42nd Graphics Interface Conference, 85-92',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1049872830804635083&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 300: {'ID': 300,\n",
       "  'title': 'Laban descriptors for gesture recognition and emotional analysis',\n",
       "  'authors': ['A Truong', 'T Zaharia', 'H Boujut'],\n",
       "  'journal': 'The Visual Computer 32 (1), 83-98',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11677760054648086407&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 301: {'ID': 301,\n",
       "  'title': 'Holographic near-eye displays for virtual and augmented reality',\n",
       "  'authors': ['A Maimone', 'JS Kollin', 'A Georgiou'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-16',\n",
       "  'citations': '236',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1882027524307278570&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 302: {'ID': 302,\n",
       "  'title': 'A deep learning framework for character motion synthesis and editing',\n",
       "  'authors': ['J Saito', 'T Komura', 'D Holden'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-11',\n",
       "  'citations': '222',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12551269696770115548&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 303: {'ID': 303,\n",
       "  'title': 'Arcs, Angles, or Areas: Individual Data Encodings in Pie and Donut Charts',\n",
       "  'authors': ['D Skau', 'R Kosara'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 121-130',\n",
       "  'citations': '56',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11475862794415010767&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 304: {'ID': 304,\n",
       "  'title': 'Modeling 3D animals from a side-view sketch',\n",
       "  'authors': ['M van de Panne', 'E Entem', 'L Barthe', 'MP Cani', 'F Cordier'],\n",
       "  'journal': 'Computers & Graphics 46, 221-230',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6022803966195086401&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 305: {'ID': 305,\n",
       "  'title': 'Coupling 3D eulerian, heightfield and particle methods for interactive simulation of large scale liquid phenomena',\n",
       "  'authors': ['M Müller', 'TY Kim', 'N Chentanez'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1661248985434529830&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 306: {'ID': 306,\n",
       "  'title': 'Recent Advances in Adaptive Sampling and Reconstruction for Monte Carlo Rendering',\n",
       "  'authors': ['M Zwicker',\n",
       "   'R Ramamoorthi',\n",
       "   '...',\n",
       "   'B Moon',\n",
       "   'W Jarosz',\n",
       "   'F Rousselle',\n",
       "   'J Lehtinen'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 667-681',\n",
       "  'citations': '89',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11565144111768031250&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 307: {'ID': 307,\n",
       "  'title': 'DenseCut: Densely Connected CRFs for Realtime GrabCut',\n",
       "  'authors': ['PHS Torr', 'MM Cheng', 'C Rother', 'VA Prisacariu', 'S Zheng'],\n",
       "  'journal': 'Computer Graphics Forum 34 (7), 193-201',\n",
       "  'citations': '60',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6143593884224678616&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 308: {'ID': 308,\n",
       "  'title': 'Visual analysis of bike-sharing systems',\n",
       "  'authors': ['CT Silva',\n",
       "   'JLD Comba',\n",
       "   'RP Torchelsen',\n",
       "   'JL Sotomayor',\n",
       "   'GN Oliveira'],\n",
       "  'journal': 'Computers & Graphics 60, 119-129',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17955021272781709505&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 309: {'ID': 309,\n",
       "  'title': 'MultiFab: a machine vision assisted platform for multi-material 3D printing',\n",
       "  'authors': ['P Sitthi-Amorn',\n",
       "   'W Matusik',\n",
       "   'J Lan',\n",
       "   'J Kwan',\n",
       "   'JE Ramos',\n",
       "   'W Wang',\n",
       "   'Y Wangy'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-11',\n",
       "  'citations': '150',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4279926628237989274&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 310: {'ID': 310,\n",
       "  'title': 'Embodied hands: modeling and capturing hands and bodies together',\n",
       "  'authors': ['MJ Black', 'J Romero', 'D Tzionas'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (6), 1-17',\n",
       "  'citations': '115',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9567138932042633150&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 311: {'ID': 311,\n",
       "  'title': 'Supporting free walking in a large virtual environment: imperceptible redirected walking with an immersive distractor.',\n",
       "  'authors': ['H Fuchs', 'H Chen'],\n",
       "  'journal': 'CGI, 22:1-22:6',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14740120980939619438&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 312: {'ID': 312,\n",
       "  'title': 'Reducing Visual Discomfort with HMDs Using Dynamic Depth of Field',\n",
       "  'authors': ['T Rhee', 'K Carnegie'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (5), 34-41',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12449382262527176599&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 313: {'ID': 313,\n",
       "  'title': 'A deep learning approach for generalized speech animation',\n",
       "  'authors': ['T Kim',\n",
       "   'Y Yue',\n",
       "   'J Krahe',\n",
       "   'J Hodgins',\n",
       "   '...',\n",
       "   'M Mahler',\n",
       "   'S Taylor',\n",
       "   'AG Rodriguez'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-11',\n",
       "  'citations': '100',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5298154376317286675&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 314: {'ID': 314,\n",
       "  'title': '3D skeleton‐based action recognition by representing motion capture sequences as 2D‐RGB images',\n",
       "  'authors': ['M Brahimi', 'T Dutoit', 'S Laraba', 'J Tilmanne'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 28 (3-4), e1782',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12082803051080603356&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 315: {'ID': 315,\n",
       "  'title': 'Triangular mesh simplification on the GPU',\n",
       "  'authors': ['A Papageorgiou', 'N Platis'],\n",
       "  'journal': 'The Visual Computer 31 (2), 235-244',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1436999025542805612&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 316: {'ID': 316,\n",
       "  'title': 'Visualizing High-Dimensional Data: Advances in the Past Decade',\n",
       "  'authors': ['PT Bremer', 'V Pascucci', 'D Maljovec', 'S Liu', 'B Wang'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (3), 1249-1268',\n",
       "  'citations': '207',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11530938751889928260&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 317: {'ID': 317,\n",
       "  'title': 'DimScanner: A relation-based visual exploration approach towards data dimension inspection',\n",
       "  'authors': ['W Hu', 'J Xia', 'X Huang', 'Y Hou', 'W Chen', 'DS Ebertk'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 81-90',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6386507252417890698&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 318: {'ID': 318,\n",
       "  'title': 'Resolving the Vergence-Accommodation Conflict in Head-Mounted Displays',\n",
       "  'authors': ['G Kramida'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (7), 1912-1931',\n",
       "  'citations': '166',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7720620668154034228&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 319: {'ID': 319,\n",
       "  'title': 'Kernel-predicting convolutional networks for denoising Monte Carlo renderings',\n",
       "  'authors': ['M Meyer',\n",
       "   'S Bako',\n",
       "   'T Vogels',\n",
       "   'A Harvill',\n",
       "   '...',\n",
       "   'J NováK',\n",
       "   'B Mcwilliams',\n",
       "   'P Sen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-14',\n",
       "  'citations': '101',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6120746394008367130&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 320: {'ID': 320,\n",
       "  'title': 'Beyond Memorability: Visualization Recognition and Recall',\n",
       "  'authors': ['NW Kim',\n",
       "   'Z Bylinskii',\n",
       "   'CS Yeh',\n",
       "   'D Borkin',\n",
       "   '...',\n",
       "   'MA Borkin',\n",
       "   'CM Bainbridge'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 519-528',\n",
       "  'citations': '133',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13495490681226155738&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 321: {'ID': 321,\n",
       "  'title': 'State of the Art in Transfer Functions for Direct Volume Rendering',\n",
       "  'authors': ['P Ljung',\n",
       "   'M Hadwiger',\n",
       "   'E Groller',\n",
       "   'CD Hansen',\n",
       "   'J Krüger',\n",
       "   'A Ynnerman'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 669-691',\n",
       "  'citations': '66',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10875673596266638856&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 322: {'ID': 322,\n",
       "  'title': 'Improved Surface Quality in 3D Printing by Optimizing the Printing Direction',\n",
       "  'authors': ['L Kobbelt', 'WM Wang', 'C Zanni'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 59-70',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8630396798125493866&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 323: {'ID': 323,\n",
       "  'title': 'Analysis and synthesis of 3D shape families via deep‐learned generative models of surfaces',\n",
       "  'authors': ['B Marlin', 'E Kalogerakis', 'H Huang'],\n",
       "  'journal': 'Computer Graphics Forum 34 (5), 25-38',\n",
       "  'citations': '62',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10124851464835467351&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 324: {'ID': 324,\n",
       "  'title': 'Montage4D: interactive seamless fusion of multiview video textures.',\n",
       "  'authors': ['A Varshney', 'R Du', 'W Chang', 'M Chuang', 'H Hoppe'],\n",
       "  'journal': 'I3D, 5:1-5:11',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3460734869926826514&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 325: {'ID': 325,\n",
       "  'title': 'Multiresolution and fast decompression for optimal web-based rendering',\n",
       "  'authors': ['F Ponchio', 'M Dellepiane'],\n",
       "  'journal': 'Graphical Models 88, 1-11',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9559323444400764128&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 326: {'ID': 326,\n",
       "  'title': 'Toward real-time 3D object recognition: A lightweight volumetric CNN framework using multitask learning',\n",
       "  'authors': ['X Li', 'Y Guo', 'S Zhi', 'Y Liu'],\n",
       "  'journal': 'Computers & Graphics 71, 199-207',\n",
       "  'citations': '39',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1014259377112489583&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 327: {'ID': 327,\n",
       "  'title': 'Tanks and temples: benchmarking large-scale scene reconstruction',\n",
       "  'authors': ['V Koltun', 'J Park', 'A Knapitsch', 'QY Zhou'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-13',\n",
       "  'citations': '145',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4996933639673643068&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 328: {'ID': 328,\n",
       "  'title': 'Dynamic 3D avatar creation from hand-held video input',\n",
       "  'authors': ['AE Ichim', 'S Bouaziz', 'M Pauly'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-14',\n",
       "  'citations': '128',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12277768444191413567&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 329: {'ID': 329,\n",
       "  'title': 'Double Conformal Geometric Algebra for Quadrics and Darboux Cyclides.',\n",
       "  'authors': ['E Hitzer', 'RB Easter'],\n",
       "  'journal': 'CGI (Short Papers), 93-96',\n",
       "  'citations': '10',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2176824098026326600&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 330: {'ID': 330,\n",
       "  'title': 'Instant field-aligned meshes',\n",
       "  'authors': ['D Panozzo', 'W Jakob', 'M Tarini', 'O Sorkine-Hornung'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-15',\n",
       "  'citations': '119',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8028350078420913471&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 331: {'ID': 331,\n",
       "  'title': 'Joint learning of image detail and transmission map for single image dehazing',\n",
       "  'authors': ['W Ren', 'S Zhang', 'J Yao', 'F He'],\n",
       "  'journal': 'The Visual Computer, 1-12',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6536545932238613421&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 332: {'ID': 332,\n",
       "  'title': 'The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?',\n",
       "  'authors': ['M Cordeil', 'J Beyer', 'H Pfister', 'B Bach', 'R Sicat'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 457-467',\n",
       "  'citations': '98',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11826275988058500921&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 333: {'ID': 333,\n",
       "  'title': 'Self Tuning Texture Optimization',\n",
       "  'authors': ['B Neubert', 'D Lischinski', 'A Kaspar', 'M Pauly', 'J Kopf'],\n",
       "  'journal': 'Computer Graphics Forum 34 (2), 349-359',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12150567648605881912&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 334: {'ID': 334,\n",
       "  'title': 'Real-time facial animation with image-based dynamic avatars',\n",
       "  'authors': ['T Shao', 'C Cao', 'Y Weng', 'K Zhou', 'H Wu'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-12',\n",
       "  'citations': '92',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7152509457634685486&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 335: {'ID': 335,\n",
       "  'title': 'Convolutional neural networks on surfaces via seamless toric covers',\n",
       "  'authors': ['E Yumer',\n",
       "   'N Dym',\n",
       "   'M Galun',\n",
       "   'M Trope',\n",
       "   '...',\n",
       "   'N Aigerman',\n",
       "   'H Maron',\n",
       "   'VG Kim'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-10',\n",
       "  'citations': '90',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3755553669350101173&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 336: {'ID': 336,\n",
       "  'title': 'High-quality streamable free-viewpoint video',\n",
       "  'authors': ['D Gillett',\n",
       "   'D Evseev',\n",
       "   'D Calabrese',\n",
       "   'P Sweeney',\n",
       "   '...',\n",
       "   'M Chuang',\n",
       "   'A Collet'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-13',\n",
       "  'citations': '208',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10457080513122513408&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 337: {'ID': 337,\n",
       "  'title': 'Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data',\n",
       "  'authors': ['Z Wang',\n",
       "   'X Zhang',\n",
       "   'X Yuan',\n",
       "   'S Chen',\n",
       "   'J Liang',\n",
       "   'J Zhang',\n",
       "   'C Guo'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 270-279',\n",
       "  'citations': '97',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6835068405696930850&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 338: {'ID': 338,\n",
       "  'title': 'Palette-based photo recoloring',\n",
       "  'authors': ['O Fried', 'A Finkelstein', 'Y Liu', 'H Chang', 'S DiVerdi'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-11',\n",
       "  'citations': '113',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12399644416665555051&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 339: {'ID': 339,\n",
       "  'title': 'Learning a model of facial shape and expression from 4D scans',\n",
       "  'authors': ['MJ Black', 'J Romero', 'H Li', 'T Li', 'T Bolkart'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (6), 1-17',\n",
       "  'citations': '86',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12545908227329232832&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 340: {'ID': 340,\n",
       "  'title': 'The Emerging Genre of Data Comics',\n",
       "  'authors': ['H Pfister', 'S Carpendale', 'NH Riche', 'B Bach'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 37 (3), 6-13',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=854412064874323895&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 341: {'ID': 341,\n",
       "  'title': 'Spherical layout and rendering methods for immersive graph visualization',\n",
       "  'authors': ['K Lee', 'OH Kwon', 'C Muelder', 'KL Ma'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 63-67',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4785446481993860310&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 342: {'ID': 342,\n",
       "  'title': 'SMPL: a skinned multi-person linear model',\n",
       "  'authors': ['MJ Black', 'J Romero', 'G Pons-Moll', 'N Mahmood', 'M Loper'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-16',\n",
       "  'citations': '620',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2337848845105698621&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 343: {'ID': 343,\n",
       "  'title': 'SentiCompass: Interactive visualization for exploring and comparing the sentiments of time-varying twitter data',\n",
       "  'authors': ['M Roche', 'A Sallaberry', 'K Klein', 'FY Wang', 'M Takatsuka'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 129-133',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6432234664108773267&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 344: {'ID': 344,\n",
       "  'title': 'Guidance in the human–machine analytics process',\n",
       "  'authors': ['A Jena',\n",
       "   'J Yang',\n",
       "   'C Collins',\n",
       "   'N Andrienko',\n",
       "   'J Choo',\n",
       "   'T Schreck',\n",
       "   '...',\n",
       "   'U Engelke'],\n",
       "  'journal': 'Visual Informatics 2 (3), 166-180',\n",
       "  'citations': '18',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16027121836903537399&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 345: {'ID': 345,\n",
       "  'title': 'LOD Generation for Urban Scenes',\n",
       "  'authors': ['F Lafarge', 'P Alliez', 'Y Verdie'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (3), 1-14',\n",
       "  'citations': '96',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14089842847128207874&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 346: {'ID': 346,\n",
       "  'title': 'Evaluating and Optimizing Evacuation Plans for Crowd Egress',\n",
       "  'authors': ['P Faloutsos',\n",
       "   'M Usman',\n",
       "   'VJ Cassol',\n",
       "   '...',\n",
       "   'G Berseth',\n",
       "   'ES Testa',\n",
       "   'CR Jung'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 37 (4), 60-71',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17701295307992217713&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 347: {'ID': 347,\n",
       "  'title': 'Single image dehazing via an improved atmospheric scattering model',\n",
       "  'authors': ['X Wang', 'D Zhang', 'M Ju'],\n",
       "  'journal': 'The Visual Computer 33 (12), 1613-1625',\n",
       "  'citations': '39',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10651344577613787256&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 348: {'ID': 348,\n",
       "  'title': 'Semantic Interaction: Coupling Cognition and Computation through Usable Interactive Analytics',\n",
       "  'authors': ['C North', 'A Endert', 'M Zhou', 'R Chang'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (4), 94-99',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17284595232050334212&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 349: {'ID': 349,\n",
       "  'title': 'The affine particle-in-cell method',\n",
       "  'authors': ['A Selle', 'A Stomakhin', 'J Teran', 'C Schroeder', 'C Jiang'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-10',\n",
       "  'citations': '147',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1369898904463161024&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 350: {'ID': 350,\n",
       "  'title': 'Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data',\n",
       "  'authors': ['C Shi',\n",
       "   'P Dragicevic',\n",
       "   'T Madhyastha',\n",
       "   'B Bach',\n",
       "   'N Heulot',\n",
       "   'T Grabowski'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 559-568',\n",
       "  'citations': '97',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16759911685577866373&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 351: {'ID': 351,\n",
       "  'title': 'VA 2: A Visual Analytics Approach for Evaluating Visual Analytics Applications',\n",
       "  'authors': ['T Ertl', 'M John', 'T Blascheck', 'K Kurzhals', 'S Koch'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 61-70',\n",
       "  'citations': '74',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8876399615514715816&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 352: {'ID': 352,\n",
       "  'title': \"The effects of virtual human's spatial and behavioral coherence with physical objects on social presence in AR\",\n",
       "  'authors': ['D Maloney', 'K Kim', 'G Bruder', 'GF Welch', 'JN Bailenson'],\n",
       "  'journal': 'Computer Animation and Virtual Worlds 28 (3-4), e1771',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15586108606341978363&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 353: {'ID': 353,\n",
       "  'title': 'Hashedcubes: Simple, Low Memory, Real-Time Visual Exploration of Big Data',\n",
       "  'authors': ['CAL Pahins', 'C Scheidegger', 'JLD Comba', 'SA Stephens'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 671-680',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1852281307733254387&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 354: {'ID': 354,\n",
       "  'title': 'Using a Virtual Maze Task to Assess Spatial Short-term Memory in Adults.',\n",
       "  'authors': ['S Cárdenas-Delgado', '...', 'MCJ Lizandra', 'M Méndez-López'],\n",
       "  'journal': 'VISIGRAPP (1: GRAPP), 46-57',\n",
       "  'citations': '8',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=848819755410598269&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 355: {'ID': 355,\n",
       "  'title': 'Fully automatic generation of anatomical face simulation models',\n",
       "  'authors': ['JL E', 'M Cong', 'R Fedkiw', 'KS Bhat', 'M Bao'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5841417284896289073&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 356: {'ID': 356,\n",
       "  'title': 'DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction',\n",
       "  'authors': ['K Veeramachaneni',\n",
       "   'S Boyer',\n",
       "   'Y Chen',\n",
       "   'M Zhao',\n",
       "   'H Qu',\n",
       "   'Q Chen'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 111-120',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6648347884737444221&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 357: {'ID': 357,\n",
       "  'title': 'State of the Art in Mobile Volume Rendering on iOS Devices.',\n",
       "  'authors': ['J Krüger', 'A Schiewe', 'M Anstoots'],\n",
       "  'journal': 'EuroVis (Short Papers), 139-143',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8730371214759106257&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 358: {'ID': 358,\n",
       "  'title': 'Interactive Rendering and Stylization of Transportation Networks using Distance Fields',\n",
       "  'authors': ['A Semmo', 'J Döllner', 'M Trapp'],\n",
       "  'journal': 'Proceedings of the 10th International Conference on Computer Graphics Theory\\xa0…',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2309384031213425053&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 359: {'ID': 359,\n",
       "  'title': 'ClothCap: seamless 4D clothing capture and retargeting',\n",
       "  'authors': ['MJ Black', 'S Hu', 'G Pons-Moll', 'S Pujades'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-15',\n",
       "  'citations': '123',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1587162403073867686&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 360: {'ID': 360,\n",
       "  'title': 'Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics',\n",
       "  'authors': ['A Endert', 'L Franklin', 'E Wall', 'LM Blaha'],\n",
       "  'journal': '2017 IEEE Conference on Visual Analytics Science and Technology (VAST), 104-115',\n",
       "  'citations': '45',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15497711287687630373&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 361: {'ID': 361,\n",
       "  'title': 'Two-shot SVBRDF capture for stationary materials',\n",
       "  'authors': ['M Aittala', 'T Weyrich', 'J Lehtinen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-13',\n",
       "  'citations': '89',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10112531025495966031&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 362: {'ID': 362,\n",
       "  'title': 'Two real-world case studies on 3D web applications for participatory urban planning.',\n",
       "  'authors': ['C Florea',\n",
       "   'T Hurskainen',\n",
       "   'T Alatalo',\n",
       "   'M Pouke',\n",
       "   'T Ojala',\n",
       "   'T Koskela'],\n",
       "  'journal': 'Web3D, 11:1-11:9',\n",
       "  'citations': '17',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5331429578794938817&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 363: {'ID': 363,\n",
       "  'title': 'Semantic shape editing using deformation handles',\n",
       "  'authors': ['JK Hodgins', 'S Chaudhuri', 'LB Kara', 'ME Yumer'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '107',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5755026306175607554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 364: {'ID': 364,\n",
       "  'title': 'In Situ Methods, Infrastructures, and Applications on High Performance Computing Platforms',\n",
       "  'authors': ['H Childs',\n",
       "   'J Ahrens',\n",
       "   'K Moreland',\n",
       "   'AC Bauer',\n",
       "   'S Klasky',\n",
       "   '...',\n",
       "   'H Abbasi',\n",
       "   'B Geveci'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 577-597',\n",
       "  'citations': '101',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2879340232052456554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 365: {'ID': 365,\n",
       "  'title': 'The Anchoring Effect in Decision-Making with Visual Analytics',\n",
       "  'authors': ['R Wesslen',\n",
       "   'I Cho',\n",
       "   'A Karduni',\n",
       "   'S Shaikh',\n",
       "   'W Dou',\n",
       "   'S Santhanam'],\n",
       "  'journal': '2017 IEEE Conference on Visual Analytics Science and Technology (VAST), 116-126',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14913235345019817367&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 366: {'ID': 366,\n",
       "  'title': 'Applying geometric constraints for perfecting CAD models in reverse engineering',\n",
       "  'authors': ['I Kovács', 'P Salvi', 'T Várady'],\n",
       "  'journal': 'Graphical Models 82, 44-57',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9396914052347578454&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 367: {'ID': 367,\n",
       "  'title': 'JumpCut: non-successive mask transfer and interpolation for video cutout',\n",
       "  'authors': ['Q Fan', 'F Zhong', 'D Lischinski', 'B Chen', 'D Cohen-Or'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-10',\n",
       "  'citations': '99',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7740321506188482181&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 368: {'ID': 368,\n",
       "  'title': 'Extended TimeWarp latency compensation for virtual reality.',\n",
       "  'authors': ['D Evangelakos', 'M Mara'],\n",
       "  'journal': 'I3D, 193-194',\n",
       "  'citations': '16',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11076087147493291972&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 369: {'ID': 369,\n",
       "  'title': 'Very High Frame Rate Volumetric Integration of Depth Images on Mobile Devices',\n",
       "  'authors': ['CY Ren',\n",
       "   'X Sun',\n",
       "   'D Murray',\n",
       "   'O Kähler',\n",
       "   'VA Prisacariu',\n",
       "   'P Torr'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (11), 1241-1250',\n",
       "  'citations': '203',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2983583513468574154&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 370: {'ID': 370,\n",
       "  'title': 'Personal Visualization and Personal Visual Analytics',\n",
       "  'authors': ['M Tory',\n",
       "   'L Bartram',\n",
       "   'S Bateman',\n",
       "   'S Carpendale',\n",
       "   '...',\n",
       "   'BA Aseniero',\n",
       "   'D Huang'],\n",
       "  'journal': 'IEEE Annals of the History of Computing, 420-433',\n",
       "  'citations': '193',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11749903023131327675&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 371: {'ID': 371,\n",
       "  'title': 'What is in a Rumour: Combined Visual Analysis of Rumour Flow and User Activity.',\n",
       "  'authors': ['EE Milios', 'R Minghim', 'A Dang', \"A Moh'd\"],\n",
       "  'journal': 'CGI (Short Papers), 17-20',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13165958982738862488&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 372: {'ID': 372,\n",
       "  'title': 'Blind inpainting using the fully convolutional neural network',\n",
       "  'authors': ['H Wang', 'BWK Ling', 'Z Yang', 'N Cai', 'Z Su', 'Z Lin'],\n",
       "  'journal': 'The Visual Computer 33 (2), 249-261',\n",
       "  'citations': '42',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6891681034560438550&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 373: {'ID': 373,\n",
       "  'title': 'Convolutional neural networks for crowd behaviour analysis: a survey',\n",
       "  'authors': ['DK Vishwakarma', 'K Singh', 'G Tripathi'],\n",
       "  'journal': 'The Visual Computer 35 (5), 753-776',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5323600679784212582&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 374: {'ID': 374,\n",
       "  'title': 'Comparison of gesture, gamepad, and gaze-based locomotion for VR worlds.',\n",
       "  'authors': ['JCS Cardoso'],\n",
       "  'journal': 'VRST, 319-320',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13681735175650785005&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 375: {'ID': 375,\n",
       "  'title': 'A material point method for viscoelastic fluids, foams and sponges',\n",
       "  'authors': ['T Gast',\n",
       "   'A Stomakhin',\n",
       "   'J Teran',\n",
       "   'D Ram',\n",
       "   'C Schroeder',\n",
       "   '...',\n",
       "   'C Jiang'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '58',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11786994698759214129&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 376: {'ID': 376,\n",
       "  'title': 'Effects of Field of View and Visual Complexity on Virtual Reality Training Effectiveness for a Visual Scanning Task',\n",
       "  'authors': ['S Scerbo',\n",
       "   'RP McMahan',\n",
       "   'ED Ragan',\n",
       "   'R Kopper',\n",
       "   'C Stinson',\n",
       "   'DA Bowman'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 21 (7), 794-807',\n",
       "  'citations': '93',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10192281412046397064&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 377: {'ID': 377,\n",
       "  'title': 'Visualizing the Evolution of Communities in Dynamic Graphs',\n",
       "  'authors': ['C Vehlow', 'D Weiskopf', 'P Auwärter', 'F Beck'],\n",
       "  'journal': 'Computer Graphics Forum 34 (1), 277-288',\n",
       "  'citations': '55',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5750894039135367430&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 378: {'ID': 378,\n",
       "  'title': 'A shape sampling technique via particle tracing for CAD models',\n",
       "  'authors': ['E Gunpinar', 'S Gunpinar'],\n",
       "  'journal': 'Graphical Models 96, 11-29',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7462302662223959976&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 379: {'ID': 379,\n",
       "  'title': 'ECharts: A declarative framework for rapid construction of web-based visualization',\n",
       "  'authors': ['H Mei',\n",
       "   'W Chen',\n",
       "   'D Li',\n",
       "   'M Zu',\n",
       "   'W Zhang',\n",
       "   'Y Shen',\n",
       "   'S Su',\n",
       "   'J Wang'],\n",
       "  'journal': 'Visual Informatics 2 (2), 136-146',\n",
       "  'citations': '52',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5395089907247180585&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 380: {'ID': 380,\n",
       "  'title': 'The light field stereoscope: immersive computer graphics via factored near-eye light field displays with focus cues',\n",
       "  'authors': ['FC Huang', 'K Chen', 'G Wetzstein'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '265',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8397688588567411597&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 381: {'ID': 381,\n",
       "  'title': 'Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles',\n",
       "  'authors': ['R Westermann', 'F Ferstl', 'K Bürger'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 767-776',\n",
       "  'citations': '77',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15351629890112791454&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 382: {'ID': 382,\n",
       "  'title': 'Hybrid-treemap layouting',\n",
       "  'authors': ['S Hahn', 'J Döllner'],\n",
       "  'journal': 'Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short\\xa0…',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1716294183648604344&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 383: {'ID': 383,\n",
       "  'title': 'Audio-driven facial animation by joint end-to-end learning of pose and emotion',\n",
       "  'authors': ['A Herva', 'T Aila', 'S Laine', 'T Karras', 'J Lehtinen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 36 (4), 1-12',\n",
       "  'citations': '106',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1628797799687817632&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 384: {'ID': 384,\n",
       "  'title': 'Low-order reconstruction operators on polyhedral meshes: application to compatible discrete operator schemes',\n",
       "  'authors': ['DA Di Pietro', 'A Ern', 'J Bonelle'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 27-41',\n",
       "  'citations': '25',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16923483002686533843&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 385: {'ID': 385,\n",
       "  'title': 'Objective Quality Assessment and Perceptual Compression of Screen Content Images',\n",
       "  'authors': ['Z Wang', 'W Lin', 'K Zeng', 'K Gu', 'S Wang'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 38 (1), 47-58',\n",
       "  'citations': '44',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17085516767460304874&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 386: {'ID': 386,\n",
       "  'title': 'Towards foveated rendering for gaze-tracked virtual reality',\n",
       "  'authors': ['C Wyman',\n",
       "   'A Patney',\n",
       "   'D Luebke',\n",
       "   '...',\n",
       "   'M Salvi',\n",
       "   'N Benty',\n",
       "   'A Kaplanyan',\n",
       "   'J Kim'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-12',\n",
       "  'citations': '174',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2007626367992907695&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 387: {'ID': 387,\n",
       "  'title': \"Missing the point: an exploration of how to guide users' attention during cinematic virtual reality.\",\n",
       "  'authors': ['NC Nilsson',\n",
       "   'SD Hartmeyer',\n",
       "   'TCM Ljung',\n",
       "   '...',\n",
       "   'MB Møller',\n",
       "   'R Nordahl',\n",
       "   'LT Nielsen'],\n",
       "  'journal': 'VRST, 229-232',\n",
       "  'citations': '54',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17530062231379572745&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 388: {'ID': 388,\n",
       "  'title': 'Guided Mesh Normal Filtering',\n",
       "  'authors': ['B Deng', 'S Bouaziz', 'J Zhang', 'W Zhang', 'L Liu'],\n",
       "  'journal': 'Computer Graphics Forum 34 (7), 23-34',\n",
       "  'citations': '83',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1863826307038929056&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 389: {'ID': 389,\n",
       "  'title': 'MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering',\n",
       "  'authors': ['F Brodkorb',\n",
       "   'T von Landesberger',\n",
       "   'P Roskosch',\n",
       "   'N Andrienko',\n",
       "   '...',\n",
       "   'G Andrienko'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 11-20',\n",
       "  'citations': '135',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18005405545066084458&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 390: {'ID': 390,\n",
       "  'title': 'Soli: ubiquitous gesture sensing with millimeter wave radar',\n",
       "  'authors': ['E Olson',\n",
       "   'C Schwesig',\n",
       "   'N Gillian',\n",
       "   '...',\n",
       "   'P Amihood',\n",
       "   'J Lien',\n",
       "   'ME Karagozler'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-19',\n",
       "  'citations': '314',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13173955939801012067&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 391: {'ID': 391,\n",
       "  'title': '3D entity-based stereo matching with ground control points and joint second-order smoothness prior',\n",
       "  'authors': ['Z Wang', 'C Li', 'F Mei', 'J Liu'],\n",
       "  'journal': 'The Visual Computer 31 (9), 1253-1269',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7273055091326148275&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 392: {'ID': 392,\n",
       "  'title': 'Direct immersogeometric fluid flow analysis using B-rep CAD models',\n",
       "  'authors': ['F Xu', 'A Krishnamurthy', 'MC Hsu', 'AJ Herrema', 'C Wang'],\n",
       "  'journal': 'Computer Aided Geometric Design 43, 143-158',\n",
       "  'citations': '36',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5024074329959066801&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 393: {'ID': 393,\n",
       "  'title': 'Motion reconstruction using very few accelerometers and ground contacts',\n",
       "  'authors': ['G Tao', 'B Krüger', 'A Weber', 'Q Riaz'],\n",
       "  'journal': 'Graphical Models 79, 23-38',\n",
       "  'citations': '29',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17777807032144340141&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 394: {'ID': 394,\n",
       "  'title': 'SSVDAGs: symmetry-aware sparse voxel DAGs.',\n",
       "  'authors': ['F Marton', 'E Gobbetti', 'AJ Villanueva'],\n",
       "  'journal': 'I3D, 7-14',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3739956100685260759&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 395: {'ID': 395,\n",
       "  'title': 'Urbane: A 3D framework to support data driven decision making in urban development',\n",
       "  'authors': ['M Park',\n",
       "   'H Doraiswamy',\n",
       "   'M Lage',\n",
       "   'N Ferreira',\n",
       "   'H Vo',\n",
       "   'H Werner',\n",
       "   '...',\n",
       "   'L Wilson'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 97-104',\n",
       "  'citations': '48',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12498137238481996470&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 396: {'ID': 396,\n",
       "  'title': 'Visual Text Analysis in Digital Humanities',\n",
       "  'authors': ['S Jänicke', 'G Franzini', 'G Scheuermann', 'MF Cheema'],\n",
       "  'journal': 'Computer Graphics Forum 36 (6), 226-250',\n",
       "  'citations': '59',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=964876928540889862&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 397: {'ID': 397,\n",
       "  'title': 'Art-directed muscle simulation for high-end facial animation',\n",
       "  'authors': ['KS Bhat', 'M Cong', 'R Fedkiw'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12935631331444166418&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 398: {'ID': 398,\n",
       "  'title': 'Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow',\n",
       "  'authors': ['D Smilkov',\n",
       "   'J Wexler',\n",
       "   'J Wilson',\n",
       "   'K Wongsuphasawat',\n",
       "   'D Mané',\n",
       "   '...',\n",
       "   'D Fritz'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (1), 1-12',\n",
       "  'citations': '157',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10686455819068863663&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 399: {'ID': 399,\n",
       "  'title': 'Automatically scheduling halide image processing pipelines',\n",
       "  'authors': ['D Sharlet',\n",
       "   'A Adams',\n",
       "   'K Fatahalian',\n",
       "   'RT Mullapudi',\n",
       "   'J Ragan-Kelley'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (4), 1-11',\n",
       "  'citations': '88',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9007610239189704140&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 400: {'ID': 400,\n",
       "  'title': 'Rapid Delaunay triangulation for randomly distributed point cloud data using adaptive Hilbert curve',\n",
       "  'authors': ['Z Lv', 'X Li', 'T Su', 'W Wang', 'W Wu'],\n",
       "  'journal': 'Computers & Graphics 54, 65-74',\n",
       "  'citations': '129',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10083275598269098714&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 401: {'ID': 401,\n",
       "  'title': 'SnapNet: 3D point cloud semantic labeling with 2D deep segmentation networks',\n",
       "  'authors': ['N Audebert', 'J Guerry', 'B Le Saux', 'A Boulch'],\n",
       "  'journal': 'Computers & Graphics 71, 189-198',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11483200480567452554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 402: {'ID': 402,\n",
       "  'title': 'Legomotion: scalable walking-based virtual locomotion',\n",
       "  'authors': ['S Tregillus', 'J Bhandari', 'E Folmer'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2892406784907683820&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 403: {'ID': 403,\n",
       "  'title': 'Ivy: Exploring Spatially Situated Visual Programming for Authoring and Understanding Intelligent Environments',\n",
       "  'authors': ['M Annett',\n",
       "   'B Ens',\n",
       "   'T Grossman',\n",
       "   'P Irani',\n",
       "   'G Fitzmaurice',\n",
       "   'F Anderson'],\n",
       "  'journal': 'Proceedings of the 43rd Graphics Interface Conference, 156-162',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17741483216722162645&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 404: {'ID': 404,\n",
       "  'title': 'Maximizing Smart Factory Systems by Incrementally Updating Point Clouds',\n",
       "  'authors': ['JS Carlson', 'R Berlin', 'E Shellshear'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (2), 62-69',\n",
       "  'citations': '46',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2497528450802033200&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 405: {'ID': 405,\n",
       "  'title': 'SemanticPaint: Interactive 3D Labeling and Learning at your Fingertips',\n",
       "  'authors': ['J Valentin',\n",
       "   'V Vineet',\n",
       "   'MM Cheng',\n",
       "   'D Kim',\n",
       "   'M Nießner',\n",
       "   '...',\n",
       "   'P Kohli',\n",
       "   'J Shotton'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (5), 1-17',\n",
       "  'citations': '90',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12547962849031990994&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 406: {'ID': 406,\n",
       "  'title': 'Printing 3D objects with interlocking parts',\n",
       "  'authors': ['Z Fu', 'L Liu', 'CW Fu', 'P Song'],\n",
       "  'journal': 'Computer Aided Geometric Design 35, 137-148',\n",
       "  'citations': '70',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8707947265089413227&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 407: {'ID': 407,\n",
       "  'title': 'The shape variational autoencoder: A deep generative model of part‐segmented 3D objects',\n",
       "  'authors': ['CKI Williams', 'C Nash'],\n",
       "  'journal': 'Computer Graphics Forum 36 (5), 1-12',\n",
       "  'citations': '59',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14909356210549455801&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 408: {'ID': 408,\n",
       "  'title': 'Convolutional wasserstein distances: efficient optimal transportation on geometric domains',\n",
       "  'authors': ['M Cuturi',\n",
       "   'T Du',\n",
       "   'J Solomon',\n",
       "   'G Peyré',\n",
       "   'A Butscher',\n",
       "   '...',\n",
       "   'F de Goes',\n",
       "   'A Nguyen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-11',\n",
       "  'citations': '310',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=773329588085970908&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 409: {'ID': 409,\n",
       "  'title': 'A System for High-Resolution Topology Optimization',\n",
       "  'authors': ['R Westermann', 'C Dick', 'J Wu'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (3), 1195-1208',\n",
       "  'citations': '76',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5263300727619100232&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 410: {'ID': 410,\n",
       "  'title': 'Embedded Data Representations',\n",
       "  'authors': ['W Willett', 'P Dragicevic', 'Y Jansen'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 461-470',\n",
       "  'citations': '75',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7314381804016460320&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 411: {'ID': 411,\n",
       "  'title': 'Cognitive Augmented Reality',\n",
       "  'authors': ['D Stricker', 'N Petersen'],\n",
       "  'journal': 'Computers & Graphics 53, 82-91',\n",
       "  'citations': '54',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1279450872554514183&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 412: {'ID': 412,\n",
       "  'title': 'Customization of 3D content with semantic meta-scenes',\n",
       "  'authors': ['K Walczak', 'J Flotyński'],\n",
       "  'journal': 'Graphical Models 88, 23-39',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16899232836547547395&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 413: {'ID': 413,\n",
       "  'title': 'Gaussian curvature using fundamental forms for binary voxel data',\n",
       "  'authors': ['O Wirjadi', 'H Hagen', 'M Kronenberger', 'J Freitag'],\n",
       "  'journal': 'Graphical Models 82, 123-136',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=308004685479384367&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 414: {'ID': 414,\n",
       "  'title': 'Automated human motion segmentation via motion regularities',\n",
       "  'authors': ['H Sun', 'R Lan'],\n",
       "  'journal': 'The Visual Computer 31 (1), 35-53',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5447359378357136615&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 415: {'ID': 415,\n",
       "  'title': 'Visualization of Eye Tracking Data: A Taxonomy and Survey',\n",
       "  'authors': ['T Ertl',\n",
       "   'M Burch',\n",
       "   'M Raschke',\n",
       "   'D Weiskopf',\n",
       "   'T Blascheck',\n",
       "   'K Kurzhals'],\n",
       "  'journal': 'Computer Graphics Forum 36 (8), 260-284',\n",
       "  'citations': '102',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9876521497478756378&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 416: {'ID': 416,\n",
       "  'title': 'Revisiting Trends in Augmented Reality Research: A Review of the 2nd Decade of ISMAR (2008–2017)',\n",
       "  'authors': ['HBL Duh', 'K Kim', 'G Bruder', 'GF Welch', 'M Billinghurst'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 24 (11), 2947-2962',\n",
       "  'citations': '76',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17192482326940983079&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 417: {'ID': 417,\n",
       "  'title': 'DocuCompass: Effective exploration of document landscapes',\n",
       "  'authors': ['T Ertl', 'M John', 'F Heimerl', 'Q Han', 'S Koch'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 11-20',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3126183974822468146&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 418: {'ID': 418,\n",
       "  'title': 'Microstructures to control elasticity in 3D printing',\n",
       "  'authors': ['S Marschner',\n",
       "   'M Gross',\n",
       "   'J Rys',\n",
       "   'C Daraio',\n",
       "   'C Schumacher',\n",
       "   'B Bickel'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-13',\n",
       "  'citations': '216',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10775464299459197503&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 419: {'ID': 419,\n",
       "  'title': 'Refinable C1 spline elements for irregular quad layout',\n",
       "  'authors': ['T Nguyen', 'J Peters'],\n",
       "  'journal': 'Computer Aided Geometric Design 43, 123-130',\n",
       "  'citations': '48',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1589267975167980958&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 420: {'ID': 420,\n",
       "  'title': 'Density maps for improved SPH boundary handling',\n",
       "  'authors': ['D Koschier', 'J Bender'],\n",
       "  'journal': 'Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation\\xa0…',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13204495366766297712&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 421: {'ID': 421,\n",
       "  'title': 'A Survey of Digital Earth',\n",
       "  'authors': ['A Mahdavi-Amiri', 'T Alderson', 'F Samavati'],\n",
       "  'journal': 'Computers & Graphics 53, 95-117',\n",
       "  'citations': '75',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11349234144439360060&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 422: {'ID': 422,\n",
       "  'title': 'Analytic Provenance for Sensemaking: A Research Agenda',\n",
       "  'authors': ['PH Nguyen',\n",
       "   'S Attfield',\n",
       "   'K Xu',\n",
       "   'A Wheat',\n",
       "   'TJ Jankun-Kelly',\n",
       "   'N Selvaraj'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (3), 56-64',\n",
       "  'citations': '65',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3229412951507267333&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 423: {'ID': 423,\n",
       "  'title': 'Wide Field Of View Varifocal Near-Eye Display Using See-Through Deformable Membrane Mirrors',\n",
       "  'authors': ['P Kellnhofer',\n",
       "   'K Torell',\n",
       "   'K Akşit',\n",
       "   'D Dunn',\n",
       "   'K Myszkowski',\n",
       "   '...',\n",
       "   'C Tippets',\n",
       "   'P Didyk'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (4), 1322-1331',\n",
       "  'citations': '82',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9783871809054206133&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 424: {'ID': 424,\n",
       "  'title': 'Virtual reality studies outside the laboratory',\n",
       "  'authors': ['K Hornbæk', 'A Mottelson'],\n",
       "  'journal': 'Proceedings of the 23rd ACM Symposium on Virtual Reality Software and\\xa0…',\n",
       "  'citations': '24',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16888917011856718686&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 425: {'ID': 425,\n",
       "  'title': 'Robust Articulated‐ICP for Real‐Time Hand Tracking',\n",
       "  'authors': ['A Tagliasacchi',\n",
       "   'A Tkach',\n",
       "   'M Botsch',\n",
       "   'M Schröder',\n",
       "   'S Bouaziz',\n",
       "   'M Pauly'],\n",
       "  'journal': 'Computer Graphics Forum 34 (5), 101-114',\n",
       "  'citations': '157',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17641049876140019762&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 426: {'ID': 426,\n",
       "  'title': 'The benefits of DOF separation in mid-air 3D object manipulation.',\n",
       "  'authors': ['D Mendes', 'A Ferreira', 'F Relvas', 'JA Jorge'],\n",
       "  'journal': 'VRST, 261-268',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12056954121079385757&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 427: {'ID': 427,\n",
       "  'title': 'Joint embeddings of shapes and images via CNN image purification',\n",
       "  'authors': ['N Fish', 'LJ Guibas', 'CR Qi', 'D Cohen-Or', 'Y Li', 'H Su'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (6), 1-12',\n",
       "  'citations': '127',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6251959556361839014&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 428: {'ID': 428,\n",
       "  'title': 'Gendered or neutral? considering the language of HCI',\n",
       "  'authors': ['A Bradley', 'C MacArthur', 'S Carpendale', 'M Hancock'],\n",
       "  'journal': 'Proceedings of the 41st Graphics Interface Conference, 163-170',\n",
       "  'citations': '14',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13630645906425868645&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 429: {'ID': 429,\n",
       "  'title': 'Visualizing Dynamic Brain Networks Using an Animated Dual-Representation.',\n",
       "  'authors': ['RV Kenyon',\n",
       "   'TY Berger-Wolf',\n",
       "   'C Ma',\n",
       "   'AG Forbes',\n",
       "   'DA Llano',\n",
       "   'BJ Slater'],\n",
       "  'journal': 'EuroVis (Short Papers), 73-77',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11372860946950775107&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 430: {'ID': 430,\n",
       "  'title': 'Architectural geometry',\n",
       "  'authors': ['J Wallner', 'M Eigensatz', 'H Pottmann', 'A Vaxman'],\n",
       "  'journal': 'Computers & Graphics 47, 145-164',\n",
       "  'citations': '116',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17248056033998412453&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 431: {'ID': 431,\n",
       "  'title': 'iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data',\n",
       "  'authors': ['L Yu',\n",
       "   'SK Ng',\n",
       "   'WS Ng',\n",
       "   'Z Huang',\n",
       "   'HM Watt',\n",
       "   'G Li',\n",
       "   'A Arunan',\n",
       "   'X Li',\n",
       "   'W Wu'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 49-56',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14785434512024751803&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 432: {'ID': 432,\n",
       "  'title': 'Visual Perspective and Feedback Guidance for VR Free-Throw Training',\n",
       "  'authors': ['AH Olivier', 'F Multon', 'A Covaci'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 35 (5), 55-65',\n",
       "  'citations': '38',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18022513925052602324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 433: {'ID': 433,\n",
       "  'title': 'Single-view reconstruction via joint analysis of image and shape collections',\n",
       "  'authors': ['H Wang', 'V Koltun', 'Q Huang'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-10',\n",
       "  'citations': '121',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15220534980879034066&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 434: {'ID': 434,\n",
       "  'title': 'Identifying Virtual 3D Geometric Shapes with a Vibrotactile Glove',\n",
       "  'authors': ['JP Molina', 'J Martinez', 'A Garcia', 'P Gonzalez', 'M Oliver'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications, 42-51',\n",
       "  'citations': '48',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9433826475599474919&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 435: {'ID': 435,\n",
       "  'title': '15 Years of Research on Redirected Walking in Immersive Virtual Environments',\n",
       "  'authors': ['NC Nilsson',\n",
       "   'T Peck',\n",
       "   'G Bruder',\n",
       "   'S Serafin',\n",
       "   '...',\n",
       "   'E Hodgson',\n",
       "   'M Whitton'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 38 (2), 44-56',\n",
       "  'citations': '53',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9660400228930306809&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 436: {'ID': 436,\n",
       "  'title': 'A Review of Eye Gaze in Virtual Agents, Social Robotics and HCI: Behaviour Generation, User Interaction and Perception',\n",
       "  'authors': ['JB Badler',\n",
       "   'CE Peters',\n",
       "   'K Ruhland',\n",
       "   'M Gleicher',\n",
       "   '...',\n",
       "   'NI Badler',\n",
       "   'S Andrist'],\n",
       "  'journal': 'Computer Graphics Forum 34 (6), 299-326',\n",
       "  'citations': '89',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11492651902761825425&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 437: {'ID': 437,\n",
       "  'title': 'Complex hole-filling algorithm for 3D models.',\n",
       "  'authors': ['K Matsuyama', 'O Khorloo', 'E Altantsetseg', 'K Konno'],\n",
       "  'journal': 'CGI, 10:1-10:6',\n",
       "  'citations': '13',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6148708527958415157&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 438: {'ID': 438,\n",
       "  'title': 'Facial performance sensing head-mounted display',\n",
       "  'authors': ['K Olszewski',\n",
       "   'C Ma',\n",
       "   'T Trutna',\n",
       "   'H Li',\n",
       "   'PL Hsieh',\n",
       "   'A Nicholls',\n",
       "   'L Trutoiu',\n",
       "   'L Wei'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-9',\n",
       "  'citations': '122',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3386150920979676960&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 439: {'ID': 439,\n",
       "  'title': 'The Reality Deck--an Immersive Gigapixel Display',\n",
       "  'authors': ['K Petkov', 'C Papadopoulos', 'AE Kaufman', 'K Mueller'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications, 33-45',\n",
       "  'citations': '39',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13815227905891968108&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 440: {'ID': 440,\n",
       "  'title': 'Sketch abstractions for character posing',\n",
       "  'authors': ['F Mutzel',\n",
       "   'M Gross',\n",
       "   'B Thomaszewski',\n",
       "   'M Nitti',\n",
       "   '...',\n",
       "   'S Coros',\n",
       "   'F Hahn'],\n",
       "  'journal': 'Proceedings of the 14th ACM SIGGRAPH/Eurographics Symposium on Computer\\xa0…',\n",
       "  'citations': '22',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13259269873479596196&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 441: {'ID': 441,\n",
       "  'title': 'SketchInsight: Natural data exploration on interactive whiteboards leveraging pen and touch interaction',\n",
       "  'authors': ['B Lee', 'S Carpendale', 'NH Riche', 'G Smith', 'A Karlson'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 199-206',\n",
       "  'citations': '27',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16302269931012866244&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 442: {'ID': 442,\n",
       "  'title': 'Two-stage Color Texture Synthesis using the Structure Tensor Field',\n",
       "  'authors': ['C Yaacoub', 'A Akl', 'C Germain', 'JP Da Costa', 'M Donias'],\n",
       "  'journal': 'Proceedings of the 10th International Conference on Computer Graphics Theory\\xa0…',\n",
       "  'citations': '9',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=213470925448623775&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 443: {'ID': 443,\n",
       "  'title': 'Automatic Portrait Segmentation for Image Stylization',\n",
       "  'authors': ['J Jia',\n",
       "   'I Sachs',\n",
       "   'E Shechtman',\n",
       "   'X Shen',\n",
       "   'A Hertzmann',\n",
       "   'B Price',\n",
       "   'S Paris'],\n",
       "  'journal': 'Computer Graphics Forum 35 (2), 93-102',\n",
       "  'citations': '104',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17987366858765903686&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 444: {'ID': 444,\n",
       "  'title': 'MegaMol—A Prototyping Framework for Particle-Based Visualization',\n",
       "  'authors': ['T Ertl', 'S Grottel', 'G Reina', 'M Krone', 'C Muller'],\n",
       "  'journal': 'IEEE Transactions on Visualization & Computer Graphics, 201-214',\n",
       "  'citations': '94',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6292937916783819798&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 445: {'ID': 445,\n",
       "  'title': 'Estimation of crowd density by clustering motion cues',\n",
       "  'authors': ['J Gubbi', 'M Palaniswami', 'S Marusic', 'AS Rao'],\n",
       "  'journal': 'The Visual Computer 31 (11), 1533-1552',\n",
       "  'citations': '28',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7222303689364218405&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 446: {'ID': 446,\n",
       "  'title': 'Copula Eigenfaces-Semiparametric Principal Component Analysis for Facial Appearance Modeling.',\n",
       "  'authors': ['B Egger', 'S Schönborn', 'T Vetter', 'V Roth', 'D Kaufmann'],\n",
       "  'journal': 'VISIGRAPP (1: GRAPP), 50-58',\n",
       "  'citations': '8',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6394376928068655515&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 447: {'ID': 447,\n",
       "  'title': 'A visual-numeric approach to clustering and anomaly detection for trajectory data',\n",
       "  'authors': ['C Leckie',\n",
       "   'JC Bezdek',\n",
       "   'M Palaniswami',\n",
       "   'S Rajasegarar',\n",
       "   'D Kumar'],\n",
       "  'journal': 'The Visual Computer 33 (3), 265-281',\n",
       "  'citations': '36',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8595481726390776825&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 448: {'ID': 448,\n",
       "  'title': 'Aggregate G-buffer anti-aliasing.',\n",
       "  'authors': ['C Crassin', 'K Fatahalian', 'AE Lefohn', 'M McGuire'],\n",
       "  'journal': 'I3D, 109-119',\n",
       "  'citations': '19',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=969332403304776680&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 449: {'ID': 449,\n",
       "  'title': 'Data-Driven Healthcare: Challenges and Opportunities for Interactive Visualization',\n",
       "  'authors': ['D Gotz', 'D Borland'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 36 (3), 90-96',\n",
       "  'citations': '43',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1017042205774588540&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 450: {'ID': 450,\n",
       "  'title': 'Visualization of Biomolecular Structures: State of the Art Revisited',\n",
       "  'authors': ['B Kozlíková',\n",
       "   'M Baaden',\n",
       "   '...',\n",
       "   'I Viola',\n",
       "   'N Lindow',\n",
       "   'D Baum',\n",
       "   'M Krone',\n",
       "   'M Falk'],\n",
       "  'journal': 'Computer Graphics Forum 36 (8), 178-204',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7675101710892103611&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 451: {'ID': 451,\n",
       "  'title': 'Deep joint demosaicking and denoising',\n",
       "  'authors': ['M Gharbi', 'G Chaurasia', 'F Durand', 'S Paris'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-12',\n",
       "  'citations': '179',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=629583401266516852&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 452: {'ID': 452,\n",
       "  'title': 'Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis',\n",
       "  'authors': ['JA Lee',\n",
       "   'M Sedlmair',\n",
       "   'SC North',\n",
       "   'J Peltonen',\n",
       "   'L Zhang',\n",
       "   '...',\n",
       "   'D Weiskopf',\n",
       "   'D Sacha'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 241-250',\n",
       "  'citations': '124',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2565838027433703082&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 453: {'ID': 453,\n",
       "  'title': 'Burst photography for high dynamic range and low-light imaging on mobile cameras',\n",
       "  'authors': ['D Sharlet',\n",
       "   'R Geiss',\n",
       "   'A Adams',\n",
       "   'SW Hasinoff',\n",
       "   'F Kainz',\n",
       "   '...',\n",
       "   'JT Barron',\n",
       "   'J Chen'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-12',\n",
       "  'citations': '139',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8772719545521007130&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 454: {'ID': 454,\n",
       "  'title': 'TerraMobilita/iQmulus urban point cloud analysis benchmark',\n",
       "  'authors': ['B Vallet',\n",
       "   'A Serna',\n",
       "   'M Brédif',\n",
       "   'B Marcotegui',\n",
       "   'N Paparoditis'],\n",
       "  'journal': 'Computers & Graphics 49, 126-133',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12860559416248661661&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 455: {'ID': 455,\n",
       "  'title': 'Instant Outdoor Localization and SLAM Initialization from 2.5 D Maps',\n",
       "  'authors': ['C Arth',\n",
       "   'V Lepetit',\n",
       "   'C Pirchheim',\n",
       "   'D Schmalstieg',\n",
       "   'J Ventura'],\n",
       "  'journal': 'IEEE Annals of the History of Computing, 1309-1318',\n",
       "  'citations': '89',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16666044752932766336&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 456: {'ID': 456,\n",
       "  'title': 'PedVR: simulating gaze-based interactions between a real user and virtual crowds.',\n",
       "  'authors': ['A Shapiro', 'A Best', 'D Manocha', 'S Narang', 'T Randhavane'],\n",
       "  'journal': 'VRST, 91-100',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10950071528836256522&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 457: {'ID': 457,\n",
       "  'title': 'Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?',\n",
       "  'authors': ['M Cordeil',\n",
       "   'K Marriott',\n",
       "   'K Klein',\n",
       "   'B Laha',\n",
       "   'T Dwyer',\n",
       "   'BH Thomas'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (1), 441-450',\n",
       "  'citations': '103',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17308161010848403525&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 458: {'ID': 458,\n",
       "  'title': 'Digital Fabrication Techniques for Cultural Heritage: A Survey',\n",
       "  'authors': ['M Dellepiane',\n",
       "   'N Pietroni',\n",
       "   'P Cignoni',\n",
       "   'M Callieri',\n",
       "   'R Scopigno'],\n",
       "  'journal': 'Computer Graphics Forum 36 (1), 6-21',\n",
       "  'citations': '64',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10787269624585668631&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 459: {'ID': 459,\n",
       "  'title': 'Optimal presentation of imagery with focus cues on multi-plane displays',\n",
       "  'authors': ['MS Banks',\n",
       "   \"JF O'Brien\",\n",
       "   'GJ Ward',\n",
       "   'R Narain',\n",
       "   'A Bulbul',\n",
       "   'RA Albert'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '91',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3483673876807314829&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 460: {'ID': 460,\n",
       "  'title': 'Hierarchical Stochastic Neighbor Embedding',\n",
       "  'authors': ['B Lelieveldt',\n",
       "   'E Eisemann',\n",
       "   'A Vilanova',\n",
       "   'N Pezzotti',\n",
       "   'T Höllt'],\n",
       "  'journal': 'Computer Graphics Forum 35 (3), 21-30',\n",
       "  'citations': '69',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16759058044879827320&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 461: {'ID': 461,\n",
       "  'title': \"How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking\",\n",
       "  'authors': ['SH Kim', 'YA Kang', 'S Lee', 'H Lam', 'YH Hung', 'JS Yi'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 22 (1), 499-508',\n",
       "  'citations': '72',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12439674802644247277&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 462: {'ID': 462,\n",
       "  'title': 'Semantic query-based generation of customized 3D scenes.',\n",
       "  'authors': ['K Walczak', 'J Flotynski'],\n",
       "  'journal': 'Web3D, 123-131',\n",
       "  'citations': '15',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9125392627249876147&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 463: {'ID': 463,\n",
       "  'title': 'Example-guided anthropometric human body modeling',\n",
       "  'authors': ['Y Zhang', 'N Magnenat-Thalmann', 'J Zheng'],\n",
       "  'journal': 'The Visual Computer 31 (12), 1615-1631',\n",
       "  'citations': '26',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15691934513354225467&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 464: {'ID': 464,\n",
       "  'title': 'Appealing Female Avatars from 3D Body Scans: Perceptual Effects of Stylization.',\n",
       "  'authors': ['MJ Black', 'J Romero', 'BJ Mohler', 'R Fleming', 'M Breidt'],\n",
       "  'journal': 'VISIGRAPP (1: GRAPP), 335-345',\n",
       "  'citations': '8',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=667672549444981890&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 465: {'ID': 465,\n",
       "  'title': 'Comparative visual analysis of vector field ensembles',\n",
       "  'authors': ['R Westermann', 'I Demir', 'M Jarema', 'J Kehrer'],\n",
       "  'journal': '2015 IEEE Conference on Visual Analytics Science and Technology (VAST), 81-88',\n",
       "  'citations': '32',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13801972894323933080&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 466: {'ID': 466,\n",
       "  'title': 'D-Map: Visual analysis of ego-centric information diffusion patterns in social media',\n",
       "  'authors': ['Z Wang', 'X Yuan', 'Y Wu', 'S Chen', 'J Liang', 'N Cao'],\n",
       "  'journal': '2016 IEEE Conference on Visual Analytics Science and Technology (VAST), 41-50',\n",
       "  'citations': '33',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11163906893795780023&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 467: {'ID': 467,\n",
       "  'title': 'Underwater Depth Estimation and Image Restoration Based on Single Images',\n",
       "  'authors': ['ER Nascimento', 'MFM Campos', 'SSC Botelho', 'PLJ Drews'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 36 (2), 24-35',\n",
       "  'citations': '83',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16883352936708988804&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 468: {'ID': 468,\n",
       "  'title': 'Dynamic Projection Mapping onto Deforming Non-Rigid Surface Using Deformable Dot Cluster Marker',\n",
       "  'authors': ['M Ishikawa', 'G Narita', 'Y Watanabe'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (3), 1235-1248',\n",
       "  'citations': '73',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14103773637752555435&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 469: {'ID': 469,\n",
       "  'title': 'Jump: virtual reality video',\n",
       "  'authors': ['J Kontkanen',\n",
       "   'C Hernández',\n",
       "   'D Gallup',\n",
       "   '...',\n",
       "   'N Snavely',\n",
       "   'JT Barron',\n",
       "   'R Anderson'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 35 (6), 1-13',\n",
       "  'citations': '145',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18392625024032692201&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 470: {'ID': 470,\n",
       "  'title': 'Reconstructing building mass models from UAV images',\n",
       "  'authors': ['M Li', 'P Wonka', 'N Smith', 'L Nan'],\n",
       "  'journal': 'Computers & Graphics 54, 84-93',\n",
       "  'citations': '37',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12710567056884258542&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 471: {'ID': 471,\n",
       "  'title': 'Learning visual similarity for product design with convolutional neural networks',\n",
       "  'authors': ['K Bala', 'S Bell'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-10',\n",
       "  'citations': '296',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10970688853567337806&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 472: {'ID': 472,\n",
       "  'title': 'VirtualOulu: collaborative, immersive and extensible 3D city model on the web.',\n",
       "  'authors': ['T Alatalo', 'M Pouke', 'T Ojala', 'T Koskela', 'P Alavesa'],\n",
       "  'journal': 'Web3D, 95-103',\n",
       "  'citations': '23',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2880944757101701452&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 473: {'ID': 473,\n",
       "  'title': 'Procedurally generated virtual reality from 3D reconstructed physical space.',\n",
       "  'authors': ['M Sra', 'S Garrido-Jurado', 'C Schmandt'],\n",
       "  'journal': 'VRST, 191-200',\n",
       "  'citations': '56',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4133575461984623598&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 474: {'ID': 474,\n",
       "  'title': 'Uncertainty modeling and error reduction for pathline computation in time-varying flow fields',\n",
       "  'authors': ['CM Chen', 'A Biswas', 'HW Shen'],\n",
       "  'journal': '2015 IEEE Pacific Visualization Symposium (PacificVis), 215-222',\n",
       "  'citations': '21',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4381148023175831716&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 475: {'ID': 475,\n",
       "  'title': 'Real-time multi-scale tracking based on compressive sensing',\n",
       "  'authors': ['J Sun', 'Y Wu', 'N Jia'],\n",
       "  'journal': 'The Visual Computer 31 (4), 471-484',\n",
       "  'citations': '39',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14132566291493535550&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 476: {'ID': 476,\n",
       "  'title': 'Design space for spatio-data coordination: Tangible interaction devices for immersive information visualisation',\n",
       "  'authors': ['M Cordeil', 'E Wilson', 'B Bach', 'Y Li', 'T Dwyer'],\n",
       "  'journal': '2017 IEEE Pacific Visualization Symposium (PacificVis), 46-50',\n",
       "  'citations': '31',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18339791819489716279&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 477: {'ID': 477,\n",
       "  'title': '3drepo. io: building the next generation Web3D repository with AngularJS and X3DOM.',\n",
       "  'authors': ['J Dobos', 'T Scully', 'Y Jung', 'T Sturm'],\n",
       "  'journal': 'Web3D, 235-243',\n",
       "  'citations': '25',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7396551301663776417&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 478: {'ID': 478,\n",
       "  'title': 'Advances in Interaction with 3D Environments',\n",
       "  'authors': ['M Hachet', 'J Jankowski'],\n",
       "  'journal': 'Computer Graphics Forum 34 (1), 152-190',\n",
       "  'citations': '69',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10922724024893996934&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 479: {'ID': 479,\n",
       "  'title': 'An L 1 image transform for edge-preserving smoothing and scene-level intrinsic decomposition',\n",
       "  'authors': ['Y Yu', 'S Bi', 'X Han'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '112',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7991232802251646765&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 480: {'ID': 480,\n",
       "  'title': 'Semantic word cloud generation based on word embeddings',\n",
       "  'authors': ['Y Tao', 'J Xu', 'H Lin'],\n",
       "  'journal': '2016 IEEE Pacific Visualization Symposium (PacificVis), 239-243',\n",
       "  'citations': '20',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17161572552076001093&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 481: {'ID': 481,\n",
       "  'title': 'Stereoscopic Thumbnail Creation via Efficient Stereo Saliency Detection',\n",
       "  'authors': ['Y Yu', 'J Shen', 'KL Ma', 'W Wang'],\n",
       "  'journal': 'IEEE Transactions on Visualization and Computer Graphics 23 (8), 2014-2027',\n",
       "  'citations': '84',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7483497392250661230&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 482: {'ID': 482,\n",
       "  'title': 'Elastic textures for additive fabrication',\n",
       "  'authors': ['J Panetta',\n",
       "   'L Malomo',\n",
       "   'D Zorin',\n",
       "   'N Pietroni',\n",
       "   'P Cignoni',\n",
       "   'Q Zhou'],\n",
       "  'journal': 'ACM Transactions on Graphics (TOG) 34 (4), 1-12',\n",
       "  'citations': '153',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14257313432769914290&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 483: {'ID': 483,\n",
       "  'title': 'State of the Art on 3D Reconstruction with RGB‐D Cameras',\n",
       "  'authors': ['M Zollhöfer',\n",
       "   'M Nießner',\n",
       "   'P Stotko',\n",
       "   'A Kolb',\n",
       "   'R Klein',\n",
       "   'C Theobalt',\n",
       "   'A Görlitz'],\n",
       "  'journal': 'Computer Graphics Forum 37 (2), 625-652',\n",
       "  'citations': '79',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9165342707514977786&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 484: {'ID': 484,\n",
       "  'title': 'Augment Your Reality',\n",
       "  'authors': ['M Bailey', 'L Avila'],\n",
       "  'journal': 'IEEE Computer Graphics and Applications 36 (1), 6-7',\n",
       "  'citations': '34',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16592330333567939816&btnI=1&nossl=1&hl=en&oe=ASCII'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-amino",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
