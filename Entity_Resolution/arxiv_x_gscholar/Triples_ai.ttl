@prefix schema: <https://schema.org/> .

<0> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) are powerful generative models, butsuffer from training instability. The recently proposed Wasserstein GAN (WGAN)makes progress toward stable training of GANs, but sometimes can still generateonly low-quality samples or fail to converge. We find that these problems areoften due to the use of weight clipping in WGAN to enforce a Lipschitzconstraint on the critic, which can lead to undesired behavior. We propose analternative to clipping weights: penalize the norm of gradient of the criticwith respect to its input. Our proposed method performs better than standardWGAN and enables stable training of a wide variety of GAN architectures withalmost no hyperparameter tuning, including 101-layer ResNets and languagemodels over discrete data. We also achieve high quality generations on CIFAR-10and LSUN bedrooms."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Faruk Ahmed"^^schema:Person,
        "Ishaan Gulrajani"^^schema:Person,
        "Martin Arjovsky"^^schema:Person,
        "Vincent Dumoulin"^^schema:Person ;
    schema:commentCount "3041"^^schema:Integer ;
    schema:dateModified "2017-12-25T23:03:49Z"^^schema:DateTime ;
    schema:datePublished "2017-03-31T19:25:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improved Training of Wasserstein GANs"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.00028v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3068694056154618633&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1> a schema:ScholarlyArticle ;
    schema:abstract "Accuracy and interpretability are two dominant features of successfulpredictive models. Typically, a choice must be made in favor of complex blackbox models such as recurrent neural networks (RNN) for accuracy versus lessaccurate but more interpretable traditional models such as logistic regression.This tradeoff poses challenges in medicine where both accuracy andinterpretability are important. We addressed this challenge by developing theREverse Time AttentIoN model (RETAIN) for application to Electronic HealthRecords (EHR) data. RETAIN achieves high accuracy while remaining clinicallyinterpretable and is based on a two-level neural attention model that detectsinfluential past visits and significant clinical variables within those visits(e.g. key diagnoses). RETAIN mimics physician practice by attending the EHRdata in a reverse time order so that recent clinical visits are likely toreceive higher attention. RETAIN was tested on a large health system EHRdataset with 14 million visits completed by 263K patients over an 8 year periodand demonstrated predictive accuracy and computational scalability comparableto state-of-the-art methods such as RNN, and ease of interpretabilitycomparable to traditional models."^^schema:Text ;
    schema:author "Andy Schuetz"^^schema:Person,
        "Edward Choi"^^schema:Person,
        "Jimeng Sun"^^schema:Person,
        "Joshua A. Kulas"^^schema:Person,
        "Mohammad Taha Bahadori"^^schema:Person,
        "Walter F. Stewart"^^schema:Person ;
    schema:commentCount "385"^^schema:Integer ;
    schema:dateModified "2017-02-26T15:13:31Z"^^schema:DateTime ;
    schema:datePublished "2016-08-19T21:54:46Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "RETAIN: An Interpretable Predictive Model for Healthcare using Reverse  Time Attention Mechanism"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.05745v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12067026852472885249&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<10> a schema:ScholarlyArticle ;
    schema:abstract "Learning from a few examples remains a key challenge in machine learning.Despite recent advances in important domains such as vision and language, thestandard supervised deep learning paradigm does not offer a satisfactorysolution for learning new concepts rapidly from little data. In this work, weemploy ideas from metric learning based on deep neural features and from recentadvances that augment neural networks with external memories. Our frameworklearns a network that maps a small labelled support set and an unlabelledexample to its label, obviating the need for fine-tuning to adapt to new classtypes. We then define one-shot learning problems on vision (using Omniglot,ImageNet) and language tasks. Our algorithm improves one-shot accuracy onImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared tocompeting approaches. We also demonstrate the usefulness of the same model onlanguage modeling by introducing a one-shot task on the Penn Treebank."^^schema:Text ;
    schema:author "Charles Blundell"^^schema:Person,
        "Daan Wierstra"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person ;
    schema:commentCount "1564"^^schema:Integer ;
    schema:dateModified "2017-12-29T17:45:19Z"^^schema:DateTime ;
    schema:datePublished "2016-06-13T19:34:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Matching Networks for One Shot Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.04080v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16507194575687684095&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<100> a schema:ScholarlyArticle ;
    schema:abstract "Taxi demand prediction is an important building block to enabling intelligenttransportation systems in a smart city. An accurate prediction model can helpthe city pre-allocate resources to meet travel demand and to reduce empty taxison streets which waste energy and worsen the traffic congestion. With theincreasing popularity of taxi requesting services such as Uber and Didi Chuxing(in China), we are able to collect large-scale taxi demand data continuously.How to utilize such big data to improve the demand prediction is an interestingand critical real-world problem. Traditional demand prediction methods mostlyrely on time series forecasting techniques, which fail to model the complexnon-linear spatial and temporal relations. Recent advances in deep learninghave shown superior performance on traditionally challenging tasks such asimage classification by learning the complex features and correlations fromlarge-scale data. This breakthrough has inspired researchers to explore deeplearning techniques on traffic prediction problems. However, existing methodson traffic prediction have only considered spatial relation (e.g., using CNN)or temporal relation (e.g., using LSTM) independently. We propose a DeepMulti-View Spatial-Temporal Network (DMVST-Net) framework to model both spatialand temporal relations. Specifically, our proposed model consists of threeviews: temporal view (modeling correlations between future demand values withnear time points via LSTM), spatial view (modeling local spatial correlationvia local CNN), and semantic view (modeling correlations among regions sharingsimilar temporal patterns). Experiments on large-scale real taxi demand datademonstrate effectiveness of our approach over state-of-the-art methods."^^schema:Text ;
    schema:author "Fei Wu"^^schema:Person,
        "Huaxiu Yao"^^schema:Person,
        "Jieping Ye"^^schema:Person,
        "Jintao Ke"^^schema:Person,
        "Pinghua Gong"^^schema:Person,
        "Siyu Lu"^^schema:Person,
        "Xianfeng Tang"^^schema:Person,
        "Yitian Jia"^^schema:Person,
        "Zhenhui Li"^^schema:Person ;
    schema:commentCount "239"^^schema:Integer ;
    schema:dateModified "2018-02-27T01:42:08Z"^^schema:DateTime ;
    schema:datePublished "2018-02-23T19:53:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.08714v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6257175571523374999&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1000> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents the first comprehensive empirical study demonstrating theefficacy of the Brain Floating Point (BFLOAT16) half-precision format for DeepLearning training across image classification, speech recognition, languagemodeling, generative networks and industrial recommendation systems. BFLOAT16is attractive for Deep Learning training for two reasons: the range of valuesit can represent is the same as that of IEEE 754 floating-point format (FP32)and conversion to/from FP32 is simple. Maintaining the same range as FP32 isimportant to ensure that no hyper-parameter tuning is required for convergence;e.g., IEEE 754 compliant half-precision floating point (FP16) requireshyper-parameter tuning. In this paper, we discuss the flow of tensors andvarious key operations in mixed precision training, and delve into details ofoperations, such as the rounding modes for converting FP32 tensors to BFLOAT16.We have implemented a method to emulate BFLOAT16 operations in Tensorflow,Caffe2, IntelCaffe, and Neon for our experiments. Our results show that deeplearning training using BFLOAT16 tensors achieves the same state-of-the-art(SOTA) results across domains as FP32 tensors in the same number of iterationsand with no changes to hyper-parameters."^^schema:Text ;
    schema:author "Abhisek Kundu"^^schema:Person,
        "Alexander Heinecke"^^schema:Person,
        "Bharat Kaul"^^schema:Person,
        "Dharma Teja Vooturi"^^schema:Person,
        "Dheevatsa Mudigere"^^schema:Person,
        "Dhiraj Kalamkar"^^schema:Person,
        "Dipankar Das"^^schema:Person,
        "Evangelos Georganas"^^schema:Person,
        "Hector Yuen"^^schema:Person,
        "Jianyu Huang"^^schema:Person,
        "Jiyan Yang"^^schema:Person,
        "Jongsoo Park"^^schema:Person,
        "Kunal Banerjee"^^schema:Person,
        "Misha Smelyanskiy"^^schema:Person,
        "Nataraj Jammalamadaka"^^schema:Person,
        "Naveen Mellempudi"^^schema:Person,
        "Pradeep Dubey"^^schema:Person,
        "Sasikanth Avancha"^^schema:Person,
        "Sudarshan Srinivasan"^^schema:Person ;
    schema:dateModified "2019-06-13T17:55:30Z"^^schema:DateTime ;
    schema:datePublished "2019-05-29T10:50:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Study of BFLOAT16 for Deep Learning Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.12322v3"^^schema:URL .

<1001> a schema:ScholarlyArticle ;
    schema:abstract "Jet tagging techniques that make use of deep learning show great potentialfor improving physics analyses at colliders. One such method is the Energy FlowNetwork (EFN) - a recently introduced neural network architecture thatrepresents jets as permutation-invariant sets of particle momenta whilemaintaining infrared and collinear safety. We develop a variant of the EnergyFlow Network architecture based on the Deep Sets formalism, incorporatingpermutation-equivariant layers. We derive conditions under which infrared andcollinear safety can be maintained, and study the performance of these networkson the canonical example of W-boson tagging. We find that equivariant EnergyFlow Networks have similar performance to Particle Flow Networks, which aresuperior to standard EFNs. However, equivariant Particle Flow Networks sufferfrom convergence and overfitting issues. Finally, we study how equivariantnetworks sculpt the jet mass and provide some initial results on decorrelationusing planing."^^schema:Text ;
    schema:author "Ayodele Ore"^^schema:Person,
        "Matthew J. Dolan"^^schema:Person ;
    schema:dateModified "2020-12-02T04:46:27Z"^^schema:DateTime ;
    schema:datePublished "2020-12-02T04:46:27Z"^^schema:DateTime ;
    schema:genre "hep-ph"^^schema:Text ;
    schema:headline "Equivariant Energy Flow Networks for Jet Tagging"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.00964v1"^^schema:URL .

<1002> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial imitation learning (GAIL) is a popular inversereinforcement learning approach for jointly optimizing policy and reward fromexpert trajectories. A primary question about GAIL is whether applying acertain policy gradient algorithm to GAIL attains a global minimizer (i.e.,yields the expert policy), for which existing understanding is very limited.Such global convergence has been shown only for the linear (or linear-type) MDPand linear (or linearizable) reward. In this paper, we study GAIL under generalMDP and for nonlinear reward function classes (as long as the objectivefunction is strongly concave with respect to the reward parameter). Wecharacterize the global convergence with a sublinear rate for a broad range ofcommonly used policy gradient algorithms, all of which are implemented in analternating manner with stochastic gradient ascent for reward update, includingprojected policy gradient (PPG)-GAIL, Frank-Wolfe policy gradient (FWPG)-GAIL,trust region policy optimization (TRPO)-GAIL and natural policy gradient(NPG)-GAIL. This is the first systematic theoretical study of GAIL for globalconvergence."^^schema:Text ;
    schema:author "Tengyu Xu"^^schema:Person,
        "Yingbin Liang"^^schema:Person,
        "Ziwei Guan"^^schema:Person ;
    schema:dateModified "2020-06-25T03:26:15Z"^^schema:DateTime ;
    schema:datePublished "2020-06-24T06:24:37Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "When Will Generative Adversarial Imitation Learning Algorithms Attain  Global Convergence"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.13506v2"^^schema:URL .

<1003> a schema:ScholarlyArticle ;
    schema:abstract "This work deals with parallel optimization of expensive objective functionswhich are modeled as sample realizations of Gaussian processes. The study isformalized as a Bayesian optimization problem, or continuous multi-armed banditproblem, where a batch of q &gt; 0 arms is pulled in parallel at each iteration.Several algorithms have been developed for choosing batches by trading offexploitation and exploration. As of today, the maximum Expected Improvement(EI) and Upper Confidence Bound (UCB) selection rules appear as the mostprominent approaches for batch selection. Here, we build upon recent work onthe multipoint Expected Improvement criterion, for which an analytic expansionrelying on Tallis' formula was recently established. The computational burdenof this selection rule being still an issue in application, we derive aclosed-form expression for the gradient of the multipoint Expected Improvement,which aims at facilitating its maximization using gradient-based ascentalgorithms. Substantial computational savings are shown in application. Inaddition, our algorithms are tested numerically and compared tostate-of-the-art UCB-based batch-sequential algorithms. Combining startingdesigns relying on UCB with gradient-based EI local optimization finallyappears as a sound option for batch design in distributed Gaussian Processoptimization."^^schema:Text ;
    schema:author "Clément Chevalier"^^schema:Person,
        "David Ginsbourger"^^schema:Person,
        "Sébastien Marmin"^^schema:Person ;
    schema:dateModified "2019-09-02T12:56:21Z"^^schema:DateTime ;
    schema:datePublished "2015-03-18T17:45:44Z"^^schema:DateTime ;
    schema:genre "math.ST"^^schema:Text,
        "stat.ML"^^schema:Text,
        "stat.TH"^^schema:Text ;
    schema:headline "Differentiating the multipoint Expected Improvement for optimal batch  design"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1503.05509v4"^^schema:URL .

<1004> a schema:ScholarlyArticle ;
    schema:abstract "Question Answering (QA) is fundamental to natural language processing in thatmost nlp problems can be phrased as QA (Kumar et al., 2015). Current weaklysupervised memory network models that have been proposed so far struggle atanswering questions that involve relations among multiple entities (such asfacebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To addressthis problem of learning multi-argument multi-hop semantic relations for thepurpose of QA, we propose a method that combines the jointly learned long-termread-write memory and attentive inference components of end-to-end memorynetworks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vectorrepresentations encoded by a Skip-Thought model (Kiros et al., 2015). Thischoice to append Skip-Thought Vectors to the existing MemN2N framework ismotivated by the fact that Skip-Thought Vectors have been shown to accuratelymodel multi-argument semantic relations (Kiros et al., 2015)."^^schema:Text ;
    schema:author "Ethan Caballero"^^schema:Person ;
    schema:dateModified "2015-11-24T02:30:16Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T22:15:46Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Skip-Thought Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1511.06420v2"^^schema:URL .

<1005> a schema:ScholarlyArticle ;
    schema:abstract "In this work we solve for partially observable reinforcement learning (RL)environments by adding recurrency. We focus on partially observable roboticassembly tasks in the continuous action domain, with force/torque sensing beingthe only observation. We have developed a new distributed RL agent, namedRecurrent Distributed DDPG (RD2), which adds a recurrent neural network layerto Ape-X DDPG and makes two important improvements on prioritized experiencereplay to stabilize training.  We demonstrate the effectiveness of RD2 on a variety of joint assembly tasksand a partially observable version of the pendulum task from OpenAI Gym. Ourresults show that RD2 is able to achieve better performance than Ape-X DDPG andPPO with LSTM on partially observable tasks with varying complexity. We alsoshow that the trained models adapt well to different initial states anddifferent types of noise injected in the simulated environment. The videopresenting our experiments is available at https://sites.google.com/view/rd2-rl"^^schema:Text ;
    schema:author "Hui Li"^^schema:Person,
        "Jieliang Luo"^^schema:Person ;
    schema:dateModified "2020-10-15T22:33:43Z"^^schema:DateTime ;
    schema:datePublished "2020-10-15T22:33:43Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Recurrent Distributed Reinforcement Learning for Partially Observable  Robotic Assembly"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.08052v1"^^schema:URL .

<1006> a schema:ScholarlyArticle ;
    schema:abstract "Resistive random access memories (RRAM) are novel nonvolatile memorytechnologies, which can be embedded at the core of CMOS, and which could beideal for the in-memory implementation of deep neural networks. A particularlyexciting vision is using them for implementing Binarized Neural Networks(BNNs), a class of deep neural networks with a highly reduced memory footprint.The challenge of resistive memory, however, is that they are prone to devicevariation, which can lead to bit errors. In this work we show that BNNs cantolerate these bit errors to an outstanding level, through simulations ofnetworks on the MNIST and CIFAR10 tasks. If a standard BNN is used, up to 10^-4bit error rate can be tolerated with little impact on recognition performanceon both MNIST and CIFAR10. We then show that by adapting the training procedureto the fact that the BNN will be operated on error-prone hardware, thistolerance can be extended to a bit error rate of 4x10^-2. The requirements forRRAM are therefore a lot less stringent for BNNs than more traditionalapplications. We show, based on experimental measurements on a RRAM HfO2technology, that this result can allow reduce RRAM programming energy by afactor 30."^^schema:Text ;
    schema:author "Damien Querlioz"^^schema:Person,
        "Elisa Vianello"^^schema:Person,
        "Etienne Nowak"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2019-04-07T13:52:42Z"^^schema:DateTime ;
    schema:datePublished "2019-04-07T13:52:42Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "Outstanding Bit Error Tolerance of Resistive RAM-Based Binarized Neural  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.03652v1"^^schema:URL .

<1007> a schema:ScholarlyArticle ;
    schema:abstract "News recommender systems are aimed to personalize users experiences and helpthem to discover relevant articles from a large and dynamic search space.Therefore, news domain is a challenging scenario for recommendations, due toits sparse user profiling, fast growing number of items, accelerated item'svalue decay, and users preferences dynamic shift. Some promising results havebeen recently achieved by the usage of Deep Learning techniques on RecommenderSystems, specially for item's feature extraction and for session-basedrecommendations with Recurrent Neural Networks. In this paper, it is proposedan instantiation of the CHAMELEON -- a Deep Learning Meta-Architecture for NewsRecommender Systems. This architecture is composed of two modules, the firstresponsible to learn news articles representations, based on their text andmetadata, and the second module aimed to provide session-based recommendationsusing Recurrent Neural Networks. The recommendation task addressed in this workis next-item prediction for users sessions: \"what is the next most likelyarticle a user might read in a session?\" Users sessions context is leveraged bythe architecture to provide additional information in such extreme cold-startscenario of news recommendation. Users' behavior and item features are bothmerged in an hybrid recommendation approach. A temporal offline evaluationmethod is also proposed as a complementary contribution, for a more realisticevaluation of such task, considering dynamic factors that affect globalreadership interests like popularity, recency, and seasonality. Experimentswith an extensive number of session-based recommendation methods were performedand the proposed instantiation of CHAMELEON meta-architecture obtained asignificant relative improvement in top-n accuracy and ranking metrics (10% onHit Rate and 13% on MRR) over the best benchmark methods."^^schema:Text ;
    schema:author "Adilson Marques da Cunha"^^schema:Person,
        "Felipe Ferreira"^^schema:Person,
        "Gabriel de Souza P. Moreira"^^schema:Person ;
    schema:dateModified "2018-09-17T03:09:58Z"^^schema:DateTime ;
    schema:datePublished "2018-07-31T21:15:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "News Session-Based Recommendations using Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.00076v3"^^schema:URL .

<1008> a schema:ScholarlyArticle ;
    schema:abstract "Aspect category sentiment analysis (ACSA) aims to predict the sentimentpolarities of the aspect categories discussed in sentences. Since a sentenceusually discusses one or more aspect categories and expresses differentsentiments toward them, various attention-based methods have been developed toallocate the appropriate sentiment words for the given aspect category andobtain promising results. However, most of these methods directly use the givenaspect category to find the aspect category-related sentiment words, which maycause mismatching between the sentiment words and the aspect categories when anunrelated sentiment word is semantically meaningful for the given aspectcategory. To mitigate this problem, we propose a Sentence Constituent-AwareNetwork (SCAN) for aspect-category sentiment analysis. SCAN contains two graphattention modules and an interactive loss function. The graph attention modulesgenerate representations of the nodes in sentence constituency parse trees forthe aspect category detection (ACD) task and the ACSA task, respectively. ACDaims to detect aspect categories discussed in sentences and is a auxiliarytask. For a given aspect category, the interactive loss function helps the ACDtask to find the nodes which can predict the aspect category but can't predictother aspect categories. The sentiment words in the nodes then are used topredict the sentiment polarity of the aspect category by the ACSA task. Theexperimental results on five public datasets demonstrate the effectiveness ofSCAN."^^schema:Text ;
    schema:author "Cunxiang Yin"^^schema:Person,
        "Sheng-hua Zhong"^^schema:Person,
        "Yuncong Li"^^schema:Person ;
    schema:dateModified "2020-10-04T01:23:17Z"^^schema:DateTime ;
    schema:datePublished "2020-10-04T01:23:17Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Sentence Constituent-Aware Aspect-Category Sentiment Analysis with Graph  Attention Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.01461v1"^^schema:URL .

<1009> a schema:ScholarlyArticle ;
    schema:abstract "Pursuing realistic results according to human visual perception is thecentral concern in the image transformation tasks. Perceptual learningapproaches like perceptual loss are empirically powerful for such tasks butthey usually rely on the pre-trained classification network to providefeatures, which are not necessarily optimal in terms of visual perception ofimage transformation. In this paper, we argue that, among the featuresrepresentation from the pre-trained classification network, only limiteddimensions are related to human visual perception, while others are irrelevant,although both will affect the final image transformation results. Under such anassumption, we try to disentangle the perception-relevant dimensions from therepresentation through our proposed online contrastive learning. The resultednetwork includes the pre-training part and a feature selection layer, followedby the contrastive learning module, which utilizes the transformed results,target images, and task-oriented distorted images as the positive, negative,and anchor samples, respectively. The contrastive learning aims at activatingthe perception-relevant dimensions and suppressing the irrelevant ones by usingthe triplet loss, so that the original representation can be disentangled forbetter perceptual quality. Experiments on various image transformation tasksdemonstrate the superiority of our framework, in terms of human visualperception, to the existing approaches using pre-trained networks andempirically designed losses."^^schema:Text ;
    schema:author "Haoyu Wu"^^schema:Person,
        "Juncheng Li"^^schema:Person,
        "Kangfu Mei"^^schema:Person,
        "Qiaosi Yi"^^schema:Person,
        "Rui Huang"^^schema:Person,
        "Yao Lu"^^schema:Person ;
    schema:dateModified "2020-06-24T06:48:38Z"^^schema:DateTime ;
    schema:datePublished "2020-06-24T06:48:38Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Disentangle Perceptual Learning through Online Contrastive Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.13511v1"^^schema:URL .

<101> a schema:ScholarlyArticle ;
    schema:abstract "In the era of end-to-end deep learning, many advances in computer vision aredriven by large amounts of labeled data. In the optical flow setting, however,obtaining dense per-pixel ground truth for real scenes is difficult and thussuch data is rare. Therefore, recent end-to-end convolutional networks foroptical flow rely on synthetic datasets for supervision, but the domainmismatch between training and test scenarios continues to be a challenge.Inspired by classical energy-based optical flow methods, we design anunsupervised loss based on occlusion-aware bidirectional flow estimation andthe robust census transform to circumvent the need for ground truth flow. Onthe KITTI benchmarks, our unsupervised approach outperforms previousunsupervised deep networks by a large margin, and is even more accurate thansimilar supervised methods trained on synthetic datasets alone. By optionallyfine-tuning on the KITTI training data, our method achieves competitive opticalflow accuracy on the KITTI 2012 and 2015 benchmarks, thus in addition enablinggeneric pre-training of supervised networks for datasets with limited amountsof ground truth."^^schema:Text ;
    schema:author "Junhwa Hur"^^schema:Person,
        "Simon Meister"^^schema:Person,
        "Stefan Roth"^^schema:Person ;
    schema:commentCount "177"^^schema:Integer ;
    schema:dateModified "2017-11-21T15:19:26Z"^^schema:DateTime ;
    schema:datePublished "2017-11-21T15:19:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional  Census Loss"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.07837v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15341806594437855223&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1010> a schema:ScholarlyArticle ;
    schema:abstract "Video Captioning and Summarization have become very popular in the recentyears due to advancements in Sequence Modelling, with the resurgence ofLong-Short Term Memory networks (LSTMs) and introduction of Gated RecurrentUnits (GRUs). Existing architectures extract spatio-temporal features usingCNNs and utilize either GRUs or LSTMs to model dependencies with soft attentionlayers. These attention layers do help in attending to the most prominentfeatures and improve upon the recurrent units, however, these models sufferfrom the inherent drawbacks of the recurrent units themselves. The introductionof the Transformer model has driven the Sequence Modelling field into a newdirection. In this project, we implement a Transformer-based model for Videocaptioning, utilizing 3D CNN architectures like C3D and Two-stream I3D forvideo extraction. We also apply certain dimensionality reduction techniques soas to keep the overall size of the model within limits. We finally present ourresults on the MSVD and ActivityNet datasets for Single and Dense videocaptioning tasks respectively."^^schema:Text ;
    schema:author "Manjot Bilkhu"^^schema:Person,
        "Siyang Wang"^^schema:Person,
        "Tushar Dobhal"^^schema:Person ;
    schema:dateModified "2019-06-06T19:59:56Z"^^schema:DateTime ;
    schema:datePublished "2019-06-06T19:59:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Attention is all you need for Videos: Self-attention based Video  Summarization using Universal Transformers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02792v1"^^schema:URL .

<1011> a schema:ScholarlyArticle ;
    schema:abstract "Many clinical deep learning algorithms are population-based and difficult tointerpret. Such properties limit their clinical utility as population-basedfindings may not generalize to individual patients and physicians are reluctantto incorporate opaque models into their clinical workflow. To overcome theseobstacles, we propose to learn patient-specific embeddings, entitled patientcardiac prototypes (PCPs), that efficiently summarize the cardiac state of thepatient. To do so, we attract representations of multiple cardiac signals fromthe same patient to the corresponding PCP via supervised contrastive learning.We show that the utility of PCPs is multifold. First, they allow for thediscovery of similar patients both within and across datasets. Second, suchsimilarity can be leveraged in conjunction with a hypernetwork to generatepatient-specific parameters, and in turn, patient-specific diagnoses. Third, wefind that PCPs act as a compact substitute for the original dataset, allowingfor dataset distillation."^^schema:Text ;
    schema:author "Dani Kiyasseh"^^schema:Person,
        "David A. Clifton"^^schema:Person,
        "Tingting Zhu"^^schema:Person ;
    schema:dateModified "2020-11-28T22:41:27Z"^^schema:DateTime ;
    schema:datePublished "2020-11-28T22:41:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "PCPs: Patient Cardiac Prototypes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.14227v1"^^schema:URL .

<1012> a schema:ScholarlyArticle ;
    schema:abstract "Stickers with vivid and engaging expressions are becoming increasinglypopular in online messaging apps, and some works are dedicated to automaticallyselect sticker response by matching the stickers image with previousutterances. However, existing methods usually focus on measuring the matchingdegree between the dialog context and sticker image, which ignores the userpreference of using stickers. Hence, in this paper, we propose to recommend anappropriate sticker to user based on multi-turn dialog context and stickerusing history of user. Two main challenges are confronted in this task. One isto model the sticker preference of user based on the previous sticker selectionhistory. Another challenge is to jointly fuse the user preference and thematching between dialog context and candidate sticker into final predictionmaking. To tackle these challenges, we propose a \\emph{Preference EnhancedSticker Response Selector} (PESRS) model. Specifically, PESRS first employs aconvolutional based sticker image encoder and a self-attention based multi-turndialog encoder to obtain the representation of stickers and utterances. Next,deep interaction network is proposed to conduct deep matching between thesticker and each utterance. Then, we model the user preference by using therecently selected stickers as input, and use a key-value memory network tostore the preference representation. PESRS then learns the short-term andlong-term dependency between all interaction results by a fusion network, anddynamically fuse the user preference representation into the final stickerselection prediction. Extensive experiments conducted on a large-scalereal-world dialog dataset show that our model achieves the state-of-the-artperformance for all commonly-used metrics. Experiments also verify theeffectiveness of each component of PESRS."^^schema:Text ;
    schema:author "Dongyan Zhao"^^schema:Person,
        "Li Liu"^^schema:Person,
        "Rui Yan"^^schema:Person,
        "Shen Gao"^^schema:Person,
        "Xiuying Chen"^^schema:Person ;
    schema:dateModified "2020-11-05T03:31:17Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T03:31:17Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Learning to Respond with Your Favorite Stickers: A Framework of Unifying  Multi-Modality and User Preference in Multi-Turn Dialog"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03322v1"^^schema:URL .

<1013> a schema:ScholarlyArticle ;
    schema:abstract "We present a new meta-learning approach for supervised anomaly classification/ one-class classification using set equivariant networks. We focus ourexperiments on an astronomy application. Our problem setting is composed of aset of classification tasks. Each task has a (small) set of positive, labeledexamples and a larger set of unlabeled examples. We expect the positiveinstances to be much more uncommon (i.e. 'anomalies') than the negative ones('normal' class). We propose a novel use of equivariant networks for thissetting. Specifically we use Deep Sets, which was developed for point-cloudsand unordered sets and is equivariant to permutation. We propose to considerthe set of positive examples of a given task as a 'point-cloud'. The key ideais that the network directly takes as input the set of positive examples inaddition to the current example to classify. This allows the model to predictat test-time on new tasks using only positive labeled examples (i.e 'One-Classclassification' setting) by design, potentially without retraining. However,the model is trained in a meta-learning regime on a dataset of several taskswith full-supervision (positive and negative labels). This setup is motivatedby our target application on stellar streams. Streams are groups of starssharing specific properties in various features. For a detected stream, we candetermine a set of stars that likely belong to the stream. We aim tocharacterize the membership of all other nearby stars. We build a meta-datasetof simulated streams injected onto real data and evaluate on unseen syntheticstreams and one known stream. Our experiments show encouraging results toexplore furthermore equivariant networks for anomaly or 'one-class'classification in a meta-learning regime."^^schema:Text ;
    schema:author "Ademola Oladosu"^^schema:Person,
        "Adrian M. Price-Whelan"^^schema:Person,
        "Brian A. Kelly"^^schema:Person,
        "Gabriella Contardo"^^schema:Person,
        "Miles Cranmer"^^schema:Person,
        "Philip Ekfeldt"^^schema:Person,
        "Shirley Ho"^^schema:Person,
        "Tony Xu"^^schema:Person ;
    schema:dateModified "2020-09-15T18:58:18Z"^^schema:DateTime ;
    schema:datePublished "2020-07-08T22:33:09Z"^^schema:DateTime ;
    schema:genre "astro-ph.GA"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Meta-Learning for Anomaly Classification with Set Equivariant Networks:  Application in the Milky Way"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.04459v2"^^schema:URL .

<1014> a schema:ScholarlyArticle ;
    schema:abstract "Human hand actions are quite complex, especially when they involve objectmanipulation, mainly due to the high dimensionality of the hand and the vastaction space that entails. Imitating those actions with dexterous hand modelsinvolves different important and challenging steps: acquiring human handinformation, retargeting it to a hand model, and learning a policy fromacquired data. In this work, we capture the hand information by using astate-of-the-art hand pose estimator. We tackle the retargeting problem fromthe hand pose to a 29 DoF hand model by combining inverse kinematics and PSOwith a task objective optimisation. This objective encourages the virtual handto accomplish the manipulation task, relieving the effect of the estimator'snoise and the domain gap. Our approach leads to a better success rate in thegrasping task compared to our inverse kinematics baseline, allowing us torecord successful human demonstrations. Furthermore, we used thesedemonstrations to learn a policy network using generative adversarial imitationlearning (GAIL) that is able to autonomously grasp an object in the virtualspace."^^schema:Text ;
    schema:author "Dafni Antotsiou"^^schema:Person,
        "Guillermo Garcia-Hernando"^^schema:Person,
        "Tae-Kyun Kim"^^schema:Person ;
    schema:dateModified "2018-10-03T17:14:05Z"^^schema:DateTime ;
    schema:datePublished "2018-10-03T17:14:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Task-Oriented Hand Motion Retargeting for Dexterous Manipulation  Imitation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.01845v1"^^schema:URL .

<1015> a schema:ScholarlyArticle ;
    schema:abstract "We focus on the problem of teaching a robot to solve tasks presentedsequentially, i.e., in a continual learning scenario. The robot should be ableto solve all tasks it has encountered, without forgetting past tasks. Weprovide preliminary work on applying Reinforcement Learning to such setting, on2D navigation tasks for a 3 wheel omni-directional robot. Our approach takesadvantage of state representation learning and policy distillation. Policiesare trained using learned features as input, rather than raw observations,allowing better sample efficiency. Policy distillation is used to combinemultiple policies into a single one that solves all encountered tasks."^^schema:Text ;
    schema:author "David Filliat"^^schema:Person,
        "Hugo Caselles-Dupré"^^schema:Person,
        "Natalia Díaz-Rodríguez"^^schema:Person,
        "René Traoré"^^schema:Person,
        "Te Sun"^^schema:Person,
        "Timothée Lesort"^^schema:Person ;
    schema:dateModified "2019-06-11T09:06:19Z"^^schema:DateTime ;
    schema:datePublished "2019-06-11T09:06:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continual Reinforcement Learning deployed in Real-life using Policy  Distillation and Sim2Real Transfer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.04452v1"^^schema:URL .

<1016> a schema:ScholarlyArticle ;
    schema:abstract "We study the ability of Wasserstein Generative Adversarial Network (WGAN) togenerate missing audio content which is, in context, (statistically similar) tothe sound and the neighboring borders. We deal with the challenge of audioinpainting long range gaps (500 ms) using WGAN models. We improved the qualityof the inpainting part using a new proposed WGAN architecture that uses ashort-range and a long-range neighboring borders compared to the classical WGANmodel. The performance was compared with two different audio instruments (pianoand guitar) and on virtuoso pianists together with a string orchestra. Theobjective difference grading (ODG) was used to evaluate the performance of botharchitectures. The proposed model outperforms the classical WGAN model andimproves the reconstruction of high-frequency content. Further, we got betterresults for instruments where the frequency spectrum is mainly in the lowerrange where small noises are less annoying for human ear and the inpaintingpart is more perceptible. Finally, we could show that better test results foraudio dataset were reached where a particular instrument is accompanist byother instruments if we train the network only on this particular instrumentneglecting the other instruments."^^schema:Text ;
    schema:author "A. Eltelt"^^schema:Person,
        "P. P. Ebner"^^schema:Person ;
    schema:dateModified "2020-03-13T09:17:01Z"^^schema:DateTime ;
    schema:datePublished "2020-03-13T09:17:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Audio inpainting with generative adversarial network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.07704v1"^^schema:URL .

<1017> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in image clustering typically focus on learning better deeprepresentations. In contrast, we present an orthogonal approach that does notrely on abstract features but instead learns to predict image transformationsand performs clustering directly in image space. This learning processnaturally fits in the gradient-based training of K-means and Gaussian mixturemodel, without requiring any additional loss or hyper-parameters. It leads usto two new deep transformation-invariant clustering frameworks, which jointlylearn prototypes and transformations. More specifically, we use deep learningmodules that enable us to resolve invariance to spatial, color andmorphological transformations. Our approach is conceptually simple and comeswith several advantages, including the possibility to easily adapt the desiredinvariance to the task and a strong interpretability of both cluster centersand assignments to clusters. We demonstrate that our novel approach yieldscompetitive and highly promising results on standard image clusteringbenchmarks. Finally, we showcase its robustness and the advantages of itsimproved interpretability by visualizing clustering results over realphotograph collections."^^schema:Text ;
    schema:author "Mathieu Aubry"^^schema:Person,
        "Thibault Groueix"^^schema:Person,
        "Tom Monnier"^^schema:Person ;
    schema:dateModified "2020-10-27T18:08:13Z"^^schema:DateTime ;
    schema:datePublished "2020-06-19T13:43:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Transformation-Invariant Clustering"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.11132v2"^^schema:URL .

<1018> a schema:ScholarlyArticle ;
    schema:abstract "Neural architecture search (NAS) can have a significant impact in computervision by automatically designing optimal neural network architectures forvarious tasks. A variant, binarized neural architecture search (BNAS), with asearch space of binarized convolutions, can produce extremely compressedmodels. Unfortunately, this area remains largely unexplored. BNAS is morechallenging than NAS due to the learning inefficiency caused by optimizationrequirements and the huge architecture space. To address these issues, weintroduce channel sampling and operation space reduction into a differentiableNAS to significantly reduce the cost of searching. This is accomplished througha performance-based strategy used to abandon less potential operations. Twooptimization methods for binarized neural networks are used to validate theeffectiveness of our BNAS. Extensive experiments demonstrate that the proposedBNAS achieves a performance comparable to NAS on both CIFAR and ImageNetdatabases. An accuracy of $96.53\\%$ vs. $97.22\\%$ is achieved on the CIFAR-10dataset, but with a significantly compressed model, and a $40\\%$ faster searchthan the state-of-the-art PC-DARTS."^^schema:Text ;
    schema:author "Baochang Zhang"^^schema:Person,
        "David Doermann"^^schema:Person,
        "Hanlin Chen"^^schema:Person,
        "Jianzhuang Liu"^^schema:Person,
        "Li'an Zhuo"^^schema:Person,
        "Rongrong Ji"^^schema:Person,
        "Xiawu Zheng"^^schema:Person ;
    schema:dateModified "2020-02-11T11:50:28Z"^^schema:DateTime ;
    schema:datePublished "2019-11-25T12:25:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Binarized Neural Architecture Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.10862v2"^^schema:URL .

<1019> a schema:ScholarlyArticle ;
    schema:abstract "By simulating the easy-to-hard learning manners of humans/animals, thelearning regimes called curriculum learning~(CL) and self-paced learning~(SPL)have been recently investigated and invoked broad interests. However, theintrinsic mechanism for analyzing why such learning regimes can work has notbeen comprehensively investigated. To this issue, this paper proposes a concaveconjugacy theory for looking into the insight of CL/SPL. Specifically, by usingthis theory, we prove the equivalence of the SPL regime and a latent concaveobjective, which is closely related to the known non-convex regularized penaltywidely used in statistics and machine learning. Beyond the previous theory forexplaining CL/SPL insights, this new theoretical framework on one handfacilitates two direct approaches for designing new SPL models for certaintasks, and on the other hand can help conduct the latent objective ofself-paced curriculum learning, which is the advanced version of both CL/SPLand possess advantages of both learning regimes to a certain extent. Thisfurther facilitates a theoretical understanding for SPCL, instead of onlyCL/SPL as conventional. Under this theory, we attempt to attain intrinsiclatent objectives of two curriculum forms, the partial order and groupcurriculums, which easily follow the theoretical understanding of thecorresponding SPCL regimes."^^schema:Text ;
    schema:author "Deyu Meng"^^schema:Person,
        "Shiqi Liu"^^schema:Person,
        "Zilu Ma"^^schema:Person ;
    schema:dateModified "2018-05-21T14:55:25Z"^^schema:DateTime ;
    schema:datePublished "2018-05-21T14:55:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Understanding Self-Paced Learning under Concave Conjugacy Theory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.08096v1"^^schema:URL .

<102> a schema:ScholarlyArticle ;
    schema:abstract "This paper investigates strategies that defend against adversarial-exampleattacks on image-classification systems by transforming the inputs beforefeeding them to the system. Specifically, we study applying imagetransformations such as bit-depth reduction, JPEG compression, total varianceminimization, and image quilting before feeding the image to a convolutionalnetwork classifier. Our experiments on ImageNet show that total varianceminimization and image quilting are very effective defenses in practice, inparticular, when the network is trained on transformed images. The strength ofthose defenses lies in their non-differentiable nature and their inherentrandomness, which makes it difficult for an adversary to circumvent thedefenses. Our best defense eliminates 60% of strong gray-box and 90% of strongblack-box attacks by a variety of major attack methods"^^schema:Text ;
    schema:author "Chuan Guo"^^schema:Person,
        "Laurens van der Maaten"^^schema:Person,
        "Mayank Rana"^^schema:Person,
        "Moustapha Cisse"^^schema:Person ;
    schema:commentCount "394"^^schema:Integer ;
    schema:dateModified "2018-01-25T19:04:48Z"^^schema:DateTime ;
    schema:datePublished "2017-10-31T21:22:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Countering Adversarial Images using Input Transformations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00117v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3375700876994648267&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1020> a schema:ScholarlyArticle ;
    schema:abstract "The recent flourish of deep learning in various tasks is largely accreditedto the rich and accessible labeled data. Nonetheless, massive supervisionremains a luxury for many real applications, boosting great interest inlabel-scarce techniques such as few-shot learning (FSL), which aims to learnconcept of new classes with a few labeled samples. A natural approach to FSL isdata augmentation and many recent works have proved the feasibility byproposing various data synthesis models. However, these models fail to wellsecure the discriminability and diversity of the synthesized data and thusoften produce undesirable results. In this paper, we propose AdversarialFeature Hallucination Networks (AFHN) which is based on conditional WassersteinGenerative Adversarial networks (cWGAN) and hallucinates diverse anddiscriminative features conditioned on the few labeled samples. Two novelregularizers, i.e., the classification regularizer and the anti-collapseregularizer, are incorporated into AFHN to encourage discriminability anddiversity of the synthesized features, respectively. Ablation study verifiesthe effectiveness of the proposed cWGAN based feature hallucination frameworkand the proposed regularizers. Comparative results on three common benchmarkdatasets substantiate the superiority of AFHN to existing data augmentationbased FSL approaches and other state-of-the-art ones."^^schema:Text ;
    schema:author "Kai Li"^^schema:Person,
        "Kunpeng Li"^^schema:Person,
        "Yulun Zhang"^^schema:Person,
        "Yun Fu"^^schema:Person ;
    schema:dateModified "2020-10-27T19:16:50Z"^^schema:DateTime ;
    schema:datePublished "2020-03-30T02:43:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Adversarial Feature Hallucination Networks for Few-Shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.13193v2"^^schema:URL .

<1021> a schema:ScholarlyArticle ;
    schema:abstract "Medical image segmentation is a relevant task as it serves as the first stepfor several diagnosis processes, thus it is indispensable in clinical usage.Whilst major success has been reported using supervised techniques, they assumea large and well-representative labelled set. This is a strong assumption inthe medical domain where annotations are expensive, time-consuming, andinherent to human bias. To address this problem, unsupervised techniques havebeen proposed in the literature yet it is still an open problem due to thedifficulty of learning any transformation pattern. In this work, we present anovel optimisation model framed into a new CNN-based contrastive registrationarchitecture for unsupervised medical image segmentation. The core of ourapproach is to exploit image-level registration and feature-level from acontrastive learning mechanism, to perform registration-based segmentation.Firstly, we propose an architecture to capture the image-to-imagetransformation pattern via registration for unsupervised medical imagesegmentation. Secondly, we embed a contrastive learning mechanism into theregistration architecture to enhance the discriminating capacity of the networkin the feature-level. We show that our proposed technique mitigates the majordrawbacks of existing unsupervised techniques. We demonstrate, throughnumerical and visual experiments, that our technique substantially outperformsthe current state-of-the-art unsupervised segmentation methods on two majormedical image datasets."^^schema:Text ;
    schema:author "Angelica I Aviles-Rivero"^^schema:Person,
        "Carola-Bibiane Schönlieb"^^schema:Person,
        "Lihao Liu"^^schema:Person ;
    schema:dateModified "2020-11-17T19:29:08Z"^^schema:DateTime ;
    schema:datePublished "2020-11-17T19:29:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Contrastive Registration for Unsupervised Medical Image Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.08894v1"^^schema:URL .

<1022> a schema:ScholarlyArticle ;
    schema:abstract "Image registration is a process of aligning two or more images of sameobjects using geometric transformation. Most of the existing approaches work onthe assumption of location invariance. These approaches require object-centricimages to perform matching. Further, in absence of intensity level symmetrybetween the corresponding points in two images, the learning based registrationapproaches rely on synthetic deformations, which often fail in real scenarios.To address these issues, a combination of convolutional neural networks (CNNs)to perform the desired registration is developed in this work. The completeobjective is divided into three sub-objectives: object localization,segmentation and matching transformation. Object localization step establishesan initial correspondence between the images. A modified version of single shotmulti-box detector is used for this purpose. The detected region is cropped tomake the images object-centric. Subsequently, the objects are segmented andmatched using a spatial transformer network employing thin plate splinedeformation. Initial experiments on MNIST and Caltech-101 datasets show thatthe proposed model is able to produce accurate matching. Quantitativeevaluation performed using dice coefficient (DC) and mean intersection overunion (mIoU) show that proposed method results in the values of 79% and 66%,respectively for MNIST dataset and the values of 94% and 90%, respectively forCaltech-101 dataset. The proposed framework is extended to the registration ofCT and US images, which is free from any data specific assumptions and hasbetter generalization capability as compared to the existingrule-based/classical approaches."^^schema:Text ;
    schema:author "Arvinder Singh Soin"^^schema:Person,
        "Deepak Mishra"^^schema:Person,
        "Mukul Sarkar"^^schema:Person,
        "Rajeev Ranjan"^^schema:Person,
        "Santanu Chaudhury"^^schema:Person ;
    schema:dateModified "2019-01-11T12:01:54Z"^^schema:DateTime ;
    schema:datePublished "2018-05-01T07:50:25Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Localization: A Missing Link in the Pipeline of Object Matching and  Registration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.00223v2"^^schema:URL .

<1023> a schema:ScholarlyArticle ;
    schema:abstract "Grasping is a fundamental robotic task needed for the deployment of householdrobots or furthering warehouse automation. However, few approaches are able toperform grasp detection in real time (frame rate). To this effect, we presentGrasp Quality Spatial Transformer Network (GQ-STN), a one-shot grasp detectionnetwork. Being based on the Spatial Transformer Network (STN), it produces notonly a grasp configuration, but also directly outputs a depth image centered atthis configuration. By connecting our architecture to an externally-trainedgrasp robustness evaluation network, we can train efficiently to satisfy arobustness metric via the backpropagation of the gradient emanating from theevaluation network. This removes the difficulty of training detection networkson sparsely annotated databases, a common issue in grasping. We further proposeto use this robustness classifier to compare approaches, being more reliablethan the traditional rectangle metric. Our GQ-STN is able to detect robustgrasps on the depth images of the Dex-Net 2.0 dataset with 92.4 % accuracy in asingle pass of the network. We finally demonstrate in a physical benchmark thatour method can propose robust grasps more often than previous sampling-basedmethods, while being more than 60 times faster."^^schema:Text ;
    schema:author "Alexandre Gariépy"^^schema:Person,
        "Brahim Chaib-draa"^^schema:Person,
        "Jean-Christophe Ruel"^^schema:Person,
        "Philippe Giguère"^^schema:Person ;
    schema:dateModified "2019-08-01T00:56:36Z"^^schema:DateTime ;
    schema:datePublished "2019-03-06T16:53:46Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "GQ-STN: Optimizing One-Shot Grasp Detection based on Robustness  Classifier"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.02489v2"^^schema:URL .

<1024> a schema:ScholarlyArticle ;
    schema:abstract "Video-to-video synthesis (vid2vid) aims at converting an input semanticvideo, such as videos of human poses or segmentation masks, to an outputphotorealistic video. While the state-of-the-art of vid2vid has advancedsignificantly, existing approaches share two major limitations. First, they aredata-hungry. Numerous images of a target human subject or a scene are requiredfor training. Second, a learned model has limited generalization capability. Apose-to-human vid2vid model can only synthesize poses of the single person inthe training set. It does not generalize to other humans that are not in thetraining set. To address the limitations, we propose a few-shot vid2vidframework, which learns to synthesize videos of previously unseen subjects orscenes by leveraging few example images of the target at test time. Our modelachieves this few-shot generalization capability via a novel network weightgeneration module utilizing an attention mechanism. We conduct extensiveexperimental validations with comparisons to strong baselines using severallarge-scale video datasets including human-dancing videos, talking-head videos,and street-scene videos. The experimental results verify the effectiveness ofthe proposed framework in addressing the two limitations of existing vid2vidapproaches."^^schema:Text ;
    schema:author "Andrew Tao"^^schema:Person,
        "Bryan Catanzaro"^^schema:Person,
        "Guilin Liu"^^schema:Person,
        "Jan Kautz"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Ting-Chun Wang"^^schema:Person ;
    schema:dateModified "2019-10-28T14:33:09Z"^^schema:DateTime ;
    schema:datePublished "2019-10-28T14:33:09Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Few-shot Video-to-Video Synthesis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12713v1"^^schema:URL .

<1025> a schema:ScholarlyArticle ;
    schema:abstract "Recently, Neural Ordinary Differential Equations has emerged as a powerfulframework for modeling physical simulations without explicitly defining theODEs governing the system, but learning them via machine learning. However, thequestion: Can Bayesian learning frameworks be integrated with Neural ODEs torobustly quantify the uncertainty in the weights of a Neural ODE? remainsunanswered. In an effort to address this question, we demonstrate thesuccessful integration of Neural ODEs with two methods of Bayesian Inference:(a) The No-U-Turn MCMC sampler (NUTS) and (b) Stochastic Langevin GradientDescent (SGLD). We test the performance of our Bayesian Neural ODE approach onclassical physical systems, as well as on standard machine learning datasetslike MNIST, using GPU acceleration. Finally, considering a simple example, wedemonstrate the probabilistic identification of model specification inpartially-described dynamical systems using universal ordinary differentialequations. Together, this gives a scientific machine learning tool forprobabilistic estimation of epistemic uncertainties."^^schema:Text ;
    schema:author "Aslan Garcia-Valadez"^^schema:Person,
        "Chris Rackauckas"^^schema:Person,
        "Mohamed Tarek"^^schema:Person,
        "Raj Dandekar"^^schema:Person,
        "Vaibhav Dixit"^^schema:Person ;
    schema:dateModified "2020-12-20T18:27:25Z"^^schema:DateTime ;
    schema:datePublished "2020-12-14T04:05:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Bayesian Neural Ordinary Differential Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.07244v2"^^schema:URL .

<1026> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, due to the emergence of deep learning, face recognition hasachieved exceptional success. However, many of these deep face recognitionmodels perform relatively poorly in handling profile faces compared to frontalfaces. The major reason for this poor performance is that it is inherentlydifficult to learn large pose invariant deep representations that are usefulfor profile face recognition. In this paper, we hypothesize that the profileface domain possesses a gradual connection with the frontal face domain in thedeep feature space. We look to exploit this connection by projecting theprofile faces and frontal faces into a common latent space and performverification or retrieval in the latent domain. We leverage a coupledgenerative adversarial network (cpGAN) structure to find the hiddenrelationship between the profile and frontal images in a latent commonembedding subspace. Specifically, the cpGAN framework consists of two GAN-basedsub-networks, one dedicated to the frontal domain and the other dedicated tothe profile domain. Each sub-network tends to find a projection that maximizesthe pair-wise correlation between two feature domains in a common embeddingfeature subspace. The efficacy of our approach compared with thestate-of-the-art is demonstrated using the CFP, CMU MultiPIE, IJB-A, and IJB-Cdatasets."^^schema:Text ;
    schema:author "Fariborz Taherkhani"^^schema:Person,
        "Jeremy Dawson"^^schema:Person,
        "Matthew C. Valenti"^^schema:Person,
        "Nasser M. Nasrabadi"^^schema:Person,
        "Veeru Talreja"^^schema:Person ;
    schema:dateModified "2020-04-25T09:01:54Z"^^schema:DateTime ;
    schema:datePublished "2020-04-25T09:01:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "PF-cpGAN: Profile to Frontal Coupled GAN for Face Recognition in the  Wild"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.02166v1"^^schema:URL .

<1027> a schema:ScholarlyArticle ;
    schema:abstract "Lots of neural network architectures have been proposed to deal with learningtasks on graph-structured data. However, most of these models concentrate ononly node features during the learning process. The edge features, whichusually play a similarly important role as the nodes, are often ignored orsimplified by these models. In this paper, we present edge-featured graphattention networks, namely EGATs, to extend the use of graph neural networks tothose tasks learning on graphs with both node and edge features. These modelscan be regarded as extensions of graph attention networks (GATs). By reformingthe model structure and the learning process, the new models can accept nodeand edge features as inputs, incorporate the edge information into featurerepresentations, and iterate both node and edge features in a parallel butmutual way. The results demonstrate that our work is highly competitive againstother node classification approaches, and can be well applied in edge-featuredgraph learning tasks."^^schema:Text ;
    schema:author "Haopeng Chen"^^schema:Person,
        "Jun Chen"^^schema:Person ;
    schema:dateModified "2021-01-19T15:08:12Z"^^schema:DateTime ;
    schema:datePublished "2021-01-19T15:08:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Edge-Featured Graph Attention Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.07671v1"^^schema:URL .

<1028> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we introduce Kathaka, a model trained with a novel two-stagetraining process for neural speech synthesis with contextually appropriateprosody. In Stage I, we learn a prosodic distribution at the sentence levelfrom mel-spectrograms available during training. In Stage II, we propose anovel method to sample from this learnt prosodic distribution using thecontextual information available in text. To do this, we use BERT on text, andgraph-attention networks on parse trees extracted from text. We show astatistically significant relative improvement of $13.2\\%$ in naturalness overa strong baseline when compared to recordings. We also conduct an ablationstudy on variations of our sampling technique, and show a statisticallysignificant improvement over the baseline in each case."^^schema:Text ;
    schema:author "Alexis Moinet"^^schema:Person,
        "Ammar Abbas"^^schema:Person,
        "Arnaud Joly"^^schema:Person,
        "Penny Karanasou"^^schema:Person,
        "Sri Karlapati"^^schema:Person,
        "Thomas Drugman"^^schema:Person,
        "Zack Hodari"^^schema:Person ;
    schema:dateModified "2020-11-04T12:20:21Z"^^schema:DateTime ;
    schema:datePublished "2020-11-04T12:20:21Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Prosodic Representation Learning and Contextual Sampling for Neural  Text-to-Speech"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02252v1"^^schema:URL .

<1029> a schema:ScholarlyArticle ;
    schema:abstract "The Federated Learning setting has a central server coordinating the trainingof a model on a network of devices. One of the challenges is variable trainingperformance when the dataset has a class imbalance. In this paper, we addressthis by introducing a new loss function called Fed-Focal Loss. We propose toaddress the class imbalance by reshaping cross-entropy loss such that itdown-weights the loss assigned to well-classified examples along the lines offocal loss. Additionally, by leveraging a tunable sampling framework, we takeinto account selective client model contributions on the central server tofurther focus the detector during training and hence improve its robustness.Using a detailed experimental analysis with the VIRTUAL (Variational FederatedMulti-Task Learning) approach, we demonstrate consistently superior performancein both the balanced and unbalanced scenarios for MNIST, FEMNIST, VSN and HARbenchmarks. We obtain a more than 9% (absolute percentage) improvement in theunbalanced MNIST benchmark. We further show that our technique can be adoptedacross multiple Federated Learning algorithms to get improvements."^^schema:Text ;
    schema:author "Ankur Narang"^^schema:Person,
        "Dipankar Sarkar"^^schema:Person,
        "Sumit Rai"^^schema:Person ;
    schema:dateModified "2020-11-12T09:52:14Z"^^schema:DateTime ;
    schema:datePublished "2020-11-12T09:52:14Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Fed-Focal Loss for imbalanced data classification in Federated Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.06283v1"^^schema:URL .

<103> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a new structured kernel interpolation (SKI) framework, whichgeneralises and unifies inducing point methods for scalable Gaussian processes(GPs). SKI methods produce kernel approximations for fast computations throughkernel interpolation. The SKI framework clarifies how the quality of aninducing point approach depends on the number of inducing (aka interpolation)points, interpolation strategy, and GP covariance kernel. SKI also provides amechanism to create new scalable kernel methods, through choosing differentkernel interpolation strategies. Using SKI, with local cubic kernelinterpolation, we introduce KISS-GP, which is 1) more scalable than inducingpoint alternatives, 2) naturally enables Kronecker and Toeplitz algebra forsubstantial additional gains in scalability, without requiring any grid data,and 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n)time and storage for GP inference. We evaluate KISS-GP for kernel matrixapproximation, kernel learning, and natural sound modelling."^^schema:Text ;
    schema:author "Andrew Gordon Wilson"^^schema:Person,
        "Hannes Nickisch"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2015-03-03T19:06:17Z"^^schema:DateTime ;
    schema:datePublished "2015-03-03T19:06:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Kernel Interpolation for Scalable Structured Gaussian Processes  (KISS-GP)"^^schema:Text ;
    schema:publisher "ICML, 1775-1784"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.01057v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10688700732600694368&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1030> a schema:ScholarlyArticle ;
    schema:abstract "Precise estimation of the probabilistic structure of natural images plays anessential role in image compression. Despite the recent remarkable success ofend-to-end optimized image compression, the latent codes are usually assumed tobe fully statistically factorized in order to simplify entropy modeling.However, this assumption generally does not hold true and may hindercompression performance. Here we present context-based convolutional networks(CCNs) for efficient and effective entropy modeling. In particular, a 3D zigzagscanning order and a 3D code dividing technique are introduced to define propercoding contexts for parallel entropy decoding, both of which boil down to placetranslation-invariant binary masks on convolution filters of CCNs. Wedemonstrate the promise of CCNs for entropy modeling in both lossless and lossyimage compression. For the former, we directly apply a CCN to the binarizedrepresentation of an image to compute the Bernoulli distribution of each codefor entropy estimation. For the latter, the categorical distribution of eachcode is represented by a discretized mixture of Gaussian distributions, whoseparameters are estimated by three CCNs. We then jointly optimize the CCN-basedentropy model along with analysis and synthesis transforms for rate-distortionperformance. Experiments on the Kodak and Tecnick datasets show that ourmethods powered by the proposed CCNs generally achieve comparable compressionperformance to the state-of-the-art while being much faster."^^schema:Text ;
    schema:author "David Zhang"^^schema:Person,
        "Jane You"^^schema:Person,
        "Kede Ma"^^schema:Person,
        "Mu Li"^^schema:Person,
        "Wangmeng Zuo"^^schema:Person ;
    schema:dateModified "2020-03-28T17:26:12Z"^^schema:DateTime ;
    schema:datePublished "2019-06-24T16:26:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Efficient and Effective Context-Based Convolutional Entropy Modeling for  Image Compression"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.10057v2"^^schema:URL .

<1031> a schema:ScholarlyArticle ;
    schema:abstract "Argumentation is a type of discourse where speakers try to persuade theiraudience about the reasonableness of a claim by presenting supportivearguments. Most work in argument mining has focused on modeling arguments inmonologues. We propose a computational model for argument mining in onlinepersuasive discussion forums that brings together the micro-level (argument asproduct) and macro-level (argument as process) models of argumentation.Fundamentally, this approach relies on identifying relations between componentsof arguments in a discussion thread. Our approach for relation prediction usescontextual information in terms of fine-tuning a pre-trained language model andleveraging discourse relations based on Rhetorical Structure Theory. Weadditionally propose a candidate selection method to automatically predict whatparts of one's argument will be targeted by other participants in thediscussion. Our models obtain significant improvements compared to recentstate-of-the-art approaches using pointer networks and a pre-trained languagemodel."^^schema:Text ;
    schema:author "Alyssa Hwang"^^schema:Person,
        "Christopher Hidey"^^schema:Person,
        "Kathy Mckeown"^^schema:Person,
        "Smaranda Muresan"^^schema:Person,
        "Tuhin Chakrabarty"^^schema:Person ;
    schema:dateModified "2020-04-30T10:33:40Z"^^schema:DateTime ;
    schema:datePublished "2020-04-30T10:33:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "AMPERSAND: Argument Mining for PERSuAsive oNline Discussions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.14677v1"^^schema:URL .

<1032> a schema:ScholarlyArticle ;
    schema:abstract "Semantic parsing over multiple knowledge bases enables a parser to exploitstructural similarities of programs across the multiple domains. However, thefundamental challenge lies in obtaining high-quality annotations of (utterance,program) pairs across various domains needed for training such models. Toovercome this, we propose a novel framework to build a unified multi-domainenabled semantic parser trained only with weak supervision (denotations).Weakly supervised training is particularly arduous as the program search spacegrows exponentially in a multi-domain setting. To solve this, we incorporate amulti-policy distillation mechanism in which we first train domain-specificsemantic parsers (teachers) using weak supervision in the absence of the groundtruth programs, followed by training a single unified parser (student) from thedomain specific policies obtained from these teachers. The resultant semanticparser is not only compact but also generalizes better, and generates moreaccurate programs. It further does not require the user to provide a domainlabel while querying. On the standard Overnight dataset (containing multipledomains), we demonstrate that the proposed model improves performance by 20% interms of denotation accuracy in comparison to baseline techniques."^^schema:Text ;
    schema:author "Abhishek Bansal"^^schema:Person,
        "Ashish Mittal"^^schema:Person,
        "Ayushi Dalmia"^^schema:Person,
        "Karthik Sankaranarayanan"^^schema:Person,
        "Parag Jain"^^schema:Person,
        "Priyanka Agrawal"^^schema:Person ;
    schema:dateModified "2019-06-12T11:27:38Z"^^schema:DateTime ;
    schema:datePublished "2019-06-12T11:27:38Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unified Semantic Parsing with Weak Supervision"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.05062v1"^^schema:URL .

<1033> a schema:ScholarlyArticle ;
    schema:abstract "Recent work achieved remarkable results in training neural machinetranslation (NMT) systems in a fully unsupervised way, with new and dedicatedarchitectures that rely on monolingual corpora only. In this work, we proposeto define unsupervised NMT (UNMT) as NMT trained with the supervision ofsynthetic bilingual data. Our approach straightforwardly enables the use ofstate-of-the-art architectures proposed for supervised NMT by replacinghuman-made bilingual data with synthetic bilingual data for training. Wepropose to initialize the training of UNMT with synthetic bilingual datagenerated by unsupervised statistical machine translation (USMT). The UNMTsystem is then incrementally improved using back-translation. Our preliminaryexperiments show that our approach achieves a new state-of-the-art forunsupervised machine translation on the WMT16 German--English news translationtask, for both translation directions."^^schema:Text ;
    schema:author "Atsushi Fujita"^^schema:Person,
        "Benjamin Marie"^^schema:Person ;
    schema:dateModified "2018-10-30T12:33:03Z"^^schema:DateTime ;
    schema:datePublished "2018-10-30T12:33:03Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Unsupervised Neural Machine Translation Initialized by Unsupervised  Statistical Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.12703v1"^^schema:URL .

<1034> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning models trained in one domain perform poorly in the otherdomains due to the existence of domain shift. Domain adaptation techniquessolve this problem by training transferable models from the label-rich sourcedomain to the label-scarce target domain. Unfortunately, a majority of theexisting domain adaptation techniques rely on the availability of target-domaindata, and thus limit their applications to a small community across fewcomputer vision problems. In this paper, we tackle the challenging zero-shotdomain adaptation (ZSDA) problem, where target-domain data is non-available inthe training stage. For this purpose, we propose conditional coupled generativeadversarial networks (CoCoGAN) by extending the coupled generative adversarialnetworks (CoGAN) into a conditioning model. Compared with the existing state ofthe arts, our proposed CoCoGAN is able to capture the joint distribution ofdual-domain samples in two different tasks, i.e. the relevant task (RT) and anirrelevant task (IRT). We train CoCoGAN with both source-domain samples in RTand dual-domain samples in IRT to complete the domain adaptation. While theformer provide high-level concepts of the non-available target-domain data, thelatter carry the sharing correlation between the two domains in RT and IRT. Totrain CoCoGAN in the absence of target-domain data for RT, we propose a newsupervisory signal, i.e. the alignment between representations across tasks.Extensive experiments carried out demonstrate that our proposed CoCoGANoutperforms existing state of the arts in image classifications."^^schema:Text ;
    schema:author "Jianmin Jiang"^^schema:Person,
        "Jinghua Wang"^^schema:Person ;
    schema:dateModified "2020-09-11T04:36:42Z"^^schema:DateTime ;
    schema:datePublished "2020-09-11T04:36:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Conditional Coupled Generative Adversarial Networks for Zero-Shot Domain  Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.05228v1"^^schema:URL .

<1035> a schema:ScholarlyArticle ;
    schema:abstract "Cardiac motion estimation and segmentation play important roles inquantitatively assessing cardiac function and diagnosing cardiovasculardiseases. In this paper, we propose a novel deep learning method for jointestimation of motion and segmentation from cardiac MR image sequences. Theproposed network consists of two branches: a cardiac motion estimation branchwhich is built on a novel unsupervised Siamese style recurrent spatialtransformer network, and a cardiac segmentation branch that is based on a fullyconvolutional network. In particular, a joint multi-scale feature encoder islearned by optimizing the segmentation branch and the motion estimation branchsimultaneously. This enables the weakly-supervised segmentation by takingadvantage of features that are unsupervisedly learned in the motion estimationbranch from a large amount of unannotated data. Experimental results usingcardiac MRI images from 220 subjects show that the joint learning of both tasksis complementary and the proposed models outperform the competing methodssignificantly in terms of accuracy and speed."^^schema:Text ;
    schema:author "Chen Qin"^^schema:Person,
        "Daniel Rueckert"^^schema:Person,
        "Jo Schlemper"^^schema:Person,
        "Stefan K. Piechnik"^^schema:Person,
        "Stefan Neubauer"^^schema:Person,
        "Steffen E. Petersen"^^schema:Person,
        "Wenjia Bai"^^schema:Person ;
    schema:dateModified "2018-06-11T15:45:47Z"^^schema:DateTime ;
    schema:datePublished "2018-06-11T15:45:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Joint Learning of Motion Estimation and Segmentation for Cardiac MR  Image Sequences"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.04066v1"^^schema:URL .

<1036> a schema:ScholarlyArticle ;
    schema:abstract "This article provides an interesting exploration of character-levelconvolutional neural network solving Chinese corpus text classificationproblem. We constructed a large-scale Chinese language dataset, and the resultshows that character-level convolutional neural network works better on Chinesecorpus than its corresponding pinyin format dataset. This is the first timethat character-level convolutional neural network applied to textclassification problem."^^schema:Text ;
    schema:author "Jun Wang"^^schema:Person,
        "Weijie Huang"^^schema:Person ;
    schema:dateModified "2016-11-15T14:41:23Z"^^schema:DateTime ;
    schema:datePublished "2016-11-14T12:24:27Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Character-level Convolutional Network for Text Classification Applied to  Chinese Corpus"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.04358v2"^^schema:URL .

<1037> a schema:ScholarlyArticle ;
    schema:abstract "Partial person re-identification (ReID) is a challenging task because onlypartial information of person images is available for matching target persons.Few studies, especially on deep learning, have focused on matching partialperson images with holistic person images. This study presents a novel deeppartial ReID framework based on pairwise spatial transformer networks(STNReID), which can be trained on existing holistic person datasets. STNReIDincludes a spatial transformer network (STN) module and a ReID module. The STNmodule samples an affined image (a semantically corresponding patch) from theholistic image to match the partial image. The ReID module extracts thefeatures of the holistic, partial, and affined images. Competition (orconfrontation) is observed between the STN module and the ReID module, andtwo-stage training is applied to acquire a strong STNReID for partial ReID.Experimental results show that our STNReID obtains 66.7% and 54.6% rank-1accuracies on partial ReID and partial iLIDS datasets, respectively. Thesevalues are at par with those obtained with state-of-the-art methods."^^schema:Text ;
    schema:author "Chi Zhang"^^schema:Person,
        "Hao Luo"^^schema:Person,
        "Wei Jiang"^^schema:Person,
        "Xing Fan"^^schema:Person ;
    schema:dateModified "2020-01-07T10:31:00Z"^^schema:DateTime ;
    schema:datePublished "2019-03-17T12:36:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "STNReID : Deep Convolutional Networks with Pairwise Spatial Transformer  Networks for Partial Person Re-identification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.07072v2"^^schema:URL .

<1038> a schema:ScholarlyArticle ;
    schema:abstract "Safe reinforcement learning (SRL) problems are typically modeled asconstrained Markov Decision Process (CMDP), in which an agent explores theenvironment to maximize the expected total reward and meanwhile avoidsviolating certain constraints on a number of expected total costs. In general,such SRL problems have nonconvex objective functions subject to multiplenonconvex constraints, and hence are very challenging to solve, particularly toprovide a globally optimal policy. Many popular SRL algorithms adopt aprimal-dual structure which utilizes the updating of dual variables forsatisfying the constraints. In contrast, we propose a primal approach, calledconstraint-rectified policy optimization (CRPO), which updates the policyalternatingly between objective improvement and constraint satisfaction. CRPOprovides a primal-type algorithmic framework to solve SRL problems, where eachpolicy update can take any variant of policy optimization step. To demonstratethe theoretical performance of CRPO, we adopt natural policy gradient (NPG) foreach policy update step and show that CRPO achieves an$\\mathcal{O}(1/\\sqrt{T})$ convergence rate to the global optimal policy in theconstrained policy set and an $\\mathcal{O}(1/\\sqrt{T})$ error bound onconstraint satisfaction. This is the first finite-time analysis of SRLalgorithms with global optimality guarantee. Our empirical results demonstratethat CRPO can outperform the existing primal-dual baseline algorithmssignificantly."^^schema:Text ;
    schema:author "Guanghui Lan"^^schema:Person,
        "Tengyu Xu"^^schema:Person,
        "Yingbin Liang"^^schema:Person ;
    schema:dateModified "2020-11-17T21:24:18Z"^^schema:DateTime ;
    schema:datePublished "2020-11-11T16:05:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Primal Approach to Constrained Policy Optimization: Global Optimality  and Finite-Time Analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05869v2"^^schema:URL .

<1039> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning has emerged as an effective approach for creating modernsoftware systems, with neural networks often surpassing hand-crafted systems.Unfortunately, neural networks are known to suffer from various safety andsecurity issues. Formal verification is a promising avenue for tackling thisdifficulty, by formally certifying that networks are correct. We propose anSMT-based technique for verifying Binarized Neural Networks - a popular kind ofneural network, where some weights have been binarized in order to render theneural network more memory and energy efficient, and quicker to evaluate. Onenovelty of our technique is that it allows the verification of neural networksthat include both binarized and non-binarized components. Neural networkverification is computationally very difficult, and so we propose here variousoptimizations, integrated into our SMT procedure as deduction steps, as well asan approach for parallelizing verification queries. We implement our techniqueas an extension to the Marabou framework, and use it to evaluate the approachon popular binarized neural network architectures."^^schema:Text ;
    schema:author "Clark Barrett"^^schema:Person,
        "Guy Amir"^^schema:Person,
        "Guy Katz"^^schema:Person,
        "Haoze Wu"^^schema:Person ;
    schema:dateModified "2021-01-17T08:41:37Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T16:21:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "An SMT-Based Approach for Verifying Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02948v2"^^schema:URL .

<104> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks have been successfully applied in applications with a largeamount of labeled data. However, the task of rapid generalization on newconcepts with small training data while preserving performances on previouslylearned ones still presents a significant challenge to neural network models.In this work, we introduce a novel meta learning method, Meta Networks(MetaNet), that learns a meta-level knowledge across tasks and shifts itsinductive biases via fast parameterization for rapid generalization. Whenevaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achievea near human-level performance and outperform the baseline approaches by up to6% accuracy. We demonstrate several appealing properties of MetaNet relating togeneralization and continual learning."^^schema:Text ;
    schema:author "Hong Yu"^^schema:Person,
        "Tsendsuren Munkhdalai"^^schema:Person ;
    schema:commentCount "274"^^schema:Integer ;
    schema:dateModified "2017-06-08T16:12:40Z"^^schema:DateTime ;
    schema:datePublished "2017-03-02T15:52:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Meta Networks"^^schema:Text ;
    schema:publisher "ICML, 2554-2563"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00837v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=373430955020553964&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1040> a schema:ScholarlyArticle ;
    schema:abstract "Audio-Visual Scene-Aware Dialog (AVSD) is an extension from Video QuestionAnswering (QA) whereby the dialogue agent is required to generate naturallanguage responses to address user queries and carry on conversations. This isa challenging task as it consists of video features of multiple modalities,including text, visual, and audio features. The agent also needs to learnsemantic dependencies among user utterances and system responses to makecoherent conversations with humans. In this work, we describe our submission tothe AVSD track of the 8th Dialogue System Technology Challenge. We adoptdot-product attention to combine text and non-text features of input video. Wefurther enhance the generation capability of the dialogue agent by adoptingpointer networks to point to tokens from multiple source sequences in eachgeneration step. Our systems achieve high performance in automatic metrics andobtain 5th and 6th place in human evaluation among all submissions."^^schema:Text ;
    schema:author "Hung Le"^^schema:Person,
        "Nancy F. Chen"^^schema:Person ;
    schema:dateModified "2020-02-25T06:41:07Z"^^schema:DateTime ;
    schema:datePublished "2020-02-25T06:41:07Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.10695v1"^^schema:URL .

<1041> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial networks (GANs) have given us a great tool to fitimplicit generative models to data. Implicit distributions are ones we cansample from easily, and take derivatives of samples with respect to modelparameters. These models are highly expressive and we argue they can prove justas useful for variational inference (VI) as they are for generative modelling.Several papers have proposed GAN-like algorithms for inference, however,connections to the theory of VI are not always well understood. This paperprovides a unifying review of existing algorithms establishing connectionsbetween variational autoencoders, adversarially learned inference, operator VI,GAN-based image reconstruction, and more. Secondly, the paper provides aframework for building new algorithms: depending on the way the variationalbound is expressed we introduce prior-contrastive and joint-contrastivemethods, and show practical inference algorithms based on either density ratioestimation or denoising."^^schema:Text ;
    schema:author "Ferenc Huszár"^^schema:Person ;
    schema:dateModified "2017-02-27T11:16:54Z"^^schema:DateTime ;
    schema:datePublished "2017-02-27T11:16:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Inference using Implicit Distributions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.08235v1"^^schema:URL .

<1042> a schema:ScholarlyArticle ;
    schema:abstract "As a dynamic and essential component in the road environment of urbanscenarios, vehicles are the most popular investigation targets. To monitortheir behavior and extract their geometric characteristics, an accurate andinstant measurement of vehicles plays a vital role in traffic andtransportation fields. Point clouds acquired from the mobile laser scanning(MLS) system deliver 3D information of road scenes with unprecedented detail.They have proven to be an adequate data source in the fields of intelligenttransportation and autonomous driving, especially for extracting vehicles.However, acquired 3D point clouds of vehicles from MLS systems are inevitablyincomplete due to object occlusion or self-occlusion. To tackle this problem,we proposed a neural network to synthesize complete, dense, and uniform pointclouds for vehicles from MLS data, named Vehicle Points Completion-Net(VPC-Net). In this network, we introduce a new encoder module to extract globalfeatures from the input instance, consisting of a spatial transformer networkand point feature enhancement layer. Moreover, a new refiner module is alsopresented to preserve the vehicle details from inputs and refine the completeoutputs with fine-grained information. Given sparse and partial point clouds asinputs, the network can generate complete and realistic vehicle structures andkeep the fine-grained details from the partial inputs. We evaluated theproposed VPC-Net in different experiments using synthetic and real-scandatasets and applied the results to 3D vehicle monitoring tasks. Quantitativeand qualitative experiments demonstrate the promising performance of theproposed VPC-Net and show state-of-the-art results."^^schema:Text ;
    schema:author "Cheng Wang"^^schema:Person,
        "Uwe Stilla"^^schema:Person,
        "Yan Xia"^^schema:Person,
        "Yusheng Xu"^^schema:Person ;
    schema:dateModified "2021-02-01T16:32:40Z"^^schema:DateTime ;
    schema:datePublished "2020-08-08T00:22:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "VPC-Net: Completion of 3D Vehicles from MLS Point Clouds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.03404v2"^^schema:URL .

<1043> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new family of policy gradient methods for reinforcementlearning, which alternate between sampling data through interaction with theenvironment, and optimizing a \"surrogate\" objective function using stochasticgradient ascent. Whereas standard policy gradient methods perform one gradientupdate per data sample, we propose a novel objective function that enablesmultiple epochs of minibatch updates. The new methods, which we call proximalpolicy optimization (PPO), have some of the benefits of trust region policyoptimization (TRPO), but they are much simpler to implement, more general, andhave better sample complexity (empirically). Our experiments test PPO on acollection of benchmark tasks, including simulated robotic locomotion and Atarigame playing, and we show that PPO outperforms other online policy gradientmethods, and overall strikes a favorable balance between sample complexity,simplicity, and wall-time."^^schema:Text ;
    schema:author "Alec Radford"^^schema:Person,
        "Filip Wolski"^^schema:Person,
        "John Schulman"^^schema:Person,
        "Oleg Klimov"^^schema:Person,
        "Prafulla Dhariwal"^^schema:Person ;
    schema:dateModified "2017-08-28T09:20:06Z"^^schema:DateTime ;
    schema:datePublished "2017-07-20T02:32:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Proximal Policy Optimization Algorithms"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.06347v2"^^schema:URL .

<1044> a schema:ScholarlyArticle ;
    schema:abstract "This article identifies and characterises political narratives regardingEurope and broadcasted in UK press during 2016 and 2017. A new theoretical andoperational framework is proposed for typifying discourse narratives propagatedin the public opinion space, based on the social constructivism and structurallinguistics approaches, and the mathematical theory of hypernetworks, whereelementary units are aggregated into high-level entities. In this line ofthought, a narrative is understood as a social construct where a related andcoherent aggregate of terms within public discourse is repeated and propagatedon media until it can be identified as a communication pattern, embodyingmeaning in a way that provides individuals some interpretation of their world.An inclusive methodology, with state-of-the-art technologies on naturallanguage processing and network theory, implements this concept of narrative. Acorpus from the Observatorium database, including articles from six UKnewspapers and incorporating far-right, right-wing, and left-wing narratives,is analysed. The research revealed clear distinctions between narratives alongthe political spectrum. In 2016 far-right was particularly focused onemigration and refugees. Namely, during the referendum campaign, Europe wasrelated to attacks on women and children, sexual offences, and terrorism.Right-wing was manly focused on internal politics, while left-wing wasremarkably mentioning a diversity of non-political topics, such as sports, sideby side with economics. During 2017, in general terrorism was less mentioned,and negotiations with EU, namely regarding economics, finance, and Ireland,became central."^^schema:Text ;
    schema:author "António Fonseca"^^schema:Person,
        "Jorge Louçã"^^schema:Person ;
    schema:dateModified "2019-02-22T17:02:18Z"^^schema:DateTime ;
    schema:datePublished "2019-02-22T17:02:18Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CY"^^schema:Text ;
    schema:headline "Topology and dynamics of narratives on Brexit propagated by UK press  during 2016 and 2017"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.08558v1"^^schema:URL .

<1045> a schema:ScholarlyArticle ;
    schema:abstract "While post-training model compression can greatly reduce the inference costof a deep neural network, uncompressed training still consumes a huge amount ofhardware resources, run-time and energy. It is highly desirable to directlytrain a compact neural network from scratch with low memory and lowcomputational cost. Low-rank tensor decomposition is one of the most effectiveapproaches to reduce the memory and computing requirements of large-size neuralnetworks. However, directly training a low-rank tensorized neural network is avery challenging task because it is hard to determine a proper tensor rank {\\ita priori}, which controls the model complexity and compression ratio in thetraining process. This paper presents a novel end-to-end framework for low-ranktensorized training of neural networks. We first develop a flexible Bayesianmodel that can handle various low-rank tensor formats (e.g., CP, Tucker, tensortrain and tensor-train matrix) that compress neural network parameters intraining. This model can automatically determine the tensor ranks inside anonlinear forward model, which is beyond the capability of existing Bayesiantensor methods. We further develop a scalable stochastic variational inferencesolver to estimate the posterior density of large-scale problems in training.Our work provides the first general-purpose rank-adaptive framework forend-to-end tensorized training. Our numerical results on various neural networkarchitectures show orders-of-magnitude parameter reduction and little accuracyloss (or even better accuracy) in the training process. Specifically, on a verylarge deep learning recommendation system with over $4.2\\times 10^9$ modelparameters, our method can reduce the variables to only $1.6\\times 10^5$automatically in the training process (i.e., by $2.6\\times 10^4$ times) whileachieving almost the same accuracy."^^schema:Text ;
    schema:author "Cole Hawkins"^^schema:Person,
        "Xing Liu"^^schema:Person,
        "Zheng Zhang"^^schema:Person ;
    schema:dateModified "2020-12-27T18:50:15Z"^^schema:DateTime ;
    schema:datePublished "2020-10-17T01:23:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Compact Neural Networks via End-to-End Training: A Bayesian  Tensor Approach with Automatic Rank Determination"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.08689v2"^^schema:URL .

<1046> a schema:ScholarlyArticle ;
    schema:abstract "Neural Ordinary Differential Equations replace the right-hand side of aconventional ODE with a neural net, which by virtue of the universalapproximation theorem, can be trained to the representation of any function.When we do not know the function itself, but have state trajectories (timeevolution) of the ODE system we can still train the neural net to learn therepresentation of the underlying but unknown ODE. However if the state of thesystem is incompletely known then the right-hand side of the ODE cannot becalculated. The derivatives to propagate the system are unavailable. We showthat a specially augmented Neural ODE can learn the system when givenincomplete state information. As a worked example we apply neural ODEs to theLotka-Voltera problem of 3 species, rabbits, wolves, and bears. We show thateven when the data for the bear time series is removed the remaining timeseries of the rabbits and wolves is sufficient to learn the dynamical systemdespite the missing the incomplete state information. This is surprising sincea conventional ODE system cannot output the correct derivatives without thefull state as the input. We implement augmented neural ODEs and differentialequation solvers in the julia programming language."^^schema:Text ;
    schema:author "Robert Strauss"^^schema:Person ;
    schema:dateModified "2020-08-22T02:59:26Z"^^schema:DateTime ;
    schema:datePublished "2020-08-19T02:21:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "physics.comp-ph"^^schema:Text,
        "q-bio.NC"^^schema:Text ;
    schema:headline "Augmenting Neural Differential Equations to Model Unknown Dynamical  Systems with Incomplete State Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.08226v3"^^schema:URL .

<1047> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we investigate the cause of the high false positive rate inVisual Relationship Detection (VRD). We observe that during training, therelationship proposal distribution is highly imbalanced: most of the negativerelationship proposals are easy to identify, e.g., the inaccurate objectdetection, which leads to the under-fitting of low-frequency difficultproposals. This paper presents Spatially-Aware Balanced negative pRoposalsAmpling (SABRA), a robust VRD framework that alleviates the influence of falsepositives. To effectively optimize the model under imbalanced distribution,SABRA adopts Balanced Negative Proposal Sampling (BNPS) strategy for mini-batchsampling. BNPS divides proposals into 5 well defined sub-classes and generatesa balanced training distribution according to the inverse frequency. BNPS givesan easier optimization landscape and significantly reduces the number of falsepositives. To further resolve the low-frequency challenging false positiveproposals with high spatial ambiguity, we improve the spatial modeling abilityof SABRA on two aspects: a simple and efficient multi-head heterogeneous graphattention network (MH-GAT) that models the global spatial interactions ofobjects, and a spatial mask decoder that learns the local spatialconfiguration. SABRA outperforms SOTA methods by a large margin on twohuman-object interaction (HOI) datasets and one general VRD dataset."^^schema:Text ;
    schema:author "Chongzhi Zhang"^^schema:Person,
        "Daisheng Jin"^^schema:Person,
        "Haiyu Zhao"^^schema:Person,
        "Hongsheng Li"^^schema:Person,
        "Jiashu Tao"^^schema:Person,
        "Mingyuan Zhang"^^schema:Person,
        "Shuai Yi"^^schema:Person,
        "Xianglong Liu"^^schema:Person,
        "Xiao Ma"^^schema:Person,
        "Yizhuo Zhou"^^schema:Person,
        "Zhoujun Li"^^schema:Person ;
    schema:dateModified "2020-12-24T12:06:11Z"^^schema:DateTime ;
    schema:datePublished "2020-12-23T06:28:00Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Towards Overcoming False Positives in Visual Relationship Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.12510v2"^^schema:URL .

<1048> a schema:ScholarlyArticle ;
    schema:abstract "The predominant approach to Visual Question Answering (VQA) demands that themodel represents within its weights all of the information required to answerany question about any image. Learning this information from any real trainingset seems unlikely, and representing it in a reasonable number of weightsdoubly so. We propose instead to approach VQA as a meta learning task, thusseparating the question answering method from the information required. At testtime, the method is provided with a support set of example questions/answers,over which it reasons to resolve the given question. The support set is notfixed and can be extended without retraining, thereby expanding thecapabilities of the model. To exploit this dynamically provided information, weadapt a state-of-the-art VQA model with two techniques from the recent metalearning literature, namely prototypical networks and meta networks.Experiments demonstrate the capability of the system to learn to producecompletely novel answers (i.e. never seen during training) from examplesprovided at test time. In comparison to the existing state of the art, theproposed method produces qualitatively distinct results with higher recall ofrare answers, and a better sample efficiency that allows training with littleinitial data. More importantly, it represents an important step towardsvision-and-language methods that can learn and reason on-the-fly."^^schema:Text ;
    schema:author "Anton van den Hengel"^^schema:Person,
        "Damien Teney"^^schema:Person ;
    schema:dateModified "2017-11-22T02:04:31Z"^^schema:DateTime ;
    schema:datePublished "2017-11-22T02:04:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Visual Question Answering as a Meta Learning Task"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.08105v1"^^schema:URL .

<1049> a schema:ScholarlyArticle ;
    schema:abstract "To overcome the limitations of Neural Programmer-Interpreters (NPI) in itsuniversality and learnability, we propose the incorporation of combinatorabstraction into neural programing and a new NPI architecture to support thisabstraction, which we call Combinatory Neural Programmer-Interpreter (CNPI).Combinator abstraction dramatically reduces the number and complexity ofprograms that need to be interpreted by the core controller of CNPI, whilestill allowing the CNPI to represent and interpret arbitrary complex programsby the collaboration of the core with the other components. We propose a smallset of four combinators to capture the most pervasive programming patterns. Dueto the finiteness and simplicity of this combinator set and the offloading ofsome burden of interpretation from the core, we are able construct a CNPI thatis universal with respect to the set of all combinatorizable programs, which isadequate for solving most algorithmic tasks. Moreover, besides supervisedtraining on execution traces, CNPI can be trained by policy gradientreinforcement learning with appropriately designed curricula."^^schema:Text ;
    schema:author "Da Xiao"^^schema:Person,
        "Jo-Yu Liao"^^schema:Person,
        "Xingyuan Yuan"^^schema:Person ;
    schema:dateModified "2018-02-08T03:08:34Z"^^schema:DateTime ;
    schema:datePublished "2018-02-08T03:08:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Improving the Universality and Learnability of Neural  Programmer-Interpreters with Combinator Abstraction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.02696v1"^^schema:URL .

<105> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge distillation (KD) consists of transferring knowledge from onemachine learning model (the teacher}) to another (the student). Commonly, theteacher is a high-capacity model with formidable performance, while the studentis more compact. By transferring knowledge, one hopes to benefit from thestudent's compactness. %we desire a compact model with performance close to theteacher's. We study KD from a new perspective: rather than compressing models,we train students parameterized identically to their teachers. Surprisingly,these {Born-Again Networks (BANs), outperform their teachers significantly,both on computer vision and language modeling tasks. Our experiments with BANsbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additionalexperiments explore two distillation objectives: (i) Confidence-Weighted byTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).Both methods elucidate the essential components of KD, demonstrating a role ofthe teacher outputs on both predicted and non-predicted classes. We presentexperiments with students of various capacities, focusing on the under-exploredcase where students overpower teachers. Our experiments show significantadvantages from transferring knowledge between DenseNets and ResNets in eitherdirection."^^schema:Text ;
    schema:author "Anima Anandkumar"^^schema:Person,
        "Laurent Itti"^^schema:Person,
        "Michael Tschannen"^^schema:Person,
        "Tommaso Furlanello"^^schema:Person,
        "Zachary C. Lipton"^^schema:Person ;
    schema:commentCount "186"^^schema:Integer ;
    schema:dateModified "2018-06-29T10:46:28Z"^^schema:DateTime ;
    schema:datePublished "2018-05-12T19:48:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Born Again Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1602-1611"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.04770v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7598194009838654531&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1050> a schema:ScholarlyArticle ;
    schema:abstract "Smooth, non-convex optimization problems on Riemannian manifolds occur inmachine learning as a result of orthonormality, rank or positivity constraints.First- and second-order necessary optimality conditions state that theRiemannian gradient must be zero, and the Riemannian Hessian must be positivesemidefinite. Generalizing Jin et al.'s recent work on perturbed gradientdescent (PGD) for optimization on linear spaces [How to Escape Saddle PointsEfficiently (2017), Stochastic Gradient Descent Escapes Saddle PointsEfficiently (2019)], we propose a version of perturbed Riemannian gradientdescent (PRGD) to show that necessary optimality conditions can be metapproximately with high probability, without evaluating the Hessian.Specifically, for an arbitrary Riemannian manifold $\\mathcal{M}$ of dimension$d$, a sufficiently smooth (possibly non-convex) objective function $f$, andunder weak conditions on the retraction chosen to move on the manifold, withhigh probability, our version of PRGD produces a point with gradient smallerthan $\\epsilon$ and Hessian within $\\sqrt{\\epsilon}$ of being positivesemidefinite in $O((\\log{d})^4 / \\epsilon^{2})$ gradient queries. This matchesthe complexity of PGD in the Euclidean case. Crucially, the dependence ondimension is low. This matters for large-scale applications including PCA andlow-rank matrix completion, which both admit natural formulations on manifolds.The key technical idea is to generalize PRGD with a distinction between twotypes of gradient steps: \"steps on the manifold\" and \"perturbed steps in atangent space of the manifold.\" Ultimately, this distinction makes it possibleto extend Jin et al.'s analysis seamlessly."^^schema:Text ;
    schema:author "Chris Criscitiello"^^schema:Person,
        "Nicolas Boumal"^^schema:Person ;
    schema:dateModified "2019-10-23T01:37:32Z"^^schema:DateTime ;
    schema:datePublished "2019-06-10T23:25:50Z"^^schema:DateTime ;
    schema:genre "cs.CC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Efficiently escaping saddle points on manifolds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.04321v3"^^schema:URL .

<1051> a schema:ScholarlyArticle ;
    schema:abstract "Meshes are important representations of physical 3D entities in the virtualworld. Applications like rendering, simulations and 3D printing require meshesto be manifold so that they can interact with the world like the real objectsthey represent. Prior methods generate meshes with great geometric accuracy butpoor manifoldness. In this work, we propose Neural Mesh Flow (NMF) to generatetwo-manifold meshes for genus-0 shapes. Specifically, NMF is a shapeauto-encoder consisting of several Neural Ordinary Differential Equation(NODE)[1] blocks that learn accurate mesh geometry by progressively deforming aspherical mesh. Training NMF is simpler compared to state-of-the-art methodssince it does not require any explicit mesh-based regularization. Ourexperiments demonstrate that NMF facilitates several applications such assingle-view mesh reconstruction, global shape parameterization, texturemapping, shape deformation and correspondence. Importantly, we demonstrate thatmanifold meshes generated using NMF are better-suited for physically-basedrendering and simulation. Code and data are released."^^schema:Text ;
    schema:author "Kunal Gupta"^^schema:Person,
        "Manmohan Chandraker"^^schema:Person ;
    schema:dateModified "2020-12-02T17:00:19Z"^^schema:DateTime ;
    schema:datePublished "2020-07-21T17:45:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic Flows"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.10973v2"^^schema:URL .

<1052> a schema:ScholarlyArticle ;
    schema:abstract "Existing approaches for unsupervised metric learning focus on exploringself-supervision information within the input image itself. We observe that,when analyzing images, human eyes often compare images against each otherinstead of examining images individually. In addition, they often pay attentionto certain keypoints, image regions, or objects which are discriminativebetween image classes but highly consistent within classes. Even if the imageis being transformed, the attention pattern will be consistent. Motivated bythis observation, we develop a new approach to unsupervised deep metriclearning where the network is learned based on self-supervision informationacross images instead of within one single image. To characterize theconsistent pattern of human attention during image comparisons, we introducethe idea of transformed attention consistency. It assumes that visually similarimages, even undergoing different image transforms, should share the sameconsistent visual attention map. This consistency leads to a pairwiseself-supervision loss, allowing us to learn a Siamese deep neural network toencode and compare images against their transformed or matched pairs. Tofurther enhance the inter-class discriminative power of the feature generatedby this network, we adapt the concept of triplet loss from supervised metriclearning to our unsupervised case and introduce the contrastive clusteringloss. Our extensive experimental results on benchmark datasets demonstrate thatour proposed method outperforms current state-of-the-art methods forunsupervised metric learning by a large margin."^^schema:Text ;
    schema:author "Shichao Kan"^^schema:Person,
        "Yang Li"^^schema:Person,
        "Zhihai He"^^schema:Person ;
    schema:dateModified "2020-08-10T19:33:47Z"^^schema:DateTime ;
    schema:datePublished "2020-08-10T19:33:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Deep Metric Learning with Transformed Attention Consistency  and Contrastive Clustering Loss"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.04378v1"^^schema:URL .

<1053> a schema:ScholarlyArticle ;
    schema:abstract "Traditional deep neural networks (NNs) have significantly contributed to thestate-of-the-art performance in the task of classification under variousapplication domains. However, NNs have not considered inherent uncertainty indata associated with the class probabilities where misclassification underuncertainty may easily introduce high risk in decision making in real-worldcontexts (e.g., misclassification of objects in roads leads to seriousaccidents). Unlike Bayesian NN that indirectly infer uncertainty through weightuncertainties, evidential NNs (ENNs) have been recently proposed to explicitlymodel the uncertainty of class probabilities and use them for classificationtasks. An ENN offers the formulation of the predictions of NNs as subjectiveopinions and learns the function by collecting an amount of evidence that canform the subjective opinions by a deterministic NN from data. However, the ENNis trained as a black box without explicitly considering inherent uncertaintyin data with their different root causes, such as vacuity (i.e., uncertaintydue to a lack of evidence) or dissonance (i.e., uncertainty due to conflictingevidence). By considering the multidimensional uncertainty, we proposed a noveluncertainty-aware evidential NN called WGAN-ENN (WENN) for solving anout-of-distribution (OOD) detection problem. We took a hybrid approach thatcombines Wasserstein Generative Adversarial Network (WGAN) with ENNs to jointlytrain a model with prior knowledge of a certain class, which has high vacuityfor OOD samples. Via extensive empirical experiments based on both syntheticand real-world datasets, we demonstrated that the estimation of uncertainty byWENN can significantly help distinguish OOD samples from boundary samples. WENNoutperformed in OOD detection when compared with other competitivecounterparts."^^schema:Text ;
    schema:author "Feng Chen"^^schema:Person,
        "Jin-Hee Cho"^^schema:Person,
        "Xujiang Zhao"^^schema:Person,
        "Yibo Hu"^^schema:Person,
        "Yuzhe Ou"^^schema:Person ;
    schema:dateModified "2020-12-26T04:28:56Z"^^schema:DateTime ;
    schema:datePublished "2020-12-26T04:28:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Multidimensional Uncertainty-Aware Evidential Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.13676v1"^^schema:URL .

<1054> a schema:ScholarlyArticle ;
    schema:abstract "In this study, a novel topology optimization approach based on conditionalWasserstein generative adversarial networks (CWGAN) is developed to replicatethe conventional topology optimization algorithms in an extremelycomputationally inexpensive way. CWGAN consists of a generator and adiscriminator, both of which are deep convolutional neural networks (CNN). Thelimited samples of data, quasi-optimal planar structures, needed for trainingpurposes are generated using the conventional topology optimization algorithms.With CWGANs, the topology optimization conditions can be set to a requiredvalue before generating samples. CWGAN truncates the global design space byintroducing an equality constraint by the designer. The results are validatedby generating an optimized planar structure using the conventional algorithmswith the same settings. A proof of concept is presented which is known to bethe first such illustration of fusion of CWGANs and topology optimization."^^schema:Text ;
    schema:author "M. -H. Herman Shen"^^schema:Person,
        "Sharad Rawat"^^schema:Person ;
    schema:dateModified "2019-01-14T15:21:44Z"^^schema:DateTime ;
    schema:datePublished "2019-01-14T15:21:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Novel Topology Optimization Approach using Conditional Deep Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.04859v1"^^schema:URL .

<1055> a schema:ScholarlyArticle ;
    schema:abstract "Supervised learning, more specifically Convolutional Neural Networks (CNN),has surpassed human ability in some visual recognition tasks such as detectionof traffic signs, faces and handwritten numbers. On the other hand, evenstate-of-the-art reinforcement learning (RL) methods have difficulties inenvironments with sparse and binary rewards. They requires manually shapingreward functions, which might be challenging to come up with. These tasks,however, are trivial to human. One of the reasons that human are betterlearners in these tasks is that we are embedded with much prior knowledge ofthe world. These knowledge might be either embedded in our genes or learnedfrom imitation - a type of supervised learning. For that reason, the best wayto narrow the gap between machine and human learning ability should be to mimichow we learn so well in various tasks by a combination of RL and supervisedlearning. Our method, which integrates Deep Deterministic Policy Gradients andHindsight Experience Replay (RL method specifically dealing with sparserewards) with an experience ranking CNN, provides a significant speedup overthe learning curve on simulated robotics tasks. Experience ranking allowshigh-reward transitions to be replayed more frequently, and therefore helplearn more efficiently. Our proposed approach can also speed up learning in anyother tasks that provide additional information for experience ranking."^^schema:Text ;
    schema:author "Hai Nguyen"^^schema:Person,
        "Hung Manh La"^^schema:Person,
        "Matthew Deans"^^schema:Person ;
    schema:dateModified "2018-09-16T05:58:46Z"^^schema:DateTime ;
    schema:datePublished "2018-09-16T05:58:46Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Deep Learning with Experience Ranking Convolutional Neural Network for  Robot Manipulator"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.05819v1"^^schema:URL .

<1056> a schema:ScholarlyArticle ;
    schema:abstract "Developmental machine learning studies how artificial agents can model theway children learn open-ended repertoires of skills. Such agents need to createand represent goals, select which ones to pursue and learn to achieve them.Recent approaches have considered goal spaces that were either fixed andhand-defined or learned using generative models of states. This limited agentsto sample goals within the distribution of known effects. We argue that theability to imagine out-of-distribution goals is key to enable creativediscoveries and open-ended learning. Children do so by leveraging thecompositionality of language as a tool to imagine descriptions of outcomes theynever experienced before, targeting them as goals during play. We introduceIMAGINE, an intrinsically motivated deep reinforcement learning architecturethat models this ability. Such imaginative agents, like children, benefit fromthe guidance of a social peer who provides language descriptions. To takeadvantage of goal imagination, agents must be able to leverage thesedescriptions to interpret their imagined out-of-distribution goals. Thisgeneralization is made possible by modularity: a decomposition between learnedgoal-achievement reward function and policy relying on deep sets, gatedattention and object-centered representations. We introduce the Playgroundenvironment and study how this form of goal imagination improves generalizationand exploration over agents lacking this capacity. In addition, we identify theproperties of goal imagination that enable these results and study the impactsof modularity and social interactions."^^schema:Text ;
    schema:author "Clément Moulin-Frier"^^schema:Person,
        "Cédric Colas"^^schema:Person,
        "Jean-Michel Dussoux"^^schema:Person,
        "Nicolas Lair"^^schema:Person,
        "Peter Ford Dominey"^^schema:Person,
        "Pierre-Yves Oudeyer"^^schema:Person,
        "Tristan Karch"^^schema:Person ;
    schema:dateModified "2020-10-21T16:48:51Z"^^schema:DateTime ;
    schema:datePublished "2020-02-21T12:59:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven  Exploration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.09253v4"^^schema:URL .

<1057> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we present a deep learning framework for multi-class breastcancer image classification as our submission to the International Conferenceon Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst CancerHistology images (BACH). As these histology images are too large to fit intoGPU memory, we first propose using Inception V3 to perform patch levelclassification. The patch level predictions are then passed through an ensemblefusion framework involving majority voting, gradient boosting machine (GBM),and logistic regression to obtain the image level prediction. We improve thesensitivity of the Normal and Benign predicted classes by designing a Dual PathNetwork (DPN) to be used as a feature extractor where these extracted featuresare further sent to a second layer of ensemble prediction fusion using GBM,logistic regression, and support vector machine (SVM) to refine predictions.Experimental results demonstrate our framework shows a 12.5$\\%$ improvementover the state-of-the-art model."^^schema:Text ;
    schema:author "Xiaohui Xie"^^schema:Person,
        "Yeeleng S. Vang"^^schema:Person,
        "Zhen Chen"^^schema:Person ;
    schema:dateModified "2018-02-03T07:13:02Z"^^schema:DateTime ;
    schema:datePublished "2018-02-03T07:13:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Learning Framework for Multi-class Breast Cancer Histology Image  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.00931v1"^^schema:URL .

<1058> a schema:ScholarlyArticle ;
    schema:abstract "The paper presents a comparative study of state-of-the-art approaches forquestion classification task: Logistic Regression, Convolutional NeuralNetworks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-RecurrentNeural Networks (QRNN). All models use pre-trained GLoVe word embeddings andtrained on human-labeled data. The best accuracy is achieved using CNN modelwith five convolutional layers and various kernel sizes stacked in parallel,followed by one fully connected layer. The model reached 90.7% accuracy on TREC10 test set. All the model architectures in this paper were developed fromscratch on PyTorch, in few cases based on reliable open-source implementation."^^schema:Text ;
    schema:author "Tamirlan Seidakhmetov"^^schema:Person ;
    schema:dateModified "2020-01-03T00:16:46Z"^^schema:DateTime ;
    schema:datePublished "2020-01-03T00:16:46Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Question Type Classification Methods Comparison"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.00571v1"^^schema:URL .

<1059> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of handling missing data with deep latent variablemodels (DLVMs). First, we present a simple technique to train DLVMs when thetraining set contains missing-at-random data. Our approach, called MIWAE, isbased on the importance-weighted autoencoder (IWAE), and maximises apotentially tight lower bound of the log-likelihood of the observed data.Compared to the original IWAE, our algorithm does not induce any additionalcomputational overhead due to the missing data. We also develop Monte Carlotechniques for single and multiple imputation using a DLVM trained on anincomplete data set. We illustrate our approach by training a convolutionalDLVM on a static binarisation of MNIST that contains 50% of missing pixels.Leveraging multiple imputation, a convolutional network trained on theseincomplete digits has a test performance similar to one trained on completedata. On various continuous and binary data sets, we also show that MIWAEprovides accurate single imputations, and is highly competitive withstate-of-the-art methods."^^schema:Text ;
    schema:author "Jes Frellsen"^^schema:Person,
        "Pierre-Alexandre Mattei"^^schema:Person ;
    schema:dateModified "2019-02-04T18:06:43Z"^^schema:DateTime ;
    schema:datePublished "2018-12-06T16:14:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "MIWAE: Deep Generative Modelling and Imputation of Incomplete Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.02633v2"^^schema:URL .

<106> a schema:ScholarlyArticle ;
    schema:abstract "For an autonomous system to be helpful to humans and to pose no unwarrantedrisks, it needs to align its values with those of the humans in its environmentin such a way that its actions contribute to the maximization of value for thehumans. We propose a formal definition of the value alignment problem ascooperative inverse reinforcement learning (CIRL). A CIRL problem is acooperative, partial-information game with two agents, human and robot; bothare rewarded according to the human's reward function, but the robot does notinitially know what this is. In contrast to classical IRL, where the human isassumed to act optimally in isolation, optimal CIRL solutions produce behaviorssuch as active teaching, active learning, and communicative actions that aremore effective in achieving value alignment. We show that computing optimaljoint policies in CIRL games can be reduced to solving a POMDP, prove thatoptimality in isolation is suboptimal in CIRL, and derive an approximate CIRLalgorithm."^^schema:Text ;
    schema:author "Anca Dragan"^^schema:Person,
        "Dylan Hadfield-Menell"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Stuart Russell"^^schema:Person ;
    schema:commentCount "221"^^schema:Integer ;
    schema:dateModified "2016-11-12T20:33:43Z"^^schema:DateTime ;
    schema:datePublished "2016-06-09T22:39:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Cooperative Inverse Reinforcement Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.03137v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15627132950356078183&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1060> a schema:ScholarlyArticle ;
    schema:abstract "Image registration is a key operation in medical image processing, allowing aplethora of applications. Mutual information (MI) is consolidated as a robustsimilarity metric often used for medical image registration. Although MIprovides a robust medical image registration, it usually fails when the neededimage transform is too big due to MI local maxima traps. In this paper, wepropose and evaluate a generalized parametric MI as an affine registration costfunction. We assessed the generalized MI (GMI) functions for separable affinetransforms and exhaustively evaluated the GMI mathematical image seeking themaximum registration range through a gradient descent simulation. We alsoemployed Monte Carlo simulation essays for testing translation registering ofrandomized T1 versus T2 images. GMI functions showed to have smooth isosurfacesdriving the algorithm to the global maxima. Results show significantlyprolonged registration ranges, avoiding the traps of local maxima. We evaluateda range of [-150mm,150mm] for translations, [-180{\\deg},180{\\deg}] forrotations, [0.5,2] for scales, and [-1,1] for skew with a success rate of99.99%, 97.58%, 99.99%, and 99.99% respectively for the transforms in thesimulated gradient descent. We also obtained 99.75% success in Monte Carlosimulation from 2,000 randomized translations trials with 1,113 subjects T1 andT2 MRI images. The findings point towards the reliability of GMI for long-rangeregistration with enhanced speed performance"^^schema:Text ;
    schema:author "Luiz Otavio Murta Jr"^^schema:Person,
        "Vinicius Pavanelli Vianna"^^schema:Person ;
    schema:dateModified "2020-11-30T17:48:28Z"^^schema:DateTime ;
    schema:datePublished "2020-11-30T17:48:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.IT"^^schema:Text,
        "eess.IV"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Long-range medical image registration through generalized mutual  information (GMI): toward a fully automatic volumetric alignment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.15049v1"^^schema:URL .

<1061> a schema:ScholarlyArticle ;
    schema:abstract "We study risk-sensitive imitation learning where the agent's goal is toperform at least as well as the expert in terms of a risk profile. We firstformulate our risk-sensitive imitation learning setting. We consider thegenerative adversarial approach to imitation learning (GAIL) and derive anoptimization problem for our formulation, which we call it risk-sensitive GAIL(RS-GAIL). We then derive two different versions of our RS-GAIL optimizationproblem that aim at matching the risk profiles of the agent and the expertw.r.t. Jensen-Shannon (JS) divergence and Wasserstein distance, and developrisk-sensitive generative adversarial imitation learning algorithms based onthese optimization problems. We evaluate the performance of our algorithms andcompare them with GAIL and the risk-averse imitation learning (RAIL) algorithmsin two MuJoCo and two OpenAI classical control tasks."^^schema:Text ;
    schema:author "Jonathan Lacotte"^^schema:Person,
        "Marco Pavone"^^schema:Person,
        "Mohammad Ghavamzadeh"^^schema:Person,
        "Yinlam Chow"^^schema:Person ;
    schema:dateModified "2018-12-24T02:41:29Z"^^schema:DateTime ;
    schema:datePublished "2018-08-13T21:08:46Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Risk-Sensitive Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.04468v2"^^schema:URL .

<1062> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning algorithms learn viable policies by imitating an expert'sbehavior when reward signals are not available. Generative AdversarialImitation Learning (GAIL) is a state-of-the-art algorithm for learning policieswhen the expert's behavior is available as a fixed set of trajectories. Weevaluate in terms of the expert's cost function and observe that thedistribution of trajectory-costs is often more heavy-tailed for GAIL-agentsthan the expert at a number of benchmark continuous-control tasks. Thus,high-cost trajectories, corresponding to tail-end events of catastrophicfailure, are more likely to be encountered by the GAIL-agents than the expert.This makes the reliability of GAIL-agents questionable when it comes todeployment in risk-sensitive applications like robotic surgery and autonomousdriving. In this work, we aim to minimize the occurrence of tail-end events byminimizing tail risk within the GAIL framework. We quantify tail risk by theConditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-AverseImitation Learning (RAIL) algorithm. We observe that the policies learned withRAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposedRAIL algorithm appears as a potent alternative to GAIL for improved reliabilityin risk-sensitive applications."^^schema:Text ;
    schema:author "Abhishek Naik"^^schema:Person,
        "Anirban Santara"^^schema:Person,
        "Balaraman Ravindran"^^schema:Person,
        "Bharat Kaul"^^schema:Person,
        "Dheevatsa Mudigere"^^schema:Person,
        "Dipankar Das"^^schema:Person,
        "Sasikanth Avancha"^^schema:Person ;
    schema:dateModified "2017-11-29T12:44:19Z"^^schema:DateTime ;
    schema:datePublished "2017-07-20T18:01:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "RAIL: Risk-Averse Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.06658v4"^^schema:URL .

<1063> a schema:ScholarlyArticle ;
    schema:abstract "Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization(PPO), as the widely employed policy based reinforcement learning (RL) methods,are prone to converge to a sub-optimal solution as they limit the policyrepresentation to a particular parametric distribution class. To address thisissue, we develop an innovative Optimistic Distributionally Robust PolicyOptimization (ODRPO) algorithm, which effectively utilizes OptimisticDistributionally Robust Optimization (DRO) approach to solve the trust regionconstrained optimization problem without parameterizing the policies. Ouralgorithm improves TRPO and PPO with a higher sample efficiency and a betterperformance of the final policy while attaining the learning stability.Moreover, it achieves a globally optimal policy update that is not promised inthe prevailing policy based RL algorithms. Experiments across tabular domainsand robotic locomotion tasks demonstrate the effectiveness of our approach."^^schema:Text ;
    schema:author "Chaoyue Zhao"^^schema:Person,
        "Jun Song"^^schema:Person ;
    schema:dateModified "2020-06-14T06:36:18Z"^^schema:DateTime ;
    schema:datePublished "2020-06-14T06:36:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Optimistic Distributionally Robust Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.07815v1"^^schema:URL .

<1064> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (NMT) has attracted a lot ofattention recently. While state-of-the-art methods for unsupervised translationusually perform well between similar languages (e.g., English-Germantranslation), they perform poorly between distant languages, becauseunsupervised alignment does not work well for distant languages. In this work,we introduce unsupervised pivot translation for distant languages, whichtranslates a language to a distant language through multiple hops, and theunsupervised translation on each hop is relatively easier than the originaldirect translation. We propose a learning to route (LTR) method to choose thetranslation path between the source and target languages. LTR is trained onlanguage pairs whose best translation path is available and is applied on theunseen language pairs for path selection. Experiments on 20 languages and 294distant language pairs demonstrate the advantages of the unsupervised pivottranslation for distant languages, as well as the effectiveness of the proposedLTR for path selection. Specifically, in the best case, LTR achieves animprovement of 5.58 BLEU points over the conventional direct unsupervisedmethod."^^schema:Text ;
    schema:author "Tao Qin"^^schema:Person,
        "Tie-Yan Liu"^^schema:Person,
        "Xiang-Yang Li"^^schema:Person,
        "Xu Tan"^^schema:Person,
        "Yichong Leng"^^schema:Person ;
    schema:dateModified "2019-06-25T02:58:06Z"^^schema:DateTime ;
    schema:datePublished "2019-06-06T07:48:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Pivot Translation for Distant Languages"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02461v3"^^schema:URL .

<1065> a schema:ScholarlyArticle ;
    schema:abstract "The recently proposed option-critic architecture Bacon et al. provide astochastic policy gradient approach to hierarchical reinforcement learning.Specifically, they provide a way to estimate the gradient of the expecteddiscounted return with respect to parameters that define a finite number oftemporally extended actions, called \\textit{options}. In this paper we show howthe option-critic architecture can be extended to estimate the natural gradientof the expected discounted return. To this end, the central questions that weconsider in this paper are: 1) what is the definition of the natural gradientin this context, 2) what is the Fisher information matrix associated with anoption's parameterized policy, 3) what is the Fisher information matrixassociated with an option's parameterized termination function, and 4) how cana compatible function approximation approach be leveraged to obtain naturalgradient estimates for both the parameterized policy and parameterizedtermination functions of an option with per-time-step time and space complexitylinear in the total number of parameters. Based on answers to these questionswe introduce the natural option critic algorithm. Experimental results showcaseimprovement over the vanilla gradient approach."^^schema:Text ;
    schema:author "Philip S. Thomas"^^schema:Person,
        "Saket Tiwari"^^schema:Person ;
    schema:dateModified "2018-12-04T15:33:26Z"^^schema:DateTime ;
    schema:datePublished "2018-12-04T15:33:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Natural Option Critic"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.01488v1"^^schema:URL .

<1066> a schema:ScholarlyArticle ;
    schema:abstract "Humans are able to conceive physical reality by jointly learning differentfacets thereof. To every pair of notions related to a perceived reality maycorrespond a mutual relation, which is a notion on its own, but one-levelhigher. Thus, we may have a description of perceived reality on at least twolevels and the translation map between them is in general, due to theirdifferent content corpus, one-to-many. Following success of the unsupervisedneural machine translation models, which are essentially one-to-one mappingstrained separately on monolingual corpora, we examine further capabilities ofthe unsupervised deep learning methods used there and apply some of thesemethods to sets of notions of different level and measure. Using the graph andword embedding-like techniques, we build one-to-many map without parallel datain order to establish a unified vector representation of the outer world bycombining notions of different kind into a unique conceptual framework. Due totheir latent similarity, by aligning the two embedding spaces in purelyunsupervised way, one obtains a geometric relation between objects of cognitionon the two levels, making it possible to express a natural knowledge using onedescription in the context of the other."^^schema:Text ;
    schema:author "Luka Nenadović"^^schema:Person,
        "Vladimir Prelovac"^^schema:Person ;
    schema:dateModified "2019-08-16T14:24:58Z"^^schema:DateTime ;
    schema:datePublished "2019-06-05T08:11:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Towards conceptual generalization in the embedding space"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.01873v3"^^schema:URL .

<1067> a schema:ScholarlyArticle ;
    schema:abstract "Early Unsupervised Domain Adaptation (UDA) methods have mostly assumed thesetting of a single source domain, where all the labeled source data come fromthe same distribution. However, in practice the labeled data can come frommultiple source domains with different distributions. In such scenarios, thesingle source domain adaptation methods can fail due to the existence of domainshifts across different source domains and multi-source domain adaptationmethods need to be designed. In this paper, we propose a novel multi-sourcedomain adaptation method, Mutual Learning Network for Multiple Source DomainAdaptation (ML-MSDA). Under the framework of mutual learning, the proposedmethod pairs the target domain with each single source domain to train aconditional adversarial domain adaptation network as a branch network, whiletaking the pair of the combined multi-source domain and target domain to traina conditional adversarial adaptive network as the guidance network. Themultiple branch networks are aligned with the guidance network to achievemutual learning by enforcing JS-divergence regularization over their predictionprobability distributions on the corresponding target data. We conductextensive experiments on multiple multi-source domain adaptation benchmarkdatasets. The results show the proposed ML-MSDA method outperforms thecomparison methods and achieves the state-of-the-art performance."^^schema:Text ;
    schema:author "Haifeng Shen"^^schema:Person,
        "Jieping Ye"^^schema:Person,
        "Yuhong Guo"^^schema:Person,
        "Zhen Zhao"^^schema:Person,
        "Zhenpeng Li"^^schema:Person ;
    schema:dateModified "2020-03-29T04:31:43Z"^^schema:DateTime ;
    schema:datePublished "2020-03-29T04:31:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Mutual Learning Network for Multi-Source Domain Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.12944v1"^^schema:URL .

<1068> a schema:ScholarlyArticle ;
    schema:abstract "We present a method to restore a clear image from a haze-affected image usinga Wasserstein generative adversarial network. As the problem isill-conditioned, previous methods have required a prior on natural images ormultiple images of the same scene. We train a generative adversarial network tolearn the probability distribution of clear images conditioned on thehaze-affected images using the Wasserstein loss function, using a gradientpenalty to enforce the Lipschitz constraint. The method is data-adaptive,end-to-end, and requires no further processing or tuning of parameters. We alsoincorporate the use of a texture-based loss metric and the L1 loss to improveresults, and show that our results are better than the currentstate-of-the-art."^^schema:Text ;
    schema:author "Bijaylaxmi Das"^^schema:Person,
        "Joshua Peter Ebenezer"^^schema:Person,
        "Sudipta Mukhopadhyay"^^schema:Person ;
    schema:dateModified "2019-03-01T16:32:05Z"^^schema:DateTime ;
    schema:datePublished "2019-03-01T16:32:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Single Image Haze Removal Using Conditional Wasserstein Generative  Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.00395v1"^^schema:URL .

<1069> a schema:ScholarlyArticle ;
    schema:abstract "Inspired by the success of adversarial learning, we propose a new end-to-endunsupervised deep learning framework for monocular depth estimation consistingof two Generative Adversarial Networks (GAN), deeply coupled with a structuredConditional Random Field (CRF) model. The two GANs aim at generating distinctand complementary disparity maps and at improving the generation quality viaexploiting the adversarial learning strategy. The deep CRF coupling model isproposed to fuse the generative and discriminative outputs from the dual GANnets. As such, the model implicitly constructs mutual constraints on the twonetwork branches and between the generator and discriminator. This facilitatesthe optimization of the whole network for better disparity generation.Extensive experiments on the KITTI, Cityscapes, and Make3D datasets clearlydemonstrate the effectiveness of the proposed approach and show superiorperformance compared to state of the art methods. The code and models areavailable at https://github.com/mihaipuscas/ 3dv---coupled-crf-disparity."^^schema:Text ;
    schema:author "Andrea Pilzer"^^schema:Person,
        "Dan Xu"^^schema:Person,
        "Mihai Marian Puscas"^^schema:Person,
        "Nicu Sebe"^^schema:Person ;
    schema:dateModified "2019-08-15T23:26:59Z"^^schema:DateTime ;
    schema:datePublished "2019-08-15T23:26:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Structured Coupled Generative Adversarial Networks for Unsupervised  Monocular Depth Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.05794v1"^^schema:URL .

<107> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning and deep learning in particular has advanced tremendously onperceptual tasks in recent years. However, it remains vulnerable againstadversarial perturbations of the input that have been crafted specifically tofool the system while being quasi-imperceptible to a human. In this work, wepropose to augment deep neural networks with a small \"detector\" subnetworkwhich is trained on the binary classification task of distinguishing genuinedata from data containing adversarial perturbations. Our method is orthogonalto prior work on addressing adversarial perturbations, which has mostly focusedon making the classification network itself more robust. We show empiricallythat adversarial perturbations can be detected surprisingly well even thoughthey are quasi-imperceptible to humans. Moreover, while the detectors have beentrained to detect only a specific adversary, they generalize to similar andweaker adversaries. In addition, we propose an adversarial attack that foolsboth the classifier and the detector and a novel training procedure for thedetector that counteracts this attack."^^schema:Text ;
    schema:author "Bastian Bischoff"^^schema:Person,
        "Jan Hendrik Metzen"^^schema:Person,
        "Tim Genewein"^^schema:Person,
        "Volker Fischer"^^schema:Person ;
    schema:commentCount "398"^^schema:Integer ;
    schema:dateModified "2017-02-21T06:53:38Z"^^schema:DateTime ;
    schema:datePublished "2017-02-14T15:44:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Detecting Adversarial Perturbations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.04267v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2337805679039722044&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1070> a schema:ScholarlyArticle ;
    schema:abstract "Lidar based 3D object detection and classification tasks are essential forautonomous driving(AD). A lidar sensor can provide the 3D point cloud datareconstruction of the surrounding environment. However, real time detection in3D point clouds still needs a strong algorithmic. This paper proposes a 3Dobject detection method based on point cloud and image which consists of thereparts.(1)Lidar-camera calibration and undistorted image transformation.(2)YOLO-based detection and PointCloud extraction, (3)K-means based point cloudsegmentation and detection experiment test and evaluation in depth image. Inour research, camera can capture the image to make the Real-time 2D objectdetection by using YOLO, we transfer the bounding box to node whose function ismaking 3d object detection on point cloud data from Lidar. By comparing whether2D coordinate transferred from the 3D point is in the object bounding box ornot can achieve High-speed 3D object recognition function in GPU. The accuracyand precision get imporved after k-means clustering in point cloud. The speedof our detection method is a advantage faster than PointNet."^^schema:Text ;
    schema:author "Kentaro Shimizu"^^schema:Person,
        "Weimin Wang"^^schema:Person,
        "Xuanyu Yin"^^schema:Person,
        "Yoko Sasaki"^^schema:Person ;
    schema:dateModified "2020-04-21T04:32:36Z"^^schema:DateTime ;
    schema:datePublished "2020-04-21T04:32:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "3D Object Detection Method Based on YOLO and K-Means for Image and Point  Clouds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.02132v1"^^schema:URL .

<1071> a schema:ScholarlyArticle ;
    schema:abstract "Many recent few-shot learning methods concentrate on designing novel modelarchitectures. In this paper, we instead show that with a simple backboneconvolutional network we can even surpass state-of-the-art classificationaccuracy. The essential part that contributes to this superior performance isan adversarial feature learning strategy that improves the generalizationcapability of our model. In this work, adversarial features are those featuresthat can cause the classifier uncertain about its prediction. In order togenerate adversarial features, we firstly locate adversarial regions based onthe derivative of the entropy with respect to an averaging mask. Then we usethe adversarial region attention to aggregate the feature maps to obtain theadversarial features. In this way, we can explore and exploit the entirespatial area of the feature maps to mine more diverse discriminative knowledge.We perform extensive model evaluations and analyses on miniImageNet andtieredImageNet datasets demonstrating the effectiveness of the proposed method."^^schema:Text ;
    schema:author "Jun Sun"^^schema:Person,
        "Wei Shen"^^schema:Person,
        "Ziqiang Shi"^^schema:Person ;
    schema:dateModified "2019-03-25T10:30:23Z"^^schema:DateTime ;
    schema:datePublished "2019-03-25T10:30:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning from Adversarial Features for Few-Shot Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.10225v1"^^schema:URL .

<1072> a schema:ScholarlyArticle ;
    schema:abstract "Recent work on predicting patient outcomes in the Intensive Care Unit (ICU)has focused heavily on the physiological time series data, largely ignoringsparse data such as diagnoses and medications. When they are included, they areusually concatenated in the late stages of a model, which may struggle to learnfrom rarer disease patterns. Instead, we propose a strategy to exploitdiagnoses as relational information by connecting similar patients in a graph.To this end, we propose LSTM-GNN for patient outcome prediction tasks: a hybridmodel combining Long Short-Term Memory networks (LSTMs) for extracting temporalfeatures and Graph Neural Networks (GNNs) for extracting the patientneighbourhood information. We demonstrate that LSTM-GNNs outperform theLSTM-only baseline on length of stay prediction tasks on the eICU database.More generally, our results indicate that exploiting information fromneighbouring patient cases using graph neural networks is a promising researchdirection, yielding tangible returns in supervised learning performance onElectronic Health Records."^^schema:Text ;
    schema:author "Catherine Tong"^^schema:Person,
        "Emma Rocheteau"^^schema:Person,
        "Nicholas Lane"^^schema:Person,
        "Petar Veličković"^^schema:Person,
        "Pietro Liò"^^schema:Person ;
    schema:dateModified "2021-01-11T15:04:07Z"^^schema:DateTime ;
    schema:datePublished "2021-01-11T15:04:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Predicting Patient Outcomes with Graph Representation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.03940v1"^^schema:URL .

<1073> a schema:ScholarlyArticle ;
    schema:abstract "Learning domain-invariant representation is a dominant approach for domaingeneralization (DG), where we need to build a classifier that is robust towarddomain shifts. However, previous domain-invariance-based methods overlooked theunderlying dependency of classes on domains, which is responsible for thetrade-off between classification accuracy and domain invariance. Because theprimary purpose of DG is to classify unseen domains rather than the invarianceitself, the improvement of the invariance can negatively affect DG performanceunder this trade-off. To overcome the problem, this study first expands theanalysis of the trade-off by Xie et. al., and provides the notion ofaccuracy-constrained domain invariance, which means the maximum domaininvariance within a range that does not interfere with accuracy. We thenpropose a novel method adversarial feature learning with accuracy constraint(AFLAC), which explicitly leads to that invariance on adversarial training.Empirical validations show that the performance of AFLAC is superior to that ofdomain-invariance-based methods on both synthetic and three real-worlddatasets, supporting the importance of considering the dependency and theefficacy of the proposed method."^^schema:Text ;
    schema:author "Kei Akuzawa"^^schema:Person,
        "Yusuke Iwasawa"^^schema:Person,
        "Yutaka Matsuo"^^schema:Person ;
    schema:dateModified "2020-03-02T11:24:01Z"^^schema:DateTime ;
    schema:datePublished "2019-04-29T09:52:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Invariant Feature Learning with Accuracy Constraint for  Domain Generalization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.12543v3"^^schema:URL .

<1074> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a deep learning framework based on Long Short-term MemoryNetwork(LSTM) that predicts price movement of cryptocurrencies fromtrade-by-trade data. The main focus of this study is on predicting short-termprice changes in a fixed time horizon from a looking back period. By carefullydesigning features and detailed searching for best hyper-parameters, the modelis trained to achieve high performance on nearly a year of trade-by-trade data.The optimal model delivers stable high performance(over 60% accuracy) onout-of-sample test periods. In a realistic trading simulation setting, theprediction made by the model could be easily monetized. Moreover, this studyshows that the LSTM model could extract universal features from trade-by-tradedata, as the learned parameters well maintain their high performance on othercryptocurrency instruments that were not included in training data. This studyexceeds existing researches in term of the scale and precision of data used, aswell as the high prediction accuracy achieved."^^schema:Text ;
    schema:author "Qi Zhao"^^schema:Person ;
    schema:dateModified "2020-10-11T10:42:02Z"^^schema:DateTime ;
    schema:datePublished "2020-10-11T10:42:02Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "q-fin.ST"^^schema:Text,
        "q-fin.TR"^^schema:Text ;
    schema:headline "A Deep Learning Framework for Predicting Digital Asset Price Movement  from Trade-by-trade Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07404v1"^^schema:URL .

<1075> a schema:ScholarlyArticle ;
    schema:abstract "Skip connections made the training of very deep networks possible and havebecome an indispensable component in a variety of neural architectures. Acompletely satisfactory explanation for their success remains elusive. Here, wepresent a novel explanation for the benefits of skip connections in trainingvery deep networks. The difficulty of training deep networks is partly due tothe singularities caused by the non-identifiability of the model. Several suchsingularities have been identified in previous works: (i) overlap singularitiescaused by the permutation symmetry of nodes in a given layer, (ii) eliminationsingularities corresponding to the elimination, i.e. consistent deactivation,of nodes, (iii) singularities generated by the linear dependence of the nodes.These singularities cause degenerate manifolds in the loss landscape that slowdown learning. We argue that skip connections eliminate these singularities bybreaking the permutation symmetry of nodes, by reducing the possibility of nodeelimination and by making the nodes less linearly dependent. Moreover, fortypical initializations, skip connections move the network away from the\"ghosts\" of these singularities and sculpt the landscape around them toalleviate the learning slow-down. These hypotheses are supported by evidencefrom simplified models, as well as from experiments with deep networks trainedon real-world datasets."^^schema:Text ;
    schema:author "A. Emin Orhan"^^schema:Person,
        "Xaq Pitkow"^^schema:Person ;
    schema:dateModified "2018-03-04T22:23:18Z"^^schema:DateTime ;
    schema:datePublished "2017-01-31T18:41:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Skip Connections Eliminate Singularities"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1701.09175v8"^^schema:URL .

<1076> a schema:ScholarlyArticle ;
    schema:abstract "Events in the real world are correlated across nearby points in time, and wemust learn from this temporally smooth data. However, when neural networks aretrained to categorize or reconstruct single items, the common practice is torandomize the order of training items. What are the effects of temporallysmooth training data on the efficiency of learning? We first tested the effectsof smoothness in training data on incremental learning in feedforward nets andfound that smoother data slowed learning. Moreover, sampling so as to minimizetemporal smoothness produced more efficient learning than sampling randomly. Ifsmoothness generally impairs incremental learning, then how can networks bemodified to benefit from smoothness in the training data? We hypothesized thattwo simple brain-inspired mechanisms, leaky memory in activation units andmemory-gating, could enable networks to rapidly extract useful representationsfrom smooth data. Across all levels of data smoothness, these brain-inspiredarchitectures achieved more efficient category learning than feedforwardnetworks. This advantage persisted, even when leaky memory networks with gatingwere trained on smooth data and tested on randomly-ordered data. Finally, weinvestigated how these brain-inspired mechanisms altered the internalrepresentations learned by the networks. We found that networks withmulti-scale leaky memory and memory-gating could learn internal representationsthat un-mixed data sources which vary on fast and slow timescales acrosstraining samples. Altogether, we identified simple mechanisms enabling neuralnetworks to learn more quickly from temporally smooth data, and to generateinternal representations that separate timescales in the training signal."^^schema:Text ;
    schema:author "Christopher J. Honey"^^schema:Person,
        "Fanjun Bu"^^schema:Person,
        "Shima Rahimi Moghaddam"^^schema:Person ;
    schema:dateModified "2020-12-12T01:24:36Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T01:24:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning Representations from Temporally Smooth Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06694v1"^^schema:URL .

<1077> a schema:ScholarlyArticle ;
    schema:abstract "Recent technological advances have proliferated the available computingpower, memory, and speed of modern Central Processing Units (CPUs), GraphicsProcessing Units (GPUs), and Field Programmable Gate Arrays (FPGAs).Consequently, the performance and complexity of Artificial Neural Networks(ANNs) is burgeoning. While GPU accelerated Deep Neural Networks (DNNs)currently offer state-of-the-art performance, they consume large amounts ofpower. Training such networks on CPUs is inefficient, as data throughput andparallel computation is limited. FPGAs are considered a suitable candidate forperformance critical, low power systems, e.g. the Internet of Things (IOT) edgedevices. Using the Xilinx SDAccel or Intel FPGA SDK for OpenCL developmentenvironment, networks described using the high-level OpenCL framework can beaccelerated on heterogeneous platforms. Moreover, the resource utilization andpower consumption of DNNs can be further enhanced by utilizing regularizationtechniques that binarize network weights. In this paper, we introduce, to thebest of our knowledge, the first FPGA-accelerated stochastically binarized DNNimplementations, and compare them to implementations accelerated using bothGPUs and FPGAs. Our developed networks are trained and benchmarked using thepopular MNIST and CIFAR-10 datasets, and achieve near state-of-the-artperformance, while offering a &gt;16-fold improvement in power consumption,compared to conventional GPU-accelerated networks. Both our FPGA-accelerateddeterminsitic and stochastic BNNs reduce inference times on MNIST and CIFAR-10by &gt;9.89x and &gt;9.91x, respectively."^^schema:Text ;
    schema:author "Corey Lammie"^^schema:Person,
        "Mostafa Rahimi Azghadi"^^schema:Person,
        "Wei Xiang"^^schema:Person ;
    schema:dateModified "2019-05-15T12:04:36Z"^^schema:DateTime ;
    schema:datePublished "2019-05-15T12:04:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Accelerating Deterministic and Stochastic Binarized Neural Networks on  FPGAs Using OpenCL"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.06105v1"^^schema:URL .

<1078> a schema:ScholarlyArticle ;
    schema:abstract "Learning from data has led to paradigm shifts in a multitude of disciplines,including web, text, and image search, speech recognition, as well asbioinformatics. Can machine learning enable similar breakthroughs inunderstanding quantum many-body systems? Here we develop an efficient deeplearning approach that enables spatially and chemically resolved insights intoquantum-mechanical observables of molecular systems. We unify concepts frommany-body Hamiltonians with purpose-designed deep tensor neural networks(DTNN), which leads to size-extensive and uniformly accurate (1 kcal/mol)predictions in compositional and configurational chemical space for moleculesof intermediate size. As an example of chemical relevance, the DTNN modelreveals a classification of aromatic rings with respect to their stability -- auseful property that is not contained as such in the training dataset. Furtherapplications of DTNN for predicting atomic energies and local chemicalpotentials in molecules, reliable isomer energies, and molecules with peculiarelectronic structure demonstrate the high potential of machine learning forrevealing novel insights into complex quantum-chemical systems."^^schema:Text ;
    schema:author "Alexandre Tkatchenko"^^schema:Person,
        "Farhad Arbabzadah"^^schema:Person,
        "Klaus R. Müller"^^schema:Person,
        "Kristof T. Schütt"^^schema:Person,
        "Stefan Chmiela"^^schema:Person ;
    schema:dateModified "2016-11-07T11:03:49Z"^^schema:DateTime ;
    schema:datePublished "2016-09-27T05:17:34Z"^^schema:DateTime ;
    schema:genre "physics.chem-ph"^^schema:Text ;
    schema:headline "Quantum-Chemical Insights from Deep Tensor Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1609.08259v4"^^schema:URL .

<1079> a schema:ScholarlyArticle ;
    schema:abstract "There has been a recent surge in research on adversarial perturbations thatdefeat Deep Neural Networks (DNNs) in machine vision; most of theseperturbation-based attacks target object classifiers. Inspired by theobservation that humans are able to recognize objects that appear out of placein a scene or along with other unlikely objects, we augment the DNN with asystem that learns context consistency rules during training and checks for theviolations of the same during testing. Our approach builds a set ofauto-encoders, one for each object class, appropriately trained so as to outputa discrepancy between the input and output if an added adversarial perturbationviolates context consistency rules. Experiments on PASCAL VOC and MS COCO showthat our method effectively detects various adversarial attacks and achieveshigh ROC-AUC (over 0.95 in most cases); this corresponds to over 20%improvement over a state-of-the-art context-agnostic method."^^schema:Text ;
    schema:author "Amit Roy-Chowdhury"^^schema:Person,
        "Ananthram Swami"^^schema:Person,
        "Chengyu Song"^^schema:Person,
        "Kevin S Chan"^^schema:Person,
        "Shasha Li"^^schema:Person,
        "Shitong Zhu"^^schema:Person,
        "Srikanth Krishnamurthy"^^schema:Person,
        "Sudipta Paul"^^schema:Person ;
    schema:dateModified "2020-07-24T17:02:41Z"^^schema:DateTime ;
    schema:datePublished "2020-07-19T19:46:45Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Connecting the Dots: Detecting Adversarial Perturbations Using Context  Inconsistency"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.09763v2"^^schema:URL .

<108> a schema:ScholarlyArticle ;
    schema:abstract "Most existing machine learning classifiers are highly vulnerable toadversarial examples. An adversarial example is a sample of input data whichhas been modified very slightly in a way that is intended to cause a machinelearning classifier to misclassify it. In many cases, these modifications canbe so subtle that a human observer does not even notice the modification atall, yet the classifier still makes a mistake. Adversarial examples posesecurity concerns because they could be used to perform an attack on machinelearning systems, even if the adversary has no access to the underlying model.Up to now, all previous work have assumed a threat model in which the adversarycan feed data directly into the machine learning classifier. This is not alwaysthe case for systems operating in the physical world, for example those whichare using signals from cameras and other sensors as an input. This paper showsthat even in such physical world scenarios, machine learning systems arevulnerable to adversarial examples. We demonstrate this by feeding adversarialimages obtained from cell-phone camera to an ImageNet Inception classifier andmeasuring the classification accuracy of the system. We find that a largefraction of adversarial examples are classified incorrectly even when perceivedthrough the camera."^^schema:Text ;
    schema:author "Alexey Kurakin"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "1687"^^schema:Integer ;
    schema:dateModified "2017-02-11T00:39:39Z"^^schema:DateTime ;
    schema:datePublished "2016-07-08T21:12:11Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial examples in the physical world"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.02533v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=263531058904899909&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1080> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we investigate the problem of scheduling and resourceallocation over a time varying set of clients with heterogeneous demands.Inthis context, a service provider has to schedule traffic destined to users withdifferent classes of requirements and to allocate bandwidth resources over timeas a means to efficiently satisfy service demands within a limited timehorizon. This is a highly intricate problem, in particular in wirelesscommunication systems, and solutions may involve tools stemming from diversefields, including combinatorics and constrained optimization. Although recentwork has successfully proposed solutions based on Deep Reinforcement Learning(DRL), the challenging setting of heterogeneous user traffic and demands hasnot been addressed. We propose a deep deterministic policy gradient algorithmthat combines state-of-the-art techniques, namely Distributional RL and DeepSets, to train a model for heterogeneous traffic scheduling. We test on diversescenarios with different time dependence dynamics, users' requirements, andresources available, demonstrating consistent results using both synthetic andreal data. We evaluate the algorithm on a wireless communication setting usingboth synthetic and real data and show significant gains in terms of Quality ofService (QoS) defined by the classes, against state-of-the-art conventionalalgorithms from combinatorics, optimization and scheduling metric(e.g.Knapsack, Integer Linear Programming, Frank-Wolfe, Exponential Rule)."^^schema:Text ;
    schema:author "Apostolos Avranas"^^schema:Person,
        "Marios Kountouris"^^schema:Person,
        "Philippe Ciblat"^^schema:Person ;
    schema:dateModified "2020-11-27T09:49:38Z"^^schema:DateTime ;
    schema:datePublished "2020-11-27T09:49:38Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Wireless Scheduling with Multiclass  Services"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13634v1"^^schema:URL .

<1081> a schema:ScholarlyArticle ;
    schema:abstract "Sparse rewards present a difficult problem in reinforcement learning and maybe inevitable in certain domains with complex dynamics such as real-worldrobotics. Hindsight Experience Replay (HER) is a recent replay memorydevelopment that allows agents to learn in sparse settings by altering memoriesto show them as successful even though they may not be. While, empirically, HERhas shown some success, it does not provide guarantees around the makeup ofsamples drawn from an agent's replay memory. This may result in minibatchesthat contain only memories with zero-valued rewards or agents learning anundesirable policy that completes HER-adjusted goals instead of the actualgoal.  In this paper, we introduce Or Your Money Back (OYMB), a replay memorysampler designed to work with HER. OYMB improves training efficiency in sparsesettings by providing a direct interface to the agent's replay memory thatallows for control over minibatch makeup, as well as a preferential lookupscheme that prioritizes real-goal memories before HER-adjusted memories. Wetest our approach on five tasks across three unique environments. Our resultsshow that using HER in combination with OYMB outperforms using HER alone andleads to agents that learn to complete the real goal more quickly."^^schema:Text ;
    schema:author "Trevor A. McInroe"^^schema:Person ;
    schema:dateModified "2020-08-28T14:48:48Z"^^schema:DateTime ;
    schema:datePublished "2020-08-28T14:48:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Sample Efficiency in Sparse Reinforcement Learning: Or Your Money Back"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.12693v1"^^schema:URL .

<1082> a schema:ScholarlyArticle ;
    schema:abstract "The following article introduces a new parametric synthesis algorithm forsound textures inspired by existing methods used for visual textures. Using a2D Convolutional Neural Network (CNN), a sound signal is modified until thetemporal cross-correlations of the feature maps of its log-spectrogram resemblethose of a target texture. We show that the resulting synthesized sound signalis both different from the original and of high quality, while being able toreproduce singular events appearing in the original. This process is performedin the time domain, discarding the harmful phase recovery step which usuallyconcludes synthesis performed in the time-frequency domain. It is alsostraightforward and flexible, as it does not require any fine tuning betweenseveral losses when synthesizing diverse sound textures. A way of extending thesynthesis in order to produce a sound of any length is also presented, afterwhich synthesized spectrograms and sound signals are showcased. We also discusson the choice of CNN, on border effects in our synthesized signals and onpossible ways of modifying the algorithm in order to improve its current longcomputation time."^^schema:Text ;
    schema:author "Axel Roebel"^^schema:Person,
        "Hugo Caracalla"^^schema:Person ;
    schema:dateModified "2019-05-09T13:51:27Z"^^schema:DateTime ;
    schema:datePublished "2019-05-09T13:51:27Z"^^schema:DateTime ;
    schema:genre "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Sound texture synthesis using convolutional neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.03637v1"^^schema:URL .

<1083> a schema:ScholarlyArticle ;
    schema:abstract "We describe a novel method for the application of Convolutional NeuralNetworks (CNNs) to fields defined on the sphere, using the HEALPix tessellationscheme. Specifically, We have developed a pixel-based approach to implementconvolutional layers on the spherical surface, similarly to what is commonlydone for CNNs in Euclidian space. The algorithm is fully integrable withexisting libraries for NNs (e.g., PyTorch or TensorFlow). We present twoapplications: (i) recognition of handwritten digits projected on the sphere;(ii) estimation of cosmological parameter from Cosmic Microwave Background(CMB) simulated maps. We have built a simple NN architecture, consisting infour convolutional+pooling layers, and have used it for all the applicationsexplored herein. For what concerns the handwritten digits, our CNN reaches anaccuracy of about 95%, comparable with other existing spherical CNNs. For CMBapplications, we have tested the CNN on the estimation of a \"mock\" parameter,defining the angular scale at which the power spectrum of a Gaussian fieldprojected on the sphere peaks. We have estimated this parameter directly frommaps, in several cases: temperature and polarization, presence of noise andpartial sky coverage. In all the cases, the NN performances are comparable withthose from standard spectrum-based bayesian methods. We demonstrate, for thefirst time, the capability of CNNs to extract information from polarizationfields and to distinguish between E and B-modes. Lastly, we have applied ourCNN to the estimation of the Thomson scattering optical depth at reionization(tau) from simulated CMB maps. Even without any specific optimization of the NNarchitecture, we reach an accuracy comparable with standard bayesian methods.This work represents a first step towards the exploitation of NNs in CMBparameter estimation and demonstrates the feasibility of our approach."^^schema:Text ;
    schema:author "Maurizio Tomasi"^^schema:Person,
        "Nicoletta Krachmalnicoff"^^schema:Person ;
    schema:dateModified "2019-07-15T13:49:57Z"^^schema:DateTime ;
    schema:datePublished "2019-02-11T19:00:02Z"^^schema:DateTime ;
    schema:genre "astro-ph.IM"^^schema:Text ;
    schema:headline "Convolutional Neural Networks on the HEALPix sphere: a pixel-based  algorithm and its application to CMB data analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.04083v2"^^schema:URL .

<1084> a schema:ScholarlyArticle ;
    schema:abstract "End-to-end models for raw audio generation are a challenge, specially if theyhave to work with non-parallel data, which is a desirable setup in manysituations. Voice conversion, in which a model has to impersonate a speaker ina recording, is one of those situations. In this paper, we propose Blow, asingle-scale normalizing flow using hypernetwork conditioning to performmany-to-many voice conversion between raw audio. Blow is trained end-to-end,with non-parallel data, on a frame-by-frame basis using a single speakeridentifier. We show that Blow compares favorably to existing flow-basedarchitectures and other competitive baselines, obtaining equal or betterperformance in both objective and subjective evaluations. We further assess theimpact of its main components with an ablation study, and quantify a number ofproperties such as the necessary amount of training data or the preference forsource or target speakers."^^schema:Text ;
    schema:author "Carlos Segura"^^schema:Person,
        "Joan Serrà"^^schema:Person,
        "Santiago Pascual"^^schema:Person ;
    schema:dateModified "2019-09-05T12:20:50Z"^^schema:DateTime ;
    schema:datePublished "2019-06-03T13:33:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Blow: a single-scale hyperconditioned flow for non-parallel raw-audio  voice conversion"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.00794v2"^^schema:URL .

<1085> a schema:ScholarlyArticle ;
    schema:abstract "To avoid the exhaustive search over locations and scales, currentstate-of-the-art object detection systems usually involve a crucial componentgenerating a batch of candidate object proposals from images. In this paper, wepresent a simple yet effective approach for segmenting object proposals via adeep architecture of recursive neural networks (ReNNs), which hierarchicallygroups regions for detecting object candidates over scales. Unlike traditionalmethods that mainly adopt fixed similarity measures for merging regions orfinding object proposals, our approach adaptively learns the region mergingsimilarity and the objectness measure during the process of hierarchical regiongrouping. Specifically, guided by a structured loss, the ReNN model jointlyoptimizes the cross-region similarity metric with the region merging process aswell as the objectness prediction. During inference of the object proposalgeneration, we introduce randomness into the greedy search to cope with theambiguity of grouping regions. Extensive experiments on standard benchmarks,e.g., PASCAL VOC and ImageNet, suggest that our approach is capable ofproducing object proposals with high recall while well preserving the objectboundaries and outperforms other existing methods in both accuracy andefficiency."^^schema:Text ;
    schema:author "Liang Lin"^^schema:Person,
        "Nong Xiao"^^schema:Person,
        "Tianshui Chen"^^schema:Person,
        "Xian Wu"^^schema:Person,
        "Xiaonan Luo"^^schema:Person ;
    schema:dateModified "2018-07-29T02:17:35Z"^^schema:DateTime ;
    schema:datePublished "2016-12-04T03:35:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Segment Object Candidates via Recursive Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1612.01057v4"^^schema:URL .

<1086> a schema:ScholarlyArticle ;
    schema:abstract "We examine Memory Networks for the task of question answering (QA), undercommon real world scenario where training examples are scarce and under weaklysupervised scenario, that is only extrinsic labels are available for training.We propose extensions for the Dynamic Memory Network (DMN), specifically withinthe attention mechanism, we call the resulting Neural Architecture as DynamicMemory Tensor Network (DMTN). Ultimately, we see that our proposed extensionsresults in over 80% improvement in the number of task passed against thebaselined standard DMN and 20% more task passed compared to state-of-the-artEnd-to-End Memory Network for Facebook's single task weakly trained 1K bAbidataset."^^schema:Text ;
    schema:author "Ajay Sohmshetty"^^schema:Person,
        "Govardana Sachithanandam Ramachandran"^^schema:Person ;
    schema:dateModified "2017-03-11T10:05:19Z"^^schema:DateTime ;
    schema:datePublished "2017-03-11T10:05:19Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1703.03939v1"^^schema:URL .

<1087> a schema:ScholarlyArticle ;
    schema:abstract "Dialogue relation extraction (DRE) aims to detect the relation between twoentities mentioned in a multi-party dialogue. It plays an important role inconstructing knowledge graphs from conversational data increasingly abundant onthe internet and facilitating intelligent dialogue system development. Theprior methods of DRE do not meaningfully leverage speaker information-they justprepend the utterances with the respective speaker names. Thus, they fail tomodel the crucial inter-speaker relations that may give additional context torelevant argument entities through pronouns and triggers. We, however, presenta graph attention network-based method for DRE where a graph, that containsmeaningfully connected speaker, entity, entity-type, and utterance nodes, isconstructed. This graph is fed to a graph attention network for contextpropagation among relevant nodes, which effectively captures the dialoguecontext. We empirically show that this graph-based approach quite effectivelycaptures the relations between different entity pairs in a dialogue as itoutperforms the state-of-the-art approaches by a significant margin on thebenchmark dataset DialogRE. Our code is released at:https://github.com/declare-lab/dialog-HGAT"^^schema:Text ;
    schema:author "Hui Chen"^^schema:Person,
        "Navonil Majumder"^^schema:Person,
        "Pengfei Hong"^^schema:Person,
        "Soujanya Poria"^^schema:Person,
        "Wei Han"^^schema:Person ;
    schema:dateModified "2020-09-14T08:20:29Z"^^schema:DateTime ;
    schema:datePublished "2020-09-10T18:51:48Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Dialogue Relation Extraction with Document-level Heterogeneous Graph  Attention Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.05092v2"^^schema:URL .

<1088> a schema:ScholarlyArticle ;
    schema:abstract "Self-supervised pre-training (SSP) employs random image transformations togenerate training data for visual representation learning. In this paper, wefirst present a modeling framework that unifies existing SSP methods aslearning to predict pseudo-labels. Then, we propose new data augmentationmethods of generating training examples whose pseudo-labels are harder topredict than those generated via random image transformations. Specifically, weuse adversarial training and CutMix to create hard examples (HEXA) to be usedas augmented views for MoCo-v2 and DeepCluster-v2, leading to two variantsHEXA_{MoCo} and HEXA_{DCluster}, respectively. In our experiments, we pre-trainmodels on ImageNet and evaluate them on multiple public benchmarks. Ourevaluation shows that the two new algorithm variants outperform their originalcounterparts, and achieve new state-of-the-art on a wide range of tasks wherelimited task supervision is available for fine-tuning. These results verifythat hard examples are instrumental in improving the generalization of thepre-trained models."^^schema:Text ;
    schema:author "Baolin Peng"^^schema:Person,
        "Chunyuan Li"^^schema:Person,
        "Jianfeng Gao"^^schema:Person,
        "Lei Zhang"^^schema:Person,
        "Mingyuan Zhou"^^schema:Person,
        "Xiujun Li"^^schema:Person ;
    schema:dateModified "2021-01-04T01:21:04Z"^^schema:DateTime ;
    schema:datePublished "2020-12-25T02:44:22Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Self-supervised Pre-training with Hard Examples Improves Visual  Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.13493v2"^^schema:URL .

<1089> a schema:ScholarlyArticle ;
    schema:abstract "Drones are enabling new forms of human actions surveillance due to their lowcost and fast mobility. However, using deep neural networks for automaticaerial action recognition is difficult due to the need for a large number oftraining aerial human action videos. Collecting a large number of human actionaerial videos is costly, time-consuming, and difficult. In this paper, weexplore two alternative data sources to improve aerial action classificationwhen only a few training aerial examples are available. As a first data source,we resort to video games. We collect plenty of aerial game action videos usingtwo gaming engines. For the second data source, we leverage conditionalWasserstein Generative Adversarial Networks to generate aerial features fromground videos. Given that both data sources have some limitations, e.g. gamevideos are biased towards specific actions categories (fighting, shooting,etc.,), and it is not easy to generate good discriminative GAN-generatedfeatures for all types of actions, we need to efficiently integrate two datasetsources with few available real aerial training videos. To address thischallenge of the heterogeneous nature of the data, we propose to use a disjointmultitask learning framework. We feed the network with real and game, or realand GAN-generated data in an alternating fashion to obtain an improved actionclassifier. We validate the proposed approach on two aerial action datasets anddemonstrate that features from aerial game videos and those generated from GANcan be extremely useful for an improved action recognition in real aerialvideos when only a few real aerial training examples are available."^^schema:Text ;
    schema:author "Mubarak Shah"^^schema:Person,
        "Waqas Sultani"^^schema:Person ;
    schema:dateModified "2020-09-12T19:44:21Z"^^schema:DateTime ;
    schema:datePublished "2019-10-22T15:02:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Human Action Recognition in Drone Videos using a Few Aerial Training  Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.10027v3"^^schema:URL .

<109> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of synthesizing a number of likely future frames from asingle input image. In contrast to traditional methods, which have tackled thisproblem in a deterministic or non-parametric way, we propose a novel approachthat models future frames in a probabilistic manner. Our probabilistic modelmakes it possible for us to sample and synthesize many possible future framesfrom a single input image. Future frame synthesis is challenging, as itinvolves low- and high-level image and motion understanding. We propose a novelnetwork structure, namely a Cross Convolutional Network to aid in synthesizingfuture frames; this network structure encodes image and motion information asfeature maps and convolutional kernels, respectively. In experiments, our modelperforms well on synthetic data, such as 2D shapes and animated game sprites,as well as on real-wold videos. We also show that our model can be applied totasks such as visual analogy-making, and present an analysis of the learnednetwork representations."^^schema:Text ;
    schema:author "Jiajun Wu"^^schema:Person,
        "Katherine L. Bouman"^^schema:Person,
        "Tianfan Xue"^^schema:Person,
        "William T. Freeman"^^schema:Person ;
    schema:commentCount "306"^^schema:Integer ;
    schema:dateModified "2016-07-09T08:41:40Z"^^schema:DateTime ;
    schema:datePublished "2016-07-09T08:41:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Visual Dynamics: Probabilistic Future Frame Synthesis via Cross  Convolutional Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.02586v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6484494541166161719&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1090> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning has shown great promise in robotics thanks to itsability to develop efficient robotic control procedures through self-training.In particular, reinforcement learning has been successfully applied to solvingthe reaching task with robotic arms. In this paper, we define a robust,reproducible and systematic experimental procedure to compare the performanceof various model-free algorithms at solving this task. The policies are trainedin simulation and are then transferred to a physical robotic manipulator. It isshown that augmenting the reward signal with the Hindsight Experience Replayexploration technique increases the average return of off-policy agents between7 and 9 folds when the target position is initialised randomly at the beginningof each episode."^^schema:Text ;
    schema:author "David McAuliffe"^^schema:Person,
        "Francisco Javier Rodríguez Lera"^^schema:Person,
        "Philip Cardiff"^^schema:Person,
        "Pierre Aumjaud"^^schema:Person ;
    schema:dateModified "2020-11-11T14:00:49Z"^^schema:DateTime ;
    schema:datePublished "2020-11-11T14:00:49Z"^^schema:DateTime ;
    schema:genre "I.2.9; I.2.11"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Reinforcement Learning Experiments and Benchmark for Solving Robotic  Reaching Tasks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05782v1"^^schema:URL .

<1091> a schema:ScholarlyArticle ;
    schema:abstract "We target the problem of detecting Trojans or backdoors in DNNs. Such modelsbehave normally with typical inputs but produce specific incorrect predictionsfor inputs poisoned with a Trojan trigger. Our approach is based on a novelobservation that the trigger behavior depends on a few ghost neurons thatactivate on trigger pattern and exhibit abnormally higher relative attributionfor wrong decisions when activated. Further, these trigger neurons are alsoactive on normal inputs of the target class. Thus, we use counterfactualattributions to localize these ghost neurons from clean inputs and thenincrementally excite them to observe changes in the model's accuracy. We usethis information for Trojan detection by using a deep set encoder that enablesinvariance to the number of model classes, architecture, etc. Our approach isimplemented in the TrinityAI tool that exploits the synergies betweentrustworthiness, resilience, and interpretability challenges in deep learning.We evaluate our approach on benchmarks with high diversity in modelarchitectures, triggers, etc. We show consistent gains (+10%) overstate-of-the-art methods that rely on the susceptibility of the DNN to specificadversarial attacks, which in turn requires strong assumptions on the nature ofthe Trojan attack."^^schema:Text ;
    schema:author "Ajay Divakaran"^^schema:Person,
        "Anirban Roy"^^schema:Person,
        "Indranil Sur"^^schema:Person,
        "Karan Sikka"^^schema:Person,
        "Susmit Jha"^^schema:Person ;
    schema:dateModified "2020-12-03T21:21:33Z"^^schema:DateTime ;
    schema:datePublished "2020-12-03T21:21:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Detecting Trojaned DNNs Using Counterfactual Attributions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02275v1"^^schema:URL .

<1092> a schema:ScholarlyArticle ;
    schema:abstract "An ability to generalize unconstrained conditions such as severe occlusionsand large pose variations remains a challenging goal to achieve in facealignment. In this paper, a multistage model based on deep neural networks isproposed which takes advantage of spatial transformer networks, hourglassnetworks and exemplar-based shape constraints. First, a spatial transformer -generative adversarial network which consists of convolutional layers andresidual units is utilized to solve the initialization issues caused by facedetectors, such as rotation and scale variations, to obtain improved facebounding boxes for face alignment. Then, stacked hourglass network is employedto obtain preliminary locations of landmarks as well as their correspondingscores. In addition, an exemplar-based shape dictionary is designed todetermine landmarks with low scores based on those with high scores. Byincorporating face shape constraints, misaligned landmarks caused by occlusionsor cluttered backgrounds can be considerably improved. Extensive experimentsbased on challenging benchmark datasets are performed to demonstrate thesuperior performance of the proposed method over other state-of-the-artmethods."^^schema:Text ;
    schema:author "Hon Keung Kwan"^^schema:Person,
        "Huabin Wang"^^schema:Person,
        "Jian Zhou"^^schema:Person,
        "Liang Tao"^^schema:Person,
        "Rui Cheng"^^schema:Person ;
    schema:dateModified "2020-02-04T01:13:58Z"^^schema:DateTime ;
    schema:datePublished "2020-02-04T01:13:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Multistage Model for Robust Face Alignment Using Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.01075v1"^^schema:URL .

<1093> a schema:ScholarlyArticle ;
    schema:abstract "Modeling the distribution of natural images is challenging, partly because ofstrong statistical dependencies which can extend over hundreds of pixels.Recurrent neural networks have been successful in capturing long-rangedependencies in a number of problems but only recently have found their wayinto generative image models. We here introduce a recurrent image model basedon multi-dimensional long short-term memory units which are particularly suitedfor image modeling due to their spatial structure. Our model scales to imagesof arbitrary size and its likelihood is computationally tractable. We find thatit outperforms the state of the art in quantitative comparisons on severalimage datasets and produces promising results when used for texture synthesisand inpainting."^^schema:Text ;
    schema:author "Lucas Theis"^^schema:Person,
        "Matthias Bethge"^^schema:Person ;
    schema:dateModified "2015-09-18T08:06:06Z"^^schema:DateTime ;
    schema:datePublished "2015-06-10T20:56:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Image Modeling Using Spatial LSTMs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1506.03478v2"^^schema:URL .

<1094> a schema:ScholarlyArticle ;
    schema:abstract "Neural Architecture Search (NAS), the process of automating architectureengineering, is an appealing next step to advancing end-to-end Automatic SpeechRecognition (ASR), replacing expert-designed networks with learned,task-specific architectures. In contrast to early computational-demanding NASmethods, recent gradient-based NAS methods, e.g., DARTS (DifferentiableARchiTecture Search), SNAS (Stochastic NAS) and ProxylessNAS, significantlyimprove the NAS efficiency. In this paper, we make two contributions. First, werigorously develop an efficient NAS method via Straight-Through (ST) gradients,called ST-NAS. Basically, ST-NAS uses the loss from SNAS but uses ST toback-propagate gradients through discrete variables to optimize the loss, whichis not revealed in ProxylessNAS. Using ST gradients to support sub-graphsampling is a core element to achieve efficient NAS beyond DARTS and SNAS.Second, we successfully apply ST-NAS to end-to-end ASR. Experiments over thewidely benchmarked 80-hour WSJ and 300-hour Switchboard datasets show that theST-NAS induced architectures significantly outperform the human-designedarchitecture across the two datasets. Strengths of ST-NAS such as architecturetransferability and low computation cost in memory and time are also reported."^^schema:Text ;
    schema:author "Huahuan Zheng"^^schema:Person,
        "Keyu An"^^schema:Person,
        "Zhijian Ou"^^schema:Person ;
    schema:dateModified "2020-11-11T09:18:58Z"^^schema:DateTime ;
    schema:datePublished "2020-11-11T09:18:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Efficient Neural Architecture Search for End-to-end Speech Recognition  via Straight-Through Gradients"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05649v1"^^schema:URL .

<1095> a schema:ScholarlyArticle ;
    schema:abstract "Learning informative representations (aka. embeddings) of users and items isthe core of modern recommender systems. Previous works exploit user-itemrelationships of one-hop neighbors in the user-item interaction graph toimprove the quality of representation. Recently, the research of Graph NeuralNetwork (GNN) for recommendation considers the implicit collaborativeinformation of multi-hop neighbors to enrich the representation. However, mostworks of GNN for recommendation systems do not consider the relationalinformation which implies the expression differences of different neighbors inthe neighborhood explicitly. The influence of each neighboring item to therepresentation of the user's preference can be represented by the correlationbetween the item and neighboring items of the user. Symmetrically, for a givenitem, the correlation between one neighboring user and neighboring users canreflect the strength of signal about the item's characteristic. To modeling theimplicit correlations of neighbors in graph embedding aggregating, we propose aNeighbor-Aware Graph Attention Network for recommendation task, termedNGAT4Rec. It employs a novel neighbor-aware graph attention layer that assignsdifferent neighbor-aware attention coefficients to different neighbors of agiven node by computing the attention among these neighbors pairwisely. ThenNGAT4Rec aggregates the embeddings of neighbors according to the correspondingneighbor-aware attention coefficients to generate next layer embedding forevery node. Furthermore, we combine more neighbor-aware graph attention layerto gather the influential signals from multi-hop neighbors. We remove featuretransformation and nonlinear activation that proved to be useless oncollaborative filtering. Extensive experiments on three benchmark datasets showthat our model outperforms various state-of-the-art models consistently."^^schema:Text ;
    schema:author "Chao Chang"^^schema:Person,
        "Fei Sun"^^schema:Person,
        "Jinbo Song"^^schema:Person,
        "Peng Jiang"^^schema:Person,
        "Xinbo Song"^^schema:Person ;
    schema:dateModified "2020-10-23T09:37:43Z"^^schema:DateTime ;
    schema:datePublished "2020-10-23T09:37:43Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text ;
    schema:headline "NGAT4Rec: Neighbor-Aware Graph Attention Network For Recommendation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.12256v1"^^schema:URL .

<1096> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of learning fair decision systems in complexscenarios in which a sensitive attribute might affect the decision along bothfair and unfair pathways. We introduce a causal approach to disregard effectsalong unfair pathways that simplifies and generalizes previous literature. Ourmethod corrects observations adversely affected by the sensitive attribute, anduses these to form a decision. This avoids disregarding fair information, anddoes not require an often intractable computation of the path-specific effect.We leverage recent developments in deep learning and approximate inference toachieve a solution that is widely applicable to complex, non-linear scenarios."^^schema:Text ;
    schema:author "Silvia Chiappa"^^schema:Person,
        "Thomas P. S. Gillam"^^schema:Person ;
    schema:dateModified "2018-02-22T16:23:51Z"^^schema:DateTime ;
    schema:datePublished "2018-02-22T16:23:51Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Path-Specific Counterfactual Fairness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.08139v1"^^schema:URL .

<1097> a schema:ScholarlyArticle ;
    schema:abstract "Recent research has demonstrated that adding some imperceptible perturbationsto original images can fool deep learning models. However, the currentadversarial perturbations are usually shown in the form of noises, and thushave no practical meaning. Image watermark is a technique widely used forcopyright protection. We can regard image watermark as a king of meaningfulnoises and adding it to the original image will not affect people'sunderstanding of the image content, and will not arouse people's suspicion.Therefore, it will be interesting to generate adversarial examples usingwatermarks. In this paper, we propose a novel watermark perturbation foradversarial examples (Adv-watermark) which combines image watermarkingtechniques and adversarial example algorithms. Adding a meaningful watermark tothe clean images can attack the DNN models. Specifically, we propose a noveloptimization algorithm, which is called Basin Hopping Evolution (BHE), togenerate adversarial watermarks in the black-box attack mode. Thanks to theBHE, Adv-watermark only requires a few queries from the threat models to finishthe attacks. A series of experiments conducted on ImageNet and CASIA-WebFacedatasets show that the proposed method can efficiently generate adversarialexamples, and outperforms the state-of-the-art attack methods. Moreover,Adv-watermark is more robust against image transformation defense methods."^^schema:Text ;
    schema:author "Xiaochun Cao"^^schema:Person,
        "Xiaoguang Han"^^schema:Person,
        "Xiaojun Jia"^^schema:Person,
        "Xingxing Wei"^^schema:Person ;
    schema:dateModified "2020-08-29T19:10:01Z"^^schema:DateTime ;
    schema:datePublished "2020-08-05T03:28:43Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01919v2"^^schema:URL .

<1098> a schema:ScholarlyArticle ;
    schema:abstract "Recently, an abundant amount of urban vehicle trajectory data has beencollected in road networks. Many studies have used machine learning algorithmsto analyze patterns in vehicle trajectories to predict location sequences ofindividual travelers. Unlike the previous studies that used a discriminativemodeling approach, this research suggests a generative modeling approach tolearn the underlying distributions of urban vehicle trajectory data. Agenerative model for urban vehicle trajectories can better generalize fromtraining data by learning the underlying distribution of the training data and,thus, produce synthetic vehicle trajectories similar to real vehicletrajectories with limited observations. Synthetic trajectories can providesolutions to data sparsity or data privacy issues in using location data. Thisresearch proposesTrajGAIL, a generative adversarial imitation learningframework for the urban vehicle trajectory generation. In TrajGAIL, learninglocation sequences in observed trajectories is formulated as an imitationlearning problem in a partially observable Markov decision process. The modelis trained by the generative adversarial framework, which uses the rewardfunction from the adversarial discriminator. The model is tested with bothsimulation and real-world datasets, and the results show that the proposedmodel obtained significant performance gains compared to existing models insequence modeling."^^schema:Text ;
    schema:author "Hwasoo Yeo"^^schema:Person,
        "Jiwon Kim"^^schema:Person,
        "Seongjin Choi"^^schema:Person ;
    schema:dateModified "2021-01-16T02:41:58Z"^^schema:DateTime ;
    schema:datePublished "2020-07-28T13:17:51Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "TrajGAIL: Generating Urban Vehicle Trajectories using Generative  Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.14189v4"^^schema:URL .

<1099> a schema:ScholarlyArticle ;
    schema:abstract "A multi-task learning (MTL) system aims at solving multiple related tasks atthe same time. With a fixed model capacity, the tasks would be conflicted witheach other, and the system usually has to make a trade-off among learning allof them together. Multiple models with different preferences over tasks have tobe trained and stored for many real-world applications where the trade-off hasto be made online. This work proposes a novel controllable Pareto multi-tasklearning framework, to enable the system to make real-time trade-off switchamong different tasks with a single model. To be specific, we formulate the MTLas a preference-conditioned multiobjective optimization problem, for whichthere is a parametric mapping from the preferences to the optimal Paretosolutions. A single hypernetwork-based multi-task neural network is built tolearn all tasks with different trade-off preferences among them, where thehypernetwork generates the model parameters conditioned on the preference. Atthe inference time, MTL practitioners can easily control the model performancebased on different trade-off preferences in real-time. Experiments on differentapplications demonstrate that the proposed model is efficient for solvingvarious multi-task learning problems."^^schema:Text ;
    schema:author "Qingfu Zhang"^^schema:Person,
        "Sam Kwong"^^schema:Person,
        "Xi Lin"^^schema:Person,
        "Zhiyuan Yang"^^schema:Person ;
    schema:dateModified "2020-10-13T11:53:55Z"^^schema:DateTime ;
    schema:datePublished "2020-10-13T11:53:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Controllable Pareto Multi-Task Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.06313v1"^^schema:URL .

<11> a schema:ScholarlyArticle ;
    schema:abstract "Skeleton based action recognition distinguishes human actions using thetrajectories of skeleton joints, which provide a very good representation fordescribing actions. Considering that recurrent neural networks (RNNs) with LongShort-Term Memory (LSTM) can learn feature representations and model long-termtemporal dependencies automatically, we propose an end-to-end fully connecteddeep LSTM network for skeleton based action recognition. Inspired by theobservation that the co-occurrences of the joints intrinsically characterizehuman actions, we take the skeleton as the input at each time slot andintroduce a novel regularization scheme to learn the co-occurrence features ofskeleton joints. To train the deep LSTM network effectively, we propose a newdropout algorithm which simultaneously operates on the gates, cells, and outputresponses of the LSTM neurons. Experimental results on three human actionrecognition datasets consistently demonstrate the effectiveness of the proposedmodel."^^schema:Text ;
    schema:author "Cuiling Lan"^^schema:Person,
        "Junliang Xing"^^schema:Person,
        "Li Shen"^^schema:Person,
        "Wenjun Zeng"^^schema:Person,
        "Wentao Zhu"^^schema:Person,
        "Xiaohui Xie"^^schema:Person,
        "Yanghao Li"^^schema:Person ;
    schema:commentCount "441"^^schema:Integer ;
    schema:dateModified "2016-03-24T22:43:55Z"^^schema:DateTime ;
    schema:datePublished "2016-03-24T22:43:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Co-occurrence Feature Learning for Skeleton based Action Recognition  using Regularized Deep LSTM Networks"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.07772v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1557422179662919133&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<110> a schema:ScholarlyArticle ;
    schema:abstract "We present a variational approximation to the information bottleneck ofTishby et al. (1999). This variational approach allows us to parameterize theinformation bottleneck model using a neural network and leverage thereparameterization trick for efficient training. We call this method \"DeepVariational Information Bottleneck\", or Deep VIB. We show that models trainedwith the VIB objective outperform those that are trained with other forms ofregularization, in terms of generalization performance and robustness toadversarial attack."^^schema:Text ;
    schema:author "Alexander A. Alemi"^^schema:Person,
        "Ian Fischer"^^schema:Person,
        "Joshua V. Dillon"^^schema:Person,
        "Kevin Murphy"^^schema:Person ;
    schema:commentCount "343"^^schema:Integer ;
    schema:dateModified "2019-10-23T22:47:44Z"^^schema:DateTime ;
    schema:datePublished "2016-12-01T20:12:40Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Deep Variational Information Bottleneck"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.00410v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7425625104303674821&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1100> a schema:ScholarlyArticle ;
    schema:abstract "Trust region methods are a popular tool in reinforcement learning as theyyield robust policy updates in continuous and discrete action spaces. However,enforcing such trust regions in deep reinforcement learning is difficult.Hence, many approaches, such as Trust Region Policy Optimization (TRPO) andProximal Policy Optimization (PPO), are based on approximations. Due to thoseapproximations, they violate the constraints or fail to find the optimalsolution within the trust region. Moreover, they are difficult to implement,lack sufficient exploration, and have been shown to depend on seeminglyunrelated implementation choices. In this work, we propose differentiableneural network layers to enforce trust regions for deep Gaussian policies viaclosed-form projections. Unlike existing methods, those layers formalize trustregions for each state individually and can complement existing reinforcementlearning algorithms. We derive trust region projections based on theKullback-Leibler divergence, the Wasserstein L2 distance, and the Frobeniusnorm for Gaussian distributions. We empirically demonstrate that thoseprojection layers achieve similar or better results than existing methods whilebeing almost agnostic to specific implementation choices."^^schema:Text ;
    schema:author "Fabian Otto"^^schema:Person,
        "Gerhard Neumann"^^schema:Person,
        "Hanna Carolin Ziesche"^^schema:Person,
        "Ngo Anh Vien"^^schema:Person,
        "Philipp Becker"^^schema:Person ;
    schema:dateModified "2021-01-22T16:52:06Z"^^schema:DateTime ;
    schema:datePublished "2021-01-22T16:52:06Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Differentiable Trust Region Layers for Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.09207v1"^^schema:URL .

<1101> a schema:ScholarlyArticle ;
    schema:abstract "Robotic grasp detection task is still challenging, particularly for novelobjects. With the recent advance of deep learning, there have been severalworks on detecting robotic grasp using neural networks. Typically, regressionbased grasp detection methods have outperformed classification based detectionmethods in computation complexity with excellent accuracy. However,classification based robotic grasp detection still seems to have merits such asintermediate step observability and straightforward back propagation routinefor end-to-end training. In this work, we propose a novel classification basedrobotic grasp detection method with multiple-stage spatial transformer networks(STN). Our proposed method was able to achieve state-of-the-art performance inaccuracy with real- time computation. Additionally, unlike other regressionbased grasp detection methods, our proposed method allows partial observationfor intermediate results such as grasp location and orientation for a number ofgrasp configuration candidates."^^schema:Text ;
    schema:author "Dongwon Park"^^schema:Person,
        "Se Young Chun"^^schema:Person ;
    schema:dateModified "2018-03-04T14:02:47Z"^^schema:DateTime ;
    schema:datePublished "2018-03-04T14:02:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Classification based Grasp Detection using Spatial Transformer Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.01356v1"^^schema:URL .

<1102> a schema:ScholarlyArticle ;
    schema:abstract "As intelligent systems gain autonomy and capability, it becomes vital toensure that their objectives match those of their human users; this is known asthe value-alignment problem. In robotics, value alignment is key to the designof collaborative robots that can integrate into human workflows, successfullyinferring and adapting to their users' objectives as they go. We argue that ameaningful solution to value alignment must combine multi-agent decision theorywith rich mathematical models of human cognition, enabling robots to tap intopeople's natural collaborative capabilities. We present a solution to thecooperative inverse reinforcement learning (CIRL) dynamic game based onwell-established cognitive models of decision making and theory of mind. Thesolution captures a key reciprocity relation: the human will not plan heractions in isolation, but rather reason pedagogically about how the robot mightlearn from them; the robot, in turn, can anticipate this and interpret thehuman's actions pragmatically. To our knowledge, this work constitutes thefirst formal analysis of value alignment grounded in empirically validatedcognitive models."^^schema:Text ;
    schema:author "Anca D. Dragan"^^schema:Person,
        "Chang Liu"^^schema:Person,
        "Dhruv Malik"^^schema:Person,
        "Dylan Hadfield-Menell"^^schema:Person,
        "Jaime F. Fisac"^^schema:Person,
        "Jessica B. Hamrick"^^schema:Person,
        "Malayandi Palaniappan"^^schema:Person,
        "Monica A. Gates"^^schema:Person,
        "S. Shankar Sastry"^^schema:Person,
        "Thomas L. Griffiths"^^schema:Person ;
    schema:dateModified "2018-02-05T20:44:09Z"^^schema:DateTime ;
    schema:datePublished "2017-07-20T03:07:19Z"^^schema:DateTime ;
    schema:genre "68T05"^^schema:Text,
        "I.2.0; I.2.6; I.2.8; I.2.9"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.HC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Pragmatic-Pedagogic Value Alignment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.06354v2"^^schema:URL .

<1103> a schema:ScholarlyArticle ;
    schema:abstract "The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EMRouting'\" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing."^^schema:Text ;
    schema:author "Ashley Daniel Gritzman"^^schema:Person ;
    schema:dateModified "2019-07-01T10:51:58Z"^^schema:DateTime ;
    schema:datePublished "2019-07-01T10:51:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by  Hinton et al"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.00652v1"^^schema:URL .

<1104> a schema:ScholarlyArticle ;
    schema:abstract "The design of systems implementing low precision neural networks withemerging memories such as resistive random access memory (RRAM) is a major leadfor reducing the energy consumption of artificial intelligence (AI). Multipleworks have for example proposed in-memory architectures to implement low powerbinarized neural networks. These simple neural networks, where synaptic weightsand neuronal activations assume binary values, can indeed approachstate-of-the-art performance on vision tasks. In this work, we revisit one ofthese architectures where synapses are implemented in a differential fashion toreduce bit errors, and synaptic weights are read using precharge senseamplifiers. Based on experimental measurements on a hybrid 130 nm CMOS/RRAMchip and on circuit simulation, we show that the same memory array architecturecan be used to implement ternary weights instead of binary weights, and thatthis technique is particularly appropriate if the sense amplifier is operatedin near-threshold regime. We also show based on neural network simulation onthe CIFAR-10 image recognition task that going from binary to ternary neuralnetworks significantly increases neural network performance. These resultshighlight that AI circuits function may sometimes be revisited when operated inlow power regimes."^^schema:Text ;
    schema:author "Axel Laborieux"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Elisa Vianello"^^schema:Person,
        "Etienne Nowak"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Liza Herrera Diez"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2020-05-05T07:26:59Z"^^schema:DateTime ;
    schema:datePublished "2020-05-05T07:26:59Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "Low Power In-Memory Implementation of Ternary Neural Networks with  Resistive RAM-Based Synapse"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.01973v1"^^schema:URL .

<1105> a schema:ScholarlyArticle ;
    schema:abstract "Many commonly used learning algorithms work by iteratively updating anintermediate solution using one or a few data points in each iteration.Analysis of differential privacy for such algorithms often involves ensuringprivacy of each step and then reasoning about the cumulative privacy cost ofthe algorithm. This is enabled by composition theorems for differential privacythat allow releasing of all the intermediate results. In this work, wedemonstrate that for contractive iterations, not releasing the intermediateresults strongly amplifies the privacy guarantees.  We describe several applications of this new analysis technique to solvingconvex optimization problems via noisy stochastic gradient descent. Forexample, we demonstrate that a relatively small number of non-private datapoints from the same distribution can be used to close the gap between privateand non-private convex optimization. In addition, we demonstrate that we canachieve guarantees similar to those obtainable using theprivacy-amplification-by-sampling technique in several natural settings wherethat technique cannot be applied."^^schema:Text ;
    schema:author "Abhradeep Thakurta"^^schema:Person,
        "Ilya Mironov"^^schema:Person,
        "Kunal Talwar"^^schema:Person,
        "Vitaly Feldman"^^schema:Person ;
    schema:dateModified "2018-12-10T23:43:40Z"^^schema:DateTime ;
    schema:datePublished "2018-08-20T18:49:32Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Privacy Amplification by Iteration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.06651v2"^^schema:URL .

<1106> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement Learning algorithms can learn complex behavioral patterns forsequential decision making tasks wherein an agent interacts with an environmentand acquires feedback in the form of rewards sampled from it. Traditionally,such algorithms make decisions, i.e., select actions to execute, at everysingle time step of the agent-environment interactions. In this paper, wepropose a novel framework, Fine Grained Action Repetition (FiGAR), whichenables the agent to decide the action as well as the time scale of repeatingit. FiGAR can be used for improving any Deep Reinforcement Learning algorithmwhich maintains an explicit policy estimate by enabling temporal abstractionsin the action space. We empirically demonstrate the efficacy of our frameworkby showing performance improvements on top of three policy search algorithms indifferent domains: Asynchronous Advantage Actor Critic in the Atari 2600domain, Trust Region Policy Optimization in Mujoco domain and DeepDeterministic Policy Gradients in the TORCS car racing domain."^^schema:Text ;
    schema:author "Aravind Srinivas"^^schema:Person,
        "Balaraman Ravindran"^^schema:Person,
        "Sahil Sharma"^^schema:Person ;
    schema:dateModified "2020-09-21T22:22:25Z"^^schema:DateTime ;
    schema:datePublished "2017-02-20T16:32:07Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning to Repeat: Fine Grained Action Repetition for Deep  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.06054v2"^^schema:URL .

<1107> a schema:ScholarlyArticle ;
    schema:abstract "The field of predictive process monitoring focuses on modelling futurecharacteristics of running business process instances, typically by eitherpredicting the outcome of particular objectives (e.g. completion (time), cost),or next-in-sequence prediction (e.g. what is the next activity to execute).This paper introduces Processes-As-Movies (PAM), a technique that provides amiddle ground between these predictive monitoring. It does so by capturingdeclarative process constraints between activities in various windows of aprocess execution trace, which represent a declarative process model atsubsequent stages of execution. This high-dimensional representation of aprocess model allows the application of predictive modelling on how suchconstraints appear and vanish throughout a process' execution. Variousrecurrent neural network topologies tailored to high-dimensional input are usedto model the process model evolution with windows as time steps, includingencoder-decoder long short-term memory networks, and convolutional longshort-term memory networks. Results show that these topologies are veryeffective in terms of accuracy and precision to predict a process model'sfuture state, which allows process owners to simultaneously verify what lineartemporal logic rules hold in a predicted process window (objective-based), andverify what future execution traces are allowed by all the constraints together(trace-based)."^^schema:Text ;
    schema:author "Jochen De Weerdt"^^schema:Person,
        "Johannes De Smedt"^^schema:Person,
        "Junichiro Mori"^^schema:Person,
        "Masanao Ochi"^^schema:Person ;
    schema:dateModified "2021-01-22T14:15:16Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T13:57:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Predictive Process Model Monitoring using Recurrent Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02819v2"^^schema:URL .

<1108> a schema:ScholarlyArticle ;
    schema:abstract "We propose a semi-supervised generative model, SeGMA, which learns a jointprobability distribution of data and their classes and which is implemented ina typical Wasserstein auto-encoder framework. We choose a mixture of Gaussiansas a target distribution in latent space, which provides a natural splitting ofdata into clusters. To connect Gaussian components with correct classes, we usea small amount of labeled data and a Gaussian classifier induced by the targetdistribution. SeGMA is optimized efficiently due to the use of Cramer-Wolddistance as a maximum mean discrepancy penalty, which yields a closed-formexpression for a mixture of spherical Gaussian components and thus obviates theneed of sampling. While SeGMA preserves all properties of its semi-supervisedpredecessors and achieves at least as good generative performance on standardbenchmark data sets, it presents additional features: (a) interpolation betweenany pair of points in the latent space produces realistically-looking samples;(b) combining the interpolation property with disentangled class and stylevariables, SeGMA is able to perform a continuous style transfer from one classto another; (c) it is possible to change the intensity of class characteristicsin a data point by moving the latent representation of the data point away fromspecific Gaussian components."^^schema:Text ;
    schema:author "Bernhard C. Geiger"^^schema:Person,
        "Jacek Tabor"^^schema:Person,
        "Maciej Wołczyk"^^schema:Person,
        "Marek Śmieja"^^schema:Person ;
    schema:dateModified "2020-08-27T08:49:02Z"^^schema:DateTime ;
    schema:datePublished "2019-06-21T21:23:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "SeGMA: Semi-Supervised Gaussian Mixture Auto-Encoder"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.09333v2"^^schema:URL .

<1109> a schema:ScholarlyArticle ;
    schema:abstract "Tracking the state of the conversation is a central component intask-oriented spoken dialogue systems. One such approach for tracking thedialogue state is slot carryover, where a model makes a binary decision if aslot from the context is relevant to the current turn. Previous work on theslot carryover task used models that made independent decisions for each slot.A close analysis of the results show that this approach results in poorperformance over longer context dialogues. In this paper, we propose to jointlymodel the slots. We propose two neural network architectures, one based onpointer networks that incorporate slot ordering information, and the otherbased on transformer networks that uses self attention mechanism to model theslot interdependencies. Our experiments on an internal dialogue benchmarkdataset and on the public DSTC2 dataset demonstrate that our proposed modelsare able to resolve longer distance slot references and are able to achievecompetitive performance."^^schema:Text ;
    schema:author "Chetan Naik"^^schema:Person,
        "Hua He"^^schema:Person,
        "Lambert Mathias"^^schema:Person,
        "Pushpendre Rastogi"^^schema:Person,
        "Tongfei Chen"^^schema:Person ;
    schema:dateModified "2019-06-04T01:13:20Z"^^schema:DateTime ;
    schema:datePublished "2019-06-04T01:13:20Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Improving Long Distance Slot Carryover in Spoken Dialogue Systems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.01149v1"^^schema:URL .

<111> a schema:ScholarlyArticle ;
    schema:abstract "This paper describes InfoGAN, an information-theoretic extension to theGenerative Adversarial Network that is able to learn disentangledrepresentations in a completely unsupervised manner. InfoGAN is a generativeadversarial network that also maximizes the mutual information between a smallsubset of the latent variables and the observation. We derive a lower bound tothe mutual information objective that can be optimized efficiently, and showthat our training procedure can be interpreted as a variation of the Wake-Sleepalgorithm. Specifically, InfoGAN successfully disentangles writing styles fromdigit shapes on the MNIST dataset, pose from lighting of 3D rendered images,and background digits from the central digit on the SVHN dataset. It alsodiscovers visual concepts that include hair styles, presence/absence ofeyeglasses, and emotions on the CelebA face dataset. Experiments show thatInfoGAN learns interpretable representations that are competitive withrepresentations learned by existing fully supervised methods."^^schema:Text ;
    schema:author "Ilya Sutskever"^^schema:Person,
        "John Schulman"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Rein Houthooft"^^schema:Person,
        "Xi Chen"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "1957"^^schema:Integer ;
    schema:dateModified "2016-06-12T02:14:31Z"^^schema:DateTime ;
    schema:datePublished "2016-06-12T02:14:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "InfoGAN: Interpretable Representation Learning by Information Maximizing  Generative Adversarial Nets"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.03657v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14881367722116467754&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1110> a schema:ScholarlyArticle ;
    schema:abstract "Surface defect detection is essential and necessary for controlling thequalities of the products during manufacturing. The challenges in this complextask include: 1) collecting defective samples and manually labeling fortraining is time-consuming; 2) the defects' characteristics are difficult todefine as new types of defect can happen all the time; 3) and the real-worldproduct images contain lots of background noise. In this paper, we present atwo-stage defect detection network based on the object detection model YOLO,and the normalizing flow-based defect detection model DifferNet. Our model hashigh robustness and performance on defect detection using real-world videoclips taken from a production line monitoring system. The normalizingflow-based anomaly detection model only requires a small number of good samplesfor training and then perform defect detection on the product images detectedby YOLO. The model we invent employs two novel strategies: 1) a two-stagenetwork using YOLO and a normalizing flow-based model to perform product defectdetection, 2) multi-scale image transformations are implemented to solve theissue product image cropped by YOLO includes many background noise. Besides,extensive experiments are conducted on a new dataset collected from thereal-world factory production line. We demonstrate that our proposed model canlearn on a small number of defect-free samples of single or multiple producttypes. The dataset will also be made public to encourage further studies andresearch in surface defect detection."^^schema:Text ;
    schema:author "Xinran Tie"^^schema:Person,
        "Zijian Kuang"^^schema:Person ;
    schema:dateModified "2020-12-12T05:38:21Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T05:38:21Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Computer Vision and Normalizing Flow Based Defect Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06737v1"^^schema:URL .

<1111> a schema:ScholarlyArticle ;
    schema:abstract "Assistance games (also known as cooperative inverse reinforcement learninggames) have been proposed as a model for beneficial AI, wherein a robotic agentmust act on behalf of a human principal but is initially uncertain about thehumans payoff function. This paper studies multi-principal assistance games,which cover the more general case in which the robot acts on behalf of N humanswho may have widely differing payoffs. Impossibility theorems in social choicetheory and voting theory can be applied to such games, suggesting thatstrategic behavior by the human principals may complicate the robots task inlearning their payoffs. We analyze in particular a bandit apprentice game inwhich the humans act first to demonstrate their individual preferences for thearms and then the robot acts to maximize the sum of human payoffs. We explorethe extent to which the cost of choosing suboptimal arms reduces the incentiveto mislead, a form of natural mechanism design. In this context we propose asocial choice method that uses shared control of a system to combine preferenceinference with social welfare optimization."^^schema:Text ;
    schema:author "Arnaud Fickinger"^^schema:Person,
        "Dylan Hadfield-Menell"^^schema:Person,
        "Simon Zhuang"^^schema:Person,
        "Stuart Russell"^^schema:Person ;
    schema:dateModified "2020-07-19T00:23:25Z"^^schema:DateTime ;
    schema:datePublished "2020-07-19T00:23:25Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Multi-Principal Assistance Games"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.09540v1"^^schema:URL .

<1112> a schema:ScholarlyArticle ;
    schema:abstract "Mixed precision training (MPT) is becoming a practical technique to improvethe speed and energy efficiency of training deep neural networks by leveragingthe fast hardware support for IEEE half-precision floating point that isavailable in existing GPUs. MPT is typically used in combination with atechnique called loss scaling, that works by scaling up the loss value upbefore the start of backpropagation in order to minimize the impact ofnumerical underflow on training. Unfortunately, existing methods make this lossscale value a hyperparameter that needs to be tuned per-model, and a singlescale cannot be adapted to different layers at different training stages. Weintroduce a loss scaling-based training method called adaptive loss scalingthat makes MPT easier and more practical to use, by removing the need to tune amodel-specific loss scale hyperparameter. We achieve this by introducinglayer-wise loss scale values which are automatically computed during trainingto deal with underflow more effectively than existing methods. We presentexperimental results on a variety of networks and tasks that show our approachcan shorten the time to convergence and improve accuracy compared to theexisting state-of-the-art MPT and single-precision floating point"^^schema:Text ;
    schema:author "Brian Vogel"^^schema:Person,
        "Ruizhe Zhao"^^schema:Person,
        "Tanvir Ahmed"^^schema:Person ;
    schema:dateModified "2019-10-28T00:13:08Z"^^schema:DateTime ;
    schema:datePublished "2019-10-28T00:13:08Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adaptive Loss Scaling for Mixed Precision Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12385v1"^^schema:URL .

<1113> a schema:ScholarlyArticle ;
    schema:abstract "We investigate under and overfitting in Generative Adversarial Networks(GANs), using discriminators unseen by the generator to measure generalization.We find that the model capacity of the discriminator has a significant effecton the generator's model quality, and that the generator's poor performancecoincides with the discriminator underfitting. Contrary to our expectations, wefind that generators with large model capacities relative to the discriminatordo not show evidence of overfitting on CIFAR10, CIFAR100, and CelebA."^^schema:Text ;
    schema:author "Amol Kapoor"^^schema:Person,
        "Ben Adlam"^^schema:Person,
        "Charles Weill"^^schema:Person ;
    schema:dateModified "2019-10-30T21:10:36Z"^^schema:DateTime ;
    schema:datePublished "2019-10-30T21:10:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Investigating Under and Overfitting in Wasserstein Generative  Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.14137v1"^^schema:URL .

<1114> a schema:ScholarlyArticle ;
    schema:abstract "This article develops a statistical test for the null hypothesis of strictstationarity of a discrete time stochastic process in the frequency domain.When the null hypothesis is true, the second order cumulant spectrum is zero atall the discrete Fourier frequency pairs in the principal domain. The test usesa window averaged sample estimate of the second order cumulant spectrum tobuild a test statistic with an asymptotic complex standard normal distribution.We derive the test statistic, study the properties of the test and demonstrateits application using 137Cs gamma ray decay data. Future areas of researchinclude testing for strict stationarity of graph signals, with applications inlearning convolutional neural networks on graphs, denoising, and inpainting."^^schema:Text ;
    schema:author "Denisa Roberts"^^schema:Person,
        "Douglas Patterson"^^schema:Person ;
    schema:dateModified "2020-03-29T18:46:52Z"^^schema:DateTime ;
    schema:datePublished "2018-01-20T20:47:27Z"^^schema:DateTime ;
    schema:genre "math.ST"^^schema:Text,
        "q-fin.ST"^^schema:Text,
        "stat.ML"^^schema:Text,
        "stat.TH"^^schema:Text ;
    schema:headline "A Second Order Cumulant Spectrum Test That a Stochastic Process is  Strictly Stationary and a Step Toward a Test for Graph Signal Strict  Stationarity"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.06727v2"^^schema:URL .

<1115> a schema:ScholarlyArticle ;
    schema:abstract "The phenomenon of ellipsis is prevalent in social conversations. Ellipsisincreases the difficulty of a series of downstream language understandingtasks, such as dialog act prediction and semantic role labeling. We propose toresolve ellipsis through automatic sentence completion to improve languageunderstanding. However, automatic ellipsis completion can result in outputwhich does not accurately reflect user intent. To address this issue, wepropose a method which considers both the original utterance that has ellipsisand the automatically completed utterance in dialog act and semantic rolelabeling tasks. Specifically, we first complete user utterances to resolveellipsis using an end-to-end pointer network model. We then train a predictionmodel using both utterances containing ellipsis and our automatically completedutterances. Finally, we combine the prediction results from these twoutterances using a selection model that is guided by expert knowledge. Ourapproach improves dialog act prediction and semantic role labeling by 1.3% and2.5% in F1 score respectively in social conversations. We also present anopen-domain human-machine conversation dataset with manually completed userutterances and annotated semantic role labeling after manual completion."^^schema:Text ;
    schema:author "Chengxi Li"^^schema:Person,
        "Dian Yu"^^schema:Person,
        "Samuel Davidson"^^schema:Person,
        "Xiyuan Zhang"^^schema:Person,
        "Zhou Yu"^^schema:Person ;
    schema:dateModified "2019-11-25T09:21:17Z"^^schema:DateTime ;
    schema:datePublished "2019-11-25T09:21:17Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Filling Conversation Ellipsis for Better Social Dialog Understanding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.10776v1"^^schema:URL .

<1116> a schema:ScholarlyArticle ;
    schema:abstract "The brain performs intelligent tasks with extremely low energy consumption.This work takes inspiration from two strategies used by the brain to achievethis energy efficiency: the absence of separation between computing and memoryfunctions, and the reliance on low precision computation. The emergence ofresistive memory technologies indeed provides an opportunity to co-integratetightly logic and memory in hardware. In parallel, the recently proposedconcept of Binarized Neural Network, where multiplications are replaced byexclusive NOR (XNOR) logic gates, offers a way to implement artificialintelligence using very low precision computation. In this work, we thereforepropose a strategy to implement low energy Binarized Neural Networks, whichemploys brain-inspired concepts, while retaining energy benefits from digitalelectronics. We design, fabricate and test a memory array, including peripheryand sensing circuits, optimized for this in-memory computing scheme. Ourcircuit employs hafnium oxide resistive memory integrated in the back end ofline of a 130 nanometer CMOS process, in a two transistors - two resistorscell, which allows performing the exclusive NOR operations of the neuralnetwork directly within the sense amplifiers. We show, based on extensiveelectrical measurements, that our design allows reducing the amount of biterrors on the synaptic weights, without the use of formal error correctingcodes. We design a whole system using this memory array. We show on standardmachine learning tasks (MNIST, CIFAR-10, ImageNet and an ECG task) that thesystem has an inherent resilience to bit errors. We evidence that its energyconsumption is attractive compared to more standard approaches, and that it canuse the memory devices in regimes where they exhibit particularly lowprogramming energy and high endurance."^^schema:Text ;
    schema:author "Bogdan Penkovsky"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Elisa Vianello"^^schema:Person,
        "Etienne Nowak"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2019-12-07T22:44:27Z"^^schema:DateTime ;
    schema:datePublished "2019-08-12T09:45:50Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "Digital Biologically Plausible Implementation of Binarized Neural  Networks with Differential Hafnium Oxide Resistive Memory Arrays"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.04066v2"^^schema:URL .

<1117> a schema:ScholarlyArticle ;
    schema:abstract "Modern neural networks tend to be overconfident on unseen, noisy orincorrectly labelled data and do not produce meaningful uncertainty measures.Bayesian deep learning aims to address this shortcoming with variationalapproximations (such as Bayes by Backprop or Multiplicative Normalising Flows).However, current approaches have limitations regarding flexibility andscalability. We introduce Bayes by Hypernet (BbH), a new method of variationalapproximation that interprets hypernetworks as implicit distributions. Itnaturally uses neural networks to model arbitrarily complex distributions andscales to modern deep learning architectures. In our experiments, wedemonstrate that our method achieves competitive accuracies and predictiveuncertainties on MNIST and a CIFAR5 task, while being the most robust againstadversarial attacks."^^schema:Text ;
    schema:author "Andrew Brock"^^schema:Person,
        "Ben Glocker"^^schema:Person,
        "Martin Rajchl"^^schema:Person,
        "Matthew C. H. Lee"^^schema:Person,
        "Nick Pawlowski"^^schema:Person ;
    schema:dateModified "2018-05-25T07:00:07Z"^^schema:DateTime ;
    schema:datePublished "2017-11-03T18:49:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Implicit Weight Uncertainty in Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.01297v2"^^schema:URL .

<1118> a schema:ScholarlyArticle ;
    schema:abstract "We train and validate a semi-supervised, multi-task LSTM on 57,675person-weeks of data from off-the-shelf wearable heart rate sensors, showinghigh accuracy at detecting multiple medical conditions, including diabetes(0.8451), high cholesterol (0.7441), high blood pressure (0.8086), and sleepapnea (0.8298). We compare two semi-supervised train- ing methods,semi-supervised sequence learning and heuristic pretraining, and show theyoutperform hand-engineered biomarkers from the medical literature. We believeour work suggests a new approach to patient risk stratification based oncardiovascular risk scores derived from popular wearables such as Fitbit, AppleWatch, or Android Wear."^^schema:Text ;
    schema:author "Avesh Singh"^^schema:Person,
        "Brandon Ballinger"^^schema:Person,
        "Carol Maguire"^^schema:Person,
        "Geoffrey H. Tison"^^schema:Person,
        "Gregory M. Marcus"^^schema:Person,
        "Jack Wang"^^schema:Person,
        "Jeffrey E. Olgin"^^schema:Person,
        "Johnson Hsieh"^^schema:Person,
        "Jose M. Sanchez"^^schema:Person,
        "Mark J. Pletcher"^^schema:Person,
        "Nimit Sohoni"^^schema:Person ;
    schema:dateModified "2018-02-07T16:31:50Z"^^schema:DateTime ;
    schema:datePublished "2018-02-07T16:31:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk  Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.02511v1"^^schema:URL .

<1119> a schema:ScholarlyArticle ;
    schema:abstract "In this work we propose a new deep multibranch neural network to solve thetasks of artist, style, and genre categorization in a multitask formulation. Inorder to gather clues from low-level texture details and, at the same time,exploit the coarse layout of the painting, the branches of the proposednetworks are fed with crops at different resolutions. We propose and comparetwo different crop strategies: the first one is a random-crop strategy thatpermits to manage the tradeoff between accuracy and speed; the second one is asmart extractor based on Spatial Transformer Networks trained to extract themost representative subregions. Furthermore, inspired by the results obtainedin other domains, we experiment the joint use of hand-crafted features directlycomputed on the input images along with neural ones. Experiments are performedon a new dataset originally sourced from wikiart.org and hosted by Kaggle, andmade suitable for artist, style and genre multitask learning. The dataset hereproposed, named MultitaskPainting100k, is composed by 100K paintings, 1508artists, 125 styles and 41 genres. Our best method, tested on theMultitaskPainting100k dataset, achieves accuracy levels of 56.5%, 57.2%, and63.6% on the tasks of artist, style and genre prediction respectively."^^schema:Text ;
    schema:author "Davide Mazzini"^^schema:Person,
        "Paolo Napoletano"^^schema:Person,
        "Raimondo Schettini"^^schema:Person,
        "Simone Bianco"^^schema:Person ;
    schema:dateModified "2018-12-19T16:12:29Z"^^schema:DateTime ;
    schema:datePublished "2018-12-19T16:12:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Multitask Painting Categorization by Deep Multibranch Neural Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.08052v1"^^schema:URL .

<112> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning frameworks have often focused on either usability or speed, butnot both. PyTorch is a machine learning library that shows that these two goalsare in fact compatible: it provides an imperative and Pythonic programmingstyle that supports code as a model, makes debugging easy and is consistentwith other popular scientific computing libraries, while remaining efficientand supporting hardware accelerators such as GPUs.  In this paper, we detail the principles that drove the implementation ofPyTorch and how they are reflected in its architecture. We emphasize that everyaspect of PyTorch is a regular Python program under the full control of itsuser. We also explain how the careful and pragmatic implementation of the keycomponents of its runtime enables them to work together to achieve compellingperformance.  We demonstrate the efficiency of individual subsystems, as well as theoverall speed of PyTorch on several common benchmarks."^^schema:Text ;
    schema:author "Adam Lerer"^^schema:Person,
        "Adam Paszke"^^schema:Person,
        "Alban Desmaison"^^schema:Person,
        "Alykhan Tejani"^^schema:Person,
        "Andreas Köpf"^^schema:Person,
        "Benoit Steiner"^^schema:Person,
        "Edward Yang"^^schema:Person,
        "Francisco Massa"^^schema:Person,
        "Gregory Chanan"^^schema:Person,
        "James Bradbury"^^schema:Person,
        "Junjie Bai"^^schema:Person,
        "Lu Fang"^^schema:Person,
        "Luca Antiga"^^schema:Person,
        "Martin Raison"^^schema:Person,
        "Natalia Gimelshein"^^schema:Person,
        "Sam Gross"^^schema:Person,
        "Sasank Chilamkurthy"^^schema:Person,
        "Soumith Chintala"^^schema:Person,
        "Trevor Killeen"^^schema:Person,
        "Zach DeVito"^^schema:Person,
        "Zeming Lin"^^schema:Person ;
    schema:commentCount "1013"^^schema:Integer ;
    schema:dateModified "2019-12-03T22:06:05Z"^^schema:DateTime ;
    schema:datePublished "2019-12-03T22:06:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MS"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "PyTorch: An Imperative Style, High-Performance Deep Learning Library"^^schema:Text ;
    schema:publisher "NeurIPS, 8024-8035"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1912.01703v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3528934790668989119&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1120> a schema:ScholarlyArticle ;
    schema:abstract "Learning node representation on dynamically-evolving, multi-relational graphdata has gained great research interest. However, most of the existing modelsfor temporal knowledge graph forecasting use Recurrent Neural Network (RNN)with discrete depth to capture temporal information, while time is a continuousvariable. Inspired by Neural Ordinary Differential Equation (NODE), we extendthe idea of continuum-depth models to time-evolving multi-relational graphdata, and propose a novel Temporal Knowledge Graph Forecasting model with NODE.Our model captures temporal information through NODE and structural informationthrough a Graph Neural Network (GNN). Thus, our graph ODE model achieves acontinuous model in time and efficiently learns node representation for futureprediction. We evaluate our model on six temporal knowledge graph datasets byperforming link forecasting. Experiment results show the superiority of ourmodel."^^schema:Text ;
    schema:author "Volker Tresp"^^schema:Person,
        "Yunpu Ma"^^schema:Person,
        "Zhen Han"^^schema:Person,
        "Zifeng Ding"^^schema:Person ;
    schema:dateModified "2021-01-13T15:49:48Z"^^schema:DateTime ;
    schema:datePublished "2021-01-13T15:49:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Temporal Knowledge Graph Forecasting with Neural ODE"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.05151v1"^^schema:URL .

<1121> a schema:ScholarlyArticle ;
    schema:abstract "Training very deep networks is an important open problem in machine learning.One of many difficulties is that the norm of the back-propagated error gradientcan grow or decay exponentially. Here we show that training very deepfeed-forward networks (FFNs) is not as difficult as previously thought. Unlikewhen back-propagation is applied to a recurrent network, application to an FFNamounts to multiplying the error gradient by a different random matrix at eachlayer. We show that the successive application of correctly scaled randommatrices to an initial vector results in a random walk of the log of the normof the resulting vectors, and we compute the scaling that makes this walkunbiased. The variance of the random walk grows only linearly with networkdepth and is inversely proportional to the size of each layer. Practically,this implies a gradient whose log-norm scales with the square root of thenetwork depth and shows that the vanishing gradient problem can be mitigated byincreasing the width of the layers. Mathematical analyses and experimentalresults using stochastic gradient descent to optimize tasks related to theMNIST and TIMIT datasets are provided to support these claims. Equations forthe optimal matrix scaling are provided for the linear and ReLU cases."^^schema:Text ;
    schema:author "David Sussillo"^^schema:Person,
        "L. F. Abbott"^^schema:Person ;
    schema:dateModified "2015-02-27T22:28:32Z"^^schema:DateTime ;
    schema:datePublished "2014-12-19T23:24:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Random Walk Initialization for Training Very Deep Feedforward Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1412.6558v3"^^schema:URL .

<1122> a schema:ScholarlyArticle ;
    schema:abstract "We present Neural-Swarm2, a learning-based method for motion planning andcontrol that allows heterogeneous multirotors in a swarm to safely fly in closeproximity. Such operation for drones is challenging due to complex aerodynamicinteraction forces, such as downwash generated by nearby drones and groundeffect. Conventional planning and control methods neglect capturing theseinteraction forces, resulting in sparse swarm configuration during flight. Ourapproach combines a physics-based nominal dynamics model with learned DeepNeural Networks (DNNs) with strong Lipschitz properties. We evolve twotechniques to accurately predict the aerodynamic interactions betweenheterogeneous multirotors: i) spectral normalization for stability andgeneralization guarantees of unseen data and ii) heterogeneous deep sets forsupporting any number of heterogeneous neighbors in a permutation-invariantmanner without reducing expressiveness. The learned residual dynamics benefitboth the proposed interaction-aware multi-robot motion planning and thenonlinear tracking control designs because the learned interaction forcesreduce the modelling errors. Experimental results demonstrate thatNeural-Swarm2 is able to generalize to larger swarms beyond training cases andsignificantly outperforms a baseline nonlinear tracking controller with up tothree times reduction in worst-case tracking errors."^^schema:Text ;
    schema:author "Guanya Shi"^^schema:Person,
        "Soon-Jo Chung"^^schema:Person,
        "Wolfgang Hönig"^^schema:Person,
        "Xichen Shi"^^schema:Person,
        "Yisong Yue"^^schema:Person ;
    schema:dateModified "2020-12-10T05:08:31Z"^^schema:DateTime ;
    schema:datePublished "2020-12-10T05:08:31Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms  using Learned Interactions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.05457v1"^^schema:URL .

<1123> a schema:ScholarlyArticle ;
    schema:abstract "Learning representations for counterfactual inference from observational datais of high practical relevance for many domains, such as healthcare, publicpolicy and economics. Counterfactual inference enables one to answer \"Whatif...?\" questions, such as \"What would be the outcome if we gave this patienttreatment $t_1$?\". However, current methods for training neural networks forcounterfactual inference on observational data are either overly complex,limited to settings with only two available treatments, or both. Here, wepresent Perfect Match (PM), a method for training neural networks forcounterfactual inference that is easy to implement, compatible with anyarchitecture, does not add computational complexity or hyperparameters, andextends to any number of treatments. PM is based on the idea of augmentingsamples within a minibatch with their propensity-matched nearest neighbours.Our experiments demonstrate that PM outperforms a number of more complexstate-of-the-art methods in inferring counterfactual outcomes across severalbenchmarks, particularly in settings with many treatments."^^schema:Text ;
    schema:author "Lorenz Linhardt"^^schema:Person,
        "Patrick Schwab"^^schema:Person,
        "Walter Karlen"^^schema:Person ;
    schema:dateModified "2019-05-27T16:47:19Z"^^schema:DateTime ;
    schema:datePublished "2018-10-01T12:31:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Perfect Match: A Simple Method for Learning Representations For  Counterfactual Inference With Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.00656v5"^^schema:URL .

<1124> a schema:ScholarlyArticle ;
    schema:abstract "We learn recurrent neural network optimizers trained on simple syntheticfunctions by gradient descent. We show that these learned optimizers exhibit aremarkable degree of transfer in that they can be used to efficiently optimizea broad range of derivative-free black-box functions, including Gaussianprocess bandits, simple control objectives, global optimization benchmarks andhyper-parameter tuning tasks. Up to the training horizon, the learnedoptimizers learn to trade-off exploration and exploitation, and comparefavourably with heavily engineered Bayesian optimization packages forhyper-parameter tuning."^^schema:Text ;
    schema:author "Matt Botvinick"^^schema:Person,
        "Matthew W. Hoffman"^^schema:Person,
        "Misha Denil"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Sergio Gomez Colmenarejo"^^schema:Person,
        "Timothy P. Lillicrap"^^schema:Person,
        "Yutian Chen"^^schema:Person ;
    schema:dateModified "2017-06-12T11:19:30Z"^^schema:DateTime ;
    schema:datePublished "2016-11-11T19:33:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning to Learn without Gradient Descent by Gradient Descent"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.03824v6"^^schema:URL .

<1125> a schema:ScholarlyArticle ;
    schema:abstract "Temporal abstraction refers to the ability of an agent to use behaviours ofcontrollers which act for a limited, variable amount of time. The optionsframework describes such behaviours as consisting of a subset of states inwhich they can initiate, an internal policy and a stochastic terminationcondition. However, much of the subsequent work on option discovery has ignoredthe initiation set, because of difficulty in learning it from data. We providea generalization of initiation sets suitable for general functionapproximation, by defining an interest function associated with an option. Wederive a gradient-based learning algorithm for interest functions, leading to anew interest-option-critic architecture. We investigate how interest functionscan be leveraged to learn interpretable and reusable temporal abstractions. Wedemonstrate the efficacy of the proposed approach through quantitative andqualitative results, in both discrete and continuous environments."^^schema:Text ;
    schema:author "Doina Precup"^^schema:Person,
        "Khimya Khetarpal"^^schema:Person,
        "Martin Klissarov"^^schema:Person,
        "Maxime Chevalier-Boisvert"^^schema:Person,
        "Pierre-Luc Bacon"^^schema:Person ;
    schema:dateModified "2020-01-01T21:24:39Z"^^schema:DateTime ;
    schema:datePublished "2020-01-01T21:24:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Options of Interest: Temporal Abstraction with Interest Functions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.00271v1"^^schema:URL .

<1126> a schema:ScholarlyArticle ;
    schema:abstract "Empirically, neural networks that attempt to learn programs from data haveexhibited poor generalizability. Moreover, it has traditionally been difficultto reason about the behavior of these models beyond a certain level of inputcomplexity. In order to address these issues, we propose augmenting neuralarchitectures with a key abstraction: recursion. As an application, weimplement recursion in the Neural Programmer-Interpreter framework on fourtasks: grade-school addition, bubble sort, topological sort, and quicksort. Wedemonstrate superior generalizability and interpretability with small amountsof training data. Recursion divides the problem into smaller pieces anddrastically reduces the domain of each neural network component, making ittractable to prove guarantees about the overall system's behavior. Ourexperience suggests that in order for neural architectures to robustly learnprogram semantics, it is necessary to incorporate a concept like recursion."^^schema:Text ;
    schema:author "Dawn Song"^^schema:Person,
        "Jonathon Cai"^^schema:Person,
        "Richard Shin"^^schema:Person ;
    schema:dateModified "2017-04-21T16:02:26Z"^^schema:DateTime ;
    schema:datePublished "2017-04-21T16:02:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.PL"^^schema:Text ;
    schema:headline "Making Neural Programming Architectures Generalize via Recursion"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1704.06611v1"^^schema:URL .

<1127> a schema:ScholarlyArticle ;
    schema:abstract "Neural network based classifiers are still prone to manipulation throughadversarial perturbations. State of the art attacks can overcome most of thedefense or detection mechanisms suggested so far, and adversaries have theupper hand in this arms race. Adversarial examples are designed to resemble thenormal input from which they were constructed, while triggering an incorrectclassification. This basic design goal leads to a characteristic spatialbehavior within the context of Activation Spaces, a term coined by the authorsto refer to the hyperspaces formed by the activation values of the network'slayers. Within the output of the first layers of the network, an adversarialexample is likely to resemble normal instances of the source class, while inthe final layers such examples will diverge towards the adversary's targetclass. The steps below enable us to leverage this inherent shift from one classto another in order to form a novel adversarial example detector. We constructEuclidian spaces out of the activation values of each of the deep neuralnetwork layers. Then, we induce a set of k-nearest neighbor classifiers (k-NN),one per activation space of each neural network layer, using thenon-adversarial examples. We leverage those classifiers to produce a sequenceof class labels for each nonperturbed input sample and estimate the a prioriprobability for a class label change between one activation space and another.During the detection phase we compute a sequence of classification labels foreach input using the trained classifiers. We then estimate the likelihood ofthose classification sequences and show that adversarial sequences are far lesslikely than normal ones. We evaluated our detection method against the state ofthe art C&amp;W attack method, using two image classification datasets (MNIST,CIFAR-10) reaching an AUC 0f 0.95 for the CIFAR-10 dataset."^^schema:Text ;
    schema:author "Yuval Elovici"^^schema:Person,
        "Ziv Katzir"^^schema:Person ;
    schema:dateModified "2018-12-04T10:33:27Z"^^schema:DateTime ;
    schema:datePublished "2018-11-22T07:17:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Detecting Adversarial Perturbations Through Spatial Behavior in  Activation Spaces"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.09043v2"^^schema:URL .

<1128> a schema:ScholarlyArticle ;
    schema:abstract "Language creates a compact representation of the world and allows thedescription of unlimited situations and objectives through compositionality.While these characterizations may foster instructing, conditioning orstructuring interactive agent behavior, it remains an open-problem to correctlyrelate language understanding and reinforcement learning in even simpleinstruction following scenarios. This joint learning problem is alleviatedthrough expert demonstrations, auxiliary losses, or neural inductive biases. Inthis paper, we propose an orthogonal approach called Hindsight Generation forExperience Replay (HIGhER) that extends the Hindsight Experience Replay (HER)approach to the language-conditioned policy setting. Whenever the agent doesnot fulfill its instruction, HIGhER learns to output a new directive thatmatches the agent trajectory, and it relabels the episode with a positivereward. To do so, HIGhER learns to map a state into an instruction by usingpast successful trajectories, which removes the need to have external expertinterventions to relabel episodes as in vanilla HER. We show the efficiency ofour approach in the BabyAI environment, and demonstrate how it complementsother instruction following methods."^^schema:Text ;
    schema:author "Florian Strub"^^schema:Person,
        "Geoffrey Cideron"^^schema:Person,
        "Mathieu Seurin"^^schema:Person,
        "Olivier Pietquin"^^schema:Person ;
    schema:dateModified "2020-12-10T16:01:45Z"^^schema:DateTime ;
    schema:datePublished "2019-10-21T15:31:29Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "HIGhER : Improving instruction following with Hindsight Generation for  Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.09451v3"^^schema:URL .

<1129> a schema:ScholarlyArticle ;
    schema:abstract "We survey results on neural network expressivity described in \"On theExpressive Power of Deep Neural Networks\". The paper motivates and developsthree natural measures of expressiveness, which all display an exponentialdependence on the depth of the network. In fact, all of these measures arerelated to a fourth quantity, trajectory length. This quantity growsexponentially in the depth of the network, and is responsible for the depthsensitivity observed. These results translate to consequences for networksduring and after training. They suggest that parameters earlier in a networkhave greater influence on its expressive power -- in particular, given a layer,its influence on expressivity is determined by the remaining depth of thenetwork after that layer. This is verified with experiments on MNIST andCIFAR-10. We also explore the effect of training on the input-output map, andfind that it trades off between the stability and expressivity."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Jon Kleinberg"^^schema:Person,
        "Maithra Raghu"^^schema:Person,
        "Surya Ganguli"^^schema:Person ;
    schema:dateModified "2016-11-24T07:09:24Z"^^schema:DateTime ;
    schema:datePublished "2016-11-24T07:09:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Survey of Expressivity in Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.08083v1"^^schema:URL .

<113> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents an actor-critic deep reinforcement learning agent withexperience replay that is stable, sample efficient, and performs remarkablywell on challenging environments, including the discrete 57-game Atari domainand several continuous control problems. To achieve this, the paper introducesseveral innovations, including truncated importance sampling with biascorrection, stochastic dueling network architectures, and a new trust regionpolicy optimization method."^^schema:Text ;
    schema:author "Koray Kavukcuoglu"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Remi Munos"^^schema:Person,
        "Victor Bapst"^^schema:Person,
        "Volodymyr Mnih"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:commentCount "355"^^schema:Integer ;
    schema:dateModified "2017-07-10T14:38:10Z"^^schema:DateTime ;
    schema:datePublished "2016-11-03T23:21:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Sample Efficient Actor-Critic with Experience Replay"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01224v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8369222693188103740&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1130> a schema:ScholarlyArticle ;
    schema:abstract "End-users, without knowledge in photography, desire to beautify their photosto have a similar color style as a well-retouched reference. However, thedefinition of style in recent image style transfer works is inappropriate. Theyusually synthesize undesirable results due to transferring exact colors to thewrong destination. It becomes even worse in sensitive cases such as portraits.In this work, we concentrate on learning low-level image transformation,especially color-shifting methods, rather than mixing contextual features, thenpresent a novel scheme to train color style transfer with ground-truth.Furthermore, we propose a color style transfer named Deep Preset. It isdesigned to 1) generalize the features representing the color transformationfrom content with natural colors to retouched reference, then blend it into thecontextual features of content, 2) predict hyper-parameters (settings orpreset) of the applied low-level color transformation methods, 3) stylizecontent to have a similar color style as reference. We script Lightroom, apowerful tool in editing photos, to generate 600,000 training samples using1,200 images from the Flick2K dataset and 500 user-generated presets with 69settings. Experimental results show that our Deep Preset outperforms theprevious works in color style transfer quantitatively and qualitatively."^^schema:Text ;
    schema:author "Jinjia Zhou"^^schema:Person,
        "Man M. Ho"^^schema:Person ;
    schema:dateModified "2021-01-02T10:53:45Z"^^schema:DateTime ;
    schema:datePublished "2020-07-21T10:41:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Deep Preset: Blending and Retouching Photos with Color Style Transfer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.10701v2"^^schema:URL .

<1131> a schema:ScholarlyArticle ;
    schema:abstract "Binarized neural networks (BNNs) have shown exciting potential for utilisingneural networks in embedded implementations where area, energy and latencyconstraints are paramount. With BNNs, multiply-accumulate (MAC) operations canbe simplified to XnorPopcount operations, leading to massive reductions in bothmemory and computation resources. Furthermore, multiple efficientimplementations of BNNs have been reported on field-programmable gate array(FPGA) implementations. This paper proposes a smaller, faster, moreenergy-efficient approximate replacement for the XnorPopcountoperation, calledXNorMaj, inspired by state-of-the-art FPGAlook-up table schemes which benefitFPGA implementations. Weshow that XNorMaj is up to 2x more resource-efficientthan the XnorPopcount operation. While the XNorMaj operation has a minordetrimental impact on accuracy, the resource savings enable us to use largernetworks to recover the loss."^^schema:Text ;
    schema:author "David Boland"^^schema:Person,
        "Hao Zhou"^^schema:Person,
        "Lingli Wang"^^schema:Person,
        "Philip H. W. Leong"^^schema:Person,
        "Sean Fox"^^schema:Person,
        "Seyedramin Rasoulinezhad"^^schema:Person ;
    schema:dateModified "2020-02-27T04:02:43Z"^^schema:DateTime ;
    schema:datePublished "2020-02-27T04:02:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "MajorityNets: BNNs Utilising Approximate Popcount for Improved  Efficiency"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.12900v1"^^schema:URL .

<1132> a schema:ScholarlyArticle ;
    schema:abstract "Many top-performing image captioning models rely solely on object featurescomputed with an object detection model to generate image descriptions.However, recent studies propose to directly use scene graphs to introduceinformation about object relations into captioning, hoping to better describeinteractions between objects. In this work, we thoroughly investigate the useof scene graphs in image captioning. We empirically study whether usingadditional scene graph encoders can lead to better image descriptions andpropose a conditional graph attention network (C-GAT), where the imagecaptioning decoder state is used to condition the graph updates. Finally, wedetermine to what extent noise in the predicted scene graphs influence captionquality. Overall, we find no significant difference between models that usescene graph features and models that only use object detection features acrossdifferent captioning metrics, which suggests that existing scene graphgeneration models are still too noisy to be useful in image captioning.Moreover, although the quality of predicted scene graphs is very low ingeneral, when using high quality scene graphs we obtain gains of up to 3.3CIDEr compared to a strong Bottom-Up Top-Down baseline. We open source code toreproduce all our experiments inhttps://github.com/iacercalixto/butd-image-captioning."^^schema:Text ;
    schema:author "Iacer Calixto"^^schema:Person,
        "Marie-Francine Moens"^^schema:Person,
        "Victor Milewski"^^schema:Person ;
    schema:dateModified "2020-10-27T17:55:55Z"^^schema:DateTime ;
    schema:datePublished "2020-09-25T16:09:08Z"^^schema:DateTime ;
    schema:genre "68T50, 68T45"^^schema:Text,
        "I.2.7; I.2.10"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Are scene graphs good enough to improve Image Captioning?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.12313v2"^^schema:URL .

<1133> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay is an important technique for addressingsample-inefficiency in deep reinforcement learning (RL), but faces difficultyin learning from binary and sparse rewards due to disproportionately fewsuccessful experiences in the replay buffer. Hindsight experience replay (HER)was recently proposed to tackle this difficulty by manipulating unsuccessfultransitions, but in doing so, HER introduces a significant bias in the replaybuffer experiences and therefore achieves a suboptimal improvement insample-efficiency. In this paper, we present an analysis on the source of biasin HER, and propose a simple and effective method to counter the bias, to mosteffectively harness the sample-efficiency provided by HER. Our method,motivated by counter-factual reasoning and called ARCHER, extends HER with atrade-off to make rewards calculated for hindsight experiences numericallygreater than real rewards. We validate our algorithm on two continuous controlenvironments from DeepMind Control Suite - Reacher and Finger, which simulatemanipulation tasks with a robotic arm - in combination with various rewardfunctions, task complexities and goal sampling strategies. Our experimentsconsistently demonstrate that countering bias using more aggressive hindsightrewards increases sample efficiency, thus establishing the greater benefit ofARCHER in RL applications with limited computing budget."^^schema:Text ;
    schema:author "Sameera Lanka"^^schema:Person,
        "Tianfu Wu"^^schema:Person ;
    schema:dateModified "2018-09-07T00:31:16Z"^^schema:DateTime ;
    schema:datePublished "2018-09-06T16:08:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience  Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.02070v2"^^schema:URL .

<1134> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised machine translation, which utilizes unpaired monolingual corporaas training data, has achieved comparable performance against supervisedmachine translation. However, it still suffers from data-scarce domains. Toaddress this issue, this paper presents a meta-learning algorithm forunsupervised neural machine translation (UNMT) that trains the model to adaptto another domain by utilizing only a small amount of training data. We assumethat domain-general knowledge is a significant factor in handling data-scarcedomains. Hence, we extend the meta-learning algorithm, which utilizes knowledgelearned from high-resource domains to boost the performance of low-resourceUNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEUscores. Extensive experimental results show that our proposed algorithm ispertinent for fast adaptation and consistently outperforms other baselinemodels."^^schema:Text ;
    schema:author "Cheonbok Park"^^schema:Person,
        "Eunjeong Park"^^schema:Person,
        "Jaegul Choo"^^schema:Person,
        "Mohammad Azam Khan"^^schema:Person,
        "Soyoung Yang"^^schema:Person,
        "Taehee Kim"^^schema:Person,
        "Tao Qin"^^schema:Person,
        "Yunwon Tae"^^schema:Person ;
    schema:dateModified "2020-10-18T17:54:13Z"^^schema:DateTime ;
    schema:datePublished "2020-10-18T17:54:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Meta-Learning for Low-Resource Unsupervised Neural MachineTranslation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.09046v1"^^schema:URL .

<1135> a schema:ScholarlyArticle ;
    schema:abstract "Using Banchoff's discrete Morse Theory, in tandem with Bloch's result on thestrong connection between the former and Forman's Morse Theory, and our ownprevious algorithm based on the later, we show that there exists acurvature-based, efficient Persistent Homology scheme for networks andhypernetworks. We also broaden the proposed method to include more generaltypes of networks, by using Bloch's extension of Banchoff's work. Moreover, weshow the connection between defect and Forman's Ricci curvature that exists inthe combinatorial setting, thus explaining previous empirical results showingvery strong correlation between Persistent Homology results obtained usingForman's Morse Theory on the one hand, and Forman's Ricci curvature, on theother."^^schema:Text ;
    schema:author "Emil Saucan"^^schema:Person ;
    schema:dateModified "2020-03-08T20:26:04Z"^^schema:DateTime ;
    schema:datePublished "2020-03-08T20:26:04Z"^^schema:DateTime ;
    schema:genre "68R10, 57Q99, 53Z99, 55U99, 05C82"^^schema:Text,
        "math.DG"^^schema:Text ;
    schema:headline "Discrete Morse Theory, Persistent Homology and Forman-Ricci Curvature"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03844v1"^^schema:URL .

<1136> a schema:ScholarlyArticle ;
    schema:abstract "Spatial transformer networks (STNs) were designed to enable convolutionalneural networks (CNNs) to learn invariance to image transformations. STNs wereoriginally proposed to transform CNN feature maps as well as input images. Thisenables the use of more complex features when predicting transformationparameters. However, since STNs perform a purely spatial transformation, theydo not, in the general case, have the ability to align the feature maps of atransformed image with those of its original. STNs are therefore unable tosupport invariance when transforming CNN feature maps. We present a simpleproof for this and study the practical implications, showing that thisinability is coupled with decreased classification accuracy. We thereforeinvestigate alternative STN architectures that make use of complex features. Wefind that while deeper localization networks are difficult to train,localization networks that share parameters with the classification networkremain stable as they grow deeper, which allows for higher classificationaccuracy on difficult datasets. Finally, we explore the interaction betweenlocalization network complexity and iterative image alignment."^^schema:Text ;
    schema:author "Lukas Finnveden"^^schema:Person,
        "Tony Lindeberg"^^schema:Person,
        "Ylva Jansson"^^schema:Person ;
    schema:dateModified "2020-12-23T11:48:25Z"^^schema:DateTime ;
    schema:datePublished "2020-04-24T12:20:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Understanding when spatial transformer networks do not support  invariance, and what to do about it"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.11678v4"^^schema:URL .

<1137> a schema:ScholarlyArticle ;
    schema:abstract "Deep generative models have been used in recent years to learn coherentlatent representations in order to synthesize high-quality images. In thiswork, we propose a neural network to learn a generative model for samplingconsistent indoor scene layouts. Our method learns the co-occurrences, andappearance parameters such as shape and pose, for different objects categoriesthrough a grammar-based auto-encoder, resulting in a compact and accuraterepresentation for scene layouts. In contrast to existing grammar-based methodswith a user-specified grammar, we construct the grammar automatically byextracting a set of production rules on reasoning about object co-occurrencesin training data. The extracted grammar is able to represent a scene by anaugmented parse tree. The proposed auto-encoder encodes these parse trees to alatent code, and decodes the latent code to a parse tree, thereby ensuring thegenerated scene is always valid. We experimentally demonstrate that theproposed auto-encoder learns not only to generate valid scenes (i.e. thearrangements and appearances of objects), but it also learns coherent latentrepresentations where nearby latent samples decode to similar scene outputs.The obtained generative model is applicable to several computer vision taskssuch as 3D pose and layout estimation from RGB-D data."^^schema:Text ;
    schema:author "Christopher Zach"^^schema:Person,
        "Ian Reid"^^schema:Person,
        "Pulak Purkait"^^schema:Person ;
    schema:dateModified "2020-08-21T03:31:42Z"^^schema:DateTime ;
    schema:datePublished "2019-12-10T07:53:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "SG-VAE: Scene Grammar Variational Autoencoder to generate new indoor  scenes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.04554v2"^^schema:URL .

<1138> a schema:ScholarlyArticle ;
    schema:abstract "This project combines recent advances in experience replay techniques,namely, Combined Experience Replay (CER), Prioritized Experience Replay (PER),and Hindsight Experience Replay (HER). We show the results of combinations ofthese techniques with DDPG and DQN methods. CER always adds the most recentexperience to the batch. PER chooses which experiences should be replayed basedon how beneficial they will be towards learning. HER learns from failure bysubstituting the desired goal with the achieved goal and recomputing the rewardfunction. The effectiveness of combinations of these experience replaytechniques is tested in a variety of OpenAI gym environments."^^schema:Text ;
    schema:author "Neil Xu"^^schema:Person,
        "Tracy Wan"^^schema:Person ;
    schema:dateModified "2018-05-15T02:50:35Z"^^schema:DateTime ;
    schema:datePublished "2018-05-15T02:50:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Advances in Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.05536v1"^^schema:URL .

<1139> a schema:ScholarlyArticle ;
    schema:abstract "In the area of geographic information processing. There are few researches ongeographic text classification. However, the application of this task inChinese is relatively rare. In our work, we intend to implement a method toextract text containing geographical entities from a large number of networktext. The geographic information in these texts is of great practicalsignificance to transportation, urban and rural planning, disaster relief andother fields. We use the method of graph convolutional neural network withattention mechanism to achieve this function. Graph attention networks is animprovement of graph convolutional neural networks. Compared with GCN, theadvantage of GAT is that the attention mechanism is proposed to weight the sumof the characteristics of adjacent nodes. In addition, We construct a Chinesedataset containing geographical classification from multiple datasets ofChinese text classification. The Macro-F Score of the geoGAT we used reached95\\% on the new Chinese dataset."^^schema:Text ;
    schema:author "Donglin Di"^^schema:Person,
        "Houbing Song"^^schema:Person,
        "Weipeng Jing"^^schema:Person,
        "Xianyang Song"^^schema:Person ;
    schema:dateModified "2021-01-13T09:32:15Z"^^schema:DateTime ;
    schema:datePublished "2021-01-13T09:32:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "geoGAT: Graph Model Based on Attention Mechanism for Geographic Text  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.11424v1"^^schema:URL .

<114> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a very deep fully convolutional encoding-decodingframework for image restoration such as denoising and super-resolution. Thenetwork is composed of multiple layers of convolution and de-convolutionoperators, learning end-to-end mappings from corrupted images to the originalones. The convolutional layers act as the feature extractor, which capture theabstraction of image contents while eliminating noises/corruptions.De-convolutional layers are then used to recover the image details. We proposeto symmetrically link convolutional and de-convolutional layers with skip-layerconnections, with which the training converges much faster and attains ahigher-quality local optimum. First, The skip connections allow the signal tobe back-propagated to bottom layers directly, and thus tackles the problem ofgradient vanishing, making training deep networks easier and achievingrestoration performance gains consequently. Second, these skip connections passimage details from convolutional layers to de-convolutional layers, which isbeneficial in recovering the original image. Significantly, with the largecapacity, we can handle different levels of noises using a single model.Experimental results show that our network achieves better performance than allpreviously reported state-of-the-art methods."^^schema:Text ;
    schema:author "Chunhua Shen"^^schema:Person,
        "Xiao-Jiao Mao"^^schema:Person,
        "Yu-Bin Yang"^^schema:Person ;
    schema:commentCount "691"^^schema:Integer ;
    schema:dateModified "2016-09-01T01:15:42Z"^^schema:DateTime ;
    schema:datePublished "2016-03-30T07:16:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks  with Symmetric Skip Connections"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.09056v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9889699634650873051&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1140> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we present a new dataset and user simulator e-QRAQ (explainableQuery, Reason, and Answer Question) which tests an Agent's ability to read anambiguous text; ask questions until it can answer a challenge question; andexplain the reasoning behind its questions and answer. The User simulatorprovides the Agent with a short, ambiguous story and a challenge question aboutthe story. The story is ambiguous because some of the entities have beenreplaced by variables. At each turn the Agent may ask for the value of avariable or try to answer the challenge question. In response the Usersimulator provides a natural language explanation of why the Agent's query oranswer was useful in narrowing down the set of possible answers, or not. Todemonstrate one potential application of the e-QRAQ dataset, we train a newneural architecture based on End-to-End Memory Networks to successfullygenerate both predictions and partial explanations of its current understandingof the problem. We observe a strong correlation between the quality of theprediction and explanation."^^schema:Text ;
    schema:author "Clemens Rosenbaum"^^schema:Person,
        "Tian Gao"^^schema:Person,
        "Tim Klinger"^^schema:Person ;
    schema:dateModified "2017-08-05T15:06:56Z"^^schema:DateTime ;
    schema:datePublished "2017-08-05T15:06:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.01776v1"^^schema:URL .

<1141> a schema:ScholarlyArticle ;
    schema:abstract "We propose a policy improvement algorithm for Reinforcement Learning (RL)which is called Rerouted Behavior Improvement (RBI). RBI is designed to takeinto account the evaluation errors of the Q-function. Such errors are common inRL when learning the $Q$-value from finite past experience data. Greedypolicies or even constrained policy optimization algorithms which ignore theseerrors may suffer from an improvement penalty (i.e. a negative policyimprovement). To minimize the improvement penalty, the RBI idea is to attenuaterapid policy changes of low probability actions which were less frequentlysampled. This approach is shown to avoid catastrophic performance degradationand reduce regret when learning from a batch of past experience. Through atwo-armed bandit with Gaussian distributed rewards example, we show that italso increases data efficiency when the optimal action has a high variance. Weevaluate RBI in two tasks in the Atari Learning Environment: (1) learning fromobservations of multiple behavior policies and (2) iterative RL. Our resultsdemonstrate the advantage of RBI over greedy policies and other constrainedpolicy optimization algorithms as a safe learning approach and as a generaldata efficient learning algorithm. An anonymous Github repository of our RBIimplementation is found at https://github.com/eladsar/rbi."^^schema:Text ;
    schema:author "Aviv Tamar"^^schema:Person,
        "Elad Sarafian"^^schema:Person,
        "Sarit Kraus"^^schema:Person ;
    schema:dateModified "2019-07-10T20:12:07Z"^^schema:DateTime ;
    schema:datePublished "2018-05-20T17:47:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Constrained Policy Improvement for Safe and Efficient Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.07805v3"^^schema:URL .

<1142> a schema:ScholarlyArticle ;
    schema:abstract "A neural ordinary differential equations network (ODE-Net)-enabledreachability method (Neuro-Reachability) is devised for the dynamicverification of networked microgrids (NMs) with unidentified subsystems andheterogeneous uncertainties. Three new contributions are presented: 1) AnODENet-enabled dynamic model discovery approach is devised to construct thedata-driven state-space model which preserves the nonlinear and differentialstructure of the NMs system; 2) A physics-data-integrated (PDI) NMs model isestablished, which empowers various NM analytics; and 3) Aconformance-empowered reachability analysis is developed to enhance thereliability of the PDI-driven dynamic verification. Extensive case studiesdemonstrate the efficacy of the ODE-Net-enabled method in microgrid dynamicmodel discovery, and the effectiveness of the Neuro-Reachability approach inverifying the NMs dynamics under multiple uncertainties and various operationalscenarios."^^schema:Text ;
    schema:author "Peng Zhang"^^schema:Person,
        "Yifan Zhou"^^schema:Person ;
    schema:dateModified "2021-01-13T15:56:56Z"^^schema:DateTime ;
    schema:datePublished "2021-01-13T15:56:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Neuro-Reachability of Networked Microgrids"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.05159v1"^^schema:URL .

<1143> a schema:ScholarlyArticle ;
    schema:abstract "Obtaining reliable data describing local poverty metrics at a granularitythat is informative to policy-makers requires expensive and logisticallydifficult surveys, particularly in the developing world. Not surprisingly, thepoverty stricken regions are also the ones which have a high probability ofbeing a war zone, have poor infrastructure and sometimes have governments thatdo not cooperate with internationally funded development efforts. We train aCNN on free and publicly available daytime satellite images of the Africancontinent from Landsat 7 to build a model for predicting local economiclivelihoods. Only 5% of the satellite images can be associated with labels(which are obtained from DHS Surveys) and thus a semi-supervised approach usinga GAN (similar to the approach of Salimans, et al. (2016)), albeit with a morestable-to-train flavor of GANs called the Wasserstein GAN regularized withgradient penalty(Gulrajani, et al. (2017)) is used. The method of multitasklearning is employed to regularize the network and also create an end-to-endmodel for the prediction of multiple poverty metrics."^^schema:Text ;
    schema:author "Anthony Perez"^^schema:Person,
        "David Lobell"^^schema:Person,
        "George Azzari"^^schema:Person,
        "Marshall Burke"^^schema:Person,
        "Stefano Ermon"^^schema:Person,
        "Swetava Ganguli"^^schema:Person ;
    schema:dateModified "2019-04-25T19:27:01Z"^^schema:DateTime ;
    schema:datePublished "2019-02-13T21:52:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Semi-Supervised Multitask Learning on Multispectral Satellite Images  Using Wasserstein Generative Adversarial Networks (GANs) for Predicting  Poverty"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.11110v2"^^schema:URL .

<1144> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing (KT) models, e.g., the deep knowledge tracing (DKT) model,track an individual learner's acquisition of skills over time by examining thelearner's performance on questions related to those skills. A practicallimitation in most existing KT models is that all questions nested under aparticular skill are treated as equivalent observations of a learner's ability,which is an inaccurate assumption in real-world educational scenarios. Toovercome this limitation we introduce qDKT, a variant of DKT that models everylearner's success probability on individual questions over time. First, qDKTincorporates graph Laplacian regularization to smooth predictions under eachskill, which is particularly useful when the number of questions in the datasetis big. Second, qDKT uses an initialization scheme inspired by the fastTextalgorithm, which has found success in a variety of language modeling tasks. Ourexperiments on several real-world datasets show that qDKT achieves state-of-artperformance on predicting learner outcomes. Because of this, qDKT can serve asa simple, yet tough-to-beat, baseline for new question-centric KT models."^^schema:Text ;
    schema:author "Andrew E. Waters"^^schema:Person,
        "Andrew S. Lan"^^schema:Person,
        "Phillip J. Grimaldi"^^schema:Person,
        "Richard G. Baraniuk"^^schema:Person,
        "Shashank Sonkar"^^schema:Person ;
    schema:dateModified "2020-05-25T23:43:55Z"^^schema:DateTime ;
    schema:datePublished "2020-05-25T23:43:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "qDKT: Question-centric Deep Knowledge Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.12442v1"^^schema:URL .

<1145> a schema:ScholarlyArticle ;
    schema:abstract "We propose a deep neural network for supervised learning on neuroanatomicalshapes. The network directly operates on raw point clouds without the need formesh processing or the identification of point correspondences, as spatialtransformer networks map the data to a canonical space. Instead of relying onhand-crafted shape descriptors, an optimal representation is learned in theend-to-end training stage of the network. The proposed network consists ofmultiple branches, so that features for multiple structures are learnedsimultaneously. We demonstrate the performance of our method on twoapplications: (i) the prediction of Alzheimer's disease and mild cognitiveimpairment and (ii) the regression of the brain age. Finally, we visualize theimportant parts of the anatomy for the prediction by adapting the occlusionmethod to point clouds."^^schema:Text ;
    schema:author "Benjamin Gutierrez-Becker"^^schema:Person,
        "Christian Wachinger"^^schema:Person ;
    schema:dateModified "2018-06-04T12:22:40Z"^^schema:DateTime ;
    schema:datePublished "2018-06-04T12:22:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Multi-Structural Shape Analysis: Application to Neuroanatomy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.01069v1"^^schema:URL .

<1146> a schema:ScholarlyArticle ;
    schema:abstract "Many recent successful (deep) reinforcement learning algorithms make use ofregularization, generally based on entropy or Kullback-Leibler divergence. Wepropose a general theory of regularized Markov Decision Processes thatgeneralizes these approaches in two directions: we consider a larger class ofregularizers, and we consider the general modified policy iteration approach,encompassing both policy iteration and value iteration. The core buildingblocks of this theory are a notion of regularized Bellman operator and theLegendre-Fenchel transform, a classical tool of convex optimization. Thisapproach allows for error propagation analyses of general algorithmic schemesof which (possibly variants of) classical algorithms such as Trust RegionPolicy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic PolicyProgramming are special cases. This also draws connections to proximal convexoptimization, especially to Mirror Descent."^^schema:Text ;
    schema:author "Bruno Scherrer"^^schema:Person,
        "Matthieu Geist"^^schema:Person,
        "Olivier Pietquin"^^schema:Person ;
    schema:dateModified "2019-06-04T07:44:24Z"^^schema:DateTime ;
    schema:datePublished "2019-01-31T09:10:08Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Theory of Regularized Markov Decision Processes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.11275v2"^^schema:URL .

<1147> a schema:ScholarlyArticle ;
    schema:abstract "Group equivariant convolutional networks (GCNNs) endow classicalconvolutional networks with additional symmetry priors, which can lead to aconsiderably improved performance. Recent advances in the theoreticaldescription of GCNNs revealed that such models can generally be understood asperforming convolutions with G-steerable kernels, that is, kernels that satisfyan equivariance constraint themselves. While the G-steerability constraint hasbeen derived, it has to date only been solved for specific use cases - ageneral characterization of G-steerable kernel spaces is still missing. Thiswork provides such a characterization for the practically relevant case of Gbeing any compact group. Our investigation is motivated by a striking analogybetween the constraints underlying steerable kernels on the one hand andspherical tensor operators from quantum mechanics on the other hand. Bygeneralizing the famous Wigner-Eckart theorem for spherical tensor operators,we prove that steerable kernel spaces are fully understood and parameterized interms of 1) generalized reduced matrix elements, 2) Clebsch-Gordancoefficients, and 3) harmonic basis functions on homogeneous spaces."^^schema:Text ;
    schema:author "Leon Lang"^^schema:Person,
        "Maurice Weiler"^^schema:Person ;
    schema:dateModified "2021-01-21T10:00:28Z"^^schema:DateTime ;
    schema:datePublished "2020-10-21T12:42:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.10952v4"^^schema:URL .

<1148> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge graphs are graphical representations of large databases of facts,which typically suffer from incompleteness. Inferring missing relations (links)between entities (nodes) is the task of link prediction. A recentstate-of-the-art approach to link prediction, ConvE, implements a convolutionalneural network to extract features from concatenated subject and relationvectors. Whilst results are impressive, the method is unintuitive and poorlyunderstood. We propose a hypernetwork architecture that generates simplifiedrelation-specific convolutional filters that (i) outperforms ConvE and allprevious approaches across standard datasets; and (ii) can be framed as tensorfactorization and thus set within a well established family of factorizationmodels for link prediction. We thus demonstrate that convolution simply offersa convenient computational means of introducing sparsity and parameter tying tofind an effective trade-off between non-linear expressiveness and the number ofparameters to learn."^^schema:Text ;
    schema:author "Carl Allen"^^schema:Person,
        "Ivana Balažević"^^schema:Person,
        "Timothy M. Hospedales"^^schema:Person ;
    schema:dateModified "2019-07-15T11:22:00Z"^^schema:DateTime ;
    schema:datePublished "2018-08-21T17:05:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hypernetwork Knowledge Graph Embeddings"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.07018v5"^^schema:URL .

<1149> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes new notions of polynomial depth (called monotone polydepth), based on a polynomial version of monotone Kolmogorov complexity. Weshow that monotone poly depth satisfies all desirable properties of depthnotions i.e., both trivial and random sequences are not monotone poly deep,monotone poly depth satisfies the slow growth law i.e., no simple process cantransform a non deep sequence into a deep one, and monotone poly deep sequencesexist (unconditionally). We give two natural examples of deep sets, by showingthat both the set of Levin-random strings and the set of Kolmogorov randomstrings are monotone poly deep."^^schema:Text ;
    schema:author "Philippe Moser"^^schema:Person ;
    schema:dateModified "2010-12-31T05:36:25Z"^^schema:DateTime ;
    schema:datePublished "2010-12-16T10:07:39Z"^^schema:DateTime ;
    schema:genre "cs.CC"^^schema:Text ;
    schema:headline "On the polynomial depth of various sets of random strings"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1012.3548v2"^^schema:URL .

<115> a schema:ScholarlyArticle ;
    schema:abstract "Effective convolutional neural networks are trained on large sets of labeleddata. However, creating large labeled datasets is a very costly andtime-consuming task. Semi-supervised learning uses unlabeled data to train amodel with higher accuracy when there is a limited set of labeled dataavailable. In this paper, we consider the problem of semi-supervised learningwith convolutional neural networks. Techniques such as randomized dataaugmentation, dropout and random max-pooling provide better generalization andstability for classifiers that are trained using gradient descent. Multiplepasses of an individual sample through the network might lead to differentpredictions due to the non-deterministic behavior of these techniques. Wepropose an unsupervised loss function that takes advantage of the stochasticnature of these methods and minimizes the difference between the predictions ofmultiple passes of a training sample through the network. We evaluate theproposed method on several benchmark datasets."^^schema:Text ;
    schema:author "Mehdi Sajjadi"^^schema:Person,
        "Mehran Javanmardi"^^schema:Person,
        "Tolga Tasdizen"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2016-06-14T22:30:08Z"^^schema:DateTime ;
    schema:datePublished "2016-06-14T22:30:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Regularization With Stochastic Transformations and Perturbations for  Deep Semi-Supervised Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.04586v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=811577089436189841&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1150> a schema:ScholarlyArticle ;
    schema:abstract "Denoising-based Unsupervised Neural Machine Translation (U-NMT) modelstypically employ denoising strategy at the encoder module to prevent the modelfrom memorizing the input source sentence. Specifically, given an inputsentence of length n, the model applies n/2 random swaps between consecutivewords and trains the denoising-based U-NMT model. Though effective, applyingdenoising strategy on every sentence in the training data leads to uncertaintyin the model thereby, limiting the benefits from the denoising-based U-NMTmodel. In this paper, we propose a simple fine-tuning strategy where wefine-tune the trained denoising-based U-NMT system without the denoisingstrategy. The input sentences are presented as is i.e., without any shufflingnoise added. We observe significant improvements in translation performance onmany language pairs from our fine-tuning strategy. Our analysis reveals thatour proposed models lead to increase in higher n-gram BLEU score compared tothe denoising U-NMT models."^^schema:Text ;
    schema:author "Pushpak Bhattacharyya"^^schema:Person,
        "Rudra Murthy V"^^schema:Person,
        "Tamali Banerjee"^^schema:Person ;
    schema:dateModified "2019-10-30T12:22:37Z"^^schema:DateTime ;
    schema:datePublished "2019-10-30T12:22:37Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Ordering Matters: Word Ordering Aware Unsupervised NMT"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.01212v1"^^schema:URL .

<1151> a schema:ScholarlyArticle ;
    schema:abstract "We present our submission to the End-to-End Multi-Domain Dialog ChallengeTrack of the Eighth Dialog System Technology Challenge. Our proposed dialogsystem adopts a pipeline architecture, with distinct components for NaturalLanguage Understanding, Dialog State Tracking, Dialog Management and NaturalLanguage Generation. At the core of our system is a reinforcement learningalgorithm which uses Deep Q-learning from Demonstrations to learn a dialogpolicy with the help of expert examples. We find that demonstrations areessential to training an accurate dialog policy where both state and actionspaces are large. Evaluation of our Dialog Management component shows that ourapproach is effective - beating supervised and reinforcement learningbaselines."^^schema:Text ;
    schema:author "Gabriel Gordon-Hall"^^schema:Person,
        "Gerasimos Lampouras"^^schema:Person,
        "Ignacio Iacobacci"^^schema:Person,
        "Philip John Gorinski"^^schema:Person ;
    schema:dateModified "2020-04-17T08:41:54Z"^^schema:DateTime ;
    schema:datePublished "2020-04-17T08:41:54Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Show Us the Way: Learning to Manage Dialog from Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.08114v1"^^schema:URL .

<1152> a schema:ScholarlyArticle ;
    schema:abstract "Many visual scenes contain text that carries crucial information, and it isthus essential to understand text in images for downstream reasoning tasks. Forexample, a deep water label on a warning sign warns people about the danger inthe scene. Recent work has explored the TextVQA task that requires reading andunderstanding text in images to answer a question. However, existing approachesfor TextVQA are mostly based on custom pairwise fusion mechanisms between apair of two modalities and are restricted to a single prediction step bycasting TextVQA as a classification task. In this work, we propose a novelmodel for the TextVQA task based on a multimodal transformer architectureaccompanied by a rich representation for text in images. Our model naturallyfuses different modalities homogeneously by embedding them into a commonsemantic space where self-attention is applied to model inter- and intra-modality context. Furthermore, it enables iterative answer decoding with adynamic pointer network, allowing the model to form an answer throughmulti-step prediction instead of one-step classification. Our model outperformsexisting approaches on three benchmark datasets for the TextVQA task by a largemargin."^^schema:Text ;
    schema:author "Amanpreet Singh"^^schema:Person,
        "Marcus Rohrbach"^^schema:Person,
        "Ronghang Hu"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:dateModified "2020-03-24T23:59:59Z"^^schema:DateTime ;
    schema:datePublished "2019-11-14T17:32:10Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Iterative Answer Prediction with Pointer-Augmented Multimodal  Transformers for TextVQA"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.06258v3"^^schema:URL .

<1153> a schema:ScholarlyArticle ;
    schema:abstract "Model-free reinforcement learning (RL) methods are succeeding in a growingnumber of tasks, aided by recent advances in deep learning. However, they tendto suffer from high sample complexity, which hinders their use in real-worlddomains. Alternatively, model-based reinforcement learning promises to reducesample complexity, but tends to require careful tuning and to date havesucceeded mainly in restrictive domains where simple models are sufficient forlearning. In this paper, we analyze the behavior of vanilla model-basedreinforcement learning methods when deep neural networks are used to learn boththe model and the policy, and show that the learned policy tends to exploitregions where insufficient data is available for the model to be learned,causing instability in training. To overcome this issue, we propose to use anensemble of models to maintain the model uncertainty and regularize thelearning process. We further show that the use of likelihood ratio derivativesyields much more stable learning than backpropagation through time. Altogether,our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO)significantly reduces the sample complexity compared to model-free deep RLmethods on challenging continuous control benchmark tasks."^^schema:Text ;
    schema:author "Aviv Tamar"^^schema:Person,
        "Ignasi Clavera"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Thanard Kurutach"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:dateModified "2018-10-05T05:08:37Z"^^schema:DateTime ;
    schema:datePublished "2018-02-28T18:58:22Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Model-Ensemble Trust-Region Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.10592v2"^^schema:URL .

<1154> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we tackle the problem of routing multiple agents in acoordinated manner. This is a complex problem that has a wide range ofapplications in fleet management to achieve a common goal, such as mapping froma swarm of robots and ride sharing. Traditional methods are typically notdesigned for realistic environments hich contain sparsely connected graphs andunknown traffic, and are often too slow in runtime to be practical. Incontrast, we propose a graph neural network based model that is able to performmulti-agent routing based on learned value iteration in a sparsely connectedgraph with dynamically changing traffic conditions. Moreover, our learnedcommunication module enables the agents to coordinate online and adapt tochanges more effectively. We created a simulated environment to mimic realisticmapping performed by autonomous vehicles with unknown minimum edge coverage andtraffic conditions; our approach significantly outperforms traditional solversboth in terms of total cost and runtime. We also show that our model trainedwith only two agents on graphs with a maximum of 25 nodes can easily generalizeto situations with more agents and/or nodes."^^schema:Text ;
    schema:author "Mengye Ren"^^schema:Person,
        "Quinlan Sykora"^^schema:Person,
        "Raquel Urtasun"^^schema:Person ;
    schema:dateModified "2020-08-14T18:08:25Z"^^schema:DateTime ;
    schema:datePublished "2020-07-09T22:16:45Z"^^schema:DateTime ;
    schema:genre "I.2.11; I.2.6"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-Agent Routing Value Iteration Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.05096v2"^^schema:URL .

<1155> a schema:ScholarlyArticle ;
    schema:abstract "Automatic and consistent meningioma segmentation in T1-weighted MRI volumesand corresponding volumetric assessment is of use for diagnosis, treatmentplanning, and tumor growth evaluation. In this paper, we optimized thesegmentation and processing speed performances using a large number of bothsurgically treated meningiomas and untreated meningiomas followed at theoutpatient clinic. We studied two different 3D neural network architectures:(i) a simple encoder-decoder similar to a 3D U-Net, and (ii) a lightweightmulti-scale architecture (PLS-Net). In addition, we studied the impact ofdifferent training schemes. For the validation studies, we used 698 T1-weightedMR volumes from St. Olav University Hospital, Trondheim, Norway. The modelswere evaluated in terms of detection accuracy, segmentation accuracy andtraining/inference speed. While both architectures reached a similar Dice scoreof 70% on average, the PLS-Net was more accurate with an F1-score of up to 88%.The highest accuracy was achieved for the largest meningiomas. Speed-wise, thePLS-Net architecture tended to converge in about 50 hours while 130 hours werenecessary for U-Net. Inference with PLS-Net takes less than a second on GPU andabout 15 seconds on CPU. Overall, with the use of mixed precision training, itwas possible to train competitive segmentation models in a relatively shortamount of time using the lightweight PLS-Net architecture. In the future, thefocus should be brought toward the segmentation of small meningiomas (less than2ml) to improve clinical relevance for automatic and early diagnosis as well asspeed of growth estimates."^^schema:Text ;
    schema:author "André Pedersen"^^schema:Person,
        "David Bouget"^^schema:Person,
        "Ingerid Reinertsen"^^schema:Person,
        "Johanna Vanel"^^schema:Person,
        "Ole Solheim"^^schema:Person,
        "Sayied Abdol Mohieb Hosainey"^^schema:Person ;
    schema:dateModified "2020-10-14T12:26:53Z"^^schema:DateTime ;
    schema:datePublished "2020-10-14T12:26:53Z"^^schema:DateTime ;
    schema:genre "I.4.6; J.3"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Fast meningioma segmentation in T1-weighted MRI volumes using a  lightweight 3D deep learning architecture"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07002v1"^^schema:URL .

<1156> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have shown great success in many diverse fields. Thetraining of these networks can take significant amounts of time, compute andenergy. As datasets get larger and models become more complex, the explorationof model architectures becomes prohibitive. In this paper we examine thecompute, energy and time costs of training a UNet based deep neural network forthe problem of predicting short term weather forecasts (called precipitationNowcasting). By leveraging a combination of data distributed andmixed-precision training, we explore the design space for this problem. We alsoshow that larger models with better performance come at a potentiallyincremental cost if appropriate optimizations are used. We show that it ispossible to achieve a significant improvement in training time by leveragingmixed-precision training without sacrificing model performance. Additionally,we find that a 1549% increase in the number of trainable parameters for anetwork comes at a relatively smaller 63.22% increase in energy usage for aUNet with 4 encoding layers."^^schema:Text ;
    schema:author "Mark M. Veillette"^^schema:Person,
        "Michael Jones"^^schema:Person,
        "Siddharth Samsi"^^schema:Person ;
    schema:dateModified "2020-08-18T17:44:24Z"^^schema:DateTime ;
    schema:datePublished "2020-08-18T17:44:24Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Compute, Time and Energy Characterization of Encoder-Decoder Networks  with Automatic Mixed Precision Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.08062v1"^^schema:URL .

<1157> a schema:ScholarlyArticle ;
    schema:abstract "Phase retrieval (PR) is an important component in modern computationalimaging systems. Many algorithms have been developed over the past halfcentury. Recent advances in deep learning have opened up a new possibility forrobust and fast PR. An emerging technique, called deep unfolding, provides asystematic connection between conventional model-based iterative algorithms andmodern data-based deep learning. Unfolded algorithms, powered by data learning,have shown remarkable performance and convergence speed improvement over theoriginal algorithms. Despite their potential, most existing unfolded algorithmsare strictly confined to a fixed number of iterations when employinglayer-dependent parameters. In this study, we develop a novel framework fordeep unfolding to overcome the existing limitations. Even if our framework canbe widely applied to general inverse problems, we take PR as an example in thepaper. Our development is based on an unfolded generalized expectationconsistent signal recovery (GEC-SR) algorithm, wherein damping factors are leftfor data-driven learning. In particular, we introduce a hypernetwork togenerate the damping factors for GEC-SR. Instead of directly learning a set ofoptimal damping factors, the hypernetwork learns how to generate the optimaldamping factors according to the clinical settings, thus ensuring itsadaptivity to different scenarios. To make the hypernetwork work adapt tovarying layer numbers, we use a recurrent architecture to develop a dynamichypernetwork, which generates a damping factor that can vary online acrosslayers. We also exploit a self-attention mechanism to enhance the robustness ofthe hypernetwork. Extensive experiments show that the proposed algorithmoutperforms existing ones in convergence speed and accuracy, and still workswell under very harsh settings, that many classical PR algorithms unstable oreven fail."^^schema:Text ;
    schema:author "Chang-Jen Wang"^^schema:Person,
        "Chao-Kai Wen"^^schema:Person,
        "Geoffrey Ye Li"^^schema:Person,
        "Shang-Ho"^^schema:Person,
        "Shi Jin"^^schema:Person,
        "Tsai"^^schema:Person ;
    schema:dateModified "2021-01-12T08:36:23Z"^^schema:DateTime ;
    schema:datePublished "2021-01-12T08:36:23Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Phase Retrieval using Expectation Consistent Signal Recovery Algorithm  based on Hypernetwork"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.04348v1"^^schema:URL .

<1158> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of imitation learning from expert demonstrations inpartially observable Markov decision processes (POMDPs). Beliefrepresentations, which characterize the distribution over the latent states ina POMDP, have been modeled using recurrent neural networks and probabilisticlatent variable models, and shown to be effective for reinforcement learning inPOMDPs. In this work, we investigate the belief representation learning problemfor generative adversarial imitation learning in POMDPs. Instead of trainingthe belief module and the policy separately as suggested in prior work, welearn the belief module jointly with the policy, using a task-aware imitationloss to ensure that the representation is more aligned with the policy'sobjective. To improve robustness of representation, we introduce severalinformative belief regularization techniques, including multi-step predictionof dynamics and action-sequences. Evaluated on various partially observablecontinuous-control locomotion tasks, our belief-module imitation learningapproach (BMIL) substantially outperforms several baselines, including theoriginal GAIL algorithm and the task-agnostic belief learning algorithm.Extensive ablation analysis indicates the effectiveness of task-aware belieflearning and belief regularization."^^schema:Text ;
    schema:author "Jian Peng"^^schema:Person,
        "Joel Lehman"^^schema:Person,
        "Qiang Liu"^^schema:Person,
        "Tanmay Gangwani"^^schema:Person ;
    schema:dateModified "2019-06-22T21:40:03Z"^^schema:DateTime ;
    schema:datePublished "2019-06-22T21:40:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Belief Representations for Imitation Learning in POMDPs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.09510v1"^^schema:URL .

<1159> a schema:ScholarlyArticle ;
    schema:abstract "State-of-the-art solutions in the areas of \"Language Modelling &amp; GeneratingText\", \"Speech Recognition\", \"Generating Image Descriptions\" or \"Video Tagging\"have been using Recurrent Neural Networks as the foundation for theirapproaches. Understanding the underlying concepts is therefore of tremendousimportance if we want to keep up with recent or upcoming publications in thoseareas. In this work we give a short overview over some of the most importantconcepts in the realm of Recurrent Neural Networks which enables readers toeasily understand the fundamentals such as but not limited to \"Backpropagationthrough Time\" or \"Long Short-Term Memory Units\" as well as some of the morerecent advances like the \"Attention Mechanism\" or \"Pointer Networks\". We alsogive recommendations for further reading regarding more complex topics where itis necessary."^^schema:Text ;
    schema:author "Robin M. Schmidt"^^schema:Person ;
    schema:dateModified "2019-11-23T06:36:13Z"^^schema:DateTime ;
    schema:datePublished "2019-11-23T06:36:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Recurrent Neural Networks (RNNs): A gentle Introduction and Overview"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.05911v1"^^schema:URL .

<116> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we introduce a new set of reinforcement learning (RL) tasks inMinecraft (a flexible 3D world). We then use these tasks to systematicallycompare and contrast existing deep reinforcement learning (DRL) architectureswith our new memory-based DRL architectures. These tasks are designed toemphasize, in a controllable manner, issues that pose challenges for RL methodsincluding partial observability (due to first-person visual observations),delayed rewards, high-dimensional visual observations, and the need to useactive perception in a correct manner so as to perform well in the tasks. Whilethese tasks are conceptually simple to describe, by virtue of having all ofthese challenges simultaneously they are difficult for current DRLarchitectures. Additionally, we evaluate the generalization performance of thearchitectures on environments not used during training. The experimentalresults show that our new architectures generalize to unseen environmentsbetter than existing DRL architectures."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Junhyuk Oh"^^schema:Person,
        "Satinder Singh"^^schema:Person,
        "Valliappa Chockalingam"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:dateModified "2016-05-30T07:40:13Z"^^schema:DateTime ;
    schema:datePublished "2016-05-30T07:40:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Control of Memory, Active Perception, and Action in Minecraft"^^schema:Text ;
    schema:publisher "ICML, 2790-2799"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.09128v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3224107450664524795&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1160> a schema:ScholarlyArticle ;
    schema:abstract "An increasing share of image and video content is analyzed by machines ratherthan viewed by humans, and therefore it becomes relevant to optimize codecs forsuch applications where the analysis is performed remotely. Unfortunately,conventional coding tools are challenging to specialize for machine tasks asthey were originally designed for human perception. However, neural networkbased codecs can be jointly trained end-to-end with any convolutional neuralnetwork (CNN)-based task model. In this paper, we propose to study anend-to-end framework enabling efficient image compression for remote machinetask analysis, using a chain composed of a compression module and a taskalgorithm that can be optimized end-to-end. We show that it is possible tosignificantly improve the task accuracy when fine-tuning jointly the codec andthe task networks, especially at low bit-rates. Depending on training ordeployment constraints, selective fine-tuning can be applied only on theencoder, decoder or task network and still achieve rate-accuracy improvementsover an off-the-shelf codec and task network. Our results also demonstrate theflexibility of end-to-end pipelines for practical applications."^^schema:Text ;
    schema:author "Akshay Pushparaja"^^schema:Person,
        "Fabien Racapé"^^schema:Person,
        "Jean Bégaint"^^schema:Person,
        "Lahiru D. Chamain"^^schema:Person,
        "Simon Feltman"^^schema:Person ;
    schema:dateModified "2020-11-10T20:10:43Z"^^schema:DateTime ;
    schema:datePublished "2020-11-10T20:10:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "End-to-end optimized image compression for machines, a study"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.06409v1"^^schema:URL .

<1161> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we introduce Graph Pointer Networks (GPNs) trained usingreinforcement learning (RL) for tackling the traveling salesman problem (TSP).GPNs build upon Pointer Networks by introducing a graph embedding layer on theinput, which captures relationships between nodes. Furthermore, to approximatesolutions to constrained combinatorial optimization problems such as the TSPwith time windows, we train hierarchical GPNs (HGPNs) using RL, which learns ahierarchical policy to find an optimal city permutation under constraints. Eachlayer of the hierarchy is designed with a separate reward function, resultingin stable training. Our results demonstrate that GPNs trained on small-scaleTSP50/100 problems generalize well to larger-scale TSP500/1000 problems, withshorter tour lengths and faster computational times. We verify that forconstrained TSP problems such as the TSP with time windows, the feasiblesolutions found via hierarchical RL training outperform previous baselines. Inthe spirit of reproducible research we make our data, models, and code publiclyavailable."^^schema:Text ;
    schema:author "Danyang He"^^schema:Person,
        "Darshan Thaker"^^schema:Person,
        "Iddo Drori"^^schema:Person,
        "Qiang Ma"^^schema:Person,
        "Suwen Ge"^^schema:Person ;
    schema:dateModified "2019-11-12T15:39:21Z"^^schema:DateTime ;
    schema:datePublished "2019-11-12T15:39:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Combinatorial Optimization by Graph Pointer Networks and Hierarchical  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04936v1"^^schema:URL .

<1162> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we introduce a provably stable architecture for Neural OrdinaryDifferential Equations (ODEs) which achieves non-trivial adversarial robustnessunder white-box adversarial attacks even when the network is trained naturally.For most existing defense methods withstanding strong white-box attacks, toimprove robustness of neural networks, they need to be trained adversarially,hence have to strike a trade-off between natural accuracy and adversarialrobustness. Inspired by dynamical system theory, we design a stabilized neuralODE network named SONet whose ODE blocks are skew-symmetric and proved to beinput-output stable. With natural training, SONet can achieve comparablerobustness with the state-of-the-art adversarial defense methods, withoutsacrificing natural accuracy. Even replacing only the first layer of a ResNetby such a ODE block can exhibit further improvement in robustness, e.g., underPGD-20 ($\\ell_\\infty=0.031$) attack on CIFAR-10 dataset, it achieves 91.57\\%and natural accuracy and 62.35\\% robust accuracy, while a counterpartarchitecture of ResNet trained with TRADES achieves natural and robust accuracy76.29\\% and 45.24\\%, respectively. To understand possible reasons behind thissurprisingly good result, we further explore the possible mechanism underlyingsuch an adversarial robustness. We show that the adaptive stepsize numericalODE solver, DOPRI5, has a gradient masking effect that fails the PGD attackswhich are sensitive to gradient information of training loss; on the otherhand, it cannot fool the CW attack of robust gradients and the SPSA attack thatis gradient-free. This provides a new explanation that the adversarialrobustness of ODE-based networks mainly comes from the obfuscated gradients innumerical ODE solvers."^^schema:Text ;
    schema:author "Hongyang Zhang"^^schema:Person,
        "Yaodong Yu"^^schema:Person,
        "Yi Ma"^^schema:Person,
        "Yifei Huang"^^schema:Person,
        "Yuan Yao"^^schema:Person ;
    schema:dateModified "2020-09-28T08:51:42Z"^^schema:DateTime ;
    schema:datePublished "2020-09-28T08:51:42Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated  Gradients"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.13145v1"^^schema:URL .

<1163> a schema:ScholarlyArticle ;
    schema:abstract "In the NIPS 2017 Learning to Run challenge, participants were tasked withbuilding a controller for a musculoskeletal model to make it run as fast aspossible through an obstacle course. Top participants were invited to describetheir algorithms. In this work, we present eight solutions that used deepreinforcement learning approaches, based on algorithms such as DeepDeterministic Policy Gradient, Proximal Policy Optimization, and Trust RegionPolicy Optimization. Many solutions use similar relaxations and heuristics,such as reward shaping, frame skipping, discretization of the action space,symmetry, and policy blending. However, each of the eight teams implementeddifferent modifications of the known algorithms."^^schema:Text ;
    schema:author "Adam Stelmaszczyk"^^schema:Person,
        "Andrew Melnik"^^schema:Person,
        "Anton Pechenko"^^schema:Person,
        "Błażej Osiński"^^schema:Person,
        "Carmichael Ong"^^schema:Person,
        "Chun Yuan"^^schema:Person,
        "Helge Ritter"^^schema:Person,
        "Henryk Michalewski"^^schema:Person,
        "Jennifer Hicks"^^schema:Person,
        "Jiale Chen"^^schema:Person,
        "Jun Shi"^^schema:Person,
        "Malte Schilling"^^schema:Person,
        "Marcel Salathé"^^schema:Person,
        "Mikhail Pavlov"^^schema:Person,
        "Piotr Jarosik"^^schema:Person,
        "Piotr Miłoś"^^schema:Person,
        "Scott Delp"^^schema:Person,
        "Sean Carroll"^^schema:Person,
        "Sergey Kolesnikov"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Sergey Plis"^^schema:Person,
        "Sharada Prasanna Mohanty"^^schema:Person,
        "Shuchang Zhou"^^schema:Person,
        "Zhewei Huang"^^schema:Person,
        "Zhibo Chen"^^schema:Person,
        "Zhihui Lin"^^schema:Person,
        "Zhizheng Zhang"^^schema:Person,
        "Zhuobin Zheng"^^schema:Person,
        "Łukasz Kidziński"^^schema:Person ;
    schema:dateModified "2018-04-02T00:19:31Z"^^schema:DateTime ;
    schema:datePublished "2018-04-02T00:19:31Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning to Run challenge solutions: Adapting reinforcement learning  methods for neuromusculoskeletal environments"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.00361v1"^^schema:URL .

<1164> a schema:ScholarlyArticle ;
    schema:abstract "We propose a reward function estimation framework for inverse reinforcementlearning with deep energy-based policies. We name our method PQR, as itsequentially estimates the Policy, the $Q$-function, and the Reward function bydeep learning. PQR does not assume that the reward solely depends on the state,instead it allows for a dependency on the choice of action. Moreover, PQRallows for stochastic state transitions. To accomplish this, we assume theexistence of one anchor action whose reward is known, typically the action ofdoing nothing, yielding no reward. We present both estimators and algorithmsfor the PQR method. When the environment transition is known, we prove that thePQR reward estimator uniquely recovers the true reward. With unknowntransitions, we bound the estimation error of PQR. Finally, the performance ofPQR is demonstrated by synthetic and real-world datasets."^^schema:Text ;
    schema:author "A. Max Reppen"^^schema:Person,
        "Carlos A. Manzanares"^^schema:Person,
        "Houssam Nassif"^^schema:Person,
        "Ronnie Sircar"^^schema:Person,
        "Sinong Geng"^^schema:Person ;
    schema:dateModified "2020-08-15T02:26:40Z"^^schema:DateTime ;
    schema:datePublished "2020-07-15T02:35:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep PQR: Solving Inverse Reinforcement Learning using Anchor Actions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.07443v2"^^schema:URL .

<1165> a schema:ScholarlyArticle ;
    schema:abstract "Dual learning has been successfully applied in many machine learningapplications including machine translation, image-to-image transformation, etc.The high-level idea of dual learning is very intuitive: if we map an $x$ fromone domain to another and then map it back, we should recover the original $x$.Although its effectiveness has been empirically verified, theoreticalunderstanding of dual learning is still very limited. In this paper, we aim atunderstanding why and when dual learning works. Based on our theoreticalanalysis, we further extend dual learning by introducing more related mappingsand propose multi-step dual learning, in which we leverage feedback signalsfrom additional domains to improve the qualities of the mappings. We prove thatmulti-step dual learn-ing can boost the performance of standard dual learningunder mild conditions. Experiments on WMT 14 English$\\leftrightarrow$German andMultiUNEnglish$\\leftrightarrow$French translations verify our theoreticalfindings on dual learning, and the results on the translations among English,French, and Spanish of MultiUN demonstrate the effectiveness of multi-step duallearning."^^schema:Text ;
    schema:author "Lirong Xia"^^schema:Person,
        "Tao Qin"^^schema:Person,
        "Tie-Yan Liu"^^schema:Person,
        "Yingce Xia"^^schema:Person,
        "Zhibing Zhao"^^schema:Person ;
    schema:dateModified "2020-05-17T12:14:35Z"^^schema:DateTime ;
    schema:datePublished "2020-05-17T12:14:35Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dual Learning: Theoretical Study and an Algorithmic Extension"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.08238v1"^^schema:URL .

<1166> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) have shown impressive performance ingenerating photo-realistic images. They fit generative models by minimizingcertain distance measure between the real image distribution and the generateddata distribution. Several distance measures have been used, such asJensen-Shannon divergence, $f$-divergence, and Wasserstein distance, andchoosing an appropriate distance measure is very important for training thegenerative network. In this paper, we choose to use the maximum meandiscrepancy (MMD) as the distance metric, which has several nice theoreticalguarantees. In fact, generative moment matching network (GMMN) (Li, Swersky,and Zemel 2015) is such a generative model which contains only one generatornetwork $G$ trained by directly minimizing MMD between the real and generateddistributions. However, it fails to generate meaningful samples on challengingbenchmark datasets, such as CIFAR-10 and LSUN. To improve on GMMN, we proposeto add an extra network $F$, called mapper. $F$ maps both real datadistribution and generated data distribution from the original data space to afeature representation space $\\mathcal{R}$, and it is trained to maximize MMDbetween the two mapped distributions in $\\mathcal{R}$, while the generator $G$tries to minimize the MMD. We call the new model generative adversarial mappingnetworks (GAMNs). We demonstrate that the adversarial mapper $F$ can help $G$to better capture the underlying data distribution. We also show that GAMNsignificantly outperforms GMMN, and is also superior to or comparable withother state-of-the-art GAN based methods on MNIST, CIFAR-10 and LSUN-Bedroomsdatasets."^^schema:Text ;
    schema:author "Guangxiang Zhu"^^schema:Person,
        "Jian Li"^^schema:Person,
        "Jianbo Guo"^^schema:Person ;
    schema:dateModified "2017-09-28T06:41:28Z"^^schema:DateTime ;
    schema:datePublished "2017-09-28T06:41:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Generative Adversarial Mapping Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.09820v1"^^schema:URL .

<1167> a schema:ScholarlyArticle ;
    schema:abstract "Unconstrained handwritten text recognition remains an important challenge fordeep neural networks. These last years, recurrent networks and morespecifically Long Short-Term Memory networks have achieved state-of-the-artperformance in this field. Nevertheless, they are made of a large number oftrainable parameters and training recurrent neural networks does not supportparallelism. This has a direct influence on the training time of sucharchitectures, with also a direct consequence on the time required to explorevarious architectures. Recently, recurrence-free architectures such as FullyConvolutional Networks with gated mechanisms have been proposed as one possiblealternative achieving competitive results. In this paper, we exploreconvolutional architectures and compare them to a CNN+BLSTM baseline. Wepropose an experimental study regarding different architectures on an offlinehandwriting recognition task using the RIMES dataset, and a modified version ofit that consists of augmenting the images with notebook backgrounds that areprinted grids."^^schema:Text ;
    schema:author "Clément Chatelain"^^schema:Person,
        "Denis Coquenet"^^schema:Person,
        "Thierry Paquet"^^schema:Person,
        "Yann Soullard"^^schema:Person ;
    schema:dateModified "2020-12-09T10:15:24Z"^^schema:DateTime ;
    schema:datePublished "2020-12-09T10:15:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Have convolutions already made recurrence obsolete for unconstrained  handwritten text recognition ?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.04954v1"^^schema:URL .

<1168> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning algorithms such as hindsight experience replay (HER)and hindsight goal generation (HGG) have been able to solve challenging roboticmanipulation tasks in multi-goal settings with sparse rewards.  HER achieves its training success through hindsight replays of pastexperience with heuristic goals, but under-performs in challenging tasks inwhich goals are difficult to explore.  HGG enhances HER by selecting intermediate goals that are easy to achieve inthe short term and promising to lead to target goals in the long term.  This guided exploration makes HGG applicable to tasks in which target goalsare far away from the object's initial position.  However, HGG is not applicable to manipulation tasks with obstacles becausethe euclidean metric used for HGG is not an accurate distance metric in suchenvironments.  In this paper, we propose graph-based hindsight goal generation (G-HGG), anextension of HGG selecting hindsight goals based on shortest distances in anobstacle-avoiding graph, which is a discrete representation of the environment.  We evaluated G-HGG on four challenging manipulation tasks with obstacles,where significant enhancements in both sample efficiency and overall successrate are shown over HGG and HER.  Videos can be viewed at https://sites.google.com/view/demos-g-hgg/."^^schema:Text ;
    schema:author "Alois Knoll"^^schema:Person,
        "Fabrice O. Morin"^^schema:Person,
        "Kai Huang"^^schema:Person,
        "Matthias Brucker"^^schema:Person,
        "Zhenshan Bing"^^schema:Person ;
    schema:dateModified "2020-07-27T12:33:55Z"^^schema:DateTime ;
    schema:datePublished "2020-07-27T12:33:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Complex Robotic Manipulation via Graph-Based Hindsight Goal Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13486v1"^^schema:URL .

<1169> a schema:ScholarlyArticle ;
    schema:abstract "Given an artistic portrait, recovering the latent photorealistic face thatpreserves the subject's identity is challenging because the facial details areoften distorted or fully lost in artistic portraits. We develop anIdentity-preserving Face Recovery from Portraits (IFRP) method that utilizes aStyle Removal network (SRN) and a Discriminative Network (DN). Our SRN,composed of an autoencoder with residual block-embedded skip connections, isdesigned to transfer feature maps of stylized images to the feature maps of thecorresponding photorealistic faces. Owing to the Spatial Transformer Network(STN), SRN automatically compensates for misalignments of stylized portraits tooutput aligned realistic face images. To ensure the identity preservation, wepromote the recovered and ground truth faces to share similar visual featuresvia a distance measure which compares features of recovered and ground truthfaces extracted from a pre-trained FaceNet network. DN has multipleconvolutional and fully-connected layers, and its role is to enforce recoveredfaces to be similar to authentic faces. Thus, we can recover high-qualityphotorealistic faces from unaligned portraits while preserving the identity ofthe face in an image. By conducting extensive evaluations on a large-scalesynthesized dataset and a hand-drawn sketch dataset, we demonstrate that ourmethod achieves superior face recovery and attains state-of-the-art results. Inaddition, our method can recover photorealistic faces from unseen stylizedportraits, artistic paintings, and hand-drawn sketches."^^schema:Text ;
    schema:author "Fatemeh Shiri"^^schema:Person,
        "Fatih Porikli"^^schema:Person,
        "Piotr Koniusz"^^schema:Person,
        "Richard Hartley"^^schema:Person,
        "Xin Yu"^^schema:Person ;
    schema:dateModified "2019-04-07T09:18:59Z"^^schema:DateTime ;
    schema:datePublished "2019-04-07T09:18:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Identity-preserving Face Recovery from Stylized Portraits"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.04241v1"^^schema:URL .

<117> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a texture-shape cue conflict. We show thatImageNet-trained CNNs are strongly biased towards recognising textures ratherthan shapes, which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture (ResNet-50) that learns a texture-basedrepresentation on ImageNet is able to learn a shape-based representationinstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwell-controlled psychophysical lab setting (nine experiments totalling 48,560psychophysical trials across 97 observers) and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortions,highlighting advantages of a shape-based representation."^^schema:Text ;
    schema:author "Claudio Michaelis"^^schema:Person,
        "Felix A. Wichmann"^^schema:Person,
        "Matthias Bethge"^^schema:Person,
        "Patricia Rubisch"^^schema:Person,
        "Robert Geirhos"^^schema:Person,
        "Wieland Brendel"^^schema:Person ;
    schema:commentCount "318"^^schema:Integer ;
    schema:dateModified "2019-01-14T13:59:09Z"^^schema:DateTime ;
    schema:datePublished "2018-11-29T15:04:05Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "q-bio.NC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "ImageNet-trained CNNs are biased towards texture; increasing shape bias  improves accuracy and robustness"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1811.12231v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14190455085351957023&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1170> a schema:ScholarlyArticle ;
    schema:abstract "Communication is a critical factor for the big multi-agent world to stayorganized and productive. Typically, most previous multi-agent\"learning-to-communicate\" studies try to predefine the communication protocolsor use technologies such as tabular reinforcement learning and evolutionaryalgorithm, which can not generalize to changing environment or large collectionof agents.  In this paper, we propose an Actor-Coordinator-Critic Net (ACCNet) frameworkfor solving \"learning-to-communicate\" problem. The ACCNet naturally combinesthe powerful actor-critic reinforcement learning technology with deep learningtechnology. It can efficiently learn the communication protocols even fromscratch under partially observable environment. We demonstrate that the ACCNetcan achieve better results than several baselines under both continuous anddiscrete action space environments. We also analyse the learned protocols anddiscuss some design considerations."^^schema:Text ;
    schema:author "Hangyu Mao"^^schema:Person,
        "Yan Ni"^^schema:Person,
        "Zhen Xiao"^^schema:Person,
        "Zhibo Gong"^^schema:Person ;
    schema:dateModified "2017-10-29T05:09:39Z"^^schema:DateTime ;
    schema:datePublished "2017-06-10T13:50:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "ACCNet: Actor-Coordinator-Critic Net for \"Learning-to-Communicate\" with  Deep Multi-agent Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1706.03235v3"^^schema:URL .

<1171> a schema:ScholarlyArticle ;
    schema:abstract "The success of deep learning has inspired recent interests in applying neuralnetworks in statistical inference. In this paper, we investigate the use ofdeep neural networks for nonparametric regression with measurement errors. Wepropose an efficient neural network design for estimating measurement errormodels, in which we use a fully connected feed-forward neural network (FNN) toapproximate the regression function $f(x)$, a normalizing flow to approximatethe prior distribution of $X$, and an inference network to approximate theposterior distribution of $X$. Our method utilizes recent advances invariational inference for deep neural networks, such as the importance weightautoencoder, doubly reparametrized gradient estimator, and non-linearindependent components estimation. We conduct an extensive numerical study tocompare the neural network approach with classical nonparametric methods andobserve that the neural network approach is more flexible in accommodatingdifferent classes of regression functions and performs superior or comparableto the best available method in nearly all settings."^^schema:Text ;
    schema:author "Jun S Liu"^^schema:Person,
        "Zheng Tracy Ke"^^schema:Person,
        "Zhirui Hu"^^schema:Person ;
    schema:dateModified "2020-07-15T06:05:37Z"^^schema:DateTime ;
    schema:datePublished "2020-07-15T06:05:37Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Measurement error models: from nonparametric methods to deep neural  networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.07498v1"^^schema:URL .

<1172> a schema:ScholarlyArticle ;
    schema:abstract "Deep Neural Networks (DNNs) are a revolutionary force in the ongoinginformation revolution, and yet their intrinsic properties remain a mystery. Inparticular, it is widely known that DNNs are highly sensitive to noise, whetheradversarial or random. This poses a fundamental challenge for hardwareimplementations of DNNs, and for their deployment in critical applications suchas autonomous driving. In this paper we construct robust DNNs via errorcorrecting codes. By our approach, either the data or internal layers of theDNN are coded with error correcting codes, and successful computation undernoise is guaranteed. Since DNNs can be seen as a layered concatenation ofclassification tasks, our research begins with the core task of classifyingnoisy coded inputs, and progresses towards robust DNNs. We focus on binary dataand linear codes. Our main result is that the prevalent parity code canguarantee robustness for a large family of DNNs, which includes the recentlypopularized binarized neural networks. Further, we show that the codedclassification problem has a deep connection to Fourier analysis of Booleanfunctions. In contrast to existing solutions in the literature, our results donot rely on altering the training process of the DNN, and providemathematically rigorous guarantees rather than experimental evidence."^^schema:Text ;
    schema:author "Anxiao Jiang"^^schema:Person,
        "Jehoshua Bruck"^^schema:Person,
        "Netanel Raviv"^^schema:Person,
        "Pulakesh Upadhyaya"^^schema:Person,
        "Siddharth Jain"^^schema:Person ;
    schema:dateModified "2020-04-29T22:55:41Z"^^schema:DateTime ;
    schema:datePublished "2020-04-22T17:07:15Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "CodNN -- Robust Neural Networks From Coded Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10700v2"^^schema:URL .

<1173> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we focus on decomposing the latent representations in GANs orlearned feature representations in deep auto-encoders into semanticallycontrollable factors in a semi-supervised manner, without modifying theoriginal trained models. Specifically, we propose a FactorsDecomposer-Entangler Network (FDEN) that learns to decompose a latentrepresentation into mutually independent factors. Given a latentrepresentation, the proposed framework draws a set of interpretable factors,each aligned to independent factors of variations by maximizing their totalcorrelation in an information-theoretic means. As a plug-in method, we haveapplied our proposed FDEN to the existing networks of Adversarially LearnedInference and Pioneer Network and conducted computer vision tasks ofimage-to-image translation in semantic ways, e.g., changing styles whilekeeping an identify of a subject, and object classification in a few-shotlearning scheme. We have also validated the effectiveness of our method withvarious ablation studies in qualitative, quantitative, and statisticalexamination."^^schema:Text ;
    schema:author "Heung-Il Suk"^^schema:Person,
        "Jee Seok Yoon"^^schema:Person,
        "Myung-Cheol Roh"^^schema:Person ;
    schema:dateModified "2019-12-18T07:18:30Z"^^schema:DateTime ;
    schema:datePublished "2019-05-27T09:54:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Plug-in Method for Representation Factorization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11088v3"^^schema:URL .

<1174> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we introduce a new method for imitation learning from videodemonstrations. Our method, Relational Mimic (RM), improves on previous visualimitation learning methods by combining generative adversarial networks andrelational learning. RM is flexible and can be used in conjunction with otherrecent advances in generative adversarial imitation learning to better addressthe need for more robust and sample-efficient approaches. In addition, weintroduce a new neural network architecture that improves upon the previousstate-of-the-art in reinforcement learning and illustrate how increasing therelational reasoning capabilities of the agent enables the latter to achieveincreasingly higher performance in a challenging locomotion task with pixelinputs. Finally, we study the effects and contributions of relational learningin policy evaluation, policy improvement and reward learning through ablationstudies."^^schema:Text ;
    schema:author "Jian Zhang"^^schema:Person,
        "Lionel Blondé"^^schema:Person,
        "Russ Webb"^^schema:Person,
        "Yichuan Charlie Tang"^^schema:Person ;
    schema:dateModified "2019-12-18T08:19:39Z"^^schema:DateTime ;
    schema:datePublished "2019-12-18T08:19:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Relational Mimic for Visual Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.08444v1"^^schema:URL .

<1175> a schema:ScholarlyArticle ;
    schema:abstract "Programming languages are emerging as a challenging and interesting domainfor machine learning. A core task, which has received significant attention inrecent years, is building generative models of source code. However, to ourknowledge, previous generative models have always been framed in terms ofgenerating static snapshots of code. In this work, we instead treat source codeas a dynamic object and tackle the problem of modeling the edits that softwaredevelopers make to source code files. This requires extracting intent fromprevious edits and leveraging it to generate subsequent edits. We developseveral neural networks and use synthetic data to test their ability to learnchallenging edit patterns that require strong generalization. We then collectand train our models on a large-scale dataset of Google source code, consistingof millions of fine-grained edits from thousands of Python developers. From themodeling perspective, our main conclusion is that a new composition ofattentional and pointer network components provides the best overallperformance and scalability. From the application perspective, our resultsprovide preliminary evidence of the feasibility of developing tools that learnto predict future edits."^^schema:Text ;
    schema:author "Daniel Tarlow"^^schema:Person,
        "David Bieber"^^schema:Person,
        "Kevin Swersky"^^schema:Person,
        "Rui Zhao"^^schema:Person ;
    schema:dateModified "2019-04-04T23:06:09Z"^^schema:DateTime ;
    schema:datePublished "2019-04-04T23:06:09Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Networks for Modeling Source Code Edits"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.02818v1"^^schema:URL .

<1176> a schema:ScholarlyArticle ;
    schema:abstract "Domain adaptation has been well-studied in supervised neural machinetranslation (SNMT). However, it has not been well-studied for unsupervisedneural machine translation (UNMT), although UNMT has recently achievedremarkable results in several domain-specific language pairs. Besides theinconsistent domains between training data and test data for SNMT, theresometimes exists an inconsistent domain between two monolingual training datafor UNMT. In this work, we empirically show different scenarios forunsupervised neural machine translation. Based on these scenarios, we revisitthe effect of the existing domain adaptation methods including batch weightingand fine tuning methods in UNMT. Finally, we propose modified methods toimprove the performances of domain-specific UNMT systems."^^schema:Text ;
    schema:author "Chenhui Chu"^^schema:Person,
        "Eiichiro Sumita"^^schema:Person,
        "Haipeng Sun"^^schema:Person,
        "Kehai Chen"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Tiejun Zhao"^^schema:Person ;
    schema:dateModified "2020-05-05T04:05:26Z"^^schema:DateTime ;
    schema:datePublished "2019-08-26T11:36:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Revisiting Simple Domain Adaptation Methods in Unsupervised Neural  Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.09605v3"^^schema:URL .

<1177> a schema:ScholarlyArticle ;
    schema:abstract "Deepfake represents a category of face-swapping attacks that leverage machinelearning models such as autoencoders or generative adversarial networks.Although the concept of the face-swapping is not new, its recent technicaladvances make fake content (e.g., images, videos) more realistic andimperceptible to Humans. Various detection techniques for Deepfake attacks havebeen explored. These methods, however, are passive measures against Deepfakesas they are mitigation strategies after the high-quality fake content isgenerated. More importantly, we would like to think ahead of the attackers withrobust defenses. This work aims to take an offensive measure to impede thegeneration of high-quality fake images or videos. Specifically, we propose touse novel transformation-aware adversarially perturbed faces as a defenseagainst GAN-based Deepfake attacks. Different from the naive adversarial faces,our proposed approach leverages differentiable random image transformationsduring the generation. We also propose to use an ensemble-based approach toenhance the defense robustness against GAN-based Deepfake variants under theblack-box setting. We show that training a Deepfake model with adversarialfaces can lead to a significant degradation in the quality of synthesizedfaces. This degradation is twofold. On the one hand, the quality of thesynthesized faces is reduced with more visual artifacts such that thesynthesized faces are more obviously fake or less convincing to humanobservers. On the other hand, the synthesized faces can easily be detectedbased on various metrics."^^schema:Text ;
    schema:author "Chaofei Yang"^^schema:Person,
        "Hai Li"^^schema:Person,
        "Lei Ding"^^schema:Person,
        "Yiran Chen"^^schema:Person ;
    schema:dateModified "2020-06-12T18:51:57Z"^^schema:DateTime ;
    schema:datePublished "2020-06-12T18:51:57Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Defending against GAN-based Deepfake Attacks via Transformation-aware  Adversarial Faces"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.07421v1"^^schema:URL .

<1178> a schema:ScholarlyArticle ;
    schema:abstract "Intelligent personal assistant systems that are able to have multi-turnconversations with human users are becoming increasingly popular. Most previousresearch has been focused on using either retrieval-based or generation-basedmethods to develop such systems. Retrieval-based methods have the advantage ofreturning fluent and informative responses with great diversity. However, theperformance of the methods is limited by the size of the response repository.On the other hand, generation-based methods can produce highly coherentresponses on any topics. But the generated responses are often generic and notinformative due to the lack of grounding knowledge. In this paper, we propose ahybrid neural conversation model that combines the merits of both responseretrieval and generation methods. Experimental results on Twitter andFoursquare data show that the proposed model outperforms both retrieval-basedmethods and generation-based methods (including a recently proposedknowledge-grounded neural conversation model) under both automatic evaluationmetrics and human evaluation. We hope that the findings in this study providenew insights on how to integrate text retrieval and text generation models forbuilding conversation systems."^^schema:Text ;
    schema:author "Chen Qu"^^schema:Person,
        "Jianfeng Gao"^^schema:Person,
        "Jingjing Liu"^^schema:Person,
        "Junjie Hu"^^schema:Person,
        "Liu Yang"^^schema:Person,
        "Minghui Qiu"^^schema:Person,
        "W. Bruce Croft"^^schema:Person,
        "Xiaodong Liu"^^schema:Person,
        "Yelong Shen"^^schema:Person ;
    schema:dateModified "2019-08-25T23:52:20Z"^^schema:DateTime ;
    schema:datePublished "2019-04-19T04:10:03Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "A Hybrid Retrieval-Generation Neural Conversation Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.09068v2"^^schema:URL .

<1179> a schema:ScholarlyArticle ;
    schema:abstract "Exploration in environments with sparse rewards has been a persistent problemin reinforcement learning (RL). Many tasks are natural to specify with a sparsereward, and manually shaping a reward function can result in suboptimalperformance. However, finding a non-zero reward is exponentially more difficultwith increasing task horizon or action dimensionality. This puts manyreal-world tasks out of practical reach of RL methods. In this work, we usedemonstrations to overcome the exploration problem and successfully learn toperform long-horizon, multi-step robotics tasks with continuous control such asstacking blocks with a robot arm. Our method, which builds on top of DeepDeterministic Policy Gradients and Hindsight Experience Replay, provides anorder of magnitude of speedup over RL on simulated robotics tasks. It is simpleto implement and makes only the additional assumption that we can collect asmall set of demonstrations. Furthermore, our method is able to solve tasks notsolvable by either RL or behavior cloning alone, and often ends upoutperforming the demonstrator policy."^^schema:Text ;
    schema:author "Ashvin Nair"^^schema:Person,
        "Bob McGrew"^^schema:Person,
        "Marcin Andrychowicz"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person ;
    schema:dateModified "2018-02-25T07:48:19Z"^^schema:DateTime ;
    schema:datePublished "2017-09-28T17:51:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Overcoming Exploration in Reinforcement Learning with Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.10089v2"^^schema:URL .

<118> a schema:ScholarlyArticle ;
    schema:abstract "Variational Autoencoders (VAEs) are expressive latent variable models thatcan be used to learn complex probability distributions from training data.However, the quality of the resulting model crucially relies on theexpressiveness of the inference model. We introduce Adversarial VariationalBayes (AVB), a technique for training Variational Autoencoders with arbitrarilyexpressive inference models. We achieve this by introducing an auxiliarydiscriminative network that allows to rephrase the maximum-likelihood-problemas a two-player game, hence establishing a principled connection between VAEsand Generative Adversarial Networks (GANs). We show that in the nonparametriclimit our method yields an exact maximum-likelihood assignment for theparameters of the generative model, as well as the exact posterior distributionover the latent variables given an observation. Contrary to competingapproaches which combine VAEs with GANs, our approach has a clear theoreticaljustification, retains most advantages of standard Variational Autoencoders andis easy to implement."^^schema:Text ;
    schema:author "Andreas Geiger"^^schema:Person,
        "Lars Mescheder"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person ;
    schema:commentCount "292"^^schema:Integer ;
    schema:dateModified "2018-06-11T12:19:02Z"^^schema:DateTime ;
    schema:datePublished "2017-01-17T15:18:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Adversarial Variational Bayes: Unifying Variational Autoencoders and  Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICML, 2391-2400"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.04722v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12656834929147362081&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1180> a schema:ScholarlyArticle ;
    schema:abstract "Integration of data from multiple omics techniques is becoming increasinglyimportant in biomedical research. Due to non-uniformity and technicallimitations in omics platforms, such integrative analyses on multiple omics,which we refer to as views, involve learning from incomplete observations withvarious view-missing patterns. This is challenging because i) complexinteractions within and across observed views need to be properly addressed foroptimal predictive power and ii) observations with various view-missingpatterns need to be flexibly integrated. To address such challenges, we proposea deep variational information bottleneck (IB) approach for incompletemulti-view observations. Our method applies the IB framework on marginal andjoint representations of the observed views to focus on intra-view andinter-view interactions that are relevant for the target. Most importantly, bymodeling the joint representations as a product of marginal representations, wecan efficiently learn from observed views with various view-missing patterns.Experiments on real-world datasets show that our method consistently achievesgain from data integration and outperforms state-of-the-art benchmarks."^^schema:Text ;
    schema:author "Changhee Lee"^^schema:Person,
        "Mihaela van der Schaar"^^schema:Person ;
    schema:dateModified "2021-02-05T06:05:39Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T06:05:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "A Variational Information Bottleneck Approach to Multi-Omics Data  Integration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03014v1"^^schema:URL .

<1181> a schema:ScholarlyArticle ;
    schema:abstract "The identification of essential genes/proteins is a critical step towards abetter understanding of human biology and pathology. Computational approacheshelped to mitigate experimental constraints by exploring machine learning (ML)methods and the correlation of essentiality with biological information,especially protein-protein interaction (PPI) networks, to predict essentialgenes. Nonetheless, their performance is still limited, as network-basedcentralities are not exclusive proxies of essentiality, and traditional MLmethods are unable to learn from non-Euclidean domains such as graphs. Giventhese limitations, we proposed EPGAT, an approach for essentiality predictionbased on Graph Attention Networks (GATs), which are attention-based GraphNeural Networks (GNNs) that operate on graph-structured data. Our modeldirectly learns patterns of gene essentiality from PPI networks, integratingadditional evidence from multiomics data encoded as node attributes. Webenchmarked EPGAT for four organisms, including humans, accurately predictinggene essentiality with AUC score ranging from 0.78 to 0.97. Our modelsignificantly outperformed network-based and shallow ML-based methods andachieved a very competitive performance against the state-of-the-art node2vecembedding method. Notably, EPGAT was the most robust approach in scenarios withlimited and imbalanced training data. Thus, the proposed approach offers apowerful and effective way to identify essential genes and proteins."^^schema:Text ;
    schema:author "Anderson Tavares"^^schema:Person,
        "João Schapke"^^schema:Person,
        "Mariana Recamonde-Mendoza"^^schema:Person ;
    schema:dateModified "2020-07-19T13:47:15Z"^^schema:DateTime ;
    schema:datePublished "2020-07-19T13:47:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.GN"^^schema:Text,
        "q-bio.MN"^^schema:Text ;
    schema:headline "EPGAT: Gene Essentiality Prediction With Graph Attention Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.09671v1"^^schema:URL .

<1182> a schema:ScholarlyArticle ;
    schema:abstract "Domain adaptation investigates the problem of cross-domain knowledge transferwhere the labeled source domain and unlabeled target domain have distinctivedata distributions. Recently, adversarial training have been successfullyapplied to domain adaptation and achieved state-of-the-art performance.However, there is still a fatal weakness existing in current adversarial modelswhich is raised from the equilibrium challenge of adversarial training.Specifically, although most of existing methods are able to confuse the domaindiscriminator, they cannot guarantee that the source domain and target domainare sufficiently similar. In this paper, we propose a novel approach named {\\itcycle-consistent conditional adversarial transfer networks} (3CATN) to handlethis issue. Our approach takes care of the domain alignment by leveragingadversarial training. Specifically, we condition the adversarial networks withthe cross-covariance of learned features and classifier predictions to capturethe multimodal structures of data distributions. However, since the classifierpredictions are not certainty information, a strong condition with thepredictions is risky when the predictions are not accurate. We, therefore,further propose that the truly domain-invariant features should be able to betranslated from one domain to the other. To this end, we introduce two featuretranslation losses and one cycle-consistent loss into the conditionaladversarial domain adaptation networks. Extensive experiments on both classicaland large-scale datasets verify that our model is able to outperform previousstate-of-the-arts with significant improvements."^^schema:Text ;
    schema:author "Erpeng Chen"^^schema:Person,
        "Jingjing Li"^^schema:Person,
        "Ke Lu"^^schema:Person,
        "Lei Zhu"^^schema:Person,
        "Zhengming Ding"^^schema:Person,
        "Zi Huang"^^schema:Person ;
    schema:dateModified "2019-09-17T07:14:26Z"^^schema:DateTime ;
    schema:datePublished "2019-09-17T07:14:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Cycle-consistent Conditional Adversarial Transfer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.07618v1"^^schema:URL .

<1183> a schema:ScholarlyArticle ;
    schema:abstract "Unlike the brain, artificial neural networks, including state-of-the-art deepneural networks for computer vision, are subject to \"catastrophic forgetting\":they rapidly forget the previous task when trained on a new one. Neurosciencesuggests that biological synapses avoid this issue through the process ofsynaptic consolidation and metaplasticity: the plasticity itself changes uponrepeated synaptic events. In this work, we show that this concept ofmetaplasticity can be transferred to a particular type of deep neural networks,binarized neural networks, to reduce catastrophic forgetting."^^schema:Text ;
    schema:author "Axel Laborieux"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Maxence Ernoult"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2021-01-19T12:32:07Z"^^schema:DateTime ;
    schema:datePublished "2021-01-19T12:32:07Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text ;
    schema:headline "Synaptic metaplasticity in binarized neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.07592v1"^^schema:URL .

<1184> a schema:ScholarlyArticle ;
    schema:abstract "The demand for abstractive dialog summary is growing in real-worldapplications. For example, customer service center or hospitals would like tosummarize customer service interaction and doctor-patient interaction. However,few researchers explored abstractive summarization on dialogs due to the lackof suitable datasets. We propose an abstractive dialog summarization datasetbased on MultiWOZ. If we directly apply previous state-of-the-art documentsummarization methods on dialogs, there are two significant drawbacks: theinformative entities such as restaurant names are difficult to preserve, andthe contents from different dialog domains are sometimes mismatched. To addressthese two drawbacks, we propose Scaffold Pointer Network (SPNet)to utilize theexisting annotation on speaker role, semantic slot and dialog domain. SPNetincorporates these semantic scaffolds for dialog summarization. Since ROUGEcannot capture the two drawbacks mentioned, we also propose a new evaluationmetric that considers critical informative entities in the text. On MultiWOZ,our proposed SPNet outperforms state-of-the-art abstractive summarizationmethods on all the automatic and human evaluation metrics."^^schema:Text ;
    schema:author "Lin Yuan"^^schema:Person,
        "Zhou Yu"^^schema:Person ;
    schema:dateModified "2019-10-02T08:22:03Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T08:22:03Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Abstractive Dialog Summarization with Semantic Scaffolds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00825v1"^^schema:URL .

<1185> a schema:ScholarlyArticle ;
    schema:abstract "Companies provide annual reports to their shareholders at the end of thefinancial year that describes their operations and financial conditions. Theaverage length of these reports is 80, and it may extend up to 250 pages long.In this paper, we propose our methodology PoinT-5 (the combination of PointerNetwork and T-5 (Test-to-text transfer Transformer) algorithms) that we used inthe Financial Narrative Summarisation (FNS) 2020 task. The proposed method usespointer networks to extract important narrative sentences from the report, andthen T-5 is used to paraphrase extracted sentences into a concise yetinformative sentence. We evaluate our method using ROUGE-N (1,2), L, and SU4.The proposed method achieves the highest precision scores in all the metricsand highest F1 scores in ROUGE1, and LCS and the only solution to cross theMUSE solution baseline in ROUGE-LCS metrics."^^schema:Text ;
    schema:author "Abhishek Singh"^^schema:Person ;
    schema:dateModified "2020-10-12T03:31:25Z"^^schema:DateTime ;
    schema:datePublished "2020-10-08T18:09:45Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "PoinT-5: Pointer Network and T-5 based Financial NarrativeSummarisation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.04191v2"^^schema:URL .

<1186> a schema:ScholarlyArticle ;
    schema:abstract "Sentence matching is a fundamental task of natural language processing withvarious applications. Most recent approaches adopt attention-based neuralmodels to build word- or phrase-level alignment between two sentences. However,these models usually ignore the inherent structure within the sentences andfail to consider various dependency relationships among text units. To addressthese issues, this paper proposes a graph-based approach for sentence matching.First, we represent a sentence pair as a graph with several carefully designstrategies. We then employ a novel gated graph attention network to encode theconstructed graph for sentence matching. Experimental results demonstrate thatour method substantially achieves state-of-the-art performance on two datasetsacross tasks of natural language and paraphrase identification. Furtherdiscussions show that our model can learn meaningful graph structure,indicating its superiority on improved interpretability."^^schema:Text ;
    schema:author "Le Hu"^^schema:Person,
        "Peng Cui"^^schema:Person,
        "Yuanchao Liu"^^schema:Person ;
    schema:dateModified "2020-10-15T11:25:54Z"^^schema:DateTime ;
    schema:datePublished "2020-10-15T11:25:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Inducing Alignment Structure with Gated Graph Attention Networks for  Sentence Matching"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07668v1"^^schema:URL .

<1187> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay, which enables the agents to remember and reuse experiencefrom the past, plays a significant role in the success of off-policyreinforcement learning (RL). To utilize the experience replay efficiently,experience transitions should be sampled with consideration of theirsignificance, such that the known prioritized experience replay (PER) furtherallows to sample more important experience. Yet, the conventional PER mayresult in generating highly biased samples due to considering a single metricsuch as TD-error and computing the sampling rate independently for eachexperience. To tackle this issue, we propose a Neural Experience Replay Sampler(NERS), which adaptively evaluates the relative importance of a sampledtransition by obtaining context from not only its (local) values thatcharacterize itself such as TD-error or the raw features but also other(global) transitions. We validate our framework on multiple benchmark tasks forboth continuous and discrete controls and show that the proposed frameworksignificantly improves the performance of various off-policy RL methods.Further analysis confirms that the improvements indeed come from the use ofdiverse features and the consideration of the relative importance ofexperiences."^^schema:Text ;
    schema:author "Eunho Yang"^^schema:Person,
        "Jinwoo Shin"^^schema:Person,
        "Kimin Lee"^^schema:Person,
        "Sung Ju Hwang"^^schema:Person,
        "Youngmin Oh"^^schema:Person ;
    schema:dateModified "2020-07-14T21:12:56Z"^^schema:DateTime ;
    schema:datePublished "2020-07-14T21:12:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning to Sample with Local and Global Contexts in Experience Replay  Buffer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.07358v1"^^schema:URL .

<1188> a schema:ScholarlyArticle ;
    schema:abstract "Current facial expression recognition methods fail to simultaneously copewith pose and subject variations.  In this paper, we propose a novel unsupervised adversarial domain adaptationmethod which can alleviate both variations at the same time. Specially, ourmethod consists of three learning strategies: adversarial domain adaptationlearning, cross adversarial feature learning, and reconstruction learning. Thefirst aims to learn pose- and expression-related feature representations in thesource domain and adapt both feature distributions to that of the target domainby imposing adversarial learning. By using personalized adversarial domainadaptation, this learning strategy can alleviate subject variations and exploitinformation from the source domain to help learning in the target domain.  The second serves to perform feature disentanglement between pose- andexpression-related feature representations by impulsing pose-related featurerepresentations expression-undistinguished and the expression-related featurerepresentations pose-undistinguished.  The last can further boost feature learning by applying face imagereconstructions so that the learned expression-related feature representationsare more pose- and identity-robust.  Experimental results on four benchmark datasets demonstrate the effectivenessof the proposed method."^^schema:Text ;
    schema:author "Can Wang"^^schema:Person,
        "Guang Liang"^^schema:Person,
        "Shangfei Wang"^^schema:Person ;
    schema:dateModified "2020-07-12T07:58:31Z"^^schema:DateTime ;
    schema:datePublished "2020-07-12T07:58:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Pose-aware Adversarial Domain Adaptation for Personalized Facial  Expression Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.05932v1"^^schema:URL .

<1189> a schema:ScholarlyArticle ;
    schema:abstract "Adjoint-based optimization methods are attractive for aerodynamic shapedesign primarily due to their computational costs being independent of thedimensionality of the input space and their ability to generate high-fidelitygradients that can then be used in a gradient-based optimizer. This makes themvery well suited for high-fidelity simulation based aerodynamic shapeoptimization of highly parametrized geometries such as aircraft wings. However,the development of adjoint-based solvers involve careful mathematical treatmentand their implementation require detailed software development. Furthermore,they can become prohibitively expensive when multiple optimization problems arebeing solved, each requiring multiple restarts to circumvent local optima. Inthis work, we propose a machine learning enabled, surrogate-based frameworkthat replaces the expensive adjoint solver, without compromising on predictingpredictive accuracy. Specifically, we first train a deep neural network (DNN)from training data generated from evaluating the high-fidelity simulation modelon a model-agnostic, design of experiments on the geometry shape parameters.The optimum shape may then be computed by using a gradient-based optimizercoupled with the trained DNN. Subsequently, we also perform a gradient-freeBayesian optimization, where the trained DNN is used as the prior mean. Weobserve that the latter framework (DNN-BO) improves upon the DNN-only basedoptimization strategy for the same computational cost. Overall, this frameworkpredicts the true optimum with very high accuracy, while requiring far fewerhigh-fidelity function calls compared to the adjoint-based method. Furthermore,we show that multiple optimization problems can be solved with the same machinelearning model with high accuracy, to amortize the offline costs associatedwith constructing our models."^^schema:Text ;
    schema:author "Jai Ahuja"^^schema:Person,
        "Romit Maulik and"^^schema:Person,
        "S. Ashwin Renganathan"^^schema:Person ;
    schema:dateModified "2020-08-15T15:09:21Z"^^schema:DateTime ;
    schema:datePublished "2020-08-15T15:09:21Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text,
        "physics.comp-ph"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Enhanced data efficiency using deep neural networks and Gaussian  processes for aerodynamic design optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.06731v1"^^schema:URL .

<119> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of attributing the prediction of a deep network to itsinput features, a problem previously studied by several other works. Weidentify two fundamental axioms---Sensitivity and Implementation Invariancethat attribution methods ought to satisfy. We show that they are not satisfiedby most known attribution methods, which we consider to be a fundamentalweakness of those methods. We use the axioms to guide the design of a newattribution method called Integrated Gradients. Our method requires nomodification to the original network and is extremely simple to implement; itjust needs a few calls to the standard gradient operator. We apply this methodto a couple of image models, a couple of text models and a chemistry model,demonstrating its ability to debug networks, to extract rules from a network,and to enable users to engage with models better."^^schema:Text ;
    schema:author "Ankur Taly"^^schema:Person,
        "Mukund Sundararajan"^^schema:Person,
        "Qiqi Yan"^^schema:Person ;
    schema:commentCount "696"^^schema:Integer ;
    schema:dateModified "2017-06-13T01:52:38Z"^^schema:DateTime ;
    schema:datePublished "2017-03-04T00:18:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Axiomatic Attribution for Deep Networks"^^schema:Text ;
    schema:publisher "ICML, 3319-3328"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01365v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6002490314140284060&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1190> a schema:ScholarlyArticle ;
    schema:abstract "We present two elegant solutions for modeling continuous-time dynamics, in anovel model-based reinforcement learning (RL) framework for semi-Markovdecision processes (SMDPs), using neural ordinary differential equations(ODEs). Our models accurately characterize continuous-time dynamics and enableus to develop high-performing policies using a small amount of data. We alsodevelop a model-based approach for optimizing time schedules to reduceinteraction rates with the environment while maintaining the near-optimalperformance, which is not possible for model-free methods. We experimentallydemonstrate the efficacy of our methods across various continuous-time domains."^^schema:Text ;
    schema:author "Finale Doshi-Velez"^^schema:Person,
        "Jianzhun Du"^^schema:Person,
        "Joseph Futoma"^^schema:Person ;
    schema:dateModified "2020-10-25T05:55:05Z"^^schema:DateTime ;
    schema:datePublished "2020-06-29T17:21:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Model-based Reinforcement Learning for Semi-Markov Decision Processes  with Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16210v2"^^schema:URL .

<1191> a schema:ScholarlyArticle ;
    schema:abstract "Fine-grained visual recognition aims to capture discriminativecharacteristics amongst visually similar categories. The state-of-the-artresearch work has significantly improved the fine-grained recognitionperformance by deep metric learning using triplet network. However, the impactof intra-category variance on the performance of recognition and robust featurerepresentation has not been well studied. In this paper, we propose to leverageintra-class variance in metric learning of triplet network to improve theperformance of fine-grained recognition. Through partitioning training imageswithin each category into a few groups, we form the triplet samples acrossdifferent categories as well as different groups, which is called GroupSensitive TRiplet Sampling (GS-TRS). Accordingly, the triplet loss function isstrengthened by incorporating intra-class variance with GS-TRS, which maycontribute to the optimization objective of triplet network. Extensiveexperiments over benchmark datasets CompCar and VehicleID show that theproposed GS-TRS has significantly outperformed state-of-the-art approaches inboth classification and retrieval tasks."^^schema:Text ;
    schema:author "Feng Gao"^^schema:Person,
        "Ling-Yu Duan"^^schema:Person,
        "Shiqi Wang"^^schema:Person,
        "Tiejun Huang"^^schema:Person,
        "Yan Bai"^^schema:Person,
        "Yihang Lou"^^schema:Person ;
    schema:dateModified "2017-03-01T09:41:02Z"^^schema:DateTime ;
    schema:datePublished "2017-03-01T09:41:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Incorporating Intra-Class Variance to Fine-Grained Visual Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1703.00196v1"^^schema:URL .

<1192> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we describe the details of the neural dependency parsersub-mitted by our team to the NLPCC 2019 Shared Task of Semi-supervised do-mainadaptation subtask on Cross-domain Dependency Parsing. Our system is based onthe stack-pointer networks(STACKPTR). Considering the im-portance of context,we utilize self-attention mechanism for the representa-tion vectors to capturethe meaning of words. In addition, to adapt three dif-ferent domains, weutilize neural network based deep transfer learning which transfers thepre-trained partial network in the source domain to be a part of deep neuralnetwork in the three target domains (product comments, product blogs and webfiction) respectively. Results on the three target domains demonstrate that ourmodel performs competitively."^^schema:Text ;
    schema:author "Junsheng Zhou"^^schema:Person,
        "Likai Wang"^^schema:Person,
        "Weiguang Qu"^^schema:Person,
        "Yanhui Gu"^^schema:Person,
        "Zhentao Xia"^^schema:Person ;
    schema:dateModified "2019-08-08T01:16:34Z"^^schema:DateTime ;
    schema:datePublished "2019-08-08T01:16:34Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Neural Network based Deep Transfer Learning for Cross-domain Dependency  Parsing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.02895v1"^^schema:URL .

<1193> a schema:ScholarlyArticle ;
    schema:abstract "The problem of vanishing and exploding gradients has been a long-standingobstacle that hinders the effective training of neural networks. Despitevarious tricks and techniques that have been employed to alleviate the problemin practice, there still lacks satisfactory theories or provable solutions. Inthis paper, we address the problem from the perspective of high-dimensionalprobability theory. We provide a rigorous result that shows, under mildconditions, how the vanishing/exploding gradients problem disappears with highprobability if the neural networks have sufficient width. Our main idea is toconstrain both forward and backward signal propagation in a nonlinear neuralnetwork through a new class of activation functions, namely Gaussian-Poincar\\'enormalized functions, and orthogonal weight matrices. Experiments on bothsynthetic and real-world data validate our theory and confirm its effectivenesson very deep neural networks when applied in practice."^^schema:Text ;
    schema:author "Stephen Gould"^^schema:Person,
        "Thalaiyasingam Ajanthan"^^schema:Person,
        "Yao Lu"^^schema:Person ;
    schema:dateModified "2020-10-16T21:57:02Z"^^schema:DateTime ;
    schema:datePublished "2020-06-22T12:07:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Bidirectional Self-Normalizing Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.12169v2"^^schema:URL .

<1194> a schema:ScholarlyArticle ;
    schema:abstract "The increased focus on misinformation has spurred development of data andsystems for detecting the veracity of a claim as well as retrievingauthoritative evidence. The Fact Extraction and VERification (FEVER) datasetprovides such a resource for evaluating end-to-end fact-checking, requiringretrieval of evidence from Wikipedia to validate a veracity prediction. We showthat current systems for FEVER are vulnerable to three categories of realisticchallenges for fact-checking -- multiple propositions, temporal reasoning, andambiguity and lexical variation -- and introduce a resource with these types ofclaims. Then we present a system designed to be resilient to these \"attacks\"using multiple pointer networks for document selection and jointly modeling asequence of evidence sentences and veracity relation predictions. We find thatin handling these attacks we obtain state-of-the-art results on FEVER, largelydue to improved evidence retrieval."^^schema:Text ;
    schema:author "Christopher Hidey"^^schema:Person,
        "Kriste Krstovski"^^schema:Person,
        "Mona Diab"^^schema:Person,
        "Siddharth Varia"^^schema:Person,
        "Smaranda Muresan"^^schema:Person,
        "Tariq Alhindi"^^schema:Person,
        "Tuhin Chakrabarty"^^schema:Person ;
    schema:dateModified "2020-04-27T15:18:49Z"^^schema:DateTime ;
    schema:datePublished "2020-04-27T15:18:49Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "DeSePtion: Dual Sequence Prediction and Adversarial Examples for  Improved Fact-Checking"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.12864v1"^^schema:URL .

<1195> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we introduce bitcell array-based support parameters to improvethe prediction accuracy of SRAM-based binarized neural network (SRAM-BNN). Ourapproach enhances the training weight space of SRAM-BNN while requiring minimaloverheads to a typical design. More flexibility of the weight space leads tohigher prediction accuracy in our design. We adapt row digital-to-analog (DAC)converter, and computing flow in SRAM-BNN for bitcell array-based weightsupports. Using the discussed interventions, our scheme also allows a dynamictrade-off of accuracy against latency to address dynamic latency constraints intypical real-time applications. We specifically discuss results on two trainingcases: (i) learning of support parameters on a pre-trained BNN and (ii)simultaneous learning of supports and weight binarization. In the former case,our approach reduces classification error in MNIST by 35.71% (error ratedecreases from 1.4% to 0.91%). In the latter case, the error is reduced by27.65% (error rate decreases from 1.4% to 1.13%). To reduce the poweroverheads, we propose a dynamic drop out a part of the support parameters. Ourarchitecture can drop out 52% of the bitcell array-based support parameterswithout losing accuracy. We also characterize our design under varying degreesof process variability in the transistors."^^schema:Text ;
    schema:author "Amit Ranjan Trivedi"^^schema:Person,
        "Shamma Nasrin"^^schema:Person,
        "Srikanth Ramakrishna"^^schema:Person,
        "Theja Tulabandhula"^^schema:Person ;
    schema:dateModified "2019-11-26T17:34:40Z"^^schema:DateTime ;
    schema:datePublished "2019-11-19T19:27:06Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Supported-BinaryNet: Bitcell Array-based Weight Supports for Dynamic  Accuracy-Latency Trade-offs in SRAM-based Binarized Neural Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.08518v2"^^schema:URL .

<1196> a schema:ScholarlyArticle ;
    schema:abstract "Emotional voice conversion aims to transform emotional prosody in speechwhile preserving the linguistic content and speaker identity. Prior studiesshow that it is possible to disentangle emotional prosody using anencoder-decoder network conditioned on discrete representation, such as one-hotemotion labels. Such networks learn to remember a fixed set of emotionalstyles. In this paper, we propose a novel framework based on variationalauto-encoding Wasserstein generative adversarial network (VAW-GAN), which makesuse of a pre-trained speech emotion recognition (SER) model to transferemotional style during training and at run-time inference. In this way, thenetwork is able to transfer both seen and unseen emotional style to a newutterance. We show that the proposed framework achieves remarkable performanceby consistently outperforming the baseline framework. This paper also marks therelease of an emotional speech dataset (ESD) for voice conversion, which hasmultiple speakers and languages."^^schema:Text ;
    schema:author "Berrak Sisman"^^schema:Person,
        "Haizhou Li"^^schema:Person,
        "Kun Zhou"^^schema:Person,
        "Rui Liu"^^schema:Person ;
    schema:dateModified "2020-10-28T07:16:18Z"^^schema:DateTime ;
    schema:datePublished "2020-10-28T07:16:18Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Seen and Unseen emotional style transfer for voice conversion with a new  emotional speech dataset"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.14794v1"^^schema:URL .

<1197> a schema:ScholarlyArticle ;
    schema:abstract "Hyperparameter optimization of neural networks can be elegantly formulated asa bilevel optimization problem. While research on bilevel optimization ofneural networks has been dominated by implicit differentiation and unrolling,hypernetworks such as Self-Tuning Networks (STNs) have recently gained tractiondue to their ability to amortize the optimization of the inner objective. Inthis paper, we diagnose several subtle pathologies in the training of STNs.Based on these observations, we propose the $\\Delta$-STN, an improvedhypernetwork architecture which stabilizes training and optimizeshyperparameters much more efficiently than STNs. The key idea is to focus onaccurately approximating the best-response Jacobian rather than the fullbest-response function; we achieve this by reparameterizing the hypernetworkand linearizing the network around the current parameters. We demonstrateempirically that our $\\Delta$-STN can tune regularization hyperparameters (e.g.weight decay, dropout, number of cutout holes) with higher accuracy, fasterconvergence, and improved stability compared to existing approaches."^^schema:Text ;
    schema:author "Juhan Bae"^^schema:Person,
        "Roger Grosse"^^schema:Person ;
    schema:dateModified "2020-10-26T12:12:23Z"^^schema:DateTime ;
    schema:datePublished "2020-10-26T12:12:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Delta-STN: Efficient Bilevel Optimization for Neural Networks using  Structured Response Jacobians"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13514v1"^^schema:URL .

<1198> a schema:ScholarlyArticle ;
    schema:abstract "In many real-world decision making problems, reaching an optimal decisionrequires taking into account a variable number of objects around the agent.Autonomous driving is a domain in which this is especially relevant, since thenumber of cars surrounding the agent varies considerably over time and affectsthe optimal action to be taken. Classical methods that process object lists candeal with this requirement. However, to take advantage of recenthigh-performing methods based on deep reinforcement learning in modularpipelines, special architectures are necessary. For these, a number of optionsexist, but a thorough comparison of the different possibilities is missing. Inthis paper, we elaborate limitations of fully-connected neural networks andother established approaches like convolutional and recurrent neural networksin the context of reinforcement learning problems that have to deal withvariable sized inputs. We employ the structure of Deep Sets in off-policyreinforcement learning for high-level decision making, highlight theircapabilities to alleviate these limitations, and show that Deep Sets not onlyyield the best overall performance but also offer better generalization tounseen situations than the other approaches."^^schema:Text ;
    schema:author "Branka Mirchevska"^^schema:Person,
        "Gabriel Kalweit"^^schema:Person,
        "Joschka Boedecker"^^schema:Person,
        "Maria Hügle"^^schema:Person,
        "Moritz Werling"^^schema:Person ;
    schema:dateModified "2019-07-25T12:08:28Z"^^schema:DateTime ;
    schema:datePublished "2019-07-25T12:08:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dynamic Input for Deep Reinforcement Learning in Autonomous Driving"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.10994v1"^^schema:URL .

<1199> a schema:ScholarlyArticle ;
    schema:abstract "Designing robust and accurate predictive models for stock price predictionhas been an active area of research for a long time. While on one side, thesupporters of the efficient market hypothesis claim that it is impossible toforecast stock prices accurately, many researchers believe otherwise. Thereexist propositions in the literature that have demonstrated that if properlydesigned and optimized, predictive models can very accurately and reliablypredict future values of stock prices. This paper presents a suite of deeplearning based models for stock price prediction. We use the historical recordsof the NIFTY 50 index listed in the National Stock Exchange of India, duringthe period from December 29, 2008 to July 31, 2020, for training and testingthe models. Our proposition includes two regression models built onconvolutional neural networks and three long and short term memory networkbased predictive models. To forecast the open values of the NIFTY 50 indexrecords, we adopted a multi step prediction technique with walk forwardvalidation. In this approach, the open values of the NIFTY 50 index arepredicted on a time horizon of one week, and once a week is over, the actualindex values are included in the training set before the model is trainedagain, and the forecasts for the next week are made. We present detailedresults on the forecasting accuracies for all our proposed models. The resultsshow that while all the models are very accurate in forecasting the NIFTY 50open values, the univariate encoder decoder convolutional LSTM with theprevious two weeks data as the input is the most accurate model. On the otherhand, a univariate CNN model with previous one week data as the input is foundto be the fastest model in terms of its execution speed."^^schema:Text ;
    schema:author "Jaydip Sen"^^schema:Person,
        "Sidra Mehtab"^^schema:Person ;
    schema:dateModified "2020-10-22T03:09:07Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T03:09:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-fin.CP"^^schema:Text ;
    schema:headline "Stock Price Prediction Using CNN and LSTM-Based Deep Learning Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13891v1"^^schema:URL .

<12> a schema:ScholarlyArticle ;
    schema:abstract "Training directed neural networks typically requires forward-propagating datathrough a computation graph, followed by backpropagating error signal, toproduce weight updates. All layers, or more generally, modules, of the networkare therefore locked, in the sense that they must wait for the remainder of thenetwork to execute forwards and propagate error backwards before they can beupdated. In this work we break this constraint by decoupling modules byintroducing a model of the future computation of the network graph. Thesemodels predict what the result of the modelled subgraph will produce using onlylocal information. In particular we focus on modelling error gradients: byusing the modelled synthetic gradient in place of true backpropagated errorgradients we decouple subgraphs, and can update them independently andasynchronously i.e. we realise decoupled neural interfaces. We show results forfeed-forward models, where every layer is trained asynchronously, recurrentneural networks (RNNs) where predicting one's future gradient extends the timeover which the RNN can effectively model, and also a hierarchical RNN systemwith ticking at different timescales. Finally, we demonstrate that in additionto predicting gradients, the same framework can be used to predict inputs,resulting in models which are decoupled in both the forward and backwards pass-- amounting to independent networks which co-learn such that they can becomposed into a single functioning corporation."^^schema:Text ;
    schema:author "Alex Graves"^^schema:Person,
        "David Silver"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Max Jaderberg"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Simon Osindero"^^schema:Person,
        "Wojciech Marian Czarnecki"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:dateModified "2017-07-03T10:52:04Z"^^schema:DateTime ;
    schema:datePublished "2016-08-18T17:29:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Decoupled Neural Interfaces using Synthetic Gradients"^^schema:Text ;
    schema:publisher "ICML, 1627-1635"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.05343v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3896090481314997713&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<120> a schema:ScholarlyArticle ;
    schema:abstract "Learning both hierarchical and temporal representation has been among thelong-standing challenges of recurrent neural networks. Multiscale recurrentneural networks have been considered as a promising approach to resolve thisissue, yet there has been a lack of empirical evidence showing that this typeof models can actually capture the temporal dependencies by discovering thelatent hierarchical structure of the sequence. In this paper, we propose anovel multiscale approach, called the hierarchical multiscale recurrent neuralnetworks, which can capture the latent hierarchical structure in the sequenceby encoding the temporal dependencies with different timescales using a novelupdate mechanism. We show some evidence that our proposed multiscalearchitecture can discover underlying hierarchical structure in the sequenceswithout using explicit boundary information. We evaluate our proposed model oncharacter-level language modelling and handwriting sequence modelling."^^schema:Text ;
    schema:author "Junyoung Chung"^^schema:Person,
        "Sungjin Ahn"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "339"^^schema:Integer ;
    schema:dateModified "2017-03-09T05:22:52Z"^^schema:DateTime ;
    schema:datePublished "2016-09-06T19:37:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Hierarchical Multiscale Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.01704v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3631406206229660252&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1200> a schema:ScholarlyArticle ;
    schema:abstract "Pose guided person image generation means to generate a photo-realisticperson image conditioned on an input person image and a desired pose. This taskrequires spatial manipulation of the source image according to the target pose.However, the generative adversarial networks (GANs) widely used for imagegeneration and translation rely on spatially local and translation equivariantoperators, i.e., convolution, pooling and unpooling, which cannot handle largeimage deformation. This paper introduces a novel two-stream appearance transfernetwork (2s-ATN) to address this challenge. It is a multi-stage architectureconsisting of a source stream and a target stream. Each stage features anappearance transfer module and several two-stream feature fusion modules. Theformer finds the dense correspondence between the two-stream feature maps andthen transfers the appearance information from the source stream to the targetstream. The latter exchange local information between the two streams andsupplement the non-local appearance transfer. Both quantitative and qualitativeresults indicate the proposed 2s-ATN can effectively handle large spatialdeformation and occlusion while retaining the appearance details. Itoutperforms prior states of the art on two widely used benchmarks."^^schema:Text ;
    schema:author "Chengkang Shen"^^schema:Person,
        "Peiyan Wang"^^schema:Person,
        "Wei Tang"^^schema:Person ;
    schema:dateModified "2020-11-09T04:21:02Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T04:21:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Two-Stream Appearance Transfer Network for Person Image Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.04181v1"^^schema:URL .

<1201> a schema:ScholarlyArticle ;
    schema:abstract "We introduce GANHopper, an unsupervised image-to-image translation networkthat transforms images gradually between two domains, through multiple hops.Instead of executing translation directly, we steer the translation byrequiring the network to produce in-between images that resemble weightedhybrids between images from the input domains. Our network is trained onunpaired images from the two domains only, without any in-between images. Allhops are produced using a single generator along each direction. In addition tothe standard cycle-consistency and adversarial losses, we introduce a newhybrid discriminator, which is trained to classify the intermediate imagesproduced by the generator as weighted hybrids, with weights based on apredetermined hop count. We also add a smoothness term to constrain themagnitude of each hop, further regularizing the translation. Compared toprevious methods, GANHopper excels at image translations involvingdomain-specific image features and geometric variations while also preservingnon-domain-specific features such as general color schemes."^^schema:Text ;
    schema:author "Daniel Cohen-Or"^^schema:Person,
        "Daniel Ritchie"^^schema:Person,
        "Hao Zhang"^^schema:Person,
        "Johannes Merz"^^schema:Person,
        "Wallace Lira"^^schema:Person ;
    schema:dateModified "2020-07-29T02:28:42Z"^^schema:DateTime ;
    schema:datePublished "2020-02-24T07:41:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.10102v5"^^schema:URL .

<1202> a schema:ScholarlyArticle ;
    schema:abstract "Weakly-supervised object detection (WOD) is a challenging problems incomputer vision. The key problem is to simultaneously infer the exact objectlocations in the training images and train the object detectors, given only thetraining images with weak image-level labels. Intuitively, by simulating theselective attention mechanism of human visual system, saliency detectiontechnique can select attractive objects in scenes and thus is a potential wayto provide useful priors for WOD. However, the way to adopt saliency detectionin WOD is not trivial since the detected saliency region might be possiblyhighly ambiguous in complex cases. To this end, this paper firstcomprehensively analyzes the challenges in applying saliency detection to WOD.Then, we make one of the earliest efforts to bridge saliency detection to WODvia the self-paced curriculum learning, which can guide the learning procedureto gradually achieve faithful knowledge of multi-class objects from easy tohard. The experimental results demonstrate that the proposed approach cansuccessfully bridge saliency detection and WOD tasks and achieve thestate-of-the-art object detection results under the weak supervision."^^schema:Text ;
    schema:author "Deyu Meng"^^schema:Person,
        "Dingwen Zhang"^^schema:Person,
        "Junwei Han"^^schema:Person,
        "Long Zhao"^^schema:Person ;
    schema:dateModified "2017-03-03T18:55:10Z"^^schema:DateTime ;
    schema:datePublished "2017-03-03T18:55:10Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Bridging Saliency Detection to Weakly Supervised Object Detection Based  on Self-paced Curriculum Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1703.01290v1"^^schema:URL .

<1203> a schema:ScholarlyArticle ;
    schema:abstract "The importance weighted autoencoder (IWAE) (Burda et al., 2016) is a popularvariational-inference method which achieves a tighter evidence bound (and hencea lower bias) than standard variational autoencoders by optimising amulti-sample objective, i.e. an objective that is expressible as an integralover $K &gt; 1$ Monte Carlo samples. Unfortunately, IWAE crucially relies on theavailability of reparametrisations and even if these exist, the multi-sampleobjective leads to inference-network gradients which break down as $K$ isincreased (Rainforth et al., 2018). This breakdown can only be circumvented byremoving high-variance score-function terms, either by heuristically ignoringthem (which yields the 'sticking-the-landing' IWAE (IWAE-STL) gradient fromRoeder et al. (2017)) or through an identity from Tucker et al. (2019) (whichyields the 'doubly-reparametrised' IWAE (IWAE-DREG) gradient). In this work, weargue that directly optimising the proposal distribution in importance samplingas in the reweighted wake-sleep (RWS) algorithm from Bornschein &amp; Bengio (2015)is preferable to optimising IWAE-type multi-sample objectives. To formalisethis argument, we introduce an adaptive-importance sampling framework termedadaptive importance sampling for learning (AISLE) which slightly generalisesthe RWS algorithm. We then show that AISLE admits IWAE-STL and IWAE-DREG (i.e.the IWAE-gradients which avoid breakdown) as special cases."^^schema:Text ;
    schema:author "Alexandre H. Thiery"^^schema:Person,
        "Axel Finke"^^schema:Person ;
    schema:dateModified "2019-09-19T09:46:02Z"^^schema:DateTime ;
    schema:datePublished "2019-07-24T14:52:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On importance-weighted autoencoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.10477v2"^^schema:URL .

<1204> a schema:ScholarlyArticle ;
    schema:abstract "With the deployment of online monitoring systems in distribution networks,massive amounts of data collected through them contains rich information on theoperating states of the networks. By leveraging the data, an unsupervisedapproach based on bidirectional generative adversarial networks (BiGANs) isproposed for operational risk assessment in distribution networks in thispaper. The approach includes two stages: (1) adversarial feature learning. Themost representative features are extracted from the online monitoring data anda statistical index $\\mathcal{N}_{\\phi}$ is calculated for the features, duringwhich we make no assumptions or simplifications on the real data. (2)operational risk assessment. The confidence level $1-\\alpha$ for the populationmean of the standardized $\\mathcal{N}_{\\phi}$ is combined with the operationalrisk levels which are divided into emergency, high risk, preventive and normal,and the p value for each data point is calculated and compared with$\\frac{\\alpha}{2}$ to determine the risk levels. The proposed approach iscapable of discovering the latent structure of the real data and providing moreaccurate assessment result. The synthetic data is employed to illustrate theselection of parameters involved in the proposed approach. Case studies on thereal-world online monitoring data validate the effectiveness and advantages ofthe proposed approach in risk assessment."^^schema:Text ;
    schema:author "Robert Qiu"^^schema:Person,
        "Tiebin Mi"^^schema:Person,
        "Xin Shi"^^schema:Person,
        "Xing He"^^schema:Person,
        "Yongli Zhu"^^schema:Person ;
    schema:dateModified "2019-07-21T04:08:47Z"^^schema:DateTime ;
    schema:datePublished "2018-08-27T22:26:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Feature Learning of Online Monitoring Data for Operational  Risk Assessment in Distribution Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.09050v2"^^schema:URL .

<1205> a schema:ScholarlyArticle ;
    schema:abstract "Multi-scale representations deeply learned via convolutional neural networkshave shown tremendous importance for various pixel-level prediction problems.In this paper we present a novel approach that advances the state of the art onpixel-level prediction in a fundamental aspect, i.e. structured multi-scalefeatures learning and fusion. In contrast to previous works directlyconsidering multi-scale feature maps obtained from the inner layers of aprimary CNN architecture, and simply fusing the features with weightedaveraging or concatenation, we propose a probabilistic graph attention networkstructure based on a novel Attention-Gated Conditional Random Fields (AG-CRFs)model for learning and fusing multi-scale representations in a principledmanner. In order to further improve the learning capacity of the networkstructure, we propose to exploit feature dependant conditional kernels withinthe deep probabilistic framework. Extensive experiments are conducted on fourpublicly available datasets (i.e. BSDS500, NYUD-V2, KITTI, and Pascal-Context)and on three challenging pixel-wise prediction problems involving both discreteand continuous labels (i.e. monocular depth estimation, object contourprediction, and semantic segmentation). Quantitative and qualitative resultsdemonstrate the effectiveness of the proposed latent AG-CRF model and theoverall probabilistic graph attention network with feature conditional kernelsfor structured feature learning and pixel-wise prediction."^^schema:Text ;
    schema:author "Dan Xu"^^schema:Person,
        "Elisa Ricci"^^schema:Person,
        "Nicu Sebe"^^schema:Person,
        "Wanli Ouyang"^^schema:Person,
        "Xavier Alameda-Pineda"^^schema:Person,
        "Xiaogang Wang"^^schema:Person ;
    schema:dateModified "2021-01-08T04:14:29Z"^^schema:DateTime ;
    schema:datePublished "2021-01-08T04:14:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Probabilistic Graph Attention Network with Conditional Kernels for  Pixel-Wise Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.02843v1"^^schema:URL .

<1206> a schema:ScholarlyArticle ;
    schema:abstract "Data-driven, knowledge-grounded neural conversation models are capable ofgenerating more informative responses. However, these models have not yetdemonstrated that they can zero-shot adapt to updated, unseen knowledge graphs.This paper proposes a new task about how to apply dynamic knowledge graphs inneural conversation model and presents a novel TV series conversation corpus(DyKgChat) for the task. Our new task and corpus aids in understanding theinfluence of dynamic knowledge graphs on responses generation. Also, we proposea preliminary model that selects an output from two networks at each time step:a sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, inorder to support dynamic knowledge graphs. To benchmark this new task andevaluate the capability of adaptation, we introduce several evaluation metricsand the experiments show that our proposed approach outperforms previousknowledge-grounded conversation models. The proposed corpus and model canmotivate the future research directions."^^schema:Text ;
    schema:author "Hung-yi Lee"^^schema:Person,
        "Yi-Lin Tuan"^^schema:Person,
        "Yun-Nung Chen"^^schema:Person ;
    schema:dateModified "2019-10-01T18:29:08Z"^^schema:DateTime ;
    schema:datePublished "2019-10-01T18:29:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic  Knowledge Graphs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00610v1"^^schema:URL .

<1207> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel domain adaptation framework that uses morphologicsegmentation to translate images from arbitrary input domains (real andsynthetic) into a uniform output domain. Our framework is based on anestablished image-to-image translation pipeline that allows us to firsttransform the input image into a generalized representation that encodesmorphology and semantics - the edge-plus-segmentation map (EPS) - which is thentransformed into an output domain. Images transformed into the output domainare photo-realistic and free of artifacts that are commonly present acrossdifferent real (e.g. lens flare, motion blur, etc.) and synthetic (e.g.unrealistic textures, simplified geometry, etc.) data sets. Our goal is toestablish a preprocessing step that unifies data from multiple sources into acommon representation that facilitates training downstream tasks in computervision. This way, neural networks for existing tasks can be trained on a largervariety of training data, while they are also less affected by overfitting tospecific data sets. We showcase the effectiveness of our approach byqualitatively and quantitatively evaluating our method on four data sets ofsimulated and real data of urban scenes. Additional results can be found on theproject website available at http://jonathank.de/research/eps/ ."^^schema:Text ;
    schema:author "Dominik L. Michels"^^schema:Person,
        "Jonathan Klein"^^schema:Person,
        "Sören Pirk"^^schema:Person ;
    schema:dateModified "2020-06-16T17:06:02Z"^^schema:DateTime ;
    schema:datePublished "2020-06-16T17:06:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.LG, cs.AI"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Domain Adaptation with Morphologic Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.09322v1"^^schema:URL .

<1208> a schema:ScholarlyArticle ;
    schema:abstract "A crucial challenge in image-based modeling of biomedical data is to identifytrends and features that separate normality and pathology. In many cases, themorphology of the imaged object exhibits continuous change as it deviates fromnormality, and thus a generative model can be trained to model thismorphological continuum. Moreover, given side information that correlates tocertain trend in morphological change, a latent variable model can beregularized such that its latent representation reflects this side information.In this work, we use the Wasserstein Auto-encoder to model this pathologycontinuum, and apply the Hilbert-Schmitt Independence Criterion (HSIC) toenforce dependency between certain latent features and the provided sideinformation. We experimentally show that the model can provide disentangled andinterpretable latent representations and also generate a continuum ofmorphological changes that corresponds to change in the side information."^^schema:Text ;
    schema:author "Charles Ding"^^schema:Person,
        "Denny Wu"^^schema:Person,
        "Hirofumi Kobayashi"^^schema:Person,
        "Keisuke Goda Marzyeh Ghassemi"^^schema:Person,
        "Lei Cheng"^^schema:Person ;
    schema:dateModified "2019-01-20T03:40:55Z"^^schema:DateTime ;
    schema:datePublished "2019-01-20T03:40:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modeling the Biological Pathology Continuum with HSIC-regularized  Wasserstein Auto-encoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.06618v1"^^schema:URL .

<1209> a schema:ScholarlyArticle ;
    schema:abstract "This work proposes an unsupervised fusion framework based on deepconvolutional transform learning. The great learning ability of convolutionalfilters for data analysis is well acknowledged. The success of convolutivefeatures owes to convolutional neural network (CNN). However, CNN cannotperform learning tasks in an unsupervised fashion. In a recent work, we showthat such shortcoming can be addressed by adopting a convolutional transformlearning (CTL) approach, where convolutional filters are learnt in anunsupervised fashion. The present paper aims at (i) proposing a deep version ofCTL; (ii) proposing an unsupervised fusion formulation taking advantage of theproposed deep CTL representation; (iii) developing a mathematically soundedoptimization strategy for performing the learning task. We apply the proposedtechnique, named DeConFuse, on the problem of stock forecasting and trading.Comparison with state-of-the-art methods (based on CNN and long short-termmemory network) shows the superiority of our method for performing a reliablefeature extraction."^^schema:Text ;
    schema:author "Angshul Majumdar"^^schema:Person,
        "Emilie Chouzenoux"^^schema:Person,
        "Giovanni Chierchia"^^schema:Person,
        "Jyoti Maggu"^^schema:Person,
        "Pooja Gupta"^^schema:Person ;
    schema:dateModified "2020-11-09T11:04:09Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T11:04:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "DeConFuse : A Deep Convolutional Transform based Unsupervised Fusion  Framework"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.04337v1"^^schema:URL .

<121> a schema:ScholarlyArticle ;
    schema:abstract "We introduce FeUdal Networks (FuNs): a novel architecture for hierarchicalreinforcement learning. Our approach is inspired by the feudal reinforcementlearning proposal of Dayan and Hinton, and gains power and efficacy bydecoupling end-to-end learning across multiple levels -- allowing it to utilisedifferent resolutions of time. Our framework employs a Manager module and aWorker module. The Manager operates at a lower temporal resolution and setsabstract goals which are conveyed to and enacted by the Worker. The Workergenerates primitive actions at every tick of the environment. The decoupledstructure of FuN conveys several benefits -- in addition to facilitating verylong timescale credit assignment it also encourages the emergence ofsub-policies associated with different goals set by the Manager. Theseproperties allow FuN to dramatically outperform a strong baseline agent ontasks that involve long-term credit assignment or memorisation. We demonstratethe performance of our proposed system on a range of tasks from the ATARI suiteand also from a 3D DeepMind Lab environment."^^schema:Text ;
    schema:author "Alexander Sasha Vezhnevets"^^schema:Person,
        "David Silver"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Max Jaderberg"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Simon Osindero"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:commentCount "329"^^schema:Integer ;
    schema:dateModified "2017-03-06T18:17:18Z"^^schema:DateTime ;
    schema:datePublished "2017-03-03T14:05:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "FeUdal Networks for Hierarchical Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 3540-3549"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01161v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2074247135017163310&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1210> a schema:ScholarlyArticle ;
    schema:abstract "Automatic Differentiation Variational Inference (ADVI) is a useful tool forefficiently learning probabilistic models in machine learning. Generallyapproximate posteriors learned by ADVI are forced to be unimodal in order tofacilitate use of the reparameterization trick. In this paper, we show howstratified sampling may be used to enable mixture distributions as theapproximate posterior, and derive a new lower bound on the evidence analogousto the importance weighted autoencoder (IWAE). We show that this \"SIWAE\" is atighter bound than both IWAE and the traditional ELBO, both of which arespecial instances of this bound. We verify empirically that the traditionalELBO objective disfavors the presence of multimodal posterior distributions andmay therefore not be able to fully capture structure in the latent space. Ourexperiments show that using the SIWAE objective allows the encoder to learnmore complex distributions which regularly contain multimodality, resulting inhigher accuracy and better calibration in the presence of incomplete, limited,or corrupted data."^^schema:Text ;
    schema:author "Andrew Gallagher"^^schema:Person,
        "Cusuh Ham"^^schema:Person,
        "Joshua V. Dillon"^^schema:Person,
        "Sharad M. Vikram"^^schema:Person,
        "Warren R. Morningstar"^^schema:Person ;
    schema:dateModified "2020-06-24T17:35:38Z"^^schema:DateTime ;
    schema:datePublished "2020-03-03T18:12:42Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Automatic Differentiation Variational Inference with Mixtures"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.01687v4"^^schema:URL .

<1211> a schema:ScholarlyArticle ;
    schema:abstract "The principle of equivariance to symmetry transformations enables atheoretically grounded approach to neural network architecture design.Equivariant networks have shown excellent performance and data efficiency onvision and medical imaging problems that exhibit symmetries. Here we show howthis principle can be extended beyond global symmetries to local gaugetransformations. This enables the development of a very general class ofconvolutional neural networks on manifolds that depend only on the intrinsicgeometry, and which includes many popular methods from equivariant andgeometric deep learning. We implement gauge equivariant CNNs for signalsdefined on the surface of the icosahedron, which provides a reasonableapproximation of the sphere. By choosing to work with this very regularmanifold, we are able to implement the gauge equivariant convolution using asingle conv2d call, making it a highly scalable and practical alternative toSpherical CNNs. Using this method, we demonstrate substantial improvements overprevious methods on the task of segmenting omnidirectional images and globalclimate patterns."^^schema:Text ;
    schema:author "Berkay Kicanaoglu"^^schema:Person,
        "Maurice Weiler"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Taco S. Cohen"^^schema:Person ;
    schema:dateModified "2019-05-13T23:03:52Z"^^schema:DateTime ;
    schema:datePublished "2019-02-11T17:01:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gauge Equivariant Convolutional Networks and the Icosahedral CNN"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.04615v3"^^schema:URL .

<1212> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks are increasingly employed in safety-critical domains. Thishas prompted interest in verifying or certifying logically encoded propertiesof neural networks. Prior work has largely focused on checking existentialproperties, wherein the goal is to check whether there exists any input thatviolates a given property of interest. However, neural network training is astochastic process, and many questions arising in their analysis requireprobabilistic and quantitative reasoning, i.e., estimating how many inputssatisfy a given property. To this end, our paper proposes a novel andprincipled framework to quantitative verification of logical propertiesspecified over neural networks. Our framework is the first to provide PAC-stylesoundness guarantees, in that its quantitative estimates are within acontrollable and bounded error from the true count. We instantiate ouralgorithmic framework by building a prototype tool called NPAQ that enableschecking rich properties over binarized neural networks. We show how emergingsecurity analyses can utilize our framework in 3 concrete point applications:quantifying robustness to adversarial inputs, efficacy of trojan attacks, andfairness/bias of given neural networks."^^schema:Text ;
    schema:author "Kuldeep S. Meel"^^schema:Person,
        "Prateek Saxena"^^schema:Person,
        "Shiqi Shen"^^schema:Person,
        "Shweta Shinde"^^schema:Person,
        "Teodora Baluta"^^schema:Person ;
    schema:dateModified "2019-06-25T09:08:03Z"^^schema:DateTime ;
    schema:datePublished "2019-06-25T09:08:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.LO"^^schema:Text ;
    schema:headline "Quantitative Verification of Neural Networks And its Security  Applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.10395v1"^^schema:URL .

<1213> a schema:ScholarlyArticle ;
    schema:abstract "With the increase of connectivity in power grid, a cascading failure may betriggered by the failure of a transmission line, which can lead to substantialeconomic losses and serious negative social impacts. Therefore, it is veryimportant to identify the critical lines under various types of attacks thatmay initiate a cascading failure and deploy defense resources to protect them.Since coordinated multistage line attacks can lead to larger negative impactscompared with a single-stage attack or a multistage attack withoutcoordination, this paper intends to identify the critical lines undercoordinated multistage attacks that may initiate a cascading failure and deploylimited defense resources optimally. To this end, we first formulate a totalgeneration loss maximization problem with the consideration of multipleattackers and multiple stages. Due to the large size of solution space, it isvery challenging to solve the formulated problem. To overcome the challenge, wereformulate the problem as a Markov game and design its components, e.g.,state, action, and reward. Next, we propose a scalable algorithm to solve theMarkov game based on multi-agent deep reinforcement learning and prioritizedexperience replay, which can determine the optimal attacking line sequences.Then, we design a defense strategy to decide the optimal defense line set.Extensive simulation results show the effectiveness of the proposed algorithmand the designed defense strategy."^^schema:Text ;
    schema:author "Chao Shen"^^schema:Person,
        "Dong Yue"^^schema:Person,
        "Liang Yu"^^schema:Person,
        "Meng Zhang"^^schema:Person,
        "Shuqi Qin"^^schema:Person,
        "Xiaohong Guan"^^schema:Person,
        "Zhen Gao"^^schema:Person ;
    schema:dateModified "2020-11-30T03:35:03Z"^^schema:DateTime ;
    schema:datePublished "2020-11-30T03:35:03Z"^^schema:DateTime ;
    schema:genre "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Smart Grid Protection Against  Coordinated Multistage Transmission Line Attacks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.14526v1"^^schema:URL .

<1214> a schema:ScholarlyArticle ;
    schema:abstract "Spatio-temporal (ST) data, which represent multiple time series datacorresponding to different spatial locations, are ubiquitous in real-worlddynamic systems, such as air quality readings. Forecasting over ST data is ofgreat importance but challenging as it is affected by many complex factors,including spatial characteristics, temporal characteristics and the intrinsiccausality between them. In this paper, we propose a general framework(HyperST-Net) based on hypernetworks for deep ST models. More specifically, itconsists of three major modules: a spatial module, a temporal module and adeduction module. Among them, the deduction module derives the parameterweights of the temporal module from the spatial characteristics, which areextracted by the spatial module. Then, we design a general form of HyperSTlayer as well as different forms for several basic layers in neural networks,including the dense layer (HyperST-Dense) and the convolutional layer(HyperST-Conv). Experiments on three types of real-world tasks demonstrate thatthe predictive models integrated with our framework achieve significantimprovements, and outperform the state-of-the-art baselines as well."^^schema:Text ;
    schema:author "Junbo Zhang"^^schema:Person,
        "Xiuwen Yi"^^schema:Person,
        "Yong Yu"^^schema:Person,
        "Yu Zheng"^^schema:Person,
        "Yuxuan Liang"^^schema:Person,
        "Zheyi Pan"^^schema:Person ;
    schema:dateModified "2018-09-28T07:29:21Z"^^schema:DateTime ;
    schema:datePublished "2018-09-28T07:29:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10889v1"^^schema:URL .

<1215> a schema:ScholarlyArticle ;
    schema:abstract "Human communication is multimodal in nature; it is through multiplemodalities, i.e., language, voice, and facial expressions, that opinions andemotions are expressed. Data in this domain exhibits complex multi-relationaland temporal interactions. Learning from this data is a fundamentallychallenging research problem. In this paper, we propose Multimodal TemporalGraph Attention Networks (MTGAT). MTGAT is an interpretable graph-based neuralmodel that provides a suitable framework for analyzing this type of multimodalsequential data. We first introduce a procedure to convert unaligned multimodalsequence data into a graph with heterogeneous nodes and edges that captures therich interactions between different modalities through time. Then, a novelgraph operation, called Multimodal Temporal Graph Attention, along with adynamic pruning and read-out technique is designed to efficiently process thismultimodal temporal graph. By learning to focus only on the importantinteractions within the graph, our MTGAT is able to achieve state-of-the-artperformance on multimodal sentiment analysis and emotion recognition benchmarksincluding IEMOCAP and CMU-MOSI, while utilizing significantly fewercomputations."^^schema:Text ;
    schema:author "Amir Zadeh"^^schema:Person,
        "Azaan Rehman"^^schema:Person,
        "Jianing Yang"^^schema:Person,
        "Louis-Philippe Morency"^^schema:Person,
        "Ruitao Yi"^^schema:Person,
        "Soujanya Poria"^^schema:Person,
        "Yongxin Wang"^^schema:Person,
        "Yuying Zhu"^^schema:Person ;
    schema:dateModified "2020-10-22T18:58:50Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T18:58:50Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human  Multimodal Language Sequences"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11985v1"^^schema:URL .

<1216> a schema:ScholarlyArticle ;
    schema:abstract "Electronic Health Records (EHRs) are commonly used to investigaterelationships between patient health information and outcomes. Deep learningmethods are emerging as powerful tools to learn such relationships, given thecharacteristic high dimension and large sample size of EHR datasets. ThePhysionet 2012 Challenge involves an EHR dataset pertaining to 12,000 ICUpatients, where researchers investigated the relationships between clinicalmeasurements, and in-hospital mortality. However, the prevalence and complexityof missing data in the Physionet data present significant challenges for theapplication of deep learning methods, such as Variational Autoencoders (VAEs).Although a rich literature exists regarding the treatment of missing data intraditional statistical models, it is unclear how this extends to deep learningarchitectures. To address these issues, we propose a novel extension of VAEscalled Importance-Weighted Autoencoders (IWAEs) to flexibly handle Missing NotAt Random (MNAR) patterns in the Physionet data. Our proposed method models themissingness mechanism using an embedded neural network, eliminating the need tospecify the exact form of the missingness mechanism a priori. We show that theuse of our method leads to more realistic imputed values relative to thestate-of-the-art, as well as significant differences in fitted downstreammodels for mortality."^^schema:Text ;
    schema:author "David K. Lim"^^schema:Person,
        "Joseph G. Ibrahim"^^schema:Person,
        "Junier B. Oliva"^^schema:Person,
        "Naim U. Rashid"^^schema:Person ;
    schema:dateModified "2021-02-05T20:05:41Z"^^schema:DateTime ;
    schema:datePublished "2021-01-18T22:53:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.AP"^^schema:Text ;
    schema:headline "Handling Non-ignorably Missing Features in Electronic Health Records  Data Using Importance-Weighted Autoencoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.07357v2"^^schema:URL .

<1217> a schema:ScholarlyArticle ;
    schema:abstract "Recently, self-normalizing neural networks (SNNs) have been proposed with theintention to avoid batch or weight normalization. The key step in SNNs is toproperly scale the exponential linear unit (referred to as SELU) to inherentlyincorporate normalization based on central limit theory. SELU is amonotonically increasing function, where it has an approximately constantnegative output for large negative input. In this work, we propose a newactivation function to break the monotonicity property of SELU while stillpreserving the self-normalizing property. Differently from SELU, the newfunction introduces a bump-shaped function in the region of negative input byregularizing a linear function with a scaled exponential function, which isreferred to as a scaled exponentially-regularized linear unit (SERLU). Thebump-shaped function has approximately zero response to large negative inputwhile being able to push the output of SERLU towards zero mean statistically.To effectively combat over-fitting, we develop a so-called shift-dropout forSERLU, which includes standard dropout as a special case. Experimental resultson MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provideconsistently promising results in comparison to other 5 activation functionsincluding ELU, SELU, Swish, Leakly ReLU and ReLU."^^schema:Text ;
    schema:author "G. Zhang"^^schema:Person,
        "H. Li"^^schema:Person ;
    schema:dateModified "2018-07-27T09:16:41Z"^^schema:DateTime ;
    schema:datePublished "2018-07-26T13:33:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.10117v2"^^schema:URL .

<1218> a schema:ScholarlyArticle ;
    schema:abstract "Prioritized Experience Replay (PER) is a deep reinforcement learningtechnique in which agents learn from transitions sampled with non-uniformprobability proportionate to their temporal-difference error. We show that anyloss function evaluated with non-uniformly sampled data can be transformed intoanother uniformly sampled loss function with the same expected gradient.Surprisingly, we find in some environments PER can be replaced entirely by thisnew loss function without impact to empirical performance. Furthermore, thisrelationship suggests a new branch of improvements to PER by correcting itsuniformly sampled loss function equivalent. We demonstrate the effectiveness ofour proposed modifications to PER and the equivalent loss function in severalMuJoCo and Atari environments."^^schema:Text ;
    schema:author "David Meger"^^schema:Person,
        "Doina Precup"^^schema:Person,
        "Scott Fujimoto"^^schema:Person ;
    schema:dateModified "2020-10-22T16:36:44Z"^^schema:DateTime ;
    schema:datePublished "2020-07-12T17:45:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "An Equivalence between Loss Functions and Non-Uniform Sampling in  Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.06049v2"^^schema:URL .

<1219> a schema:ScholarlyArticle ;
    schema:abstract "Multi-objective optimization problems are prevalent in machine learning.These problems have a set of optimal solutions, called the Pareto front, whereeach point on the front represents a different trade-off between possiblyconflicting objectives. Recent optimization algorithms can target a specificdesired ray in loss space, but still face two grave limitations: (i) A separatemodel has to be trained for each point on the front; and (ii) The exacttrade-off must be known prior to the optimization process. Here, we tackle theproblem of learning the entire Pareto front, with the capability of selecting adesired operating point on the front after training. We call this new setupPareto-Front Learning (PFL).  We describe an approach to PFL implemented using HyperNetworks, which we termPareto HyperNetworks (PHNs). PHN learns the entire Pareto front simultaneouslyusing a single hypernetwork, which receives as input a desired preferencevector and returns a Pareto-optimal model whose loss vector is in the desiredray. The unified model is runtime efficient compared to training multiplemodels, and generalizes to new operating points not used during training. Weevaluate our method on a wide set of problems, from multi-task regression andclassification to fairness. PHNs learns the entire Pareto front in roughly thesame time as learning a single point on the front, and also reaches a bettersolution set. PFL opens the door to new applications where models are selectedbased on preferences that are only available at run time."^^schema:Text ;
    schema:author "Aviv Navon"^^schema:Person,
        "Aviv Shamsian"^^schema:Person,
        "Ethan Fetaya"^^schema:Person,
        "Gal Chechik"^^schema:Person ;
    schema:dateModified "2020-10-08T16:39:20Z"^^schema:DateTime ;
    schema:datePublished "2020-10-08T16:39:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Learning the Pareto Front with Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.04104v1"^^schema:URL .

<122> a schema:ScholarlyArticle ;
    schema:abstract "We propose a general purpose variational inference algorithm that forms anatural counterpart of gradient descent for optimization. Our methoditeratively transports a set of particles to match the target distribution, byapplying a form of functional gradient descent that minimizes the KLdivergence. Empirical studies are performed on various real world models anddatasets, on which our method is competitive with existing state-of-the-artmethods. The derivation of our method is based on a new theoretical result thatconnects the derivative of KL divergence under smooth transforms with Stein'sidentity and a recently proposed kernelized Stein discrepancy, which is ofindependent interest."^^schema:Text ;
    schema:author "Dilin Wang"^^schema:Person,
        "Qiang Liu"^^schema:Person ;
    schema:commentCount "296"^^schema:Integer ;
    schema:dateModified "2019-09-09T17:31:39Z"^^schema:DateTime ;
    schema:datePublished "2016-08-16T03:24:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stein Variational Gradient Descent: A General Purpose Bayesian Inference  Algorithm"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.04471v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14137569249878560716&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1220> a schema:ScholarlyArticle ;
    schema:abstract "Recent research has shown remarkable success in revealing \"steering\"directions in the latent spaces of pre-trained GANs. These directionscorrespond to semantically meaningful image transformations e.g., shift, zoom,color manipulations), and have similar interpretable effects across allcategories that the GAN can generate. Some methods focus on user-specifiedtransformations, while others discover transformations in an unsupervisedmanner. However, all existing techniques rely on an optimization procedure toexpose those directions, and offer no control over the degree of allowedinteraction between different transformations. In this paper, we show that\"steering\" trajectories can be computed in closed form directly from thegenerator's weights without any form of training or optimization. This appliesto user-prescribed geometric transformations, as well as to unsuperviseddiscovery of more complex effects. Our approach allows determining both linearand nonlinear trajectories, and has many advantages over previous methods. Inparticular, we can control whether one transformation is allowed to come on theexpense of another (e.g. zoom-in with or without allowing translation to keepthe object centered). Moreover, we can determine the natural end-point of thetrajectory, which corresponds to the largest extent to which a transformationcan be applied without incurring degradation. Finally, we show how transferringattributes between images can be achieved without optimization, even acrossdifferent categories."^^schema:Text ;
    schema:author "Nurit Spingarn-Eliezer"^^schema:Person,
        "Ron Banner"^^schema:Person,
        "Tomer Michaeli"^^schema:Person ;
    schema:dateModified "2021-01-24T16:50:39Z"^^schema:DateTime ;
    schema:datePublished "2020-12-09T21:34:34Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "GAN \"Steerability\" without optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.05328v2"^^schema:URL .

<1221> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in neural sequence-to-sequence models have led to promisingresults for several language generation-based tasks, including dialogueresponse generation, summarization, and machine translation. However, thesemodels are known to have several problems, especially in the context ofchit-chat based dialogue systems: they tend to generate short and dullresponses that are often too generic. Furthermore, these models do not groundconversational responses on knowledge and facts, resulting in turns that arenot accurate, informative and engaging for the users. In this paper, we proposeand experiment with a series of response generation models that aim to serve inthe general scenario where in addition to the dialogue context, relevantunstructured external knowledge in the form of text is also assumed to beavailable for models to harness. Our proposed approach extendspointer-generator networks (See et al., 2017) by allowing the decoder tohierarchically attend and copy from external knowledge in addition to thedialogue context. We empirically show the effectiveness of the proposed modelcompared to several baselines including (Ghazvininejad et al., 2018; Zhang etal., 2018) through both automatic evaluation metrics and human evaluation onCONVAI2 dataset."^^schema:Text ;
    schema:author "Abhinav Rastogi"^^schema:Person,
        "Dilek Hakkani-Tur"^^schema:Person,
        "Guan-Lin Chao"^^schema:Person,
        "Semih Yavuz"^^schema:Person ;
    schema:dateModified "2019-08-28T14:03:44Z"^^schema:DateTime ;
    schema:datePublished "2019-08-28T14:03:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "DeepCopy: Grounded Response Generation with Hierarchical Pointer  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.10731v1"^^schema:URL .

<1222> a schema:ScholarlyArticle ;
    schema:abstract "Text summarization is an NLP task which aims to convert a textual documentinto a shorter one while keeping as much meaning as possible. This pedagogicalarticle reviews a number of recent Deep Learning architectures that have helpedto advance research in this field. We will discuss in particular applicationsof pointer networks, hierarchical Transformers and Reinforcement Learning. Weassume basic knowledge of Seq2Seq architecture and Transformer networks withinNLP."^^schema:Text ;
    schema:author "Pirmin Lemberger"^^schema:Person ;
    schema:dateModified "2020-05-25T09:12:37Z"^^schema:DateTime ;
    schema:datePublished "2020-05-25T09:12:37Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Learning Models for Automatic Summarization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.11988v1"^^schema:URL .

<1223> a schema:ScholarlyArticle ;
    schema:abstract "Archetypes are typical population representatives in an extremal sense, wheretypicality is understood as the most extreme manifestation of a trait orfeature. In linear feature space, archetypes approximate the data convex hullallowing all data points to be expressed as convex mixtures of archetypes.However, it might not always be possible to identify meaningful archetypes in agiven feature space. Learning an appropriate feature space and identifyingsuitable archetypes simultaneously addresses this problem. This paperintroduces a generative formulation of the linear archetype model,parameterized by neural networks. By introducing the distance-dependentarchetype loss, the linear archetype model can be integrated into the latentspace of a variational autoencoder, and an optimal representation with respectto the unknown archetypes can be learned end-to-end. The reformulation oflinear Archetypal Analysis as deep variational information bottleneck, allowsthe incorporation of arbitrarily complex side information during training.Furthermore, an alternative prior, based on a modified Dirichlet distribution,is proposed. The real-world applicability of the proposed method isdemonstrated by exploring archetypes of female facial expressions while usingmulti-rater based emotion scores of these expressions as side information. Asecond application illustrates the exploration of the chemical space of smallorganic molecules. In this experiment, it is demonstrated that exchanging theside information but keeping the same set of molecules, e. g. using as sideinformation the heat capacity of each molecule instead of the band gap energy,will result in the identification of different archetypes. As an application,these learned representations of chemical space might reveal distinct startingpoints for de novo molecular design."^^schema:Text ;
    schema:author "Fabricio Arend Torres"^^schema:Person,
        "Mario Wieser"^^schema:Person,
        "Maxim Samarin"^^schema:Person,
        "Sebastian Mathias Keller"^^schema:Person,
        "Volker Roth"^^schema:Person ;
    schema:dateModified "2020-02-03T15:13:49Z"^^schema:DateTime ;
    schema:datePublished "2020-02-03T15:13:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Extremal Representations with Deep Archetypal Analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.00815v1"^^schema:URL .

<1224> a schema:ScholarlyArticle ;
    schema:abstract "Survival models are a popular tool for the analysis of time to event datawith applications in medicine, engineering, economics and many more. Advanceslike the Cox proportional hazard model have enabled researchers to betterdescribe hazard rates for the occurrence of single fatal events, but arelimited by modeling assumptions, like proportionality of hazard rates andlinear effects. Moreover, common phenomena are often better described throughmultiple states, for example, the progress of a disease might be modeled ashealthy, sick and dead instead of healthy and dead, where the competing natureof death and disease has to be taken into account. Also, individualcharacteristics can vary significantly between observational units, likepatients, resulting in idiosyncratic hazard rates and different diseasetrajectories. These considerations require flexible modeling assumptions.Current standard models, however, are often ill-suited for such an analysis. Toovercome these issues, we propose the use of neural ordinary differentialequations as a flexible and general method for estimating multi-state survivalmodels by directly solving the Kolmogorov forward equations. To quantify theuncertainty in the resulting individual cause-specific hazard rates, we furtherintroduce a variational latent variable model. We show that our model exhibitsstate-of-the-art performance on popular survival data sets and demonstrate itsefficacy in a multi-state setting."^^schema:Text ;
    schema:author "Alexander Gusev"^^schema:Person,
        "Sebastian M Schmon"^^schema:Person,
        "Stefan Groha"^^schema:Person ;
    schema:dateModified "2020-06-08T19:24:54Z"^^schema:DateTime ;
    schema:datePublished "2020-06-08T19:24:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural ODEs for Multi-State Survival Analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04893v1"^^schema:URL .

<1225> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) do not have a predictable recognitionbehavior with respect to the input resolution change. This prevents thefeasibility of deployment on different input image resolutions for a specificmodel. To achieve efficient and flexible image classification at runtime, weemploy meta learners to generate convolutional weights of main networks forvarious input scales and maintain privatized Batch Normalization layers perscale. For improved training performance, we further utilize knowledgedistillation on the fly over model predictions based on different inputresolutions. The learned meta network could dynamically parameterize mainnetworks to act on input images of arbitrary size with consistently betteraccuracy compared to individually trained models. Extensive experiments on theImageNet demonstrate that our method achieves an improved accuracy-efficiencytrade-off during the adaptive inference process. By switching executable inputresolutions, our method could satisfy the requirement of fast adaption indifferent resource-constrained environments. Code and models are available athttps://github.com/d-li14/SAN."^^schema:Text ;
    schema:author "Anbang Yao"^^schema:Person,
        "Duo Li"^^schema:Person,
        "Qifeng Chen"^^schema:Person ;
    schema:dateModified "2020-07-13T04:27:25Z"^^schema:DateTime ;
    schema:datePublished "2020-07-13T04:27:25Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Learn Parameterized Classification Networks for Scalable  Input Images"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.06181v1"^^schema:URL .

<1226> a schema:ScholarlyArticle ;
    schema:abstract "The overreliance on large parallel corpora significantly limits theapplicability of machine translation systems to the majority of language pairs.Back-translation has been dominantly used in previous approaches forunsupervised neural machine translation, where pseudo sentence pairs aregenerated to train the models with a reconstruction loss. However, the pseudosentences are usually of low quality as translation errors accumulate duringtraining. To avoid this fundamental issue, we propose an alternative but moreeffective approach, extract-edit, to extract and then edit real sentences fromthe target monolingual corpora. Furthermore, we introduce a comparativetranslation loss to evaluate the translated target sentences and thus train theunsupervised translation systems. Experiments show that the proposed approachconsistently outperforms the previous state-of-the-art unsupervised machinetranslation systems across two benchmarks (English-French and English-German)and two low-resource language pairs (English-Romanian and English-Russian) bymore than 2 (up to 3.63) BLEU points."^^schema:Text ;
    schema:author "Jiawei Wu"^^schema:Person,
        "William Yang Wang"^^schema:Person,
        "Xin Wang"^^schema:Person ;
    schema:dateModified "2019-04-04T03:22:40Z"^^schema:DateTime ;
    schema:datePublished "2019-04-04T03:22:40Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Extract and Edit: An Alternative to Back-Translation for Unsupervised  Neural Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.02331v1"^^schema:URL .

<1227> a schema:ScholarlyArticle ;
    schema:abstract "A key obstacle in automated analytics and meta-learning is the inability torecognize when different datasets contain measurements of the same variable.Because provided attribute labels are often uninformative in practice, thistask may be more robustly addressed by leveraging the data values themselvesrather than just relying on their arbitrarily selected variable names. Here, wepresent a computationally efficient method to identify high-confidence variablematches between a given set of data values and a large repository of previouslyencountered datasets. Our approach enjoys numerous advantages overdistributional similarity based techniques because we leverage learned vectorembeddings of datasets which adaptively account for natural forms of datavariation encountered in practice. Based on the neural architecture of deepsets, our embeddings can be computed for both numeric and string data. Indataset search and schema matching tasks, our methods outperform standardstatistical techniques and we find that the learned embeddings generalize wellto new data sources."^^schema:Text ;
    schema:author "Alex Smola"^^schema:Person,
        "Jonas Mueller"^^schema:Person ;
    schema:dateModified "2019-09-11T04:10:48Z"^^schema:DateTime ;
    schema:datePublished "2019-09-11T04:10:48Z"^^schema:DateTime ;
    schema:genre "cs.DB"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Recognizing Variables from their Data via Deep Embeddings of  Distributions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.04844v1"^^schema:URL .

<1228> a schema:ScholarlyArticle ;
    schema:abstract "Learning to insert an object instance into an image in a semanticallycoherent manner is a challenging and interesting problem. Solving it requires(a) determining a location to place an object in the scene and (b) determiningits appearance at the location. Such an object insertion model can potentiallyfacilitate numerous image editing and scene parsing applications. In thispaper, we propose an end-to-end trainable neural network for the task ofinserting an object instance mask of a specified class into the semantic labelmap of an image. Our network consists of two generative modules where onedetermines where the inserted object mask should be (i.e., location and scale)and the other determines what the object mask shape (and pose) should looklike. The two modules are connected together via a spatial transformationnetwork and jointly trained. We devise a learning procedure that leverage bothsupervised and unsupervised data and show our model can insert an object atdiverse locations with various appearances. We conduct extensive experimentalvalidations with comparisons to strong baselines to verify the effectiveness ofthe proposed network."^^schema:Text ;
    schema:author "Donghoon Lee"^^schema:Person,
        "Jan Kautz"^^schema:Person,
        "Jinwei Gu"^^schema:Person,
        "Ming-Hsuan Yang"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Sifei Liu"^^schema:Person ;
    schema:dateModified "2018-12-07T16:46:05Z"^^schema:DateTime ;
    schema:datePublished "2018-12-06T05:04:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Context-Aware Synthesis and Placement of Object Instances"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.02350v2"^^schema:URL .

<1229> a schema:ScholarlyArticle ;
    schema:abstract "Gaussian processes offer an attractive framework for predictive modeling fromlongitudinal data, i.e., irregularly sampled, sparse observations from a set ofindividuals over time. However, such methods have two key shortcomings: (i)They rely on ad hoc heuristics or expensive trial and error to choose theeffective kernels, and (ii) They fail to handle multilevel correlationstructure in the data. We introduce Longitudinal deep kernel Gaussian processregression (L-DKGPR), which to the best of our knowledge, is the only method toovercome these limitations by fully automating the discovery of complexmultilevel correlation structure from longitudinal data. Specifically, L-DKGPReliminates the need for ad hoc heuristics or trial and error using a noveladaptation of deep kernel learning that combines the expressive power of deepneural networks with the flexibility of non-parametric kernel methods. L-DKGPReffectively learns the multilevel correlation with a novel addictive kernelthat simultaneously accommodates both time-varying and the time-invarianteffects. We derive an efficient algorithm to train L-DKGPR using latent spaceinducing points and variational inference. Results of extensive experiments onseveral benchmark data sets demonstrate that L-DKGPR significantly outperformsthe state-of-the-art longitudinal data analysis (LDA) methods."^^schema:Text ;
    schema:author "Dongkuan Xu"^^schema:Person,
        "Junjie Liang"^^schema:Person,
        "Vasant Honavar"^^schema:Person,
        "Yanting Wu"^^schema:Person ;
    schema:dateModified "2020-12-07T20:44:53Z"^^schema:DateTime ;
    schema:datePublished "2020-05-24T15:10:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Longitudinal Deep Kernel Gaussian Process Regression"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.11770v4"^^schema:URL .

<123> a schema:ScholarlyArticle ;
    schema:abstract "We propose a method to learn deep ReLU-based classifiers that are provablyrobust against norm-bounded adversarial perturbations on the training data. Forpreviously unseen examples, the approach is guaranteed to detect alladversarial examples, though it may flag some non-adversarial examples as well.The basic idea is to consider a convex outer approximation of the set ofactivations reachable through a norm-bounded perturbation, and we develop arobust optimization procedure that minimizes the worst case loss over thisouter region (via a linear program). Crucially, we show that the dual problemto this linear program can be represented itself as a deep network similar tothe backpropagation network, leading to very efficient optimization approachesthat produce guaranteed bounds on the robust loss. The end result is that byexecuting a few more forward and backward passes through a slightly modifiedversion of the original network (though possibly with much larger batch sizes),we can learn a classifier that is provably robust to any norm-boundedadversarial attack. We illustrate the approach on a number of tasks to trainclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce aconvolutional classifier that provably has less than 5.8% test error for anyadversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$),and code for all experiments in the paper is available athttps://github.com/locuslab/convex_adversarial."^^schema:Text ;
    schema:author "Eric Wong"^^schema:Person,
        "J. Zico Kolter"^^schema:Person ;
    schema:commentCount "348"^^schema:Integer ;
    schema:dateModified "2018-06-08T19:04:49Z"^^schema:DateTime ;
    schema:datePublished "2017-11-02T17:59:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Provable defenses against adversarial examples via the convex outer  adversarial polytope"^^schema:Text ;
    schema:publisher "ICML, 5283-5292"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00851v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8192568202377907397&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1230> a schema:ScholarlyArticle ;
    schema:abstract "Numerical reasoning over texts, such as addition, subtraction, sorting andcounting, is a challenging machine reading comprehension task, since itrequires both natural language understanding and arithmetic computation. Toaddress this challenge, we propose a heterogeneous graph representation for thecontext of the passage and question needed for such reasoning, and design aquestion directed graph attention network to drive multi-step numericalreasoning over this context graph."^^schema:Text ;
    schema:author "Kunlong Chen"^^schema:Person,
        "Le Song"^^schema:Person,
        "Taifeng Wang"^^schema:Person,
        "Wei Chu"^^schema:Person,
        "Weidi Xu"^^schema:Person,
        "Xingyi Cheng"^^schema:Person,
        "Yuan Qi"^^schema:Person,
        "Yuyu Zhang"^^schema:Person,
        "Zou Xiaochuan"^^schema:Person ;
    schema:dateModified "2020-09-16T03:37:54Z"^^schema:DateTime ;
    schema:datePublished "2020-09-16T03:37:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Question Directed Graph Attention Network for Numerical Reasoning over  Text"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.07448v1"^^schema:URL .

<1231> a schema:ScholarlyArticle ;
    schema:abstract "In a dialog, there can be multiple valid next utterances at any point. Thepresent end-to-end neural methods for dialog do not take this into account.They learn with the assumption that at any time there is only one correct nextutterance. In this work, we focus on this problem in the goal-oriented dialogsetting where there are different paths to reach a goal. We propose a newmethod, that uses a combination of supervised learning and reinforcementlearning approaches to address this issue. We also propose a new and moreeffective testbed, permuted-bAbI dialog tasks, by introducing multiple validnext utterances to the original-bAbI dialog tasks, which allows evaluation ofgoal-oriented dialog systems in a more realistic setting. We show that there isa significant drop in performance of existing end-to-end neural methods from81.5% per-dialog accuracy on original-bAbI dialog tasks to 30.3% onpermuted-bAbI dialog tasks. We also show that our proposed method improves theperformance and achieves 47.3% per-dialog accuracy on permuted-bAbI dialogtasks."^^schema:Text ;
    schema:author "Janarthanan Rajendran"^^schema:Person,
        "Jatin Ganhotra"^^schema:Person,
        "Lazaros Polymenakos"^^schema:Person,
        "Satinder Singh"^^schema:Person ;
    schema:dateModified "2018-08-24T19:24:58Z"^^schema:DateTime ;
    schema:datePublished "2018-08-24T19:24:58Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Learning End-to-End Goal-Oriented Dialog with Multiple Answers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.09996v1"^^schema:URL .

<1232> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, We Apply Reinforcement learning (RL) techniques to train arealistic biomechanical model to work with different people and on differentwalking environments. We benchmarking 3 RL algorithms: Deep DeterministicPolicy Gradient (DDPG), Trust Region Policy Optimization (TRPO) and ProximalPolicy Optimization (PPO) in OpenSim environment, Also we apply imitationlearning to a prosthetics domain to reduce the training time needed to designcustomized prosthetics. We use DDPG algorithm to train an original expertagent. We then propose a modification to the Dataset Aggregation (DAgger)algorithm to reuse the expert knowledge and train a new target agent toreplicate that behaviour in fewer than 5 iterations, compared to the 100iterations taken by the expert agent which means reducing training time by 95%.Our modifications to the DAgger algorithm improve the balance betweenexploiting the expert policy and exploring the environment. We show empiricallythat these improve convergence time of the target agent, particularly whenthere is some degree of variation between expert and naive agent."^^schema:Text ;
    schema:author "Benjamin Rosman"^^schema:Person,
        "Montaser Mohammedalamen"^^schema:Person,
        "Waleed D. Khamies"^^schema:Person ;
    schema:dateModified "2019-01-15T11:35:26Z"^^schema:DateTime ;
    schema:datePublished "2019-01-15T11:35:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Transfer Learning for Prosthetics Using Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.04772v1"^^schema:URL .

<1233> a schema:ScholarlyArticle ;
    schema:abstract "In order to design a more potent and effective chemical entity, it isessential to identify molecular structures with the desired chemicalproperties. Recent advances in generative models using neural networks andmachine learning are being widely used by many emerging startups andresearchers in this domain to design virtual libraries of drug-like compounds.Although these models can help a scientist to produce novel molecularstructures rapidly, the challenge still exists in the intelligent explorationof the latent spaces of generative models, thereby reducing the randomness inthe generative procedure. In this work we present a manifold traversal withheuristic search to explore the latent chemical space. Different heuristics andscores such as the Tanimoto coefficient, synthetic accessibility, bindingactivity, and QED drug-likeness can be incorporated to increase the validityand proximity for desired molecular properties of the generated molecules. Forevaluating the manifold traversal exploration, we produce the latent chemicalspace using various generative models such as grammar variational autoencoders(with and without attention) as they deal with the randomized generation andvalidity of compounds. With this novel traversal method, we are able to findmore unseen compounds and more specific regions to mine in the latent space.Finally, these components are brought together in a simple platform allowingusers to perform search, visualization and selection of novel generatedcompounds."^^schema:Text ;
    schema:author "Harshdeep Singh"^^schema:Person,
        "Jeremiah Hayes"^^schema:Person,
        "Nicholas McCarthy"^^schema:Person,
        "Qurrat Ul Ain"^^schema:Person ;
    schema:dateModified "2020-09-29T12:11:40Z"^^schema:DateTime ;
    schema:datePublished "2020-09-29T12:11:40Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.BM"^^schema:Text ;
    schema:headline "ChemoVerse: Manifold traversal of latent spaces for novel molecule  discovery"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.13946v1"^^schema:URL .

<1234> a schema:ScholarlyArticle ;
    schema:abstract "Effective planning in model-based reinforcement learning (MBRL) andmodel-predictive control (MPC) relies on the accuracy of the learned dynamicsmodel. In many instances of MBRL and MPC, this model is assumed to bestationary and is periodically re-trained from scratch on state transitionexperience collected from the beginning of environment interactions. Thisimplies that the time required to train the dynamics model - and the pauserequired between plan executions - grows linearly with the size of thecollected experience. We argue that this is too slow for lifelong robotlearning and propose HyperCRL, a method that continually learns the encountereddynamics in a sequence of tasks using task-conditional hypernetworks. Ourmethod has three main attributes: first, it enables constant-time dynamicslearning sessions between planning and only needs to store the most recentfixed-size portion of the state transition experience; second, it usesfixed-capacity hypernetworks to represent non-stationary and task-awaredynamics; third, it outperforms existing continual learning alternatives thatrely on fixed-capacity networks, and does competitively with baselines thatremember an ever increasing coreset of past experience. We show that HyperCRLis effective in continual model-based reinforcement learning in robotlocomotion and manipulation scenarios, such as tasks involving pushing and dooropening. Our project website with code and videos is at this linkhttp://rvl.cs.toronto.edu/blog/2020/hypercrl/"^^schema:Text ;
    schema:author "Florian Shkurti"^^schema:Person,
        "Homanga Bharadhwaj"^^schema:Person,
        "Kevin Xie"^^schema:Person,
        "Yizhou Huang"^^schema:Person ;
    schema:dateModified "2020-09-25T01:46:26Z"^^schema:DateTime ;
    schema:datePublished "2020-09-25T01:46:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Continual Model-Based Reinforcement Learning with Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.11997v1"^^schema:URL .

<1235> a schema:ScholarlyArticle ;
    schema:abstract "Analyzing the handwriting generation process is an important issue and hasbeen tackled by various generation models, such as kinematics based models andstochastic models. In this study, we use a reinforcement learning (RL)framework to realize handwriting generation with the careful future planningability. In fact, the handwriting process of human beings is also supported bytheir future planning ability; for example, the ability is necessary togenerate a closed trajectory like '0' because any shortsighted model, such as aMarkovian model, cannot generate it. For the algorithm, we employ generativeadversarial imitation learning (GAIL). Typical RL algorithms require the manualdefinition of the reward function, which is very crucial to control thegeneration process. In contrast, GAIL trains the reward function along with theother modules of the framework. In other words, through GAIL, we can understandthe reward of the handwriting generation process from handwriting examples. Ourexperimental results qualitatively and quantitatively show that the learnedreward catches the trends in handwriting generation and thus GAIL is wellsuited for the acquisition of handwriting behavior."^^schema:Text ;
    schema:author "Brian Kenji Iwana"^^schema:Person,
        "Keisuke Kanda"^^schema:Person,
        "Seiichi Uchida"^^schema:Person ;
    schema:dateModified "2020-09-23T07:04:08Z"^^schema:DateTime ;
    schema:datePublished "2020-09-23T07:04:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "What is the Reward for Handwriting? -- Handwriting Generation by  Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.10962v1"^^schema:URL .

<1236> a schema:ScholarlyArticle ;
    schema:abstract "Although there has been substantial research in software analytics for effortestimation in traditional software projects, little work has been done forestimation in agile projects, especially estimating user stories or issues.Story points are the most common unit of measure used for estimating the effortinvolved in implementing a user story or resolving an issue. In this paper, weoffer for the \\emph{first} time a comprehensive dataset for story points-basedestimation that contains 23,313 issues from 16 open source projects. We alsopropose a prediction model for estimating story points based on a novelcombination of two powerful deep learning architectures: long short-term memoryand recurrent highway network. Our prediction system is \\emph{end-to-end}trainable from raw input data to prediction outcomes without any manual featureengineering. An empirical evaluation demonstrates that our approachconsistently outperforms three common effort estimation baselines and twoalternatives in both Mean Absolute Error and the Standardized Accuracy."^^schema:Text ;
    schema:author "Aditya Ghose"^^schema:Person,
        "Hoa Khanh Dam"^^schema:Person,
        "Morakot Choetkiertikul"^^schema:Person,
        "Tim Menzies"^^schema:Person,
        "Trang Pham"^^schema:Person,
        "Truyen Tran"^^schema:Person ;
    schema:dateModified "2016-09-06T06:18:04Z"^^schema:DateTime ;
    schema:datePublished "2016-09-02T07:42:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A deep learning model for estimating story points"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1609.00489v2"^^schema:URL .

<1237> a schema:ScholarlyArticle ;
    schema:abstract "Loop Closure Detection (LCD) is the essential module in the simultaneouslocalization and mapping (SLAM) task. In the current appearance-based SLAMmethods, the visual inputs are usually affected by illumination, appearance andviewpoints changes. Comparing to the visual inputs, with the active property,light detection and ranging (LiDAR) based point-cloud inputs are invariant tothe illumination and appearance changes. In this paper, we extract 3D voxelmaps and 2D top view maps from LiDAR inputs, and the former could capture thelocal geometry into a simplified 3D voxel format, the later could capture thelocal road structure into a 2D image format. However, the most challengeproblem is to obtain efficient features from 3D and 2D maps to against theviewpoints difference. In this paper, we proposed a synchronous adversarialfeature learning method for the LCD task, which could learn the higher levelabstract features from different domains without any label data. To the best ofour knowledge, this work is the first to extract multi-domain adversarialfeatures for the LCD task in real time. To investigate the performance, we testthe proposed method on the KITTI odometry dataset. The extensive experimentsresults show that, the proposed method could largely improve LCD accuracy evenunder huge viewpoints differences."^^schema:Text ;
    schema:author "Jianda Han"^^schema:Person,
        "Lingyun Xu"^^schema:Person,
        "Peng Yin"^^schema:Person,
        "Weiliang Xu"^^schema:Person,
        "Yan Peng"^^schema:Person,
        "Yuqing He"^^schema:Person ;
    schema:dateModified "2018-04-05T16:40:16Z"^^schema:DateTime ;
    schema:datePublished "2018-04-05T16:40:16Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Synchronous Adversarial Feature Learning for LiDAR based Loop Closure  Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.01945v1"^^schema:URL .

<1238> a schema:ScholarlyArticle ;
    schema:abstract "In multi-task reinforcement learning there are two main challenges: attraining time, the ability to learn different policies with a single model; attest time, inferring which of those policies applying without an externalsignal. In the case of continual reinforcement learning a third challengearises: learning tasks sequentially without forgetting the previous ones. Inthis paper, we tackle these challenges by proposing DisCoRL, an approachcombining state representation learning and policy distillation. We experimenton a sequence of three simulated 2D navigation tasks with a 3 wheelomni-directional robot. Moreover, we tested our approach's robustness bytransferring the final policy into a real life setting. The policy can solveall tasks and automatically infer which one to run."^^schema:Text ;
    schema:author "David Filliat"^^schema:Person,
        "Guanghang Cai"^^schema:Person,
        "Hugo Caselles-Dupré"^^schema:Person,
        "Natalia Díaz-Rodríguez"^^schema:Person,
        "René Traoré"^^schema:Person,
        "Te Sun"^^schema:Person,
        "Timothée Lesort"^^schema:Person ;
    schema:dateModified "2019-07-11T09:12:42Z"^^schema:DateTime ;
    schema:datePublished "2019-07-11T09:12:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DisCoRL: Continual Reinforcement Learning via Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.05855v1"^^schema:URL .

<1239> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial imitation learning (GAIL) has shown promising resultsby taking advantage of generative adversarial nets, especially in the field ofrobot learning. However, the requirement of isolated single modaldemonstrations limits the scalability of the approach to real world scenariossuch as autonomous vehicles' demand for a proper understanding of humandrivers' behavior. In this paper, we propose a novel multi-modal GAILframework, named Triple-GAIL, that is able to learn skill selection andimitation jointly from both expert demonstrations and continuously generatedexperiences with data augmentation purpose by introducing an auxiliary skillselector. We provide theoretical guarantees on the convergence to optima forboth of the generator and the selector respectively. Experiments on real drivertrajectories and real-time strategy game datasets demonstrate that Triple-GAILcan better fit multi-modal behaviors close to the demonstrators and outperformsstate-of-the-art methods."^^schema:Text ;
    schema:author "Bin Wang"^^schema:Person,
        "Cong Fei"^^schema:Person,
        "Hongbo Zhang"^^schema:Person,
        "Jianye Hao"^^schema:Person,
        "Wulong Liu"^^schema:Person,
        "Xuewu Ji"^^schema:Person,
        "Yuzheng Zhuang"^^schema:Person,
        "Zongzhang Zhang"^^schema:Person ;
    schema:dateModified "2020-05-22T01:05:30Z"^^schema:DateTime ;
    schema:datePublished "2020-05-19T03:24:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative  Adversarial Nets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.10622v2"^^schema:URL .

<124> a schema:ScholarlyArticle ;
    schema:abstract "We show that there may exist an inherent tension between the goal ofadversarial robustness and that of standard generalization. Specifically,training robust models may not only be more resource-consuming, but also leadto a reduction of standard accuracy. We demonstrate that this trade-off betweenthe standard accuracy of a model and its robustness to adversarialperturbations provably exists in a fairly simple and natural setting. Thesefindings also corroborate a similar phenomenon observed empirically in morecomplex settings. Further, we argue that this phenomenon is a consequence ofrobust classifiers learning fundamentally different feature representationsthan standard classifiers. These differences, in particular, seem to result inunexpected benefits: the representations learned by robust models tend to alignbetter with salient data characteristics and human perception."^^schema:Text ;
    schema:author "Aleksander Madry"^^schema:Person,
        "Alexander Turner"^^schema:Person,
        "Dimitris Tsipras"^^schema:Person,
        "Logan Engstrom"^^schema:Person,
        "Shibani Santurkar"^^schema:Person ;
    schema:commentCount "272"^^schema:Integer ;
    schema:dateModified "2019-09-09T08:09:25Z"^^schema:DateTime ;
    schema:datePublished "2018-05-30T18:00:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Robustness May Be at Odds with Accuracy"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.12152v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5850945088404252192&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1240> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay enables off-policy reinforcement learning (RL) agents toutilize past experiences to maximize the cumulative reward. Prioritizedexperience replay that weighs experiences by the magnitude of theirtemporal-difference error ($|\\text{TD}|$) significantly improves the learningefficiency. But how $|\\text{TD}|$ is related to the importance of experience isnot well understood. We address this problem from an economic perspective, bylinking $|\\text{TD}|$ to value of experience, which is defined as the valueadded to the cumulative reward by accessing the experience. We theoreticallyshow the value metrics of experience are upper-bounded by $|\\text{TD}|$ forQ-learning. Furthermore, we successfully extend our theoretical framework tomaximum-entropy RL by deriving the lower and upper bounds of these valuemetrics for soft Q-learning, which turn out to be the product of $|\\text{TD}|$and \"on-policyness\" of the experiences. Our framework links two importantquantities in RL: $|\\text{TD}|$ and value of experience. We empirically showthat the bounds hold in practice, and experience replay using the upper boundas priority improves maximum-entropy RL in Atari games."^^schema:Text ;
    schema:author "Ang A. Li"^^schema:Person,
        "Chenglin Miao"^^schema:Person,
        "Zongqing Lu"^^schema:Person ;
    schema:dateModified "2021-02-05T16:09:07Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T16:09:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Revisiting Prioritized Experience Replay: A Value Perspective"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03261v1"^^schema:URL .

<1241> a schema:ScholarlyArticle ;
    schema:abstract "Model compression is significant for the wide adoption of Recurrent NeuralNetworks (RNNs) in both user devices possessing limited resources and businessclusters requiring quick responses to large-scale service requests. This workaims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing thesizes of basic structures within LSTM units, including input updates, gates,hidden states, cell states and outputs. Independently reducing the sizes ofbasic structures can result in inconsistent dimensions among them, andconsequently, end up with invalid LSTM units. To overcome the problem, wepropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISSwill simultaneously decrease the sizes of all basic structures by one andthereby always maintain the dimension consistency. By learning ISS within LSTMunits, the obtained LSTMs remain regular while having much smaller basicstructures. Based on group Lasso regularization, our method achieves 10.59xspeedup without losing any perplexity of a language modeling of Penn TreeBankdataset. It is also successfully evaluated through a compact model with only2.69M weights for machine Question Answering of SQuAD dataset. Our approach issuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks(RHNs). Our source code is publicly available athttps://github.com/wenwei202/iss-rnns"^^schema:Text ;
    schema:author "Bin Hu"^^schema:Person,
        "Fang Liu"^^schema:Person,
        "Hai Li"^^schema:Person,
        "Minjia Zhang"^^schema:Person,
        "Samyam Rajbhandari"^^schema:Person,
        "Wei Wen"^^schema:Person,
        "Wenhan Wang"^^schema:Person,
        "Yiran Chen"^^schema:Person,
        "Yuxiong He"^^schema:Person ;
    schema:dateModified "2018-02-11T16:36:32Z"^^schema:DateTime ;
    schema:datePublished "2017-09-15T01:10:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning Intrinsic Sparse Structures within Long Short-Term Memory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.05027v7"^^schema:URL .

<1242> a schema:ScholarlyArticle ;
    schema:abstract "Machine Learning algorithms based on Brain-inspired Hyperdimensional (HD)computing imitate cognition by exploiting statistical properties ofhigh-dimensional vector spaces. It is a promising solution for achieving highenergy-efficiency in different machine learning tasks, such as classification,semi-supervised learning and clustering. A weakness of existing HDcomputing-based ML algorithms is the fact that they have to be binarized forachieving very high energy-efficiency. At the same time, binarized models reachlower classification accuracies. To solve the problem of the trade-off betweenenergy-efficiency and classification accuracy, we propose the QubitHDalgorithm. It stochastically binarizes HD-based algorithms, while maintainingcomparable classification accuracies to their non-binarized counterparts. TheFPGA implementation of QubitHD provides a 65% improvement in terms ofenergy-efficiency, and a 95% improvement in terms of the training time, ascompared to state-of-the-art HD-based ML algorithms. It also outperformsstate-of-the-art low-cost classifiers (like Binarized Neural Networks) in termsof speed and energy-efficiency by an order of magnitude during training andinference."^^schema:Text ;
    schema:author "Alexander Sanchez de la Cerda"^^schema:Person,
        "Giovanni De Micheli"^^schema:Person,
        "Mohsen Imani"^^schema:Person,
        "Samuel Bosch"^^schema:Person,
        "Tajana Simunic Rosing"^^schema:Person ;
    schema:dateModified "2019-12-02T13:12:54Z"^^schema:DateTime ;
    schema:datePublished "2019-11-27T22:20:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "QubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.12446v2"^^schema:URL .

<1243> a schema:ScholarlyArticle ;
    schema:abstract "Current approaches for predicting sets from feature vectors ignore theunordered nature of sets and suffer from discontinuity issues as a result. Wepropose a general model for predicting sets that properly respects thestructure of sets and avoids this problem. With a single feature vector asinput, we show that our model is able to auto-encode point sets, predict theset of bounding boxes of objects in an image, and predict the set of attributesof these objects."^^schema:Text ;
    schema:author "Adam Prügel-Bennett"^^schema:Person,
        "Jonathon Hare"^^schema:Person,
        "Yan Zhang"^^schema:Person ;
    schema:dateModified "2020-04-24T20:49:06Z"^^schema:DateTime ;
    schema:datePublished "2019-06-15T13:48:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Set Prediction Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.06565v6"^^schema:URL .

<1244> a schema:ScholarlyArticle ;
    schema:abstract "Graph Identification (GI) has long been researched in graph learning and isessential in certain applications (e.g. social community detection).Specifically, GI requires to predict the label/score of a target graph givenits collection of node features and edge connections. While this task iscommon, more complex cases arise in practice---we are supposed to do theinverse thing by, for example, grouping similar users in a social network giventhe labels of different communities. This triggers an interesting thought: canwe identify nodes given the labels of the graphs they belong to? Therefore,this paper defines a novel problem dubbed Inverse Graph Identification (IGI),as opposed to GI. Upon a formal discussion of the variants of IGI, we choose aparticular case study of node clustering by making use of the graph labels andnode features, with an assistance of a hierarchical graph that furthercharacterizes the connections between different graphs. To address this task,we propose Gaussian Mixture Graph Convolutional Network (GMGCN), a simple yeteffective method that makes the node-level message passing process using GraphAttention Network (GAT) under the protocol of GI and then infers the categoryof each node via a Gaussian Mixture Layer (GML). The training of GMGCN isfurther boosted by a proposed consensus loss to take advantage of the structureof the hierarchical graph. Extensive experiments are conducted to test therationality of the formulation of IGI. We verify the superiority of theproposed method compared to other baselines on several benchmarks we have builtup. We will release our codes along with the benchmark data to facilitate moreresearch attention to the IGI problem."^^schema:Text ;
    schema:author "Junzhou Huang"^^schema:Person,
        "Peilin Zhao"^^schema:Person,
        "Tian Bian"^^schema:Person,
        "Tingyang Xu"^^schema:Person,
        "Wenbing Huang"^^schema:Person,
        "Xi Xiao"^^schema:Person,
        "Yu Rong"^^schema:Person ;
    schema:dateModified "2020-07-12T12:06:17Z"^^schema:DateTime ;
    schema:datePublished "2020-07-12T12:06:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Inverse Graph Identification: Can We Identify Node Labels Given Graph  Labels?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.05970v1"^^schema:URL .

<1245> a schema:ScholarlyArticle ;
    schema:abstract "We recently proposed the S4NN algorithm, essentially an adaptation ofbackpropagation to multilayer spiking neural networks that use simple non-leakyintegrate-and-fire neurons and a form of temporal coding known astime-to-first-spike coding. With this coding scheme, neurons fire at most onceper stimulus, but the firing order carries information. Here, we introduceBS4NN, a modification of S4NN in which the synaptic weights are constrained tobe binary (+1 or -1), in order to decrease memory and computation footprints.This was done using two sets of weights: firstly, real-valued weights, updatedby gradient descent, and used in the backward pass of backpropagation, andsecondly, their signs, used in the forward pass. Similar strategies have beenused to train (non-spiking) binarized neural networks. The main difference isthat BS4NN operates in the time domain: spikes are propagated sequentially, anddifferent neurons may reach their threshold at different times, which increasescomputational power. We validated BS4NN on two popular benchmarks, MNIST andFashion MNIST, and obtained state-of-the-art accuracies for this sort ofnetworks (97.0% and 87.3% respectively) with a negligible accuracy drop withrespect to real-valued weights (0.4% and 0.7%, respectively). We alsodemonstrated that BS4NN outperforms a simple BNN with the same architectures onthose two datasets (by 0.2% and 0.9% respectively), presumably because itleverages the temporal dimension."^^schema:Text ;
    schema:author "Maryam Mirsadeghi"^^schema:Person,
        "Saeed Reza Kheradpisheh"^^schema:Person,
        "Timothée Masquelier"^^schema:Person ;
    schema:dateModified "2020-07-08T11:31:32Z"^^schema:DateTime ;
    schema:datePublished "2020-07-08T11:31:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "BS4NN: Binarized Spiking Neural Networks with Temporal Coding and  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.04039v1"^^schema:URL .

<1246> a schema:ScholarlyArticle ;
    schema:abstract "Note that this paper is superceded by \"Black-Box Adversarial Attacks withLimited Queries and Information.\"  Current neural network-based image classifiers are susceptible to adversarialexamples, even in the black-box setting, where the attacker is limited to queryaccess without access to gradients. Previous methods --- substitute networksand coordinate-based finite-difference methods --- are either unreliable orquery-inefficient, making these methods impractical for certain problems.  We introduce a new method for reliably generating adversarial examples undermore restricted, practical black-box threat models. First, we apply naturalevolution strategies to perform black-box attacks using two to three orders ofmagnitude fewer queries than previous methods. Second, we introduce a newalgorithm to perform targeted adversarial attacks in the partial-informationsetting, where the attacker only has access to a limited number of targetclasses. Using these techniques, we successfully perform the first targetedadversarial attack against a commercially deployed machine learning system, theGoogle Cloud Vision API, in the partial information setting."^^schema:Text ;
    schema:author "Andrew Ilyas"^^schema:Person,
        "Anish Athalye"^^schema:Person,
        "Jessy Lin"^^schema:Person,
        "Logan Engstrom"^^schema:Person ;
    schema:dateModified "2018-04-06T17:20:27Z"^^schema:DateTime ;
    schema:datePublished "2017-12-19T18:58:10Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Query-Efficient Black-box Adversarial Examples (superceded)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1712.07113v2"^^schema:URL .

<1247> a schema:ScholarlyArticle ;
    schema:abstract "Interpretable machine learning has gained much attention recently. Briefnessand comprehensiveness are necessary in order to provide a large amount ofinformation concisely when explaining a black-box decision system. However,existing interpretable machine learning methods fail to consider briefness andcomprehensiveness simultaneously, leading to redundant explanations. We proposethe variational information bottleneck for interpretation, VIBI, asystem-agnostic interpretable method that provides a brief but comprehensiveexplanation. VIBI adopts an information theoretic principle, informationbottleneck principle, as a criterion for finding such explanations. For eachinstance, VIBI selects key features that are maximally compressed about aninput (briefness), and informative about a decision made by a black-box systemon that input (comprehensive). We evaluate VIBI on three datasets and comparewith state-of-the-art interpretable machine learning methods in terms of bothinterpretability and fidelity evaluated by human and quantitative metrics"^^schema:Text ;
    schema:author "Eric Xing"^^schema:Person,
        "Heewook Lee"^^schema:Person,
        "Pengtao Xie"^^schema:Person,
        "Seojin Bang"^^schema:Person,
        "Wei Wu"^^schema:Person ;
    schema:dateModified "2019-10-03T08:24:25Z"^^schema:DateTime ;
    schema:datePublished "2019-02-19T06:42:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Explaining a black-box using Deep Variational Information Bottleneck  Approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.06918v2"^^schema:URL .

<1248> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we explore the inclusion of latent random variables into thedynamic hidden state of a recurrent neural network (RNN) by combining elementsof the variational autoencoder. We argue that through the use of high-levellatent random variables, the variational RNN (VRNN)1 can model the kind ofvariability observed in highly structured sequential data such as naturalspeech. We empirically evaluate the proposed model against related sequentialmodels on four speech datasets and one handwriting dataset. Our results showthe important roles that latent random variables can play in the RNN dynamichidden state."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Junyoung Chung"^^schema:Person,
        "Kratarth Goel"^^schema:Person,
        "Kyle Kastner"^^schema:Person,
        "Laurent Dinh"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:dateModified "2016-04-06T20:52:32Z"^^schema:DateTime ;
    schema:datePublished "2015-06-07T04:23:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "A Recurrent Latent Variable Model for Sequential Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1506.02216v6"^^schema:URL .

<1249> a schema:ScholarlyArticle ;
    schema:abstract "Effective inference for a generative adversarial model remains an importantand challenging problem. We propose a novel approach, Decomposed AdversarialLearned Inference (DALI), which explicitly matches prior and conditionaldistributions in both data and code spaces, and puts a direct constraint on thedependency structure of the generative model. We derive an equivalent form ofthe prior and conditional matching objective that can be optimized efficientlywithout any parametric assumption on the data. We validate the effectiveness ofDALI on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative andqualitative evaluations. Results demonstrate that DALI significantly improvesboth reconstruction and generation as compared to other adversarial inferencemodels."^^schema:Text ;
    schema:author "Alexander Hanbo Li"^^schema:Person,
        "Changyou Chen"^^schema:Person,
        "Jing Gao"^^schema:Person,
        "Yaqing Wang"^^schema:Person ;
    schema:dateModified "2020-04-21T20:00:35Z"^^schema:DateTime ;
    schema:datePublished "2020-04-21T20:00:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Decomposed Adversarial Learned Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10267v1"^^schema:URL .

<125> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks are both computationally intensive and memory intensive,making them difficult to deploy on embedded systems. Also, conventionalnetworks fix the architecture before training starts; as a result, trainingcannot improve the architecture. To address these limitations, we describe amethod to reduce the storage and computation required by neural networks by anorder of magnitude without affecting their accuracy by learning only theimportant connections. Our method prunes redundant connections using athree-step method. First, we train the network to learn which connections areimportant. Next, we prune the unimportant connections. Finally, we retrain thenetwork to fine tune the weights of the remaining connections. On the ImageNetdataset, our method reduced the number of parameters of AlexNet by a factor of9x, from 61 million to 6.7 million, without incurring accuracy loss. Similarexperiments with VGG-16 found that the number of parameters can be reduced by13x, from 138 million to 10.3 million, again with no loss of accuracy."^^schema:Text ;
    schema:author "Jeff Pool"^^schema:Person,
        "John Tran"^^schema:Person,
        "Song Han"^^schema:Person,
        "William J. Dally"^^schema:Person ;
    schema:commentCount "2416"^^schema:Integer ;
    schema:dateModified "2015-10-30T23:29:27Z"^^schema:DateTime ;
    schema:datePublished "2015-06-08T19:28:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning both Weights and Connections for Efficient Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02626v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6338930303179684776&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1250> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel hierarchical generative model with a simple Markovianstructure and a corresponding inference model. Both the generative andinference model are trained using the adversarial learning paradigm. Wedemonstrate that the hierarchical structure supports the learning ofprogressively more abstract representations as well as providing semanticallymeaningful reconstructions with different levels of fidelity. Furthermore, weshow that minimizing the Jensen-Shanon divergence between the generative andinference network is enough to minimize the reconstruction error. The resultingsemantically meaningful hierarchical latent structure discovery is exemplifiedon the CelebA dataset. There, we show that the features learned by our model inan unsupervised way outperform the best handcrafted features. Furthermore, theextracted features remain competitive when compared to several recent deepsupervised approaches on an attribute prediction task on CelebA. Finally, weleverage the model's inference network to achieve state-of-the-art performanceon a semi-supervised variant of the MNIST digit classification task."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Jovana Mitrovic"^^schema:Person,
        "Mohamed Ishmael Belghazi"^^schema:Person,
        "Negar Rostamzadeh"^^schema:Person,
        "Olivier Mastropietro"^^schema:Person,
        "Sai Rajeswar"^^schema:Person ;
    schema:dateModified "2018-02-04T04:49:18Z"^^schema:DateTime ;
    schema:datePublished "2018-02-04T04:49:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Adversarially Learned Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.01071v1"^^schema:URL .

<1251> a schema:ScholarlyArticle ;
    schema:abstract "Explaining the output of a complicated machine learning model like a deepneural network (DNN) is a central challenge in machine learning. Severalproposed local explanation methods address this issue by identifying whatdimensions of a single input are most responsible for a DNN's output. The goalof this work is to assess the sensitivity of local explanations to DNNparameter values. Somewhat surprisingly, we find that DNNs withrandomly-initialized weights produce explanations that are both visually andquantitatively similar to those produced by DNNs with learned weights. Ourconjecture is that this phenomenon occurs because these explanations aredominated by the lower level features of a DNN, and that a DNN's architectureprovides a strong prior which significantly affects the representations learnedat these lower layers. NOTE: This work is now subsumed by our recentmanuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where weexpand on findings and address concerns raised in Sundararajan et. al. (2018)."^^schema:Text ;
    schema:author "Been Kim"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Julius Adebayo"^^schema:Person,
        "Justin Gilmer"^^schema:Person ;
    schema:dateModified "2018-10-08T08:18:14Z"^^schema:DateTime ;
    schema:datePublished "2018-10-08T08:18:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to  Parameter Values"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.03307v1"^^schema:URL .

<1252> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a detailed and extensive comparison of the Trust RegionPolicy Optimization and DeepQ-Network with Normalized Advantage Functions withrespect to other state of the art algorithms, namely Deep Deterministic PolicyGradient and Vanilla Policy Gradient. Comparisons demonstrate that the formerhave better performances then the latter when asking robotic arms to accomplishmanipulation tasks such as reaching a random target pose and pick &amp;placing anobject. Both simulated and real-world experiments are provided. Simulation letsus show the procedures that we adopted to precisely estimate the algorithmshyper-parameters and to correctly design good policies. Real-world experimentslet show that our polices, if correctly trained on simulation, can betransferred and executed in a real environment with almost no changes."^^schema:Text ;
    schema:author "Andrea Franceschetti"^^schema:Person,
        "Elisa Tosello"^^schema:Person,
        "Nicola Castaman"^^schema:Person,
        "Stefano Ghidoni"^^schema:Person ;
    schema:dateModified "2020-05-06T07:34:28Z"^^schema:DateTime ;
    schema:datePublished "2020-05-06T07:34:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Robotic Arm Control and Task Training through Deep Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.02632v1"^^schema:URL .

<1253> a schema:ScholarlyArticle ;
    schema:abstract "Non-adversarial generative models such as variational auto-encoder (VAE),Wasserstein auto-encoders with maximum mean discrepancy (WAE-MMD),sliced-Wasserstein auto-encoder (SWAE) are relatively easy to train and haveless mode collapse compared to Wasserstein auto-encoder with generativeadversarial network (WAE-GAN). However, they are not very accurate inapproximating the target distribution in the latent space because they don'thave a discriminator to detect the minor difference between real and fake. Tothis end, we develop a novel non-adversarial framework called TessellatedWasserstein Auto-encoders (TWAE) to tessellate the support of the targetdistribution into a given number of regions by the centroidal Voronoitessellation (CVT) technique and design batches of data according to thetessellation instead of random shuffling for accurate computation ofdiscrepancy. Theoretically, we demonstrate that the error of estimate to thediscrepancy decreases when the numbers of samples $n$ and regions $m$ of thetessellation become larger with rates of $\\mathcal{O}(\\frac{1}{\\sqrt{n}})$ and$\\mathcal{O}(\\frac{1}{\\sqrt{m}})$, respectively. Given fixed $n$ and $m$, anecessary condition for the upper bound of measurement error to be minimized isthat the tessellation is the one determined by CVT. TWAE is very flexible todifferent non-adversarial metrics and can substantially enhance theirgenerative performance in terms of Fr\\'{e}chet inception distance (FID)compared to VAE, WAE-MMD, SWAE. Moreover, numerical results indeed demonstratethat TWAE is competitive to the adversarial model WAE-GAN, demonstrating itspowerful generative ability."^^schema:Text ;
    schema:author "Kuo Gai"^^schema:Person,
        "Shihua Zhang"^^schema:Person ;
    schema:dateModified "2020-05-20T09:21:05Z"^^schema:DateTime ;
    schema:datePublished "2020-05-20T09:21:05Z"^^schema:DateTime ;
    schema:genre "90-08, 68T01"^^schema:Text,
        "I.2.6; I.5.1; I.4.0"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Tessellated Wasserstein Auto-Encoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.09923v1"^^schema:URL .

<1254> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural network with dual-path bi-directional long short-term memory(BiLSTM) block has been proved to be very effective in sequence modeling,especially in speech separation, e.g. DPRNN-TasNet \\cite{luo2019dual}. In thispaper, we propose several improvements of dual-path BiLSTM based network forend-to-end approach to monaural speech separation. Firstly a dual-path networkwith intra-parallel BiLSTM and inter-parallel BiLSTM components is introducedto reduce performance sub-variances among different branches. Secondly, wepropose to use global context aware inter-intra cross-parallel BiLSTM tofurther perceive the global contextual information. Finally, a spiralmulti-stage dual-path BiLSTM is proposed to iteratively refine the separationresults of the previous stages. All these networks take the mixed utterance oftwo speakers and map it to two separate utterances, where each utterancecontains only one speaker's voice. For the objective, we propose to train thenetwork by directly optimizing the utterance level scale-invariantsignal-to-distortion ratio (SI-SDR) in a permutation invariant training (PIT)style. Our experiments on the public WSJ0-2mix data corpus results in 20.55dBSDR improvement, 20.35dB SI-SDR improvement, 3.69 of PESQ, and 94.86\\% ofESTOI, which shows our proposed networks can lead to performance improvement onthe speaker separation task. We have open-sourced our re-implementation of theDPRNN-TasNet inhttps://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation,and our LaFurca is realized based on this implementation of DPRNN-TasNet, it isbelieved that the results in this paper can be reproduced with ease."^^schema:Text ;
    schema:author "Jiqing Han"^^schema:Person,
        "Rujie Liu"^^schema:Person,
        "Ziqiang Shi"^^schema:Person ;
    schema:dateModified "2020-10-27T00:49:42Z"^^schema:DateTime ;
    schema:datePublished "2020-01-23T02:03:26Z"^^schema:DateTime ;
    schema:genre "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "LaFurca: Iterative Refined Speech Separation Based on Context-Aware  Dual-Path Parallel Bi-LSTM"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.08998v4"^^schema:URL .

<1255> a schema:ScholarlyArticle ;
    schema:abstract "Electroencephalography (EEG) data are difficult to obtain due to complexexperimental setups and reduced comfort with prolonged wearing. This poseschallenges to train powerful deep learning model with the limited EEG data.Being able to generate EEG data computationally could address this limitation.We propose a novel Wasserstein Generative Adversarial Network with gradientpenalty (WGAN-GP) to synthesize EEG data. This network addresses severalmodeling challenges of simulating time-series EEG data including frequencyartifacts and training instability. We further extended this network to aclass-conditioned variant that also includes a classification branch to performevent-related classification. We trained the proposed networks to generate oneand 64-channel data resembling EEG signals routinely seen in a rapid serialvisual presentation (RSVP) experiment and demonstrated the validity of thegenerated samples. We also tested intra-subject cross-session classificationperformance for classifying the RSVP target events and showed thatclass-conditioned WGAN-GP can achieve improved event-classification performanceover EEGNet."^^schema:Text ;
    schema:author "Paul Rad"^^schema:Person,
        "Sharaj Panwar"^^schema:Person,
        "Tzyy-Ping Jung"^^schema:Person,
        "Yufei Huang"^^schema:Person ;
    schema:dateModified "2020-07-01T16:17:27Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T16:43:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.AP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modeling EEG data distribution with a Wasserstein Generative Adversarial  Network to predict RSVP Events"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04379v2"^^schema:URL .

<1256> a schema:ScholarlyArticle ;
    schema:abstract "This work adopts the very successful distributional perspective onreinforcement learning and adapts it to the continuous control setting. Wecombine this within a distributed framework for off-policy learning in order todevelop what we call the Distributed Distributional Deep Deterministic PolicyGradient algorithm, D4PG. We also combine this technique with a number ofadditional, simple improvements such as the use of $N$-step returns andprioritized experience replay. Experimentally we examine the contribution ofeach of these individual components, and show how they interact, as well astheir combined contributions. Our results show that across a wide variety ofsimple control tasks, difficult manipulation tasks, and a set of hardobstacle-based locomotion tasks the D4PG algorithm achieves state of the artperformance."^^schema:Text ;
    schema:author "Alistair Muldal"^^schema:Person,
        "Dan Horgan"^^schema:Person,
        "David Budden"^^schema:Person,
        "Dhruva TB"^^schema:Person,
        "Gabriel Barth-Maron"^^schema:Person,
        "Matthew W. Hoffman"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person,
        "Will Dabney"^^schema:Person ;
    schema:dateModified "2018-04-23T11:57:21Z"^^schema:DateTime ;
    schema:datePublished "2018-04-23T11:57:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Distributed Distributional Deterministic Policy Gradients"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.08617v1"^^schema:URL .

<1257> a schema:ScholarlyArticle ;
    schema:abstract "Recently, learned image compression methods have been actively studied. Amongthem, entropy-minimization based approaches have achieved superior resultscompared to conventional image codecs such as BPG and JPEG2000. However, thequality enhancement and rate-minimization are conflictively coupled in theprocess of image compression. That is, maintaining high image quality entailsless compression and vice versa. However, by jointly training separate qualityenhancement in conjunction with image compression, the coding efficiency can beimproved. In this paper, we propose a novel joint learning scheme of imagecompression and quality enhancement, called JointIQ-Net, as well as entropymodel improvement, thus achieving significantly improved coding efficiencyagainst the previous methods. Our proposed JointIQ-Net combines an imagecompression sub-network and a quality enhancement sub-network in a cascade,both of which are end-to-end trained in a combined manner within theJointIQ-Net. Also the JointIQ-Net benefits from improved entropy-minimizationthat newly adopts a Gussian Mixture Model (GMM) and further exploits globalcontext to estimate the probabilities of latent representations. In order toshow the effectiveness of our proposed JointIQ-Net, extensive experiments havebeen performed, and showed that the JointIQ-Net achieves a remarkableperformance improvement in coding efficiency in terms of both PSNR and MS-SSIM,compared to the previous learned image compression methods and the conventionalcodecs such as VVC Intra (VTM 7.1), BPG, and JPEG2000. To the best of ourknowledge, this is the first end-to-end optimized image compression method thatoutperforms VTM 7.1 (Intra), the latest reference software of the VVC standard,in terms of the PSNR and MS-SSIM."^^schema:Text ;
    schema:author "Jooyoung Lee"^^schema:Person,
        "Munchurl Kim"^^schema:Person,
        "Seunghyun Cho"^^schema:Person ;
    schema:dateModified "2020-03-13T08:45:53Z"^^schema:DateTime ;
    schema:datePublished "2019-12-30T05:10:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "An End-to-End Joint Learning Scheme of Image Compression and Quality  Enhancement with Improved Entropy Minimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.12817v2"^^schema:URL .

<1258> a schema:ScholarlyArticle ;
    schema:abstract "Although providing exceptional results for many computer vision tasks,state-of-the-art deep learning algorithms catastrophically struggle in low datascenarios. However, if data in additional modalities exist (e.g. text) this cancompensate for the lack of data and improve the classification results. Toovercome this data scarcity, we design a cross-modal feature generationframework capable of enriching the low populated embedding space in few-shotscenarios, leveraging data from the auxiliary modality. Specifically, we traina generative model that maps text data into the visual feature space to obtainmore reliable prototypes. This allows to exploit data from additionalmodalities (e.g. text) during training while the ultimate task at test timeremains classification with exclusively visual data. We show that in such casesnearest neighbor classification is a viable approach and outperformstate-of-the-art single-modal and multimodal few-shot learning methods on theCUB-200 and Oxford-102 datasets."^^schema:Text ;
    schema:author "Frederik Pahde"^^schema:Person,
        "Mihai Puscas"^^schema:Person,
        "Moin Nabi"^^schema:Person,
        "Tassilo Klein"^^schema:Person ;
    schema:dateModified "2020-11-17T19:32:59Z"^^schema:DateTime ;
    schema:datePublished "2020-11-17T19:32:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Multimodal Prototypical Networks for Few-shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.08899v1"^^schema:URL .

<1259> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial attacks have been widely studied in the field of computer visionbut their impact on network security applications remains an area of openresearch. As IoT, 5G and AI continue to converge to realize the promise of thefourth industrial revolution (Industry 4.0), security incidents and events onIoT networks have increased. Deep learning techniques are being applied todetect and mitigate many of such security threats against IoT networks.Feedforward Neural Networks (FNN) have been widely used for classifyingintrusion attacks in IoT networks. In this paper, we consider a variant of theFNN known as the Self-normalizing Neural Network (SNN) and compare itsperformance with the FNN for classifying intrusion attacks in an IoT network.Our analysis is performed using the BoT-IoT dataset from the Cyber Range Lab ofthe center of UNSW Canberra Cyber. In our experimental results, the FNNoutperforms the SNN for intrusion detection in IoT networks based on multipleperformance metrics such as accuracy, precision, and recall as well asmulti-classification metrics such as Cohen's Kappa score. However, when testedfor adversarial robustness, the SNN demonstrates better resilience against theadversarial samples from the IoT dataset, presenting a promising future in thequest for safer and more secure deep learning in IoT networks."^^schema:Text ;
    schema:author "Ashraf Matrawy"^^schema:Person,
        "Olakunle Ibitoye"^^schema:Person,
        "Omair Shafiq"^^schema:Person ;
    schema:dateModified "2019-05-13T16:43:14Z"^^schema:DateTime ;
    schema:datePublished "2019-05-13T16:43:14Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text ;
    schema:headline "Analyzing Adversarial Attacks Against Deep Learning for Intrusion  Detection in IoT Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.05137v1"^^schema:URL .

<126> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes the novel Pose Guided Person Generation Network (PG$^2$)that allows to synthesize person images in arbitrary poses, based on an imageof that person and a novel pose. Our generation framework PG$^2$ utilizes thepose information explicitly and consists of two key stages: pose integrationand image refinement. In the first stage the condition image and the targetpose are fed into a U-Net-like network to generate an initial but coarse imageof the person with the target pose. The second stage then refines the initialand blurry result by training a U-Net-like generator in an adversarial way.Extensive experimental results on both 128$\\times$64 re-identification imagesand 256$\\times$256 fashion photos show that our model generates high-qualityperson images with convincing details."^^schema:Text ;
    schema:author "Bernt Schiele"^^schema:Person,
        "Liqian Ma"^^schema:Person,
        "Luc Van Gool"^^schema:Person,
        "Qianru Sun"^^schema:Person,
        "Tinne Tuytelaars"^^schema:Person,
        "Xu Jia"^^schema:Person ;
    schema:commentCount "309"^^schema:Integer ;
    schema:dateModified "2018-01-28T09:25:08Z"^^schema:DateTime ;
    schema:datePublished "2017-05-25T21:29:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Pose Guided Person Image Generation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.09368v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4891149081490254273&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1260> a schema:ScholarlyArticle ;
    schema:abstract "Image inpainting is the task of filling-in missing regions of a damaged orincomplete image. In this work we tackle this problem not only by using theavailable visual data but also by incorporating image semantics through the useof generative models. Our contribution is twofold: First, we learn a datalatent space by training an improved version of the Wasserstein generativeadversarial network, for which we incorporate a new generator and discriminatorarchitecture. Second, the learned semantic information is combined with a newoptimization loss for inpainting whose minimization infers the missing contentconditioned by the available data. It takes into account powerful contextualand perceptual content inherent in the image itself. The benefits include theability to recover large regions by accumulating semantic information even itis not fully present in the damaged image. Experiments show that the presentedmethod obtains qualitative and quantitative top-tier results in differentexperimental situations and also achieves accurate photo-realism comparable tostate-of-the-art works."^^schema:Text ;
    schema:author "Coloma Ballester"^^schema:Person,
        "Joan Sintes"^^schema:Person,
        "Patricia Vitoria"^^schema:Person ;
    schema:dateModified "2018-12-03T20:28:17Z"^^schema:DateTime ;
    schema:datePublished "2018-12-03T20:28:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Semantic Image Inpainting Through Improved Wasserstein Generative  Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.01071v1"^^schema:URL .

<1261> a schema:ScholarlyArticle ;
    schema:abstract "This paper studies numerical solutions for parameterized partial differentialequations (P-PDEs) with deep learning (DL). P-PDEs arise in many importantapplication areas and the computational cost using traditional numericalschemes can be exorbitant, especially when the parameters fall into aparticular range and the underlying PDE is required to be solved with highaccuracy. Recently, solving PDEs with DL has become an emerging field. Existingworks demonstrate great potentials of the DL based approach in speeding upnumerical solutions of PDEs. However, there is still limited research on the DLapproach for P-PDEs. If we directly apply existing supervised learning modelsto P-PDEs, the models need to be constantly fine-tuned or retrained when theparameters change. This drastically limits the applicability and utility ofthese models in practice. To resolve this issue, we propose ameta-learning-based method that can efficiently solve P-PDEs with a wide rangeof parameters without retraining. Our key observation is to regard training asolver for the P-PDE with a given set of parameters as a learning task. Then,training a solver for the P-PDEs with varied parameters can be viewed as amulti-task learning problem, to which meta-learning is one of the mosteffective approaches. This new perspective can be applied to many existing PDEsolvers. As an example, we adopt the Multigrid Network (MgNet) as the basesolver. To achieve multi-task learning, we introduce a new hypernetwork, calledMeta-NN, in MgNet and refer to the entire network as the Meta-MgNet. Meta-NNtakes the differential operators and the right-hand-side of the underlyingP-PDEs as inputs and generates appropriate smoothers for MgNet which cansignificantly affect the convergent speed. Finally, extensive numericalexperiments demonstrate that Meta-MgNet is more efficient in solving P-PDEsthan the MG methods and MgNet."^^schema:Text ;
    schema:author "Bin Dong"^^schema:Person,
        "Jinchao Xu"^^schema:Person,
        "Yuyan Chen"^^schema:Person ;
    schema:dateModified "2020-11-01T16:21:02Z"^^schema:DateTime ;
    schema:datePublished "2020-10-27T06:13:50Z"^^schema:DateTime ;
    schema:genre "65N55"^^schema:Text,
        "G.1.8"^^schema:Text,
        "cs.NA"^^schema:Text,
        "math.NA"^^schema:Text ;
    schema:headline "Meta-MgNet: Meta Multigrid Networks for Solving Parameterized Partial  Differential Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.14088v2"^^schema:URL .

<1262> a schema:ScholarlyArticle ;
    schema:abstract "We study the role of latent space dimensionality in Wasserstein auto-encoders(WAEs). Through experimentation on synthetic and real datasets, we argue thatrandom encoders should be preferred over deterministic encoders. We highlightthe potential of WAEs for representation learning with promising results on abenchmark disentanglement task."^^schema:Text ;
    schema:author "Bernhard Schoelkopf"^^schema:Person,
        "Ilya Tolstikhin"^^schema:Person,
        "Paul K. Rubenstein"^^schema:Person ;
    schema:dateModified "2018-02-11T16:10:41Z"^^schema:DateTime ;
    schema:datePublished "2018-02-11T16:10:41Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Latent Space of Wasserstein Auto-Encoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.03761v1"^^schema:URL .

<1263> a schema:ScholarlyArticle ;
    schema:abstract "We study the use of hypermodels to represent epistemic uncertainty and guideexploration. This generalizes and extends the use of ensembles to approximateThompson sampling. The computational cost of training an ensemble grows withits size, and as such, prior work has typically been limited to ensembles withtens of elements. We show that alternative hypermodels can enjoy dramaticefficiency gains, enabling behavior that would otherwise require hundreds orthousands of elements, and even succeed in situations where ensemble methodsfail to learn regardless of size. This allows more accurate approximation ofThompson sampling as well as use of more sophisticated exploration schemes. Inparticular, we consider an approximate form of information-directed samplingand demonstrate performance gains relative to Thompson sampling. Asalternatives to ensembles, we consider linear and neural network hypermodels,also known as hypernetworks. We prove that, with neural network base models, alinear hypermodel can represent essentially any distribution over functions,and as such, hypernetworks are no more expressive."^^schema:Text ;
    schema:author "Benjamin Van Roy"^^schema:Person,
        "Ian Osband"^^schema:Person,
        "Morteza Ibrahimi"^^schema:Person,
        "Vikranth Dwaracherla"^^schema:Person,
        "Xiuyuan Lu"^^schema:Person,
        "Zheng Wen"^^schema:Person ;
    schema:dateModified "2020-06-12T20:59:21Z"^^schema:DateTime ;
    schema:datePublished "2020-06-12T20:59:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hypermodels for Exploration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.07464v1"^^schema:URL .

<1264> a schema:ScholarlyArticle ;
    schema:abstract "Humans often learn how to perform tasks via imitation: they observe othersperform a task, and then very quickly infer the appropriate actions to takebased on their observations. While extending this paradigm to autonomous agentsis a well-studied problem in general, there are two particular aspects thathave largely been overlooked: (1) that the learning is done from observationonly (i.e., without explicit action information), and (2) that the learning istypically done very quickly. In this work, we propose a two-phase, autonomousimitation learning technique called behavioral cloning from observation (BCO),that aims to provide improved performance with respect to both of theseaspects. First, we allow the agent to acquire experience in a self-supervisedfashion. This experience is used to develop a model which is then utilized tolearn a particular task by observing an expert perform that task without theknowledge of the specific actions taken. We experimentally compare BCO toimitation learning methods, including the state-of-the-art, generativeadversarial imitation learning (GAIL) technique, and we show comparable taskperformance in several different simulation domains while exhibiting increasedlearning speed after expert trajectories become available."^^schema:Text ;
    schema:author "Faraz Torabi"^^schema:Person,
        "Garrett Warnell"^^schema:Person,
        "Peter Stone"^^schema:Person ;
    schema:dateModified "2018-05-11T21:48:52Z"^^schema:DateTime ;
    schema:datePublished "2018-05-04T22:36:58Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Behavioral Cloning from Observation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.01954v2"^^schema:URL .

<1265> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we tackle the problem of pose guided person image generation,which aims to transfer a person image from the source pose to a novel targetpose while maintaining the source appearance. Given the inefficiency ofstandard CNNs in handling large spatial transformation, we propose astructure-aware flow based method for high-quality person image generation.Specifically, instead of learning the complex overall pose changes of humanbody, we decompose the human body into different semantic parts (e.g., head,torso, and legs) and apply different networks to predict the flow fields forthese parts separately. Moreover, we carefully design the network modules toeffectively capture the local and global semantic correlations of featureswithin and among the human parts respectively. Extensive experimental resultsshow that our method can generate high-quality results under large posediscrepancy and outperforms state-of-the-art methods in both qualitative andquantitative comparisons."^^schema:Text ;
    schema:author "Jilin Tang"^^schema:Person,
        "Kun Zhou"^^schema:Person,
        "Mengmeng Wang"^^schema:Person,
        "Tianjia Shao"^^schema:Person,
        "Yi Yuan"^^schema:Person,
        "Yong Liu"^^schema:Person ;
    schema:dateModified "2021-02-05T03:07:57Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T03:07:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Structure-aware Person Image Generation with Pose Decomposition and  Semantic Correlation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02972v1"^^schema:URL .

<1266> a schema:ScholarlyArticle ;
    schema:abstract "Machine reading comprehension (MRC) is the task that asks a machine to answerquestions based on a given context. For Chinese MRC, due to the non-literal andnon-compositional semantic characteristics, Chinese idioms pose uniquechallenges for machines to understand. Previous studies tend to treat idiomsseparately without fully exploiting the relationship among them. In this paper,we first define the concept of literal meaning coverage to measure theconsistency between semantics and literal meanings for Chinese idioms. With thedefinition, we prove that the literal meanings of many idioms are far fromtheir semantics, and we also verify that the synonymic relationship canmitigate this inconsistency, which would be beneficial for idiom comprehension.Furthermore, to fully utilize the synonymic relationship, we propose thesynonym knowledge enhanced reader. Specifically, for each idiom, we firstconstruct a synonym graph according to the annotations from a high-qualitysynonym dictionary or the cosine similarity between the pre-trained idiomembeddings and then incorporate the graph attention network and gate mechanismto encode the graph. Experimental results on ChID, a large-scale Chinese idiomreading comprehension dataset, show that our model achieves state-of-the-artperformance."^^schema:Text ;
    schema:author "Jiali Zeng"^^schema:Person,
        "Kun Tao"^^schema:Person,
        "Ran Wang"^^schema:Person,
        "Siyu Long"^^schema:Person,
        "Xin-Yu Dai"^^schema:Person ;
    schema:dateModified "2020-11-09T15:28:53Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T15:28:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Synonym Knowledge Enhanced Reader for Chinese Idiom Reading  Comprehension"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.04499v1"^^schema:URL .

<1267> a schema:ScholarlyArticle ;
    schema:abstract "Existing neural methods for data-to-text generation are still struggling toproduce long and diverse texts: they are insufficient to model input datadynamically during generation, to capture inter-sentence coherence, or togenerate diversified expressions. To address these issues, we propose aPlanning-based Hierarchical Variational Model (PHVM). Our model first plans asequence of groups (each group is a subset of input items to be covered by asentence) and then realizes each sentence conditioned on the planning resultand the previously generated context, thereby decomposing long text generationinto dependent sentence generation sub-tasks. To capture expression diversity,we devise a hierarchical latent structure where a global planning latentvariable models the diversity of reasonable planning and a sequence of locallatent variables controls sentence realization. Experiments show that our modeloutperforms state-of-the-art baselines in long and diverse text generation."^^schema:Text ;
    schema:author "Jiangtao Wen"^^schema:Person,
        "Minlie Huang"^^schema:Person,
        "Wenfei Xu"^^schema:Person,
        "Xiaoyan Zhu"^^schema:Person,
        "Zhihong Shao"^^schema:Person ;
    schema:dateModified "2019-08-25T01:57:50Z"^^schema:DateTime ;
    schema:datePublished "2019-08-19T06:20:38Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Long and Diverse Text Generation with Planning-based Hierarchical  Variational Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.06605v2"^^schema:URL .

<1268> a schema:ScholarlyArticle ;
    schema:abstract "Social biases based on gender, race, etc. have been shown to pollute machinelearning (ML) pipeline predominantly via biased training datasets.Crowdsourcing, a popular cost-effective measure to gather labeled trainingdatasets, is not immune to the inherent social biases of crowd workers. Toensure such social biases aren't passed onto the curated datasets, it'simportant to know how biased each crowd worker is. In this work, we propose anew method based on counterfactual fairness to quantify the degree of inherentsocial bias in each crowd worker. This extra information can be leveragedtogether with individual worker responses to curate a less biased dataset."^^schema:Text ;
    schema:author "Bhavya Ghai"^^schema:Person,
        "Klaus Mueller"^^schema:Person,
        "Q. Vera Liao"^^schema:Person,
        "Yunfeng Zhang"^^schema:Person ;
    schema:dateModified "2020-04-04T21:41:55Z"^^schema:DateTime ;
    schema:datePublished "2020-04-04T21:41:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.HC"^^schema:Text ;
    schema:headline "Measuring Social Biases of Crowd Workers using Counterfactual Queries"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.02028v1"^^schema:URL .

<1269> a schema:ScholarlyArticle ;
    schema:abstract "The typical bottom-up human pose estimation framework includes two stages,keypoint detection and grouping. Most existing works focus on developinggrouping algorithms, e.g., associative embedding, and pixel-wise keypointregression that we adopt in our approach. We present several schemes that arerarely or unthoroughly studied before for improving keypoint detection andgrouping (keypoint regression) performance. First, we exploit the keypointheatmaps for pixel-wise keypoint regression instead of separating them forimproving keypoint regression. Second, we adopt a pixel-wise spatialtransformer network to learn adaptive representations for handling the scaleand orientation variance to further improve keypoint regression quality. Last,we present a joint shape and heatvalue scoring scheme to promote the estimatedposes that are more likely to be true poses. Together with the tradeoff heatmapestimation loss for balancing the background and keypoint pixels and thusimproving heatmap estimation quality, we get the state-of-the-art bottom-uphuman pose estimation result. Code is available athttps://github.com/HRNet/HRNet-Bottom-up-Pose-Estimation."^^schema:Text ;
    schema:author "Bin Xiao"^^schema:Person,
        "Depu Meng"^^schema:Person,
        "Dong Liu"^^schema:Person,
        "Jingdong Wang"^^schema:Person,
        "Ke Sun"^^schema:Person,
        "Zhaoxiang Zhang"^^schema:Person,
        "Zigang Geng"^^schema:Person ;
    schema:dateModified "2020-06-28T01:14:59Z"^^schema:DateTime ;
    schema:datePublished "2020-06-28T01:14:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Bottom-Up Human Pose Estimation by Ranking Heatmap-Guided Adaptive  Keypoint Estimates"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.15480v1"^^schema:URL .

<127> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose to employ the convolutional neural network (CNN)for the image question answering (QA). Our proposed CNN provides an end-to-endframework with convolutional architectures for learning not only the image andquestion representations, but also their inter-modal interactions to producethe answer. More specifically, our model consists of three CNNs: one image CNNto encode the image content, one sentence CNN to compose the words of thequestion, and one multimodal convolution layer to learn their jointrepresentation for the classification in the space of candidate answer words.We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QAdatasets, which are two benchmark datasets for the image QA, with theperformances significantly outperforming the state-of-the-art."^^schema:Text ;
    schema:author "Hang Li"^^schema:Person,
        "Lin Ma"^^schema:Person,
        "Zhengdong Lu"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2015-11-13T09:54:59Z"^^schema:DateTime ;
    schema:datePublished "2015-06-01T03:09:49Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning to Answer Questions From Image Using Convolutional Neural  Network"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.00333v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15810845386202392485&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1270> a schema:ScholarlyArticle ;
    schema:abstract "Designing rewards for Reinforcement Learning (RL) is challenging because itneeds to convey the desired task, be efficient to optimize, and be easy tocompute. The latter is particularly problematic when applying RL to robotics,where detecting whether the desired configuration is reached might requireconsiderable supervision and instrumentation. Furthermore, we are ofteninterested in being able to reach a wide range of configurations, hence settingup a different reward every time might be unpractical. Methods like HindsightExperience Replay (HER) have recently shown promise to learn policies able toreach many goals, without the need of a reward. Unfortunately, without trickslike resetting to points along the trajectory, HER might require many samplesto discover how to reach certain areas of the state-space. In this work weinvestigate different approaches to incorporate demonstrations to drasticallyspeed up the convergence to a policy able to reach any goal, also surpassingthe performance of an agent trained with other Imitation Learning algorithms.Furthermore, we show our method can also be used when the available experttrajectories do not contain the actions, which can leverage kinesthetic orthird person demonstration. The code is available athttps://sites.google.com/view/goalconditioned-il/."^^schema:Text ;
    schema:author "Carlos Florensa"^^schema:Person,
        "Mariano Phielipp"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Yiming Ding"^^schema:Person ;
    schema:dateModified "2020-05-27T06:47:07Z"^^schema:DateTime ;
    schema:datePublished "2019-06-13T17:39:52Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Goal-conditioned Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.05838v3"^^schema:URL .

<1271> a schema:ScholarlyArticle ;
    schema:abstract "The standard interpretation of importance-weighted autoencoders is that theymaximize a tighter lower bound on the marginal likelihood than the standardevidence lower bound. We give an alternate interpretation of this procedure:that it optimizes the standard variational lower bound, but using a morecomplex distribution. We formally derive this result, present a tighter lowerbound, and visualize the implicit importance-weighted distribution."^^schema:Text ;
    schema:author "Chris Cremer"^^schema:Person,
        "David Duvenaud"^^schema:Person,
        "Quaid Morris"^^schema:Person ;
    schema:dateModified "2017-08-15T01:56:16Z"^^schema:DateTime ;
    schema:datePublished "2017-04-10T15:45:41Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Reinterpreting Importance-Weighted Autoencoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1704.02916v2"^^schema:URL .

<1272> a schema:ScholarlyArticle ;
    schema:abstract "Nigerian Pidgin is arguably the most widely spoken language in Nigeria.Variants of this language are also spoken across West and Central Africa,making it a very important language. This work aims to establish supervised andunsupervised neural machine translation (NMT) baselines between English andNigerian Pidgin. We implement and compare NMT models with differenttokenization methods, creating a solid foundation for future works."^^schema:Text ;
    schema:author "Kelechi Ogueji"^^schema:Person,
        "Orevaoghene Ahia"^^schema:Person ;
    schema:dateModified "2020-03-27T22:40:01Z"^^schema:DateTime ;
    schema:datePublished "2020-03-27T22:40:01Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Towards Supervised and Unsupervised Neural Machine Translation Baselines  for Nigerian Pidgin"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.12660v1"^^schema:URL .

<1273> a schema:ScholarlyArticle ;
    schema:abstract "An online resource scheduling framework is proposed for minimizing the sum ofweighted task latency for all the Internet of things (IoT) users, by optimizingoffloading decision, transmission power and resource allocation in thelarge-scale mobile edge computing (MEC) system. Towards this end, a deepreinforcement learning (DRL) based solution is proposed, which includes thefollowing components. Firstly, a related and regularized stacked auto encoder(2r-SAE) with unsupervised learning is applied to perform data compression andrepresentation for high dimensional channel quality information (CQI) data,which can reduce the state space for DRL. Secondly, we present an adaptivesimulated annealing based approach (ASA) as the action search method of DRL, inwhich an adaptive h-mutation is used to guide the search direction and anadaptive iteration is proposed to enhance the search efficiency during the DRLprocess. Thirdly, a preserved and prioritized experience replay (2p-ER) isintroduced to assist the DRL to train the policy network and find the optimaloffloading policy. Numerical results are provided to demonstrate that theproposed algorithm can achieve near-optimal performance while significantlydecreasing the computational time compared with existing benchmarks."^^schema:Text ;
    schema:author "Cunhua Pan"^^schema:Person,
        "Feibo Jiang"^^schema:Person,
        "Kezhi Wang"^^schema:Person,
        "Kun Yang"^^schema:Person,
        "Li Dong"^^schema:Person ;
    schema:dateModified "2020-04-14T21:47:24Z"^^schema:DateTime ;
    schema:datePublished "2020-01-24T23:01:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stacked Auto Encoder Based Deep Reinforcement Learning for Online  Resource Scheduling in Large-Scale MEC Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.09223v2"^^schema:URL .

<1274> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, ride-hailing services have been increasingly prevalent asthey provide huge convenience for passengers. As a fundamental problem, thetimely prediction of passenger demands in different regions is vital foreffective traffic flow control and route planning. As both spatial and temporalpatterns are indispensable passenger demand prediction, relevant research hasevolved from pure time series to graph-structured data for modeling historicalpassenger demand data, where a snapshot graph is constructed for each time slotby connecting region nodes via different relational edges (e.g.,origin-destination relationship, geographical distance, etc.). Consequently,the spatiotemporal passenger demand records naturally carry dynamic patterns inthe constructed graphs, where the edges also encode important information aboutthe directions and volume (i.e., weights) of passenger demands between twoconnected regions. However, existing graph-based solutions fail tosimultaneously consider those three crucial aspects of dynamic, directed, andweighted (DDW) graphs, leading to limited expressiveness when learning graphrepresentations for passenger demand prediction. Therefore, we propose a novelspatiotemporal graph attention network, namely Gallat (Graph prediction withall attention) as a solution. In Gallat, by comprehensively incorporating thosethree intrinsic properties of DDW graphs, we build three attention layers tofully capture the spatiotemporal dependencies among different regions acrossall historical time slots. Moreover, the model employs a subtask to conductpretraining so that it can obtain accurate results more quickly. We evaluatethe proposed model on real-world datasets, and our experimental resultsdemonstrate that Gallat outperforms the state-of-the-art approaches."^^schema:Text ;
    schema:author "Ben Wang"^^schema:Person,
        "Chunyang Liu"^^schema:Person,
        "Hongzhi Yin"^^schema:Person,
        "Jie Xu"^^schema:Person,
        "Tianyu Wo"^^schema:Person,
        "Tong Chen"^^schema:Person,
        "Yuandong Wang"^^schema:Person ;
    schema:dateModified "2021-01-04T03:32:01Z"^^schema:DateTime ;
    schema:datePublished "2021-01-04T03:32:01Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Passenger Mobility Prediction via Representation Learning for Dynamic  Directed and Weighted Graph"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.00752v1"^^schema:URL .

<1275> a schema:ScholarlyArticle ;
    schema:abstract "This paper investigates the idea of encoding object-centered representationsin the design of the reward function and policy architectures of alanguage-guided reinforcement learning agent. This is done using a combinationof object-wise permutation invariant networks inspired from Deep Sets andgated-attention mechanisms. In a 2D procedurally-generated world where agentstargeting goals in natural language navigate and interact with objects, we showthat these architectures demonstrate strong generalization capacities toout-of-distribution goals. We study the generalization to varying numbers ofobjects at test time and further extend the object-centered architectures togoals involving relational reasoning."^^schema:Text ;
    schema:author "Clément Moulin-Frier"^^schema:Person,
        "Cédric Colas"^^schema:Person,
        "Laetitia Teodorescu"^^schema:Person,
        "Pierre-Yves Oudeyer"^^schema:Person,
        "Tristan Karch"^^schema:Person ;
    schema:dateModified "2020-03-20T18:22:40Z"^^schema:DateTime ;
    schema:datePublished "2020-03-20T18:22:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Sets for Generalization in RL"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.09443v1"^^schema:URL .

<1276> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning aims at searching the best policy model for decisionmaking, and has been shown powerful for sequential recommendations. Thetraining of the policy by reinforcement learning, however, is placed in anenvironment. In many real-world applications, however, the policy training inthe real environment can cause an unbearable cost, due to the exploration inthe environment. Environment reconstruction from the past data is thus anappealing way to release the power of reinforcement learning in theseapplications. The reconstruction of the environment is, basically, to extractthe casual effect model from the data. However, real-world applications areoften too complex to offer fully observable environment information. Therefore,quite possibly there are unobserved confounding variables lying behind thedata. The hidden confounder can obstruct an effective reconstruction of theenvironment. In this paper, by treating the hidden confounder as a hiddenpolicy, we propose a deconfounded multi-agent environment reconstruction(DEMER) approach in order to learn the environment together with the hiddenconfounder. DEMER adopts a multi-agent generative adversarial imitationlearning framework. It proposes to introduce the confounder embedded policy,and use the compatible discriminator for training the policies. We then applyDEMER in an application of driver program recommendation. We firstly use anartificial driver program recommendation environment, abstracted from the realapplication, to verify and analyze the effectiveness of DEMER. We then testDEMER in the real application of Didi Chuxing. Experiment results show thatDEMER can effectively reconstruct the hidden confounder, and thus can build theenvironment better. DEMER also derives a recommendation policy with asignificantly improved performance in the test phase of the real application."^^schema:Text ;
    schema:author "Jieping Ye"^^schema:Person,
        "Qingyang Li"^^schema:Person,
        "Wenjie Shang"^^schema:Person,
        "Yang Yu"^^schema:Person,
        "Yiping Meng"^^schema:Person,
        "Zhiwei Qin"^^schema:Person ;
    schema:dateModified "2019-07-12T10:13:05Z"^^schema:DateTime ;
    schema:datePublished "2019-07-12T10:13:05Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Environment Reconstruction with Hidden Confounders for Reinforcement  Learning based Recommendation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.06584v1"^^schema:URL .

<1277> a schema:ScholarlyArticle ;
    schema:abstract "As application demands for zeroth-order (gradient-free) optimizationaccelerate, the need for variance reduced and faster converging approaches isalso intensifying. This paper addresses these challenges by presenting: a) acomprehensive theoretical analysis of variance reduced zeroth-order (ZO)optimization, b) a novel variance reduced ZO algorithm, called ZO-SVRG, and c)an experimental evaluation of our approach in the context of two compellingapplications, black-box chemical material classification and generation ofadversarial examples from black-box deep neural network models. Our theoreticalanalysis uncovers an essential difficulty in the analysis of ZO-SVRG: theunbiased assumption on gradient estimates no longer holds. We prove thatcompared to its first-order counterpart, ZO-SVRG with a two-point randomgradient estimator could suffer an additional error of order $O(1/b)$, where$b$ is the mini-batch size. To mitigate this error, we propose two acceleratedversions of ZO-SVRG utilizing variance reduced gradient estimators, whichachieve the best rate known for ZO stochastic optimization (in terms ofiterations). Our extensive experimental results show that our approachesoutperform other state-of-the-art ZO algorithms, and strike a balance betweenthe convergence rate and the function query complexity."^^schema:Text ;
    schema:author "Bhavya Kailkhura"^^schema:Person,
        "Lisa Amini"^^schema:Person,
        "Paishun Ting"^^schema:Person,
        "Pin-Yu Chen"^^schema:Person,
        "Shiyu Chang"^^schema:Person,
        "Sijia Liu"^^schema:Person ;
    schema:dateModified "2018-06-07T17:02:19Z"^^schema:DateTime ;
    schema:datePublished "2018-05-25T21:18:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.10367v2"^^schema:URL .

<1278> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we tackle the problem of learning control policies for taskswhen provided with constraints in natural language. In contrast to instructionfollowing, language here is used not to specify goals, but rather to describesituations that an agent must avoid during its exploration of the environment.Specifying constraints in natural language also differs from the predominantparadigm in safe reinforcement learning, where safety criteria are enforced byhand-defined cost functions. While natural language allows for easy andflexible specification of safety constraints and budget limitations, itsambiguous nature presents a challenge when mapping these specifications intorepresentations that can be used by techniques for safe reinforcement learning.To address this, we develop a model that contains two components: (1) aconstraint interpreter to encode natural language constraints into vectorrepresentations capturing spatial and temporal information on forbidden states,and (2) a policy network that uses these representations to output a policywith minimal constraint violations. Our model is end-to-end differentiable andwe train it using a recently proposed algorithm for constrained policyoptimization. To empirically demonstrate the effectiveness of our approach, wecreate a new benchmark task for autonomous navigation with crowd-sourcedfree-form text specifying three different types of constraints. Our methodoutperforms several baselines by achieving 6-7 times higher returns and 76%fewer constraint violations on average. Dataset and code to reproduce ourexperiments are available at https://sites.google.com/view/polco-hazard-world/."^^schema:Text ;
    schema:author "Karthik Narasimhan"^^schema:Person,
        "Michael Hu"^^schema:Person,
        "Peter J. Ramadge"^^schema:Person,
        "Tsung-Yen Yang"^^schema:Person,
        "Yinlam Chow"^^schema:Person ;
    schema:dateModified "2020-10-11T03:41:56Z"^^schema:DateTime ;
    schema:datePublished "2020-10-11T03:41:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Safe Reinforcement Learning with Natural Language Constraints"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.05150v1"^^schema:URL .

<1279> a schema:ScholarlyArticle ;
    schema:abstract "Magnetic resonance (MR) protocols rely on several sequences to assesspathology and organ status properly. Despite advances in image analysis, wetend to treat each sequence, here termed modality, in isolation. Takingadvantage of the common information shared between modalities (an organ'sanatomy) is beneficial for multi-modality processing and learning. However, wemust overcome inherent anatomical misregistrations and disparities in signalintensity across the modalities to obtain this benefit. We present a methodthat offers improved segmentation accuracy of the modality of interest (over asingle input model), by learning to leverage information present in othermodalities, even if few (semi-supervised) or no (unsupervised) annotations areavailable for this specific modality. Core to our method is learning adisentangled decomposition into anatomical and imaging factors. Sharedanatomical factors from the different inputs are jointly processed and fused toextract more accurate segmentation masks. Image misregistrations are correctedwith a Spatial Transformer Network, which non-linearly aligns the anatomicalfactors. The imaging factor captures signal intensity characteristics acrossdifferent modality data and is used for image reconstruction, enablingsemi-supervised learning. Temporal and slice pairing between inputs are learneddynamically. We demonstrate applications in Late Gadolinium Enhanced (LGE) andBlood Oxygenation Level Dependent (BOLD) cardiac segmentation, as well as in T2abdominal segmentation. Code is available athttps://github.com/vios-s/multimodal_segmentation."^^schema:Text ;
    schema:author "Agisilaos Chartsias"^^schema:Person,
        "Chengjia Wang"^^schema:Person,
        "David E. Newby"^^schema:Person,
        "Giorgos Papanastasiou"^^schema:Person,
        "Rohan Dharmakumar"^^schema:Person,
        "Scott Semple"^^schema:Person,
        "Sotirios A. Tsaftaris"^^schema:Person ;
    schema:dateModified "2020-11-09T19:18:39Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T17:44:00Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Disentangle, align and fuse for multimodal and semi-supervised image  segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04417v5"^^schema:URL .

<128> a schema:ScholarlyArticle ;
    schema:abstract "We present an attention-based model for recognizing multiple objects inimages. The proposed model is a deep recurrent neural network trained withreinforcement learning to attend to the most relevant regions of the inputimage. We show that the model learns to both localize and recognize multipleobjects despite being given only class labels during training. We evaluate themodel on the challenging task of transcribing house number sequences fromGoogle Street View images and show that it is both more accurate than thestate-of-the-art convolutional networks and uses fewer parameters and lesscomputation."^^schema:Text ;
    schema:author "Jimmy Ba"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Volodymyr Mnih"^^schema:Person ;
    schema:commentCount "702"^^schema:Integer ;
    schema:dateModified "2015-04-23T16:49:23Z"^^schema:DateTime ;
    schema:datePublished "2014-12-24T20:58:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Multiple Object Recognition with Visual Attention"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.7755v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9270621198392182178&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1280> a schema:ScholarlyArticle ;
    schema:abstract "Efficient learning in the environment with sparse rewards is one of the mostimportant challenges in Deep Reinforcement Learning (DRL). In continuous DRLenvironments such as robotic arms control, Hindsight Experience Replay (HER)has been shown an effective solution. However, due to the brittleness ofdeterministic methods, HER and its variants typically suffer from a majorchallenge for stability and convergence, which significantly affects the finalperformance. This challenge severely limits the applicability of such methodsto complex real-world domains. To tackle this challenge, in this paper, wepropose Soft Hindsight Experience Replay (SHER), a novel approach based on HERand Maximum Entropy Reinforcement Learning (MERL), combining the failedexperiences reuse and maximum entropy probabilistic inference model. Weevaluate SHER on Open AI Robotic manipulation tasks with sparse rewards.Experimental results show that, in contrast to HER and its variants, ourproposed SHER achieves state-of-the-art performance, especially in thedifficult HandManipulation tasks. Furthermore, our SHER method is more stable,achieving very similar performance across different random seeds."^^schema:Text ;
    schema:author "Houqiang Li"^^schema:Person,
        "Liansheng Zhuang"^^schema:Person,
        "Qiwei He"^^schema:Person ;
    schema:dateModified "2020-02-06T03:57:04Z"^^schema:DateTime ;
    schema:datePublished "2020-02-06T03:57:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Soft Hindsight Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.02089v1"^^schema:URL .

<1281> a schema:ScholarlyArticle ;
    schema:abstract "Despite being impactful on a variety of problems and applications, thegenerative adversarial nets (GANs) are remarkably difficult to train. Thisissue is formally analyzed by \\cite{arjovsky2017towards}, who also propose analternative direction to avoid the caveats in the minmax two-player training ofGANs. The corresponding algorithm, called Wasserstein GAN (WGAN), hinges on the1-Lipschitz continuity of the discriminator. In this paper, we propose a novelapproach to enforcing the Lipschitz continuity in the training procedure ofWGANs. Our approach seamlessly connects WGAN with one of the recentsemi-supervised learning methods. As a result, it gives rise to not only betterphoto-realistic samples than the previous methods but also state-of-the-artsemi-supervised learning results. In particular, our approach gives rise to theinception score of more than 5.0 with only 1,000 CIFAR-10 images and is thefirst that exceeds the accuracy of 90% on the CIFAR-10 dataset using only 4,000labeled images, to the best of our knowledge."^^schema:Text ;
    schema:author "Boqing Gong"^^schema:Person,
        "Liqiang Wang"^^schema:Person,
        "Wei Lu"^^schema:Person,
        "Xiang Wei"^^schema:Person,
        "Zixia Liu"^^schema:Person ;
    schema:dateModified "2018-03-05T08:00:39Z"^^schema:DateTime ;
    schema:datePublished "2018-03-05T08:00:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improving the Improved Training of Wasserstein GANs: A Consistency Term  and Its Dual Effect"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.01541v1"^^schema:URL .

<1282> a schema:ScholarlyArticle ;
    schema:abstract "Episodic learning is a popular practice among researchers and practitionersinterested in few-shot learning. It consists of organising training in a seriesof learning problems, each relying on small \"support\" and \"query\" sets to mimicthe few-shot circumstances encountered during evaluation. In this paper, weinvestigate the usefulness of episodic learning in Prototypical Networks andMatching Networks, two of the most popular algorithms making use of thispractice. Surprisingly, in our experiments we found that, for Prototypical andMatching Networks, it is detrimental to use the episodic learning strategy ofseparating training samples between support and query set, as it is adata-inefficient way to exploit training batches. These \"non-episodic\"variants, which are closely related to the classic Neighbourhood ComponentAnalysis, reliably improve over their episodic counterparts in multipledatasets, achieving an accuracy that (in the case of Prototypical Networks) iscompetitive with the state-of-the-art, despite being extremely simple."^^schema:Text ;
    schema:author "Luca Bertinetto"^^schema:Person,
        "Steinar Laenen"^^schema:Person ;
    schema:dateModified "2020-12-17T18:52:47Z"^^schema:DateTime ;
    schema:datePublished "2020-12-17T18:52:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "On Episodes, Prototypical Networks, and Few-shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.09831v1"^^schema:URL .

<1283> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent Neural Networks (RNNs) play a major role in the field of sequentiallearning, and have outperformed traditional algorithms on many benchmarks.Training deep RNNs still remains a challenge, and most of the state-of-the-artmodels are structured with a transition depth of 2-4 layers. Recurrent HighwayNetworks (RHNs) were introduced in order to tackle this issue. These haveachieved state-of-the-art performance on a few benchmarks using a depth of 10layers. However, the performance of this architecture suffers from abottleneck, and ceases to improve when an attempt is made to add more layers.In this work, we analyze the causes for this, and postulate that the mainsource is the way that the information flows through time. We introduce a noveland simple variation for the RHN cell, called Highway State Gating (HSG), whichallows adding more layers, while continuing to improve performance. By using agating mechanism for the state, we allow the net to \"choose\" whether to passinformation directly through time, or to gate it. This mechanism also allowsthe gradient to back-propagate directly through time and, therefore, results ina slightly faster convergence. We use the Penn Treebank (PTB) dataset as aplatform for empirical proof of concept. Empirical results show that theimprovement due to Highway State Gating is for all depths, and as the depthincreases, the improvement also increases."^^schema:Text ;
    schema:author "Haim Permuter"^^schema:Person,
        "Ron Shoham"^^schema:Person ;
    schema:dateModified "2018-05-23T15:53:10Z"^^schema:DateTime ;
    schema:datePublished "2018-05-23T15:53:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Highway State Gating for Recurrent Highway Networks: improving  information flow through time"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.09238v1"^^schema:URL .

<1284> a schema:ScholarlyArticle ;
    schema:abstract "Attention-based end-to-end text-to-speech synthesis (TTS) is superior toconventional statistical methods in many ways. Transformer-based TTS is one ofsuch successful implementations. While Transformer TTS models the speech framesequence well with a self-attention mechanism, it does not associate input textwith output utterances from a syntactic point of view at sentence level. Wepropose a novel neural TTS model, denoted as GraphSpeech, that is formulatedunder graph neural network framework. GraphSpeech encodes explicitly thesyntactic relation of input lexical tokens in a sentence, and incorporates suchinformation to derive syntactically motivated character embeddings for TTSattention mechanism. Experiments show that GraphSpeech consistently outperformsthe Transformer TTS baseline in terms of spectrum and prosody rendering ofutterances."^^schema:Text ;
    schema:author "Berrak Sisman"^^schema:Person,
        "Haizhou Li"^^schema:Person,
        "Rui Liu"^^schema:Person ;
    schema:dateModified "2021-02-08T07:18:06Z"^^schema:DateTime ;
    schema:datePublished "2020-10-23T14:14:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "GraphSpeech: Syntax-Aware Graph Attention Network For Neural Speech  Synthesis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.12423v2"^^schema:URL .

<1285> a schema:ScholarlyArticle ;
    schema:abstract "Predicting future states or actions of a given system remains a fundamental,yet unsolved challenge of intelligence, especially in the scope of complex andnon-deterministic scenarios, such as modeling behavior of humans. Existingapproaches provide results under strong assumptions concerning unimodality offuture states, or, at best, assuming specific probability distributions thatoften poorly fit to real-life conditions. In this work we introduce a robustand flexible probabilistic framework that allows to model future predictionswith virtually no constrains regarding the modality or underlying probabilitydistribution. To achieve this goal, we leverage a hypernetwork architecture andtrain a continuous normalizing flow model. The resulting method dubbed RegFlowachieves state-of-the-art results on several benchmark datasets, outperformingcompeting approaches by a significant margin."^^schema:Text ;
    schema:author "Jacek Tabor"^^schema:Person,
        "Maciej Zięba"^^schema:Person,
        "Marcin Przewięźlikowski"^^schema:Person,
        "Marek Śmieja"^^schema:Person,
        "Przemysław Spurek"^^schema:Person,
        "Tomasz Trzcinski"^^schema:Person ;
    schema:dateModified "2020-11-30T08:45:37Z"^^schema:DateTime ;
    schema:datePublished "2020-11-30T08:45:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "RegFlow: Probabilistic Flow-based Regression for Future Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.14620v1"^^schema:URL .

<1286> a schema:ScholarlyArticle ;
    schema:abstract "Research in analysis of microblogging platforms is experiencing a renewedsurge with a large number of works applying representation learning models forapplications like sentiment analysis, semantic textual similarity computation,hashtag prediction, etc. Although the performance of the representationlearning models has been better than the traditional baselines for such tasks,little is known about the elementary properties of a tweet encoded within theserepresentations, or why particular representations work better for certaintasks. Our work presented here constitutes the first step in opening theblack-box of vector embeddings for tweets. Traditional feature engineeringmethods for high-level applications have exploited various elementaryproperties of tweets. We believe that a tweet representation is effective foran application because it meticulously encodes the application-specificelementary properties of tweets. To understand the elementary propertiesencoded in a tweet representation, we evaluate the representations on theaccuracy to which they can model each of those properties such as tweet length,presence of particular words, hashtags, mentions, capitalization, etc. Oursystematic extensive study of nine supervised and four unsupervised tweetrepresentations against most popular eight textual and five social elementaryproperties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors(STV) best encode the textual and social properties of tweets respectively.FastText is the best model for low resource settings, providing very littledegradation with reduction in embedding size. Finally, we draw interestinginsights by correlating the model performance obtained for elementary propertyprediction tasks with the highlevel downstream applications."^^schema:Text ;
    schema:author "J Ganesh"^^schema:Person,
        "Manish Gupta"^^schema:Person,
        "Vasudeva Varma"^^schema:Person ;
    schema:dateModified "2017-06-21T06:59:17Z"^^schema:DateTime ;
    schema:datePublished "2017-04-04T07:24:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Interpretation of Semantic Tweet Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1704.00898v2"^^schema:URL .

<1287> a schema:ScholarlyArticle ;
    schema:abstract "Neural ordinary differential equations (NODEs) have recently attractedincreasing attention; however, their empirical performance on benchmark tasks(e.g. image classification) are significantly inferior to discrete-layermodels. We demonstrate an explanation for their poorer performance is theinaccuracy of existing gradient estimation methods: the adjoint method hasnumerical errors in reverse-mode integration; the naive method directlyback-propagates through ODE solvers, but suffers from a redundantly deepcomputation graph when searching for the optimal stepsize. We propose theAdaptive Checkpoint Adjoint (ACA) method: in automatic differentiation, ACAapplies a trajectory checkpoint strategy which records the forward-modetrajectory as the reverse-mode trajectory to guarantee accuracy; ACA deletesredundant components for shallow computation graphs; and ACA supports adaptivesolvers. On image classification tasks, compared with the adjoint and naivemethod, ACA achieves half the error rate in half the training time; NODEtrained with ACA outperforms ResNet in both accuracy and test-retestreliability. On time-series modeling, ACA outperforms competing methods.Finally, in an example of the three-body problem, we show NODE with ACA canincorporate physical knowledge to achieve better accuracy. We provide thePyTorch implementation of ACA:\\url{https://github.com/juntang-zhuang/torch-ACA}."^^schema:Text ;
    schema:author "James Duncan"^^schema:Person,
        "Juntang Zhuang"^^schema:Person,
        "Nicha Dvornek"^^schema:Person,
        "Sekhar Tatikonda"^^schema:Person,
        "Xenophon Papademetris"^^schema:Person,
        "Xiaoxiao Li"^^schema:Person ;
    schema:dateModified "2020-06-03T19:48:00Z"^^schema:DateTime ;
    schema:datePublished "2020-06-03T19:48:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adaptive Checkpoint Adjoint Method for Gradient Estimation in Neural ODE"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.02493v1"^^schema:URL .

<1288> a schema:ScholarlyArticle ;
    schema:abstract "This work proposes a novel method based on a pseudo-parabolic diffusionprocess to be employed for texture recognition. The proposed operator isapplied over a range of time scales giving rise to a family of imagestransformed by nonlinear filters. Therefore each of those images are encoded bya local descriptor (we use local binary patterns for that purpose) and they aresummarized by a simple histogram, yielding in this way the image featurevector. The proposed approach is tested on the classification of wellestablished benchmark texture databases and on a practical task of plantspecies recognition. In both cases, it is compared with severalstate-of-the-art methodologies employed for texture recognition. Our proposaloutperforms those methods in terms of classification accuracy, confirming itscompetitiveness. The good performance can be justified to a large extent by theability of the pseudo-parabolic operator to smooth possibly noisy detailsinside homogeneous regions of the image at the same time that it preservesdiscontinuities that convey critical information for the object description.Such results also confirm that model-based approaches like the proposed one canstill be competitive with the omnipresent learning-based approaches, especiallywhen the user does not have access to a powerful computational structure and alarge amount of labeled data for training."^^schema:Text ;
    schema:author "Eduardo Abreu"^^schema:Person,
        "Jardel Vieira"^^schema:Person,
        "Joao B. Florindo"^^schema:Person ;
    schema:dateModified "2021-01-24T00:39:00Z"^^schema:DateTime ;
    schema:datePublished "2020-11-14T00:04:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NA"^^schema:Text,
        "math.NA"^^schema:Text ;
    schema:headline "Texture image classification based on a pseudo-parabolic diffusion model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.07173v2"^^schema:URL .

<1289> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning (RL) enables agents to take decision based on a rewardfunction. However, in the process of learning, the choice of values forlearning algorithm parameters can significantly impact the overall learningprocess. In this paper, we use a genetic algorithm (GA) to find the values ofparameters used in Deep Deterministic Policy Gradient (DDPG) combined withHindsight Experience Replay (HER), to help speed up the learning agent. We usedthis method on fetch-reach, slide, push, pick and place, and door opening inrobotic manipulation tasks. Our experimental evaluation shows that our methodleads to better performance, faster than the original algorithm."^^schema:Text ;
    schema:author "Adarsh Sehgal"^^schema:Person,
        "Hai Nguyen"^^schema:Person,
        "Hung Manh La"^^schema:Person,
        "Sushil J. Louis"^^schema:Person ;
    schema:dateModified "2019-02-19T20:11:08Z"^^schema:DateTime ;
    schema:datePublished "2019-02-19T20:11:08Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning using Genetic Algorithm for Parameter  Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.04100v1"^^schema:URL .

<129> a schema:ScholarlyArticle ;
    schema:abstract "We introduce Group equivariant Convolutional Neural Networks (G-CNNs), anatural generalization of convolutional neural networks that reduces samplecomplexity by exploiting symmetries. G-CNNs use G-convolutions, a new type oflayer that enjoys a substantially higher degree of weight sharing than regularconvolution layers. G-convolutions increase the expressive capacity of thenetwork without increasing the number of parameters. Group convolution layersare easy to use and can be implemented with negligible computational overheadfor discrete groups generated by translations, reflections and rotations.G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST."^^schema:Text ;
    schema:author "Max Welling"^^schema:Person,
        "Taco S. Cohen"^^schema:Person ;
    schema:commentCount "459"^^schema:Integer ;
    schema:dateModified "2016-06-03T10:54:16Z"^^schema:DateTime ;
    schema:datePublished "2016-02-24T16:17:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Group Equivariant Convolutional Networks"^^schema:Text ;
    schema:publisher "ICML, 2990-2999"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.07576v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2225506382057001717&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1290> a schema:ScholarlyArticle ;
    schema:abstract "Chinese parsing has traditionally been solved by three pipeline systemsincluding word-segmentation, part-of-speech tagging and dependency parsingmodules. In this paper, we propose an end-to-end Chinese parsing model based oncharacter inputs which jointly learns to output word segmentation,part-of-speech tags and dependency structures. In particular, our parsing modelrelies on word-char graph attention networks, which can enrich the characterinputs with external word knowledge. Experiments on three Chinese parsingbenchmark datasets show the effectiveness of our models, achieving thestate-of-the-art results on end-to-end Chinese parsing."^^schema:Text ;
    schema:author "Yuan Zhang"^^schema:Person,
        "Yue Zhang"^^schema:Person,
        "Zhiyang Teng"^^schema:Person ;
    schema:dateModified "2020-12-08T12:24:36Z"^^schema:DateTime ;
    schema:datePublished "2020-12-08T12:24:36Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "End-to-End Chinese Parsing Exploiting Lexicons"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.04395v1"^^schema:URL .

<1291> a schema:ScholarlyArticle ;
    schema:abstract "Instantaneous and on demand accuracy-efficiency trade-off has been recentlyexplored in the context of neural networks slimming. In this paper, we proposea flexible quantization strategy, termed Switchable Precision neural Networks(SP-Nets), to train a shared network capable of operating at multiplequantization levels. At runtime, the network can adjust its precision on thefly according to instant memory, latency, power consumption and accuracydemands. For example, by constraining the network weights to 1-bit withswitchable precision activations, our shared network spans from BinaryConnectto Binarized Neural Network, allowing to perform dot-products using onlysummations or bit operations. In addition, a self-distillation scheme isproposed to increase the performance of the quantized switches. We tested ourapproach with three different quantizers and demonstrate the performance ofSP-Nets against independently trained quantized models in classificationaccuracy for Tiny ImageNet and ImageNet datasets using ResNet-18 and MobileNetarchitectures."^^schema:Text ;
    schema:author "Bohan Zhuang"^^schema:Person,
        "Ian Reid"^^schema:Person,
        "Luis Guerra"^^schema:Person,
        "Tom Drummond"^^schema:Person ;
    schema:dateModified "2020-02-07T14:43:44Z"^^schema:DateTime ;
    schema:datePublished "2020-02-07T14:43:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Switchable Precision Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.02815v1"^^schema:URL .

<1292> a schema:ScholarlyArticle ;
    schema:abstract "Pose-guided person image generation and animation aim to transform a sourceperson image to target poses. These tasks require spatial manipulation ofsource data. However, Convolutional Neural Networks are limited by the lack ofability to spatially transform the inputs. In this paper, we propose adifferentiable global-flow local-attention framework to reassemble the inputsat the feature level. This framework first estimates global flow fields betweensources and targets. Then, corresponding local source feature patches aresampled with content-aware local attention coefficients. We show that ourframework can spatially transform the inputs in an efficient manner. Meanwhile,we further model the temporal consistency for the person image animation taskto generate coherent videos. The experiment results of both image generationand animation tasks demonstrate the superiority of our model. Besides,additional results of novel view synthesis and face image animation show thatour model is applicable to other tasks requiring spatial transformation. Thesource code of our project is available athttps://github.com/RenYurui/Global-Flow-Local-Attention."^^schema:Text ;
    schema:author "Ge Li"^^schema:Person,
        "Shan Liu"^^schema:Person,
        "Thomas H. Li"^^schema:Person,
        "Yurui Ren"^^schema:Person ;
    schema:dateModified "2020-08-27T08:59:44Z"^^schema:DateTime ;
    schema:datePublished "2020-08-27T08:59:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Spatial Transformation for Pose-Guided Person Image Generation and  Animation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.12606v1"^^schema:URL .

<1293> a schema:ScholarlyArticle ;
    schema:abstract "A privacy-preserving framework in which a computational resource providerreceives encrypted data from a client and returns prediction results withoutdecrypting the data, i.e., oblivious neural network or encrypted prediction,has been studied in machine learning that provides prediction services. In thiswork, we present MOBIUS (Model-Oblivious BInary neUral networkS), a new systemthat combines Binarized Neural Networks (BNNs) and secure computation based onsecret sharing as tools for scalable and fast privacy-preserving machinelearning. BNNs improve computational performance by binarizing values intraining to $-1$ and $+1$, while secure computation based on secret sharingprovides fast and various computations under encrypted forms via modulooperations with a short bit length. However, combining these tools is nottrivial because their operations have different algebraic structures and theuse of BNNs downgrades prediction accuracy in general. MOBIUS uses improvedprocedures of BNNs and secure computation that have compatible algebraicstructures without downgrading prediction accuracy. We created animplementation of MOBIUS in C++ using the ABY library (NDSS 2015). We thenconducted experiments using the MNIST dataset, and the results show that MOBIUScan return a prediction within 0.76 seconds, which is six times faster thanSecureML (IEEE S\\&amp;P 2017). MOBIUS allows a client to request for encryptedprediction and allows a trainer to obliviously publish an encrypted model to acloud provided by a computational resource provider, i.e., without revealingthe original model itself to the provider."^^schema:Text ;
    schema:author "Goichiro Hanaoka"^^schema:Person,
        "Hiromasa Kitai"^^schema:Person,
        "Jason Paul Cruz"^^schema:Person,
        "Naohisa Nishida"^^schema:Person,
        "Naoto Yanai"^^schema:Person,
        "Nuttapong Attrapadung"^^schema:Person,
        "Tadanori Teruya"^^schema:Person,
        "Takahiro Matsuda"^^schema:Person,
        "Tatsumi Oba"^^schema:Person,
        "Yuji Unagami"^^schema:Person ;
    schema:dateModified "2018-11-29T09:18:38Z"^^schema:DateTime ;
    schema:datePublished "2018-11-29T09:18:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text ;
    schema:headline "MOBIUS: Model-Oblivious Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.12028v1"^^schema:URL .

<1294> a schema:ScholarlyArticle ;
    schema:abstract "The options framework is a popular approach for building temporally extendedactions in reinforcement learning. In particular, the option-criticarchitecture provides general purpose policy gradient theorems for learningactions from scratch that are extended in time. However, past work makes thekey assumption that each of the components of option-critic has independentparameters. In this work we note that while this key assumption of the policygradient theorems of option-critic holds in the tabular case, it is alwaysviolated in practice for the deep function approximation setting. We thusreconsider this assumption and consider more general extensions ofoption-critic and hierarchical option-critic training that optimize for thefull architecture with each update. It turns out that not assuming parameterindependence challenges a belief in prior work that training the policy overoptions can be disentangled from the dynamics of the underlying options. Infact, learning can be sped up by focusing the policy over options on stateswhere options are actually likely to terminate. We put our new algorithms tothe test in application to sample efficient learning of Atari games, anddemonstrate significantly improved stability and faster convergence whenlearning long options."^^schema:Text ;
    schema:author "Clemens Rosenbaum"^^schema:Person,
        "Gerald Tesauro"^^schema:Person,
        "Ignacio Cases"^^schema:Person,
        "Matthew Riemer"^^schema:Person,
        "Miao Liu"^^schema:Person ;
    schema:dateModified "2020-02-06T06:19:04Z"^^schema:DateTime ;
    schema:datePublished "2019-12-31T16:49:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Role of Weight Sharing During Deep Option Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.13408v2"^^schema:URL .

<1295> a schema:ScholarlyArticle ;
    schema:abstract "Deep convolutional neural networks (DCNNs) have recently demonstratedhigh-quality results in single-image super-resolution (SR). DCNNs often sufferfrom over-parametrization and large amounts of redundancy, which results ininefficient inference and high memory usage, preventing massive applications onmobile devices. As a way to significantly reduce model size and computationtime, binarized neural network has only been shown to excel on semantic-leveltasks such as image classification and recognition. However, little effort ofnetwork quantization has been spent on image enhancement tasks like SR, asnetwork quantization is usually assumed to sacrifice pixel-level accuracy. Inthis work, we explore an network-binarization approach for SR tasks withoutsacrificing much reconstruction accuracy. To achieve this, we binarize theconvolutional filters in only residual blocks, and adopt a learnable weight foreach binary filter. We evaluate this idea on several state-of-the-artDCNN-based architectures, and show that binarized SR networks achievecomparable qualitative and quantitative results as their real-weightcounterparts. Moreover, the proposed binarized strategy could help reduce modelsize by 80% when applying on SRResNet, and could potentially speed up inferenceby 5 times."^^schema:Text ;
    schema:author "Hongyu Xiong"^^schema:Person,
        "Lizhuang Ma"^^schema:Person,
        "Yinglan Ma"^^schema:Person,
        "Zhe Hu"^^schema:Person ;
    schema:dateModified "2018-12-16T02:44:20Z"^^schema:DateTime ;
    schema:datePublished "2018-12-16T02:44:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Efficient Super Resolution Using Binarized Neural Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.06378v1"^^schema:URL .

<1296> a schema:ScholarlyArticle ;
    schema:abstract "Undirected graphical models are compact representations of joint probabilitydistributions over random variables. To solve inference tasks of interest,graphical models of arbitrary topology can be trained using empirical riskminimization. However, to solve inference tasks that were not seen duringtraining, these models (EGMs) often need to be re-trained. Instead, we proposean inference-agnostic adversarial training framework which produces aninfinitely-large ensemble of graphical models (AGMs). The ensemble is optimizedto generate data within the GAN framework, and inference is performed using afinite subset of these models. AGMs perform comparably with EGMs on inferencetasks that the latter were specifically optimized for. Most importantly, AGMsshow significantly better generalization to unseen inference tasks compared toEGMs, as well as deep neural architectures like GibbsNet and VAEAC which allowarbitrary conditioning. Finally, AGMs allow fast data sampling, competitivewith Gibbs sampling from EGMs."^^schema:Text ;
    schema:author "Adarsh K. Jeewajee"^^schema:Person,
        "Leslie P. Kaelbling"^^schema:Person ;
    schema:dateModified "2020-10-22T05:05:01Z"^^schema:DateTime ;
    schema:datePublished "2020-07-09T19:13:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarially-learned Inference via an Ensemble of Discrete Undirected  Graphical Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.05033v3"^^schema:URL .

<1297> a schema:ScholarlyArticle ;
    schema:abstract "End-to-end training of neural networks is a promising approach to automaticconstruction of dialog systems using a human-to-human dialog corpus. Recently,Vinyals et al. tested neural conversation models using OpenSubtitles. Lowe etal. released the Ubuntu Dialogue Corpus for researching unstructured multi-turndialogue systems. Furthermore, the approach has been extended to accomplishtask oriented dialogs to provide information properly with naturalconversation. For example, Ghazvininejad et al. proposed a knowledge groundedneural conversation model [3], where the research is aiming at combiningconversational dialogs with task-oriented knowledge using unstructured datasuch as Twitter data for conversation and Foursquare data for externalknowledge.However, the task is still limited to a restaurant informationservice, and has not yet been tested with a wide variety of dialog tasks. Inaddition, it is still unclear how to create intelligent dialog systems that canrespond like a human agent.  In consideration of these problems, we proposed a challenge track to the 6thdialog system technology challenges (DSTC6) using human-to-human dialog data tomimic human dialog behaviors. The focus of the challenge track is to trainend-to-end conversation models from human-to-human conversation and accomplishend-to-end dialog tasks in various situations assuming a customer service, inwhich a system plays a role of human agent and generates natural andinformative sentences in response to user's questions or comments given dialogcontext."^^schema:Text ;
    schema:author "Chiori Hori"^^schema:Person,
        "Takaaki Hori"^^schema:Person ;
    schema:dateModified "2018-01-30T17:33:49Z"^^schema:DateTime ;
    schema:datePublished "2017-06-22T18:00:34Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "End-to-end Conversation Modeling Track in DSTC6"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1706.07440v2"^^schema:URL .

<1298> a schema:ScholarlyArticle ;
    schema:abstract "To improve efficiency and reduce failures in autonomous vehicles, researchhas focused on developing robust and safe learning methods that take intoaccount disturbances in the environment. Existing literature in robustreinforcement learning poses the learning problem as a two player game betweenthe autonomous system and disturbances. This paper examines two differentalgorithms to solve the game, Robust Adversarial Reinforcement Learning andNeural Fictitious Self Play, and compares performance on an autonomous drivingscenario. We extend the game formulation to a semi-competitive setting anddemonstrate that the resulting adversary better captures meaningfuldisturbances that lead to better overall performance. The resulting robustpolicy exhibits improved driving efficiency while effectively reducingcollision rates compared to baseline control policies produced by traditionalreinforcement learning methods."^^schema:Text ;
    schema:author "Katherine Driggs-Campbell"^^schema:Person,
        "Mykel J. Kochenderfer"^^schema:Person,
        "Xiaobai Ma"^^schema:Person ;
    schema:dateModified "2019-03-08T19:44:29Z"^^schema:DateTime ;
    schema:datePublished "2019-03-08T19:44:29Z"^^schema:DateTime ;
    schema:genre "60-06"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improved Robustness and Safety for Autonomous Vehicle Control with  Adversarial Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.03642v1"^^schema:URL .

<1299> a schema:ScholarlyArticle ;
    schema:abstract "Data augmentation (DA) is fundamental against overfitting in largeconvolutional neural networks, especially with a limited training dataset. Inimages, DA is usually based on heuristic transformations, like geometric orcolor transformations. Instead of using predefined transformations, our worklearns data augmentation directly from the training data by learning totransform images with an encoder-decoder architecture combined with a spatialtransformer network. The transformed images still belong to the same class butare new, more complex samples for the classifier. Our experiments show that ourapproach is better than previous generative data augmentation methods, andcomparable to predefined transformation methods when training an imageclassifier."^^schema:Text ;
    schema:author "David Vazquez"^^schema:Person,
        "Ismail Ben Ayed"^^schema:Person,
        "Marco Pedersoli"^^schema:Person,
        "Saypraseuth Mounsaveng"^^schema:Person ;
    schema:dateModified "2019-09-21T09:43:24Z"^^schema:DateTime ;
    schema:datePublished "2019-09-21T09:43:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Learning of General Transformations for Data Augmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.09801v1"^^schema:URL .

<13> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial perturbations of normal images are usually imperceptible tohumans, but they can seriously confuse state-of-the-art machine learningmodels. What makes them so special in the eyes of image classifiers? In thispaper, we show empirically that adversarial examples mainly lie in the lowprobability regions of the training distribution, regardless of attack typesand targeted models. Using statistical hypothesis testing, we find that modernneural density models are surprisingly good at detecting imperceptible imageperturbations. Based on this discovery, we devised PixelDefend, a new approachthat purifies a maliciously perturbed image by moving it back towards thedistribution seen in the training data. The purified image is then run throughan unmodified classifier, making our method agnostic to both the classifier andthe attacking method. As a result, PixelDefend can be used to protect alreadydeployed models and be combined with other model-specific defenses. Experimentsshow that our method greatly improves resilience across a wide variety ofstate-of-the-art attacking methods, increasing accuracy on the strongest attackfrom 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10."^^schema:Text ;
    schema:author "Nate Kushman"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person,
        "Stefano Ermon"^^schema:Person,
        "Taesup Kim"^^schema:Person,
        "Yang Song"^^schema:Person ;
    schema:commentCount "278"^^schema:Integer ;
    schema:dateModified "2018-05-21T05:26:01Z"^^schema:DateTime ;
    schema:datePublished "2017-10-30T04:21:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "PixelDefend: Leveraging Generative Models to Understand and Defend  against Adversarial Examples"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.10766v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9269726813530152599&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<130> a schema:ScholarlyArticle ;
    schema:abstract "Teaching machines to read natural language documents remains an elusivechallenge. Machine reading systems can be tested on their ability to answerquestions posed on the contents of documents that they have seen, but until nowlarge scale training and test datasets have been missing for this type ofevaluation. In this work we define a new methodology that resolves thisbottleneck and provides large scale supervised reading comprehension data. Thisallows us to develop a class of attention based deep neural networks that learnto read real documents and answer complex questions with minimal priorknowledge of language structure."^^schema:Text ;
    schema:author "Edward Grefenstette"^^schema:Person,
        "Karl Moritz Hermann"^^schema:Person,
        "Lasse Espeholt"^^schema:Person,
        "Mustafa Suleyman"^^schema:Person,
        "Phil Blunsom"^^schema:Person,
        "Tomáš Kočiský"^^schema:Person,
        "Will Kay"^^schema:Person ;
    schema:commentCount "1635"^^schema:Integer ;
    schema:dateModified "2015-11-19T15:43:23Z"^^schema:DateTime ;
    schema:datePublished "2015-06-10T14:54:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Teaching Machines to Read and Comprehend"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.03340v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5371787459515302436&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1300> a schema:ScholarlyArticle ;
    schema:abstract "Industrial robot manipulators are not able to match the precision and speedwith which humans are able to execute contact rich tasks even to this day.Therefore, as a means overcome this gap, we demonstrate generative methods forimitating a peg-in-hole insertion task in a 6-DOF robot manipulator. Inparticular, generative adversarial imitation learning (GAIL) is used tosuccessfully achieve this task with a 10 um, and a 6 um peg-hole clearance onthe Yaskawa GP8 industrial robot. Experimental results show that the policysuccessfully learns within 20 episodes from a handful of human expertdemonstrations on the robot (i.e., &lt; 10 tele-operated robot demonstrations).The insertion time improves from &gt; 20 seconds (which also includes failedinsertions) to &lt; 15 seconds, thereby validating the effectiveness of thisapproach."^^schema:Text ;
    schema:author "Bharadwaj Amrutur"^^schema:Person,
        "Sagar Gubbi"^^schema:Person,
        "Shishir Kolathaya"^^schema:Person ;
    schema:dateModified "2020-12-26T08:42:15Z"^^schema:DateTime ;
    schema:datePublished "2020-12-26T08:42:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Imitation Learning for High Precision Peg-in-Hole Tasks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.01052v1"^^schema:URL .

<1301> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose neural network models based on the neural ordinarydifferential equation (NODE) for small-footprint keyword spotting (KWS). Wepresent techniques to apply NODE to KWS that make it possible to adopt BatchNormalization to NODE-based network and to reduce the number of computationsduring inference. Finally, we show that the number of model parameters of theproposed model is smaller by 68% than that of the conventional KWS model."^^schema:Text ;
    schema:author "Hiroshi Fuketa"^^schema:Person,
        "Yukinori Morita"^^schema:Person ;
    schema:dateModified "2020-09-06T12:06:36Z"^^schema:DateTime ;
    schema:datePublished "2020-08-01T08:01:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Neural ODE with Temporal Convolution and Time Delay Neural Networks for  Small-Footprint Keyword Spotting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.00209v2"^^schema:URL .

<1302> a schema:ScholarlyArticle ;
    schema:abstract "Learning under a Wasserstein loss, a.k.a. Wasserstein loss minimization(WLM), is an emerging research topic for gaining insights from a large set ofstructured objects. Despite being conceptually simple, WLM problems arecomputationally challenging because they involve minimizing over functions ofquantities (i.e. Wasserstein distances) that themselves require numericalalgorithms to compute. In this paper, we introduce a stochastic approach basedon simulated annealing for solving WLMs. Particularly, we have developed aGibbs sampler to approximate effectively and efficiently the partial gradientsof a sequence of Wasserstein losses. Our new approach has the advantages ofnumerical stability and readiness for warm starts. These characteristics arevaluable for WLM problems that often require multiple levels of iterations inwhich the oracle for computing the value and gradient of a loss function isembedded. We applied the method to optimal transport with Coulomb cost and theWasserstein non-negative matrix factorization problem, and made comparisonswith the existing method of entropy regularization."^^schema:Text ;
    schema:author "James Z. Wang"^^schema:Person,
        "Jia Li"^^schema:Person,
        "Jianbo Ye"^^schema:Person ;
    schema:dateModified "2017-06-06T16:17:56Z"^^schema:DateTime ;
    schema:datePublished "2016-08-12T17:49:10Z"^^schema:DateTime ;
    schema:genre "stat.CO"^^schema:Text ;
    schema:headline "A Simulated Annealing based Inexact Oracle for Wasserstein Loss  Minimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1608.03859v4"^^schema:URL .

<1303> a schema:ScholarlyArticle ;
    schema:abstract "The main bottleneck when performing computational fluid dynamics (CFD)simulations of combustion systems is the computation and integration of thehighly non-linear and stiff chemical source terms. In recent times, machinelearning has emerged as a promising tool to accelerate combustion chemistry,involving the use of regression models to predict the chemical source terms asfunctions of the thermochemical state of the system. However, combustion is ahighly nonlinear phenomenon, and this often leads to divergence from the truesolution when the neural network representation of chemical kinetics isintegrated in time. This is because these approaches minimize the error duringtraining without guaranteeing successful integration with ordinary differentialequation (ODE) solvers. In this work, a novel neural ODE approach to combustionmodeling, ChemNODE, is developed to address this issue. The source termspredicted by the neural network are integrated during training, and bybackpropagating errors through the ODE solver, the neural network weights areadjusted accordingly to minimize the difference between the predicted andactual ODE solutions. It is shown that even when the dimensionality of thethermochemical manifold is trimmed to remove redundant species, the proposedapproach accurately captures the correct physical behavior and reproduces theresults obtained using the full chemical kinetic mechanism."^^schema:Text ;
    schema:author "Opeoluwa Owoyele"^^schema:Person,
        "Pinaki Pal"^^schema:Person ;
    schema:dateModified "2021-02-03T20:18:17Z"^^schema:DateTime ;
    schema:datePublished "2020-12-03T23:49:02Z"^^schema:DateTime ;
    schema:genre "cs.CE"^^schema:Text,
        "physics.flu-dyn"^^schema:Text ;
    schema:headline "ChemNODE: A Neural Ordinary Differential Equations Approach for Chemical  Kinetics Solvers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.04749v2"^^schema:URL .

<1304> a schema:ScholarlyArticle ;
    schema:abstract "The Orienteering Problem with Time Windows (OPTW) is a combinatorialoptimization problem where the goal is to maximize the total scores collectedfrom visited locations, under some time constraints. Several heuristics havebeen proposed for the OPTW, yet in comparison with machine learning models, aheuristic typically has a smaller potential for generalization andpersonalization. The application of neural network models to combinatorialoptimization has recently shown promising results in similar problems like theTravelling Salesman Problem. A neural network allows learning solutions usingreinforcement learning or in a supervised way, depending on the available data.After learning, it can potentially generalize and be quickly fine-tuned tofurther improve performance and personalization. This is advantageous since,for real word applications, a solution's quality, personalization and executiontimes are all important factors to be taken into account.  Here we explore the use of Pointer Network models trained with reinforcementlearning for solving the OPTW problem. Among its various applications, the OPTWcan be used to model the Tourist Trip Design Problem (TTDP). We train thePointer Network with the TTDP problem in mind, by sampling variables that canchange across tourists for a particular instance-region: starting position,starting time, time available and the scores of each point of interest. After amodel-region is trained it can infer a solution for a particular tourist usingbeam search. We evaluate our approach on several existing benchmark OPTWinstances. We show that it is able to generalize across different generatedtourists for each region and that it generally outperforms the most commonlyused heuristic while computing the solution in realistic times."^^schema:Text ;
    schema:author "Hugo L. Fernandes"^^schema:Person,
        "Ricardo Gama"^^schema:Person ;
    schema:dateModified "2020-11-07T00:38:06Z"^^schema:DateTime ;
    schema:datePublished "2020-11-07T00:38:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "A Reinforcement Learning Approach to the Orienteering Problem with Time  Windows"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03647v1"^^schema:URL .

<1305> a schema:ScholarlyArticle ;
    schema:abstract "Endoscopy is a widely used imaging modality to diagnose and treat diseases inhollow organs as for example the gastrointestinal tract, the kidney and theliver. However, due to varied modalities and use of different imaging protocolsat various clinical centers impose significant challenges when generalisingdeep learning models. Moreover, the assembly of large datasets from differentclinical centers can introduce a huge label bias that renders any learnt modelunusable. Also, when using new modality or presence of images with rarepatterns, a bulk amount of similar image data and their corresponding labelsare required for training these models. In this work, we propose to use afew-shot learning approach that requires less training data and can be used topredict label classes of test samples from an unseen dataset. We propose anovel additive angular margin metric in the framework of prototypical networkin few-shot learning setting. We compare our approach to the severalestablished methods on a large cohort of multi-center, multi-organ, andmulti-modal endoscopy data. The proposed algorithm outperforms existingstate-of-the-art methods."^^schema:Text ;
    schema:author "Binod Bhattarai"^^schema:Person,
        "Jens Rittscher"^^schema:Person,
        "Sharib Ali"^^schema:Person,
        "Tae-Kyun Kim"^^schema:Person ;
    schema:dateModified "2020-03-26T20:28:04Z"^^schema:DateTime ;
    schema:datePublished "2020-03-23T00:20:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Additive Angular Margin for Few Shot Learning to Classify Clinical  Endoscopy Images"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.10033v2"^^schema:URL .

<1306> a schema:ScholarlyArticle ;
    schema:abstract "We introduce natural language processing into the study of knot theory, asmade natural by the braid word representation of knots. We study the UNKNOTproblem of determining whether or not a given knot is the unknot. Afterdescribing an algorithm to randomly generate $N$-crossing braids and their knotclosures and discussing the induced prior on the distribution of knots, weapply binary classification to the UNKNOT decision problem. We find that theReformer and shared-QK Transformer network architectures outperformfully-connected networks, though all perform well. Perhaps surprisingly, wefind that accuracy increases with the length of the braid word, and that thenetworks learn a direct correlation between the confidence of their predictionsand the degree of the Jones polynomial. Finally, we utilize reinforcementlearning (RL) to find sequences of Markov moves and braid relations thatsimplify knots and can identify unknots by explicitly giving the sequence ofunknotting actions. Trust region policy optimization (TRPO) performsconsistently well for a wide range of crossing numbers and thoroughlyoutperformed other RL algorithms and random walkers. Studying these actions, wefind that braid relations are more useful in simplifying to the unknot than oneof the Markov moves."^^schema:Text ;
    schema:author "Fabian Ruehle"^^schema:Person,
        "James Halverson"^^schema:Person,
        "Piotr Sułkowski"^^schema:Person,
        "Sergei Gukov"^^schema:Person ;
    schema:dateModified "2020-10-28T18:00:05Z"^^schema:DateTime ;
    schema:datePublished "2020-10-28T18:00:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "hep-th"^^schema:Text,
        "math.GT"^^schema:Text ;
    schema:headline "Learning to Unknot"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.16263v1"^^schema:URL .

<1307> a schema:ScholarlyArticle ;
    schema:abstract "Denoising autoencoders (DAE) are trained to reconstruct their clean inputswith noise injected at the input level, while variational autoencoders (VAE)are trained with noise injected in their stochastic hidden layer, with aregularizer that encourages this noise injection. In this paper, we show thatinjecting noise both in input and in the stochastic hidden layer can beadvantageous and we propose a modified variational lower bound as an improvedobjective function in this setup. When input is corrupted, then the standardVAE lower bound involves marginalizing the encoder conditional distributionover the input noise, which makes the training criterion intractable. Instead,we propose a modified training criterion which corresponds to a tractable boundwhen input is corrupted. Experimentally, we find that the proposed denoisingvariational autoencoder (DVAE) yields better average log-likelihood than theVAE and the importance weighted autoencoder on the MNIST and Frey Facedatasets."^^schema:Text ;
    schema:author "Daniel Jiwoong Im"^^schema:Person,
        "Roland Memisevic"^^schema:Person,
        "Sungjin Ahn"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:dateModified "2016-01-04T15:12:46Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T21:56:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Denoising Criterion for Variational Auto-Encoding Framework"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1511.06406v2"^^schema:URL .

<1308> a schema:ScholarlyArticle ;
    schema:abstract "Since the emergence of large annotated datasets, state-of-the-art hand poseestimation methods have been mostly based on discriminative learning. Recently,a hybrid approach has embedded a kinematic layer into the deep learningstructure in such a way that the pose estimates obey the physical constraintsof human hand kinematics. However, the existing approach relies on a singleperson's hand shape parameters, which are fixed constants. Therefore, theexisting hybrid method has problems to generalize to new, unseen hands. In thiswork, we extend the kinematic layer to make the hand shape parameterslearnable. In this way, the learnt network can generalize towards arbitraryhand shapes. Furthermore, inspired by the idea of Spatial Transformer Networks,we apply a cascade of appearance normalization networks to decrease thevariance in the input data. The input images are shifted, rotated, and globallyscaled to a similar appearance. The effectiveness and limitations of ourproposed approach are extensively evaluated on the Hands 2017 challenge datasetand the NYU dataset."^^schema:Text ;
    schema:author "Dongheui Lee"^^schema:Person,
        "Jan Wöhlke"^^schema:Person,
        "Shile Li"^^schema:Person ;
    schema:dateModified "2018-07-02T21:27:08Z"^^schema:DateTime ;
    schema:datePublished "2018-07-02T21:27:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Model-based Hand Pose Estimation for Generalized Hand Shape with  Appearance Normalization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.00898v1"^^schema:URL .

<1309> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent Neural Networks have lately gained a lot of popularity in languagemodelling tasks, especially in neural machine translation(NMT). Very recent NMTmodels are based on Encoder-Decoder, where a deep LSTM based encoder is used toproject the source sentence to a fixed dimensional vector and then another deepLSTM decodes the target sentence from the vector. However there has been verylittle work on exploring architectures that have more than one layer inspace(i.e. in each time step). This paper examines the effectiveness of thesimple Recurrent Highway Networks(RHN) in NMT tasks. The model uses RecurrentHighway Neural Network in encoder and decoder, with attention .We also explorethe reconstructor model to improve adequacy. We demonstrate the effectivenessof all three approaches on the IWSLT English-Vietnamese dataset. We see thatRHN performs on par with LSTM based models and even better in some cases.We seethat deep RHN models are easy to train compared to deep LSTM based modelsbecause of highway connections. The paper also investigates the effects ofincreasing recurrent depth in each time step."^^schema:Text ;
    schema:author "Maulik Parmar"^^schema:Person,
        "V. Susheela Devi"^^schema:Person ;
    schema:dateModified "2019-04-28T08:27:55Z"^^schema:DateTime ;
    schema:datePublished "2019-04-28T08:27:55Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Neural Machine Translation with Recurrent Highway Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.01996v1"^^schema:URL .

<131> a schema:ScholarlyArticle ;
    schema:abstract "High network communication cost for synchronizing gradients and parameters isthe well-known bottleneck of distributed training. In this work, we proposeTernGrad that uses ternary gradients to accelerate distributed deep learning indata parallelism. Our approach requires only three numerical levels {-1,0,1},which can aggressively reduce the communication time. We mathematically provethe convergence of TernGrad under the assumption of a bound on gradients.Guided by the bound, we propose layer-wise ternarizing and gradient clipping toimprove its convergence. Our experiments show that applying TernGrad on AlexNetdoes not incur any accuracy loss and can even improve accuracy. The accuracyloss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, aperformance model is proposed to study the scalability of TernGrad. Experimentsshow significant speed gains for various deep neural networks. Our source codeis available."^^schema:Text ;
    schema:author "Chunpeng Wu"^^schema:Person,
        "Cong Xu"^^schema:Person,
        "Feng Yan"^^schema:Person,
        "Hai Li"^^schema:Person,
        "Wei Wen"^^schema:Person,
        "Yandan Wang"^^schema:Person,
        "Yiran Chen"^^schema:Person ;
    schema:commentCount "289"^^schema:Integer ;
    schema:dateModified "2017-12-29T02:51:48Z"^^schema:DateTime ;
    schema:datePublished "2017-05-22T17:42:15Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.5.1"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep  Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.07878v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10878522154628533487&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1310> a schema:ScholarlyArticle ;
    schema:abstract "As an emerging type of user-generated content, micro-video drasticallyenriches people's entertainment experiences and social interactions. However,the popularity pattern of an individual micro-video still remains elusive amongthe researchers. One of the major challenges is that the potential popularityof a micro-video tends to fluctuate under the impact of various externalfactors, which makes it full of uncertainties. In addition, since micro-videosare mainly uploaded by individuals that lack professional techniques, multipletypes of noise could exist that obscure useful information. In this paper, wepropose a multimodal variational encoder-decoder (MMVED) framework formicro-video popularity prediction tasks. MMVED learns a stochastic Gaussianembedding of a micro-video that is informative to its popularity level whilepreserves the inherent uncertainties simultaneously. Moreover, through theoptimization of a deep variational information bottleneck lower-bound (IBLBO),the learned hidden representation is shown to be maximally expressive about thepopularity target while maximally compressive to the noise in micro-videofeatures. Furthermore, the Bayesian product-of-experts principle is applied tothe multimodal encoder, where the decision for information keeping ordiscarding is made comprehensively with all available modalities. Extensiveexperiments conducted on a public dataset and a dataset we collect from Xiguademonstrate the effectiveness of the proposed MMVED framework."^^schema:Text ;
    schema:author "Jiayi Xie"^^schema:Person,
        "Yaochen Zhu"^^schema:Person,
        "Zhenzhong Chen"^^schema:Person ;
    schema:dateModified "2020-03-28T06:08:16Z"^^schema:DateTime ;
    schema:datePublished "2020-03-28T06:08:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Predicting the Popularity of Micro-videos with Multimodal Variational  Encoder-Decoder Framework"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.12724v1"^^schema:URL .

<1311> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new framework named DS-WGAN that integrates the doublystochastic (DS) structure and the Wasserstein generative adversarial networks(WGAN) to model, estimate, and simulate a wide class of arrival processes withgeneral non-stationary and random arrival rates. Regarding statisticalproperties, we prove consistency and convergence rate for the estimator solvedby the DS-WGAN framework under a non-parametric smoothness condition. Regardingcomputational efficiency and tractability, we address a challenge in gradientevaluation and model estimation, arised from the discontinuity in thesimulator. We then show that the DS-WGAN framework can conveniently facilitatewhat-if simulation and predictive simulation for future scenarios that aredifferent from the history. Numerical experiments with synthetic and real datasets are implemented to demonstrate the performance of DS-WGAN. The performanceis measured from both a statistical perspective and an operational performanceevaluation perspective. Numerical experiments suggest that, in terms ofperformance, the successful model estimation for DS-WGAN only requires amoderate size of representative data, which can be appealing in many contextsof operational management."^^schema:Text ;
    schema:author "Yufeng Zheng"^^schema:Person,
        "Zeyu Zheng"^^schema:Person ;
    schema:dateModified "2021-01-26T05:21:24Z"^^schema:DateTime ;
    schema:datePublished "2020-12-27T13:32:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Doubly Stochastic Generative Arrivals Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.13940v2"^^schema:URL .

<1312> a schema:ScholarlyArticle ;
    schema:abstract "Vehicle theft is arguably one of the fastest-growing types of crime in India.In some of the urban areas, vehicle theft cases are believed to be around 100each day. Identification of stolen vehicles in such precarious scenarios is notpossible using traditional methods like manual checking and radio frequencyidentification(RFID) based technologies. This paper presents a deep learningbased automatic traffic surveillance system for the detection ofstolen/suspicious cars from the closed circuit television(CCTV) camera footage.It mainly comprises of four parts: Select-Detector, Image Quality Enhancer,Image Transformer, and Smart Recognizer. The Select-Detector is used forextracting the frames containing vehicles and to detect the license plates muchefficiently with minimum time complexity. The quality of the license plates isthen enhanced using Image Quality Enhancer which uses pix2pix generativeadversarial network(GAN) for enhancing the license plates that are affected bytemporal changes like low light, shadow, etc. Image Transformer is used totackle the problem of inefficient recognition of license plates which are nothorizontal(which are at an angle) by transforming the license plate todifferent levels of rotation and cropping. Smart Recognizer recognizes thelicense plate number using Tesseract optical character recognition(OCR) andcorrects the wrongly recognized characters using Error-Detector. Theeffectiveness of the proposed approach is tested on the government's CCTVcamera footage, which resulted in identifying the stolen/suspicious cars withan accuracy of 87%."^^schema:Text ;
    schema:author "K. V. Kadambari"^^schema:Person,
        "Vishnu Vardhan Nimmalapudi"^^schema:Person ;
    schema:dateModified "2020-07-17T07:18:12Z"^^schema:DateTime ;
    schema:datePublished "2020-07-17T07:18:12Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Learning Based Traffic Surveillance System For Missing and  Suspicious Car Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.08783v1"^^schema:URL .

<1313> a schema:ScholarlyArticle ;
    schema:abstract "We study the relations between the notions of highness, lowness and logicaldepth in the setting of complexity theory. We introduce a new notion of polylogdepth based on time bounded Kolmogorov complexity. We show polylog depthsatisfies all basic logical depth properties, namely sets in P are not polylogdeep, sets with (time bounded)-Kolmogorov complexity greater than polylog arenot polylog deep, and only polylog deep sets can polynomially Turing compute apolylog deep set. We prove that if NP does not have p-measure zero, then NPcontains polylog deep sets. We show that every high set for E contains apolylog deep set in its polynomial Turing degree, and that there existlow(E,EXP) polylog deep sets. Keywords: algorithmic information theory;Kolmogorov complexity; Bennett logical depth."^^schema:Text ;
    schema:author "Philippe Moser"^^schema:Person ;
    schema:dateModified "2019-10-15T15:39:53Z"^^schema:DateTime ;
    schema:datePublished "2016-02-10T11:40:14Z"^^schema:DateTime ;
    schema:genre "cs.CC"^^schema:Text ;
    schema:headline "Polynomial Depth, Highness and Lowness for E"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1602.03332v2"^^schema:URL .

<1314> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a new type of generative model that is able to quicklylearn a latent representation without an encoder. This is achieved usingempirical Bayes to calculate the expectation of the posterior, which isimplemented by initialising a latent vector with zeros, then using the gradientof the log-likelihood of the data with respect to this zero vector as newlatent points. The approach has similar characteristics to autoencoders, butwith a simpler architecture, and is demonstrated in a variational autoencoderequivalent that permits sampling. This also allows implicit representationnetworks to learn a space of implicit functions without requiring ahypernetwork, retaining their representation advantages across datasets. Theexperiments show that the proposed method converges faster, with significantlylower reconstruction error than autoencoders, while requiring half theparameters."^^schema:Text ;
    schema:author "Chris G. Willcocks"^^schema:Person,
        "Sam Bond-Taylor"^^schema:Person ;
    schema:dateModified "2021-01-21T15:38:55Z"^^schema:DateTime ;
    schema:datePublished "2020-07-06T15:00:11Z"^^schema:DateTime ;
    schema:genre "68T01 (Primary), 68T07 (Secondary)"^^schema:Text,
        "I.5.0; I.4.0; G.3"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Gradient Origin Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02798v4"^^schema:URL .

<1315> a schema:ScholarlyArticle ;
    schema:abstract "Despite all the impressive advances of recurrent neural networks, sequentialdata is still in need of better modelling. Truncated backpropagation throughtime (TBPTT), the learning algorithm most widely used in practice, suffers fromthe truncation bias, which drastically limits its ability to learn long-termdependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses thisissue, but its high computational requirements make it infeasible in practice.The Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRLwith a smaller runtime and memory cost, but with the disadvantage of obtainingnoisy gradients that also limit its practical applicability. In this paper wepropose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kroneckerproduct decomposition to approximate the gradients for a large class of RNNs.We show that KF-RTRL is an unbiased and memory efficient online learningalgorithm. Our theoretical analysis shows that, under reasonable assumptions,the noise introduced by our algorithm is not only stable over time but alsoasymptotically much smaller than the one of the UORO algorithm. We also confirmthese theoretical results experimentally. Further, we show empirically that theKF-RTRL algorithm captures long-term dependencies and almost matches theperformance of TBPTT on real world tasks by training Recurrent Highway Networkson a synthetic string memorization task and on the Penn TreeBank task,respectively. These results indicate that RTRL based approaches might be apromising future alternative to TBPTT."^^schema:Text ;
    schema:author "Angelika Steger"^^schema:Person,
        "Asier Mujika"^^schema:Person,
        "Florian Meier"^^schema:Person ;
    schema:dateModified "2018-12-05T20:34:34Z"^^schema:DateTime ;
    schema:datePublished "2018-05-28T09:40:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Approximating Real-Time Recurrent Learning with Random Kronecker Factors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.10842v2"^^schema:URL .

<1316> a schema:ScholarlyArticle ;
    schema:abstract "This study develops an unsupervised learning algorithm for products of expertcapsules with dynamic routing. Analogous to binary-valued neurons in RestrictedBoltzmann Machines, the magnitude of a squashed capsule firing takes valuesbetween zero and one, representing the probability of the capsule being on.This analogy motivates the design of an energy function for capsule networks.In order to have an efficient sampling procedure where hidden layer nodes arenot connected, the energy function is made consistent with dynamic routing inthe sense of the probability of a capsule firing, and inference on the capsulenetwork is computed with the dynamic routing between capsules procedure. Inorder to optimize the log-likelihood of the visible layer capsules, thegradient is found in terms of this energy function. The developed unsupervisedlearning algorithm is used to train a capsule network on standard visiondatasets, and is able to generate realistic looking images from its learneddistribution."^^schema:Text ;
    schema:author "Michael Hauser"^^schema:Person ;
    schema:dateModified "2019-07-26T15:58:56Z"^^schema:DateTime ;
    schema:datePublished "2019-07-26T15:58:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Training products of expert capsules with mixing by dynamic routing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.11643v1"^^schema:URL .

<1317> a schema:ScholarlyArticle ;
    schema:abstract "Learning with sparse rewards remains a significant challenge in reinforcementlearning (RL), especially when the aim is to train a policy capable ofachieving multiple different goals. To date, the most successful approaches fordealing with multi-goal, sparse reward environments have been model-free RLalgorithms. In this work we propose PlanGAN, a model-based algorithmspecifically designed for solving multi-goal tasks in environments with sparserewards. Our method builds on the fact that any trajectory of experiencecollected by an agent contains useful information about how to achieve thegoals observed during that trajectory. We use this to train an ensemble ofconditional generative models (GANs) to generate plausible trajectories thatlead the agent from its current state towards a specified goal. We then combinethese imagined trajectories into a novel planning algorithm in order to achievethe desired goal as efficiently as possible. The performance of PlanGAN hasbeen tested on a number of robotic navigation/manipulation tasks in comparisonwith a range of model-free reinforcement learning baselines, includingHindsight Experience Replay. Our studies indicate that PlanGAN can achievecomparable performance whilst being around 4-8 times more sample efficient."^^schema:Text ;
    schema:author "Giovanni Montana"^^schema:Person,
        "Henry Charlesworth"^^schema:Person ;
    schema:dateModified "2020-06-01T12:53:09Z"^^schema:DateTime ;
    schema:datePublished "2020-06-01T12:53:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.00900v1"^^schema:URL .

<1318> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks (CNNs) have recently emerged as a popularbuilding block for natural language processing (NLP). Despite their success,most existing CNN models employed in NLP share the same learned (and static)set of filters for all input sentences. In this paper, we consider an approachof using a small meta network to learn context-sensitive convolutional filtersfor text processing. The role of meta network is to abstract the contextualinformation of a sentence or document into a set of input-aware filters. Wefurther generalize this framework to model sentence pairs, where abidirectional filter generation mechanism is introduced to encapsulateco-dependent sentence representations. In our benchmarks on four differenttasks, including ontology classification, sentiment analysis, answer sentenceselection, and paraphrase identification, our proposed model, a modified CNNwith context-sensitive filters, consistently outperforms the standard CNN andattention-based CNN baselines. By visualizing the learned context-sensitivefilters, we further validate and rationalize the effectiveness of proposedframework."^^schema:Text ;
    schema:author "Dinghan Shen"^^schema:Person,
        "Lawrence Carin"^^schema:Person,
        "Martin Renqiang Min"^^schema:Person,
        "Yitong Li"^^schema:Person ;
    schema:dateModified "2018-08-30T16:29:50Z"^^schema:DateTime ;
    schema:datePublished "2017-09-25T02:29:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Context-Sensitive Convolutional Filters for Text Processing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.08294v3"^^schema:URL .

<1319> a schema:ScholarlyArticle ;
    schema:abstract "Video generation models often operate under the assumption of fixed framerates, which leads to suboptimal performance when it comes to handling flexibleframe rates (e.g., increasing the frame rate of more dynamic portion of thevideo as well as handling missing video frames). To resolve the restrictednature of existing video generation models' ability to handle arbitrarytimesteps, we propose continuous-time video generation by combining neural ODE(Vid-ODE) with pixel-level video processing techniques. Using ODE-ConvGRU as anencoder, a convolutional version of the recently proposed neural ODE, whichenables us to learn continuous-time dynamics, Vid-ODE can learn thespatio-temporal dynamics of input videos of flexible frame rates. The decoderintegrates the learned dynamics function to synthesize video frames at anygiven timesteps, where the pixel-level composition technique is used tomaintain the sharpness of individual frames. With extensive experiments on fourreal-world video datasets, we verify that the proposed Vid-ODE outperformsstate-of-the-art approaches under various video generation settings, bothwithin the trained time range (interpolation) and beyond the range(extrapolation). To the best of our knowledge, Vid-ODE is the first worksuccessfully performing continuous-time video generation using real-worldvideos."^^schema:Text ;
    schema:author "Edward Choi"^^schema:Person,
        "Jaegul Choo"^^schema:Person,
        "Joonseok Lee"^^schema:Person,
        "Junsoo Lee"^^schema:Person,
        "Kangyeol Kim"^^schema:Person,
        "Sookyung Kim"^^schema:Person,
        "Sunghyun Park"^^schema:Person ;
    schema:dateModified "2020-10-16T06:50:47Z"^^schema:DateTime ;
    schema:datePublished "2020-10-16T06:50:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Vid-ODE: Continuous-Time Video Generation with Neural Ordinary  Differential Equation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.08188v1"^^schema:URL .

<132> a schema:ScholarlyArticle ;
    schema:abstract "Attack detection problems in the smart grid are posed as statistical learningproblems for different attack scenarios in which the measurements are observedin batch or online settings. In this approach, machine learning algorithms areused to classify measurements as being either secure or attacked. An attackdetection framework is provided to exploit any available prior knowledge aboutthe system and surmount constraints arising from the sparse structure of theproblem in the proposed approach. Well-known batch and online learningalgorithms (supervised and semi-supervised) are employed with decision andfeature level fusion to model the attack detection problem. The relationshipsbetween statistical and geometric properties of attack vectors employed in theattack scenarios and learning algorithms are analyzed to detect unobservableattacks using statistical learning methods. The proposed algorithms areexamined on various IEEE test systems. Experimental analyses show that machinelearning algorithms can detect attacks with performances higher than the attackdetection algorithms which employ state vector estimation methods in theproposed attack detection framework."^^schema:Text ;
    schema:author "Fatos T. Yarman Vural"^^schema:Person,
        "H. Vincent Poor"^^schema:Person,
        "Inaki Esnaola"^^schema:Person,
        "Mete Ozay"^^schema:Person,
        "Sanjeev R. Kulkarni"^^schema:Person ;
    schema:commentCount "196"^^schema:Integer ;
    schema:dateModified "2015-03-22T19:38:45Z"^^schema:DateTime ;
    schema:datePublished "2015-03-22T19:38:45Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "Machine Learning Methods for Attack Detection in the Smart Grid"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (8), 1773-1786"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.06468v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8039699353196777267&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1320> a schema:ScholarlyArticle ;
    schema:abstract "This paper evaluates adaptive Q-learning (AQL) and single-partition adaptiveQ-learning (SPAQL), two algorithms for efficient model-free episodicreinforcement learning (RL), in two classical control problems (Pendulum andCartpole). AQL adaptively partitions the state-action space of a Markovdecision process (MDP), while learning the control policy, i. e., the mappingfrom states to actions. The main difference between AQL and SPAQL is that thelatter learns time-invariant policies, where the mapping from states to actionsdoes not depend explicitly on the time step. This paper also proposes the SPAQLwith terminal state (SPAQL-TS), an improved version of SPAQL tailored for thedesign of regulators for control problems. The time-invariant policies areshown to result in a better performance than the time-variant ones in bothproblems studied. These algorithms are particularly fitted to RL problems wherethe action space is finite, as is the case with the Cartpole problem. SPAQL-TSsolves the OpenAI Gym Cartpole problem, while also displaying a higher sampleefficiency than trust region policy optimization (TRPO), a standard RLalgorithm for solving control tasks. Moreover, the policies learned by SPAQLare interpretable, while TRPO policies are typically encoded as neuralnetworks, and therefore hard to interpret. Yielding interpretable policieswhile being sample-efficient are the major advantages of SPAQL."^^schema:Text ;
    schema:author "João Pedro Araújo"^^schema:Person,
        "Miguel Ayala Botto"^^schema:Person,
        "Mário A. T. Figueiredo"^^schema:Person ;
    schema:dateModified "2020-11-03T18:58:55Z"^^schema:DateTime ;
    schema:datePublished "2020-11-03T18:58:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Control with adaptive Q-learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02141v1"^^schema:URL .

<1321> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we present the Role Playing Learning (RPL) scheme for a mobilerobot to navigate socially with its human companion in populated environments.Neural networks (NN) are constructed to parameterize a stochastic policy thatdirectly maps sensory data collected by the robot to its velocity outputs,while respecting a set of social norms. An efficient simulative learningenvironment is built with maps and pedestrians trajectories collected from anumber of real-world crowd data sets. In each learning iteration, a robotequipped with the NN policy is created virtually in the learning environment toplay itself as a companied pedestrian and navigate towards a goal in a sociallyconcomitant manner. Thus, we call this process Role Playing Learning, which isformulated under a reinforcement learning (RL) framework. The NN policy isoptimized end-to-end using Trust Region Policy Optimization (TRPO), withconsideration of the imperfectness of robot's sensor measurements. Simulativeand experimental results are provided to demonstrate the efficacy andsuperiority of our method."^^schema:Text ;
    schema:author "Mingming Li"^^schema:Person,
        "Rui Jiang"^^schema:Person,
        "Shuzhi Sam Ge"^^schema:Person,
        "Tong Heng Lee"^^schema:Person ;
    schema:dateModified "2017-05-29T09:42:36Z"^^schema:DateTime ;
    schema:datePublished "2017-05-29T09:42:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Role Playing Learning for Socially Concomitant Mobile Robot Navigation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.10092v1"^^schema:URL .

<1322> a schema:ScholarlyArticle ;
    schema:abstract "Black Sigatoka disease severely decreases global banana production, andclimate change aggravates the problem by altering fungal species distributions.Due to the heavy financial burden of managing this infectious disease, farmersin developing countries face significant banana crop losses. Though scientistshave produced mathematical models of infectious diseases, adapting these modelsto incorporate climate effects is difficult. We present MR. NODE (MultiplepredictoR Neural ODE), a neural network that models the dynamics of blackSigatoka infection learnt directly from data via Neural Ordinary DifferentialEquations. Our method encodes external predictor factors into the latent spacein addition to the variable that we infer, and it can also predict theinfection risk at an arbitrary point in time. Empirically, we demonstrate onhistorical climate data that our method has superior generalization performanceon time points up to one month in the future and unseen irregularities. Webelieve that our method can be a useful tool to control the spread of blackSigatoka."^^schema:Text ;
    schema:author "Jesse Bettencourt"^^schema:Person,
        "Matthieu Chan Chee"^^schema:Person,
        "Minh Duc Hoang"^^schema:Person,
        "Shion Fujimori"^^schema:Person,
        "Sornnujah Kathirgamanathan"^^schema:Person,
        "Yuchen Wang"^^schema:Person,
        "Ziyad Edher"^^schema:Person ;
    schema:dateModified "2021-01-10T06:21:44Z"^^schema:DateTime ;
    schema:datePublished "2020-12-01T21:59:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Forecasting Black Sigatoka Infection Risks with Latent Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.00752v2"^^schema:URL .

<1323> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we address the novel, highly challenging problem of estimatingthe layout of a complex urban driving scenario. Given a single color imagecaptured from a driving platform, we aim to predict the bird's-eye view layoutof the road and other traffic participants. The estimated layout should reasonbeyond what is visible in the image, and compensate for the loss of 3Dinformation due to projection. We dub this problem amodal scene layoutestimation, which involves \"hallucinating\" scene layout for even parts of theworld that are occluded in the image. To this end, we present MonoLayout, adeep neural network for real-time amodal scene layout estimation from a singleimage. We represent scene layout as a multi-channel semantic occupancy grid,and leverage adversarial feature learning to hallucinate plausible completionsfor occluded image parts. Due to the lack of fair baseline methods, we extendseveral state-of-the-art approaches for road-layout estimation and vehicleoccupancy estimation in bird's-eye view to the amodal setup for rigorousevaluation. By leveraging temporal sensor fusion to generate training labels,we significantly outperform current art over a number of datasets. On the KITTIand Argoverse datasets, we outperform all baselines by a significant margin. Wealso make all our annotations, and code publicly available. A video abstract ofthis paper is available https://www.youtube.com/watch?v=HcroGyo6yRQ ."^^schema:Text ;
    schema:author "K. Madhava Krishna"^^schema:Person,
        "Kaustubh Mani"^^schema:Person,
        "Krishna Murthy Jatavallabhula"^^schema:Person,
        "N. Sai Shankar"^^schema:Person,
        "Shubhika Garg"^^schema:Person,
        "Swapnil Daga"^^schema:Person ;
    schema:dateModified "2020-02-19T19:16:34Z"^^schema:DateTime ;
    schema:datePublished "2020-02-19T19:16:34Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "MonoLayout: Amodal scene layout from a single image"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.08394v1"^^schema:URL .

<1324> a schema:ScholarlyArticle ;
    schema:abstract "Image classification has become one of the main tasks in the field ofcomputer vision technologies. In this context, a recent algorithm calledCapsNet that implements an approach based on activity vectors and dynamicrouting between capsules may overcome some of the limitations of the currentstate of the art artificial neural networks (ANN) classifiers, such asconvolutional neural networks (CNN). In this paper, we evaluated theperformance of the CapsNet algorithm in comparison with three well-knownclassifiers (Fisher-faces, LeNet, and ResNet). We tested the classificationaccuracy on four datasets with a different number of instances and classes,including images of faces, traffic signs, and everyday objects. The evaluationresults show that even for simple architectures, training the CapsNet algorithmrequires significant computational resources and its classification performancefalls below the average accuracy values of the other three classifiers.However, we argue that CapsNet seems to be a promising new technique for imageclassification, and further experiments using more robust computation resourcesand re-fined CapsNet architectures may produce better outcomes."^^schema:Text ;
    schema:author "Juan Carrillo"^^schema:Person,
        "Rinat Mukhometzianov"^^schema:Person ;
    schema:dateModified "2018-05-28T22:54:17Z"^^schema:DateTime ;
    schema:datePublished "2018-05-28T22:54:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "CapsNet comparative performance evaluation for image classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.11195v1"^^schema:URL .

<1325> a schema:ScholarlyArticle ;
    schema:abstract "Person Re-Identification (ReID) requires comparing two images of personcaptured under different conditions. Existing work based on neural networksoften computes the similarity of feature maps from one single convolutionallayer. In this work, we propose an efficient, end-to-end fully convolutionalSiamese network that computes the similarities at multiple levels. Wedemonstrate that multi-level similarity can improve the accuracy considerablyusing low-complexity network structures in ReID problem. Specifically, first,we use several convolutional layers to extract the features of two inputimages. Then, we propose Convolution Similarity Network to compute thesimilarity score maps for the inputs. We use spatial transformer networks(STNs) to determine spatial attention. We propose to apply efficient depth-wiseconvolution to compute the similarity. The proposed Convolution SimilarityNetworks can be inserted into different convolutional layers to extract visualsimilarities at different levels. Furthermore, we use an improved ranking lossto further improve the performance. Our work is the first to propose to computevisual similarities at low, middle and high levels for ReID. With extensiveexperiments and analysis, we demonstrate that our system, compact yeteffective, can achieve competitive results with much smaller model size andcomputational complexity."^^schema:Text ;
    schema:author "Ngai-Man Cheung"^^schema:Person,
        "Yiluan Guo"^^schema:Person ;
    schema:dateModified "2018-04-02T03:06:54Z"^^schema:DateTime ;
    schema:datePublished "2018-03-30T06:18:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Efficient and Deep Person Re-Identification using Multi-Level Similarity"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.11353v2"^^schema:URL .

<1326> a schema:ScholarlyArticle ;
    schema:abstract "A normalizing flow is an invertible mapping between an arbitrary probabilitydistribution and a standard normal distribution; it can be used for densityestimation and statistical inference. Computing the flow follows the change ofvariables formula and thus requires invertibility of the mapping and anefficient way to compute the determinant of its Jacobian. To satisfy theserequirements, normalizing flows typically consist of carefully chosencomponents. Continuous normalizing flows (CNFs) are mappings obtained bysolving a neural ordinary differential equation (ODE). The neural ODE'sdynamics can be chosen almost arbitrarily while ensuring invertibility.Moreover, the log-determinant of the flow's Jacobian can be obtained byintegrating the trace of the dynamics' Jacobian along the flow. Our proposedOT-Flow approach tackles two critical computational challenges that limit amore widespread use of CNFs. First, OT-Flow leverages optimal transport (OT)theory to regularize the CNF and enforce straight trajectories that are easierto integrate. Second, OT-Flow features exact trace computation with timecomplexity equal to trace estimators used in existing CNFs. On fivehigh-dimensional density estimation and generative modeling tasks, OT-Flowperforms competitively to state-of-the-art CNFs while on average requiringone-fourth of the number of weights with an 8x speedup in training time and 24xspeedup in inference."^^schema:Text ;
    schema:author "Derek Onken"^^schema:Person,
        "Lars Ruthotto"^^schema:Person,
        "Samy Wu Fung"^^schema:Person,
        "Xingjian Li"^^schema:Person ;
    schema:dateModified "2020-12-02T19:20:54Z"^^schema:DateTime ;
    schema:datePublished "2020-05-29T22:31:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal  Transport"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.00104v3"^^schema:URL .

<1327> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning has demonstrated increasing capabilities forcontinuous control problems, including agents that can move with skill andagility through their environment. An open problem in this setting is that ofdeveloping good strategies for integrating or merging policies for multipleskills, where each individual skill is a specialist in a specific skill and itsassociated state distribution. We extend policy distillation methods to thecontinuous action setting and leverage this technique to combine expertpolicies, as evaluated in the domain of simulated bipedal locomotion acrossdifferent classes of terrain. We also introduce an input injection method foraugmenting an existing policy network to exploit new input features. Lastly,our method uses transfer learning to assist in the efficient acquisition of newskills. The combination of these methods allows a policy to be incrementallyaugmented with new skills. We compare our progressive learning and integrationvia distillation (PLAID) method against three alternative baselines."^^schema:Text ;
    schema:author "Cheng Xie"^^schema:Person,
        "Glen Berseth"^^schema:Person,
        "Michiel Van de Panne"^^schema:Person,
        "Paul Cernek"^^schema:Person ;
    schema:dateModified "2018-02-13T17:57:21Z"^^schema:DateTime ;
    schema:datePublished "2018-02-13T17:57:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Progressive Reinforcement Learning with Distillation for Multi-Skilled  Motion Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.04765v1"^^schema:URL .

<1328> a schema:ScholarlyArticle ;
    schema:abstract "In Intelligent Tutoring System (ITS), tracing the student's knowledge stateduring learning has been studied for several decades in order to provide moresupportive learning instructions. In this paper, we propose a novel model forknowledge tracing that i) captures students' learning ability and dynamicallyassigns students into distinct groups with similar ability at regular timeintervals, and ii) combines this information with a Recurrent Neural Networkarchitecture known as Deep Knowledge Tracing. Experimental results confirm thatthe proposed model is significantly better at predicting student performancethan well known state-of-the-art techniques for student modelling."^^schema:Text ;
    schema:author "Feida Zhu"^^schema:Person,
        "Jill Jenn Vie"^^schema:Person,
        "Michel C. Desmarais"^^schema:Person,
        "Sein Minn"^^schema:Person,
        "Yi Yu"^^schema:Person ;
    schema:dateModified "2021-01-07T14:18:38Z"^^schema:DateTime ;
    schema:datePublished "2018-09-24T01:11:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Deep Knowledge Tracing and Dynamic Student Classification for Knowledge  Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.08713v2"^^schema:URL .

<1329> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we provide the details of implementing various reinforcementlearning (RL) algorithms for controlling a Cart-Pole system. In particular, wedescribe various RL concepts such as Q-learning, Deep Q Networks (DQN), DoubleDQN, Dueling networks, (prioritized) experience replay and show their effect onthe learning performance. In the process, the readers will be introduced toOpenAI/Gym and Keras utilities used for implementing the above concepts. It isobserved that DQN with PER provides best performance among all otherarchitectures being able to solve the problem within 150 episodes."^^schema:Text ;
    schema:author "Swagat Kumar"^^schema:Person ;
    schema:dateModified "2020-06-12T16:27:27Z"^^schema:DateTime ;
    schema:datePublished "2020-06-08T21:14:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Balancing a CartPole System with Reinforcement Learning -- A Tutorial"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04938v2"^^schema:URL .

<133> a schema:ScholarlyArticle ;
    schema:abstract "Gradient descent finds a global minimum in training deep neural networksdespite the objective function being non-convex. The current paper provesgradient descent achieves zero training loss in polynomial time for a deepover-parameterized neural network with residual connections (ResNet). Ouranalysis relies on the particular structure of the Gram matrix induced by theneural network architecture. This structure allows us to show the Gram matrixis stable throughout the training process and this stability implies the globaloptimality of the gradient descent algorithm. We further extend our analysis todeep residual convolutional neural networks and obtain a similar convergenceresult."^^schema:Text ;
    schema:author "Haochuan Li"^^schema:Person,
        "Jason D. Lee"^^schema:Person,
        "Liwei Wang"^^schema:Person,
        "Simon S. Du"^^schema:Person,
        "Xiyu Zhai"^^schema:Person ;
    schema:commentCount "240"^^schema:Integer ;
    schema:dateModified "2019-05-28T19:01:22Z"^^schema:DateTime ;
    schema:datePublished "2018-11-09T07:39:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gradient Descent Finds Global Minima of Deep Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1675-1685"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1811.03804v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6996824436391186988&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1330> a schema:ScholarlyArticle ;
    schema:abstract "In order for reinforcement learning techniques to be useful in real-worlddecision making processes, they must be able to produce robust performance fromlimited data. Deep policy optimization methods have achieved impressive resultson complex tasks, but their real-world adoption remains limited because theyoften require significant amounts of data to succeed. When combined with smallsample sizes, these methods can result in unstable learning due to theirreliance on high-dimensional sample-based estimates. In this work, we developtechniques to control the uncertainty introduced by these estimates. Weleverage these techniques to propose a deep policy optimization approachdesigned to produce stable performance even when data is scarce. The resultingalgorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robustpolicy updates that adapt to the level of uncertainty present throughout thelearning process."^^schema:Text ;
    schema:author "Christos G. Cassandras"^^schema:Person,
        "Ioannis Ch. Paschalidis"^^schema:Person,
        "James Queeney"^^schema:Person ;
    schema:dateModified "2020-12-19T21:51:23Z"^^schema:DateTime ;
    schema:datePublished "2020-12-19T21:51:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region  Approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.10791v1"^^schema:URL .

<1331> a schema:ScholarlyArticle ;
    schema:abstract "This paper describes the submission of LMU Munich to the WMT 2020unsupervised shared task, in two language directions, German&lt;-&gt;Upper Sorbian.Our core unsupervised neural machine translation (UNMT) system follows thestrategy of Chronopoulou et al. (2020), using a monolingual pretrained languagegeneration model (on German) and fine-tuning it on both German and UpperSorbian, before initializing a UNMT model, which is trained with onlinebacktranslation. Pseudo-parallel data obtained from an unsupervised statisticalmachine translation (USMT) system is used to fine-tune the UNMT model. We alsoapply BPE-Dropout to the low resource (Upper Sorbian) data to obtain a morerobust system. We additionally experiment with residual adapters and find themuseful in the Upper Sorbian-&gt;German direction. We explore sampling duringbacktranslation and curriculum learning to use SMT translations in a moreprincipled way. Finally, we ensemble our best-performing systems and reach aBLEU score of 32.4 on German-&gt;Upper Sorbian and 35.2 on Upper Sorbian-&gt;German."^^schema:Text ;
    schema:author "Alexander Fraser"^^schema:Person,
        "Alexandra Chronopoulou"^^schema:Person,
        "Dario Stojanovski"^^schema:Person,
        "Viktor Hangya"^^schema:Person ;
    schema:dateModified "2020-10-25T19:04:03Z"^^schema:DateTime ;
    schema:datePublished "2020-10-25T19:04:03Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "The LMU Munich System for the WMT 2020 Unsupervised Machine Translation  Shared Task"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13192v1"^^schema:URL .

<1332> a schema:ScholarlyArticle ;
    schema:abstract "Large-scale synthetic datasets are beneficial to stereo matching but usuallyintroduce known domain bias. Although unsupervised image-to-image translationnetworks represented by CycleGAN show great potential in dealing with domaingap, it is non-trivial to generalize this method to stereo matching due to theproblem of pixel distortion and stereo mismatch after translation. In thispaper, we propose an end-to-end training framework with domain translation andstereo matching networks to tackle this challenge. First, joint optimizationbetween domain translation and stereo matching networks in our end-to-endframework makes the former facilitate the latter one to the maximum extent.Second, this framework introduces two novel losses, i.e., bidirectionalmulti-scale feature re-projection loss and correlation consistency loss, tohelp translate all synthetic stereo images into realistic ones as well asmaintain epipolar constraints. The effective combination of above twocontributions leads to impressive stereo-consistent translation and disparityestimation accuracy. In addition, a mode seeking regularization term is addedto endow the synthetic-to-real translation results with higher fine-graineddiversity. Extensive experiments demonstrate the effectiveness of the proposedframework on bridging the synthetic-to-real domain gap on stereo matching."^^schema:Text ;
    schema:author "Chengxi Yang"^^schema:Person,
        "Hongsheng Li"^^schema:Person,
        "Rui Liu"^^schema:Person,
        "Wenxiu Sun"^^schema:Person,
        "Xiaogang Wang"^^schema:Person ;
    schema:dateModified "2020-05-05T03:11:38Z"^^schema:DateTime ;
    schema:datePublished "2020-05-05T03:11:38Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "StereoGAN: Bridging Synthetic-to-Real Domain Gap by Joint Optimization  of Domain Translation and Stereo Matching"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.01927v1"^^schema:URL .

<1333> a schema:ScholarlyArticle ;
    schema:abstract "Models encapsulating narrative schema knowledge have proven to be useful fora range of event-related tasks, but these models typically do not engage withtemporal relationships between events. We present a a BART-based conditionalgeneration model capable of capturing event cooccurrence as well as temporalityof event sequences. This single model can address both temporal ordering,sorting a given sequence of events into the order they occurred, and eventinfilling, predicting new events which fit into a temporally-ordered sequenceof existing ones. Our model is trained as a denoising autoencoder: we taketemporally-ordered event sequences, shuffle them, delete some events, and thenattempting to recover the original event sequence. In this fashion, the modellearns to make inferences given incomplete knowledge about the events in anunderlying scenario. On the temporal ordering task, we show that our model isable to unscramble event sequences from existing datasets without access toexplicitly labeled temporal training data, outperforming both a BERT-basedpairwise model and a BERT-based pointer network. On event infilling, humanevaluation shows that our model is able to generate events that fit bettertemporally into the input events when compared to GPT-2 story completionmodels."^^schema:Text ;
    schema:author "Greg Durrett"^^schema:Person,
        "Nathanael Chambers"^^schema:Person,
        "Shih-Ting Lin"^^schema:Person ;
    schema:dateModified "2020-12-31T18:10:18Z"^^schema:DateTime ;
    schema:datePublished "2020-12-31T18:10:18Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Conditional Generation of Temporally-ordered Event Sequences"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.15786v1"^^schema:URL .

<1334> a schema:ScholarlyArticle ;
    schema:abstract "Neural network quantization and pruning are two techniques commonly used toreduce the computational complexity and memory footprint of these models fordeployment. However, most existing pruning strategies operate on full-precisionand cannot be directly applied to discrete parameter distributions afterquantization. In contrast, we study a combination of these two techniques toachieve further network compression. In particular, we propose an effectivepruning strategy for selecting redundant low-precision filters. Furthermore, weleverage Bayesian optimization to efficiently determine the pruning ratio foreach layer. We conduct extensive experiments on CIFAR-10 and ImageNet withvarious architectures and precisions. In particular, for ResNet-18 on ImageNet,we prune 26.12% of the model size with Binarized Neural Network quantization,achieving a top-1 classification accuracy of 47.32% in a model of 2.47 MB and59.30% with a 2-bit DoReFa-Net in 4.36 MB."^^schema:Text ;
    schema:author "Bohan Zhuang"^^schema:Person,
        "Ian Reid"^^schema:Person,
        "Luis Guerra"^^schema:Person,
        "Tom Drummond"^^schema:Person ;
    schema:dateModified "2020-02-03T01:10:13Z"^^schema:DateTime ;
    schema:datePublished "2020-02-03T01:10:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Automatic Pruning for Quantized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.00523v1"^^schema:URL .

<1335> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of distributed multi-robot coverage over an unknown,nonuniform sensory field. Modeling the sensory field as a realization of aGaussian Process and using Bayesian techniques, we devise a policy which aimsto balance the tradeoff between learning the sensory function and covering theenvironment. We propose an adaptive coverage algorithm called DeterministicSequencing of Learning and Coverage (DSLC) that schedules learning and coverageepochs such that its emphasis gradually shifts from exploration to exploitationwhile never fully ceasing to learn. Using a novel definition of coverage regretwhich characterizes overall coverage performance of a multi-robot team over atime horizon $T$, we analyze DSLC to provide an upper bound on expectedcumulative coverage regret. Finally, we illustrate the empirical performance ofthe algorithm through simulations of the coverage task over an unknowndistribution of wildfires."^^schema:Text ;
    schema:author "Andrew McDonald"^^schema:Person,
        "Lai Wei"^^schema:Person,
        "Vaibhav Srivastava"^^schema:Person ;
    schema:dateModified "2021-02-05T05:08:18Z"^^schema:DateTime ;
    schema:datePublished "2021-01-12T05:46:13Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Regret Analysis of Distributed Gaussian Process Estimation and Coverage"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.04306v2"^^schema:URL .

<1336> a schema:ScholarlyArticle ;
    schema:abstract "The advent of deep learning has considerably accelerated machine learningdevelopment. The deployment of deep neural networks at the edge is howeverlimited by their high memory and energy consumption requirements. With newmemory technology available, emerging Binarized Neural Networks (BNNs) arepromising to reduce the energy impact of the forthcoming machine learninghardware generation, enabling machine learning on the edge devices and avoidingdata transfer over the network. In this work, after presenting ourimplementation employing a hybrid CMOS - hafnium oxide resistive memorytechnology, we suggest strategies to apply BNNs to biomedical signals such aselectrocardiography and electroencephalography, keeping accuracy level andreducing memory requirements. We investigate the memory-accuracy trade-off whenbinarizing whole network and binarizing solely the classifier part. We alsodiscuss how these results translate to the edge-oriented Mobilenet~V1 neuralnetwork on the Imagenet task. The final goal of this research is to enablesmart autonomous healthcare devices."^^schema:Text ;
    schema:author "Bogdan Penkovsky"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Elisa Vianello"^^schema:Person,
        "Etienne Nowak"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2020-06-20T15:27:21Z"^^schema:DateTime ;
    schema:datePublished "2020-06-20T15:27:21Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "In-Memory Resistive RAM Implementation of Binarized Neural Networks for  Medical Applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.11595v1"^^schema:URL .

<1337> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents an approach to improve computational fluid dynamicssimulations forecasts of air pollution using deep learning. Our method, whichintegrates Principal Components Analysis (PCA) and adversarial training, is away to improve the forecast skill of reduced order models obtained from theoriginal model solution. Once the reduced-order model (ROM) is obtained viaPCA, a Long Short-Term Memory network (LSTM) is adversarially trained on theROM to make forecasts. Once trained, the adversarially trained LSTM outperformsa LSTM trained in a classical way. The study area is in London, includingvelocities and a concentration tracer that replicates a busy traffic junction.This adversarially trained LSTM-based approach is used on the ROM in order toproduce faster forecasts of the air pollution tracer."^^schema:Text ;
    schema:author "Christopher Pain"^^schema:Person,
        "César Quilodrán-Casas"^^schema:Person,
        "Rossella Arcucci"^^schema:Person,
        "Yike Guo"^^schema:Person ;
    schema:dateModified "2021-01-05T15:02:18Z"^^schema:DateTime ;
    schema:datePublished "2021-01-05T15:02:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "physics.flu-dyn"^^schema:Text ;
    schema:headline "Adversarially trained LSTMs on reduced order models of urban air  pollution simulations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.01568v1"^^schema:URL .

<1338> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning has achieved remarkable successes in solving challengingreinforcement learning (RL) problems when dense reward function is provided.However, in sparse reward environment it still often suffers from the need tocarefully shape reward function to guide policy optimization. This limits theapplicability of RL in the real world since both reinforcement learning anddomain-specific knowledge are required. It is therefore of great practicalimportance to develop algorithms which can learn from a binary signalindicating successful task completion or other unshaped, sparse reward signals.We propose a novel method called competitive experience replay, whichefficiently supplements a sparse reward by placing learning in the context ofan exploration competition between a pair of agents. Our method complements therecently proposed hindsight experience replay (HER) by inducing an automaticexploratory curriculum. We evaluate our approach on the tasks of reachingvarious goal locations in an ant maze and manipulating objects with a roboticarm. Each task provides only binary rewards indicating whether or not the goalis achieved. Our method asymmetrically augments these sparse rewards for a pairof agents each learning the same task, creating a competitive game designed todrive exploration. Extensive experiments demonstrate that this method leads tofaster converge and improved task performance."^^schema:Text ;
    schema:author "Alexander Trott"^^schema:Person,
        "Caiming Xiong"^^schema:Person,
        "Hao Liu"^^schema:Person,
        "Richard Socher"^^schema:Person ;
    schema:dateModified "2019-02-17T00:23:55Z"^^schema:DateTime ;
    schema:datePublished "2019-02-01T19:23:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Competitive Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.00528v4"^^schema:URL .

<1339> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have revolutionized the field of machine learning byproviding unprecedented human-like performance in solving many real-worldproblems such as image and speech recognition. Training of large DNNs, however,is a computationally intensive task, and this necessitates the development ofnovel computing architectures targeting this application. A computationalmemory unit where resistive memory devices are organized in crossbar arrays canbe used to locally store the synaptic weights in their conductance states. Theexpensive multiply accumulate operations can be performed in place usingKirchhoff's circuit laws in a non-von Neumann manner. However, a key challengeremains the inability to alter the conductance states of the devices in areliable manner during the weight update process. We propose a mixed-precisionarchitecture that combines a computational memory unit storing the synapticweights with a digital processing unit and an additional memory unitaccumulating weight updates in high precision. The new architecture deliversclassification accuracies comparable to those of floating-point implementationswithout being constrained by challenges associated with the non-ideal weightupdate characteristics of emerging resistive memories. A two layer neuralnetwork in which the computational memory unit is realized using non-linearstochastic models of phase-change memory devices achieves a test accuracy of97.40% on the MNIST handwritten digit classification problem."^^schema:Text ;
    schema:author "Abu Sebastian"^^schema:Person,
        "Bipin Rajendran"^^schema:Person,
        "Evangelos Eleftheriou"^^schema:Person,
        "Irem Boybat"^^schema:Person,
        "Manuel Le Gallo"^^schema:Person,
        "Nandakumar S. R."^^schema:Person ;
    schema:dateModified "2017-12-04T16:54:12Z"^^schema:DateTime ;
    schema:datePublished "2017-12-04T16:54:12Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "Mixed-precision training of deep neural networks using computational  memory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1712.01192v1"^^schema:URL .

<134> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we analyze the numerics of common algorithms for trainingGenerative Adversarial Networks (GANs). Using the formalism of smoothtwo-player games we analyze the associated gradient vector field of GANtraining objectives. Our findings suggest that the convergence of currentalgorithms suffers due to two factors: i) presence of eigenvalues of theJacobian of the gradient vector field with zero real-part, and ii) eigenvalueswith big imaginary part. Using these findings, we design a new algorithm thatovercomes some of these limitations and has better convergence properties.Experimentally, we demonstrate its superiority on training common GANarchitectures and show convergence on GAN architectures that are known to benotoriously hard to train."^^schema:Text ;
    schema:author "Andreas Geiger"^^schema:Person,
        "Lars Mescheder"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person ;
    schema:commentCount "208"^^schema:Integer ;
    schema:dateModified "2018-06-11T13:12:41Z"^^schema:DateTime ;
    schema:datePublished "2017-05-30T05:54:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "The Numerics of GANs"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10461v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10067526666278916016&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1340> a schema:ScholarlyArticle ;
    schema:abstract "Sequential recommendation systems model dynamic preferences of users based ontheir historical interactions with platforms. Despite recent progress, modelingshort-term and long-term behavior of users in such systems is nontrivial andchallenging. To address this, we present a solution enhanced by a knowledgegraph called KATRec (Knowledge Aware aTtentive sequential Recommendations).KATRec learns the short and long-term interests of users by modeling theirsequence of interacted items and leveraging pre-existing side informationthrough a knowledge graph attention network. Our novel knowledge graph-enhancedsequential recommender contains item multi-relations at the entity-level andusers' dynamic sequences at the item-level. KATRec improves item representationlearning by considering higher-order connections and incorporating them in userpreference representation while recommending the next item. Experiments onthree public datasets show that KATRec outperforms state-of-the-artrecommendation models and demonstrates the importance of modeling both temporaland side information to achieve high-quality recommendations."^^schema:Text ;
    schema:author "Danial Mohseni-Taheri"^^schema:Person,
        "Mehrnaz Amjadi"^^schema:Person,
        "Theja Tulabandhula"^^schema:Person ;
    schema:dateModified "2020-12-06T17:03:52Z"^^schema:DateTime ;
    schema:datePublished "2020-12-06T17:03:52Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text ;
    schema:headline "KATRec: Knowledge Aware aTtentive Sequential Recommendations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.03323v1"^^schema:URL .

<1341> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks (DNNs) have achieved outstanding performance in a widerange of applications, e.g., image classification, natural language processing,etc. Despite the good performance, the huge number of parameters in DNNs bringschallenges to efficient training of DNNs and also their deployment in low-enddevices with limited computing resources. In this paper, we explore thecorrelations in the weight matrices, and approximate the weight matrices withthe low-rank block-term tensors. We name the new corresponding structure asblock-term tensor layers (BT-layers), which can be easily adapted to neuralnetwork models, such as CNNs and RNNs. In particular, the inputs and theoutputs in BT-layers are reshaped into low-dimensional high-order tensors witha similar or improved representation power. Sufficient experiments havedemonstrated that BT-layers in CNNs and RNNs can achieve a very largecompression ratio on the number of parameters while preserving or improving therepresentation power of the original DNNs."^^schema:Text ;
    schema:author "Di Chen"^^schema:Person,
        "Guangxi Li"^^schema:Person,
        "Haiqin Yang"^^schema:Person,
        "Jinmian Ye"^^schema:Person,
        "Shandian Zhe"^^schema:Person,
        "Zenglin Xu"^^schema:Person ;
    schema:dateModified "2020-12-18T06:47:53Z"^^schema:DateTime ;
    schema:datePublished "2020-10-10T09:58:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Block-term Tensor Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.04963v2"^^schema:URL .

<1342> a schema:ScholarlyArticle ;
    schema:abstract "Allowing effective inference of latent vectors while training GANs cangreatly increase their applicability in various downstream tasks. Recentapproaches, such as ALI and BiGAN frameworks, develop methods of inference oflatent variables in GANs by adversarially training an image generator alongwith an encoder to match two joint distributions of image and latent vectorpairs. We generalize these approaches to incorporate multiple layers offeedback on reconstructions, self-supervision, and other forms of supervisionbased on prior or learned knowledge about the desired solutions. We achievethis by modifying the discriminator's objective to correctly identify more thantwo joint distributions of tuples of an arbitrary number of random variablesconsisting of images, latent vectors, and other variables generated throughauxiliary tasks, such as reconstruction and inpainting or as outputs ofsuitable pre-trained models. We design a non-saturating maximization objectivefor the generator-encoder pair and prove that the resulting adversarial gamecorresponds to a global optimum that simultaneously matches all thedistributions. Within our proposed framework, we introduce a novel set oftechniques for providing self-supervised feedback to the model based onproperties, such as patch-level correspondence and cycle consistency ofreconstructions. Through comprehensive experiments, we demonstrate theefficacy, scalability, and flexibility of the proposed approach for a varietyof tasks."^^schema:Text ;
    schema:author "Abhishek Kumar"^^schema:Person,
        "Homanga Bharadhwaj"^^schema:Person,
        "Piyush Rai"^^schema:Person,
        "Yatin Dandi"^^schema:Person ;
    schema:dateModified "2020-12-21T15:34:08Z"^^schema:DateTime ;
    schema:datePublished "2020-06-15T02:18:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generalized Adversarially Learned Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.08089v3"^^schema:URL .

<1343> a schema:ScholarlyArticle ;
    schema:abstract "The Maximum Mean Discrepancy (MMD) has found numerous applications instatistics and machine learning, most recently as a penalty in the WassersteinAuto-Encoder (WAE). In this paper we compute closed-form expressions forestimating the Gaussian kernel based MMD between a given distribution and thestandard multivariate normal distribution. This formula reveals a connection tothe Baringhaus-Henze-Epps-Pulley (BHEP) statistic of the Henze-Zirkler test andprovides further insights about the MMD. We introduce the standardized versionof MMD as a penalty for the WAE training objective, allowing for a betterinterpretability of MMD values and more compatibility across differenthyperparameter settings. Next, we propose using a version of batchnormalization at the code layer; this has the benefits of making the kernelwidth selection easier, reducing the training effort, and preventing outliersin the aggregate code distribution. Our experiments on synthetic and real datashow that the analytic formulation improves over the commonly used stochasticapproximation of the MMD, and demonstrate that code normalization providessignificant benefits when training WAEs."^^schema:Text ;
    schema:author "Raif M. Rustamov"^^schema:Person ;
    schema:dateModified "2020-06-02T17:53:22Z"^^schema:DateTime ;
    schema:datePublished "2019-01-10T15:43:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Closed-form Expressions for Maximum Mean Discrepancy with Applications  to Wasserstein Auto-Encoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.03227v2"^^schema:URL .

<1344> a schema:ScholarlyArticle ;
    schema:abstract "Long Short-Term Memory Networks (LSTMs) have been applied to daily dischargeprediction with remarkable success. Many practical scenarios, however, requirepredictions at more granular timescales. For instance, accurate prediction ofshort but extreme flood peaks can make a life-saving difference, yet such peaksmay escape the coarse temporal resolution of daily predictions. Naivelytraining an LSTM on hourly data, however, entails very long input sequencesthat make learning hard and computationally expensive. In this study, wepropose two Multi-Timescale LSTM (MTS-LSTM) architectures that jointly predictmultiple timescales within one model, as they process long-past inputs at asingle temporal resolution and branch out into each individual timescale formore recent input steps. We test these models on 516 basins across thecontinental United States and benchmark against the US National Water Model.Compared to naive prediction with a distinct LSTM per timescale, themulti-timescale architectures are computationally more efficient with no lossin accuracy. Beyond prediction quality, the multi-timescale LSTM can processdifferent input variables at different timescales, which is especially relevantto operational applications where the lead time of meteorological forcingsdepends on their temporal resolution."^^schema:Text ;
    schema:author "Daniel Klotz"^^schema:Person,
        "Frederik Kratzert"^^schema:Person,
        "Grey Nearing"^^schema:Person,
        "Jimmy Lin"^^schema:Person,
        "Martin Gauch"^^schema:Person,
        "Sepp Hochreiter"^^schema:Person ;
    schema:dateModified "2020-10-15T17:52:16Z"^^schema:DateTime ;
    schema:datePublished "2020-10-15T17:52:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "physics.ao-ph"^^schema:Text ;
    schema:headline "Rainfall-Runoff Prediction at Multiple Timescales with a Single Long  Short-Term Memory Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07921v1"^^schema:URL .

<1345> a schema:ScholarlyArticle ;
    schema:abstract "We study the roots of algorithmic progress in deep policy gradient algorithmsthrough a case study on two popular algorithms: Proximal Policy Optimization(PPO) and Trust Region Policy Optimization (TRPO). Specifically, we investigatethe consequences of \"code-level optimizations:\" algorithm augmentations foundonly in implementations or described as auxiliary details to the corealgorithm. Seemingly of secondary importance, such optimizations turn out tohave a major impact on agent behavior. Our results show that they (a) areresponsible for most of PPO's gain in cumulative reward over TRPO, and (b)fundamentally change how RL methods function. These insights show thedifficulty and importance of attributing performance gains in deepreinforcement learning. Code for reproducing our results is available athttps://github.com/MadryLab/implementation-matters ."^^schema:Text ;
    schema:author "Aleksander Madry"^^schema:Person,
        "Andrew Ilyas"^^schema:Person,
        "Dimitris Tsipras"^^schema:Person,
        "Firdaus Janoos"^^schema:Person,
        "Larry Rudolph"^^schema:Person,
        "Logan Engstrom"^^schema:Person,
        "Shibani Santurkar"^^schema:Person ;
    schema:dateModified "2020-05-25T16:24:59Z"^^schema:DateTime ;
    schema:datePublished "2020-05-25T16:24:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Implementation Matters in Deep Policy Gradients: A Case Study on PPO and  TRPO"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.12729v1"^^schema:URL .

<1346> a schema:ScholarlyArticle ;
    schema:abstract "Transition-based top-down parsing with pointer networks has achievedstate-of-the-art results in multiple parsing tasks, while having a linear timecomplexity. However, the decoder of these parsers has a sequential structure,which does not yield the most appropriate inductive bias for deriving treestructures. In this paper, we propose hierarchical pointer network parsers, andapply them to dependency and sentence-level discourse parsing tasks. Ourresults on standard benchmark datasets demonstrate the effectiveness of ourapproach, outperforming existing methods and setting a new state-of-the-art."^^schema:Text ;
    schema:author "Lidong Bing"^^schema:Person,
        "Linlin Liu"^^schema:Person,
        "Shafiq Joty"^^schema:Person,
        "Simeng Han"^^schema:Person,
        "Xiang Lin"^^schema:Person ;
    schema:dateModified "2019-08-30T07:22:43Z"^^schema:DateTime ;
    schema:datePublished "2019-08-30T07:22:43Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Hierarchical Pointer Net Parsing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.11571v1"^^schema:URL .

<1347> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we present a fully automated lung computed tomography (CT)cancer diagnosis system, DeepLung. DeepLung consists of two components, noduledetection (identifying the locations of candidate nodules) and classification(classifying candidate nodules into benign or malignant). Considering the 3Dnature of lung CT data and the compactness of dual path networks (DPN), twodeep 3D DPN are designed for nodule detection and classification respectively.Specifically, a 3D Faster Regions with Convolutional Neural Net (R-CNN) isdesigned for nodule detection with 3D dual path blocks and a U-net-likeencoder-decoder structure to effectively learn nodule features. For noduleclassification, gradient boosting machine (GBM) with 3D dual path networkfeatures is proposed. The nodule classification subnetwork was validated on apublic dataset from LIDC-IDRI, on which it achieved better performance thanstate-of-the-art approaches and surpassed the performance of experienceddoctors based on image modality. Within the DeepLung system, candidate nodulesare detected first by the nodule detection subnetwork, and nodule diagnosis isconducted by the classification subnetwork. Extensive experimental resultsdemonstrate that DeepLung has performance comparable to experienced doctorsboth for the nodule-level and patient-level diagnosis on the LIDC-IDRIdataset.\\footnote{https://github.com/uci-cbcl/DeepLung.git}"^^schema:Text ;
    schema:author "Chaochun Liu"^^schema:Person,
        "Wei Fan"^^schema:Person,
        "Wentao Zhu"^^schema:Person,
        "Xiaohui Xie"^^schema:Person ;
    schema:dateModified "2018-01-25T23:22:00Z"^^schema:DateTime ;
    schema:datePublished "2018-01-25T23:22:00Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "DeepLung: Deep 3D Dual Path Nets for Automated Pulmonary Nodule  Detection and Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.09555v1"^^schema:URL .

<1348> a schema:ScholarlyArticle ;
    schema:abstract "Optical satellite sensors cannot see the Earth's surface through clouds.Despite the periodic revisit cycle, image sequences acquired by Earthobservation satellites are therefore irregularly sampled in time.State-of-the-art methods for crop classification (and other time seriesanalysis tasks) rely on techniques that implicitly assume regular temporalspacing between observations, such as recurrent neural networks (RNNs). Wepropose to use neural ordinary differential equations (NODEs) in combinationwith RNNs to classify crop types in irregularly spaced image sequences. Theresulting ODE-RNN models consist of two steps: an update step, where arecurrent unit assimilates new input data into the model's hidden state; and aprediction step, in which NODE propagates the hidden state until the nextobservation arrives. The prediction step is based on a continuousrepresentation of the latent dynamics, which has several advantages. At theconceptual level, it is a more natural way to describe the mechanisms thatgovern the phenological cycle. From a practical point of view, it makes itpossible to sample the system state at arbitrary points in time, such that onecan integrate observations whenever they are available, and extrapolate beyondthe last observation. Our experiments show that ODE-RNN indeed improvesclassification accuracy over common baselines such as LSTM, GRU, and temporalconvolution. The gains are most prominent in the challenging scenario whereonly few observations are available (i.e., frequent cloud cover). Moreover, weshow that the ability to extrapolate translates to better classificationperformance early in the season, which is important for forecasting."^^schema:Text ;
    schema:author "Jan Dirk Wegner"^^schema:Person,
        "Konrad Schindler"^^schema:Person,
        "Mehmet Ozgur Turkoglu"^^schema:Person,
        "Nando Metzger"^^schema:Person,
        "Stefano D'Aronco"^^schema:Person ;
    schema:dateModified "2020-12-04T11:56:50Z"^^schema:DateTime ;
    schema:datePublished "2020-12-04T11:56:50Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Crop Classification under Varying Cloud Cover with Neural Ordinary  Differential Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02542v1"^^schema:URL .

<1349> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we consider a platform of flying mobile edge computing(F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providingcomputation resource, and they enable task offloading from user equipment (UE).We aim to minimize energy consumption of all the UEs via optimizing the userassociation, resource allocation and the trajectory of UAVs. To this end, wefirst propose a Convex optimizAtion based Trajectory control algorithm (CAT),which solves the problem in an iterative way by using block coordinate descent(BCD) method. Then, to make the real-time decision while taking into accountthe dynamics of the environment (i.e., UAV may take off from differentlocations), we propose a deep Reinforcement leArning based Trajectory controlalgorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) toimprove the convergence of the training procedure. Different from the convexoptimization based algorithm which may be susceptible to the initial points andrequires iterations, RAT can be adapted to any taking off points of the UAVsand can obtain the solution more rapidly than CAT once training process hasbeen completed. Simulation results show that the proposed CAT and RAT achievethe similar performance and both outperform traditional algorithms."^^schema:Text ;
    schema:author "Arumugam Nallanathan"^^schema:Person,
        "Cunhua Pan"^^schema:Person,
        "Kezhi Wang"^^schema:Person,
        "Liang Wang"^^schema:Person,
        "Nauman Aslam"^^schema:Person,
        "Wei Xu"^^schema:Person ;
    schema:dateModified "2019-11-10T10:24:04Z"^^schema:DateTime ;
    schema:datePublished "2019-11-10T10:24:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text,
        "eess.SP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning Based Dynamic Trajectory Control for  UAV-assisted Mobile Edge Computing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.03887v1"^^schema:URL .

<135> a schema:ScholarlyArticle ;
    schema:abstract "For natural language understanding (NLU) technology to be maximally useful,both practically and as a scientific object of study, it must be general: itmust be able to process language in a way that is not exclusively tailored toany one specific task or dataset. In pursuit of this objective, we introducethe General Language Understanding Evaluation benchmark (GLUE), a tool forevaluating and analyzing the performance of models across a diverse range ofexisting NLU tasks. GLUE is model-agnostic, but it incentivizes sharingknowledge across tasks because certain tasks have very limited training data.We further provide a hand-crafted diagnostic test suite that enables detailedlinguistic analysis of NLU models. We evaluate baselines based on currentmethods for multi-task and transfer learning and find that they do notimmediately give substantial improvements over the aggregate performance oftraining a separate model per task, indicating room for improvement indeveloping general and robust NLU systems."^^schema:Text ;
    schema:author "Alex Wang"^^schema:Person,
        "Amanpreet Singh"^^schema:Person,
        "Felix Hill"^^schema:Person,
        "Julian Michael"^^schema:Person,
        "Omer Levy"^^schema:Person,
        "Samuel R. Bowman"^^schema:Person ;
    schema:commentCount "619"^^schema:Integer ;
    schema:dateModified "2019-02-22T23:53:34Z"^^schema:DateTime ;
    schema:datePublished "2018-04-20T06:35:04Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language  Understanding"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.07461v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17443412968683100072&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1350> a schema:ScholarlyArticle ;
    schema:abstract "Neural end-to-end goal-oriented dialog systems showed promise to reduce theworkload of human agents for customer service, as well as reduce wait time forusers. However, their inability to handle new user behavior at deployment haslimited their usage in real world. In this work, we propose an end-to-endtrainable method for neural goal-oriented dialog systems which handles new userbehaviors at deployment by transferring the dialog to a human agentintelligently. The proposed method has three goals: 1) maximize user's tasksuccess by transferring to human agents, 2) minimize the load on the humanagents by transferring to them only when it is essential and 3) learn onlinefrom the human agent's responses to reduce human agents load further. Weevaluate our proposed method on a modified-bAbI dialog task that simulates thescenario of new user behaviors occurring at test time. Experimental resultsshow that our proposed method is effective in achieving the desired goals."^^schema:Text ;
    schema:author "Janarthanan Rajendran"^^schema:Person,
        "Jatin Ganhotra"^^schema:Person,
        "Lazaros Polymenakos"^^schema:Person ;
    schema:dateModified "2019-07-17T16:50:16Z"^^schema:DateTime ;
    schema:datePublished "2019-07-17T16:50:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Learning End-to-End Goal-Oriented Dialog with Maximal User Task Success  and Minimal Human Agent Use"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.07638v1"^^schema:URL .

<1351> a schema:ScholarlyArticle ;
    schema:abstract "Product recommendation can be considered as a problem in data fusion--estimation of the joint distribution between individuals, their behaviors, andgoods or services of interest. This work proposes a conditional, coupledgenerative adversarial network (RecommenderGAN) that learns to produce samplesfrom a joint distribution between (view, buy) behaviors found in extremelysparse implicit feedback training data. User interaction is represented by twomatrices having binary-valued elements. In each matrix, nonzero values indicatewhether a user viewed or bought a specific item in a given product category,respectively. By encoding actions in this manner, the model is able torepresent entire, large scale product catalogs. Conversion rate statisticscomputed on trained GAN output samples ranged from 1.323 to 1.763 percent.These statistics are found to be significant in comparison to null hypothesistesting results. The results are shown comparable to published conversion ratesaggregated across many industries and product types. Our results arepreliminary, however they suggest that the recommendations produced by themodel may provide utility for consumers and digital retailers."^^schema:Text ;
    schema:author "Akhilesh Maewal"^^schema:Person,
        "Joel R. Bock"^^schema:Person ;
    schema:dateModified "2020-09-01T15:01:29Z"^^schema:DateTime ;
    schema:datePublished "2020-07-07T23:35:36Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Adversarial learning for product recommendation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.07269v2"^^schema:URL .

<1352> a schema:ScholarlyArticle ;
    schema:abstract "An agent that has well understood the environment should be able to apply itsskills for any given goals, leading to the fundamental problem of learning theUniversal Value Function Approximator (UVFA). A UVFA learns to predict thecumulative rewards between all state-goal pairs. However, empirically, thevalue function for long-range goals is always hard to estimate and mayconsequently result in failed policy. This has presented challenges to thelearning process and the capability of neural networks. We propose a method toaddress this issue in large MDPs with sparse rewards, in which exploration androuting across remote states are both extremely challenging. Our methodexplicitly models the environment in a hierarchical manner, with a high-leveldynamic landmark-based map abstracting the visited state space, and a low-levelvalue network to derive precise local decisions. We use farthest point samplingto select landmark states from past experience, which has improved explorationcompared with simple uniform sampling. Experimentally we showed that our methodenables the agent to reach long-range goals at the early training stage, andachieve better performance than standard RL algorithms for a number ofchallenging tasks."^^schema:Text ;
    schema:author "Fangchen Liu"^^schema:Person,
        "Hao Su"^^schema:Person,
        "Zhiao Huang"^^schema:Person ;
    schema:dateModified "2019-08-15T08:01:56Z"^^schema:DateTime ;
    schema:datePublished "2019-08-15T08:01:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Mapping State Space using Landmarks for Universal Goal Reaching"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.05451v1"^^schema:URL .

<1353> a schema:ScholarlyArticle ;
    schema:abstract "Fair machine learning is receiving an increasing attention in machinelearning fields. Researchers in fair learning have developed correlation orassociation-based measures such as demographic disparity, mistreatmentdisparity, calibration, causal-based measures such as total effect, direct andindirect discrimination, and counterfactual fairness, and fairness notions suchas equality of opportunity and equal odds that consider both decisions in thetraining data and decisions made by predictive models. In this paper, wedevelop a new causal-based fairness notation, called equality of effort.Different from existing fairness notions which mainly focus on discovering thedisparity of decisions between two groups of individuals, the proposed equalityof effort notation helps answer questions like to what extend a legitimatevariable should change to make a particular individual achieve a certainoutcome level and addresses the concerns whether the efforts made to achievethe same outcome level for individuals from the protected group and that fromthe unprotected group are different. We develop algorithms for determiningwhether an individual or a group of individuals is discriminated in terms ofequality of effort. We also develop an optimization-based method for removingdiscriminatory effects from the data if discrimination is detected. We conductempirical evaluations to compare the equality of effort and existing fairnessnotion and show the effectiveness of our proposed algorithms."^^schema:Text ;
    schema:author "Lu Zhang"^^schema:Person,
        "Wen Huang"^^schema:Person,
        "Xintao Wu"^^schema:Person,
        "Yongkai Wu"^^schema:Person ;
    schema:dateModified "2019-11-11T18:49:45Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T18:49:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text ;
    schema:headline "Fairness through Equality of Effort"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.08292v1"^^schema:URL .

<1354> a schema:ScholarlyArticle ;
    schema:abstract "Ultrasound images are one of the most widely used techniques in clinicalsettings to analyze and detect different organs for study or diagnoses ofdiseases. The dependence on subjective opinions of experts such as radiologistscalls for an automatic recognition and detection system that can provide anobjective analysis. Previous work done on this topic is limited and can beclassified by the organ of interest. Hybrid neural networks, linear andlogistic regression models, 3D reconstructed models, and various machinelearning techniques have been used to solve complex problems such as detectionof lesions and cancer. Our project aims to use Dual Path Networks (DPN) tosegment and detect shapes in ultrasound images taken from 3D printed models ofthe liver. Further the DPN deep architectures could be coupled with FullyConvolutional Network (FCN) to refine the results. Data denoised with variousfilters would be used to gauge how they fare against each other and provide thebest results. Small amount of dataset works with DPNs, and hence, that shouldbe appropriate for us as our dataset shall be limited in size. Moreover, theultrasound scans shall need to be taken from different orientations of thescanner with respect to the organ, such that the training dataset canaccurately perform segmentation and shape detection."^^schema:Text ;
    schema:author "Haixia Wu"^^schema:Person,
        "Ruturaj Gole"^^schema:Person,
        "Subho Ghose"^^schema:Person ;
    schema:dateModified "2019-11-22T05:27:00Z"^^schema:DateTime ;
    schema:datePublished "2019-11-22T05:27:00Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Shape Detection In 2D Ultrasound Images"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.09863v1"^^schema:URL .

<1355> a schema:ScholarlyArticle ;
    schema:abstract "We present recurrent transformer networks (RTNs) for obtaining densecorrespondences between semantically similar images. Our networks accomplishthis through an iterative process of estimating spatial transformations betweenthe input images and using these transformations to generate alignedconvolutional activations. By directly estimating the transformations betweenan image pair, rather than employing spatial transformer networks toindependently normalize each individual image, we show that greater accuracycan be achieved. This process is conducted in a recursive manner to refine boththe transformation estimates and the feature representations. In addition, atechnique is presented for weakly-supervised training of RTNs that is based ona proposed classification loss. With RTNs, state-of-the-art performance isattained on several benchmarks for semantic correspondence."^^schema:Text ;
    schema:author "Dongbo Min"^^schema:Person,
        "Kwanghoon Sohn"^^schema:Person,
        "Sangryul Jeon"^^schema:Person,
        "Seungryong Kim"^^schema:Person,
        "Stephen Lin"^^schema:Person ;
    schema:dateModified "2018-10-29T14:37:29Z"^^schema:DateTime ;
    schema:datePublished "2018-10-29T14:37:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Recurrent Transformer Networks for Semantic Correspondence"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.12155v1"^^schema:URL .

<1356> a schema:ScholarlyArticle ;
    schema:abstract "In this study, we propose a novel framework for hyperspectral unmixing byusing an improved deep spectral convolution network (DSCN++) combined withendmember uncertainty. DSCN++ is used to compute high-level representationswhich are further modeled with Multinomial Mixture Model to estimate abundancemaps. In the reconstruction step, a new trainable uncertainty term based on anonlinear neural network model is introduced to provide robustness to endmemberuncertainty. For the optimization of the coefficients of the multinomial modeland the uncertainty term, Wasserstein Generative Adversarial Network (WGAN) isexploited to improve stability and to capture uncertainty. Experiments areperformed on both real and synthetic datasets. The results validate that theproposed method obtains state-of-the-art hyperspectral unmixing performanceparticularly on the real datasets compared to the baseline techniques."^^schema:Text ;
    schema:author "Gozde Bozdagi Akar"^^schema:Person,
        "Savas Ozkan"^^schema:Person ;
    schema:dateModified "2019-10-20T18:38:01Z"^^schema:DateTime ;
    schema:datePublished "2018-08-03T07:40:25Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Improved Deep Spectral Convolution Network For Hyperspectral Unmixing  With Multinomial Mixture Kernel and Endmember Uncertainty"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.01104v4"^^schema:URL .

<1357> a schema:ScholarlyArticle ;
    schema:abstract "A key question for machine learning approaches in particle physics is how tobest represent and learn from collider events. As an event is intrinsically avariable-length unordered set of particles, we build upon recent machinelearning efforts to learn directly from sets of features or \"point clouds\".Adapting and specializing the \"Deep Sets\" framework to particle physics, weintroduce Energy Flow Networks, which respect infrared and collinear safety byconstruction. We also develop Particle Flow Networks, which allow for generalenergy dependence and the inclusion of additional particle-level informationsuch as charge and flavor. These networks feature a per-particle internal(latent) representation, and summing over all particles yields an overallevent-level latent representation. We show how this latent space decompositionunifies existing event representations based on detector images and radiationmoments. To demonstrate the power and simplicity of this set-based approach, weapply these networks to the collider task of discriminating quark jets fromgluon jets, finding similar or improved performance compared to existingmethods. We also show how the learned event representation can be directlyvisualized, providing insight into the inner workings of the model. Thesearchitectures lend themselves to efficiently processing and analyzing eventsfor a wide variety of tasks at the Large Hadron Collider. Implementations andexamples of our architectures are available online in our EnergyFlow package."^^schema:Text ;
    schema:author "Eric M. Metodiev"^^schema:Person,
        "Jesse Thaler"^^schema:Person,
        "Patrick T. Komiske"^^schema:Person ;
    schema:dateModified "2019-01-11T18:35:51Z"^^schema:DateTime ;
    schema:datePublished "2018-10-11T18:00:00Z"^^schema:DateTime ;
    schema:genre "hep-ex"^^schema:Text,
        "hep-ph"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Energy Flow Networks: Deep Sets for Particle Jets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.05165v2"^^schema:URL .

<1358> a schema:ScholarlyArticle ;
    schema:abstract "While hardware implementations of inference routines for Binarized NeuralNetworks (BNNs) are plentiful, current realizations of efficient BNN hardwaretraining accelerators, suitable for Internet of Things (IoT) edge devices,leave much to be desired. Conventional BNN hardware training acceleratorsperform forward and backward propagations with parameters adopting binaryrepresentations, and optimization using parameters adopting floating orfixed-point real-valued representations--requiring two distinct sets of networkparameters. In this paper, we propose a hardware-friendly training method that,contrary to conventional methods, progressively binarizes a singular set offixed-point network parameters, yielding notable reductions in power andresource utilizations. We use the Intel FPGA SDK for OpenCL developmentenvironment to train our progressively binarizing DNNs on an OpenVINO FPGA. Webenchmark our training approach on both GPUs and FPGAs using CIFAR-10 andcompare it to conventional BNNs."^^schema:Text ;
    schema:author "Corey Lammie"^^schema:Person,
        "Mostafa Rahimi Azghadi"^^schema:Person,
        "Wei Xiang"^^schema:Person ;
    schema:dateModified "2020-01-08T06:01:13Z"^^schema:DateTime ;
    schema:datePublished "2020-01-08T06:01:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Training Progressively Binarizing Deep Networks Using FPGAs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.02390v1"^^schema:URL .

<1359> a schema:ScholarlyArticle ;
    schema:abstract "Recent work has established the equivalence between deep neural networks andGaussian processes (GPs), resulting in so-called neural network Gaussianprocesses (NNGPs). The behaviour of these models depends on the initialisationof the corresponding network. In this work, we consider the impact of noiseregularisation (e.g. dropout) on NNGPs, and relate their behaviour to signalpropagation theory in noise regularised deep neural networks. For ReLUactivations, we find that the best performing NNGPs have kernel parameters thatcorrespond to a recently proposed initialisation scheme for noise regularisedReLU networks. In addition, we show how the noise influences the covariancematrix of the NNGP, producing a stronger prior towards simple functions awayfrom the training points. We verify our theoretical findings with experimentson MNIST and CIFAR-10 as well as on synthetic data."^^schema:Text ;
    schema:author "Arnu Pretorius"^^schema:Person,
        "Herman Kamper"^^schema:Person,
        "Steve Kroon"^^schema:Person ;
    schema:dateModified "2019-10-12T13:23:58Z"^^schema:DateTime ;
    schema:datePublished "2019-10-12T13:23:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the expected behaviour of noise regularised deep neural networks as  Gaussian processes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.05563v1"^^schema:URL .

<136> a schema:ScholarlyArticle ;
    schema:abstract "We present a semi-supervised learning framework based on graph embeddings.Given a graph between instances, we train an embedding for each instance tojointly predict the class label and the neighborhood context in the graph. Wedevelop both transductive and inductive variants of our method. In thetransductive variant of our method, the class labels are determined by both thelearned embeddings and input feature vectors, while in the inductive variant,the embeddings are defined as a parametric function of the feature vectors, sopredictions can be made on instances not seen during training. On a large anddiverse set of benchmark tasks, including text classification, distantlysupervised entity extraction, and entity classification, we show improvedperformance over many of the existing models."^^schema:Text ;
    schema:author "Ruslan Salakhutdinov"^^schema:Person,
        "William W. Cohen"^^schema:Person,
        "Zhilin Yang"^^schema:Person ;
    schema:commentCount "577"^^schema:Integer ;
    schema:dateModified "2016-05-26T23:57:09Z"^^schema:DateTime ;
    schema:datePublished "2016-03-29T17:46:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Revisiting Semi-Supervised Learning with Graph Embeddings"^^schema:Text ;
    schema:publisher "ICML, 40-48"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.08861v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1517411880091060899&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1360> a schema:ScholarlyArticle ;
    schema:abstract "International Classification of Diseases(ICD) is an authoritative health careclassification system of different diseases and conditions for clinical andmanagement purposes. Considering the complicated and dedicated process toassign correct codes to each patient admission based on overall diagnosis, wepropose a hierarchical deep learning model with attention mechanism which canautomatically assign ICD diagnostic codes given written diagnosis. We utilizecharacter-aware neural language models to generate hidden representations ofwritten diagnosis descriptions and ICD codes, and design an attention mechanismto address the mismatch between the numbers of descriptions and correspondingcodes. Our experimental results show the strong potential of automated ICDcoding from diagnosis descriptions. Our best model achieves 0.53 and 0.90 of F1score and area under curve of receiver operating characteristic respectively.The result outperforms those achieved using character-unaware encoding methodor without attention mechanism. It indicates that our proposed deep learningmodel can code automatically in a reasonable way and provide a framework forcomputer-auxiliary ICD coding."^^schema:Text ;
    schema:author "Eric P. Xing"^^schema:Person,
        "Haoran Shi"^^schema:Person,
        "Ming Zhang"^^schema:Person,
        "Pengtao Xie"^^schema:Person,
        "Zhiting Hu"^^schema:Person ;
    schema:dateModified "2017-11-30T16:16:11Z"^^schema:DateTime ;
    schema:datePublished "2017-11-11T04:34:51Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Towards Automated ICD Coding Using Deep Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.04075v3"^^schema:URL .

<1361> a schema:ScholarlyArticle ;
    schema:abstract "Despite the recent success of reinforcement learning in various domains,these approaches remain, for the most part, deterringly sensitive tohyper-parameters and are often riddled with essential engineering featsallowing their success. We consider the case of off-policy generativeadversarial imitation learning, and perform an in-depth review, qualitative andquantitative, of the method. Crucially, we show that forcing the learned rewardfunction to be local Lipschitz-continuous is a sine qua non condition for themethod to perform well. We then study the effects of this necessary conditionand provide several theoretical results involving the local Lipschitzness ofthe state-value function. Finally, we propose a novel reward-modulationtechnique inspired from a new interpretation of gradient-penalty regularizationin reinforcement learning. Besides being extremely easy to implement andbringing little to no overhead, we show that our method provides improvementsin several continuous control environments of the MuJoCo suite."^^schema:Text ;
    schema:author "Alexandros Kalousis"^^schema:Person,
        "Lionel Blondé"^^schema:Person,
        "Pablo Strasser"^^schema:Person ;
    schema:dateModified "2020-06-28T20:55:31Z"^^schema:DateTime ;
    schema:datePublished "2020-06-28T20:55:31Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial  Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16785v1"^^schema:URL .

<1362> a schema:ScholarlyArticle ;
    schema:abstract "Zero-shot domain adaptation (ZSDA) is a category of domain adaptationproblems where neither data sample nor label is available for parameterlearning in the target domain. With the hypothesis that the shift between agiven pair of domains is shared across tasks, we propose a new method for ZSDAby transferring domain shift from an irrelevant task (IrT) to the task ofinterest (ToI). Specifically, we first identify an IrT, where dual-domainsamples are available, and capture the domain shift with a coupled generativeadversarial networks (CoGAN) in this task. Then, we train a CoGAN for the ToIand restrict it to carry the same domain shift as the CoGAN for IrT does. Inaddition, we introduce a pair of co-training classifiers to regularize thetraining procedure of CoGAN in the ToI. The proposed method not only derivesmachine learning models for the non-available target-domain data, but alsosynthesizes the data themselves. We evaluate the proposed method on benchmarkdatasets and achieve the state-of-the-art performances."^^schema:Text ;
    schema:author "Jianmin Jiang"^^schema:Person,
        "Jinghua Wang"^^schema:Person ;
    schema:dateModified "2020-09-11T03:41:32Z"^^schema:DateTime ;
    schema:datePublished "2020-09-11T03:41:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Adversarial Learning for Zero-shot Domain Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.05214v1"^^schema:URL .

<1363> a schema:ScholarlyArticle ;
    schema:abstract "Automatic crack detection on pavement surfaces is an important research fieldin the scope of developing an intelligent transportation infrastructure system.In this paper, a cost effective solution for road crack inspection by mountingcommercial grade sport camera, GoPro, on the rear of the moving vehicle isintroduced. Also, a novel method called ConnCrack combining conditionalWasserstein generative adversarial network and connectivity maps is proposedfor road crack detection. In this method, a 121-layer densely connected neuralnetwork with deconvolution layers for multi-level feature fusion is used asgenerator, and a 5-layer fully convolutional network is used as discriminator.To overcome the scattered output issue related to deconvolution layers,connectivity maps are introduced to represent the crack information within theproposed ConnCrack. The proposed method is tested on a publicly availabledataset as well our collected data. The results show that the proposed methodachieves state-of-the-art performance compared with other existing methods interms of precision, recall and F1 score."^^schema:Text ;
    schema:author "Mustafa Gül"^^schema:Person,
        "Qipei Mei"^^schema:Person ;
    schema:dateModified "2019-10-22T04:29:26Z"^^schema:DateTime ;
    schema:datePublished "2019-07-13T05:43:06Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "A Cost Effective Solution for Road Crack Inspection using Cameras and  Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.06014v2"^^schema:URL .

<1364> a schema:ScholarlyArticle ;
    schema:abstract "Cooperative motion planning is still a challenging task for robots. Recently,Value Iteration Networks (VINs) were proposed to model motion planning tasks asNeural Networks. In this work, we extend VINs to solve cooperative planningtasks under non-holonomic constraints. For this, we interconnect multiple VINsto pay respect to each other's outputs. Policies for cooperation are generatedvia iterative gradient descend. Validation in simulation shows that theresulting networks can resolve non-holonomic motion planning problems thatrequire cooperation."^^schema:Text ;
    schema:author "Christoph Stiller"^^schema:Person,
        "Eike Rehder"^^schema:Person,
        "Maximilian Naumann"^^schema:Person,
        "Niels Ole Salscheider"^^schema:Person ;
    schema:dateModified "2017-09-15T15:36:51Z"^^schema:DateTime ;
    schema:datePublished "2017-09-15T15:36:51Z"^^schema:DateTime ;
    schema:genre "cs.MA"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Cooperative Motion Planning for Non-Holonomic Agents with Value  Iteration Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.05273v1"^^schema:URL .

<1365> a schema:ScholarlyArticle ;
    schema:abstract "Scenario generations of cooling, heating, and power loads are of greatsignificance for the economic operation and stability analysis of integratedenergy systems. In this paper, a novel deep generative network is proposed tomodel cooling, heating, and power load curves based on generative momentmatching networks (GMMN) where an auto-encoder transforms high-dimensional loadcurves into low-dimensional latent variables and the maximum mean discrepancyrepresents the similarity metrics between the generated samples and the realsamples. After training the model, the new scenarios are generated by feedingGaussian noise to the generator of the GMMN. Unlike the explicit densitymodels, the proposed GMMN does not need to artificially assume the probabilitydistribution of the load curves, which leads to stronger universality. Thesimulation results show that GMMN not only fits the probability distribution ofmultiple load curves well, but also accurately captures the shape (e.g., largepeaks, fast ramps, and fluctuation), frequency-domain characteristics, andtemporal-spatial correlations of cooling, heating, and power loads.Furthermore, the energy consumption of generated samples closely resembles thatof real samples."^^schema:Text ;
    schema:author "Kody Powell"^^schema:Person,
        "Qi Liu"^^schema:Person,
        "Wenlong Liao"^^schema:Person,
        "Yuelong Wang"^^schema:Person,
        "Yusen Wang"^^schema:Person ;
    schema:dateModified "2021-02-05T18:57:22Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T18:57:22Z"^^schema:DateTime ;
    schema:genre "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Scenario Generation for Cooling, Heating, and Power Loads Using  Generative Moment Matching Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03360v1"^^schema:URL .

<1366> a schema:ScholarlyArticle ;
    schema:abstract "Perfect channel state information (CSI) is usually required when consideringrelay selection and power allocation in cooperative communication. However, itis difficult to get an accurate CSI in practical situations. In this letter, westudy the outage probability minimizing problem based on optimizing relayselection and transmission power. We propose a prioritized experience replayaided deep deterministic policy gradient learning framework, which can find anoptimal solution by dealing with continuous action space, without any priorknowledge of CSI. Simulation results reveal that our approach outperformsreinforcement learning based methods in existing literatures, and improves thecommunication success rate by about 5%."^^schema:Text ;
    schema:author "Erwu Liu"^^schema:Person,
        "Gang Shen"^^schema:Person,
        "Jie Wang"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Yiming Liu"^^schema:Person,
        "Yuanzhe Geng"^^schema:Person,
        "Zhao Dong"^^schema:Person ;
    schema:dateModified "2021-01-28T14:47:41Z"^^schema:DateTime ;
    schema:datePublished "2020-12-11T12:36:39Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Deep Deterministic Policy Gradient for Relay Selection and Power  Allocation in Cooperative Communication Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.12114v3"^^schema:URL .

<1367> a schema:ScholarlyArticle ;
    schema:abstract "Many state-of-art neural models designed for monotonicity reasoning performpoorly on downward inference. To address this shortcoming, we developed anattentive tree-structured neural network. It consists of a tree-basedlong-short-term-memory network (Tree-LSTM) with soft attention. It is designedto model the syntactic parse tree information from the sentence pair of areasoning task. A self-attentive aggregator is used for aligning therepresentations of the premise and the hypothesis. We present our model andevaluate it using the Monotonicity Entailment Dataset (MED). We show andattempt to explain that our model outperforms existing models on MED."^^schema:Text ;
    schema:author "Zeming Chen"^^schema:Person ;
    schema:dateModified "2021-01-03T01:29:48Z"^^schema:DateTime ;
    schema:datePublished "2021-01-03T01:29:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Attentive Tree-structured Network for Monotonicity Reasoning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.00540v1"^^schema:URL .

<1368> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks (DNN) have been a de facto standard for nowadaysbiometric recognition solutions. A serious, but still overlooked problem inthese DNN-based recognition systems is their vulnerability against adversarialattacks. Adversarial attacks can easily cause the output of a DNN system togreatly distort with only tiny changes in its input. Such distortions canpotentially lead to an unexpected match between a valid biometric and asynthetic one constructed by a strategic attacker, raising security issue. Inthis work, we show how this issue can be resolved by learning robust biometricfeatures through a deep, information-theoretic framework, which builds upon therecent deep variational information bottleneck method but is carefully adaptedto biometric recognition tasks. Empirical evaluation demonstrates that ourmethod not only offers stronger robustness against adversarial attacks but alsoprovides better recognition performance over state-of-the-art approaches."^^schema:Text ;
    schema:author "Qiao Wang"^^schema:Person,
        "Renjie Xie"^^schema:Person,
        "Yan Wo"^^schema:Person,
        "Yanzhi Chen"^^schema:Person ;
    schema:dateModified "2019-02-23T12:26:13Z"^^schema:DateTime ;
    schema:datePublished "2019-02-23T12:26:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "A Deep, Information-theoretic Framework for Robust Biometric Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.08785v1"^^schema:URL .

<1369> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a novel method to generate answers for non-extractionmachine reading comprehension (MRC) tasks whose answers cannot be simplyextracted as one span from the given passages. Using a pointer network-styleextractive decoder for such type of MRC may result in unsatisfactoryperformance when the ground-truth answers are given by human annotators orhighly re-paraphrased from parts of the passages. On the other hand, usinggenerative decoder cannot well guarantee the resulted answers with well-formedsyntax and semantics when encountering long sentences. Therefore, to alleviatethe obvious drawbacks of both sides, we propose an answer making-up method fromextracted multi-spans that are learned by our model as highly confident$n$-gram candidates in the given passage. That is, the returned answers arecomposed of discontinuous multi-spans but not just one consecutive span in thegiven passages anymore. The proposed method is simple but effective: empiricalexperiments on MS MARCO show that the proposed method has a better performanceon accurately generating long answers, and substantially outperforms twocompetitive typical one-span and Seq2Seq baseline decoders."^^schema:Text ;
    schema:author "Hai Zhao"^^schema:Person,
        "Xi Zhou"^^schema:Person,
        "Xiang Zhou"^^schema:Person,
        "Yiqing Zhang"^^schema:Person,
        "Zhuosheng Zhang"^^schema:Person ;
    schema:dateModified "2020-09-14T01:44:42Z"^^schema:DateTime ;
    schema:datePublished "2020-09-14T01:44:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Composing Answer from Multi-spans for Reading Comprehension"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.06141v1"^^schema:URL .

<137> a schema:ScholarlyArticle ;
    schema:abstract "The ability to act in multiple environments and transfer previous knowledgeto new situations can be considered a critical aspect of any intelligent agent.Towards this goal, we define a novel method of multitask and transfer learningthat enables an autonomous agent to learn how to behave in multiple taskssimultaneously, and then generalize its knowledge to new domains. This method,termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and modelcompression techniques to train a single policy network that learns how to actin a set of distinct tasks by using the guidance of several expert teachers. Wethen show that the representations learnt by the deep policy network arecapable of generalizing to new tasks with no prior expert guidance, speeding uplearning in novel environments. Although our method can in general be appliedto a wide range of problems, we use Atari games as a testing environment todemonstrate these methods."^^schema:Text ;
    schema:author "Emilio Parisotto"^^schema:Person,
        "Jimmy Lei Ba"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person ;
    schema:commentCount "288"^^schema:Integer ;
    schema:dateModified "2016-02-22T19:59:40Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T20:17:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06342v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10238698941349147210&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1370> a schema:ScholarlyArticle ;
    schema:abstract "Many tasks in practice require the collaboration of multiple agents throughreinforcement learning. In general, cooperative multiagent reinforcementlearning algorithms can be classified into two paradigms: Joint Action Learners(JALs) and Independent Learners (ILs). In many practical applications, agentsare unable to observe other agents' actions and rewards, making JALsinapplicable. In this work, we focus on independent learning paradigm in whicheach agent makes decisions based on its local observations only. However,learning is challenging in independent settings due to the local viewpoints ofall agents, which perceive the world as a non-stationary environment due to theconcurrently exploring teammates. In this paper, we propose a novel frameworkcalled Independent Generative Adversarial Self-Imitation Learning (IGASIL) toaddress the coordination problems in fully cooperative multiagent environments.To the best of our knowledge, we are the first to combine self-imitationlearning with generative adversarial imitation learning (GAIL) and apply it tocooperative multiagent systems. Besides, we put forward a Sub-CurriculumExperience Replay mechanism to pick out the past beneficial experiences as muchas possible and accelerate the self-imitation learning process. Evaluationsconducted in the testbed of StarCraft unit micromanagement and a commonlyadopted benchmark show that our IGASIL produces state-of-the-art results andeven outperforms JALs in terms of both convergence speed and final performance."^^schema:Text ;
    schema:author "Jianye Hao"^^schema:Person,
        "Weixun Wang"^^schema:Person,
        "Xiaotian Hao"^^schema:Person,
        "Yaodong Yang"^^schema:Person ;
    schema:dateModified "2019-09-25T13:11:33Z"^^schema:DateTime ;
    schema:datePublished "2019-09-25T13:11:33Z"^^schema:DateTime ;
    schema:genre "cs.MA"^^schema:Text ;
    schema:headline "Independent Generative Adversarial Self-Imitation Learning in  Cooperative Multiagent Systems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.11468v1"^^schema:URL .

<1371> a schema:ScholarlyArticle ;
    schema:abstract "Neural style transfer is an emerging technique which is able to endowdaily-life images with attractive artistic styles. Previous work has succeededin applying convolutional neural networks (CNNs) to style transfer formonocular images or videos. However, style transfer for stereoscopic images isstill a missing piece. Different from processing a monocular image, the twoviews of a stylized stereoscopic pair are required to be consistent to provideobservers a comfortable visual experience. In this paper, we propose a noveldual path network for view-consistent style transfer on stereoscopic images.While each view of the stereoscopic pair is processed in an individual path, anovel feature aggregation strategy is proposed to effectively share informationbetween the two paths. Besides a traditional perceptual loss being used forcontrolling the style transfer quality in each view, a multi-layer view loss isleveraged to enforce the network to coordinate the learning of both the pathsto generate view-consistent stylized results. Extensive experiments show that,compared against previous methods, our proposed model can produce stylizedstereoscopic images which achieve decent view consistency."^^schema:Text ;
    schema:author "Fumin Shen"^^schema:Person,
        "Haozhi Huang"^^schema:Person,
        "Lin Ma"^^schema:Person,
        "Tong Zhang"^^schema:Person,
        "Wei Liu"^^schema:Person,
        "Xinyu Gong"^^schema:Person ;
    schema:dateModified "2018-07-27T15:51:44Z"^^schema:DateTime ;
    schema:datePublished "2018-02-27T16:02:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Neural Stereoscopic Image Style Transfer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.09985v4"^^schema:URL .

<1372> a schema:ScholarlyArticle ;
    schema:abstract "Neural Ordinary Differential Equations (NODEs) have proven to be a powerfulmodeling tool for approximating (interpolation) and forecasting (extrapolation)irregularly sampled time series data. However, their performance degradessubstantially when applied to real-world data, especially long-term data withcomplex behaviors (e.g., long-term trend across years, mid-term seasonalityacross months, and short-term local variation across days). To address themodeling of such complex data with different behaviors at different frequencies(time spans), we propose a novel progressive learning paradigm of NODEs forlong-term time series forecasting. Specifically, following the principle ofcurriculum learning, we gradually increase the complexity of data and networkcapacity as training progresses. Our experiments with both synthetic data andreal traffic data (PeMS Bay Area traffic data) show that our trainingmethodology consistently improves the performance of vanilla NODEs by over 64%."^^schema:Text ;
    schema:author "Ajay Divakaran"^^schema:Person,
        "Hammad A. Ayyubi"^^schema:Person,
        "Yi Yao"^^schema:Person ;
    schema:dateModified "2020-03-08T01:15:01Z"^^schema:DateTime ;
    schema:datePublished "2020-03-08T01:15:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Progressive Growing of Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03695v1"^^schema:URL .

<1373> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we attempt to advance the research work done in human actionrecognition to a rather specialized application namely Indian Classical Dance(ICD) classification. The variation in such dance forms in terms of hand andbody postures, facial expressions or emotions and head orientation makes poseestimation an extremely challenging task. To circumvent this problem, weconstruct a pose-oblivious shape signature which is fed to a sequence learningframework. The pose signature representation is done in two-fold process.First, we represent person-pose in first frame of a dance video using symmetricSpatial Transformer Networks (STN) to extract good person object proposals andCNN-based parallel single person pose estimator (SPPE). Next, the pose basisare converted to pose flows by assigning a similarity score between successiveposes followed by non-maximal suppression. Instead of feeding a simple chain ofjoints in the sequence learner which generally hinders the network performancewe constitute a feature vector of the normalized distance vectors, flow, anglesbetween anchor joints which captures the adjacency configuration in theskeletal pattern. Thus, the kinematic relationship amongst the body jointsacross the frames using pose estimation helps in better establishing thespatio-temporal dependencies. We present an exhaustive empirical evaluation ofstate-of-the-art deep network based methods for dance classification on ICDdataset."^^schema:Text ;
    schema:author "Brejesh Lall"^^schema:Person,
        "Prerana Mukherjee"^^schema:Person,
        "Vinay Kaushik"^^schema:Person ;
    schema:dateModified "2018-12-13T02:16:38Z"^^schema:DateTime ;
    schema:datePublished "2018-12-13T02:16:38Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Nrityantar: Pose oblivious Indian classical dance sequence  classification system"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.05231v1"^^schema:URL .

<1374> a schema:ScholarlyArticle ;
    schema:abstract "Existing work on risk-sensitive reinforcement learning - both for symmetricand downside risk measures - has typically used direct Monte-Carlo estimationof policy gradients. While this approach yields unbiased gradient estimates, italso suffers from high variance and decreased sample efficiency compared totemporal-difference methods. In this paper, we study prediction and controlwith aversion to downside risk which we gauge by the lower partial moment ofthe return. We introduce a new Bellman equation that upper bounds the lowerpartial moment, circumventing its non-linearity. We prove that this proxy forthe lower partial moment is a contraction, and provide intuition into thestability of the algorithm by variance decomposition. This allowssample-efficient, on-line estimation of partial moments. For risk-sensitivecontrol, we instantiate Reward Constrained Policy Optimization, a recentactor-critic method for finding constrained policies, with our proxy for thelower partial moment. We extend the method to use natural policy gradients anddemonstrate the effectiveness of our approach on three benchmark problems forrisk-sensitive reinforcement learning."^^schema:Text ;
    schema:author "Rahul Savani"^^schema:Person,
        "Thomas Spooner"^^schema:Person ;
    schema:dateModified "2020-07-08T15:44:33Z"^^schema:DateTime ;
    schema:datePublished "2020-07-08T15:44:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "q-fin.CP"^^schema:Text,
        "q-fin.PM"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Natural Actor-Critic Algorithm with Downside Risk Constraints"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.04203v1"^^schema:URL .

<1375> a schema:ScholarlyArticle ;
    schema:abstract "To address the challenges in learning deep generative models (e.g.,theblurriness of variational auto-encoder and the instability of traininggenerative adversarial networks, we propose a novel deep generative model,named Wasserstein-Wasserstein auto-encoders (WWAE). We formulate WWAE asminimization of the penalized optimal transport between the target distributionand the generated distribution. By noticing that both the prior $P_Z$ and theaggregated posterior $Q_Z$ of the latent code Z can be well captured byGaussians, the proposed WWAE utilizes the closed-form of the squaredWasserstein-2 distance for two Gaussians in the optimization process. As aresult, WWAE does not suffer from the sampling burden and it is computationallyefficient by leveraging the reparameterization trick. Numerical resultsevaluated on multiple benchmark datasets including MNIST, fashion- MNIST andCelebA show that WWAE learns better latent structures than VAEs and generatessamples of better visual quality and higher FID scores than VAEs and GANs."^^schema:Text ;
    schema:author "Can Yang"^^schema:Person,
        "Jin Liu"^^schema:Person,
        "Shunkang Zhang"^^schema:Person,
        "Yang Wang"^^schema:Person,
        "Yuan Gao"^^schema:Person,
        "Yuling Jiao"^^schema:Person ;
    schema:dateModified "2019-02-25T14:57:11Z"^^schema:DateTime ;
    schema:datePublished "2019-02-25T14:57:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Wasserstein-Wasserstein Auto-Encoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.09323v1"^^schema:URL .

<1376> a schema:ScholarlyArticle ;
    schema:abstract "MOBA games, e.g., Honor of Kings, League of Legends, and Dota 2, pose grandchallenges to AI systems such as multi-agent, enormous state-action space,complex action control, etc. Developing AI for playing MOBA games has raisedmuch attention accordingly. However, existing work falls short in handling theraw game complexity caused by the explosion of agent combinations, i.e.,lineups, when expanding the hero pool in case that OpenAI's Dota AI limits theplay to a pool of only 17 heroes. As a result, full MOBA games withoutrestrictions are far from being mastered by any existing AI system. In thispaper, we propose a MOBA AI learning paradigm that methodologically enablesplaying full MOBA games with deep reinforcement learning. Specifically, wedevelop a combination of novel and existing learning techniques, includingcurriculum self-play learning, policy distillation, off-policy adaption,multi-head value estimation, and Monte-Carlo tree-search, in training andplaying a large pool of heroes, meanwhile addressing the scalability issueskillfully. Tested on Honor of Kings, a popular MOBA game, we show how to buildsuperhuman AI agents that can defeat top esports players. The superiority ofour AI is demonstrated by the first large-scale performance test of MOBA AIagent in the literature."^^schema:Text ;
    schema:author "Bei Shi"^^schema:Person,
        "Bo Liu"^^schema:Person,
        "Bo Yuan"^^schema:Person,
        "Deheng Ye"^^schema:Person,
        "Fuhao Qiu"^^schema:Person,
        "Guibin Chen"^^schema:Person,
        "Hongsheng Yu"^^schema:Person,
        "Jia Chen"^^schema:Person,
        "Lanxiao Huang"^^schema:Person,
        "Liang Wang"^^schema:Person,
        "Qiang Fu"^^schema:Person,
        "Sheng Chen"^^schema:Person,
        "Tengfei Shi"^^schema:Person,
        "Wei Liu"^^schema:Person,
        "Wei Yang"^^schema:Person,
        "Wen Zhang"^^schema:Person,
        "Yinyuting Yin"^^schema:Person,
        "Zhao Liu"^^schema:Person ;
    schema:dateModified "2020-12-31T13:25:17Z"^^schema:DateTime ;
    schema:datePublished "2020-11-25T12:52:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Towards Playing Full MOBA Games with Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12692v4"^^schema:URL .

<1377> a schema:ScholarlyArticle ;
    schema:abstract "Issued from Optimal Transport, the Wasserstein distance has gained importancein Machine Learning due to its appealing geometrical properties and theincreasing availability of efficient approximations. In this work, we considerthe problem of estimating the Wasserstein distance between two probabilitydistributions when observations are polluted by outliers. To that end, weinvestigate how to leverage Medians of Means (MoM) estimators to robustify theestimation of Wasserstein distance. Exploiting the dual Kantorovitchformulation of Wasserstein distance, we introduce and discuss novel MoM-basedrobust estimators whose consistency is studied under a data contamination modeland for which convergence rates are provided. These MoM estimators enable tomake Wasserstein Generative Adversarial Network (WGAN) robust to outliers, aswitnessed by an empirical study on two benchmarks CIFAR10 and Fashion MNIST.Eventually, we discuss how to combine MoM with the entropy-regularizedapproximation of the Wasserstein distance and propose a simple MoM-basedre-weighting scheme that could be used in conjunction with the Sinkhornalgorithm."^^schema:Text ;
    schema:author "Florence d'Alché-Buc"^^schema:Person,
        "Guillaume Staerman"^^schema:Person,
        "Pavlo Mozharovskyi"^^schema:Person,
        "Pierre Laforgue"^^schema:Person ;
    schema:dateModified "2020-10-22T09:06:21Z"^^schema:DateTime ;
    schema:datePublished "2020-06-18T07:31:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "When OT meets MoM: Robust estimation of Wasserstein Distance"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.10325v2"^^schema:URL .

<1378> a schema:ScholarlyArticle ;
    schema:abstract "The task of multi-person human pose estimation in natural scenes is quitechallenging. Existing methods include both top-down and bottom-up approaches.The main advantage of bottom-up methods is its excellent tradeoff betweenestimation accuracy and computational cost. We follow this path and aim todesign smaller, faster, and more accurate neural networks for the regression ofkeypoints and limb association vectors. These two regression tasks arenaturally dependent on each other. In this work, we propose a dual-path networkspecially designed for multi-person human pose estimation, and compare ourperformance with the openpose network in aspects of model size, forward speed,and estimation accuracy."^^schema:Text ;
    schema:author "Guanghan Ning"^^schema:Person,
        "Zhihai He"^^schema:Person ;
    schema:dateModified "2017-10-27T15:16:51Z"^^schema:DateTime ;
    schema:datePublished "2017-10-27T15:16:51Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Dual Path Networks for Multi-Person Human Pose Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.10192v1"^^schema:URL .

<1379> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel conditional GAN (cGAN) model for continuous fine-grainedhuman action segmentation, that utilises multi-modal data and learned scenecontext information. The proposed approach utilises two GANs: termed Action GANand Auxiliary GAN, where the Action GAN is trained to operate over the currentRGB frame while the Auxiliary GAN utilises supplementary information such asdepth or optical flow. The goal of both GANs is to generate similar `actioncodes', a vector representation of the current action. To facilitate thisprocess a context extractor that incorporates data and recent outputs from bothmodes is used to extract context information to aid recognition. The result isa recurrent GAN architecture which learns a task specific loss function frommultiple feature modalities. Extensive evaluations on variants of the proposedmodel to show the importance of utilising different information streams such ascontext and auxiliary information in the proposed network; and show that ourmodel is capable of outperforming state-of-the-art methods for three widelyused datasets: 50 Salads, MERL Shopping and Georgia Tech Egocentric Activities,comprising both static and dynamic camera settings."^^schema:Text ;
    schema:author "Clinton Fookes"^^schema:Person,
        "Harshala Gammulle"^^schema:Person,
        "Simon Denman"^^schema:Person,
        "Sridha Sridharan"^^schema:Person,
        "Tharindu Fernando"^^schema:Person ;
    schema:dateModified "2019-09-20T01:17:00Z"^^schema:DateTime ;
    schema:datePublished "2019-09-20T01:17:00Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Coupled Generative Adversarial Network for Continuous Fine-grained  Action Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.09283v1"^^schema:URL .

<138> a schema:ScholarlyArticle ;
    schema:abstract "The recent success of deep neural networks relies on massive amounts oflabeled data. For a target task where labeled data is unavailable, domainadaptation can transfer a learner from a different source domain. In thispaper, we propose a new approach to domain adaptation in deep networks that canjointly learn adaptive classifiers and transferable features from labeled datain the source domain and unlabeled data in the target domain. We relax ashared-classifier assumption made by previous methods and assume that thesource classifier and target classifier differ by a residual function. Weenable classifier adaptation by plugging several layers into deep network toexplicitly learn the residual function with reference to the target classifier.We fuse features of multiple layers with tensor product and embed them intoreproducing kernel Hilbert spaces to match distributions for featureadaptation. The adaptation can be achieved in most feed-forward models byextending them with new residual layers and loss functions, which can betrained efficiently via back-propagation. Empirical evidence shows that the newapproach outperforms state of the art methods on standard domain adaptationbenchmarks."^^schema:Text ;
    schema:author "Han Zhu"^^schema:Person,
        "Jianmin Wang"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Mingsheng Long"^^schema:Person ;
    schema:commentCount "534"^^schema:Integer ;
    schema:dateModified "2017-02-16T07:56:49Z"^^schema:DateTime ;
    schema:datePublished "2016-02-14T09:47:30Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Domain Adaptation with Residual Transfer Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.04433v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12070836061117770706&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1380> a schema:ScholarlyArticle ;
    schema:abstract "When traveling to a foreign country, we are often in dire need of anintelligent conversational agent to provide instant and informative responsesto our various queries. However, to build such a travel agent is non-trivial.First of all, travel naturally involves several sub-tasks such as hotelreservation, restaurant recommendation and taxi booking etc, which invokes theneed for global topic control. Secondly, the agent should consider variousconstraints like price or distance given by the user to recommend anappropriate venue. In this paper, we present a Deep Conversational Recommender(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)models with a neural latent topic component to better guide response generationand make the training easier. To consider the various constraints for venuerecommendation, we leverage a graph convolutional network (GCN) based approachto capture the relationships between different venues and the match betweenvenue and dialog context. For response generation, we combine the topic-basedcomponent with the idea of pointer networks, which allows us to effectivelyincorporate recommendation results. We perform extensive evaluation on amulti-turn task-oriented dialog dataset in travel domain and the results showthat our method achieves superior performance as compared to a wide range ofbaselines."^^schema:Text ;
    schema:author "Lizi Liao"^^schema:Person,
        "Minlie Huang"^^schema:Person,
        "Ryuichi Takanobu"^^schema:Person,
        "Tat-Seng Chua"^^schema:Person,
        "Xun Yang"^^schema:Person,
        "Yunshan Ma"^^schema:Person ;
    schema:dateModified "2019-06-25T04:39:26Z"^^schema:DateTime ;
    schema:datePublished "2019-06-25T04:39:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Conversational Recommender in Travel"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.00710v1"^^schema:URL .

<1381> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, advances in machine learning algorithms, cheap computationalresources, and the availability of big data have spurred the deep learningrevolution in various application domains. In particular, supervised learningtechniques in image analysis have led to superhuman performance in varioustasks, such as classification, localization, and segmentation, whileunsupervised learning techniques based on increasingly advanced generativemodels have been applied to generate high-resolution synthetic imagesindistinguishable from real images.  In this paper we consider a state-of-the-art machine learning model for imageinpainting, namely a Wasserstein Generative Adversarial Network based on afully convolutional architecture with a contextual attention mechanism. We showthat this model can successfully be transferred to the setting of digitalelevation models (DEMs) for the purpose of generating semantically plausibledata for filling voids. Training, testing and experimentation is done onGeoTIFF data from various regions in Norway, made openly available by theNorwegian Mapping Authority."^^schema:Text ;
    schema:author "Georg Muntingh"^^schema:Person,
        "Konstantinos Gavriil"^^schema:Person,
        "Oliver J. D. Barrowclough"^^schema:Person ;
    schema:dateModified "2019-02-26T13:24:22Z"^^schema:DateTime ;
    schema:datePublished "2018-11-30T10:04:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Void Filling of Digital Elevation Models with Deep Generative Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.12693v2"^^schema:URL .

<1382> a schema:ScholarlyArticle ;
    schema:abstract "Noting the erroneous proclivity of information-theoretic approaches, like theAkaike information criterion (AIC), to select simpler models while performingmodel selection with a small sample size, we address the problem of new physicsmodel selection in $b\\to c \\tau \\nu_{\\tau}$ decays in this paper by employing aspecific machine learning algorithm (self-normalizing neural networks, a.k.a.SNN) for supervised classification and regression, in a model-independentframework. While the outcomes of the classification with real data-set arecompared with AIC, with the SNNs outperforming AIC$_c$ in all aspects of modelselection, the regression-outcomes are compared with the results from Bayesiananalyses; the obtained parameter spaces differ considerably while keepingmaximum posterior (MAP) estimates similar. A few of the two-operator scenarioswith a tensor-type interaction are found to be the most probable solution forthe data. We also test the effectiveness of our trained networks with theexpected, more precise data in Belle-II. The trained networks and associatedfunctionalities are supplied for the use of the community."^^schema:Text ;
    schema:author "Shantanu Sahoo"^^schema:Person,
        "Soumitra Nandi"^^schema:Person,
        "Srimoy Bhattacharya"^^schema:Person,
        "Sunando Kumar Patra"^^schema:Person ;
    schema:dateModified "2020-08-10T18:00:02Z"^^schema:DateTime ;
    schema:datePublished "2020-08-10T18:00:02Z"^^schema:DateTime ;
    schema:genre "hep-ex"^^schema:Text,
        "hep-lat"^^schema:Text,
        "hep-ph"^^schema:Text,
        "physics.data-an"^^schema:Text ;
    schema:headline "'Deep' Dive into $b \\to c$ Anomalies: Standardized and Future-proof  Model Selection Using Self-normalizing Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.04316v1"^^schema:URL .

<1383> a schema:ScholarlyArticle ;
    schema:abstract "GANs have been shown to perform exceedingly well on tasks pertaining to imagegeneration and style transfer. In the field of language modelling, wordembeddings such as GLoVe and word2vec are state-of-the-art methods for applyingneural network models on textual data. Attempts have been made to utilize GANswith word embeddings for text generation. This study presents an approach totext generation using Skip-Thought sentence embeddings with GANs based ongradient penalty functions and f-measures. The proposed architecture aims toreproduce writing style in the generated text by modelling the way ofexpression at a sentence level across all the works of an author. Extensiveexperiments were run in different embedding settings on a variety of tasksincluding conditional text generation and language generation. The modeloutperforms baseline text generation networks across several automatedevaluation metrics like BLEU-n, METEOR and ROUGE. Further, wide applicabilityand effectiveness in real life tasks are demonstrated through human judgementscores."^^schema:Text ;
    schema:author "Afroz Ahamad"^^schema:Person ;
    schema:dateModified "2020-05-16T10:18:53Z"^^schema:DateTime ;
    schema:datePublished "2018-08-27T06:51:07Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Generating Text through Adversarial Training using Skip-Thought Vectors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.08703v3"^^schema:URL .

<1384> a schema:ScholarlyArticle ;
    schema:abstract "The high penetration of volatile renewable energy sources such as solar makemethods for coping with the uncertainty associated with them of paramountimportance. Probabilistic forecasts are an example of these methods, as theyassist energy planners in their decision-making process by providing them withinformation about the uncertainty of future power generation. Currently, thereis a trend towards the use of deep learning probabilistic forecasting methods.However, the point at which the more complex deep learning methods should bepreferred over more simple approaches is not yet clear. Therefore, the currentarticle presents a simple comparison between a long short-term memory neuralnetwork and other more simple approaches. The comparison consists of trainingand comparing models able to provide one-day-ahead probabilistic forecasts fora solar power system. Moreover, the current paper makes use of an open-sourcedataset provided during the Global Energy Forecasting Competition of 2014(GEFCom14)."^^schema:Text ;
    schema:author "Jorge Angel Gonzalez Ordiano"^^schema:Person,
        "Ralf Mikut"^^schema:Person,
        "Umit Cali"^^schema:Person,
        "Vinayak Sharma"^^schema:Person ;
    schema:dateModified "2021-01-20T18:13:07Z"^^schema:DateTime ;
    schema:datePublished "2021-01-20T18:13:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Probabilistic Solar Power Forecasting: Long Short-Term Memory Network vs  Simpler Approaches"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.08236v1"^^schema:URL .

<1385> a schema:ScholarlyArticle ;
    schema:abstract "Humans can robustly learn novel visual concepts even when images undergovarious deformations and lose certain information. Mimicking the same behaviorand synthesizing deformed instances of new concepts may help visual recognitionsystems perform better one-shot learning, i.e., learning concepts from one orfew examples. Our key insight is that, while the deformed images may not bevisually realistic, they still maintain critical semantic information andcontribute significantly to formulating classifier decision boundaries.Inspired by the recent progress of meta-learning, we combine a meta-learnerwith an image deformation sub-network that produces additional trainingexamples, and optimize both models in an end-to-end manner. The deformationsub-network learns to deform images by fusing a pair of images --- a probeimage that keeps the visual content and a gallery image that diversifies thedeformations. We demonstrate results on the widely used one-shot learningbenchmarks (miniImageNet and ImageNet 1K Challenge datasets), whichsignificantly outperform state-of-the-art approaches. Code is available athttps://github.com/tankche1/IDeMe-Net."^^schema:Text ;
    schema:author "Lin Ma"^^schema:Person,
        "Martial Hebert"^^schema:Person,
        "Wei Liu"^^schema:Person,
        "Yanwei Fu"^^schema:Person,
        "Yu-Xiong Wang"^^schema:Person,
        "Zitian Chen"^^schema:Person ;
    schema:dateModified "2019-07-18T03:51:34Z"^^schema:DateTime ;
    schema:datePublished "2019-05-28T06:56:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Image Deformation Meta-Networks for One-Shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11641v2"^^schema:URL .

<1386> a schema:ScholarlyArticle ;
    schema:abstract "Network representation learning (NRL) methods aim to map each vertex into alow dimensional space by preserving the local and global structure of a givennetwork, and in recent years they have received a significant attention thanksto their success in several challenging problems. Although various approacheshave been proposed to compute node embeddings, many successful methods benefitfrom random walks in order to transform a given network into a collection ofsequences of nodes and then they target to learn the representation of nodes bypredicting the context of each vertex within the sequence. In this paper, weintroduce a general framework to enhance the embeddings of nodes acquired bymeans of the random walk-based approaches. Similar to the notion of topicalword embeddings in NLP, the proposed method assigns each vertex to a topic withthe favor of various statistical models and community detection methods, andthen generates the enhanced community representations. We evaluate our methodon two downstream tasks: node classification and link prediction. Theexperimental results demonstrate that the incorporation of vertex and topicembeddings outperform widely-known baseline NRL methods."^^schema:Text ;
    schema:author "Abdulkadir Çelikkanat"^^schema:Person,
        "Fragkiskos D. Malliaros"^^schema:Person ;
    schema:dateModified "2018-10-16T10:26:47Z"^^schema:DateTime ;
    schema:datePublished "2018-10-16T10:26:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "TNE: A Latent Model for Representation Learning on Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.06917v1"^^schema:URL .

<1387> a schema:ScholarlyArticle ;
    schema:abstract "Traditional distributed deep reinforcement learning (RL) commonly relies onexchanging the experience replay memory (RM) of each agent. Since the RMcontains all state observations and action policy history, it may incur hugecommunication overhead while violating the privacy of each agent.Alternatively, this article presents a communication-efficient andprivacy-preserving distributed RL framework, coined federated reinforcementdistillation (FRD). In FRD, each agent exchanges its proxy experience replaymemory (ProxRM), in which policies are locally averaged with respect to proxystates clustering actual states. To provide FRD design insights, we presentablation studies on the impact of ProxRM structures, neural networkarchitectures, and communication intervals. Furthermore, we propose an improvedversion of FRD, coined mixup augmented FRD (MixFRD), in which ProxRM isinterpolated using the mixup data augmentation algorithm. Simulations in aCartpole environment validate the effectiveness of MixFRD in reducing thevariance of mission completion time and communication cost, compared to thebenchmark schemes, vanilla FRD, federated reinforcement learning (FRL), andpolicy distillation (PD)."^^schema:Text ;
    schema:author "Han Cha"^^schema:Person,
        "Hyesung Kim"^^schema:Person,
        "Jihong Park"^^schema:Person,
        "Mehdi Bennis"^^schema:Person,
        "Seong-Lyun Kim"^^schema:Person ;
    schema:dateModified "2020-05-15T12:44:25Z"^^schema:DateTime ;
    schema:datePublished "2020-05-13T01:36:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Proxy Experience Replay: Federated Distillation for Distributed  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.06105v2"^^schema:URL .

<1388> a schema:ScholarlyArticle ;
    schema:abstract "We present OpenSeq2Seq - a TensorFlow-based toolkit for trainingsequence-to-sequence models that features distributed and mixed-precisiontraining. Benchmarks on machine translation and speech recognition tasks showthat models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3xless training time. OpenSeq2Seq currently provides building blocks for modelsthat solve a wide range of tasks including neural machine translation,automatic speech recognition, and speech synthesis."^^schema:Text ;
    schema:author "Boris Ginsburg"^^schema:Person,
        "Carl Case"^^schema:Person,
        "Huyen Nguyen"^^schema:Person,
        "Igor Gitman"^^schema:Person,
        "Jason Li"^^schema:Person,
        "Oleksii Kuchaiev"^^schema:Person,
        "Paulius Micikevicius"^^schema:Person,
        "Vitaly Lavrukhin"^^schema:Person ;
    schema:dateModified "2018-11-21T17:48:55Z"^^schema:DateTime ;
    schema:datePublished "2018-05-25T22:54:38Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.10387v2"^^schema:URL .

<1389> a schema:ScholarlyArticle ;
    schema:abstract "Assessing fetal development is usually carried out by techniques such asultrasound imaging, which is generally unavailable in rural areas due to thehigh cost, maintenance, skills and training needed to operate the deviceseffectively. In this work, we propose a low-cost one-dimensional Doppler-basedmethod for estimating gestational age (GA). Doppler time series were collectedfrom 401 pregnancies between 5 and 9 months GA using a smartphone. The proposedmodel for GA estimation is based on sequence learning by forming a temporallydependent model using a convolutional long-short-term memory network.Time-frequency features are extracted from Doppler signals and regularizedbefore feeding to the network. The overall mean absolute GA error with respectto the last menstrual period was found to be 0.71 month, which outperforms allprevious works."^^schema:Text ;
    schema:author "Gari D. Clifford"^^schema:Person,
        "Nasim Katebi"^^schema:Person,
        "Reza Sameni"^^schema:Person ;
    schema:dateModified "2020-11-24T14:54:39Z"^^schema:DateTime ;
    schema:datePublished "2020-11-24T14:54:39Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text ;
    schema:headline "Deep Sequence Learning for Accurate Gestational Age Estimation from a  $\\$$25 Doppler Device"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.00553v1"^^schema:URL .

<139> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a new optimization algorithm called Entropy-SGD fortraining deep neural networks that is motivated by the local geometry of theenergy landscape. Local extrema with low generalization error have a largeproportion of almost-zero eigenvalues in the Hessian with very few positive ornegative eigenvalues. We leverage upon this observation to construct alocal-entropy-based objective function that favors well-generalizable solutionslying in large flat regions of the energy landscape, while avoidingpoorly-generalizable solutions located in the sharp valleys. Conceptually, ouralgorithm resembles two nested loops of SGD where we use Langevin dynamics inthe inner loop to compute the gradient of the local entropy before each updateof the weights. We show that the new objective has a smoother energy landscapeand show improved generalization over SGD using uniform stability, undercertain assumptions. Our experiments on convolutional and recurrent networksdemonstrate that Entropy-SGD compares favorably to state-of-the-art techniquesin terms of generalization error and training time."^^schema:Text ;
    schema:author "Anna Choromanska"^^schema:Person,
        "Carlo Baldassi"^^schema:Person,
        "Christian Borgs"^^schema:Person,
        "Jennifer Chayes"^^schema:Person,
        "Levent Sagun"^^schema:Person,
        "Pratik Chaudhari"^^schema:Person,
        "Riccardo Zecchina"^^schema:Person,
        "Stefano Soatto"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "281"^^schema:Integer ;
    schema:dateModified "2017-04-21T07:16:30Z"^^schema:DateTime ;
    schema:datePublished "2016-11-06T20:22:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Entropy-SGD: Biasing Gradient Descent Into Wide Valleys"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01838v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=496423886429566828&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1390> a schema:ScholarlyArticle ;
    schema:abstract "The skip-thought model has been proven to be effective at learning sentencerepresentations and capturing sentence semantics. In this paper, we propose asuite of techniques to trim and improve it. First, we validate a hypothesisthat, given a current sentence, inferring the previous and inferring the nextsentence provide similar supervision power, therefore only one decoder forpredicting the next sentence is preserved in our trimmed skip-thought model.Second, we present a connection layer between encoder and decoder to help themodel to generalize better on semantic relatedness tasks. Third, we found thata good word embedding initialization is also essential for learning bettersentence representations. We train our model unsupervised on a large corpuswith contiguous sentences, and then evaluate the trained model on 7 supervisedtasks, which includes semantic relatedness, paraphrase detection, and textclassification benchmarks. We empirically show that, our proposed model is afaster, lighter-weight and equally powerful alternative to the originalskip-thought model."^^schema:Text ;
    schema:author "Chen Fang"^^schema:Person,
        "Hailin Jin"^^schema:Person,
        "Shuai Tang"^^schema:Person,
        "Virginia R. de Sa"^^schema:Person,
        "Zhaowen Wang"^^schema:Person ;
    schema:dateModified "2017-06-09T22:44:31Z"^^schema:DateTime ;
    schema:datePublished "2017-06-09T22:44:31Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Trimming and Improving Skip-thought Vectors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1706.03148v1"^^schema:URL .

<1391> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new sample-efficient methodology, called Supervised PolicyUpdate (SPU), for deep reinforcement learning. Starting with data generated bythe current policy, SPU formulates and solves a constrained optimizationproblem in the non-parameterized proximal policy space. Using supervisedregression, it then converts the optimal non-parameterized policy to aparameterized policy, from which it draws new samples. The methodology isgeneral in that it applies to both discrete and continuous action spaces, andcan handle a wide variety of proximity constraints for the non-parameterizedoptimization problem. We show how the Natural Policy Gradient and Trust RegionPolicy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization(PPO) problem can be addressed by this methodology. The SPU implementation ismuch simpler than TRPO. In terms of sample efficiency, our extensiveexperiments show SPU outperforms TRPO in Mujoco simulated robotic tasks andoutperforms PPO in Atari video game tasks."^^schema:Text ;
    schema:author "Keith W. Ross"^^schema:Person,
        "Quan Vuong"^^schema:Person,
        "Yiming Zhang"^^schema:Person ;
    schema:dateModified "2018-12-24T01:42:07Z"^^schema:DateTime ;
    schema:datePublished "2018-05-29T20:57:19Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Supervised Policy Update for Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.11706v4"^^schema:URL .

<1392> a schema:ScholarlyArticle ;
    schema:abstract "With the rising incidence of some diseases, such as obesity and diabetes, ahealthy diet is arousing increasing attention. However, most existingfood-related research efforts focus on recipe retrieval, user preference-basedfood recommendation, cooking assistance, or the nutrition and calorieestimation of dishes, ignoring the personalized health-aware foodrecommendation. Therefore, in this work, we present a personalized health-awarefood recommendation scheme, namely Market2Dish, mapping the ingredientsdisplayed in the market to the healthy dishes eaten at home. The proposedscheme comprises three components, namely recipe retrieval, user-healthprofiling, and health-aware food recommendation. In particular, reciperetrieval aims to acquire the ingredients available to the users, and thenretrieve recipe candidates from a large-scale recipe dataset. User healthprofiling is to characterize the health conditions of users by capturing thetextual health-related information crawled from social networks. Specifically,to solve the issue that the health-related information is extremely sparse, weincorporate a word-class interaction mechanism into the proposed deep model tolearn the fine-grained correlations between the textual tweets and pre-definedhealth concepts. For the health-aware food recommendation, we present a novelcategory-aware hierarchical memory network-based recommender to learn thehealth-aware user-recipe interactions for better food recommendation. Moreover,extensive experiments demonstrate the effectiveness of the health-aware foodrecommendation scheme."^^schema:Text ;
    schema:author "Hao Jiang"^^schema:Person,
        "Ling-yu Duan"^^schema:Person,
        "Liqiang Nie"^^schema:Person,
        "Peiguang Jing"^^schema:Person,
        "Wenjie Wang"^^schema:Person,
        "Xuemeng Song"^^schema:Person ;
    schema:dateModified "2020-12-11T15:19:19Z"^^schema:DateTime ;
    schema:datePublished "2020-12-11T15:19:19Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text ;
    schema:headline "Market2Dish: Health-aware Food Recommendation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06416v1"^^schema:URL .

<1393> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel multi-modal unspoken punctuation prediction system for theEnglish language which combines acoustic and text features. We demonstrate forthe first time, that by relying exclusively on synthetic data generated using aprosody-aware text-to-speech system, we can outperform a model trained withexpensive human audio recordings on the unspoken punctuation predictionproblem. Our model architecture is well suited for on-device use. This isachieved by leveraging hash-based embeddings of automatic speech recognitiontext output in conjunction with acoustic features as input to a quasi-recurrentneural network, keeping the model size small and latency low."^^schema:Text ;
    schema:author "Balint Miklos"^^schema:Person,
        "Bogdan Prisacari"^^schema:Person,
        "Daniel Valcarce"^^schema:Person,
        "Daria Soboleva"^^schema:Person,
        "Felix Weissenberger"^^schema:Person,
        "Julia Proskurnia"^^schema:Person,
        "Justin Lu"^^schema:Person,
        "Márius Šajgalík"^^schema:Person,
        "Ondrej Skopek"^^schema:Person,
        "Rohit Prabhavalkar"^^schema:Person,
        "Victor Cărbune"^^schema:Person ;
    schema:dateModified "2020-10-20T11:30:26Z"^^schema:DateTime ;
    schema:datePublished "2020-10-20T11:30:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Replacing Human Audio with Synthetic Audio for On-device Unspoken  Punctuation Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.10203v1"^^schema:URL .

<1394> a schema:ScholarlyArticle ;
    schema:abstract "This paper illustrates the details description of technical textclassification system and its results that developed as a part of participationin the shared task TechDofication 2020. The shared task consists of twosub-tasks: (i) first task identify the coarse-grained technical domain of giventext in a specified language and (ii) the second task classify a text ofcomputer science domain into fine-grained sub-domains. A classification system(called 'TechTexC') is developed to perform the classification task using threetechniques: convolution neural network (CNN), bidirectional long short termmemory (BiLSTM) network, and combined CNN with BiLSTM. Results show that CNNwith BiLSTM model outperforms the other techniques concerning task-1 ofsub-tasks (a, b, c and g) and task-2a. This combined model obtained f1 scoresof 82.63 (sub-task a), 81.95 (sub-task b), 82.39 (sub-task c), 84.37 (sub-taskg), and 67.44 (task-2a) on the development dataset. Moreover, in the case oftest set, the combined CNN with BiLSTM approach achieved that higher accuracyfor the subtasks 1a (70.76%), 1b (79.97%), 1c (65.45%), 1g (49.23%) and 2a(70.14%)."^^schema:Text ;
    schema:author "Eftekhar Hossain"^^schema:Person,
        "Mohammed Moshiul Hoque"^^schema:Person,
        "Omar Sharif"^^schema:Person ;
    schema:dateModified "2020-12-21T15:22:47Z"^^schema:DateTime ;
    schema:datePublished "2020-12-21T15:22:47Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "TechTexC: Classification of Technical Texts using Convolution and  Bidirectional Long Short Term Memory Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11420v1"^^schema:URL .

<1395> a schema:ScholarlyArticle ;
    schema:abstract "Graph convolutional networks (GCNs), which generalize CNNs to more genericnon-Euclidean structures, have achieved remarkable performance forskeleton-based action recognition. However, there still exist several issues inthe previous GCN-based models. First, the topology of the graph is setheuristically and fixed over all the model layers and input data. This may notbe suitable for the hierarchy of the GCN model and the diversity of the data inaction recognition tasks. Second, the second-order information of the skeletondata, i.e., the length and orientation of the bones, is rarely investigated,which is naturally more informative and discriminative for the human actionrecognition. In this work, we propose a novel multi-stream attention-enhancedadaptive graph convolutional neural network (MS-AAGCN) for skeleton-basedaction recognition. The graph topology in our model can be either uniformly orindividually learned based on the input data in an end-to-end manner. Thisdata-driven approach increases the flexibility of the model for graphconstruction and brings more generality to adapt to various data samples.Besides, the proposed adaptive graph convolutional layer is further enhanced bya spatial-temporal-channel attention module, which helps the model pay moreattention to important joints, frames and features. Moreover, the informationof both the joints and bones, together with their motion information, aresimultaneously modeled in a multi-stream framework, which shows notableimprovement for the recognition accuracy. Extensive experiments on the twolarge-scale datasets, NTU-RGBD and Kinetics-Skeleton, demonstrate that theperformance of our model exceeds the state-of-the-art with a significantmargin."^^schema:Text ;
    schema:author "Hanqing Lu"^^schema:Person,
        "Jian Cheng"^^schema:Person,
        "Lei Shi"^^schema:Person,
        "Yifan Zhang"^^schema:Person ;
    schema:dateModified "2019-12-15T04:10:48Z"^^schema:DateTime ;
    schema:datePublished "2019-12-15T04:10:48Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Skeleton-Based Action Recognition with Multi-Stream Adaptive Graph  Convolutional Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.06971v1"^^schema:URL .

<1396> a schema:ScholarlyArticle ;
    schema:abstract "Machine reading comprehension (MRC) aims to teach machines to read andcomprehend human languages, which is a long-standing goal of natural languageprocessing (NLP). With the burst of deep neural networks and the evolution ofcontextualized language models (CLMs), the research of MRC has experienced twosignificant breakthroughs. MRC and CLM, as a phenomenon, have a great impact onthe NLP community. In this survey, we provide a comprehensive and comparativereview on MRC covering overall research topics about 1) the origin anddevelopment of MRC and CLM, with a particular focus on the role of CLMs; 2) theimpact of MRC and CLM to the NLP community; 3) the definition, datasets, andevaluation of MRC; 4) general MRC architecture and technical methods in theview of two-stage Encoder-Decoder solving architecture from the insights of thecognitive process of humans; 5) previous highlights, emerging topics, and ourempirical analysis, among which we especially focus on what works in differentperiods of MRC researches. We propose a full-view categorization and newtaxonomies on these topics. The primary views we have arrived at are that 1)MRC boosts the progress from language processing to understanding; 2) the rapidimprovement of MRC systems greatly benefits from the development of CLMs; 3)the theme of MRC is gradually moving from shallow text matching to cognitivereasoning."^^schema:Text ;
    schema:author "Hai Zhao"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Zhuosheng Zhang"^^schema:Person ;
    schema:dateModified "2020-05-13T10:58:50Z"^^schema:DateTime ;
    schema:datePublished "2020-05-13T10:58:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Machine Reading Comprehension: The Role of Contextualized Language  Models and Beyond"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.06249v1"^^schema:URL .

<1397> a schema:ScholarlyArticle ;
    schema:abstract "Simulation is an appealing option for validating the safety of autonomousvehicles. Generative Adversarial Imitation Learning (GAIL) has recently beenshown to learn representative human driver models. These human driver modelswere learned through training in single-agent environments, but they havedifficulty in generalizing to multi-agent driving scenarios. We argue thesedifficulties arise because observations at training and test time are sampledfrom different distributions. This difference makes such models unsuitable forthe simulation of driving scenes, where multiple agents must interactrealistically over long time horizons. We extend GAIL to address theseshortcomings through a parameter-sharing approach grounded in curriculumlearning. Compared with single-agent GAIL policies, policies generated by ourPS-GAIL method prove superior at interacting stably in a multi-agent settingand capturing the emergent behavior of human drivers."^^schema:Text ;
    schema:author "Alex Kuefler"^^schema:Person,
        "Blake Wulfe"^^schema:Person,
        "Derek J. Phillips"^^schema:Person,
        "Jeremy Morton"^^schema:Person,
        "Mykel J. Kochenderfer"^^schema:Person,
        "Raunak P. Bhattacharyya"^^schema:Person ;
    schema:dateModified "2018-03-02T21:18:16Z"^^schema:DateTime ;
    schema:datePublished "2018-03-02T21:18:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Multi-Agent Imitation Learning for Driving Simulation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.01044v1"^^schema:URL .

<1398> a schema:ScholarlyArticle ;
    schema:abstract "We propose CaSPR, a method to learn object-centric Canonical SpatiotemporalPoint Cloud Representations of dynamically moving or evolving objects. Our goalis to enable information aggregation over time and the interrogation of objectstate at any spatiotemporal neighborhood in the past, observed or not.Different from previous work, CaSPR learns representations that supportspacetime continuity, are robust to variable and irregularly spacetime-sampledpoint clouds, and generalize to unseen object instances. Our approach dividesthe problem into two subtasks. First, we explicitly encode time by mapping aninput point cloud sequence to a spatiotemporally-canonicalized object space. Wethen leverage this canonicalization to learn a spatiotemporal latentrepresentation using neural ordinary differential equations and a generativemodel of dynamically evolving shapes using continuous normalizing flows. Wedemonstrate the effectiveness of our method on several applications includingshape reconstruction, camera pose estimation, continuous spatiotemporalsequence reconstruction, and correspondence estimation from irregularly orintermittently sampled observations."^^schema:Text ;
    schema:author "Davis Rempe"^^schema:Person,
        "Leonidas J. Guibas"^^schema:Person,
        "Srinath Sridhar"^^schema:Person,
        "Tolga Birdal"^^schema:Person,
        "Yongheng Zhao"^^schema:Person,
        "Zan Gojcic"^^schema:Person ;
    schema:dateModified "2020-11-11T19:00:31Z"^^schema:DateTime ;
    schema:datePublished "2020-08-06T17:58:48Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.02792v2"^^schema:URL .

<1399> a schema:ScholarlyArticle ;
    schema:abstract "The state-of-the-art (SOTA) for mixed precision training is dominated byvariants of low precision floating point operations, and in particular, FP16accumulating into FP32 Micikevicius et al. (2017). On the other hand, while alot of research has also happened in the domain of low and mixed-precisionInteger training, these works either present results for non-SOTA networks (forinstance only AlexNet for ImageNet-1K), or relatively small datasets (likeCIFAR-10). In this work, we train state-of-the-art visual understanding neuralnetworks on the ImageNet-1K dataset, with Integer operations on General Purpose(GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate(FMA) operations which take two pairs of INT16 operands and accumulate resultsinto an INT32 output.We propose a shared exponent representation of tensors anddevelop a Dynamic Fixed Point (DFP) scheme suitable for common neural networkoperations. The nuances of developing an efficient integer convolution kernelis examined, including methods to handle overflow of the INT32 accumulator. Weimplement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; andthese networks achieve or exceed SOTA accuracy within the same number ofiterations as their FP32 counterparts without any change in hyper-parametersand with a 1.8X improvement in end-to-end training throughput. To the best ofour knowledge these results represent the first INT16 training results on GPhardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reportedaccuracy using half-precision"^^schema:Text ;
    schema:author "Alexander Heinecke"^^schema:Person,
        "Bharat Kaul"^^schema:Person,
        "Dheevatsa Mudigere"^^schema:Person,
        "Dhiraj Kalamkar"^^schema:Person,
        "Dipankar Das"^^schema:Person,
        "Evangelos Georganas"^^schema:Person,
        "Evarist Fomenko"^^schema:Person,
        "Jesus Corbal"^^schema:Person,
        "Karthik Vaidyanathan"^^schema:Person,
        "Kunal Banerjee"^^schema:Person,
        "Naveen Mellempudi"^^schema:Person,
        "Nikita Shustrov"^^schema:Person,
        "Pradeep Dubey"^^schema:Person,
        "Roma Dubtsov"^^schema:Person,
        "Sasikanth Avancha"^^schema:Person,
        "Srinivas Sridharan"^^schema:Person,
        "Vadim Pirogov"^^schema:Person ;
    schema:dateModified "2018-02-23T18:02:58Z"^^schema:DateTime ;
    schema:datePublished "2018-02-03T07:01:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NA"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Mixed Precision Training of Convolutional Neural Networks using Integer  Operations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.00930v2"^^schema:URL .

<14> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks are both computationally intensive and memory intensive,making them difficult to deploy on embedded systems with limited hardwareresources. To address this limitation, we introduce \"deep compression\", a threestage pipeline: pruning, trained quantization and Huffman coding, that worktogether to reduce the storage requirement of neural networks by 35x to 49xwithout affecting their accuracy. Our method first prunes the network bylearning only the important connections. Next, we quantize the weights toenforce weight sharing, finally, we apply Huffman coding. After the first twosteps we retrain the network to fine tune the remaining connections and thequantized centroids. Pruning, reduces the number of connections by 9x to 13x;Quantization then reduces the number of bits that represent each connectionfrom 32 to 5. On the ImageNet dataset, our method reduced the storage requiredby AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our methodreduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss ofaccuracy. This allows fitting the model into on-chip SRAM cache rather thanoff-chip DRAM memory. Our compression method also facilitates the use ofcomplex neural networks in mobile applications where application size anddownload bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU,compressed network has 3x to 4x layerwise speedup and 3x to 7x better energyefficiency."^^schema:Text ;
    schema:author "Huizi Mao"^^schema:Person,
        "Song Han"^^schema:Person,
        "William J. Dally"^^schema:Person ;
    schema:commentCount "3559"^^schema:Integer ;
    schema:dateModified "2016-02-15T06:25:40Z"^^schema:DateTime ;
    schema:datePublished "2015-10-01T09:03:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained  Quantization and Huffman Coding"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.00149v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7860777411990654691&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<140> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning is a powerful paradigm for learning optimal policiesfrom experimental data. However, to find optimal policies, most reinforcementlearning algorithms explore all possible actions, which may be harmful forreal-world systems. As a consequence, learning algorithms are rarely applied onsafety-critical systems in the real world. In this paper, we present a learningalgorithm that explicitly considers safety, defined in terms of stabilityguarantees. Specifically, we extend control-theoretic results on Lyapunovstability verification and show how to use statistical models of the dynamicsto obtain high-performance control policies with provable stabilitycertificates. Moreover, under additional regularity assumptions in terms of aGaussian process prior, we prove that one can effectively and safely collectdata in order to learn about the dynamics and thus both improve controlperformance and expand the safe region of the state space. In our experiments,we show how the resulting algorithm can safely optimize a neural network policyon a simulated inverted pendulum, without the pendulum ever falling down."^^schema:Text ;
    schema:author "Andreas Krause"^^schema:Person,
        "Angela P. Schoellig"^^schema:Person,
        "Felix Berkenkamp"^^schema:Person,
        "Matteo Turchetta"^^schema:Person ;
    schema:commentCount "217"^^schema:Integer ;
    schema:dateModified "2017-11-13T18:49:54Z"^^schema:DateTime ;
    schema:datePublished "2017-05-23T22:20:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Safe Model-based Reinforcement Learning with Stability Guarantees"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08551v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7457682645751123115&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1400> a schema:ScholarlyArticle ;
    schema:abstract "Prioritized experience replay (PER) samples important transitions, ratherthan uniformly, to improve the performance of a deep reinforcement learningagent. We claim that such prioritization has to be balanced with samplediversity for making the DQN stabilized and preventing forgetting. Our proposedimprovement over PER, called Predictive PER (PPER), takes three countermeasures(TDInit, TDClip, TDPred) to (i) eliminate priority outliers and explosions and(ii) improve the sample diversity and distributions, weighted by priorities,both leading to stabilizing the DQN. The most notable among the three is theintroduction of the second DNN called TDPred to generalize the in-distributionpriorities. Ablation study and full experiments with Atari games show that eachcountermeasure by its own way and PPER contribute to successfully enhancingstability and thus performance over PER."^^schema:Text ;
    schema:author "Ichiro Hasuo"^^schema:Person,
        "Jaeyoung Lee"^^schema:Person,
        "Sanghwa Lee"^^schema:Person ;
    schema:dateModified "2020-11-26T02:12:31Z"^^schema:DateTime ;
    schema:datePublished "2020-11-26T02:12:31Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Predictive PER: Balancing Priority and Diversity towards Stable Deep  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13093v1"^^schema:URL .

<1401> a schema:ScholarlyArticle ;
    schema:abstract "Across- and within-recording variabilities in electroencephalographic (EEG)activity is a major limitation in EEG-based brain-computer interfaces (BCIs).Specifically, gradual changes in fatigue and vigilance levels during long EEGrecording durations and BCI system usage bring along significant fluctuationsin BCI performances even when these systems are calibrated daily. We addressthis in an experimental offline study from EEG-based BCI speller usage dataacquired for one hour duration. As the main part of our methodologicalapproach, we propose the concept of adversarial invariant feature learning forBCIs as a regularization approach on recently expanding EEG deep learningarchitectures, to learn nuisance-invariant discriminative features. Weempirically demonstrate the feasibility of adversarial feature learning oneliminating drowsiness effects from event related EEG activity features, byusing temporal recording block ordering as the source of drowsinessvariability."^^schema:Text ;
    schema:author "Barry Oken"^^schema:Person,
        "Deniz Erdogmus"^^schema:Person,
        "Melanie Fried-Oken"^^schema:Person,
        "Ozan Ozdenizci"^^schema:Person,
        "Tab Memmott"^^schema:Person ;
    schema:dateModified "2019-07-22T19:28:37Z"^^schema:DateTime ;
    schema:datePublished "2019-07-22T19:28:37Z"^^schema:DateTime ;
    schema:genre "cs.HC"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Adversarial Feature Learning in Brain Interfacing: An Experimental Study  on Eliminating Drowsiness Effects"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.09540v1"^^schema:URL .

<1402> a schema:ScholarlyArticle ;
    schema:abstract "Data augmentation is an effective technique to improve the generalization ofdeep neural networks. Recently, AutoAugment proposed a well-designed searchspace and a search algorithm that automatically finds augmentation policies ina data-driven manner. However, AutoAugment is computationally intensive. Inthis paper, we propose an efficient gradient-based search algorithm, calledHypernetwork-Based Augmentation (HBA), which simultaneously learns modelparameters and augmentation hyperparameters in a single training. Our HBA usesa hypernetwork to approximate a population-based training algorithm, whichenables us to tune augmentation hyperparameters by gradient descent. Besides,we introduce a weight sharing strategy that simplifies our hypernetworkarchitecture and speeds up our search algorithm. We conduct experiments onCIFAR-10, CIFAR-100, SVHN, and ImageNet. Our results demonstrate that HBA issignificantly faster than state-of-the-art methods while achieving competitiveaccuracy."^^schema:Text ;
    schema:author "Che-Han Chang"^^schema:Person,
        "Chih-Yang Chen"^^schema:Person,
        "Edward Y. Chang"^^schema:Person ;
    schema:dateModified "2020-06-11T10:36:39Z"^^schema:DateTime ;
    schema:datePublished "2020-06-11T10:36:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Hypernetwork-Based Augmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.06320v1"^^schema:URL .

<1403> a schema:ScholarlyArticle ;
    schema:abstract "Basing on the analysis by revealing the equivalence of modern networks, wefind that both ResNet and DenseNet are essentially derived from the same \"densetopology\", yet they only differ in the form of connection -- addition (dubbed\"inner link\") vs. concatenation (dubbed \"outer link\"). However, both two formsof connections have the superiority and insufficiency. To combine theiradvantages and avoid certain limitations on representation learning, we presenta highly efficient and modularized Mixed Link Network (MixNet) which isequipped with flexible inner link and outer link modules. Consequently, ResNet,DenseNet and Dual Path Network (DPN) can be regarded as a special case ofMixNet, respectively. Furthermore, we demonstrate that MixNets can achievesuperior efficiency in parameter over the state-of-the-art architectures onmany competitive datasets like CIFAR-10/100, SVHN and ImageNet."^^schema:Text ;
    schema:author "Jian Yang"^^schema:Person,
        "Tong Lu"^^schema:Person,
        "Wenhai Wang"^^schema:Person,
        "Xiang Li"^^schema:Person ;
    schema:dateModified "2018-02-06T05:50:34Z"^^schema:DateTime ;
    schema:datePublished "2018-02-06T05:50:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Mixed Link Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.01808v1"^^schema:URL .

<1404> a schema:ScholarlyArticle ;
    schema:abstract "In statistical relational learning, knowledge graph completion deals withautomatically understanding the structure of large knowledge graphs---labeleddirected graphs---and predicting missing relationships---labeled edges.State-of-the-art embedding models propose different trade-offs between modelingexpressiveness, and time and space complexity. We reconcile both expressivenessand complexity through the use of complex-valued embeddings and explore thelink between such complex-valued embeddings and unitary diagonalization. Wecorroborate our approach theoretically and show that all real squarematrices---thus all possible relation/adjacency matrices---are the real part ofsome unitarily diagonalizable matrix. This results opens the door to a lot ofother applications of square matrices factorization. Our approach based oncomplex embeddings is arguably simple, as it only involves a Hermitian dotproduct, the complex counterpart of the standard dot product between realvectors, whereas other methods resort to more and more complicated compositionfunctions to increase their expressiveness. The proposed complex embeddings arescalable to large data sets as it remains linear in both space and time, whileconsistently outperforming alternative approaches on standard link predictionbenchmarks."^^schema:Text ;
    schema:author "Christopher R. Dance"^^schema:Person,
        "Guillaume Bouchard"^^schema:Person,
        "Johannes Welbl"^^schema:Person,
        "Sebastian Riedel"^^schema:Person,
        "Théo Trouillon"^^schema:Person,
        "Éric Gaussier"^^schema:Person ;
    schema:dateModified "2017-11-26T20:39:34Z"^^schema:DateTime ;
    schema:datePublished "2017-02-22T16:28:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.SP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Knowledge Graph Completion via Complex Tensor Factorization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.06879v2"^^schema:URL .

<1405> a schema:ScholarlyArticle ;
    schema:abstract "We show that an end-to-end deep learning approach can be used to recognizeeither English or Mandarin Chinese speech--two vastly different languages.Because it replaces entire pipelines of hand-engineered components with neuralnetworks, end-to-end learning allows us to handle a diverse variety of speechincluding noisy environments, accents and different languages. Key to ourapproach is our application of HPC techniques, resulting in a 7x speedup overour previous system. Because of this efficiency, experiments that previouslytook weeks now run in days. This enables us to iterate more quickly to identifysuperior architectures and algorithms. As a result, in several cases, oursystem is competitive with the transcription of human workers when benchmarkedon standard datasets. Finally, using a technique called Batch Dispatch withGPUs in the data center, we show that our system can be inexpensively deployedin an online setting, delivering low latency when serving users at scale."^^schema:Text ;
    schema:author "Adam Coates"^^schema:Person,
        "Andrew Ng"^^schema:Person,
        "Awni Hannun"^^schema:Person,
        "Billy Jun"^^schema:Person,
        "Bo Xiao"^^schema:Person,
        "Bryan Catanzaro"^^schema:Person,
        "Carl Case"^^schema:Person,
        "Chong Wang"^^schema:Person,
        "Christopher Fougner"^^schema:Person,
        "Dani Yogatama"^^schema:Person,
        "Dario Amodei"^^schema:Person,
        "David Seetapun"^^schema:Person,
        "Eric Battenberg"^^schema:Person,
        "Erich Elsen"^^schema:Person,
        "Greg Diamos"^^schema:Person,
        "Jared Casper"^^schema:Person,
        "Jesse Engel"^^schema:Person,
        "Jingdong Chen"^^schema:Person,
        "Jonathan Raiman"^^schema:Person,
        "Jun Zhan"^^schema:Person,
        "Libby Lin"^^schema:Person,
        "Linxi Fan"^^schema:Person,
        "Mike Chrzanowski"^^schema:Person,
        "Patrick LeGresley"^^schema:Person,
        "Rishita Anubhai"^^schema:Person,
        "Ryan Prenger"^^schema:Person,
        "Sanjeev Satheesh"^^schema:Person,
        "Sharan Narang"^^schema:Person,
        "Sherjil Ozair"^^schema:Person,
        "Shubho Sengupta"^^schema:Person,
        "Tony Han"^^schema:Person,
        "Yi Wang"^^schema:Person,
        "Zhenyao Zhu"^^schema:Person,
        "Zhiqian Wang"^^schema:Person ;
    schema:dateModified "2015-12-08T19:13:50Z"^^schema:DateTime ;
    schema:datePublished "2015-12-08T19:13:50Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1512.02595v1"^^schema:URL .

<1406> a schema:ScholarlyArticle ;
    schema:abstract "Actor critic methods with sparse rewards in model-based deep reinforcementlearning typically require a deterministic binary reward function that reflectsonly two possible outcomes: if, for each step, the goal has been achieved ornot. Our hypothesis is that we can influence an agent to learn faster byapplying an external environmental pressure during training, which adverselyimpacts its ability to get higher rewards. As such, we deviate from theclassical paradigm of sparse rewards and add a uniformly sampled reward valueto the baseline reward to show that (1) sample efficiency of the trainingprocess can be correlated to the adversity experienced during training, (2) itis possible to achieve higher performance in less time and with less resources,(3) we can reduce the performance variability experienced seed over seed, (4)there is a maximum point after which more pressure will not generate betterresults, and (5) that random positive incentives have an adverse effect whenusing a negative reward strategy, making an agent under those conditions learnpoorly and more slowly. These results have been shown to be valid for DeepDeterministic Policy Gradients using Hindsight Experience Replay in a wellknown Mujoco environment, but we argue that they could be generalized to othermethods and environments as well."^^schema:Text ;
    schema:author "Amir Barati Farimani"^^schema:Person,
        "Juan Vargas"^^schema:Person,
        "Lazar Andjelic"^^schema:Person ;
    schema:dateModified "2020-01-18T20:52:05Z"^^schema:DateTime ;
    schema:datePublished "2020-01-18T20:52:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Effects of sparse rewards of different magnitudes in the speed of  learning of model-based actor critic methods"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.06725v1"^^schema:URL .

<1407> a schema:ScholarlyArticle ;
    schema:abstract "Image registration with deep neural networks has become an active field ofresearch and exciting avenue for a long standing problem in medical imaging.The goal is to learn a complex function that maps the appearance of input imagepairs to parameters of a spatial transformation in order to align correspondinganatomical structures. We argue and show that the current direct, non-iterativeapproaches are sub-optimal, in particular if we seek accurate alignment ofStructures-of-Interest (SoI). Information about SoI is often available attraining time, for example, in form of segmentations or landmarks. We introducea novel, generic framework, Image-and-Spatial Transformer Networks (ISTNs), toleverage SoI information allowing us to learn new image representations thatare optimised for the downstream registration task. Thanks to theserepresentations we can employ a test-specific, iterative refinement over thetransformation parameters which yields highly accurate registration even withvery limited training data. Performance is demonstrated on pairwise 3D brainregistration and illustrative synthetic data."^^schema:Text ;
    schema:author "Andreas Schuh"^^schema:Person,
        "Ben Glocker"^^schema:Person,
        "Matthew C. H. Lee"^^schema:Person,
        "Michiel Schaap"^^schema:Person,
        "Ozan Oktay"^^schema:Person ;
    schema:dateModified "2019-07-22T09:39:53Z"^^schema:DateTime ;
    schema:datePublished "2019-07-22T09:39:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Image-and-Spatial Transformer Networks for Structure-Guided Image  Registration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.09200v1"^^schema:URL .

<1408> a schema:ScholarlyArticle ;
    schema:abstract "Recent successful deep reinforcement learning algorithms, such as TrustRegion Policy Optimization (TRPO) or Proximal Policy Optimization (PPO), arefundamentally variations of conservative policy iteration (CPI). Thesealgorithms iterate policy evaluation followed by a softened policy improvementstep. As so, they are naturally on-policy. In this paper, we propose to combine(any kind of) soft greediness with Modified Policy Iteration (MPI). Theproposed abstract framework applies repeatedly: (i) a partial policy evaluationstep that allows off-policy learning and (ii) any softened greedy step. Ourcontribution can be seen as a new generic tool for the deep reinforcementlearning toolbox. As a proof of concept, we instantiate this framework with thePPO greediness. Comparison to the original PPO shows that our algorithm is muchmore sample efficient. We also show that it is competitive with thestate-of-art off-policy algorithm Soft Actor Critic (SAC)."^^schema:Text ;
    schema:author "Erinc Merdivan"^^schema:Person,
        "Matthieu Geist"^^schema:Person,
        "Sten Hanke"^^schema:Person ;
    schema:dateModified "2020-01-24T10:08:28Z"^^schema:DateTime ;
    schema:datePublished "2019-07-02T11:22:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modified Actor-Critics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.01298v2"^^schema:URL .

<1409> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we investigate the joint user pairing and association problemfor multicell non-orthogonal multiple access (NOMA) systems. We consider ascenario where the user equipments (UEs) are located in a multicell networkequipped with multiple base stations. Each base station has multiple orthogonalphysical resource blocks (PRBs). Each PRB can be allocated to a pair of UEsusing NOMA. Each UE has the additional freedom to be served by any one of thebase stations, which further increases the complexity of the joint user pairingand association algorithm design. Leveraging the recent success on usingmachine learning to solve numerical optimization problems, we formulate thejoint user pairing and association problem as a combinatorial optimizationproblem. The solution is found using an emerging deep learning architecturecalled Pointer Network (PtrNet), which has a lower computational complexitycompared to solutions based on iterative algorithms and has been proven toachieve near-optimal performance. The training phase of the PtrNet is based ondeep reinforcement learning (DRL), and does not require the use of the optimalsolution of the formulated problem as training labels. Simulation results showthat the proposed joint user pairing and association scheme achievesnear-optimal performance in terms of the aggregate data rate, and outperformsthe random user pairing and association heuristic by up to 30%."^^schema:Text ;
    schema:author "Manyou Ma"^^schema:Person,
        "Vincent W. S. Wong"^^schema:Person ;
    schema:dateModified "2020-04-15T23:42:19Z"^^schema:DateTime ;
    schema:datePublished "2020-04-15T23:42:19Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Joint User Pairing and Association for Multicell NOMA: A Pointer  Network-based Approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.07395v1"^^schema:URL .

<141> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, stochastic gradient descent (SGD) based techniques hasbecome the standard tools for training neural networks. However, formaltheoretical understanding of why SGD can train neural networks in practice islargely missing.  In this paper, we make progress on understanding this mystery by providing aconvergence analysis for SGD on a rich subset of two-layer feedforward networkswith ReLU activations. This subset is characterized by a special structurecalled \"identity mapping\". We prove that, if input follows from Gaussiandistribution, with standard $O(1/\\sqrt{d})$ initialization of the weights, SGDconverges to the global minimum in polynomial number of steps. Unlike normalvanilla networks, the \"identity mapping\" makes our network asymmetric and thusthe global minimum is unique. To complement our theory, we are also able toshow experimentally that multi-layer networks with this mapping have betterperformance compared with normal vanilla networks.  Our convergence theorem differs from traditional non-convex optimizationtechniques. We show that SGD converges to optimal in \"two phases\": In phase I,the gradient points to the wrong direction, however, a potential function $g$gradually decreases. Then in phase II, SGD enters a nice one point convexregion and converges. We also show that the identity mapping is necessary forconvergence, as it moves the initial point to a better place for optimization.Experiment verifies our claims."^^schema:Text ;
    schema:author "Yang Yuan"^^schema:Person,
        "Yuanzhi Li"^^schema:Person ;
    schema:commentCount "267"^^schema:Integer ;
    schema:dateModified "2017-11-01T21:42:23Z"^^schema:DateTime ;
    schema:datePublished "2017-05-28T02:11:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Convergence Analysis of Two-layer Neural Networks with ReLU Activation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.09886v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=212149420094118161&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1410> a schema:ScholarlyArticle ;
    schema:abstract "Named entity recognition (NER) is highly sensitive to sentential syntacticand semantic properties where entities may be extracted according to how theyare used and placed in the running text. To model such properties, one couldrely on existing resources to providing helpful knowledge to the NER task; someexisting studies proved the effectiveness of doing so, and yet are limited inappropriately leveraging the knowledge such as distinguishing the importantones for particular context. In this paper, we improve NER by leveragingdifferent types of syntactic information through attentive ensemble, whichfunctionalizes by the proposed key-value memory networks, syntax attention, andthe gate mechanism for encoding, weighting and aggregating such syntacticinformation, respectively. Experimental results on six English and Chinesebenchmark datasets suggest the effectiveness of the proposed model and showthat it outperforms previous studies on all experiment datasets."^^schema:Text ;
    schema:author "Xiang Ao"^^schema:Person,
        "Xiang Wan"^^schema:Person,
        "Yan Song"^^schema:Person,
        "Yuanhe Tian"^^schema:Person,
        "Yuyang Nie"^^schema:Person ;
    schema:dateModified "2020-10-29T10:25:17Z"^^schema:DateTime ;
    schema:datePublished "2020-10-29T10:25:17Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Improving Named Entity Recognition with Attentive Ensemble of Syntactic  Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.15466v1"^^schema:URL .

<1411> a schema:ScholarlyArticle ;
    schema:abstract "Learning models of the environment from data is often viewed as an essentialcomponent to building intelligent reinforcement learning (RL) agents. Thecommon practice is to separate the learning of the model from its use, byconstructing a model of the environment's dynamics that correctly predicts theobserved state transitions. In this paper we argue that the limitedrepresentational resources of model-based RL agents are better used to buildmodels that are directly useful for value-based planning. As our maincontribution, we introduce the principle of value equivalence: two models arevalue equivalent with respect to a set of functions and policies if they yieldthe same Bellman updates. We propose a formulation of the model learningproblem based on the value equivalence principle and analyze how the set offeasible solutions is impacted by the choice of policies and functions.Specifically, we show that, as we augment the set of policies and functionsconsidered, the class of value equivalent models shrinks, until eventuallycollapsing to a single point corresponding to a model that perfectly describesthe environment. In many problems, directly modelling state-to-statetransitions may be both difficult and unnecessary. By leveraging thevalue-equivalence principle one may find simpler models without compromisingperformance, saving computation and memory. We illustrate the benefits ofvalue-equivalent model learning with experiments comparing it against moretraditional counterparts like maximum likelihood estimation. More generally, weargue that the principle of value equivalence underlies a number of recentempirical successes in RL, such as Value Iteration Networks, the Predictron,Value Prediction Networks, TreeQN, and MuZero, and provides a first theoreticalunderpinning of those results."^^schema:Text ;
    schema:author "André Barreto"^^schema:Person,
        "Christopher Grimm"^^schema:Person,
        "David Silver"^^schema:Person,
        "Satinder Singh"^^schema:Person ;
    schema:dateModified "2020-11-06T18:25:54Z"^^schema:DateTime ;
    schema:datePublished "2020-11-06T18:25:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "The Value Equivalence Principle for Model-Based Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03506v1"^^schema:URL .

<1412> a schema:ScholarlyArticle ;
    schema:abstract "Learning from unordered sets is a fundamental learning setup, recentlyattracting increasing attention. Research in this area has focused on the casewhere elements of the set are represented by feature vectors, and far lessemphasis has been given to the common case where set elements themselves adhereto their own symmetries. That case is relevant to numerous applications, fromdeblurring image bursts to multi-view 3D shape recognition and reconstruction.In this paper, we present a principled approach to learning sets of generalsymmetric elements. We first characterize the space of linear layers that areequivariant both to element reordering and to the inherent symmetries ofelements, like translation in the case of images. We further show that networksthat are composed of these layers, called Deep Sets for Symmetric Elements(DSS) layers, are universal approximators of both invariant and equivariantfunctions, and that these networks are strictly more expressive than Siamesenetworks. DSS layers are also straightforward to implement. Finally, we showthat they improve over existing set-learning architectures in a series ofexperiments with images, graphs, and point-clouds."^^schema:Text ;
    schema:author "Ethan Fetaya"^^schema:Person,
        "Gal Chechik"^^schema:Person,
        "Haggai Maron"^^schema:Person,
        "Or Litany"^^schema:Person ;
    schema:dateModified "2020-11-29T07:34:07Z"^^schema:DateTime ;
    schema:datePublished "2020-02-20T07:29:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Learning Sets of Symmetric Elements"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.08599v4"^^schema:URL .

<1413> a schema:ScholarlyArticle ;
    schema:abstract "Many existing approaches for unsupervised domain adaptation (UDA) focus onadapting under only data distribution shift and offer limited success underadditional cross-domain label distribution shift. Recent work based onself-training using target pseudo-labels has shown promise, but on challengingshifts pseudo-labels may be highly unreliable, and using them for self-trainingmay cause error accumulation and domain misalignment. We propose SelectiveEntropy Optimization via Committee Consistency (SENTRY), a UDA algorithm thatjudges the reliability of a target instance based on its predictive consistencyunder a committee of random image transformations. Our algorithm thenselectively minimizes predictive entropy to increase confidence on highlyconsistent target instances, while maximizing predictive entropy to reduceconfidence on highly inconsistent ones. In combination with pseudo-label basedapproximate target class balancing, our approach leads to significantimprovements over the state-of-the-art on 27/31 domain shifts from standard UDAbenchmarks as well as benchmarks designed to stress-test adaptation under labeldistribution shift."^^schema:Text ;
    schema:author "Deeksha Kartik"^^schema:Person,
        "Judy Hoffman"^^schema:Person,
        "Shivam Khare"^^schema:Person,
        "Viraj Prabhu"^^schema:Person ;
    schema:dateModified "2020-12-21T16:24:50Z"^^schema:DateTime ;
    schema:datePublished "2020-12-21T16:24:50Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "SENTRY: Selective Entropy Optimization via Committee Consistency for  Unsupervised Domain Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11460v1"^^schema:URL .

<1414> a schema:ScholarlyArticle ;
    schema:abstract "Motivated by the desire to exploit patterns shared across classes, we presenta simple yet effective class-specific memory module for fine-grained featurelearning. The memory module stores the prototypical feature representation foreach category as a moving average. We hypothesize that the combination ofsimilarities with respect to each category is itself a useful discriminativecue. To detect these similarities, we use attention as a querying mechanism.The attention scores with respect to each class prototype are used as weightsto combine prototypes via weighted sum, producing a uniquely tailored responsefeature representation for a given input. The original and response featuresare combined to produce an augmented feature for classification. We integrateour class-specific memory module into a standard convolutional neural network,yielding a Categorical Memory Network. Our memory module significantly improvesaccuracy over baseline CNNs, achieving competitive accuracy withstate-of-the-art methods on four benchmarks, including CUB-200-2011, StanfordCars, FGVC Aircraft, and NABirds."^^schema:Text ;
    schema:author "Joshua Marsh"^^schema:Person,
        "Liang Zheng"^^schema:Person,
        "Stephen Gould"^^schema:Person,
        "Weijian Deng"^^schema:Person ;
    schema:dateModified "2020-12-12T11:50:13Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T11:50:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Fine-grained Classification via Categorical Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06793v1"^^schema:URL .

<1415> a schema:ScholarlyArticle ;
    schema:abstract "We address the problem of finding realistic geometric corrections to aforeground object such that it appears natural when composited into abackground image. To achieve this, we propose a novel Generative AdversarialNetwork (GAN) architecture that utilizes Spatial Transformer Networks (STNs) asthe generator, which we call Spatial Transformer GANs (ST-GANs). ST-GANs seekimage realism by operating in the geometric warp parameter space. Inparticular, we exploit an iterative STN warping scheme and propose a sequentialtraining strategy that achieves better results compared to naive training of asingle generator. One of the key advantages of ST-GAN is its applicability tohigh-resolution images indirectly since the predicted warp parameters aretransferable between reference frames. We demonstrate our approach in twoapplications: (1) visualizing how indoor furniture (e.g. from product images)might be perceived in a room, (2) hallucinating how accessories like glasseswould look when matched with real portraits."^^schema:Text ;
    schema:author "Chen-Hsuan Lin"^^schema:Person,
        "Eli Shechtman"^^schema:Person,
        "Ersin Yumer"^^schema:Person,
        "Oliver Wang"^^schema:Person,
        "Simon Lucey"^^schema:Person ;
    schema:dateModified "2018-03-05T18:59:01Z"^^schema:DateTime ;
    schema:datePublished "2018-03-05T18:59:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "ST-GAN: Spatial Transformer Generative Adversarial Networks for Image  Compositing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.01837v1"^^schema:URL .

<1416> a schema:ScholarlyArticle ;
    schema:abstract "We propose a comprehensive framework able to address both the predictabilityof the first and of the second kind for high-dimensional chaotic models. Forthis purpose, we analyse the properties of a newly introduced multistableclimate toy model constructed by coupling the Lorenz '96 model with azero-dimensional energy balance model. First, the attractors of the system areidentified with Monte Carlo Basin Bifurcation Analysis. Additionally, we areable to detect the Melancholia state separating the two attractors. Then,Neural Ordinary Differential Equations are applied in order to predict thefuture state of the system in both of the identified attractors."^^schema:Text ;
    schema:author "Jürgen Kurths"^^schema:Person,
        "Maximilian Gelbrecht"^^schema:Person,
        "Niklas Boers"^^schema:Person,
        "Valerio Lucarini"^^schema:Person ;
    schema:dateModified "2020-11-13T06:50:40Z"^^schema:DateTime ;
    schema:datePublished "2020-11-13T06:50:40Z"^^schema:DateTime ;
    schema:genre "nlin.CD"^^schema:Text,
        "physics.ao-ph"^^schema:Text,
        "physics.data-an"^^schema:Text ;
    schema:headline "Analysis of a bistable climate toy model with physics-based machine  learning methods"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12227v1"^^schema:URL .

<1417> a schema:ScholarlyArticle ;
    schema:abstract "Training a deep neural network requires a large amount of single-task dataand involves a long time-consuming optimization phase. This is not scalable tocomplex, realistic environments with new unexpected changes. Humans can performfast incremental learning on the fly and memory systems in the brain play acritical role. We introduce Sparse Meta Networks -- a meta-learning approach tolearn online sequential adaptation algorithms for deep neural networks, byusing deep neural networks. We augment a deep neural network with alayer-specific fast-weight memory. The fast-weights are generated sparsely ateach time step and accumulated incrementally through time providing a usefulinductive bias for online continual adaptation. We demonstrate strongperformance on a variety of sequential adaptation scenarios, from a simpleonline reinforcement learning to a large scale adaptive language modelling."^^schema:Text ;
    schema:author "Tsendsuren Munkhdalai"^^schema:Person ;
    schema:dateModified "2020-09-03T17:06:52Z"^^schema:DateTime ;
    schema:datePublished "2020-09-03T17:06:52Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Sparse Meta Networks for Sequential Adaptation and its Application to  Adaptive Language Modelling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.01803v1"^^schema:URL .

<1418> a schema:ScholarlyArticle ;
    schema:abstract "Activation function is crucial to the recent successes of deep neuralnetworks. In this paper, we first propose a new activation function, MultipleParametric Exponential Linear Units (MPELU), aiming to generalize and unify therectified and exponential linear units. As the generalized form, MPELU sharesthe advantages of Parametric Rectified Linear Unit (PReLU) and ExponentialLinear Unit (ELU), leading to better classification performance and convergenceproperty. In addition, weight initialization is very important to train verydeep networks. The existing methods laid a solid foundation for networks usingrectified linear units but not for exponential linear units. This papercomplements the current theory and extends it to the wider range. Specifically,we put forward a way of initialization, enabling training of very deep networksusing exponential linear units. Experiments demonstrate that the proposedinitialization not only helps the training process but leads to bettergeneralization performance. Finally, utilizing the proposed activation functionand initialization, we present a deep MPELU residual architecture that achievesstate-of-the-art performance on the CIFAR-10/100 datasets. The code isavailable at https://github.com/Coldmooon/Code-for-MPELU."^^schema:Text ;
    schema:author "Chunxiao Fan"^^schema:Person,
        "Qiong Wu"^^schema:Person,
        "Yang Li"^^schema:Person,
        "Yong Li"^^schema:Person,
        "Yue Ming"^^schema:Person ;
    schema:dateModified "2017-01-17T08:44:56Z"^^schema:DateTime ;
    schema:datePublished "2016-06-01T14:33:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Improving Deep Neural Network with Multiple Parametric Exponential  Linear Units"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1606.00305v3"^^schema:URL .

<1419> a schema:ScholarlyArticle ;
    schema:abstract "Exploiting a common language as an auxiliary for better translation has along tradition in machine translation and lets supervised learning-basedmachine translation enjoy the enhancement delivered by the well-used pivotlanguage in the absence of a source language to target language parallelcorpus. The rise of unsupervised neural machine translation (UNMT) almostcompletely relieves the parallel corpus curse, though UNMT is still subject tounsatisfactory performance due to the vagueness of the clues available for itscore back-translation training. Further enriching the idea of pivot translationby extending the use of parallel corpora beyond the source-target paradigm, wepropose a new reference language-based framework for UNMT, RUNMT, in which thereference language only shares a parallel corpus with the source, but thiscorpus still indicates a signal clear enough to help the reconstructiontraining of UNMT through a proposed reference agreement mechanism. Experimentalresults show that our methods improve the quality of UNMT over that of a strongbaseline that uses only one auxiliary language, demonstrating the usefulness ofthe proposed reference language-based UNMT and establishing a good start forthe community."^^schema:Text ;
    schema:author "Eiichiro Sumita"^^schema:Person,
        "Hai Zhao"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Zuchao Li"^^schema:Person ;
    schema:dateModified "2020-10-09T15:48:59Z"^^schema:DateTime ;
    schema:datePublished "2020-04-05T08:28:08Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Reference Language based Unsupervised Neural Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.02127v2"^^schema:URL .

<142> a schema:ScholarlyArticle ;
    schema:abstract "Recent object detection systems rely on two critical steps: (1) a set ofobject proposals is predicted as efficiently as possible, and (2) this set ofcandidate proposals is then passed to an object classifier. Such approacheshave been shown they can be fast, while achieving the state of the art indetection performance. In this paper, we propose a new way to generate objectproposals, introducing an approach based on a discriminative convolutionalnetwork. Our model is trained jointly with two objectives: given an imagepatch, the first part of the system outputs a class-agnostic segmentation mask,while the second part of the system outputs the likelihood of the patch beingcentered on a full object. At test time, the model is efficiently applied onthe whole test image and generates a set of segmentation masks, each of thembeing assigned with a corresponding object likelihood score. We show that ourmodel yields significant improvements over state-of-the-art object proposalalgorithms. In particular, compared to previous approaches, our model obtainssubstantially higher object recall using fewer proposals. We also show that ourmodel is able to generalize to unseen categories it has not seen duringtraining. Unlike all previous approaches for generating object masks, we do notrely on edges, superpixels, or any other form of low-level segmentation."^^schema:Text ;
    schema:author "Pedro O. Pinheiro"^^schema:Person,
        "Piotr Dollar"^^schema:Person,
        "Ronan Collobert"^^schema:Person ;
    schema:commentCount "536"^^schema:Integer ;
    schema:dateModified "2015-09-01T16:03:01Z"^^schema:DateTime ;
    schema:datePublished "2015-06-20T06:36:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Segment Object Candidates"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.06204v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5802251840817059987&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1420> a schema:ScholarlyArticle ;
    schema:abstract "The last decades have seen great progress in saliency prediction, with thesuccess of deep neural networks that are able to encode high-level semantics.Yet, while humans have the innate capability in leveraging their knowledge todecide where to look (e.g. people pay more attention to familiar faces such ascelebrities), saliency prediction models have only been trained with largeeye-tracking datasets. This work proposes to bridge this gap by explicitlyincorporating external knowledge for saliency models as humans do. We developnetworks that learn to highlight regions by incorporating prior knowledge ofsemantic relationships, be it general or domain-specific, depending on the taskof interest. At the core of the method is a new Graph Semantic Saliency Network(GraSSNet) that constructs a graph that encodes semantic relationships learnedfrom external knowledge. A Spatial Graph Attention Network is then developed toupdate saliency features based on the learned graph. Experiments show that theproposed model learns to predict saliency from the external knowledge andoutperforms the state-of-the-art on four saliency benchmarks."^^schema:Text ;
    schema:author "Ming Jiang"^^schema:Person,
        "Qi Zhao"^^schema:Person,
        "Yifeng Zhang"^^schema:Person ;
    schema:dateModified "2020-07-27T20:12:28Z"^^schema:DateTime ;
    schema:datePublished "2020-07-27T20:12:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Saliency Prediction with External Knowledge"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13839v1"^^schema:URL .

<1421> a schema:ScholarlyArticle ;
    schema:abstract "Recovering a photorealistic face from an artistic portrait is a challengingtask since crucial facial details are often distorted or completely lost inartistic compositions. To handle this loss, we propose an Attribute-guided FaceRecovery from Portraits (AFRP) that utilizes a Face Recovery Network (FRN) anda Discriminative Network (DN). FRN consists of an autoencoder with residualblock-embedded skip-connections and incorporates facial attribute vectors intothe feature maps of input portraits at the bottleneck of the autoencoder. DNhas multiple convolutional and fully-connected layers, and its role is toenforce FRN to generate authentic face images with corresponding facialattributes dictated by the input attribute vectors. %Leveraging on the spatialtransformer networks, FRN automatically compensates for misalignments ofportraits. % and generates aligned face images. For the preservation ofidentities, we impose the recovered and ground-truth faces to share similarvisual features. Specifically, DN determines whether the recovered image lookslike a real face and checks if the facial attributes extracted from therecovered image are consistent with given attributes. %Our method can recoverhigh-quality photorealistic faces from unaligned portraits while preserving theidentity of the face images as well as it can reconstruct a photorealistic faceimage with a desired set of attributes. Our method can recover photorealisticidentity-preserving faces with desired attributes from unseen stylizedportraits, artistic paintings, and hand-drawn sketches. On large-scalesynthesized and sketch datasets, we demonstrate that our face recovery methodachieves state-of-the-art results."^^schema:Text ;
    schema:author "Fatemeh Shiri"^^schema:Person,
        "Fatih Porikli"^^schema:Person,
        "Piotr Koniusz"^^schema:Person,
        "Richard Hartley"^^schema:Person,
        "Xin Yu"^^schema:Person ;
    schema:dateModified "2019-04-07T09:29:36Z"^^schema:DateTime ;
    schema:datePublished "2019-04-07T09:29:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Recovering Faces from Portraits with Auxiliary Facial Attributes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.03612v1"^^schema:URL .

<1422> a schema:ScholarlyArticle ;
    schema:abstract "Establishing mathematical models is a ubiquitous and effective method tounderstand the objective world. Due to complex physiological structures anddynamic behaviors, mathematical representation of the human face is anespecially challenging task. A mathematical model for face image representationcalled GmFace is proposed in the form of a multi-Gaussian function in thispaper. The model utilizes the advantages of two-dimensional Gaussian functionwhich provides a symmetric bell surface with a shape that can be controlled byparameters. The GmNet is then designed using Gaussian functions as neurons,with parameters that correspond to each of the parameters of GmFace in order totransform the problem of GmFace parameter solving into a network optimizationproblem of GmNet. The face modeling process can be described by the followingsteps: (1) GmNet initialization; (2) feeding GmNet with face image(s); (3)training GmNet until convergence; (4) drawing out the parameters of GmNet (asthe same as GmFace); (5) recording the face model GmFace. Furthermore, usingGmFace, several face image transformation operations can be realizedmathematically through simple parameter computation."^^schema:Text ;
    schema:author "Hong Qin"^^schema:Person,
        "Jian Xu"^^schema:Person,
        "Lina Yu"^^schema:Person,
        "Linjun Sun"^^schema:Person,
        "Liping Zhang"^^schema:Person,
        "Weijun Li"^^schema:Person,
        "Xiaoli Dong"^^schema:Person,
        "Xin Ning"^^schema:Person ;
    schema:dateModified "2020-08-03T10:11:10Z"^^schema:DateTime ;
    schema:datePublished "2020-08-03T10:11:10Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "GmFace: A Mathematical Model for Face Image Representation Using  Multi-Gaussian"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.00752v1"^^schema:URL .

<1423> a schema:ScholarlyArticle ;
    schema:abstract "Learning meaningful representations that maintain the content necessary for aparticular task while filtering away detrimental variations is a problem ofgreat interest in machine learning. In this paper, we tackle the problem oflearning representations invariant to a specific factor or trait of data. Therepresentation learning process is formulated as an adversarial minimax game.We analyze the optimal equilibrium of such a game and find that it amounts tomaximizing the uncertainty of inferring the detrimental factor given therepresentation while maximizing the certainty of making task-specificpredictions. On three benchmark tasks, namely fair and bias-freeclassification, language-independent generation, and lighting-independent imageclassification, we show that the proposed framework induces an invariantrepresentation, and leads to better generalization evidenced by the improvedperformance."^^schema:Text ;
    schema:author "Eduard Hovy"^^schema:Person,
        "Graham Neubig"^^schema:Person,
        "Qizhe Xie"^^schema:Person,
        "Yulun Du"^^schema:Person,
        "Zihang Dai"^^schema:Person ;
    schema:dateModified "2018-01-29T00:59:58Z"^^schema:DateTime ;
    schema:datePublished "2017-05-31T14:57:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Controllable Invariance through Adversarial Feature Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.11122v3"^^schema:URL .

<1424> a schema:ScholarlyArticle ;
    schema:abstract "In sponsored search, keyword recommendations help advertisers to achieve muchbetter performance within limited budget. Many works have been done to minenumerous candidate keywords from search logs or landing pages. However, thestrategy to select from given candidates remains to be improved. The existingrelevance-based, popularity-based and regular combinatorial strategies fail totake the internal or external competitions among keywords into consideration.In this paper, we regard keyword recommendations as a combinatorialoptimization problem and solve it with a modified pointer network structure.The model is trained on an actor-critic based deep reinforcement learningframework. A pre-clustering method called Equal Size K-Means is proposed toaccelerate the training and testing procedure on the framework by reducing theaction space. The performance of framework is evaluated both in offline andonline environments, and remarkable improvements can be observed."^^schema:Text ;
    schema:author "Jianwei Wu"^^schema:Person,
        "Lin Sun"^^schema:Person,
        "Tao Rong"^^schema:Person,
        "Zhipeng Li"^^schema:Person ;
    schema:dateModified "2019-07-18T13:29:04Z"^^schema:DateTime ;
    schema:datePublished "2019-07-18T13:29:04Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Combinatorial Keyword Recommendations for Sponsored Search with Deep  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.08686v1"^^schema:URL .

<1425> a schema:ScholarlyArticle ;
    schema:abstract "Learning equivariant representations is a promising way to reduce sample andmodel complexity and improve the generalization performance of deep neuralnetworks. The spherical CNNs are successful examples, producingSO(3)-equivariant representations of spherical inputs. There are two main typesof spherical CNNs. The first type lifts the inputs to functions on the rotationgroup SO(3) and applies convolutions on the group, which are computationallyexpensive since SO(3) has one extra dimension. The second type appliesconvolutions directly on the sphere, which are limited to zonal (isotropic)filters, and thus have limited expressivity. In this paper, we present a newtype of spherical CNN that allows anisotropic filters in an efficient way,without ever leaving the spherical domain. The key idea is to considerspin-weighted spherical functions, which were introduced in physics in thestudy of gravitational waves. These are complex-valued functions on the spherewhose phases change upon rotation. We define a convolution betweenspin-weighted functions and build a CNN based on it. The spin-weightedfunctions can also be interpreted as spherical vector fields, allowingapplications to tasks where the inputs or outputs are vector fields.Experiments show that our method outperforms previous methods on tasks likeclassification of spherical images, classification of 3D shapes and semanticsegmentation of spherical panoramas."^^schema:Text ;
    schema:author "Ameesh Makadia"^^schema:Person,
        "Carlos Esteves"^^schema:Person,
        "Kostas Daniilidis"^^schema:Person ;
    schema:dateModified "2020-10-26T17:38:17Z"^^schema:DateTime ;
    schema:datePublished "2020-06-18T17:57:21Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Spin-Weighted Spherical CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.10731v2"^^schema:URL .

<1426> a schema:ScholarlyArticle ;
    schema:abstract "Planar pushing remains a challenging research topic, where building thedynamic model of the interaction is the core issue. Even an accurate analyticaldynamic model is inherently unstable because physics parameters such as inertiaand friction can only be approximated. Data-driven models usually rely on largeamounts of training data, but data collection is time consuming when workingwith real robots.  In this paper, we collect all training data in a physics simulator and buildan LSTM-based model to fit the pushing dynamics. Domain Randomization isapplied to capture the pushing trajectories of a generalized class of objects.When executed on the real robot, the trained recursive model adapts to thetracked object's real dynamics within a few steps. We propose the algorithm\\emph{Recurrent} Model Predictive Path Integral (RMPPI) as a variation of theoriginal MPPI approach, employing state-dependent recurrent models.  As a comparison, we also train a Deep Deterministic Policy Gradient (DDPG)network as a model-free baseline, which is also used as the action generator inthe data collection phase. During policy training, Hindsight Experience Replayis used to improve exploration efficiency. Pushing experiments on our UR5platform demonstrate the model's adaptability and the effectiveness of theproposed framework."^^schema:Text ;
    schema:author "Hongzhuo Liang"^^schema:Person,
        "Jianwei Zhang"^^schema:Person,
        "Lin Cong"^^schema:Person,
        "Michael Görner"^^schema:Person,
        "Norman Hendrich"^^schema:Person,
        "Philipp Ruppel"^^schema:Person ;
    schema:dateModified "2020-07-27T10:52:27Z"^^schema:DateTime ;
    schema:datePublished "2020-07-27T10:52:27Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Self-Adapting Recurrent Models for Object Pushing from Learning in  Simulation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13421v1"^^schema:URL .

<1427> a schema:ScholarlyArticle ;
    schema:abstract "Fabricating neural models for a wide range of mobile devices demands for aspecific design of networks due to highly constrained resources. Both evolutionalgorithms (EA) and reinforced learning methods (RL) have been dedicated tosolve neural architecture search problems. However, these combinations usuallyconcentrate on a single objective such as the error rate of imageclassification. They also fail to harness the very benefits from both sides. Inthis paper, we present a new multi-objective oriented algorithm called MoreMNAS(Multi-Objective Reinforced Evolution in Mobile Neural Architecture Search) byleveraging good virtues from both EA and RL. In particular, we incorporate avariant of multi-objective genetic algorithm NSGA-II, in which the search spaceis composed of various cells so that crossovers and mutations can be performedat the cell level. Moreover, reinforced control is mixed with a naturalmutating process to regulate arbitrary mutation, maintaining a delicate balancebetween exploration and exploitation. Therefore, not only does our methodprevent the searched models from degrading during the evolution process, but italso makes better use of learned knowledge. Our experiments conducted inSuper-resolution domain (SR) deliver rivalling models compared to somestate-of-the-art methods with fewer FLOPS."^^schema:Text ;
    schema:author "Bo Zhang"^^schema:Person,
        "Hailong Ma"^^schema:Person,
        "Ruijun Xu"^^schema:Person,
        "Xiangxiang Chu"^^schema:Person ;
    schema:dateModified "2019-01-16T15:07:10Z"^^schema:DateTime ;
    schema:datePublished "2019-01-04T12:21:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Multi-Objective Reinforced Evolution in Mobile Neural Architecture  Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.01074v3"^^schema:URL .

<1428> a schema:ScholarlyArticle ;
    schema:abstract "Integration of reinforcement learning and imitation learning is an importantproblem that has been studied for a long time in the field of intelligentrobotics. Reinforcement learning optimizes policies to maximize the cumulativereward, whereas imitation learning attempts to extract general knowledge aboutthe trajectories demonstrated by experts, i.e., demonstrators. Because each ofthem has their own drawbacks, methods combining them and compensating for eachset of drawbacks have been explored thus far. However, many of the methods areheuristic and do not have a solid theoretical basis. In this paper, we presenta new theory for integrating reinforcement and imitation learning by extendingthe probabilistic generative model framework for reinforcement learning, {\\itplan by inference}. We develop a new probabilistic graphical model forreinforcement learning with multiple types of rewards and a probabilisticgraphical model for Markov decision processes with multiple optimalityemissions (pMDP-MO). Furthermore, we demonstrate that the integrated learningmethod of reinforcement learning and imitation learning can be formulated as aprobabilistic inference of policies on pMDP-MO by considering the output of thediscriminator in generative adversarial imitation learning as an additionaloptimal emission observation. We adapt the generative adversarial imitationlearning and task-achievement reward to our proposed framework, achievingsignificantly better performance than agents trained with reinforcementlearning or imitation learning alone. Experiments demonstrate that ourframework successfully integrates imitation and reinforcement learning evenwhen the number of demonstrators is only a few."^^schema:Text ;
    schema:author "Akira Kinose"^^schema:Person,
        "Tadahiro Taniguchi"^^schema:Person ;
    schema:dateModified "2019-10-16T08:24:58Z"^^schema:DateTime ;
    schema:datePublished "2019-07-03T21:38:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Integration of Imitation Learning using GAIL and Reinforcement Learning  using Task-achievement Rewards via Probabilistic Graphical Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.02140v2"^^schema:URL .

<1429> a schema:ScholarlyArticle ;
    schema:abstract "Reconstructing under-sampled k-space measurements in Compressed Sensing MRI(CS-MRI) is classically solved with regularized least-squares. Recently, deeplearning has been used to amortize this optimization by training reconstructionnetworks on a dataset of under-sampled measurements. Here, a crucial designchoice is the regularization function(s) and corresponding weight(s). In thispaper, we explore a novel strategy of using a hypernetwork to generate theparameters of a separate reconstruction network as a function of theregularization weight(s), resulting in a regularization-agnostic reconstructionmodel. At test time, for a given under-sampled image, our model can rapidlycompute reconstructions with different amounts of regularization. We analyzethe variability of these reconstructions, especially in situations when theoverall quality is similar. Finally, we propose and empirically demonstrate anefficient and data-driven way of maximizing reconstruction performance givenlimited hypernetwork capacity. Our code is publicly available athttps://github.com/alanqrwang/RegAgnosticCSMRI."^^schema:Text ;
    schema:author "Adrian V. Dalca"^^schema:Person,
        "Alan Q. Wang"^^schema:Person,
        "Mert R. Sabuncu"^^schema:Person ;
    schema:dateModified "2021-01-06T18:55:37Z"^^schema:DateTime ;
    schema:datePublished "2021-01-06T18:55:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Regularization-Agnostic Compressed Sensing MRI Reconstruction with  Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.02194v1"^^schema:URL .

<143> a schema:ScholarlyArticle ;
    schema:abstract "This paper contributes to a development of randomized methods for neuralnetworks. The proposed learner model is generated incrementally by stochasticconfiguration (SC) algorithms, termed as Stochastic Configuration Networks(SCNs). In contrast to the existing randomised learning algorithms for singlelayer feed-forward neural networks (SLFNNs), we randomly assign the inputweights and biases of the hidden nodes in the light of a supervisory mechanism,and the output weights are analytically evaluated in either constructive orselective manner. As fundamentals of SCN-based data modelling techniques, weestablish some theoretical results on the universal approximation property.Three versions of SC algorithms are presented for regression problems(applicable for classification problems as well) in this work. Simulationresults concerning both function approximation and real world data regressionindicate some remarkable merits of our proposed SCNs in terms of less humanintervention on the network size setting, the scope adaptation of randomparameters, fast learning and sound generalization."^^schema:Text ;
    schema:author "Dianhui Wang"^^schema:Person,
        "Ming Li"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:dateModified "2017-02-27T14:49:35Z"^^schema:DateTime ;
    schema:datePublished "2017-02-10T14:24:16Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text ;
    schema:headline "Stochastic Configuration Networks: Fundamentals and Algorithms"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (10), 3466-3479"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.03180v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=188615526968185965&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1430> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we propose a new method to get the specified network parametersthrough one time feed-forward propagation of the meta networks and explore theapplication to neural style transfer. Recent works on style transfer typicallyneed to train image transformation networks for every new style, and the styleis encoded in the network parameters by enormous iterations of stochasticgradient descent. To tackle these issues, we build a meta network which takesin the style image and produces a corresponding image transformations networkdirectly. Compared with optimization-based methods for every style, our metanetworks can handle an arbitrary new style within $19ms$ seconds on one modernGPU card. The fast image transformation network generated by our meta networkis only 449KB, which is capable of real-time executing on a mobile device. Wealso investigate the manifold of the style transfer networks by operating thehidden features from meta networks. Experiments have well validated theeffectiveness of our method. Code and trained models has been releasedhttps://github.com/FalongShen/styletransfer."^^schema:Text ;
    schema:author "Falong Shen"^^schema:Person,
        "Gang Zeng"^^schema:Person,
        "Shuicheng Yan"^^schema:Person ;
    schema:dateModified "2017-09-13T02:18:39Z"^^schema:DateTime ;
    schema:datePublished "2017-09-13T02:18:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Meta Networks for Neural Style Transfer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.04111v1"^^schema:URL .

<1431> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a robust adversarial reinforcement learning (RARL)-basedmulti-access point (AP) coordination method that is robust even againstunexpected decentralized operations of uncoordinated APs. Multi-AP coordinationis a promising technique towards IEEE 802.11be, and there are studies that useRL for multi-AP coordination. Indeed, a simple RL-based multi-AP coordinationmethod diminishes the collision probability among the APs; therefore, themethod is a promising approach to improve time-resource efficiency. However,this method is vulnerable to frame transmissions of uncoordinated APs that areless aware of frame transmissions of other coordinated APs. To help the centralagent experience even such unexpected frame transmissions, in addition to thecentral agent, the proposed method also competitively trains an adversarial APthat disturbs coordinated APs by causing frame collisions intensively. Besides,we propose to exploit a history of frame losses of a coordinated AP to promotereasonable competition between the central agent and adversarial AP. Thesimulation results indicate that the proposed method can avoid uncoordinatedinterference and thereby improve the minimum sum of the throughputs in thesystem compared to not considering the uncoordinated AP."^^schema:Text ;
    schema:author "Koji Yamamoto"^^schema:Person,
        "Masahiro Morikura"^^schema:Person,
        "Takayuki Nishio"^^schema:Person,
        "Yusuke Koda"^^schema:Person,
        "Yuto Kihira"^^schema:Person ;
    schema:dateModified "2020-04-02T06:27:45Z"^^schema:DateTime ;
    schema:datePublished "2020-04-02T06:27:45Z"^^schema:DateTime ;
    schema:genre "cs.NI"^^schema:Text ;
    schema:headline "Adversarial Reinforcement Learning-based Robust Access Point  Coordination Against Uncoordinated Interference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.00835v1"^^schema:URL .

<1432> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge distillation between machine learning models has opened many newavenues for parameter count reduction, performance improvements, or amortizingtraining time when changing architectures between the teacher and studentnetwork. In the case of reinforcement learning, this technique has also beenapplied to distill teacher policies to students. Until now, policy distillationrequired access to a simulator or real world trajectories.  In this paper we introduce a simulator-free approach to knowledgedistillation in the context of reinforcement learning. A key challenge ishaving the student learn the multiplicity of cases that correspond to a givenaction. While prior work has shown that data-free knowledge distillation ispossible with supervised learning models by generating synthetic examples,these approaches to are vulnerable to only producing a single prototype examplefor each class. We propose an extension to explicitly handle multipleobservations per output class that seeks to find as many exemplars as possiblefor a given output class by reinitializing our data generator and making use ofan adversarial loss.  To the best of our knowledge, this is the first demonstration ofsimulator-free knowledge distillation between a teacher and a student policy.This new approach improves over the state of the art on data-free learning ofstudent networks on benchmark datasets (MNIST, Fashion-MNIST, CIFAR-10), and wealso demonstrate that it specifically tackles issues with multiple input modes.We also identify open problems when distilling agents trained in highdimensional environments such as Pong, Breakout, or Seaquest."^^schema:Text ;
    schema:author "Jonathan Raiman"^^schema:Person ;
    schema:dateModified "2020-11-23T15:31:12Z"^^schema:DateTime ;
    schema:datePublished "2020-11-23T15:31:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Adversarial Simulator"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11472v1"^^schema:URL .

<1433> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we introduce a generalized value iteration network (GVIN),which is an end-to-end neural network planning module. GVIN emulates the valueiteration algorithm by using a novel graph convolution operator, which enablesGVIN to learn and plan on irregular spatial graphs. We propose three noveldifferentiable kernels as graph convolution operators and show that theembedding based kernel achieves the best performance. We further proposeepisodic Q-learning, an improvement upon traditional n-step Q-learning thatstabilizes training for networks that contain a planning module. Lastly, weevaluate GVIN on planning problems in 2D mazes, irregular graphs, andreal-world street networks, showing that GVIN generalizes well for botharbitrary graphs and unseen graphs of larger scale and outperforms a naivegeneralization of VIN (discretizing a spatial graph into a 2D image)."^^schema:Text ;
    schema:author "Colin Targonski"^^schema:Person,
        "Hanyu Guo"^^schema:Person,
        "Jelena Kovačević"^^schema:Person,
        "Melissa C. Smith"^^schema:Person,
        "Siheng Chen"^^schema:Person,
        "Sufeng Niu"^^schema:Person ;
    schema:dateModified "2017-10-26T15:23:18Z"^^schema:DateTime ;
    schema:datePublished "2017-06-08T00:04:05Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Generalized Value Iteration Networks: Life Beyond Lattices"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1706.02416v2"^^schema:URL .

<1434> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial imitation learning (GAIL) has attracted increasingattention in the field of robot learning. It enables robots to learn a policyto achieve a task demonstrated by an expert while simultaneously estimating thereward function behind the expert's behaviors. However, this framework islimited to learning a single task with a single reward function. This studyproposes an extended framework called situated GAIL (S-GAIL), in which a taskvariable is introduced to both the discriminator and generator of the GAILframework. The task variable has the roles of discriminating different contextsand making the framework learn different reward functions and policies formultiple tasks. To achieve the early convergence of learning and robustnessduring reward estimation, we introduce a term to adjust the entropyregularization coefficient in the generator's objective function. Ourexperiments using two setups (navigation in a discrete grid world and armreaching in a continuous space) demonstrate that the proposed framework canacquire multiple reward functions and policies more effectively than existingframeworks. The task variable enables our framework to differentiate contextswhile sharing common knowledge among multiple tasks."^^schema:Text ;
    schema:author "Kyoichiro Kobayashi"^^schema:Person,
        "Minoru Asada"^^schema:Person,
        "Ryo Iwaki"^^schema:Person,
        "Takato Horii"^^schema:Person,
        "Yukie Nagai"^^schema:Person ;
    schema:dateModified "2019-11-01T07:50:30Z"^^schema:DateTime ;
    schema:datePublished "2019-11-01T07:50:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Situated GAIL: Multitask imitation using task-conditioned adversarial  inverse reinforcement learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.00238v1"^^schema:URL .

<1435> a schema:ScholarlyArticle ;
    schema:abstract "Synchronized stochastic gradient descent (SGD) optimizers with dataparallelism are widely used in training large-scale deep neural networks.Although using larger mini-batch sizes can improve the system scalability byreducing the communication-to-computation ratio, it may hurt the generalizationability of the models. To this end, we build a highly scalable deep learningtraining system for dense GPU clusters with three main contributions: (1) Wepropose a mixed-precision training method that significantly improves thetraining throughput of a single GPU without losing accuracy. (2) We propose anoptimization approach for extremely large mini-batch size (up to 64k) that cantrain CNN models on the ImageNet dataset without losing accuracy. (3) Wepropose highly optimized all-reduce algorithms that achieve up to 3x and 11xspeedup on AlexNet and ResNet-50 respectively than NCCL-based training on acluster with 1024 Tesla P40 GPUs. On training ResNet-50 with 90 epochs, thestate-of-the-art GPU-based system with 1024 Tesla P100 GPUs spent 15 minutesand achieved 74.9\\% top-1 test accuracy, and another KNL-based system with 2048Intel KNLs spent 20 minutes and achieved 75.4\\% accuracy. Our training systemcan achieve 75.8\\% top-1 test accuracy in only 6.6 minutes using 2048 Tesla P40GPUs. When training AlexNet with 95 epochs, our system can achieve 58.7\\% top-1test accuracy within 4 minutes, which also outperforms all other existingsystems."^^schema:Text ;
    schema:author "Feihu Zhou"^^schema:Person,
        "Guangxiao Hu"^^schema:Person,
        "Haidong Rong"^^schema:Person,
        "Liqiang Xie"^^schema:Person,
        "Liwei Yu"^^schema:Person,
        "Shaohuai Shi"^^schema:Person,
        "Shutao Song"^^schema:Person,
        "Tiegang Chen"^^schema:Person,
        "Wei He"^^schema:Person,
        "Xianyan Jia"^^schema:Person,
        "Xiaowen Chu"^^schema:Person,
        "Yangzihao Wang"^^schema:Person,
        "Yuanzhou Yang"^^schema:Person,
        "Zhenyu Guo"^^schema:Person ;
    schema:dateModified "2018-07-30T07:40:44Z"^^schema:DateTime ;
    schema:datePublished "2018-07-30T07:40:44Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Highly Scalable Deep Learning Training System with Mixed-Precision:  Training ImageNet in Four Minutes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.11205v1"^^schema:URL .

<1436> a schema:ScholarlyArticle ;
    schema:abstract "Score matching is a popular method for estimating unnormalized statisticalmodels. However, it has been so far limited to simple, shallow models orlow-dimensional data, due to the difficulty of computing the Hessian oflog-density functions. We show this difficulty can be mitigated by projectingthe scores onto random vectors before comparing them. This objective, calledsliced score matching, only involves Hessian-vector products, which can beeasily implemented using reverse-mode automatic differentiation. Therefore,sliced score matching is amenable to more complex models and higher dimensionaldata compared to score matching. Theoretically, we prove the consistency andasymptotic normality of sliced score matching estimators. Moreover, wedemonstrate that sliced score matching can be used to learn deep scoreestimators for implicit distributions. In our experiments, we show sliced scorematching can learn deep energy-based models effectively, and can produceaccurate score estimates for applications such as variational inference withimplicit distributions and training Wasserstein Auto-Encoders."^^schema:Text ;
    schema:author "Jiaxin Shi"^^schema:Person,
        "Sahaj Garg"^^schema:Person,
        "Stefano Ermon"^^schema:Person,
        "Yang Song"^^schema:Person ;
    schema:dateModified "2019-06-27T08:00:36Z"^^schema:DateTime ;
    schema:datePublished "2019-05-17T02:02:30Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Sliced Score Matching: A Scalable Approach to Density and Score  Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.07088v2"^^schema:URL .

<1437> a schema:ScholarlyArticle ;
    schema:abstract "Query-based moment localization is a new task that localizes the best matchedsegment in an untrimmed video according to a given sentence query. In thislocalization task, one should pay more attention to thoroughly mine visual andlinguistic information. To this end, we propose a novel Cross- and Self-ModalGraph Attention Network (CSMGAN) that recasts this task as a process ofiterative messages passing over a joint graph. Specifically, the joint graphconsists of Cross-Modal interaction Graph (CMG) and Self-Modal relation Graph(SMG), where frames and words are represented as nodes, and the relationsbetween cross- and self-modal node pairs are described by an attentionmechanism. Through parametric message passing, CMG highlights relevantinstances across video and sentence, and then SMG models the pairwise relationinside each modality for frame (word) correlating. With multiple layers of sucha joint graph, our CSMGAN is able to effectively capture high-orderinteractions between two modalities, thus enabling a further preciselocalization. Besides, to better comprehend the contextual details in thequery, we develop a hierarchical sentence encoder to enhance the queryunderstanding. Extensive experiments on four public datasets demonstrate theeffectiveness of our proposed model, and GCSMAN significantly outperforms thestate-of-the-arts."^^schema:Text ;
    schema:author "Daizong Liu"^^schema:Person,
        "Jianfeng Dong"^^schema:Person,
        "Pan Zhou"^^schema:Person,
        "Xiao-Yang Liu"^^schema:Person,
        "Xiaoye Qu"^^schema:Person,
        "Zichuan Xu"^^schema:Person ;
    schema:dateModified "2020-08-13T01:56:06Z"^^schema:DateTime ;
    schema:datePublished "2020-08-04T08:25:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Jointly Cross- and Self-Modal Graph Attention Network for Query-Based  Moment Localization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01403v2"^^schema:URL .

<1438> a schema:ScholarlyArticle ;
    schema:abstract "This paper explores the connection between steganography and adversarialimages. On the one hand, ste-ganalysis helps in detecting adversarialperturbations. On the other hand, steganography helps in forging adversarialperturbations that are not only invisible to the human eye but alsostatistically undetectable. This work explains how to use these informationhiding tools for attacking or defending computer vision image classification.We play this cat and mouse game with state-of-art classifiers, steganalyzers,and steganographic embedding schemes. It turns out that steganography helpsmore the attacker than the defender."^^schema:Text ;
    schema:author "Benoît Bonnet"^^schema:Person,
        "Patrick Bas"^^schema:Person,
        "Teddy Furon"^^schema:Person ;
    schema:dateModified "2020-10-15T06:30:07Z"^^schema:DateTime ;
    schema:datePublished "2020-10-15T06:30:07Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "eess.IV"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Adversarial Images through Stega Glasses"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07542v1"^^schema:URL .

<1439> a schema:ScholarlyArticle ;
    schema:abstract "This report describes the systems submitted to the first and second tracks ofthe VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020, which ranked secondin both tracks. Three key points of the system pipeline are explored: (1)investigating multiple CNN architectures including ResNet, Res2Net and dualpath network (DPN) to extract the x-vectors, (2) using a composite angularmargin softmax loss to train the speaker models, and (3) applying scorenormalization and system fusion to boost the performance. Measured on theVoxSRC-20 Eval set, the best submitted systems achieve an EER of $3.808\\%$ anda MinDCF of $0.1958$ in the close-condition track 1, and an EER of $3.798\\%$and a MinDCF of $0.1942$ in the open-condition track 2, respectively."^^schema:Text ;
    schema:author "Xu Xiang"^^schema:Person ;
    schema:dateModified "2020-10-31T06:36:26Z"^^schema:DateTime ;
    schema:datePublished "2020-10-31T06:36:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "The xx205 System for the VoxCeleb Speaker Recognition Challenge 2020"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00200v1"^^schema:URL .

<144> a schema:ScholarlyArticle ;
    schema:abstract "Motivated by the recent progress in generative models, we introduce a modelthat generates images from natural language descriptions. The proposed modeliteratively draws patches on a canvas, while attending to the relevant words inthe description. After training on Microsoft COCO, we compare our model withseveral baseline generative models on image generation and retrieval tasks. Wedemonstrate that our model produces higher quality samples than otherapproaches and generates images with novel scene compositions corresponding topreviously unseen captions in the dataset."^^schema:Text ;
    schema:author "Elman Mansimov"^^schema:Person,
        "Emilio Parisotto"^^schema:Person,
        "Jimmy Lei Ba"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person ;
    schema:commentCount "221"^^schema:Integer ;
    schema:dateModified "2016-02-29T17:56:29Z"^^schema:DateTime ;
    schema:datePublished "2015-11-09T18:18:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Generating Images from Captions with Attention"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.02793v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13416680903946375913&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1440> a schema:ScholarlyArticle ;
    schema:abstract "When answering a question, people often draw upon their rich world knowledgein addition to the particular context. While recent works retrieve supportingfacts/evidence from commonsense knowledge bases to supply additionalinformation to each question, there is still ample opportunity to advance it onthe quality of the evidence. It is crucial since the quality of the evidence isthe key to answering commonsense questions, and even determines the upper boundon the QA systems performance. In this paper, we propose a recursive erasurememory network (REM-Net) to cope with the quality improvement of evidence. Toaddress this, REM-Net is equipped with a module to refine the evidence byrecursively erasing the low-quality evidence that does not explain the questionanswering. Besides, instead of retrieving evidence from existing knowledgebases, REM-Net leverages a pre-trained generative model to generate candidateevidence customized for the question. We conduct experiments on two commonsensequestion answering datasets, WIQA and CosmosQA. The results demonstrate theperformance of REM-Net and show that the refined evidence is explainable."^^schema:Text ;
    schema:author "Liang Lin"^^schema:Person,
        "Meng Fang"^^schema:Person,
        "Qingxing Cao"^^schema:Person,
        "Xiaodan Liang"^^schema:Person,
        "Xunlin Zhan"^^schema:Person,
        "Yinya Huang"^^schema:Person ;
    schema:dateModified "2021-01-03T10:48:56Z"^^schema:DateTime ;
    schema:datePublished "2020-12-24T10:07:32Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence  Refinement"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.13185v2"^^schema:URL .

<1441> a schema:ScholarlyArticle ;
    schema:abstract "Cross-spectral iris recognition is emerging as a promising biometric approachto authenticating the identity of individuals. However, matching iris imagesacquired at different spectral bands shows significant performance degradationwhen compared to single-band near-infrared (NIR) matching due to the spectralgap between iris images obtained in the NIR and visual-light (VIS) spectra.Although researchers have recently focused on deep-learning-based approaches torecover invariant representative features for more accurate recognitionperformance, the existing methods cannot achieve the expected accuracy requiredfor commercial applications. Hence, in this paper, we propose a conditionalcoupled generative adversarial network (CpGAN) architecture for cross-spectraliris recognition by projecting the VIS and NIR iris images into alow-dimensional embedding domain to explore the hidden relationship betweenthem. The conditional CpGAN framework consists of a pair of GAN-based networks,one responsible for retrieving images in the visible domain and otherresponsible for retrieving images in the NIR domain. Both networks try to mapthe data into a common embedding subspace to ensure maximum pair-wisesimilarity between the feature vectors from the two iris modalities of the samesubject. To prove the usefulness of our proposed approach, extensiveexperimental results obtained on the PolyU dataset are compared to existingstate-of-the-art cross-spectral recognition methods."^^schema:Text ;
    schema:author "Fariborz Taherkhani"^^schema:Person,
        "Jeremy Dawson"^^schema:Person,
        "Moktari Mostofa"^^schema:Person,
        "Nasser M. Nasrabadi"^^schema:Person ;
    schema:dateModified "2020-10-09T19:13:24Z"^^schema:DateTime ;
    schema:datePublished "2020-10-09T19:13:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Cross-Spectral Iris Matching Using Conditional Coupled GAN"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11689v1"^^schema:URL .

<1442> a schema:ScholarlyArticle ;
    schema:abstract "Solving the Goal-Conditioned Reward Sparse (GCRS) task is a challengingreinforcement learning problem due to the sparsity of reward signals. In thiswork, we propose a new formulation of GCRS tasks from the perspective of thedrifted random walk on the state space, and design a novel method calledEvolutionary Stochastic Policy Distillation (ESPD) to solve them based on theinsight of reducing the First Hitting Time of the stochastic process. As aself-imitate approach, ESPD enables a target policy to learn from a series ofits stochastic variants through the technique of policy distillation (PD). Thelearning mechanism of ESPD can be considered as an Evolution Strategy (ES) thatapplies perturbations upon policy directly on the action space, with a SELECTfunction to check the superiority of stochastic variants and then use PD toupdate the policy. The experiments based on the MuJoCo robotics control suiteshow the high learning efficiency of the proposed method."^^schema:Text ;
    schema:author "Bo Dai"^^schema:Person,
        "Bolei Zhou"^^schema:Person,
        "Dahua Lin"^^schema:Person,
        "Hao Sun"^^schema:Person,
        "Xinyu Pan"^^schema:Person ;
    schema:dateModified "2020-04-30T11:00:24Z"^^schema:DateTime ;
    schema:datePublished "2020-04-27T16:19:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Evolutionary Stochastic Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.12909v2"^^schema:URL .

<1443> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel architecture for $k$-shot classification on the Omniglotdataset. Building on prototypical networks, we extend their architecture towhat we call Gaussian prototypical networks. Prototypical networks learn a mapbetween images and embedding vectors, and use their clustering forclassification. In our model, a part of the encoder output is interpreted as aconfidence region estimate about the embedding point, and expressed as aGaussian covariance matrix. Our network then constructs a direction and classdependent distance metric on the embedding space, using uncertainties ofindividual data points as weights. We show that Gaussian prototypical networksare a preferred architecture over vanilla prototypical networks with anequivalent number of parameters. We report state-of-the-art performance in1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.We explore artificially down-sampling a fraction of images in the training set,which improves our performance even further. We therefore hypothesize thatGaussian prototypical networks might perform better in less homogeneous,noisier datasets, which are commonplace in real world applications."^^schema:Text ;
    schema:author "Stanislav Fort"^^schema:Person ;
    schema:dateModified "2017-08-09T06:53:31Z"^^schema:DateTime ;
    schema:datePublished "2017-08-09T06:53:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.02735v1"^^schema:URL .

<1444> a schema:ScholarlyArticle ;
    schema:abstract "Hindsight Experience Replay (HER) is one of the efficient algorithm to solveReinforcement Learning tasks related to sparse rewarded environments.But due toits reduced sample efficiency and slower convergence HER fails to performeffectively. Natural gradients solves these challenges by converging the modelparameters better. It avoids taking bad actions that collapse the trainingperformance. However updating parameters in neural networks requires expensivecomputation and thus increase in training time. Our proposed method solves theabove mentioned challenges with better sample efficiency and faster convergencewith increased success rate. A common failure mode for DDPG is that the learnedQ-function begins to dramatically overestimate Q-values, which then leads tothe policy breaking, because it exploits the errors in the Q-function. We solvethis issue by including Twin Delayed Deep Deterministic Policy Gradients(TD3)in HER. TD3 learns two Q-functions instead of one and it adds noise tothetarget action, to make it harder for the policy to exploit Q-function errors.The experiments are done with the help of OpenAis Mujoco environments. Resultson these environments show that our algorithm (TDHER+KFAC) performs betterinmost of the scenarios"^^schema:Text ;
    schema:author "Abhik Singla"^^schema:Person,
        "Dhuruva Priyan G M"^^schema:Person,
        "Shalabh Bhatnagar"^^schema:Person ;
    schema:dateModified "2020-10-09T20:25:14Z"^^schema:DateTime ;
    schema:datePublished "2020-10-09T20:25:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Hindsight Experience Replay with Kronecker Product Approximate Curvature"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.06142v1"^^schema:URL .

<1445> a schema:ScholarlyArticle ;
    schema:abstract "Policy distillation, which transfers a teacher policy to a student policy hasachieved great success in challenging tasks of deep reinforcement learning.This teacher-student framework requires a well-trained teacher model which iscomputationally expensive. Moreover, the performance of the student model couldbe limited by the teacher model if the teacher model is not optimal. In thelight of collaborative learning, we study the feasibility of involving jointintellectual efforts from diverse perspectives of student models. In this work,we introduce dual policy distillation(DPD), a student-student framework inwhich two learners operate on the same environment to explore differentperspectives of the environment and extract knowledge from each other toenhance their learning. The key challenge in developing this dual learningframework is to identify the beneficial knowledge from the peer learner forcontemporary learning-based reinforcement learning algorithms, since it isunclear whether the knowledge distilled from an imperfect and noisy peerlearner would be helpful. To address the challenge, we theoretically justifythat distilling knowledge from a peer learner will lead to policy improvementand propose a disadvantageous distillation strategy based on the theoreticalresults. The conducted experiments on several continuous control tasks showthat the proposed framework achieves superior performance with a learning-basedagent and function approximation without the use of expensive teacher models."^^schema:Text ;
    schema:author "Daochen Zha"^^schema:Person,
        "Kwei-Herng Lai"^^schema:Person,
        "Xia Hu"^^schema:Person,
        "Yuening Li"^^schema:Person ;
    schema:dateModified "2020-06-07T06:49:47Z"^^schema:DateTime ;
    schema:datePublished "2020-06-07T06:49:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Dual Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04061v1"^^schema:URL .

<1446> a schema:ScholarlyArticle ;
    schema:abstract "Chemical process optimization and control are affected by 1) plant-modelmismatch, 2) process disturbances, and 3) constraints for safe operation.Reinforcement learning by policy optimization would be a natural way to solvethis due to its ability to address stochasticity, plant-model mismatch, anddirectly account for the effect of future uncertainty and its feedback in aproper closed-loop manner; all without the need of an inner optimization loop.One of the main reasons why reinforcement learning has not been considered forindustrial processes (or almost any engineering application) is that it lacks aframework to deal with safety critical constraints. Present algorithms forpolicy optimization use difficult-to-tune penalty parameters, fail to reliablysatisfy state constraints or present guarantees only in expectation. We proposea chance constrained policy optimization (CCPO) algorithm which guarantees thesatisfaction of joint chance constraints with a high probability - which iscrucial for safety critical tasks. This is achieved by the introduction ofconstraint tightening (backoffs), which are computed simultaneously with thefeedback policy. Backoffs are adjusted with Bayesian optimization using theempirical cumulative distribution function of the probabilistic constraints,and are therefore self-tuned. This results in a general methodology that can beimbued into present policy optimization algorithms to enable them to satisfyjoint chance constraints with high probability. We present case studies thatanalyze the performance of the proposed approach."^^schema:Text ;
    schema:author "Dongda Zhang"^^schema:Person,
        "Ehecatl Antonio del Rio-Chanona"^^schema:Person,
        "Eric Bradford"^^schema:Person,
        "Federico Galvanin"^^schema:Person,
        "Ilya Orson Sandoval"^^schema:Person,
        "Panagiotis Petsagkourakis"^^schema:Person ;
    schema:dateModified "2020-12-17T12:34:26Z"^^schema:DateTime ;
    schema:datePublished "2020-07-30T14:20:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Chance Constrained Policy Optimization for Process Control and  Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.00030v2"^^schema:URL .

<1447> a schema:ScholarlyArticle ;
    schema:abstract "Storage and retrieval of data in a computer memory plays a major role insystem performance. Traditionally, computer memory organization is static -i.e., they do not change based on the application-specific characteristics inmemory access behaviour during system operation. Specifically, the associationof a data block with a search pattern (or cues) as well as the granularity of astored data do not evolve. Such a static nature of computer memory, we observe,not only limits the amount of data we can store in a given physical storage,but it also misses the opportunity for dramatic performance improvement invarious applications. On the contrary, human memory is characterized byseemingly infinite plasticity in storing and retrieving data - as well asdynamically creating/updating the associations between data and correspondingcues. In this paper, we introduce Neural Storage (NS), a brain-inspiredlearning memory paradigm that organizes the memory as a flexible neural memorynetwork. In NS, the network structure, strength of associations, andgranularity of the data adjust continuously during system operation, providingunprecedented plasticity and performance benefits. We present the associatedstorage/retrieval/retention algorithms in NS, which integrate a formalizedlearning process. Using a full-blown operational model, we demonstrate that NSachieves an order of magnitude improvement in memory access performance for tworepresentative applications when compared to traditional content-based memory."^^schema:Text ;
    schema:author "Prabuddha Chakraborty"^^schema:Person,
        "Swarup Bhunia"^^schema:Person ;
    schema:dateModified "2021-01-07T19:19:25Z"^^schema:DateTime ;
    schema:datePublished "2021-01-07T19:19:25Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.AR"^^schema:Text,
        "cs.ET"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural Storage: A New Paradigm of Elastic Memory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.02729v1"^^schema:URL .

<1448> a schema:ScholarlyArticle ;
    schema:abstract "One of the most exciting applications of Spin Torque Magnetoresistive RandomAccess Memory (ST-MRAM) is the in-memory implementation of deep neuralnetworks, which could allow improving the energy efficiency of ArtificialIntelligence by orders of magnitude with regards to its implementation oncomputers and graphics cards. In particular, ST-MRAM could be ideal forimplementing Binarized Neural Networks (BNNs), a type of deep neural networksdiscovered in 2016, which can achieve state-of-the-art performance with ahighly reduced memory footprint with regards to conventional artificialintelligence approaches. The challenge of ST-MRAM, however, is that it is proneto write errors and usually requires the use of error correction. In this work,we show that these bit errors can be tolerated by BNNs to an outstanding level,based on examples of image recognition tasks (MNIST, CIFAR-10 and ImageNet):bit error rates of ST-MRAM up to 0.1% have little impact on recognitionaccuracy. The requirements for ST-MRAM are therefore considerably relaxed forBNNs with regards to traditional applications. By consequence, we show that forBNNs, ST-MRAMs can be programmed with weak (low-energy) programming conditions,without error correcting codes. We show that this result can allow the use oflow energy and low area ST-MRAM cells, and show that the energy savings at thesystem level can reach a factor two."^^schema:Text ;
    schema:author "Adrien F. Vincent"^^schema:Person,
        "Bogdan Penkovsky"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Nicolas Locatelli"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2019-08-12T11:04:16Z"^^schema:DateTime ;
    schema:datePublished "2019-08-12T11:04:16Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Implementing Binarized Neural Networks with Magnetoresistive RAM without  Error Correction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.04085v1"^^schema:URL .

<1449> a schema:ScholarlyArticle ;
    schema:abstract "Model usage is the central challenge of model-based reinforcement learning.Although dynamics model based on deep neural networks provide goodgeneralization for single step prediction, such ability is over exploited whenit is used to predict long horizon trajectories due to compounding errors. Inthis work, we propose a Dyna-style model-based reinforcement learningalgorithm, which we called Maximum Entropy Model Rollouts (MEMR). To eliminatethe compounding errors, we only use our model to generate single-step rollouts.Furthermore, we propose to generate \\emph{diverse} model rollouts bynon-uniform sampling of the environment states such that the entropy of themodel rollouts is maximized. We mathematically derived the maximum entropysampling criteria for one data case under Gaussian prior. To accomplish thiscriteria, we propose to utilize a prioritized experience replay. Ourpreliminary experiments in challenging locomotion benchmarks show that ourapproach achieves the same sample efficiency of the best model-basedalgorithms, matches the asymptotic performance of the best model-freealgorithms, and significantly reduces the computation requirements of othermodel-based methods."^^schema:Text ;
    schema:author "Chi Zhang"^^schema:Person,
        "Sanmukh Rao Kuppannagari"^^schema:Person,
        "Viktor K Prasanna"^^schema:Person ;
    schema:dateModified "2020-06-29T00:07:27Z"^^schema:DateTime ;
    schema:datePublished "2020-06-08T21:38:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Maximum Entropy Model Rollouts: Fast Model Based Policy Optimization  without Compounding Errors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04802v2"^^schema:URL .

<145> a schema:ScholarlyArticle ;
    schema:abstract "While great strides have been made in using deep learning algorithms to solvesupervised learning tasks, the problem of unsupervised learning - leveragingunlabeled examples to learn about the structure of a domain - remains adifficult unsolved challenge. Here, we explore prediction of future frames in avideo sequence as an unsupervised learning rule for learning about thestructure of the visual world. We describe a predictive neural network(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"from the neuroscience literature. These networks learn to predict future framesin a video sequence, with each layer in the network making local predictionsand only forwarding deviations from those predictions to subsequent networklayers. We show that these networks are able to robustly learn to predict themovement of synthetic (rendered) objects, and that in doing so, the networkslearn internal representations that are useful for decoding latent objectparameters (e.g. pose) that support object recognition with fewer trainingviews. We also show that these networks can scale to complex natural imagestreams (car-mounted camera videos), capturing key aspects of both egocentricmovement and the movement of objects in the visual scene, and therepresentation learned in this setting is useful for estimating the steeringangle. Altogether, these results suggest that prediction represents a powerfulframework for unsupervised learning, allowing for implicit learning of objectand scene structure."^^schema:Text ;
    schema:author "David Cox"^^schema:Person,
        "Gabriel Kreiman"^^schema:Person,
        "William Lotter"^^schema:Person ;
    schema:commentCount "427"^^schema:Integer ;
    schema:dateModified "2017-03-01T01:00:54Z"^^schema:DateTime ;
    schema:datePublished "2016-05-25T23:58:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "q-bio.NC"^^schema:Text ;
    schema:headline "Deep Predictive Coding Networks for Video Prediction and Unsupervised  Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.08104v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11254875356366916799&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1450> a schema:ScholarlyArticle ;
    schema:abstract "Open-world learning is a problem where an autonomous agent detects thingsthat it does not know and learns them over time from a non-stationary andnever-ending stream of data; in an open-world environment, the training dataand objective criteria are never available at once. The agent should grasp newknowledge from learning without forgetting acquired prior knowledge.Researchers proposed a few open-world learning agents for image classificationtasks that operate in complex scenarios. However, all prior work on open-worldlearning has all labeled data to learn the new classes from the stream ofimages. In scenarios where autonomous agents should respond in near real-timeor work in areas with limited communication infrastructure, human labeling ofdata is not possible. Therefore, supervised open-world learning agents are notscalable solutions for such applications. Herein, we propose a new frameworkthat enables agents to learn new classes from a stream of unlabeled data in anunsupervised manner. Also, we study the robustness and learning speed of suchagents with supervised and unsupervised feature representation. We alsointroduce a new metric for open-world learning without labels. We anticipateour theories and method to be a starting point for developing autonomous trueopen-world never-ending learning agents."^^schema:Text ;
    schema:author "Akshay Raj Dhamija"^^schema:Person,
        "Chunchun Li"^^schema:Person,
        "Mohsen Jafarzadeh"^^schema:Person,
        "Steve Cruz"^^schema:Person,
        "Terrance E. Boult"^^schema:Person,
        "Touqeer Ahmad"^^schema:Person ;
    schema:dateModified "2020-12-14T01:39:54Z"^^schema:DateTime ;
    schema:datePublished "2020-11-25T17:41:03Z"^^schema:DateTime ;
    schema:genre "68T45"^^schema:Text,
        "I.4.8"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Open-World Learning Without Labels"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12906v2"^^schema:URL .

<1451> a schema:ScholarlyArticle ;
    schema:abstract "Solving tasks in Reinforcement Learning is no easy feat. As the goal of theagent is to maximize the accumulated reward, it often learns to exploitloopholes and misspecifications in the reward signal resulting in unwantedbehavior. While constraints may solve this issue, there is no closed formsolution for general constraints. In this work we present a novelmulti-timescale approach for constrained policy optimization, called `RewardConstrained Policy Optimization' (RCPO), which uses an alternative penaltysignal to guide the policy towards a constraint satisfying one. We prove theconvergence of our approach and provide empirical evidence of its ability totrain constraint satisfying policies."^^schema:Text ;
    schema:author "Chen Tessler"^^schema:Person,
        "Daniel J. Mankowitz"^^schema:Person,
        "Shie Mannor"^^schema:Person ;
    schema:dateModified "2018-12-26T11:09:40Z"^^schema:DateTime ;
    schema:datePublished "2018-05-28T17:31:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Reward Constrained Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.11074v3"^^schema:URL .

<1452> a schema:ScholarlyArticle ;
    schema:abstract "3D LiDARs and 2D cameras are increasingly being used alongside each other insensor rigs for perception tasks. Before these sensors can be used to gathermeaningful data, however, their extrinsics (and intrinsics) need to beaccurately calibrated, as the performance of the sensor rig is extremelysensitive to these calibration parameters. A vast majority of existingcalibration techniques require significant amounts of data and/or calibrationtargets and human effort, severely impacting their applicability in large-scaleproduction systems. We address this gap with CalibNet: a self-supervised deepnetwork capable of automatically estimating the 6-DoF rigid body transformationbetween a 3D LiDAR and a 2D camera in real-time. CalibNet alleviates the needfor calibration targets, thereby resulting in significant savings incalibration efforts. During training, the network only takes as input a LiDARpoint cloud, the corresponding monocular image, and the camera calibrationmatrix K. At train time, we do not impose direct supervision (i.e., we do notdirectly regress to the calibration parameters, for example). Instead, we trainthe network to predict calibration parameters that maximize the geometric andphotometric consistency of the input images and point clouds. CalibNet learnsto iteratively solve the underlying geometric problem and accurately predictsextrinsic calibration parameters for a wide range of mis-calibrations, withoutrequiring retraining or domain adaptation. The project page is hosted athttps://epiception.github.io/CalibNet"^^schema:Text ;
    schema:author "Ganesh Iyer"^^schema:Person,
        "J. Krishna Murthy"^^schema:Person,
        "K. Madhava Krishna"^^schema:Person,
        "R. Karnik Ram."^^schema:Person ;
    schema:dateModified "2019-08-04T10:40:14Z"^^schema:DateTime ;
    schema:datePublished "2018-03-22T00:24:04Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "CalibNet: Geometrically Supervised Extrinsic Calibration using 3D  Spatial Transformer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.08181v2"^^schema:URL .

<1453> a schema:ScholarlyArticle ;
    schema:abstract "Extraction of adverse drug events from biomedical literature and othertextual data is an important component to monitor drug-safety and this hasattracted attention of many researchers in healthcare. Existing works are morepivoted around entity-relation extraction using bidirectional long short termmemory networks (Bi-LSTM) which does not attain the best featurerepresentations. In this paper, we introduce a question answering frameworkthat exploits the robustness, masking and dynamic attention capabilities ofRoBERTa by a technique of domain adaptation and attempt to overcome theaforementioned limitations. Our model outperforms the prior work by 9.53%F1-Score."^^schema:Text ;
    schema:author "Harshit Jain"^^schema:Person,
        "Nishant Raj"^^schema:Person,
        "Suyash Mishra"^^schema:Person ;
    schema:dateModified "2020-10-30T19:09:48Z"^^schema:DateTime ;
    schema:datePublished "2020-10-30T19:09:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "A Sui Generis QA Approach using RoBERTa for Adverse Drug Event  Identification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00057v1"^^schema:URL .

<1454> a schema:ScholarlyArticle ;
    schema:abstract "Many imaging technologies rely on tomographic reconstruction, which requiressolving a multidimensional inverse problem given a finite number ofprojections. Backprojection is a popular class of algorithm for tomographicreconstruction, however it typically results in poor image reconstructions whenthe projection angles are sparse and/or if the sensors characteristics are notuniform. Several deep learning based algorithms have been developed to solvethis inverse problem and reconstruct the image using a limited number ofprojections. However these algorithms typically require examples of theground-truth (i.e. examples of reconstructed images) to yield good performance.In this paper, we introduce an unsupervised sparse-view backprojectionalgorithm, which does not require ground-truth. The algorithm consists of twomodules in a generator-projector framework; a convolutional neural network anda spatial transformer network. We evaluated our algorithm using computedtomography (CT) images of the human chest. We show that our algorithmsignificantly out-performs filtered backprojection when the projection anglesare very sparse, as well as when the sensor characteristics vary for differentangles. Our approach has practical applications for medical imaging and otherimaging modalities (e.g. radar) where sparse and/or non-uniform projections maybe acquired due to time or sampling constraints."^^schema:Text ;
    schema:author "Paul Sajda"^^schema:Person,
        "Xueqing Liu"^^schema:Person ;
    schema:dateModified "2020-06-01T05:02:53Z"^^schema:DateTime ;
    schema:datePublished "2020-06-01T05:02:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unsupervised Sparse-view Backprojection via Convolutional and Spatial  Transformer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.01658v1"^^schema:URL .

<1455> a schema:ScholarlyArticle ;
    schema:abstract "To make human-like decisions under complex driving environment is achallenging task for autonomous agents. Imitation Learning orlearning-from-demonstration methods have seen great potential for achievingsuch a goal. Some state-of-the-art studies apply Generative AdversarialImitation Learning (GAIL) to learn sequential decision-making and controlpolicies. While GAIL can directly learn a policy, it lacks the ability torecover a reward function, which is considered robust and adaptable toenvironments changes. Adversarial Inverse Reinforcement Learning (AIRL) isanother learning-from-demonstration method that can achieve similar benefits asGAIL but also learns the reward function with the policy simultaneously. In theoriginal work of AIRL, it has been demonstrated in single-agent environmentssuch as maze navigation and ant running tasks in OpenAI Gyms. In this paper, weaugment AIRL by concatenating semantic reward terms in the learning frameworkto improve and stabilize its performance, and then extend it to a morepractical but challenging situation, i.e. decision-making scenario in highlyinteractive driving environment. Four performance evaluation metrics areproposed and compared with some Imitation Learning based methods andReinforcement Learning based methods. Simulation results show that theaugmented AIRL outperforms all the other methods, and the trained vehicle agentcan perform decision-making behaviors comparable with that of the experts."^^schema:Text ;
    schema:author "Ching-Yao Chan"^^schema:Person,
        "Dapeng Liu"^^schema:Person,
        "Hanhan Li"^^schema:Person,
        "Jiayu Chen"^^schema:Person,
        "Pin Wang"^^schema:Person ;
    schema:dateModified "2020-02-02T22:57:56Z"^^schema:DateTime ;
    schema:datePublished "2019-11-19T02:06:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Human-like Decision Making for Autonomous Driving via Adversarial  Inverse Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.08044v2"^^schema:URL .

<1456> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we study an intelligent reflecting surface (IRS)-aidedwireless secure communication system for physical layer security, where an IRSis deployed to adjust its surface reflecting elements to guarantee securecommunication of multiple legitimate users in the presence of multipleeavesdroppers. Aiming to improve the system secrecy rate, a design problem forjointly optimizing the base station (BS)'s beamforming and the IRS's reflectingbeamforming is formulated given the different quality of service (QoS)requirements and time-varying channel condition. As the system is highlydynamic and complex, and it is challenging to address the non-convexoptimization problem, a novel deep reinforcement learning (DRL)-based securebeamforming approach is firstly proposed to achieve the optimal beamformingpolicy against eavesdroppers in dynamic environments. Furthermore,post-decision state (PDS) and prioritized experience replay (PER) schemes areutilized to enhance the learning efficiency and secrecy performance.Specifically, PDS is capable of tracing the environment dynamic characteristicsand adjust the beamforming policy accordingly. Simulation results demonstratethat the proposed deep PDS-PER learning-based secure beamforming approach cansignificantly improve the system secrecy rate and QoS satisfaction probabilityin IRS-aided secure communication systems."^^schema:Text ;
    schema:author "Dusit Niyato"^^schema:Person,
        "Helin Yang"^^schema:Person,
        "Jun Zhao"^^schema:Person,
        "Liang Xiao"^^schema:Person,
        "Qingqing Wu"^^schema:Person,
        "Zehui Xiong"^^schema:Person ;
    schema:dateModified "2020-12-24T14:04:07Z"^^schema:DateTime ;
    schema:datePublished "2020-02-27T17:29:14Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning Based Intelligent Reflecting Surface for  Secure Wireless Communications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.12271v5"^^schema:URL .

<1457> a schema:ScholarlyArticle ;
    schema:abstract "Gradient control plays an important role in feed-forward networks applied tovarious computer vision tasks. Previous work has shown that Recurrent HighwayNetworks minimize the problem of vanishing or exploding gradients. They achievethis by setting the eigenvalues of the temporal Jacobian to 1 across the timesteps. In this work, batch normalized recurrent highway networks are proposedto control the gradient flow in an improved way for network convergence.Specifically, the introduced model can be formed by batch normalizing theinputs at each recurrence loop. The proposed model is tested on an imagecaptioning task using MSCOCO dataset. Experimental results indicate that thebatch normalized recurrent highway networks converge faster and performs bettercompared with the traditional LSTM and RHN based models."^^schema:Text ;
    schema:author "Alexander Loui"^^schema:Person,
        "Carl Salvaggio"^^schema:Person,
        "Chi Zhang"^^schema:Person,
        "Raymond Ptucha"^^schema:Person,
        "Shagan Sah"^^schema:Person,
        "Thang Nguyen"^^schema:Person ;
    schema:dateModified "2018-09-26T23:56:24Z"^^schema:DateTime ;
    schema:datePublished "2018-09-26T23:56:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Batch-normalized Recurrent Highway Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10271v1"^^schema:URL .

<1458> a schema:ScholarlyArticle ;
    schema:abstract "Markov Random Fields (MRFs), a formulation widely used in generative imagemodeling, have long been plagued by the lack of expressive power. This issue isprimarily due to the fact that conventional MRFs formulations tend to usesimplistic factors to capture local patterns. In this paper, we move beyondsuch limitations, and propose a novel MRF model that uses fully-connectedneurons to express the complex interactions among pixels. Through theoreticalanalysis, we reveal an inherent connection between this model and recurrentneural networks, and thereon derive an approximated feed-forward network thatcouples multiple RNNs along opposite directions. This formulation combines theexpressive power of deep neural networks and the cyclic dependency structure ofMRF in a unified model, bringing the modeling capability to a new level. Thefeed-forward approximation also allows it to be efficiently learned from data.Experimental results on a variety of low-level vision tasks show notableimprovement over state-of-the-arts."^^schema:Text ;
    schema:author "Dahua Lin"^^schema:Person,
        "Xiaoou Tang"^^schema:Person,
        "Zhirong Wu"^^schema:Person ;
    schema:dateModified "2016-09-07T15:56:36Z"^^schema:DateTime ;
    schema:datePublished "2016-09-07T15:56:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Markov Random Field for Image Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1609.02036v1"^^schema:URL .

<1459> a schema:ScholarlyArticle ;
    schema:abstract "Recent studies have reported biases in machine learning image classifiers,especially against particular demographic groups. Counterfactual examples foran input -- perturbations that change specific features but not others -- havebeen shown to be useful for evaluating explainability and fairness of machinelearning models. However, generating counterfactual examples for images isnon-trivial due to the underlying causal structure governing the variousfeatures of an image. To be meaningful, generated perturbations need to satisfyconstraints implied by the causal model. We present a method for generatingcounterfactuals by incorporating a structural causal model (SCM) in a novelimproved variant of Adversarially Learned Inference (ALI), that generatescounterfactuals in accordance with the causal relationships between differentattributes of an image. Based on the generated counterfactuals, we show how toevaluate bias and explain a pre-trained machine learning classifier. We alsopropose a counterfactual regularizer that can mitigate bias in the classifier.On the Morpho-MNIST dataset, our method generates counterfactuals comparable inquality to prior work on SCM-based counterfactuals. Our method also works onthe more complex CelebA faces dataset; generated counterfactuals areindistinguishable from original images in a human evaluation experiment. As adownstream task, we use counterfactuals to evaluate a standard classifiertrained on CelebA data and show that it is biased w.r.t. skin and hair color,and show how counterfactual regularization can be used to remove the identifiedbiases."^^schema:Text ;
    schema:author "Amit Sharma"^^schema:Person,
        "Saloni Dash"^^schema:Person,
        "Vineeth N Balasubramanian"^^schema:Person ;
    schema:dateModified "2021-02-03T09:12:31Z"^^schema:DateTime ;
    schema:datePublished "2020-09-17T13:19:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Evaluating and Mitigating Bias in Image Classifiers: A Causal  Perspective Using Counterfactuals"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.08270v3"^^schema:URL .

<146> a schema:ScholarlyArticle ;
    schema:abstract "We present a simple and general method to train a single neural networkexecutable at different widths (number of channels in a layer), permittinginstant and adaptive accuracy-efficiency trade-offs at runtime. Instead oftraining individual networks with different width configurations, we train ashared network with switchable batch normalization. At runtime, the network canadjust its width on the fly according to on-device benchmarks and resourceconstraints, rather than downloading and offloading different models. Ourtrained networks, named slimmable neural networks, achieve similar (and in manycases better) ImageNet classification accuracy than individually trained modelsof MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widthsrespectively. We also demonstrate better performance of slimmable modelscompared with individual ones across a wide range of applications includingCOCO bounding-box object detection, instance segmentation and person keypointdetection without tuning hyper-parameters. Lastly we visualize and discuss thelearned features of slimmable networks. Code and models are available at:https://github.com/JiahuiYu/slimmable_networks"^^schema:Text ;
    schema:author "Jiahui Yu"^^schema:Person,
        "Jianchao Yang"^^schema:Person,
        "Linjie Yang"^^schema:Person,
        "Ning Xu"^^schema:Person,
        "Thomas Huang"^^schema:Person ;
    schema:commentCount "247"^^schema:Integer ;
    schema:dateModified "2018-12-21T03:36:48Z"^^schema:DateTime ;
    schema:datePublished "2018-12-21T03:36:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Slimmable Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1812.08928v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15212173000600372424&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1460> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, I argue that counterfactual fairness does not constitute anecessary condition for an algorithm to be fair, and subsequently suggest howthe constraint can be modified in order to remedy this shortcoming. To thisend, I discuss a hypothetical scenario in which counterfactual fairness and anintuitive judgment of fairness come apart. Then, I turn to the question how theconcept of discrimination can be explicated in order to examine theshortcomings of counterfactual fairness as a necessary condition of algorithmicfairness in more detail. I then incorporate the insights of this analysis intoa novel fairness constraint, causal relevance fairness, which is a modificationof the counterfactual fairness constraint that seems to circumvent itsshortcomings."^^schema:Text ;
    schema:author "Fabian Beigang"^^schema:Person ;
    schema:dateModified "2020-11-14T14:49:51Z"^^schema:DateTime ;
    schema:datePublished "2020-11-14T14:49:51Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Shortcomings of Counterfactual Fairness and a Proposed Modification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.07312v1"^^schema:URL .

<1461> a schema:ScholarlyArticle ;
    schema:abstract "X-ray Computed Tomography (CT) is widely used in clinical applications suchas diagnosis and image-guided interventions. In this paper, we propose a newdeep learning based model for CT image reconstruction with the backbone networkarchitecture built by unrolling an iterative algorithm. However, unlike theexisting strategy to include as many data-adaptive components in the unrolleddynamics model as possible, we find that it is enough to only learn the partswhere traditional designs mostly rely on intuitions and experience. Morespecifically, we propose to learn an initializer for the conjugate gradient(CG) algorithm that involved in one of the subproblems of the backbone model.Other components, such as image priors and hyperparameters, are kept as theoriginal design. Since a hypernetwork is introduced to inference on theinitialization of the CG module, it makes the proposed model a certainmeta-learning model. Therefore, we shall call the proposed model themeta-inversion network (MetaInv-Net). The proposed MetaInv-Net can be designedwith much less trainable parameters while still preserves its superior imagereconstruction performance than some state-of-the-art deep models in CTimaging. In simulated and real data experiments, MetaInv-Net performs very welland can be generalized beyond the training setting, i.e., to other scanningsettings, noise levels, and data sets."^^schema:Text ;
    schema:author "Baodong Liu"^^schema:Person,
        "Bin Dong"^^schema:Person,
        "Haimiao Zhang"^^schema:Person,
        "Hengyong Yu"^^schema:Person ;
    schema:dateModified "2020-09-18T01:17:18Z"^^schema:DateTime ;
    schema:datePublished "2020-05-30T04:19:09Z"^^schema:DateTime ;
    schema:genre "65F10, 68T05, 92B20, 94A08"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "math.OC"^^schema:Text,
        "physics.med-ph"^^schema:Text ;
    schema:headline "MetaInv-Net: Meta Inversion Network for Sparse View CT Image  Reconstruction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.00171v3"^^schema:URL .

<1462> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we present an attribute-guided deep coupled learning frameworkto address the problem of matching polarimetric thermal face photos against agallery of visible faces. The coupled framework contains two sub-networks, onededicated to the visible spectrum and the second sub-network dedicated to thepolarimetric thermal spectrum. Each sub-network is made of a generativeadversarial network (GAN) architecture. We propose a novel Attribute-GuidedCoupled Generative Adversarial Network (AGC-GAN) architecture which utilizesfacial attributes to improve the thermal-to-visible face recognitionperformance. The proposed AGC-GAN exploits the facial attributes and leveragesmultiple loss functions in order to learn rich discriminative features in acommon embedding subspace. To achieve a realistic photo reconstruction whilepreserving the discriminative information, we also add a perceptual loss termto the coupling loss function. An ablation study is performed to show theeffectiveness of different loss functions for optimizing the proposed method.Moreover, the superiority of the model compared to the state-of-the-art modelsis demonstrated using polarimetric dataset."^^schema:Text ;
    schema:author "Nasser M. Nasrabadi"^^schema:Person,
        "Seyed Mehdi Iranmanesh"^^schema:Person ;
    schema:dateModified "2019-07-27T21:14:30Z"^^schema:DateTime ;
    schema:datePublished "2019-07-27T21:14:30Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Attribute-Guided Deep Polarimetric Thermal-to-visible Face Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.11980v1"^^schema:URL .

<1463> a schema:ScholarlyArticle ;
    schema:abstract "We present a proxy dataset of vital signs with class labels indicatingpatient transitions from the ward to intensive care units called Ward2ICU.Patient privacy is protected using a Wasserstein Generative Adversarial Networkto implicitly learn an approximation of the data distribution, allowing us tosample synthetic data. The quality of data generation is assessed directly onthe binary classification task by comparing specificity and sensitivity of anLSTM classifier on proxy and original datasets. We initialize a discussion ofunintentionally disclosing commercial sensitive information and propose asolution for a special case through class label balancing"^^schema:Text ;
    schema:author "André Soares de Moura Costa"^^schema:Person,
        "Daniel Severo"^^schema:Person,
        "Estevam R. Hruschka Jr"^^schema:Person,
        "Flávio Amaro"^^schema:Person ;
    schema:dateModified "2019-10-02T02:38:33Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T02:38:33Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Ward2ICU: A Vital Signs Dataset of Inpatients from the General Ward"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00752v1"^^schema:URL .

<1464> a schema:ScholarlyArticle ;
    schema:abstract "Event Detection (ED) aims to recognize instances of specified types of eventtriggers in text. Different from English ED, Chinese ED suffers from theproblem of word-trigger mismatch due to the uncertain word boundaries. Existingapproaches injecting word information into character-level models have achievedpromising progress to alleviate this problem, but they are limited by twoissues. First, the interaction between characters and lexicon words is notfully exploited. Second, they ignore the semantic information provided by eventlabels. We thus propose a novel architecture named Label enhanced HeterogeneousGraph Attention Networks (L-HGAT). Specifically, we transform each sentenceinto a graph, where character nodes and word nodes are connected with differenttypes of edges, so that the interaction between words and characters is fullyreserved. A heterogeneous graph attention networks is then introduced topropagate relational message and enrich information interaction. Furthermore,we convert each label into a trigger-prototype-based embedding, and design amargin loss to guide the model distinguish confusing event labels. Experimentson two benchmark datasets show that our model achieves significant improvementover a range of competitive baseline methods."^^schema:Text ;
    schema:author "Bowen Yu"^^schema:Person,
        "Jinqiao Shi"^^schema:Person,
        "Quangang Li"^^schema:Person,
        "Shiyao Cui"^^schema:Person,
        "Tingwen Liu"^^schema:Person,
        "Xin Cong"^^schema:Person ;
    schema:dateModified "2020-12-03T12:49:22Z"^^schema:DateTime ;
    schema:datePublished "2020-12-03T12:49:22Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Label Enhanced Event Detection with Heterogeneous Graph Attention  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.01878v1"^^schema:URL .

<1465> a schema:ScholarlyArticle ;
    schema:abstract "Learning optimal policies from sparse feedback is a known challenge inreinforcement learning. Hindsight Experience Replay (HER) is a multi-goalreinforcement learning algorithm that comes to solve such tasks. The algorithmtreats every failure as a success for an alternative (virtual) goal that hasbeen achieved in the episode and then generalizes from that virtual goal toreal goals. HER has known flaws and is limited to relatively simple tasks. Inthis thesis, we present three algorithms based on the existing HER algorithmthat improves its performances. First, we prioritize virtual goals from whichthe agent will learn more valuable information. We call this property the\\textit{instructiveness} of the virtual goal and define it by a heuristicmeasure, which expresses how well the agent will be able to generalize fromthat virtual goal to actual goals. Secondly, we designed a filtering processthat detects and removes misleading samples that may induce bias throughout thelearning process. Lastly, we enable the learning of complex, sequential, tasksusing a form of curriculum learning combined with HER. We call this algorithm\\textit{Curriculum HER}. To test our algorithms, we built three challengingmanipulation environments with sparse reward functions. Each environment hasthree levels of complexity. Our empirical results show vast improvement in thefinal success rate and sample efficiency when compared to the original HERalgorithm."^^schema:Text ;
    schema:author "Binyamin Manela"^^schema:Person ;
    schema:dateModified "2020-01-12T07:22:15Z"^^schema:DateTime ;
    schema:datePublished "2020-01-12T07:22:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Complex Manipulation Tasks with Sparse  Feedback"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.03877v1"^^schema:URL .

<1466> a schema:ScholarlyArticle ;
    schema:abstract "The deployment of deep neural networks in real-world applications is mostlyrestricted by their high inference costs. Extensive efforts have been made toimprove the accuracy with expert-designed or algorithm-searched architectures.However, the incremental improvement is typically achieved with increasinglymore expensive models that only a small portion of input instances really need.Inference with a static architecture that processes all input instances via thesame transformation would thus incur unnecessary computational costs.Therefore, customizing the model capacity in an instance-aware manner is muchneeded for higher inference efficiency. In this paper, we propose DynamicRouting Networks (DRNets), which support efficient instance-aware inference byrouting the input instance to only necessary transformation branches selectedfrom a candidate set of branches for each connection between transformationnodes. The branch selection is dynamically determined via the correspondingbranch importance weights, which are first generated from lightweighthypernetworks (RouterNets) and then recalibrated with Gumbel-Softmax before theselection. Extensive experiments show that DRNets can reduce a substantialamount of parameter size and FLOPs during inference with prediction performancecomparable to state-of-the-art architectures."^^schema:Text ;
    schema:author "Beng Chin Ooi"^^schema:Person,
        "Shaofeng Cai"^^schema:Person,
        "Wei Wang"^^schema:Person,
        "Yao Shu"^^schema:Person ;
    schema:dateModified "2020-11-08T13:11:45Z"^^schema:DateTime ;
    schema:datePublished "2019-05-13T03:45:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dynamic Routing Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.04849v5"^^schema:URL .

<1467> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised domain adaptation of speech signal aims at adapting awell-trained source-domain acoustic model to the unlabeled data from targetdomain. This can be achieved by adversarial training of deep neural network(DNN) acoustic models to learn an intermediate deep representation that is bothsenone-discriminative and domain-invariant. Specifically, the DNN is trained tojointly optimize the primary task of senone classification and the secondarytask of domain classification with adversarial objective functions. In thiswork, instead of only focusing on learning a domain-invariant feature (i.e. theshared component between domains), we also characterize the difference betweenthe source and target domain distributions by explicitly modeling the privatecomponent of each domain through a private component extractor DNN. The privatecomponent is trained to be orthogonal with the shared component and thusimplicitly increases the degree of domain-invariance of the shared component. Areconstructor DNN is used to reconstruct the original speech feature from theprivate and shared components as a regularization. This domain separationframework is applied to the unsupervised environment adaptation task andachieved 11.08% relative WER reduction from the gradient reversal layertraining, a representative adversarial training method, for automatic speechrecognition on CHiME-3 dataset."^^schema:Text ;
    schema:author "Jinyu Li"^^schema:Person,
        "Vadim Mazalov"^^schema:Person,
        "Yifan Gong"^^schema:Person,
        "Zhong Meng"^^schema:Person,
        "Zhuo Chen"^^schema:Person ;
    schema:dateModified "2019-04-30T15:57:25Z"^^schema:DateTime ;
    schema:datePublished "2017-11-21T19:44:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Unsupervised Adaptation with Domain Separation Networks for Robust  Speech Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.08010v2"^^schema:URL .

<1468> a schema:ScholarlyArticle ;
    schema:abstract "Contrastive learning has recently shown immense potential in unsupervisedvisual representation learning. Existing studies in this track mainly focus onintra-image invariance learning. The learning typically uses rich intra-imagetransformations to construct positive pairs and then maximizes agreement usinga contrastive loss. The merits of inter-image invariance, conversely, remainmuch less explored. One major obstacle to exploit inter-image invariance isthat it is unclear how to reliably construct inter-image positive pairs, andfurther derive effective supervision from them since there are no pairannotations available. In this work, we present a rigorous and comprehensivestudy on inter-image invariance learning from three main constitutingcomponents: pseudo-label maintenance, sampling strategy, and decision boundarydesign. Through carefully-designed comparisons and analysis, we propose aunified framework that supports the integration of unsupervised intra- andinter-image invariance learning. With all the obtained recipes, our finalmodel, namely InterCLR, achieves state-of-the-art performance on standardbenchmarks. Code and models will be available athttps://github.com/open-mmlab/OpenSelfSup."^^schema:Text ;
    schema:author "Chen Change Loy"^^schema:Person,
        "Jiahao Xie"^^schema:Person,
        "Xiaohang Zhan"^^schema:Person,
        "Yew Soon Ong"^^schema:Person,
        "Ziwei Liu"^^schema:Person ;
    schema:dateModified "2020-08-26T17:44:23Z"^^schema:DateTime ;
    schema:datePublished "2020-08-26T17:44:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Delving into Inter-Image Invariance for Unsupervised Visual  Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.11702v1"^^schema:URL .

<1469> a schema:ScholarlyArticle ;
    schema:abstract "Deep networks for stereo matching typically leverage 2D or 3D convolutionalencoder-decoder architectures to aggregate cost and regularize the cost volumefor accurate disparity estimation. Due to content-insensitive convolutions anddown-sampling and up-sampling operations, these cost aggregation mechanisms donot take full advantage of the information available in the images. Disparitymaps suffer from over-smoothing near occlusion boundaries, and erroneouspredictions in thin structures. In this paper, we show how deep adaptivefiltering and differentiable semi-global aggregation can be integrated inexisting 2D and 3D convolutional networks for end-to-end stereo matching,leading to improved accuracy. The improvements are due to utilizing RGBinformation from the images as a signal to dynamically guide the matchingprocess, in addition to being the signal we attempt to match across the images.We show extensive experimental results on the KITTI 2015 and Virtual KITTI 2datasets comparing four stereo networks (DispNetC, GCNet, PSMNet and GANet)after integrating four adaptive filters (segmentation-aware bilateralfiltering, dynamic filtering networks, pixel adaptive convolution andsemi-global aggregation) into their architectures. Our code is available athttps://github.com/ccj5351/DAFStereoNets."^^schema:Text ;
    schema:author "Changjiang Cai"^^schema:Person,
        "Philippos Mordohai"^^schema:Person ;
    schema:dateModified "2020-10-14T18:32:39Z"^^schema:DateTime ;
    schema:datePublished "2020-10-14T18:32:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Do End-to-end Stereo Algorithms Under-utilize Information?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07350v1"^^schema:URL .

<147> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a novel scheme to train binary convolutional neural networks(CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time.It has been known that using binary weights and activations drastically reducememory size and accesses, and can replace arithmetic operations with moreefficient bitwise operations, leading to much faster test-time inference andlower power consumption. However, previous works on binarizing CNNs usuallyresult in severe prediction accuracy degradation. In this paper, we addressthis issue with two major innovations: (1) approximating full-precision weightswith the linear combination of multiple binary weight bases; (2) employingmultiple binary activations to alleviate information loss. The implementationof the resulting binary CNN, denoted as ABC-Net, is shown to achieve muchcloser performance to its full-precision counterpart, and even reach thecomparable prediction accuracy on ImageNet and forest trail datasets, givenadequate binary weight bases and activations."^^schema:Text ;
    schema:author "Cong Zhao"^^schema:Person,
        "Wei Pan"^^schema:Person,
        "Xiaofan Lin"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2017-11-30T09:58:14Z"^^schema:DateTime ;
    schema:datePublished "2017-11-30T09:58:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Accurate Binary Convolutional Neural Network"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.11294v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9345699458847974423&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1470> a schema:ScholarlyArticle ;
    schema:abstract "Sentences are important semantic units of natural language. A generic,distributional representation of sentences that can capture the latentsemantics is beneficial to multiple downstream applications. We observe asimple geometry of sentences -- the word representations of a given sentence(on average 10.23 words in all SemEval datasets with a standard deviation 4.84)roughly lie in a low-rank subspace (roughly, rank 4). Motivated by thisobservation, we represent a sentence by the low-rank subspace spanned by itsword vectors. Such an unsupervised representation is empirically validated viasemantic textual similarity tasks on 19 different datasets, where itoutperforms the sophisticated neural network models, including skip-thoughtvectors, by 15% on average."^^schema:Text ;
    schema:author "Jiaqi Mu"^^schema:Person,
        "Pramod Viswanath"^^schema:Person,
        "Suma Bhat"^^schema:Person ;
    schema:dateModified "2017-04-18T14:30:32Z"^^schema:DateTime ;
    schema:datePublished "2017-04-18T14:30:32Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Representing Sentences as Low-Rank Subspaces"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1704.05358v1"^^schema:URL .

<1471> a schema:ScholarlyArticle ;
    schema:abstract "In the era of big data, the need to expand the amount of data through datasharing to improve model performance has become increasingly compelling. As aresult, effective collaborative learning models need to be developed withrespect to both privacy and utility concerns. In this work, we propose a newfederated multi-task learning method for effective parameter transfer withdifferential privacy to protect gradients at the client level. Specifically,the lower layers of the networks are shared across all clients to capturetransferable feature representation, while top layers of the network aretask-specific for on-client personalization. Our proposed algorithm naturallyresolves the statistical heterogeneity problem in federated networks. We are,to the best of knowledge, the first to provide both privacy and utilityguarantees for such a proposed federated algorithm. The convergences are provedfor the cases with Lipschitz smooth objective functions under the non-convex,convex, and strongly convex settings. Empirical experiment results on differentdatasets have been conducted to demonstrate the effectiveness of the proposedalgorithm and verify the implications of the theoretical findings."^^schema:Text ;
    schema:author "Cen Chen"^^schema:Person,
        "Huiwen Wu"^^schema:Person,
        "Li Wang"^^schema:Person ;
    schema:dateModified "2020-11-14T00:53:16Z"^^schema:DateTime ;
    schema:datePublished "2020-11-14T00:53:16Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Theoretical Perspective on Differentially Private Federated Multi-task  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.07179v1"^^schema:URL .

<1472> a schema:ScholarlyArticle ;
    schema:abstract "The problem of phase retrieval has been intriguing researchers for decadesdue to its appearance in a wide range of applications. The task of a phaseretrieval algorithm is typically to recover a signal from linear phase-lessmeasurements. In this paper, we approach the problem by proposing a hybridmodel-based data-driven deep architecture, referred to as the Unfolded PhaseRetrieval (UPR), that shows potential in improving the performance of thestate-of-the-art phase retrieval algorithms. Specifically, the proposed methodbenefits from versatility and interpretability of well established model-basedalgorithms, while simultaneously benefiting from the expressive power of deepneural networks. Our numerical results illustrate the effectiveness of suchhybrid deep architectures and showcase the untapped potential of data-aidedmethodologies to enhance the existing phase retrieval algorithms."^^schema:Text ;
    schema:author "Mojtaba Soltanalian"^^schema:Person,
        "Naveed Naimipour"^^schema:Person,
        "Shahin Khobahi"^^schema:Person ;
    schema:dateModified "2020-03-09T20:22:40Z"^^schema:DateTime ;
    schema:datePublished "2020-03-09T20:22:40Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "UPR: A Model-Driven Architecture for Deep Phase Retrieval"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.04396v1"^^schema:URL .

<1473> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (UNMT) has recently achievedremarkable results with only large monolingual corpora in each language.However, the uncertainty of associating target with source sentences makes UNMTtheoretically an ill-posed problem. This work investigates the possibility ofutilizing images for disambiguation to improve the performance of UNMT. Ourassumption is intuitively based on the invariant property of image, i.e., thedescription of the same visual content by different languages should beapproximately similar. We propose an unsupervised multi-modal machinetranslation (UMNMT) framework based on the language translation cycleconsistency loss conditional on the image, targeting to learn the bidirectionalmulti-modal translation simultaneously. Through an alternate training betweenmulti-modal and uni-modal, our inference model can translate with or withoutthe image. On the widely used Multi30K dataset, the experimental results of ourapproach are significantly better than those of the text-only UNMT on the 2016test dataset."^^schema:Text ;
    schema:author "C. -C. Jay Kuo"^^schema:Person,
        "Fei Huang"^^schema:Person,
        "Kai Fan"^^schema:Person,
        "Nguyen Bach"^^schema:Person,
        "Yuanhang Su"^^schema:Person ;
    schema:dateModified "2019-05-27T02:00:51Z"^^schema:DateTime ;
    schema:datePublished "2018-11-28T02:48:25Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Multi-modal Neural Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.11365v2"^^schema:URL .

<1474> a schema:ScholarlyArticle ;
    schema:abstract "The formation of stars in massive clusters is one of the main modes of thestar formation process. However, the study of massive star forming regions ishampered by their typically large distances to the Sun. One exception to thisis the massive star forming region Cygnus OB2 in the Cygnus X region, at thedistance of about 1400 pc. Cygnus OB2 hosts very rich populations of massiveand low-mass stars, being the best target in our Galaxy to study the formationof stars, circumstellar disks, and planets in presence of massive stars. Inthis paper we combine a wide and deep set of photometric data, from the r bandto 24 micron, in order to select the disk bearing population of stars in CygnusOB2 and identify the class I, class II, and stars with transition andpre-transition disks. We selected 1843 sources with infrared excesses in anarea of 1 degree x 1 degree centered on Cyg OB2 in several evolutionary stages:8.4% class I, 13.1% flat-spectrum sources, 72.9% class II, 2.3% pre-transitiondisks, and 3.3% transition disks. The spatial distribution of these sourcesshows a central cluster surrounded by a annular overdensity and some clumps ofrecent star formation in the outer region. Several candidate subclusters areidentified, both along the overdensity and in the rest of the association."^^schema:Text ;
    schema:author "A. Fruscione"^^schema:Person,
        "D. Garcia-Alvarez"^^schema:Person,
        "J. E. Drew"^^schema:Person,
        "J. J. Drake"^^schema:Person,
        "J. L. Hora"^^schema:Person,
        "M. G. Guarcello"^^schema:Person,
        "N. J. Wright"^^schema:Person,
        "R. A. Gutermuth"^^schema:Person,
        "R. King"^^schema:Person,
        "T. Aldcroft"^^schema:Person,
        "T. Naylor"^^schema:Person,
        "V. L. Kashyap"^^schema:Person ;
    schema:dateModified "2013-06-24T20:00:17Z"^^schema:DateTime ;
    schema:datePublished "2013-06-24T20:00:17Z"^^schema:DateTime ;
    schema:genre "astro-ph.SR"^^schema:Text ;
    schema:headline "The protoplanetary disks in the nearby massive star forming region  Cygnus OB2"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1306.5757v1"^^schema:URL .

<1475> a schema:ScholarlyArticle ;
    schema:abstract "Action planning using learned and differentiable forward models of the worldis a general approach which has a number of desirable properties, includingimproved sample complexity over model-free RL methods, reuse of learned modelsacross different tasks, and the ability to perform efficient gradient-basedoptimization in continuous action spaces. However, this approach does not applystraightforwardly when the action space is discrete. In this work, we show thatit is in fact possible to effectively perform planning via backprop in discreteaction spaces, using a simple paramaterization of the actions vectors on thesimplex combined with input noise when training the forward model. Ourexperiments show that this approach can match or outperform model-free RL anddiscrete planning methods on gridworld navigation tasks in terms of performanceand/or planning time while using limited environment interactions, and canadditionally be used to perform model-based control in a challenging new taskwhere the action space combines discrete and continuous actions. We furthermorepropose a policy distillation approach which yields a fast policy network whichcan be used at inference time, removing the need for an iterative planningprocedure."^^schema:Text ;
    schema:author "Mikael Henaff"^^schema:Person,
        "William F. Whitney"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:dateModified "2018-04-04T06:34:26Z"^^schema:DateTime ;
    schema:datePublished "2017-05-19T20:38:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Model-Based Planning with Discrete and Continuous Actions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.07177v2"^^schema:URL .

<1476> a schema:ScholarlyArticle ;
    schema:abstract "Efficient and accurate object detection in video and image analysis is one ofthe major beneficiaries of the advancement in computer vision systems with thehelp of deep learning. With the aid of deep learning, more powerful toolsevolved, which are capable to learn high-level and deeper features and thus canovercome the existing problems in traditional architectures of object detectionalgorithms. The work in this thesis aims to achieve high accuracy in objectdetection with good real-time performance.  In the area of computer vision, a lot of research is going into the area ofdetection and processing of visual information, by improving the existingalgorithms. The binarized neural network has shown high performance in variousvision tasks such as image classification, object detection, and semanticsegmentation. The Modified National Institute of Standards and Technologydatabase (MNIST), Canadian Institute for Advanced Research (CIFAR), and StreetView House Numbers (SVHN) datasets are used which is implemented using apre-trained convolutional neural network (CNN) that is 22 layers deep.Supervised learning is used in the work, which classifies the particulardataset with the proper structure of the model. In still images, to improveaccuracy, Googlenet is used. The final layer of the Googlenet is replaced withthe transfer learning to improve the accuracy of the Googlenet. At the sametime, the accuracy in moving images can be maintained by transfer learningtechniques. Hardware is the main backbone for any model to obtain fasterresults with a large number of datasets. Here, Nvidia Jetson Nano is used whichis a graphics processing unit (GPU), that can handle a large number ofcomputations in the process of object detection. Results show that the accuracyof objects detected by the transfer learning method is more when compared tothe existing methods."^^schema:Text ;
    schema:author "Karthik E"^^schema:Person ;
    schema:dateModified "2021-01-05T07:28:38Z"^^schema:DateTime ;
    schema:datePublished "2021-01-04T06:16:52Z"^^schema:DateTime ;
    schema:genre "F.2.2"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.AR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Framework for Fast Scalable BNN Inference using Googlenet and Transfer  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.00793v2"^^schema:URL .

<1477> a schema:ScholarlyArticle ;
    schema:abstract "Very deep CNNs achieve state-of-the-art results in both computer vision andspeech recognition, but are difficult to train. The most popular way to trainvery deep CNNs is to use shortcut connections (SC) together with batchnormalization (BN). Inspired by Self- Normalizing Neural Networks, we proposethe self-normalizing deep CNN (SNDCNN) based acoustic model topology, byremoving the SC/BN and replacing the typical RELU activations with scaledexponential linear unit (SELU) in ResNet-50. SELU activations make the networkself-normalizing and remove the need for both shortcut connections and batchnormalization. Compared to ResNet- 50, we can achieve the same or lower (up to4.5% relative) word error rate (WER) while boosting both training and inferencespeed by 60%-80%. We also explore other model inference optimization schemes tofurther reduce latency for production use."^^schema:Text ;
    schema:author "Daben Liu"^^schema:Person,
        "Henry Mason"^^schema:Person,
        "Leo Liu"^^schema:Person,
        "Tim Ng"^^schema:Person,
        "Xiaodan Zhuang"^^schema:Person,
        "Zhen Huang"^^schema:Person ;
    schema:dateModified "2020-03-23T20:39:17Z"^^schema:DateTime ;
    schema:datePublished "2019-10-04T15:31:48Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "SNDCNN: Self-normalizing deep CNNs with scaled exponential linear units  for speech recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.01992v3"^^schema:URL .

<1478> a schema:ScholarlyArticle ;
    schema:abstract "Designing missiles' autopilot controllers has been a complex task, given theextensive flight envelope and the nonlinear flight dynamics. A solution thatcan excel both in nominal performance and in robustness to uncertainties isstill to be found. While Control Theory often debouches into parameters'scheduling procedures, Reinforcement Learning has presented interesting resultsin ever more complex tasks, going from videogames to robotic tasks withcontinuous action domains. However, it still lacks clearer insights on how tofind adequate reward functions and exploration strategies. To the best of ourknowledge, this work is pioneer in proposing Reinforcement Learning as aframework for flight control. In fact, it aims at training a model-free agentthat can control the longitudinal flight of a missile, achieving optimalperformance and robustness to uncertainties. To that end, under TRPO'smethodology, the collected experience is augmented according to HER, stored ina replay buffer and sampled according to its significance. Not only does thiswork enhance the concept of prioritized experience replay into BPER, but italso reformulates HER, activating them both only when the training progressconverges to suboptimal policies, in what is proposed as the SER methodology.Besides, the Reward Engineering process is carefully detailed. The results showthat it is possible both to achieve the optimal performance and to improve theagent's robustness to uncertainties (with low damage on nominal performance) byfurther training it in non-nominal environments, therefore validating theproposed approach and encouraging future research in this field."^^schema:Text ;
    schema:author "Bernardo Cortez"^^schema:Person ;
    schema:dateModified "2020-11-26T09:30:04Z"^^schema:DateTime ;
    schema:datePublished "2020-11-26T09:30:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Reinforcement Learning for Robust Missile Autopilot Design"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12956v1"^^schema:URL .

<1479> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) have been very successful at solving avariety of computer vision tasks such as object classification and detection,semantic segmentation, activity understanding, to name just a few. One keyenabling factor for their great performance has been the ability to train verydeep networks. Despite their huge success in many tasks, CNNs do not work wellwith non-Euclidean data, which is prevalent in many real-world applications.Graph Convolutional Networks (GCNs) offer an alternative that allows fornon-Eucledian data input to a neural network. While GCNs already achieveencouraging results, they are currently limited to architectures with arelatively small number of layers, primarily due to vanishing gradients duringtraining. This work transfers concepts such as residual/dense connections anddilated convolutions from CNNs to GCNs in order to successfully train very deepGCNs. We show the benefit of using deep GCNs (with as many as $112$ layers)experimentally across various datasets and tasks. Specifically, we achievestate-of-the-art performance in part segmentation and semantic segmentation onpoint clouds and in node classification of protein functions across biologicalprotein-protein interaction (PPI) graphs. We believe that the insights in thiswork will open avenues for future research on GCNs and their application tofurther tasks not explored in this paper. The source code for this work isavailable at https://github.com/lightaime/deep_gcns_torch andhttps://github.com/lightaime/deep_gcns for Pytorch and Tensorflowimplementation respectively."^^schema:Text ;
    schema:author "Abdulellah Abualshour"^^schema:Person,
        "Ali Thabet"^^schema:Person,
        "Bernard Ghanem"^^schema:Person,
        "Guocheng Qian"^^schema:Person,
        "Guohao Li"^^schema:Person,
        "Itzel C. Delgadillo"^^schema:Person,
        "Matthias Müller"^^schema:Person ;
    schema:dateModified "2020-06-14T19:38:05Z"^^schema:DateTime ;
    schema:datePublished "2019-10-15T15:10:34Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "DeepGCNs: Making GCNs Go as Deep as CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.06849v2"^^schema:URL .

<148> a schema:ScholarlyArticle ;
    schema:abstract "Recent deep networks are capable of memorizing the entire data even when thelabels are completely random. To overcome the overfitting on corrupted labels,we propose a novel technique of learning another neural network, calledMentorNet, to supervise the training of the base deep networks, namely,StudentNet. During training, MentorNet provides a curriculum (sample weightingscheme) for StudentNet to focus on the sample the label of which is probablycorrect. Unlike the existing curriculum that is usually predefined by humanexperts, MentorNet learns a data-driven curriculum dynamically with StudentNet.Experimental results demonstrate that our approach can significantly improvethe generalization performance of deep networks trained on corrupted trainingdata. Notably, to the best of our knowledge, we achieve the best-publishedresult on WebVision, a large benchmark containing 2.2 million images ofreal-world noisy labels. The code are at https://github.com/google/mentornet"^^schema:Text ;
    schema:author "Li Fei-Fei"^^schema:Person,
        "Li-Jia Li"^^schema:Person,
        "Lu Jiang"^^schema:Person,
        "Thomas Leung"^^schema:Person,
        "Zhengyuan Zhou"^^schema:Person ;
    schema:commentCount "240"^^schema:Integer ;
    schema:dateModified "2018-08-13T21:27:39Z"^^schema:DateTime ;
    schema:datePublished "2017-12-14T00:02:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks  on Corrupted Labels"^^schema:Text ;
    schema:publisher "ICML, 2309-2318"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.05055v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15068880048981139697&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1480> a schema:ScholarlyArticle ;
    schema:abstract "Exploration efficiency is a challenging problem in multi-agent reinforcementlearning (MARL), as the policy learned by confederate MARL depends on thecollaborative approach among multiple agents. Another important problem is theless informative reward restricts the learning speed of MARL compared with theinformative label in supervised learning. In this work, we leverage on a novelcommunication method to guide MARL to accelerate exploration and propose apredictive network to forecast the reward of current state-action pair and usethe guidance learned by the predictive network to modify the reward function.An improved prioritized experience replay is employed to better take advantageof the different knowledge learned by different agents which utilizesTime-difference (TD) error more effectively. Experimental results demonstratesthat the proposed algorithm outperforms existing methods in cooperativemulti-agent environments. We remark that this algorithm can be extended tosupervised learning to speed up its training."^^schema:Text ;
    schema:author "Qichao Wang"^^schema:Person,
        "Qisheng Wang"^^schema:Person ;
    schema:dateModified "2019-12-25T07:05:14Z"^^schema:DateTime ;
    schema:datePublished "2019-07-18T02:27:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Prioritized Guidance for Efficient Multi-Agent Reinforcement Learning  Exploration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.07847v3"^^schema:URL .

<1481> a schema:ScholarlyArticle ;
    schema:abstract "We present a multi-agent actor-critic method that aims to implicitly addressthe credit assignment problem under fully cooperative settings. Our keymotivation is that credit assignment among agents may not require an explicitformulation as long as (1) the policy gradients derived from a centralizedcritic carry sufficient information for the decentralized agents to maximizetheir joint action value through optimal cooperation and (2) a sustained levelof exploration is enforced throughout training. Under the centralized trainingwith decentralized execution (CTDE) paradigm, we achieve the former byformulating the centralized critic as a hypernetwork such that a latent staterepresentation is integrated into the policy gradients through itsmultiplicative association with the stochastic policies; to achieve the latter,we derive a simple technique called adaptive entropy regularization wheremagnitudes of the entropy gradients are dynamically rescaled based on thecurrent policy stochasticity to encourage consistent levels of exploration. Ouralgorithm, referred to as LICA, is evaluated on several benchmarks includingthe multi-agent particle environments and a set of challenging StarCraft IImicromanagement tasks, and we show that LICA significantly outperforms previousmethods."^^schema:Text ;
    schema:author "Meng Zhou"^^schema:Person,
        "Pengwei Sui"^^schema:Person,
        "Yixuan Li"^^schema:Person,
        "Yuk Ying Chung"^^schema:Person,
        "Ziyu Liu"^^schema:Person ;
    schema:dateModified "2020-10-22T14:18:50Z"^^schema:DateTime ;
    schema:datePublished "2020-07-06T05:25:02Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Implicit Credit Assignment for Cooperative Multi-Agent  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02529v2"^^schema:URL .

<1482> a schema:ScholarlyArticle ;
    schema:abstract "We present a method to train self-binarizing neural networks, that is,networks that evolve their weights and activations during training to becomebinary. To obtain similar binary networks, existing methods rely on the signactivation function. This function, however, has no gradients for non-zerovalues, which makes standard backpropagation impossible. To circumvent thedifficulty of training a network relying on the sign activation function, thesemethods alternate between floating-point and binary representations of thenetwork during training, which is sub-optimal and inefficient. We approach thebinarization task by training on a unique representation involving a smoothactivation function, which is iteratively sharpened during training until itbecomes a binary representation equivalent to the sign activation function.Additionally, we introduce a new technique to perform binary batchnormalization that simplifies the conventional batch normalization bytransforming it into a simple comparison operation. This is unlike existingmethods, which are forced to the retain the conventional floating-point-basedbatch normalization. Our binary networks, apart from displaying advantages oflower memory and computation as compared to conventional floating-point andbinary networks, also show higher classification accuracy than existingstate-of-the-art methods on multiple benchmark datasets."^^schema:Text ;
    schema:author "Fayez Lahoud"^^schema:Person,
        "Pablo Márquez-Neila"^^schema:Person,
        "Radhakrishna Achanta"^^schema:Person,
        "Sabine Süsstrunk"^^schema:Person ;
    schema:dateModified "2019-02-02T14:48:16Z"^^schema:DateTime ;
    schema:datePublished "2019-02-02T14:48:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Self-Binarizing Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.00730v1"^^schema:URL .

<1483> a schema:ScholarlyArticle ;
    schema:abstract "Diagnosis and treatment of multiple pulmonary nodules are clinicallyimportant but challenging. Prior studies on nodule characterization usesolitary-nodule approaches on multiple nodular patients, which ignores therelations between nodules. In this study, we propose a multiple instancelearning (MIL) approach and empirically prove the benefit to learn therelations between multiple nodules. By treating the multiple nodules from asame patient as a whole, critical relational information betweensolitary-nodule voxels is extracted. To our knowledge, it is the first study tolearn the relations between multiple pulmonary nodules. Inspired by recentadvances in natural language processing (NLP) domain, we introduce aself-attention transformer equipped with 3D CNN, named {NoduleSAT}, to replacetypical pooling-based aggregation in multiple instance learning. Extensiveexperiments on lung nodule false positive reduction on LUNA16 database, andmalignancy classification on LIDC-IDRI database, validate the effectiveness ofthe proposed method."^^schema:Text ;
    schema:author "Bingbing Ni"^^schema:Person,
        "Haoran Deng"^^schema:Person,
        "Jiancheng Yang"^^schema:Person,
        "Xiaoyang Huang"^^schema:Person,
        "Yi Xu"^^schema:Person ;
    schema:dateModified "2020-04-12T16:05:08Z"^^schema:DateTime ;
    schema:datePublished "2020-04-12T16:05:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Relational Learning between Multiple Pulmonary Nodules via Deep Set  Attention Transformers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.05640v1"^^schema:URL .

<1484> a schema:ScholarlyArticle ;
    schema:abstract "In neuroimaging studies, the human cortex is commonly modeled as a sphere topreserve the topological structure of the cortical surface. Corticalneuroimaging measures hence can be modeled in spherical representation. In thiswork, we explore analyzing the human cortex using spherical CNNs in anAlzheimer's disease (AD) classification task using cortical morphometricmeasures derived from structural MRI. Our results show superior performance inclassifying AD versus cognitively normal and in predicting MCI progressionwithin two years, using structural MRI information only. This work demonstratesfor the first time the potential of the spherical CNNs framework in thediscriminative analysis of the human cortex and could be extended to othermodalities and other neurological diseases."^^schema:Text ;
    schema:author "Andrew F. Laine"^^schema:Person,
        "Elsa D. Angelini"^^schema:Person,
        "Jie Yang"^^schema:Person,
        "Xinyang Feng"^^schema:Person ;
    schema:dateModified "2018-12-19T04:16:18Z"^^schema:DateTime ;
    schema:datePublished "2018-12-19T04:16:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Discriminative analysis of the human cortex using spherical CNNs - a  study on Alzheimer's disease diagnosis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.07749v1"^^schema:URL .

<1485> a schema:ScholarlyArticle ;
    schema:abstract "Generation of stroke-based non-photorealistic imagery, is an importantproblem in the computer vision community. As an endeavor in this direction,substantial recent research efforts have been focused on teaching machines \"howto paint\", in a manner similar to a human painter. However, the applicabilityof previous methods has been limited to datasets with little variation inposition, scale and saliency of the foreground object. As a consequence, wefind that these methods struggle to cover the granularity and diversitypossessed by real world images. To this end, we propose a Semantic Guidancepipeline with 1) a bi-level painting procedure for learning the distinctionbetween foreground and background brush strokes at training time. 2) We alsointroduce invariance to the position and scale of the foreground object througha neural alignment model, which combines object localization and spatialtransformer networks in an end to end manner, to zoom into a particularsemantic instance. 3) The distinguishing features of the in-focus object arethen amplified by maximizing a novel guided backpropagation based focus reward.The proposed agent does not require any supervision on human stroke-data andsuccessfully handles variations in foreground object attributes, thus,producing much higher quality canvases for the CUB-200 Birds and StanfordCars-196 datasets. Finally, we demonstrate the further efficacy of our methodon complex datasets with multiple foreground object instances by evaluating anextension of our method on the challenging Virtual-KITTI dataset."^^schema:Text ;
    schema:author "Jaskirat Singh"^^schema:Person,
        "Liang Zheng"^^schema:Person ;
    schema:dateModified "2020-11-25T09:00:04Z"^^schema:DateTime ;
    schema:datePublished "2020-11-25T09:00:04Z"^^schema:DateTime ;
    schema:genre "cs.CG"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Combining Semantic Guidance and Deep Reinforcement Learning For  Generating Human Level Paintings"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12589v1"^^schema:URL .

<1486> a schema:ScholarlyArticle ;
    schema:abstract "Platelet products are both expensive and have very short shelf lives. Asusage rates for platelets are highly variable, the effective management ofplatelet demand and supply is very important yet challenging. The primary goalof this paper is to present an efficient forecasting model for platelet demandat Canadian Blood Services (CBS). To accomplish this goal, four differentdemand forecasting methods, ARIMA (Auto Regressive Moving Average), Prophet,lasso regression (least absolute shrinkage and selection operator) and LSTM(Long Short-Term Memory) networks are utilized and evaluated. We use a largeclinical dataset for a centralized blood distribution centre for four hospitalsin Hamilton, Ontario, spanning from 2010 to 2018 and consisting of dailyplatelet transfusions along with information such as the productspecifications, the recipients' characteristics, and the recipients' laboratorytest results. This study is the first to utilize different methods fromstatistical time series models to data-driven regression and a machine learningtechnique for platelet transfusion using clinical predictors and with differentamounts of data. We find that the multivariate approaches have the highestaccuracy in general, however, if sufficient data are available, a simpler timeseries approach such as ARIMA appears to be sufficient. We also comment on theapproach to choose clinical indicators (inputs) for the multivariate models."^^schema:Text ;
    schema:author "Douglas G. Down"^^schema:Person,
        "Maryam Motamedi"^^schema:Person,
        "Na Li"^^schema:Person,
        "Nancy M. Heddle"^^schema:Person ;
    schema:dateModified "2021-01-06T23:54:10Z"^^schema:DateTime ;
    schema:datePublished "2021-01-06T23:54:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.AP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Demand Forecasting for Platelet Usage: from Univariate Time Series to  Multivariate Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.02305v1"^^schema:URL .

<1487> a schema:ScholarlyArticle ;
    schema:abstract "Due to the widespread use of positron emission tomography (PET) in clinicalpractice, the potential risk of PET-associated radiation dose to patients needsto be minimized. However, with the reduction in the radiation dose, theresultant images may suffer from noise and artifacts that compromise diagnosticperformance. In this paper, we propose a parameter-transferred Wassersteingenerative adversarial network (PT-WGAN) for low-dose PET image denoising. Thecontributions of this paper are twofold: i) a PT-WGAN framework is designed todenoise low-dose PET images without compromising structural details, and ii) atask-specific initialization based on transfer learning is developed to trainPT-WGAN using trainable parameters transferred from a pretrained model, whichsignificantly improves the training efficiency of PT-WGAN. The experimentalresults on clinical data show that the proposed network can suppress imagenoise more effectively while preserving better image fidelity than recentlypublished state-of-the-art methods. We make our code available athttps://github.com/90n9-yu/PT-WGAN."^^schema:Text ;
    schema:author "Ge Wang"^^schema:Person,
        "Guodong Liang"^^schema:Person,
        "Hongming Shan"^^schema:Person,
        "Ming Li"^^schema:Person,
        "Ning Tu"^^schema:Person,
        "Shanshan Wang"^^schema:Person,
        "Yu Gong"^^schema:Person,
        "Yueyang Teng"^^schema:Person ;
    schema:dateModified "2020-08-26T06:09:12Z"^^schema:DateTime ;
    schema:datePublished "2019-10-13T02:41:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Parameter-Transferred Wasserstein Generative Adversarial Network  (PT-WGAN) for Low-Dose PET Image Denoising"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.06749v3"^^schema:URL .

<1488> a schema:ScholarlyArticle ;
    schema:abstract "Gait is a unique biometric feature that can be recognized at a distance;thus, it has broad applications in crime prevention, forensic identification,and social security. To portray a gait, existing gait recognition methodsutilize either a gait template which makes it difficult to preserve temporalinformation, or a gait sequence that maintains unnecessary sequentialconstraints and thus loses the flexibility of gait recognition. In this paper,we present a novel perspective that utilizes gait as a deep set, which meansthat a set of gait frames are integrated by a global-local fused deep networkinspired by the way our left- and right-hemisphere processes information tolearn information that can be used in identification. Based on this deep setperspective, our method is immune to frame permutations, and can naturallyintegrate frames from different videos that have been acquired under differentscenarios, such as diverse viewing angles, different clothes, or differentitem-carrying conditions. Experiments show that under normal walkingconditions, our single-model method achieves an average rank-1 accuracy of96.1% on the CASIA-B gait dataset and an accuracy of 87.9% on the OU-MVLP gaitdataset. Under various complex scenarios, our model also exhibits a high levelof robustness. It achieves accuracies of 90.8% and 70.3% on CASIA-B underbag-carrying and coat-wearing walking conditions respectively, significantlyoutperforming the best existing methods. Moreover, the proposed methodmaintains a satisfactory accuracy even when only small numbers of frames areavailable in the test samples; for example, it achieves 85.0% on CASIA-B evenwhen using only 7 frames. The source code has been released athttps://github.com/AbnerHqC/GaitSet."^^schema:Text ;
    schema:author "Hanqing Chao"^^schema:Person,
        "Jianfeng Feng"^^schema:Person,
        "Junping Zhang"^^schema:Person,
        "Kun Wang"^^schema:Person,
        "Yiwei He"^^schema:Person ;
    schema:dateModified "2021-02-05T15:49:54Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T15:49:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "GaitSet: Cross-view Gait Recognition through Utilizing Gait as a Deep  Set"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03247v1"^^schema:URL .

<1489> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (UNMT) requires only monolingual dataof similar language pairs during training and can produce bi-directionaltranslation models with relatively good performance on alphabetic languages(Lample et al., 2018). However, no research has been done to logographiclanguage pairs. This study focuses on Chinese-Japanese UNMT trained by datacontaining sub-character (ideograph or stroke) level information which isdecomposed from character level data. BLEU scores of both character andsub-character level systems were compared against each other and the resultsshowed that despite the effectiveness of UNMT on character level data,sub-character level data could further enhance the performance, in which thestroke level system outperformed the ideograph level system."^^schema:Text ;
    schema:author "Longtu Zhang"^^schema:Person,
        "Mamoru Komachi"^^schema:Person ;
    schema:dateModified "2019-03-01T03:57:15Z"^^schema:DateTime ;
    schema:datePublished "2019-03-01T03:57:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Chinese-Japanese Unsupervised Neural Machine Translation Using  Sub-character Level Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.00149v1"^^schema:URL .

<149> a schema:ScholarlyArticle ;
    schema:abstract "Recent work on generative modeling of text has found that variationalauto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTMlanguage models (Bowman et al., 2015). This negative result is so far poorlyunderstood, but has been attributed to the propensity of LSTM decoders toignore conditioning information from the encoder. In this paper, we experimentwith a new type of decoder for VAE: a dilated CNN. By changing the decoder'sdilation architecture, we control the effective context from previouslygenerated words. In experiments, we find that there is a trade off between thecontextual capacity of the decoder and the amount of encoding information used.We show that with the right decoder, VAE can outperform LSTM language models.We demonstrate perplexity gains on two datasets, representing the firstpositive experimental result on the use VAE for generative modeling of text.Further, we conduct an in-depth investigation of the use of VAE (with our newdecoding architecture) for semi-supervised and unsupervised labeling tasks,demonstrating gains over several strong baselines."^^schema:Text ;
    schema:author "Ruslan Salakhutdinov"^^schema:Person,
        "Taylor Berg-Kirkpatrick"^^schema:Person,
        "Zhiting Hu"^^schema:Person,
        "Zichao Yang"^^schema:Person ;
    schema:commentCount "189"^^schema:Integer ;
    schema:dateModified "2017-06-18T00:31:34Z"^^schema:DateTime ;
    schema:datePublished "2017-02-27T04:16:01Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Improved Variational Autoencoders for Text Modeling using Dilated  Convolutions"^^schema:Text ;
    schema:publisher "ICML, 3881-3890"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.08139v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=123823476347966018&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1490> a schema:ScholarlyArticle ;
    schema:abstract "Neural differential equations are a promising new member in the neuralnetwork family. They show the potential of differential equations for timeseries data analysis. In this paper, the strength of the ordinary differentialequation (ODE) is explored with a new extension. The main goal of this work isto answer the following questions: (i)~can ODE be used to redefine the existingneural network model? (ii)~can Neural ODEs solve the irregular sampling ratechallenge of existing neural network models for a continuous time series, i.e.,length and dynamic nature, (iii)~how to reduce the training and evaluation timeof existing Neural ODE systems? This work leverages the mathematical foundationof ODEs to redesign traditional RNNs such as Long Short-Term Memory (LSTM) andGated Recurrent Unit (GRU). The main contribution of this paper is toillustrate the design of two new ODE-based RNN models (GRU-ODE model andLSTM-ODE) which can compute the hidden state and cell state at any point oftime using an ODE solver. These models reduce the computation overhead ofhidden state and cell state by a vast amount. The performance evaluation ofthese two new models for learning continuous time series with irregularsampling rate is then demonstrated. Experiments show that these new ODE basedRNN models require less training time than Latent ODEs and conventional NeuralODEs. They can achieve higher accuracy quickly, and the design of the neuralnetwork is simpler than, previous neural ODE systems."^^schema:Text ;
    schema:author "Barak A. Pearlmutter"^^schema:Person,
        "Mansura Habiba"^^schema:Person ;
    schema:dateModified "2020-05-20T01:02:29Z"^^schema:DateTime ;
    schema:datePublished "2020-05-20T01:02:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Ordinary Differential Equation based Recurrent Neural Network  Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.09807v1"^^schema:URL .

<1491> a schema:ScholarlyArticle ;
    schema:abstract "How can we make machine learning provably robust against adversarial examplesin a scalable way? Since certified defense methods, which ensure$\\epsilon$-robust, consume huge resources, they can only achieve small degreeof robustness in practice. Lipschitz margin training (LMT) is a scalablecertified defense, but it can also only achieve small robustness due toover-regularization. How can we make certified defense more efficiently? Wepresent LC-LMT, a light weight Lipschitz margin training which solves the aboveproblem. Our method has the following properties; (a) efficient: it can achieve$\\epsilon$-robustness at early epoch, and (b) robust: it has a potential to gethigher robustness than LMT. In the evaluation, we demonstrate the benefits ofthe proposed method. LC-LMT can achieve required robustness more than 30 epochearlier than LMT in MNIST, and shows more than 90 $\\%$ accuracy against bothlegitimate and adversarial inputs."^^schema:Text ;
    schema:author "Hajime Ono"^^schema:Person,
        "Kazuya Kakizaki"^^schema:Person,
        "Tsubasa Takahashi"^^schema:Person ;
    schema:dateModified "2018-11-20T05:22:55Z"^^schema:DateTime ;
    schema:datePublished "2018-11-20T05:22:55Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Lightweight Lipschitz Margin Training for Certified Defense against  Adversarial Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.08080v1"^^schema:URL .

<1492> a schema:ScholarlyArticle ;
    schema:abstract "We present a method for using previously-trained 'teacher' agents tokickstart the training of a new 'student' agent. To this end, we leverage ideasfrom policy distillation and population based training. Our method places noconstraints on the architecture of the teacher or student agents, and itregulates itself to allow the students to surpass their teachers inperformance. We show that, on a challenging and computationally-intensivemulti-task benchmark (DMLab-30), kickstarted training improves the dataefficiency of new agents, making it significantly easier to iterate on theirdesign. We also show that the same kickstarting pipeline can allow a singlestudent agent to leverage multiple 'expert' teachers which specialize onindividual tasks. In this setting kickstarting yields surprisingly large gains,with the kickstarted agent matching the performance of an agent trained fromscratch in almost 10x fewer steps, and surpassing its final performance by 42percent. Kickstarting is conceptually simple and can easily be incorporatedinto reinforcement learning experiments."^^schema:Text ;
    schema:author "Andrew Zisserman"^^schema:Person,
        "Augustin Zidek"^^schema:Person,
        "Carl Doersch"^^schema:Person,
        "Heinrich Kuttler"^^schema:Person,
        "Joel Z. Leibo"^^schema:Person,
        "Jonathan J. Hudson"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "S. M. Ali Eslami"^^schema:Person,
        "Simon Osindero"^^schema:Person,
        "Simon Schmitt"^^schema:Person,
        "Wojciech M. Czarnecki"^^schema:Person ;
    schema:dateModified "2018-03-10T16:45:00Z"^^schema:DateTime ;
    schema:datePublished "2018-03-10T16:45:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Kickstarting Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.03835v1"^^schema:URL .

<1493> a schema:ScholarlyArticle ;
    schema:abstract "With the explosive growth of online products and content, recommendationtechniques have been considered as an effective tool to overcome informationoverload, improve user experience, and boost business revenue. In recent years,we have observed a new desideratum of considering long-term rewards of multiplerelated recommendation tasks simultaneously. The consideration of long-termrewards is strongly tied to business revenue and growth. Learning multipletasks simultaneously could generally improve the performance of individual taskdue to knowledge sharing in multi-task learning. While a few existing workshave studied long-term rewards in recommendations, they mainly focus on asingle recommendation task. In this paper, we propose {\\it PoDiRe}: a\\underline{po}licy \\underline{di}stilled \\underline{re}commender that canaddress long-term rewards of recommendations and simultaneously handle multiplerecommendation tasks. This novel recommendation solution is based on a marriageof deep reinforcement learning and knowledge distillation techniques, which isable to establish knowledge sharing among different tasks and reduce the sizeof a learning model. The resulting model is expected to attain betterperformance and lower response latency for real-time recommendation services.In collaboration with Samsung Game Launcher, one of the world's largestcommercial mobile game platforms, we conduct a comprehensive experimental studyon large-scale real data with hundreds of millions of events and show that oursolution outperforms many state-of-the-art methods in terms of several standardevaluation metrics."^^schema:Text ;
    schema:author "Li Li"^^schema:Person,
        "Muhe Xie"^^schema:Person,
        "Ping-Chun Hsieh"^^schema:Person,
        "Rui Chen"^^schema:Person,
        "Xi Liu"^^schema:Person,
        "Yong Ge"^^schema:Person ;
    schema:dateModified "2020-01-27T06:05:42Z"^^schema:DateTime ;
    schema:datePublished "2020-01-27T06:05:42Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Developing Multi-Task Recommendations with Long-Term Rewards via Policy  Distilled Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.09595v1"^^schema:URL .

<1494> a schema:ScholarlyArticle ;
    schema:abstract "Neural machine translation~(NMT) is ineffective for zero-resource languages.Recent works exploring the possibility of unsupervised neural machinetranslation (UNMT) with only monolingual data can achieve promising results.However, there are still big gaps between UNMT and NMT with parallelsupervision. In this work, we introduce a multilingual unsupervised NMT(\\method) framework to leverage weakly supervised signals from high-resourcelanguage pairs to zero-resource translation directions. More specifically, forunsupervised language pairs \\texttt{En-De}, we can make full use of theinformation from parallel dataset \\texttt{En-Fr} to jointly train theunsupervised translation directions all in one model. \\method is based onmultilingual models which require no changes to the standard unsupervised NMT.Empirical results demonstrate that \\method significantly improves thetranslation quality by more than 3 BLEU score on six benchmark unsupervisedtranslation directions."^^schema:Text ;
    schema:author "Hai Zhao"^^schema:Person,
        "Hongxiao Bai"^^schema:Person,
        "Lei Li"^^schema:Person,
        "Mingxuan Wang"^^schema:Person ;
    schema:dateModified "2020-09-25T03:44:16Z"^^schema:DateTime ;
    schema:datePublished "2020-04-07T05:46:49Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Cross-lingual Supervision Improves Unsupervised Neural Machine  Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.03137v2"^^schema:URL .

<1495> a schema:ScholarlyArticle ;
    schema:abstract "We use neural ordinary differential equations to formulate a variant of theTransformer that is depth-adaptive in the sense that an input-dependent numberof time steps is taken by the ordinary differential equation solver. Our goalin proposing the N-ODE Transformer is to investigate whether itsdepth-adaptivity may aid in overcoming some specific known theoreticallimitations of the Transformer in handling nonlocal effects. Specifically, weconsider the simple problem of determining the parity of a binary sequence, forwhich the standard Transformer has known limitations that can only be overcomeby using a sufficiently large number of layers or attention heads. We find,however, that the depth-adaptivity of the N-ODE Transformer does not provide aremedy for the inherently nonlocal nature of the parity problem, and provideexplanations for why this is so. Next, we pursue regularization of the N-ODETransformer by penalizing the arclength of the ODE trajectories, but find thatthis fails to improve the accuracy or efficiency of the N-ODE Transformer onthe challenging parity problem. We suggest future avenues of research formodifications and extensions of the N-ODE Transformer that may lead to improvedaccuracy and efficiency for sequence modelling tasks such as neural machinetranslation."^^schema:Text ;
    schema:author "Aaron Baier-Reinio"^^schema:Person,
        "Hans De Sterck"^^schema:Person ;
    schema:dateModified "2020-10-22T00:48:24Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T00:48:24Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "N-ODE Transformer: A Depth-Adaptive Variant of the Transformer Using  Neural Ordinary Differential Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11358v1"^^schema:URL .

<1496> a schema:ScholarlyArticle ;
    schema:abstract "We present an approach for mobile robots to learn to navigate in dynamicenvironments with pedestrians via raw depth inputs, in a socially compliantmanner. To achieve this, we adopt a generative adversarial imitation learning(GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Ourapproach overcomes the disadvantages of previous methods, as they heavilydepend on the full knowledge of the location and velocity information of nearbypedestrians, which not only requires specific sensors, but also the extractionof such state information from raw sensory input could consume much computationtime. In this paper, our proposed GAIL-based model performs directly on rawdepth inputs and plans in real-time. Experiments show that our GAIL-basedapproach greatly improves the safety and efficiency of the behavior of mobilerobots from pure behavior cloning. The real-world deployment also shows thatour method is capable of guiding autonomous vehicles to navigate in a sociallycompliant manner directly through raw depth inputs. In addition, we release asimulation plugin for modeling pedestrian behaviors based on the social forcemodel."^^schema:Text ;
    schema:author "Jingwei Zhang"^^schema:Person,
        "Lei Tai"^^schema:Person,
        "Ming Liu"^^schema:Person,
        "Wolfram Burgard"^^schema:Person ;
    schema:dateModified "2018-02-26T05:56:54Z"^^schema:DateTime ;
    schema:datePublished "2017-10-06T18:29:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Socially Compliant Navigation through Raw Depth Inputs with Generative  Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.02543v2"^^schema:URL .

<1497> a schema:ScholarlyArticle ;
    schema:abstract "The key issue of few-shot learning is learning to generalize. This paperproposes a large margin principle to improve the generalization capacity ofmetric based methods for few-shot learning. To realize it, we develop a unifiedframework to learn a more discriminative metric space by augmenting theclassification loss function with a large margin distance loss function fortraining. Extensive experiments on two state-of-the-art few-shot learningmethods, graph neural networks and prototypical networks, show that our methodcan improve the performance of existing models substantially with very littlecomputational overhead, demonstrating the effectiveness of the large marginprinciple and the potential of our method."^^schema:Text ;
    schema:author "Jiatao Gu"^^schema:Person,
        "Lei Zhang"^^schema:Person,
        "Qimai Li"^^schema:Person,
        "Victor O. K. Li"^^schema:Person,
        "Wangmeng Xiang"^^schema:Person,
        "Xiao-Ming Wu"^^schema:Person,
        "Yong Wang"^^schema:Person ;
    schema:dateModified "2018-09-21T06:39:48Z"^^schema:DateTime ;
    schema:datePublished "2018-07-08T19:44:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Large Margin Few-Shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.02872v2"^^schema:URL .

<1498> a schema:ScholarlyArticle ;
    schema:abstract "Tensor methods have become a promising tool to solve high-dimensionalproblems in the big data era. By exploiting possible low-rank tensorfactorization, many high-dimensional model-based or data-driven problems can besolved to facilitate decision making or machine learning. In this paper, wesummarize the recent applications of tensor computation in obtaining compactmodels for uncertainty quantification and deep learning. In uncertaintyanalysis where obtaining data samples is expensive, we show how tensor methodscan significantly reduce the simulation or measurement cost. To enable thedeployment of deep learning on resource-constrained hardware platforms, tensormethods can be used to significantly compress an over-parameterized neuralnetwork model or directly train a small-size model from scratch viaoptimization or statistical techniques. Recent Bayesian tensorized neuralnetworks can automatically determine their tensor ranks in the trainingprocess."^^schema:Text ;
    schema:author "Chunfeng Cui"^^schema:Person,
        "Cole Hawkins"^^schema:Person,
        "Zheng Zhang"^^schema:Person ;
    schema:dateModified "2019-08-21T03:48:18Z"^^schema:DateTime ;
    schema:datePublished "2019-08-21T03:48:18Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Tensor Methods for Generating Compact Uncertainty Quantification and  Deep Learning Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.07699v1"^^schema:URL .

<1499> a schema:ScholarlyArticle ;
    schema:abstract "Dealing with sparse rewards is a longstanding challenge in reinforcementlearning. The recent use of hindsight methods have achieved success on avariety of sparse-reward tasks, but they fail on complex tasks such as stackingmultiple blocks with a robot arm in simulation. Curiosity-driven explorationusing the prediction error of a learned dynamics model as an intrinsic rewardhas been shown to be effective for exploring a number of sparse-rewardenvironments. We present a method that combines hindsight with curiosity-drivenexploration and curriculum learning in order to solve the challengingsparse-reward block stacking task. We are the first to stack more than twoblocks using only sparse reward without human demonstrations."^^schema:Text ;
    schema:author "John B. Lanier"^^schema:Person,
        "Pierre Baldi"^^schema:Person,
        "Stephen McAleer"^^schema:Person ;
    schema:dateModified "2019-06-09T21:11:08Z"^^schema:DateTime ;
    schema:datePublished "2019-06-09T21:11:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Curiosity-Driven Multi-Criteria Hindsight Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.03710v1"^^schema:URL .

<15> a schema:ScholarlyArticle ;
    schema:abstract "Bat algorithm (BA) is a recent optimization algorithm based on swarmintelligence and inspiration from the echolocation behavior of bats. One of theissues in the standard bat algorithm is the premature convergence that canoccur due to the low exploration ability of the algorithm under someconditions. To overcome this deficiency, directional echolocation is introducedto the standard bat algorithm to enhance its exploration and exploitationcapabilities. In addition to such directional echolocation, three otherimprovements have been embedded into the standard bat algorithm to enhance itsperformance. The new proposed approach, namely the directional Bat Algorithm(dBA), has been then tested using several standard and non-standard benchmarksfrom the CEC2005 benchmark suite. The performance of dBA has been compared withten other algorithms and BA variants using non-parametric statistical tests.The statistical test results show the superiority of the directional batalgorithm."^^schema:Text ;
    schema:author "Asma Chakri"^^schema:Person,
        "Mohamed Benouaret"^^schema:Person,
        "Rabia Khelif"^^schema:Person,
        "Xin-She Yang"^^schema:Person ;
    schema:commentCount "131"^^schema:Integer ;
    schema:dateModified "2018-04-22T10:36:56Z"^^schema:DateTime ;
    schema:datePublished "2018-04-22T10:36:56Z"^^schema:DateTime ;
    schema:genre "90C30, 68W20"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "New directional bat algorithm for continuous optimization problems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 69, 159-175"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.05854v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15807104368648205349&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<150> a schema:ScholarlyArticle ;
    schema:abstract "Observational studies are rising in importance due to the widespreadaccumulation of data in fields such as healthcare, education, employment andecology. We consider the task of answering counterfactual questions such as,\"Would this patient have lower blood sugar had she received a differentmedication?\". We propose a new algorithmic framework for counterfactualinference which brings together ideas from domain adaptation and representationlearning. In addition to a theoretical justification, we perform an empiricalcomparison with previous approaches to causal inference from observationaldata. Our deep learning algorithm significantly outperforms the previousstate-of-the-art."^^schema:Text ;
    schema:author "David Sontag"^^schema:Person,
        "Fredrik D. Johansson"^^schema:Person,
        "Uri Shalit"^^schema:Person ;
    schema:commentCount "196"^^schema:Integer ;
    schema:dateModified "2018-06-06T13:00:53Z"^^schema:DateTime ;
    schema:datePublished "2016-05-12T02:59:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Representations for Counterfactual Inference"^^schema:Text ;
    schema:publisher "ICML, 3020-3029"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.03661v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=364993537171423085&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1500> a schema:ScholarlyArticle ;
    schema:abstract "Artificial neural networks suffer from catastrophic forgetting when they aresequentially trained on multiple tasks. To overcome this problem, we present anovel approach based on task-conditioned hypernetworks, i.e., networks thatgenerate the weights of a target model based on task identity. Continuallearning (CL) is less difficult for this class of models thanks to a simple keyfeature: instead of recalling the input-output relations of all previously seendata, task-conditioned hypernetworks only require rehearsing task-specificweight realizations, which can be maintained in memory using a simpleregularizer. Besides achieving state-of-the-art performance on standard CLbenchmarks, additional experiments on long task sequences reveal thattask-conditioned hypernetworks display a very large capacity to retain previousmemories. Notably, such long memory lifetimes are achieved in a compressiveregime, when the number of trainable hypernetwork weights is comparable orsmaller than target network size. We provide insight into the structure oflow-dimensional task embedding spaces (the input space of the hypernetwork) andshow that task-conditioned hypernetworks demonstrate transfer learning.Finally, forward information transfer is further supported by empirical resultson a challenging CL benchmark based on the CIFAR-10/100 image datasets."^^schema:Text ;
    schema:author "Benjamin F. Grewe"^^schema:Person,
        "Christian Henning"^^schema:Person,
        "Johannes von Oswald"^^schema:Person,
        "João Sacramento"^^schema:Person ;
    schema:dateModified "2020-02-12T14:56:57Z"^^schema:DateTime ;
    schema:datePublished "2019-06-03T10:45:08Z"^^schema:DateTime ;
    schema:genre "68T99"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continual learning with hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.00695v3"^^schema:URL .

<1501> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we introduce a novel type of Rectified Linear Unit (ReLU),called a Dual Rectified Linear Unit (DReLU). A DReLU, which comes with anunbounded positive and negative image, can be used as a drop-in replacement fora tanh activation function in the recurrent step of Quasi-Recurrent NeuralNetworks (QRNNs) (Bradbury et al. (2017)). Similar to ReLUs, DReLUs are lessprone to the vanishing gradient problem, they are noise robust, and they inducesparse activations.  We independently reproduce the QRNN experiments of Bradbury et al. (2017) andcompare our DReLU-based QRNNs with the original tanh-based QRNNs and LongShort-Term Memory networks (LSTMs) on sentiment classification and word-levellanguage modeling. Additionally, we evaluate on character-level languagemodeling, showing that we are able to stack up to eight QRNN layers withDReLUs, thus making it possible to improve the current state-of-the-art incharacter-level language modeling over shallow architectures based on LSTMs."^^schema:Text ;
    schema:author "Fréderic Godin"^^schema:Person,
        "Jonas Degrave"^^schema:Person,
        "Joni Dambre"^^schema:Person,
        "Wesley De Neve"^^schema:Person ;
    schema:dateModified "2017-10-31T15:50:57Z"^^schema:DateTime ;
    schema:datePublished "2017-07-25T20:52:32Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Dual Rectified Linear Units (DReLUs): A Replacement for Tanh Activation  Functions in Quasi-Recurrent Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.08214v2"^^schema:URL .

<1502> a schema:ScholarlyArticle ;
    schema:abstract "Network pruning has been the driving force for the acceleration of neuralnetworks and the alleviation of model storage/transmission burden. With theadvent of AutoML and neural architecture search (NAS), pruning has becometopical with automatic mechanism and searching based architecture optimization.Yet, current automatic designs rely on either reinforcement learning orevolutionary algorithm. Due to the non-differentiability of those algorithms,the pruning algorithm needs a long searching stage before reaching theconvergence.  To circumvent this problem, this paper introduces a differentiable pruningmethod via hypernetworks for automatic network pruning. The specificallydesigned hypernetworks take latent vectors as input and generate the weightparameters of the backbone network. The latent vectors control the outputchannels of the convolutional layers in the backbone network and act as ahandle for the pruning of the layers. By enforcing $\\ell_1$ sparsityregularization to the latent vectors and utilizing proximal gradient solver,sparse latent vectors can be obtained. Passing the sparsified latent vectorsthrough the hypernetworks, the corresponding slices of the generated weightparameters can be removed, achieving the effect of network pruning. The latentvectors of all the layers are pruned together, resulting in an automatic layerconfiguration. Extensive experiments are conducted on various networks forimage classification, single image super-resolution, and denoising. And theexperimental results validate the proposed method."^^schema:Text ;
    schema:author "Kai Zhang"^^schema:Person,
        "Luc Van Gool"^^schema:Person,
        "Radu Timofte"^^schema:Person,
        "Shuhang Gu"^^schema:Person,
        "Yawei Li"^^schema:Person ;
    schema:dateModified "2020-08-01T10:59:30Z"^^schema:DateTime ;
    schema:datePublished "2020-03-30T17:59:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "DHP: Differentiable Meta Pruning via HyperNetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.13683v3"^^schema:URL .

<1503> a schema:ScholarlyArticle ;
    schema:abstract "Depth estimation is an active area of research in the field of computervision, and has garnered significant interest due to its rising demand in alarge number of applications ranging from robotics and unmanned aerial vehiclesto autonomous vehicles. A particularly challenging problem in this area ismonocular depth estimation, where the goal is to infer depth from a singleimage. An effective strategy that has shown considerable promise in recentyears for tackling this problem is the utilization of deep convolutional neuralnetworks. Despite these successes, the memory and computational requirements ofsuch networks have made widespread deployment in embedded scenarios verychallenging. In this study, we introduce DepthNet Nano, a highly compact selfnormalizing network for monocular depth estimation designed using a humanmachine collaborative design strategy, where principled network designprototyping based on encoder-decoder design principles are coupled withmachine-driven design exploration. The result is a compact deep neural networkwith highly customized macroarchitecture and microarchitecture designs, as wellas self-normalizing characteristics, that are highly tailored for the task ofembedded depth estimation. The proposed DepthNet Nano possesses a highlyefficient network architecture (e.g., 24X smaller and 42X fewer MAC operationsthan Alhashim et al. on KITTI), while still achieving comparable performancewith state-of-the-art networks on the NYU-Depth V2 and KITTI datasets.Furthermore, experiments on inference speed and energy efficiency on a JetsonAGX Xavier embedded module further illustrate the efficacy of DepthNet Nano atdifferent resolutions and power budgets (e.g., ~14 FPS and &gt;0.46images/sec/watt at 384 X 1280 at a 30W power budget on KITTI)."^^schema:Text ;
    schema:author "Alexander Wong"^^schema:Person,
        "Linda Wang"^^schema:Person,
        "Mahmoud Famouri"^^schema:Person ;
    schema:dateModified "2020-04-17T00:41:35Z"^^schema:DateTime ;
    schema:datePublished "2020-04-17T00:41:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "DepthNet Nano: A Highly Compact Self-Normalizing Neural Network for  Monocular Depth Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.08008v1"^^schema:URL .

<1504> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge distillation extracts general knowledge from a pre-trained teachernetwork and provides guidance to a target student network. Most studiesmanually tie intermediate features of the teacher and student, and transferknowledge through pre-defined links. However, manual selection often constructsineffective links that limit the improvement from the distillation. There hasbeen an attempt to address the problem, but it is still challenging to identifyeffective links under practical scenarios. In this paper, we introduce aneffective and efficient feature distillation method utilizing all the featurelevels of the teacher without manually selecting the links. Specifically, ourmethod utilizes an attention-based meta-network that learns relativesimilarities between features, and applies identified similarities to controldistillation intensities of all possible pairs. As a result, our methoddetermines competent links more efficiently than the previous approach andprovides better performance on model compression and transfer learning tasks.Further qualitative analyses and ablative studies describe how our methodcontributes to better distillation. The implementation code is available atgithub.com/clovaai/attention-feature-distillation."^^schema:Text ;
    schema:author "Byeongho Heo"^^schema:Person,
        "Mingi Ji"^^schema:Person,
        "Sungrae Park"^^schema:Person ;
    schema:dateModified "2021-02-05T03:07:57Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T03:07:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Show, Attend and Distill:Knowledge Distillation via Attention-based  Feature Matching"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02973v1"^^schema:URL .

<1505> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (UNMT) has recently achievedremarkable results for several language pairs. However, it can only translatebetween a single language pair and cannot produce translation results formultiple language pairs at the same time. That is, research on multilingualUNMT has been limited. In this paper, we empirically introduce a simple methodto translate between thirteen languages using a single encoder and a singledecoder, making use of multilingual data to improve UNMT for all languagepairs. On the basis of the empirical findings, we propose two knowledgedistillation methods to further enhance multilingual UNMT performance. Ourexperiments on a dataset with English translated to and from twelve otherlanguages (including three language families and six language branches) showremarkable results, surpassing strong unsupervised individual baselines whileachieving promising performance between non-English language pairs in zero-shottranslation scenarios and alleviating poor performance in low-resource languagepairs."^^schema:Text ;
    schema:author "Eiichiro Sumita"^^schema:Person,
        "Haipeng Sun"^^schema:Person,
        "Kehai Chen"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Tiejun Zhao"^^schema:Person ;
    schema:dateModified "2020-04-21T17:26:16Z"^^schema:DateTime ;
    schema:datePublished "2020-04-21T17:26:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Knowledge Distillation for Multilingual Unsupervised Neural Machine  Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10171v1"^^schema:URL .

<1506> a schema:ScholarlyArticle ;
    schema:abstract "We propose a reinforcement learning agent to solve hard exploration games bylearning a range of directed exploratory policies. We construct an episodicmemory-based intrinsic reward using k-nearest neighbors over the agent's recentexperience to train the directed exploratory policies, thereby encouraging theagent to repeatedly revisit all states in its environment. A self-supervisedinverse dynamics model is used to train the embeddings of the nearest neighbourlookup, biasing the novelty signal towards what the agent can control. Weemploy the framework of Universal Value Function Approximators (UVFA) tosimultaneously learn many directed exploration policies with the same neuralnetwork, with different trade-offs between exploration and exploitation. Byusing the same neural network for different degrees ofexploration/exploitation, transfer is demonstrated from predominantlyexploratory policies yielding effective exploitative policies. The proposedmethod can be incorporated to run with modern distributed RL agents thatcollect large amounts of experience from many actors running in parallel onseparate environment instances. Our method doubles the performance of the baseagent in all hard exploration in the Atari-57 suite while maintaining a veryhigh score across the remaining games, obtaining a median human normalisedscore of 1344.0%. Notably, the proposed method is the first algorithm toachieve non-zero rewards (with a mean score of 8,400) in the game of Pitfall!without using demonstrations or hand-crafted features."^^schema:Text ;
    schema:author "Adrià Puigdomènech Badia"^^schema:Person,
        "Alex Vitvitskyi"^^schema:Person,
        "Alexander Pritzel"^^schema:Person,
        "Andew Bolt"^^schema:Person,
        "Bilal Piot"^^schema:Person,
        "Charles Blundell"^^schema:Person,
        "Daniel Guo"^^schema:Person,
        "Martín Arjovsky"^^schema:Person,
        "Olivier Tieleman"^^schema:Person,
        "Pablo Sprechmann"^^schema:Person,
        "Steven Kapturowski"^^schema:Person ;
    schema:dateModified "2020-02-14T13:57:22Z"^^schema:DateTime ;
    schema:datePublished "2020-02-14T13:57:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Never Give Up: Learning Directed Exploration Strategies"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.06038v1"^^schema:URL .

<1507> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we study the problem of making predictions using multiplestructural casual models defined by different agents, under the constraint thatthe prediction satisfies the criterion of counterfactual fairness. Relying onthe frameworks of causality, fairness and opinion pooling, we build upon andextend previous work focusing on the qualitative aggregation of causal Bayesiannetworks and causal models. In order to complement previous qualitativeresults, we devise a method based on Monte Carlo simulations. This methodenables a decision-maker to aggregate the outputs of the causal models providedby different experts while guaranteeing the counterfactual fairness of theresult. We demonstrate our approach on a simple, yet illustrative, toy casestudy."^^schema:Text ;
    schema:author "Fabio Massimo Zennaro"^^schema:Person,
        "Magdalena Ivanovska"^^schema:Person ;
    schema:dateModified "2018-10-01T13:11:27Z"^^schema:DateTime ;
    schema:datePublished "2018-10-01T13:11:27Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Counterfactually Fair Prediction Using Multiple Causal Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.00694v1"^^schema:URL .

<1508> a schema:ScholarlyArticle ;
    schema:abstract "We present 180 AGN candidates based on color selection from the IRASslow-scan deep observations, with color criteria broadened from the initialPoint-Source Catalog samples to include similar objects with redshifts up toz=1 and allowing for two-band detections. Spectroscopic identifications havebeen obtained for 80 (44%); some additional ones are secure based on radiodetections or optical morphology, although yet unobserved spectroscopically.These spectroscopic identifications include 13 Sy 1 galaxies, 17 Sy 2 Seyferts,29 starbursts, 7 LINER systems, and 13 emission-line galaxies so heavilyreddened as to remain of ambiguous classification. The optical magnitudes rangefrom R=12.0-20.5; counts suggest that incompleteness is important fainter thanR=15.5. Redshifts extend to z=0.51, with a significant part of the sample atz&gt;0.2. The sample includes slightly more AGN than star-forming systems amongthose where the spectra contain enough diagnostic feature to make thedistinction. The active nuclei include several broad-line objects with strongFe II emission, and composite objects with the absorption-line signatures offading starbursts. These AGN with warm far-IR colors have little overlap withthe \"red AGN\" identified with 2MASS; only a single Sy 1 was detected by 2MASSwith J-K &gt; 2. Some reliable IRAS detections have either very faint opticalcounterparts or only absorption-line galaxies, potentially being deeplyobscured AGN. The IRAS detections include a newly identified symbiotic star,and several possible examples of the \"Vega phenomenon\", including dwarfs ascool as type K. Appendices detail these candidate stars, and theoptical-identification content of a particularly deep set of high-latitude IRASscans (probing the limits of optical identification from IRAS data alone)."^^schema:Text ;
    schema:author "Alana May"^^schema:Person,
        "Bryan K. Irby"^^schema:Person,
        "Daniel Golombek"^^schema:Person,
        "George K. Miley"^^schema:Person,
        "Jack F. Gallimore"^^schema:Person,
        "M. H. K. de Grijp"^^schema:Person,
        "William C. Keel"^^schema:Person ;
    schema:dateModified "2005-03-03T15:25:54Z"^^schema:DateTime ;
    schema:datePublished "2005-03-03T15:25:54Z"^^schema:DateTime ;
    schema:genre "astro-ph"^^schema:Text ;
    schema:headline "An Atlas of Warm AGN and Starbursts from the IRAS Deep Fields"^^schema:Text ;
    schema:url "http://arxiv.org/abs/astro-ph/0503080v1"^^schema:URL .

<1509> a schema:ScholarlyArticle ;
    schema:abstract "The vast majority of research on explainability focuses onpost-explainability rather than explainable modeling. Namely, an explanationmodel is derived to explain a complex black box model built with the solepurpose of achieving the highest performance possible. In part, this trendmight be driven by the misconception that there is a trade-off betweenexplainability and accuracy. Furthermore, the consequential work on Shapelyvalues, grounded in game theory, has also contributed to a new wave ofpost-explainability research on better approximations for various machinelearning models, including deep learning models. We propose a new architecturethat inherently produces explainable predictions in the form of additivefeature attributions. Our approach learns a graph representation for eachrecord in the dataset. Attribute centric features are then derived from thegraph and fed into a contribution deep set model to produce the finalpredictions. We show that our explainable model attains the same level ofperformance as black box models. Finally, we provide an augmented modeltraining approach that leverages the missingness property and yields highlevels of consistency (as required for the Shapely values) without loss ofaccuracy."^^schema:Text ;
    schema:author "Asif Chowdhury"^^schema:Person,
        "Gabriel Terejanu"^^schema:Person,
        "Jawad Chowdhury"^^schema:Person,
        "Rezaur Rashid"^^schema:Person ;
    schema:dateModified "2020-02-12T20:02:10Z"^^schema:DateTime ;
    schema:datePublished "2020-02-12T20:02:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Explainable Deep Modeling of Tabular Data using TableGraphNet"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.05205v1"^^schema:URL .

<151> a schema:ScholarlyArticle ;
    schema:abstract "We present two approaches that use unlabeled data to improve sequencelearning with recurrent networks. The first approach is to predict what comesnext in a sequence, which is a conventional language model in natural languageprocessing. The second approach is to use a sequence autoencoder, which readsthe input sequence into a vector and predicts the input sequence again. Thesetwo algorithms can be used as a \"pretraining\" step for a later supervisedsequence learning algorithm. In other words, the parameters obtained from theunsupervised step can be used as a starting point for other supervised trainingmodels. In our experiments, we find that long short term memory recurrentnetworks after being pretrained with the two approaches are more stable andgeneralize better. With pretraining, we are able to train long short termmemory recurrent networks up to a few hundred timesteps, thereby achievingstrong performance in many text classification tasks, such as IMDB, DBpedia and20 Newsgroups."^^schema:Text ;
    schema:author "Andrew M. Dai"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "676"^^schema:Integer ;
    schema:dateModified "2015-11-04T18:48:36Z"^^schema:DateTime ;
    schema:datePublished "2015-11-04T18:48:36Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Semi-supervised Sequence Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.01432v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6463821397595411961&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1510> a schema:ScholarlyArticle ;
    schema:abstract "Natural language is hypothetically the best user interface for many domains.However, general models that provide an interface between natural language andany other domain still do not exist. Providing natural language interface torelational databases could possibly attract a vast majority of users that areor are not proficient with query languages. With the rise of deep learningtechniques, there is extensive ongoing research in designing a suitable naturallanguage interface to relational databases.  This survey aims to overview some of the latest methods and models proposedin the area of SQL query generation from natural language. We describe modelswith various architectures such as convolutional neural networks, recurrentneural networks, pointer networks, reinforcement learning, etc. Severaldatasets intended to address the problem of SQL query generation areinterpreted and briefly overviewed. In the end, evaluation metrics utilized inthe field are presented mainly as a combination of execution accuracy andlogical form accuracy."^^schema:Text ;
    schema:author "Frosina Stojanovska"^^schema:Person,
        "Jovan Kalajdjieski"^^schema:Person,
        "Martina Toshevska"^^schema:Person ;
    schema:dateModified "2020-05-15T17:31:29Z"^^schema:DateTime ;
    schema:datePublished "2020-05-15T17:31:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Recent Advances in SQL Query Generation: A Survey"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.07667v1"^^schema:URL .

<1511> a schema:ScholarlyArticle ;
    schema:abstract "As a non-parametric Bayesian model which produces informative predictivedistribution, Gaussian process (GP) has been widely used in various fields,like regression, classification and optimization. The cubic complexity ofstandard GP however leads to poor scalability, which poses challenges in theera of big data. Hence, various scalable GPs have been developed in theliterature in order to improve the scalability while retaining desirableprediction accuracy. This paper devotes to investigating the methodologicalcharacteristics and performance of representative global and local scalable GPsincluding sparse approximations and local aggregations from four mainperspectives: scalability, capability, controllability and robustness. Thenumerical experiments on two toy examples and five real-world datasets with upto 250K points offer the following findings. In terms of scalability, most ofthe scalable GPs own a time complexity that is linear to the training size. Interms of capability, the sparse approximations capture the long-term spatialcorrelations, the local aggregations capture the local patterns but suffer fromover-fitting in some scenarios. In terms of controllability, we could improvethe performance of sparse approximations by simply increasing the inducingsize. But this is not the case for local aggregations. In terms of robustness,local aggregations are robust to various initializations of hyperparameters dueto the local attention mechanism. Finally, we highlight that the proper hybridof global and local scalable GPs may be a promising way to improve both themodel capability and scalability for big data."^^schema:Text ;
    schema:author "Haitao Liu"^^schema:Person,
        "Jianfei Cai"^^schema:Person,
        "Yew-Soon Ong"^^schema:Person,
        "Yi Wang"^^schema:Person ;
    schema:dateModified "2018-11-03T04:46:58Z"^^schema:DateTime ;
    schema:datePublished "2018-11-03T04:46:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Understanding and Comparing Scalable Gaussian Process Regression for Big  Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.01159v1"^^schema:URL .

<1512> a schema:ScholarlyArticle ;
    schema:abstract "Despite their elegant formulation and lightweight memory cost, neuralordinary differential equations (NODEs) suffer from known representationallimitations. In particular, the single flow learned by NODEs cannot express allhomeomorphisms from a given data space to itself, and their static weightparametrization restricts the type of functions they can learn compared todiscrete architectures with layer-dependent weights. Here, we describe a newmodule called neurally-controlled ODE (N-CODE) designed to improve theexpressivity of NODEs. The parameters of N-CODE modules are dynamic variablesgoverned by a trainable map from initial or current activation state, resultingin forms of open-loop and closed-loop control, respectively. A single module issufficient for learning a distribution on non-autonomous flows that adaptivelydrive neural representations. We provide theoretical and empirical evidencethat N-CODE circumvents limitations of previous models and show how increasedmodel expressivity manifests in several domains. In supervised learning, wedemonstrate that our framework achieves better performance than NODEs asmeasured by both training speed and testing accuracy. In unsupervised learning,we apply this control perspective to an image Autoencoder endowed with a latenttransformation flow, greatly improving representational power over a vanillamodel and leading to state-of-the-art image reconstruction on CIFAR-10."^^schema:Text ;
    schema:author "Mathieu Chalvidal"^^schema:Person,
        "Matthew Ricci"^^schema:Person,
        "Rufin VanRullen"^^schema:Person,
        "Thomas Serre"^^schema:Person ;
    schema:dateModified "2020-10-07T08:10:07Z"^^schema:DateTime ;
    schema:datePublished "2020-06-16T22:21:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Go with the Flow: Adaptive Control for Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.09545v2"^^schema:URL .

<1513> a schema:ScholarlyArticle ;
    schema:abstract "Monitoring student knowledge states or skill acquisition levels known asknowledge tracing, is a fundamental part of intelligent tutoring systems.Despite its inherent challenges, recent deep neural networks based knowledgetracing models have achieved great success, which is largely from models'ability to learn sequential dependencies of questions in student exercise data.However, in addition to sequential information, questions inherently exhibitside relations, which can enrich our understandings about student knowledgestates and has great potentials to advance knowledge tracing. Thus, in thispaper, we exploit side relations to improve knowledge tracing and design anovel framework DTKS. The experimental results on real education data validatethe effectiveness of the proposed framework and demonstrate the importance ofside information in knowledge tracing."^^schema:Text ;
    schema:author "Gale Yan Huang"^^schema:Person,
        "Jiliang Tang"^^schema:Person,
        "Xiaoqin Feng"^^schema:Person,
        "Zhiwei Wang"^^schema:Person,
        "Zitao Liu"^^schema:Person ;
    schema:dateModified "2019-09-01T10:23:21Z"^^schema:DateTime ;
    schema:datePublished "2019-09-01T10:23:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Knowledge Tracing with Side Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.00372v1"^^schema:URL .

<1514> a schema:ScholarlyArticle ;
    schema:abstract "Fair inference in supervised learning is an important and active area ofresearch, yielding a range of useful methods to assess and account for fairnesscriteria when predicting ground truth targets. As shown in recent work,however, when target labels are error-prone, potential prediction unfairnesscan arise from measurement error. In this paper, we show that, when anerror-prone proxy target is used, existing methods to assess and calibratefairness criteria do not extend to the true target variable of interest. Toremedy this problem, we suggest a framework resulting from the combination oftwo existing literatures: fair ML methods, such as those found in thecounterfactual fairness literature on the one hand, and, on the other,measurement models found in the statistical literature. We discuss theseapproaches and their connection resulting in our framework. In a healthcaredecision problem, we find that using a latent variable model to account formeasurement error removes the unfairness detected previously."^^schema:Text ;
    schema:author "Ayoub Bagheri"^^schema:Person,
        "Daniel L. Oberski"^^schema:Person,
        "Erik-Jan van Kesteren"^^schema:Person,
        "Laura Boeschoten"^^schema:Person ;
    schema:dateModified "2020-03-17T10:31:59Z"^^schema:DateTime ;
    schema:datePublished "2020-03-17T10:31:59Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Fair inference on error-prone outcomes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.07621v1"^^schema:URL .

<1515> a schema:ScholarlyArticle ;
    schema:abstract "Very recently proximal policy optimization (PPO) algorithms have beenproposed as first-order optimization methods for effective reinforcementlearning. While PPO is inspired by the same learning theory that justifiestrust region policy optimization (TRPO), PPO substantially simplifies algorithmdesign and improves data efficiency by performing multiple epochs of\\emph{clipped policy optimization} from sampled data. Although clipping in PPOstands for an important new mechanism for efficient and reliable policy update,it may fail to adaptively improve learning performance in accordance with theimportance of each sampled state. To address this issue, a new surrogatelearning objective featuring an adaptive clipping mechanism is proposed in thispaper, enabling us to develop a new algorithm, known as PPO-$\\lambda$.PPO-$\\lambda$ optimizes policies repeatedly based on a theoretical target foradaptive policy improvement. Meanwhile, destructively large policy update canbe effectively prevented through both clipping and adaptive control of ahyperparameter $\\lambda$ in PPO-$\\lambda$, ensuring high learning reliability.PPO-$\\lambda$ enjoys the same simple and efficient design as PPO. Empiricallyon several Atari game playing tasks and benchmark control tasks, PPO-$\\lambda$also achieved clearly better performance than PPO."^^schema:Text ;
    schema:author "Gang Chen"^^schema:Person,
        "Mengjie Zhang"^^schema:Person,
        "Yiming Peng"^^schema:Person ;
    schema:dateModified "2018-04-17T20:24:27Z"^^schema:DateTime ;
    schema:datePublished "2018-04-17T20:24:27Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "An Adaptive Clipping Approach for Proximal Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.06461v1"^^schema:URL .

<1516> a schema:ScholarlyArticle ;
    schema:abstract "Generative moment matching networks (GMMNs) are introduced for generatingquasi-random samples from multivariate models with any underlying copula inorder to compute estimates under variance reduction. So far, quasi-randomsampling for multivariate distributions required a careful design, exploitingspecific properties (such as conditional distributions) of the impliedparametric copula or the underlying quasi-Monte Carlo (QMC) point set, and wasonly tractable for a small number of models. Utilizing GMMNs allows one toconstruct quasi-random samples for a much larger variety of multivariatedistributions without such restrictions, including empirical ones from realdata with dependence structures not well captured by parametric copulas. Oncetrained on pseudo-random samples from a parametric model or on real data, theseneural networks only require a multivariate standard uniform randomized QMCpoint set as input and are thus fast in estimating expectations of interestunder dependence with variance reduction. Numerical examples are considered todemonstrate the approach, including applications inspired by risk managementpractice. All results are reproducible with the demos GMMN_QMC_paper,GMMN_QMC_data and GMMN_QMC_timings as part of the R package gnn."^^schema:Text ;
    schema:author "Avinash Prasad"^^schema:Person,
        "Marius Hofert"^^schema:Person,
        "Mu Zhu"^^schema:Person ;
    schema:dateModified "2020-04-02T21:02:04Z"^^schema:DateTime ;
    schema:datePublished "2018-11-01T23:59:41Z"^^schema:DateTime ;
    schema:genre "62H99, 65C60, 60E05, 00A72, 65C10"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Quasi-random sampling for multivariate distributions via generative  neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.00683v3"^^schema:URL .

<1517> a schema:ScholarlyArticle ;
    schema:abstract "Given a network and a partition in n communities, we address the issues ``howcommunities influence each other'' and ``when two given communities docommunicate''. We prove that, for a small-world network, among communities, asimple superposition principle applies and each community plays the role of amicroscopic spin governed by a sort of effective TAP (Thouless, Anderson andPalmer) equations. The relative susceptibilities derived from these equationscalculated at finite or zero temperature (where the method provides aneffective percolation theory) give us the answers to the above issues. As forthe already studied case n=1, these equations are exact in the paramagneticregions (at T=0 this means below the percolation threshold) and provideeffective approximations in the other regions. However, unlike the case n=1,asymmetries among the communities may lead, via the TAP-like structure of theequations, to many metastable states whose number, in the case of negativeshort-cuts among the communities, may grow exponentially fast with n and glassyscenarios with a remarkable presence of abrupt jumps take place. Furthermore,as a byproduct, from the relative susceptibilities a natural and efficientmethod to detect the community structure of a generic network emerges."^^schema:Text ;
    schema:author "J. F. F. Mendes"^^schema:Person,
        "M. Ostilli"^^schema:Person ;
    schema:dateModified "2009-08-27T19:29:23Z"^^schema:DateTime ;
    schema:datePublished "2008-12-02T22:14:23Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "cond-mat.stat-mech"^^schema:Text ;
    schema:headline "Small-world of communities: communication and correlation of the  meta-network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/0812.0608v2"^^schema:URL .

<1518> a schema:ScholarlyArticle ;
    schema:abstract "The domains of transport and logistics are increasingly relying on autonomousmobile robots for the handling and distribution of passengers or resources. Atlarge system scales, finding decentralized path planning and coordinationsolutions is key to efficient system performance. Recently, Graph NeuralNetworks (GNNs) have become popular due to their ability to learn communicationpolicies in decentralized multi-agent systems. Yet, vanilla GNNs rely onsimplistic message aggregation mechanisms that prevent agents from prioritizingimportant information.  To tackle this challenge, in this paper, we extend our previous work thatutilizes GNNs in multi-agent path planning by incorporating a novel mechanismto allow for message-dependent attention. Our Message-Aware Graph AttentionneTwork (MAGAT) is based on a key-query-like mechanism that determines therelative importance of features in the messages received from variousneighboring robots. We show that MAGAT is able to achieve a performance closeto that of a coupled centralized expert algorithm. Further, ablation studiesand comparisons to several benchmark models show that our attention mechanismis very effective across different robot densities and performs stably indifferent constraints in communication bandwidth.  Experiments demonstrate that our model is able to generalize well inpreviously unseen problem instances, and it achieves a 47% improvement over thebenchmark success rate, even in very large-scale instances that are 100x largerthan the training instances."^^schema:Text ;
    schema:author "Amanda Prorok"^^schema:Person,
        "Qingbiao Li"^^schema:Person,
        "Weizhe Lin"^^schema:Person,
        "Zhe Liu"^^schema:Person ;
    schema:dateModified "2020-11-26T10:37:13Z"^^schema:DateTime ;
    schema:datePublished "2020-11-26T10:37:13Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Message-Aware Graph Attention Networks for Large-Scale Multi-Robot Path  Planning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13219v1"^^schema:URL .

<1519> a schema:ScholarlyArticle ;
    schema:abstract "Early identification of COVID-19 using a deep model trained on Chest X-Rayand CT images has gained considerable attention from researchers to speed upthe process of identification of active COVID-19 cases. These deep models actas an aid to hospitals that suffer from the unavailability of specialists orradiologists, specifically in remote areas. Various deep models have beenproposed to detect the COVID-19 cases, but few works have been performed toprevent the deep models against adversarial attacks capable of fooling the deepmodel by using a small perturbation in image pixels. This paper presents anevaluation of the performance of deep COVID-19 models against adversarialattacks. Also, it proposes an efficient yet effective Fuzzy Unique ImageTransformation (FUIT) technique that downsamples the image pixels into aninterval. The images obtained after the FUIT transformation are furtherutilized for training the secure deep model that preserves high accuracy of thediagnosis of COVID-19 cases and provides reliable defense against theadversarial attacks. The experiments and results show the proposed modelprevents the deep model against the six adversarial attacks and maintains highaccuracy to classify the COVID-19 cases from the Chest X-Ray image and CT imageDatasets. The results also recommend that a careful inspection is requiredbefore practically applying the deep models to diagnose the COVID-19 cases."^^schema:Text ;
    schema:author "Achyut Mani Tripathi"^^schema:Person,
        "Ashish Mishra"^^schema:Person ;
    schema:dateModified "2020-09-08T21:35:24Z"^^schema:DateTime ;
    schema:datePublished "2020-09-08T21:35:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Fuzzy Unique Image Transformation: Defense Against Adversarial Attacks  On Deep COVID-19 Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.04004v1"^^schema:URL .

<152> a schema:ScholarlyArticle ;
    schema:abstract "We investigate the problem of learning representations that are invariant tocertain nuisance or sensitive factors of variation in the data while retainingas much of the remaining information as possible. Our model is based on avariational autoencoding architecture with priors that encourage independencebetween sensitive and latent factors of variation. Any subsequent processing,such as classification, can then be performed on this purged latentrepresentation. To remove any remaining dependencies we incorporate anadditional penalty term based on the \"Maximum Mean Discrepancy\" (MMD) measure.We discuss how these architectures can be efficiently trained on data and showin experiments that this method is more effective than previous work inremoving unwanted sources of variation while maintaining informative latentrepresentations."^^schema:Text ;
    schema:author "Christos Louizos"^^schema:Person,
        "Kevin Swersky"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Yujia Li"^^schema:Person ;
    schema:commentCount "225"^^schema:Integer ;
    schema:dateModified "2017-08-10T03:07:31Z"^^schema:DateTime ;
    schema:datePublished "2015-11-03T09:27:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Variational Fair Autoencoder"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.00830v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13824730458224470490&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1520> a schema:ScholarlyArticle ;
    schema:abstract "We present, for the first time, a novel deep neural network architecturecalled \\dcn with a dual-path connection between the input image and outputclass label for mammogram image processing. This architecture is built uponU-Net, which non-linearly maps the input data into a deep latent space. Onepath of the \\dcnn, the locality preserving learner, is devoted tohierarchically extracting and exploiting intrinsic features of the input, whilethe other path, called the conditional graph learner, focuses on modeling theinput-mask correlations. The learned mask is further used to improveclassification results, and the two learning paths complement each other. Byintegrating the two learners our new architecture provides a simple buteffective way to jointly learn the segmentation and predict the class label.Benefiting from the powerful expressive capacity of deep neural networks a morediscriminative representation can be learned, in which both the semantics andstructure are well preserved. Experimental results show that \\dcn achieves thebest mammography segmentation and classification simultaneously, outperformingrecent state-of-the-art models."^^schema:Text ;
    schema:author "Dave Laurenson"^^schema:Person,
        "Dongdong Chen"^^schema:Person,
        "Heyi Li"^^schema:Person,
        "Mike E. Davies"^^schema:Person,
        "William H. Nailon"^^schema:Person ;
    schema:dateModified "2019-03-01T11:51:47Z"^^schema:DateTime ;
    schema:datePublished "2019-03-01T11:51:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Deep DUAL-PATH Network for Improved Mammogram Image Processing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.00001v1"^^schema:URL .

<1521> a schema:ScholarlyArticle ;
    schema:abstract "The predictive power and overall computational efficiency ofDiffusion-convolutional neural networks make them an attractive choice for nodeclassification tasks. However, a naive dense-tensor-based implementation ofDCNNs leads to $\\mathcal{O}(N^2)$ memory complexity which is prohibitive forlarge graphs. In this paper, we introduce a simple method for thresholdinginput graphs that provably reduces memory requirements of DCNNs to O(N) (i.e.linear in the number of nodes in the input) without significantly affectingpredictive performance."^^schema:Text ;
    schema:author "Ananthram Swami"^^schema:Person,
        "Don Towsley"^^schema:Person,
        "James Atwood"^^schema:Person,
        "Siddharth Pal"^^schema:Person ;
    schema:dateModified "2017-10-26T17:16:14Z"^^schema:DateTime ;
    schema:datePublished "2017-10-26T17:16:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Sparse Diffusion-Convolutional Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.09813v1"^^schema:URL .

<1522> a schema:ScholarlyArticle ;
    schema:abstract "Neural Ordinary Differential Equations (ODEs) are elegant reinterpretationsof deep networks where continuous time can replace the discrete notion ofdepth, ODE solvers perform forward propagation, and the adjoint method enablesefficient, constant memory backpropagation. Neural ODEs are universalapproximators only when they are non-autonomous, that is, the dynamics dependsexplicitly on time. We propose a novel family of Neural ODEs with time-varyingweights, where time-dependence is non-parametric, and the smoothness of weighttrajectories can be explicitly controlled to allow a tradeoff betweenexpressiveness and efficiency. Using this enhanced expressiveness, weoutperform previous Neural ODE variants in both speed and representationalcapacity, ultimately outperforming standard ResNet and CNN models on selectimage classification and video prediction tasks."^^schema:Text ;
    schema:author "Adrian Weller"^^schema:Person,
        "Ameesh Makadia"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Jake Varley"^^schema:Person,
        "Jared Quincy Davis"^^schema:Person,
        "Jean-Jacques Slotine"^^schema:Person,
        "Krzysztof Choromanski"^^schema:Person,
        "Valerii Likhosterov"^^schema:Person,
        "Vikas Sindhwani"^^schema:Person ;
    schema:dateModified "2020-05-06T16:40:50Z"^^schema:DateTime ;
    schema:datePublished "2020-05-05T01:41:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Time Dependence in Non-Autonomous Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.01906v2"^^schema:URL .

<1523> a schema:ScholarlyArticle ;
    schema:abstract "This work presents Kornia, an open source computer vision library built upona set of differentiable routines and modules that aims to solve genericcomputer vision problems. The package uses PyTorch as its main backend, notonly for efficiency but also to take advantage of the reverseauto-differentiation engine to define and compute the gradient of complexfunctions. Inspired by OpenCV, Kornia is composed of a set of modulescontaining operators that can be integrated into neural networks to trainmodels to perform a wide range of operations including imagetransformations,camera calibration, epipolar geometry, and low level imageprocessing techniques, such as filtering and edge detection that operatedirectly on high dimensional tensor representations on graphical processingunits, generating faster systems. Examples of classical vision problemsimplemented using our framework are provided including a benchmark comparing toexisting vision libraries."^^schema:Text ;
    schema:author "D. Mishkin"^^schema:Person,
        "D. Ponsa"^^schema:Person,
        "E. Riba"^^schema:Person,
        "F. Moreno-Noguer"^^schema:Person,
        "G. Bradski"^^schema:Person,
        "J. Shi"^^schema:Person ;
    schema:dateModified "2020-09-21T08:48:28Z"^^schema:DateTime ;
    schema:datePublished "2020-09-21T08:48:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "A survey on Kornia: an Open Source Differentiable Computer Vision  Library for PyTorch"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.10521v1"^^schema:URL .

<1524> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have demonstrated their superior performance in almostevery Natural Language Processing task, however, their increasing complexityraises concerns. In particular, these networks require high expenses oncomputational hardware, and training budget is a concern for many. Even for atrained network, the inference phase can be too demanding forresource-constrained devices, thus limiting its applicability. Thestate-of-the-art transformer models are a vivid example. Simplifying thecomputations performed by a network is one way of relaxing the complexityrequirements. In this paper, we propose an end to end binarized neural networkarchitecture for the intent classification task. In order to fully utilize thepotential of end to end binarization, both input representations (vectorembeddings of tokens statistics) and the classifier are binarized. Wedemonstrate the efficiency of such architecture on the intent classification ofshort texts over three datasets and for text classification with a largerdataset. The proposed architecture achieves comparable to the state-of-the-artresults on standard intent classification datasets while utilizing ~ 20-40%lesser memory and training time. Furthermore, the individual components of thearchitecture, such as binarized vector embeddings of documents or binarizedclassifiers, can be used separately with not necessarily fully binaryarchitectures."^^schema:Text ;
    schema:author "Akshat Agarwal"^^schema:Person,
        "Denis Kleyko"^^schema:Person,
        "Harshil Jain"^^schema:Person,
        "Kumar Shridhar"^^schema:Person ;
    schema:dateModified "2020-10-11T11:21:53Z"^^schema:DateTime ;
    schema:datePublished "2020-10-11T11:21:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "End to End Binarized Neural Networks for Text Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.05223v1"^^schema:URL .

<1525> a schema:ScholarlyArticle ;
    schema:abstract "fairseq is an open-source sequence modeling toolkit that allows researchersand developers to train custom models for translation, summarization, languagemodeling, and other text generation tasks. The toolkit is based on PyTorch andsupports distributed training across multiple GPUs and machines. We alsosupport fast mixed-precision training and inference on modern GPUs. A demovideo can be found at https://www.youtube.com/watch?v=OtgDdWtHvto"^^schema:Text ;
    schema:author "Alexei Baevski"^^schema:Person,
        "Angela Fan"^^schema:Person,
        "David Grangier"^^schema:Person,
        "Michael Auli"^^schema:Person,
        "Myle Ott"^^schema:Person,
        "Nathan Ng"^^schema:Person,
        "Sam Gross"^^schema:Person,
        "Sergey Edunov"^^schema:Person ;
    schema:dateModified "2019-04-01T18:05:02Z"^^schema:DateTime ;
    schema:datePublished "2019-04-01T18:05:02Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.01038v1"^^schema:URL .

<1526> a schema:ScholarlyArticle ;
    schema:abstract "Batch normalization (BN) allows training very deep networks by normalizingactivations by mini-batch sample statistics which renders BN unstable for smallbatch sizes. Current small-batch solutions such as Instance Norm, Layer Norm,and Group Norm use channel statistics which can be computed even for a singlesample. Such methods are less stable than BN as they critically depend on thestatistics of a single input sample. To address this problem, we propose anormalization of activation without sample statistics. We present WeightAlign:a method that normalizes the weights by the mean and scaled standard derivationcomputed within a filter, which normalizes activations without computing anysample statistics. Our proposed method is independent of batch size and stableover a wide range of batch sizes. Because weight statistics are orthogonal tosample statistics, we can directly combine WeightAlign with any method foractivation normalization. We experimentally demonstrate these benefits forclassification on CIFAR-10, CIFAR-100, ImageNet, for semantic segmentation onPASCAL VOC 2012 and for domain adaptation on Office-31."^^schema:Text ;
    schema:author "Jan van Gemert"^^schema:Person,
        "Xiangwei Shi"^^schema:Person,
        "Xin Liu"^^schema:Person,
        "Yunqiang Li"^^schema:Person ;
    schema:dateModified "2020-10-14T15:25:39Z"^^schema:DateTime ;
    schema:datePublished "2020-10-14T15:25:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "WeightAlign: Normalizing Activations by Weight Alignment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07160v1"^^schema:URL .

<1527> a schema:ScholarlyArticle ;
    schema:abstract "When watching omnidirectional images (ODIs), subjects can access differentviewports by moving their heads. Therefore, it is necessary to predictsubjects' head fixations on ODIs. Inspired by generative adversarial imitationlearning (GAIL), this paper proposes a novel approach to predict saliency ofhead fixations on ODIs, named SalGAIL. First, we establish a dataset forattention on ODIs (AOI). In contrast to traditional datasets, our AOI datasetis large-scale, which contains the head fixations of 30 subjects viewing 600ODIs. Next, we mine our AOI dataset and determine three findings: (1) Theconsistency of head fixations are consistent among subjects, and it growsalongside the increased subject number; (2) The head fixations exist with afront center bias (FCB); and (3) The magnitude of head movement is similaracross subjects. According to these findings, our SalGAIL approach applies deepreinforcement learning (DRL) to predict the head fixations of one subject, inwhich GAIL learns the reward of DRL, rather than the traditional human-designedreward. Then, multi-stream DRL is developed to yield the head fixations ofdifferent subjects, and the saliency map of an ODI is generated via convolutingpredicted head fixations. Finally, experiments validate the effectiveness ofour approach in predicting saliency maps of ODIs, significantly better than 10state-of-the-art approaches."^^schema:Text ;
    schema:author "Li Yang"^^schema:Person,
        "Mai Xu"^^schema:Person,
        "Xiaoming Tao"^^schema:Person,
        "Yiping Duan"^^schema:Person,
        "Zulin Wang"^^schema:Person ;
    schema:dateModified "2019-04-15T14:36:40Z"^^schema:DateTime ;
    schema:datePublished "2019-04-15T14:36:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Saliency Prediction on Omnidirectional Images with Generative  Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.07080v1"^^schema:URL .

<1528> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Imitation Learning suffers from the fundamentalproblem of reward bias stemming from the choice of reward functions used in thealgorithm. Different types of biases also affect different types ofenvironments - which are broadly divided into survival and task-basedenvironments. We provide a theoretical sketch of why existing reward functionswould fail in imitation learning scenarios in task based environments withmultiple terminal states. We also propose a new reward function for GAIL whichoutperforms existing GAIL methods on task based environments with single andmultiple terminal states and effectively overcomes both survival andtermination bias."^^schema:Text ;
    schema:author "Katia Sycara"^^schema:Person,
        "Rohit Jena"^^schema:Person,
        "Siddharth Agrawal"^^schema:Person ;
    schema:dateModified "2020-09-20T16:24:10Z"^^schema:DateTime ;
    schema:datePublished "2020-09-20T16:24:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Addressing reward bias in Adversarial Imitation Learning with neutral  reward functions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.09467v1"^^schema:URL .

<1529> a schema:ScholarlyArticle ;
    schema:abstract "We introduce \\textbf{inverse modified differential equations} (IMDEs) tocontribute to the fundamental theory of discovery of dynamics. In particular,we investigate the IMDEs for the neural ordinary differential equations (neuralODEs). Training such a learning model actually returns an approximation of anIMDE, rather than the original system. Thus, the convergence analysis fordata-driven discovery is illuminated. The discrepancy of discovery depends onthe order of the integrator used. Furthermore, IMDEs make clear the behavior ofparameterizing some blocks in neural ODEs. We also perform several experimentsto numerically substantiate our theoretical results."^^schema:Text ;
    schema:author "Aiqing Zhu"^^schema:Person,
        "Pengzhan Jin"^^schema:Person,
        "Yifa Tang"^^schema:Person ;
    schema:dateModified "2020-09-10T11:50:32Z"^^schema:DateTime ;
    schema:datePublished "2020-09-02T13:30:16Z"^^schema:DateTime ;
    schema:genre "cs.NA"^^schema:Text,
        "math.NA"^^schema:Text ;
    schema:headline "Inverse modified differential equations for discovery of dynamics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.01058v2"^^schema:URL .

<153> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning classifiers are known to be vulnerable to inputs maliciouslyconstructed by adversaries to force misclassification. Such adversarialexamples have been extensively studied in the context of computer visionapplications. In this work, we show adversarial attacks are also effective whentargeting neural network policies in reinforcement learning. Specifically, weshow existing adversarial example crafting techniques can be used tosignificantly degrade test-time performance of trained policies. Our threatmodel considers adversaries capable of introducing small perturbations to theraw input of the policy. We characterize the degree of vulnerability acrosstasks and training algorithms, for a subclass of adversarial-example attacks inwhite-box and black-box settings. Regardless of the learned task or trainingalgorithm, we observe a significant drop in performance, even with smalladversarial perturbations that do not interfere with human perception. Videosare available at http://rll.berkeley.edu/adversarial."^^schema:Text ;
    schema:author "Ian Goodfellow"^^schema:Person,
        "Nicolas Papernot"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sandy Huang"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "256"^^schema:Integer ;
    schema:dateModified "2017-02-08T04:33:55Z"^^schema:DateTime ;
    schema:datePublished "2017-02-08T04:33:55Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Attacks on Neural Network Policies"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.02284v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1879545961701003590&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1530> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) for text generation have recentlyreceived many criticisms, as they perform worse than their MLE counterparts. Wesuspect previous text GANs' inferior performance is due to the lack of areliable guiding signal in their discriminators. To address this problem, wepropose a generative adversarial imitation learning framework for textgeneration that uses large pre-trained language models to provide more reliablereward guidance. Our approach uses contrastive discriminator, and proximalpolicy optimization (PPO) to stabilize and improve text generation performance.For evaluation, we conduct experiments on a diverse set of unconditional andconditional text generation tasks. Experimental results show that TextGAILachieves better performance in terms of both quality and diversity than the MLEbaseline. We also validate our intuition that TextGAIL's discriminatordemonstrates the capability of providing reasonable rewards with an additionaltask."^^schema:Text ;
    schema:author "Lei Li"^^schema:Person,
        "Qingyang Wu"^^schema:Person,
        "Zhou Yu"^^schema:Person ;
    schema:dateModified "2020-06-23T23:22:07Z"^^schema:DateTime ;
    schema:datePublished "2020-04-07T00:24:35Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "TextGAIL: Generative Adversarial Imitation Learning for Text Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.13796v2"^^schema:URL .

<1531> a schema:ScholarlyArticle ;
    schema:abstract "Value Iteration Networks (VINs) are effective differentiable path planningmodules that can be used by agents to perform navigation while stillmaintaining end-to-end differentiability of the entire architecture. Despitetheir effectiveness, they suffer from several disadvantages including traininginstability, random seed sensitivity, and other optimization problems. In thiswork, we reframe VINs as recurrent-convolutional networks which demonstratesthat VINs couple recurrent convolutions with an unconventional max-poolingactivation. From this perspective, we argue that standard gated recurrentupdate equations could potentially alleviate the optimization issues plaguingVIN. The resulting architecture, which we call the Gated Path Planning Network,is shown to empirically outperform VIN on a variety of metrics such as learningspeed, hyperparameter sensitivity, iteration count, and even generalization.Furthermore, we show that this performance gap is consistent across differentmaze transition types, maze sizes and even show success on a challenging 3Denvironment, where the planner is only provided with first-person RGB images."^^schema:Text ;
    schema:author "Devendra Singh Chaplot"^^schema:Person,
        "Emilio Parisotto"^^schema:Person,
        "Eric Xing"^^schema:Person,
        "Lisa Lee"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person ;
    schema:dateModified "2018-06-17T16:32:52Z"^^schema:DateTime ;
    schema:datePublished "2018-06-17T16:32:52Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gated Path Planning Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.06408v1"^^schema:URL .

<1532> a schema:ScholarlyArticle ;
    schema:abstract "Autonomous agents situated in real-world environments must be able to masterlarge repertoires of skills. While a single short skill can be learned quickly,it would be impractical to learn every task independently. Instead, the agentshould share knowledge across behaviors such that each task can be learnedefficiently, and such that the resulting model can generalize to new tasks,especially ones that are compositions or subsets of tasks seen previously. Apolicy conditioned on a goal or demonstration has the potential to shareknowledge between tasks if it sees enough diversity of inputs. However, thesemethods may not generalize to a more complex task at test time. We introducecompositional plan vectors (CPVs) to enable a policy to perform compositions oftasks without additional supervision. CPVs represent trajectories as the sum ofthe subtasks within them. We show that CPVs can be learned within a one-shotimitation learning framework without any additional supervision or informationabout task hierarchy, and enable a demonstration-conditioned policy togeneralize to tasks that sequence twice as many skills as the tasks seen duringtraining.  Analogously to embeddings such as word2vec in NLP, CPVs can also supportsimple arithmetic operations -- for example, we can add the CPVs for twodifferent tasks to command an agent to compose both tasks, without anyadditional training."^^schema:Text ;
    schema:author "Coline Devin"^^schema:Person,
        "Daniel Geng"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:dateModified "2020-08-02T01:00:16Z"^^schema:DateTime ;
    schema:datePublished "2019-10-30T17:50:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Plan Arithmetic: Compositional Plan Vectors for Multi-Task Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.14033v2"^^schema:URL .

<1533> a schema:ScholarlyArticle ;
    schema:abstract "While many recent works have studied the problem of algorithmic fairness fromthe perspective of predictions, here we investigate the fairness of recourseactions recommended to individuals to recover from an unfavourableclassification. To this end, we propose two new fairness criteria at the groupand individual level which---unlike prior work on equalising the averagedistance from the decision boundary across protected groups---are based on acausal framework that explicitly models relationships between input features,thereby allowing to capture downstream effects of recourse actions performed inthe physical world. We explore how our criteria relate to others, such ascounterfactual fairness, and show that fairness of recourse is complementary tofairness of prediction. We then investigate how to enforce fair recourse in thetraining of the classifier. Finally, we discuss whether fairness violations inthe data generating process revealed by our criteria may be better addressed bysocietal interventions and structural changes to the system, as opposed toconstraints on the classifier."^^schema:Text ;
    schema:author "Adrian Weller"^^schema:Person,
        "Amir-Hossein Karimi"^^schema:Person,
        "Bernhard Schölkopf"^^schema:Person,
        "Isabel Valera"^^schema:Person,
        "Julius von Kügelgen"^^schema:Person,
        "Umang Bhatt"^^schema:Person ;
    schema:dateModified "2020-10-14T09:48:33Z"^^schema:DateTime ;
    schema:datePublished "2020-10-13T16:35:06Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Fairness of Causal Algorithmic Recourse"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.06529v2"^^schema:URL .

<1534> a schema:ScholarlyArticle ;
    schema:abstract "Compared to reinforcement learning, imitation learning (IL) is a powerfulparadigm for training agents to learn control policies efficiently from expertdemonstrations. However, in most cases, obtaining demonstration data is costlyand laborious, which poses a significant challenge in some scenarios. Apromising alternative is to train agent learning skills via imitation learningwithout expert demonstrations, which, to some extent, would extremely expandimitation learning areas. To achieve such expectation, in this paper, wepropose Hindsight Generative Adversarial Imitation Learning (HGAIL) algorithm,with the aim of achieving imitation learning satisfying no need ofdemonstrations. Combining hindsight idea with the generative adversarialimitation learning (GAIL) framework, we realize implementing imitation learningsuccessfully in cases of expert demonstration data are not available.Experiments show that the proposed method can train policies showing comparableperformance to current imitation learning methods. Further more, HGAILessentially endows curriculum learning mechanism which is critical for learningpolicies."^^schema:Text ;
    schema:author "Boyao Li"^^schema:Person,
        "Naijun Liu"^^schema:Person,
        "Shuo Wang"^^schema:Person,
        "Tao Lu"^^schema:Person,
        "Yinghao Cai"^^schema:Person ;
    schema:dateModified "2019-03-19T06:16:56Z"^^schema:DateTime ;
    schema:datePublished "2019-03-19T06:16:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hindsight Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.07854v1"^^schema:URL .

<1535> a schema:ScholarlyArticle ;
    schema:abstract "The article describes the application of the Hough transform to a honeycombblock image. The problem of cutting a mold from a honeycomb block is described.A number of image transformations are considered to increase the efficiency ofthe Hough algorithm. A method for obtaining a binary image using a simplethreshold, a method for obtaining a binary image using Otsu binarization, andthe Canny Edge Detection algorithm are considered. The method of binaryskeleton (skeletonization) is considered, in which the skeleton is obtainedusing 2 main morphological operations: Dilation and Erosion. As a result of anumber of experiments, the optimal sequence of processing the original imagewas revealed, which allows obtaining the coordinates of the maximum number offaces. This result allows one to choose the optimal places for cutting ahoneycomb block, which will improve the quality of the resulting shapes."^^schema:Text ;
    schema:author "A S Kubrikova"^^schema:Person,
        "I A Paulin"^^schema:Person,
        "M V Kubrikov"^^schema:Person,
        "M V Saramud"^^schema:Person ;
    schema:dateModified "2020-10-26T18:48:46Z"^^schema:DateTime ;
    schema:datePublished "2020-10-26T18:48:46Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Application of sequential processing of computer vision methods for  solving the problem of detecting the edges of a honeycomb block"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13837v1"^^schema:URL .

<1536> a schema:ScholarlyArticle ;
    schema:abstract "Recently, a deep reinforcement learning method is proposed to solvemultiobjective optimization problem. In this method, the multiobjectiveoptimization problem is decomposed to a number of single-objective optimizationsubproblems and all the subproblems are optimized in a collaborative manner.Each subproblem is modeled with a pointer network and the model is trained withreinforcement learning. However, when pointer network extracts the features ofan instance, it ignores the underlying structure information of the inputnodes. Thus, this paper proposes a multiobjective deep reinforcement learningmethod using decomposition and attention model to solve multiobjectiveoptimization problem. In our method, each subproblem is solved by an attentionmodel, which can exploit the structure features as well as node features ofinput nodes. The experiment results on multiobjective travelling salesmanproblem show the proposed algorithm achieves better performance compared withthe previous method."^^schema:Text ;
    schema:author "Hong Wu"^^schema:Person,
        "Jiahai Wang"^^schema:Person,
        "Zizhen Zhang"^^schema:Person ;
    schema:dateModified "2020-02-13T12:59:39Z"^^schema:DateTime ;
    schema:datePublished "2020-02-13T12:59:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "MODRL/D-AM: Multiobjective Deep Reinforcement Learning Algorithm Using  Decomposition and Attention Model for Multiobjective Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.05484v1"^^schema:URL .

<1537> a schema:ScholarlyArticle ;
    schema:abstract "A large number of deep learning architectures use spatial transformations ofCNN feature maps or filters to better deal with variability in objectappearance caused by natural image transformations. In this paper, we provethat spatial transformations of CNN feature maps cannot align the feature mapsof a transformed image to match those of its original, for general affinetransformations, unless the extracted features are themselves invariant. Ourproof is based on elementary analysis for both the single- and multi-layernetwork case. The results imply that methods based on spatial transformationsof CNN feature maps or filters cannot replace image alignment of the input andcannot enable invariant recognition for general affine transformations,specifically not for scaling transformations or shear transformations. Forrotations and reflections, spatially transforming feature maps or filters canenable invariance but only for networks with learnt or hardcoded rotation- orreflection-invariant features"^^schema:Text ;
    schema:author "Lukas Finnveden"^^schema:Person,
        "Maksim Maydanskiy"^^schema:Person,
        "Tony Lindeberg"^^schema:Person,
        "Ylva Jansson"^^schema:Person ;
    schema:dateModified "2020-04-30T12:12:58Z"^^schema:DateTime ;
    schema:datePublished "2020-04-30T12:12:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Inability of spatial transformations of CNN feature maps to support  invariant recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.14716v1"^^schema:URL .

<1538> a schema:ScholarlyArticle ;
    schema:abstract "Recent sparse MRI reconstruction models have used Deep Neural Networks (DNNs)to reconstruct relatively high-quality images from highly undersampled k-spacedata, enabling much faster MRI scanning. However, these techniques sometimesstruggle to reconstruct sharp images that preserve fine detail whilemaintaining a natural appearance. In this work, we enhance the image quality byusing a Conditional Wasserstein Generative Adversarial Network combined with anovel Adaptive Gradient Balancing technique that stabilizes the training andminimizes the degree of artifacts, while maintaining a high-qualityreconstruction that produces sharper images than other techniques."^^schema:Text ;
    schema:author "Anne Menini"^^schema:Person,
        "Christopher J. Hardy"^^schema:Person,
        "Itzik Malkiel"^^schema:Person,
        "Lior Wolf"^^schema:Person,
        "Sangtae Ahn"^^schema:Person,
        "Valentina Taviani"^^schema:Person ;
    schema:dateModified "2019-05-02T22:26:06Z"^^schema:DateTime ;
    schema:datePublished "2019-05-02T22:26:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Conditional WGANs with Adaptive Gradient Balancing for Sparse MRI  Reconstruction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.00985v1"^^schema:URL .

<1539> a schema:ScholarlyArticle ;
    schema:abstract "The quantized neural networks (QNNs) can be useful for neural networkacceleration and compression, but during the training process they pose achallenge: how to propagate the gradient of loss function through the graphflow with a derivative of 0 almost everywhere. In response to thisnon-differentiable situation, we propose a novel Asymptotic-Quantized Estimator(AQE) to estimate the gradient. In particular, during back-propagation, thegraph that relates inputs to output remains smoothness and differentiability.At the end of training, the weights and activations have been quantized tolow-precision because of the asymptotic behaviour of AQE. Meanwhile, we proposea M-bit Inputs and N-bit Weights Network (MINW-Net) trained by AQE, a quantizedneural network with 1-3 bits weights and activations. In the inference phase,we can use XNOR or SHIFT operations instead of convolution operations toaccelerate the MINW-Net. Our experiments on CIFAR datasets demonstrate that ourAQE is well defined, and the QNNs with AQE perform better than that withStraight-Through Estimator (STE). For example, in the case of the same ConvNetthat has 1-bit weights and activations, our MINW-Net with AQE can achieve aprediction accuracy 1.5\\% higher than the Binarized Neural Network (BNN) withSTE. The MINW-Net, which is trained from scratch by AQE, can achieve comparableclassification accuracy as 32-bit counterparts on CIFAR test sets. Extensiveexperimental results on ImageNet dataset show great superiority of the proposedAQE and our MINW-Net achieves comparable results with other state-of-the-artQNNs."^^schema:Text ;
    schema:author "Hao Zhang"^^schema:Person,
        "Jian Yang"^^schema:Person,
        "Jun Chen"^^schema:Person,
        "Shengnan Hou"^^schema:Person,
        "Yong Liu"^^schema:Person ;
    schema:dateModified "2020-03-04T03:17:47Z"^^schema:DateTime ;
    schema:datePublished "2020-03-04T03:17:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Propagating Asymptotic-Estimated Gradients for Low Bitwidth Quantized  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.04296v1"^^schema:URL .

<154> a schema:ScholarlyArticle ;
    schema:abstract "Machine comprehension of text is an important problem in natural languageprocessing. A recently released dataset, the Stanford Question AnsweringDataset (SQuAD), offers a large number of real questions and their answerscreated by humans through crowdsourcing. SQuAD provides a challenging testbedfor evaluating machine comprehension algorithms, partly because compared withprevious datasets, in SQuAD the answers do not come from a small set ofcandidate answers and they have variable lengths. We propose an end-to-endneural architecture for the task. The architecture is based on match-LSTM, amodel we proposed previously for textual entailment, and Pointer Net, asequence-to-sequence model proposed by Vinyals et al.(2015) to constrain theoutput tokens to be from the input sequences. We propose two ways of usingPointer Net for our task. Our experiments show that both of our two modelssubstantially outperform the best results obtained by Rajpurkar et al.(2016)using logistic regression and manually crafted features."^^schema:Text ;
    schema:author "Jing Jiang"^^schema:Person,
        "Shuohang Wang"^^schema:Person ;
    schema:commentCount "370"^^schema:Integer ;
    schema:dateModified "2016-11-07T03:39:40Z"^^schema:DateTime ;
    schema:datePublished "2016-08-29T03:42:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Machine Comprehension Using Match-LSTM and Answer Pointer"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.07905v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8536399820764102165&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1540> a schema:ScholarlyArticle ;
    schema:abstract "We propose Neural Image Compression (NIC), a two-step method to buildconvolutional neural networks for gigapixel image analysis solely using weakimage-level labels. First, gigapixel images are compressed using a neuralnetwork trained in an unsupervised fashion, retaining high-level informationwhile suppressing pixel-level noise. Second, a convolutional neural network(CNN) is trained on these compressed image representations to predictimage-level labels, avoiding the need for fine-grained manual annotations. Wecompared several encoding strategies, namely reconstruction error minimization,contrastive training and adversarial feature learning, and evaluated NIC on asynthetic task and two public histopathology datasets. We found that NIC canexploit visual cues associated with image-level labels successfully,integrating both global and local visual information. Furthermore, wevisualized the regions of the input gigapixel images where the CNN attended to,and confirmed that they overlapped with annotations from human experts."^^schema:Text ;
    schema:author "David Tellez"^^schema:Person,
        "Francesco Ciompi"^^schema:Person,
        "Geert Litjens"^^schema:Person,
        "Jeroen van der Laak"^^schema:Person ;
    schema:dateModified "2020-04-15T13:25:07Z"^^schema:DateTime ;
    schema:datePublished "2018-11-07T11:29:34Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Neural Image Compression for Gigapixel Histopathology Image Analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.02840v2"^^schema:URL .

<1541> a schema:ScholarlyArticle ;
    schema:abstract "Fair classification has become an important topic in machine learningresearch. While most bias mitigation strategies focus on neural networks, wenoticed a lack of work on fair classifiers based on decision trees even thoughthey have proven very efficient. In an up-to-date comparison ofstate-of-the-art classification algorithms in tabular data, tree boostingoutperforms deep learning. For this reason, we have developed a novel approachof adversarial gradient tree boosting. The objective of the algorithm is topredict the output $Y$ with gradient tree boosting while minimizing the abilityof an adversarial neural network to predict the sensitive attribute $S$. Theapproach incorporates at each iteration the gradient of the neural networkdirectly in the gradient tree boosting. We empirically assess our approach on 4popular data sets and compare against state-of-the-art algorithms. The resultsshow that our algorithm achieves a higher accuracy while obtaining the samelevel of fairness, as measured using a set of different common fairnessdefinitions."^^schema:Text ;
    schema:author "Boris Ruf"^^schema:Person,
        "Marcin Detyniecki"^^schema:Person,
        "Sylvain Lamprier"^^schema:Person,
        "Vincent Grari"^^schema:Person ;
    schema:dateModified "2019-11-18T10:28:37Z"^^schema:DateTime ;
    schema:datePublished "2019-11-13T09:43:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Fair Adversarial Gradient Tree Boosting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.05369v2"^^schema:URL .

<1542> a schema:ScholarlyArticle ;
    schema:abstract "Using the multilayer convolutional neural network (CNN), we can detect thequantum phases in random electron systems, and phase diagrams of two and higherdimensional Anderson transitions and quantum percolations as well as disorderedtopological systems have been obtained. Here, instead of using CNN to analyzethe wave functions, we analyze the dynamics of wave packets via long short-termmemory network (LSTM). We adopt the quasi-periodic quantum kicked rotors, whichsimulate the three and four dimensional Anderson transitions. By supervisedtraining, we let LSTM extract the features of the time series of wave packetdisplacements in localized and delocalized phases. We then simulate the wavepackets in unknown phases and let LSTM classify the time series to localizedand delocalized phases. We compare the phase diagrams obtained by LSTM andthose obtained by CNN."^^schema:Text ;
    schema:author "Tomi Ohtsuki"^^schema:Person,
        "Tomohiro Mano"^^schema:Person ;
    schema:dateModified "2021-01-23T06:45:06Z"^^schema:DateTime ;
    schema:datePublished "2021-01-23T06:45:06Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "cond-mat.mes-hall"^^schema:Text ;
    schema:headline "Machine learning the dynamics of quantum kicked rotor"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.09432v1"^^schema:URL .

<1543> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of learning efficient and inductive graphconvolutional networks for text classification with a large number of examplesand features. Existing state-of-the-art graph embedding based methods such aspredictive text embedding (PTE) and TextGCN have shortcomings in terms ofpredictive performance, scalability and inductive capability. To address theselimitations, we propose a heterogeneous graph convolutional network (HeteGCN)modeling approach that unites the best aspects of PTE and TextGCN together. Themain idea is to learn feature embeddings and derive document embeddings using aHeteGCN architecture with different graphs used across layers. We simplifyTextGCN by dissecting into several HeteGCN models which (a) helps to study theusefulness of individual models and (b) offers flexibility in fusing learnedembeddings from different models. In effect, the number of model parameters isreduced significantly, enabling faster training and improving performance insmall labeled training set scenario. Our detailed experimental studiesdemonstrate the efficacy of the proposed approach."^^schema:Text ;
    schema:author "Arun Iyer"^^schema:Person,
        "Rahul Ragesh"^^schema:Person,
        "Ram Bairi"^^schema:Person,
        "Sundararajan Sellamanickam"^^schema:Person,
        "Vijay Lingam"^^schema:Person ;
    schema:dateModified "2020-08-19T12:24:35Z"^^schema:DateTime ;
    schema:datePublished "2020-08-19T12:24:35Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "HeteGCN: Heterogeneous Graph Convolutional Networks for Text  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.12842v1"^^schema:URL .

<1544> a schema:ScholarlyArticle ;
    schema:abstract "We present a virtual image refocusing method over an extended depth of field(DOF) enabled by cascaded neural networks and a double-helix point-spreadfunction (DH-PSF). This network model, referred to as W-Net, is composed of twocascaded generator and discriminator network pairs. The first generator networklearns to virtually refocus an input image onto a user-defined plane, while thesecond generator learns to perform a cross-modality image transformation,improving the lateral resolution of the output image. Using this W-Net modelwith DH-PSF engineering, we extend the DOF of a fluorescence microscope by~20-fold. This approach can be applied to develop deep learning-enabled imagereconstruction methods for localization microscopy techniques that utilizeengineered PSFs to improve their imaging performance, including spatialresolution and volumetric imaging throughput."^^schema:Text ;
    schema:author "Aydogan Ozcan"^^schema:Person,
        "Hongda Wang"^^schema:Person,
        "Luzhe Huang"^^schema:Person,
        "Xilin Yang"^^schema:Person,
        "Yair Rivenson"^^schema:Person,
        "Yichen Wu"^^schema:Person,
        "Yilin Luo"^^schema:Person ;
    schema:dateModified "2020-12-22T09:15:26Z"^^schema:DateTime ;
    schema:datePublished "2020-12-22T09:15:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "physics.optics"^^schema:Text ;
    schema:headline "Deep learning-based virtual refocusing of images using an engineered  point-spread function"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11892v1"^^schema:URL .

<1545> a schema:ScholarlyArticle ;
    schema:abstract "We present a simple regularisation of Adversarial Perturbations based uponthe perceptual loss. While the resulting perturbations remain imperceptible tothe human eye, they differ from existing adversarial perturbations in twoimportant regards: (i) our resulting perturbations are semi-sparse, andtypically make alterations to objects and regions of interest leaving thebackground static; (ii) our perturbations do not alter the distribution of datain the image and are undetectable by state-of-the-art methods. As such thiswork reinforces the connection between explainable AI and adversarialperturbations. We demonstrate the merits of our approach by evaluating onstandard explainability benchmark and by defeating a recent test for detectingadversarial perturbations."^^schema:Text ;
    schema:author "Andrew Elliott"^^schema:Person,
        "Chris Russell"^^schema:Person,
        "Stephen Law"^^schema:Person ;
    schema:dateModified "2020-05-21T18:50:43Z"^^schema:DateTime ;
    schema:datePublished "2019-12-19T17:25:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Perturbations on the Perceptual Ball"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.09405v3"^^schema:URL .

<1546> a schema:ScholarlyArticle ;
    schema:abstract "Unitary Evolution Recurrent Neural Networks (uRNNs) have three attractiveproperties: (a) the unitary property, (b) the complex-valued nature, and (c)their efficient linear operators. The literature so far does not address -- howcritical is the unitary property of the model? Furthermore, uRNNs have not beenevaluated on large tasks. To study these shortcomings, we propose the complexevolution Recurrent Neural Networks (ceRNNs), which is similar to uRNNs butdrops the unitary property selectively. On a simple multivariate linearregression task, we illustrate that dropping the constraints improves thelearning trajectory. In copy memory task, ceRNNs and uRNNs perform identically,demonstrating that their superior performance over LSTMs is due tocomplex-valued nature and their linear operators. In a large scale real-worldspeech recognition, we find that pre-pending a uRNN degrades the performance ofour baseline LSTM acoustic models, while pre-pending a ceRNN improves theperformance over the baseline by 0.8% absolute WER."^^schema:Text ;
    schema:author "Izhak Shafran"^^schema:Person,
        "R. J. Skerry-Ryan"^^schema:Person,
        "Tom Bagby"^^schema:Person ;
    schema:dateModified "2019-06-05T18:51:26Z"^^schema:DateTime ;
    schema:datePublished "2019-06-05T18:51:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Complex Evolution Recurrent Neural Networks (ceRNNs)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02246v1"^^schema:URL .

<1547> a schema:ScholarlyArticle ;
    schema:abstract "Automatic industrial scheduling, aiming at optimizing the sequence of jobsover limited resources, is widely needed in manufacturing industries. However,existing scheduling systems heavily rely on heuristic algorithms, which eithergenerate ineffective solutions or compute inefficiently when job scaleincreases. Thus, it is of great importance to develop new large-scalealgorithms that are not only efficient and effective, but also capable ofsatisfying complex constraints in practice. In this paper, we propose a BilevelDeep reinforcement learning Scheduler, \\textit{BDS}, in which the higher levelis responsible for exploring an initial global sequence, whereas the lowerlevel is aiming at exploitation for partial sequence refinements, and the twolevels are connected by a sliding-window sampling mechanism. In theimplementation, a Double Deep Q Network (DDQN) is used in the upper level andGraph Pointer Network (GPN) lies within the lower level. After the theoreticalguarantee for the convergence of BDS, we evaluate it in an industrial automaticwarehouse scenario, with job number up to $5000$ in each production line. It isshown that our proposed BDS significantly outperforms two most used heuristics,three strong deep networks, and another bilevel baseline approach. Inparticular, compared with the most used greedy-based heuristic algorithm inreal world which takes nearly an hour, our BDS can decrease the makespan by27.5\\%, 28.6\\% and 22.1\\% for 3 largest datasets respectively, withcomputational time less than 200 seconds."^^schema:Text ;
    schema:author "Dirk Schnieders"^^schema:Person,
        "Hui-Ling Zhen"^^schema:Person,
        "Jia Zeng"^^schema:Person,
        "Jiawen Lu"^^schema:Person,
        "Jun Wang"^^schema:Person,
        "Longkang Li"^^schema:Person,
        "Mingxuan Yuan"^^schema:Person,
        "XialiangTong"^^schema:Person ;
    schema:dateModified "2020-08-10T13:46:28Z"^^schema:DateTime ;
    schema:datePublished "2020-08-10T13:46:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Bilevel Learning Model Towards Industrial Scheduling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.04130v1"^^schema:URL .

<1548> a schema:ScholarlyArticle ;
    schema:abstract "In addition to accuracy, fairness and robustness are two critical concernsfor federated learning systems. In this work, we first identify that robustnessto adversarial training-time attacks and fairness, measured as the uniformityof performance across devices, are competing constraints in statisticallyheterogeneous networks. To address these constraints, we propose employing asimple, general multi-task learning objective, and analyze the ability of theobjective to achieve a favorable tradeoff between fairness and robustness. Wedevelop a scalable solver for the objective and show that multi-task learningcan enable more accurate, robust, and fair models relative to state-of-the-artbaselines across a suite of federated datasets."^^schema:Text ;
    schema:author "Ahmad Beirami"^^schema:Person,
        "Shengyuan Hu"^^schema:Person,
        "Tian Li"^^schema:Person,
        "Virginia Smith"^^schema:Person ;
    schema:dateModified "2020-12-08T05:15:39Z"^^schema:DateTime ;
    schema:datePublished "2020-12-08T05:15:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Federated Multi-Task Learning for Competing Constraints"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.04221v1"^^schema:URL .

<1549> a schema:ScholarlyArticle ;
    schema:abstract "We are concerned with a worst-case scenario in model generalization, in thesense that a model aims to perform well on many unseen domains while there isonly one single domain available for training. We propose a new method namedadversarial domain augmentation to solve this Out-of-Distribution (OOD)generalization problem. The key idea is to leverage adversarial training tocreate \"fictitious\" yet \"challenging\" populations, from which a model can learnto generalize with theoretical guarantees. To facilitate fast and desirabledomain augmentation, we cast the model training in a meta-learning scheme anduse a Wasserstein Auto-Encoder (WAE) to relax the widely used worst-caseconstraint. Detailed theoretical analysis is provided to testify ourformulation, while extensive experiments on multiple benchmark datasetsindicate its superior performance in tackling single domain generalization."^^schema:Text ;
    schema:author "Fengchun Qiao"^^schema:Person,
        "Long Zhao"^^schema:Person,
        "Xi Peng"^^schema:Person ;
    schema:dateModified "2020-03-30T04:39:53Z"^^schema:DateTime ;
    schema:datePublished "2020-03-30T04:39:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Learn Single Domain Generalization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.13216v1"^^schema:URL .

<155> a schema:ScholarlyArticle ;
    schema:abstract "This article presents the prediction difference analysis method forvisualizing the response of a deep neural network to a specific input. Whenclassifying images, the method highlights areas in a given input image thatprovide evidence for or against a certain class. It overcomes severalshortcoming of previous methods and provides great additional insight into thedecision making process of classifiers. Making neural network decisionsinterpretable through visualization is important both to improve models and toaccelerate the adoption of black-box classifiers in application areas such asmedicine. We illustrate the method in experiments on natural images (ImageNetdata), as well as medical images (MRI brain scans)."^^schema:Text ;
    schema:author "Luisa M Zintgraf"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Taco S Cohen"^^schema:Person,
        "Tameem Adel"^^schema:Person ;
    schema:commentCount "256"^^schema:Integer ;
    schema:dateModified "2017-02-15T13:25:26Z"^^schema:DateTime ;
    schema:datePublished "2017-02-15T13:25:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Visualizing Deep Neural Network Decisions: Prediction Difference  Analysis"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.04595v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13321146675816614452&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1550> a schema:ScholarlyArticle ;
    schema:abstract "Motivated by the human way of memorizing images we introduce their functionalrepresentation, where an image is represented by a neural network. For thispurpose, we construct a hypernetwork which takes an image and returns weightsto the target network, which maps point from the plane (representing positionsof the pixel) into its corresponding color in the image. Since the obtainedrepresentation is continuous, one can easily inspect the image at variousresolutions and perform on it arbitrary continuous operations. Moreover, byinspecting interpolations we show that such representation has some propertiescharacteristic to generative models. To evaluate the proposed mechanismexperimentally, we apply it to image super-resolution problem. Despite using asingle model for various scaling factors, we obtained results comparable toexisting super-resolution methods."^^schema:Text ;
    schema:author "Jacek Tabor"^^schema:Person,
        "Jakub Nowak"^^schema:Person,
        "Maciej Wołczyk"^^schema:Person,
        "Marek Śmieja"^^schema:Person,
        "Sylwester Klocek"^^schema:Person,
        "Łukasz Maziarka"^^schema:Person ;
    schema:dateModified "2019-06-03T13:11:41Z"^^schema:DateTime ;
    schema:datePublished "2019-02-27T09:12:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hypernetwork functional image representation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.10404v3"^^schema:URL .

<1551> a schema:ScholarlyArticle ;
    schema:abstract "Turing machine and decision tree have developed independently for a longtime. With the recent development of differentiable models, there is anintersection between them. Neural turing machine(NTM) opens door for the memorynetwork. It use differentiable attention mechanism to read/write externalmemory bank. Differentiable forest brings differentiable properties toclassical decision tree. In this short note, we show the deep connectionbetween these two models. That is: differentiable forest is a special case ofNTM. Differentiable forest is actually decision tree based neural turingmachine. Based on this deep connection, we propose a response augmenteddifferential forest (RaDF). The controller of RaDF is differentiable forest,the external memory of RaDF are response vectors which would be read/write byleaf nodes."^^schema:Text ;
    schema:author "Yingshi Chen"^^schema:Person ;
    schema:dateModified "2020-10-27T01:39:09Z"^^schema:DateTime ;
    schema:datePublished "2020-10-27T01:39:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A short note on the decision tree based neural turing machine"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.14753v1"^^schema:URL .

<1552> a schema:ScholarlyArticle ;
    schema:abstract "Identifying and locating diseases in chest X-rays are very challenging, dueto the low visual contrast between normal and abnormal regions, and distortionscaused by other overlapping tissues. An interesting phenomenon is that thereexist many similar structures in the left and right parts of the chest, such asribs, lung fields and bronchial tubes. This kind of similarities can be used toidentify diseases in chest X-rays, according to the experience ofbroad-certificated radiologists. Aimed at improving the performance of existingdetection methods, we propose a deep end-to-end module to exploit thecontralateral context information for enhancing feature representations ofdisease proposals. First of all, under the guidance of the spine line, thespatial transformer network is employed to extract local contralateral patches,which can provide valuable context information for disease proposals. Then, webuild up a specific module, based on both additive and subtractive operations,to fuse the features of the disease proposal and the contralateral patch. Ourmethod can be integrated into both fully and weakly supervised diseasedetection frameworks. It achieves 33.17 AP50 on a carefully annotated privatechest X-ray dataset which contains 31,000 images. Experiments on the NIH chestX-ray dataset indicate that our method achieves state-of-the-art performance inweakly-supervised disease localization."^^schema:Text ;
    schema:author "Chaowei Fang"^^schema:Person,
        "Gangming Zhao"^^schema:Person,
        "Guanbin Li"^^schema:Person,
        "Licheng Jiao"^^schema:Person,
        "Yizhou Yu"^^schema:Person ;
    schema:dateModified "2020-10-09T10:15:26Z"^^schema:DateTime ;
    schema:datePublished "2020-10-09T10:15:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Contralaterally Enhanced Networks for Thoracic Disease Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.04483v1"^^schema:URL .

<1553> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning has led to tremendous advancements in the field of ArtificialIntelligence. One caveat however is the substantial amount of compute needed totrain these deep learning models. Training a benchmark dataset like ImageNet ona single machine with a modern GPU can take upto a week, distributing trainingon multiple machines has been observed to drastically bring this time down.Recent work has brought down ImageNet training time to a time as low as 4minutes by using a cluster of 2048 GPUs. This paper surveys the variousalgorithms and techniques used to distribute training and presents the currentstate of the art for a modern distributed training framework. Morespecifically, we explore the synchronous and asynchronous variants ofdistributed Stochastic Gradient Descent, various All Reduce gradientaggregation strategies and best practices for obtaining higher throughout andlower latency over a cluster such as mixed precision training, large batchtraining and gradient compression."^^schema:Text ;
    schema:author "Karanbir Chahal"^^schema:Person,
        "Kuntal Dey"^^schema:Person,
        "Manraj Singh Grover"^^schema:Person ;
    schema:dateModified "2018-10-28T09:37:47Z"^^schema:DateTime ;
    schema:datePublished "2018-10-28T09:37:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.11787v1"^^schema:URL .

<1554> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, the graph attention network (GAT) is firstly utilized for thechannel estimation. In accordance with the 6G expectations, we consider ahigh-altitude platform station (HAPS) mounted reconfigurable intelligentsurface-assisted two-way communications and obtain a low overhead and a highnormalized mean square error performance. The performance of the proposedmethod is investigated on the two-way backhauling link over the RIS-integratedHAPS. The simulation results denote that the GAT estimator overperforms theleast square in full-duplex channel estimation. Contrary to the previouslyintroduced methods, GAT at one of the nodes can separately estimate thecascaded channel coefficients. Thus, there is no need to use time-divisionduplex mode during pilot signaling in full-duplex communication. Moreover, itis shown that the GAT estimator is robust to hardware imperfections and changesin small scale fading characteristics even if the training data do not includeall these variations."^^schema:Text ;
    schema:author "Ali Rıza Ekti"^^schema:Person,
        "Chongwen Huang"^^schema:Person,
        "Güneş Karabulut Kurt"^^schema:Person,
        "Halim Yanikomeroglu"^^schema:Person,
        "Kürşat Tekbıyık"^^schema:Person ;
    schema:dateModified "2020-10-22T19:45:52Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T19:45:52Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Channel Estimation for Full-Duplex RIS-assisted HAPS Backhauling with  Graph Attention Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.12004v1"^^schema:URL .

<1555> a schema:ScholarlyArticle ;
    schema:abstract "mRNA vaccines are receiving increased interest as potential alternatives toconventional methods for the prevention of several diseases, includingCovid-19. This paper proposes and evaluates three deep learning models (LongShort Term Memory networks, Gated Recurrent Unit networks, and GraphConvolutional Networks) as a method to predict the stability/reactivity andrisk of degradation of sequences of RNA. Reasonably accurate results were ableto be generated, with the Graph Convolutional Network being the best predictorof reactivity (RMSE = 0.249) while the Gated Recurrent Unit Network was thebest at predicting risks of degradation under various circumstances (RMSE =0.266). Results suggest feasibility of applying such methods in mRNA vaccineresearch in the near future."^^schema:Text ;
    schema:author "Ankit Singhal"^^schema:Person ;
    schema:dateModified "2020-11-09T10:42:53Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T10:42:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.QM"^^schema:Text ;
    schema:headline "Application and Comparison of Deep Learning Methods in the Prediction of  RNA Sequence Degradation and Stability"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05136v1"^^schema:URL .

<1556> a schema:ScholarlyArticle ;
    schema:abstract "ViZDoom is a robust, first-person shooter reinforcement learning environment,characterized by a significant degree of latent state information. In thispaper, double-Q learning and prioritized experience replay methods are testedunder a certain ViZDoom combat scenario using a competitive deep recurrentQ-network (DRQN) architecture. In addition, an ensembling technique known assnapshot ensembling is employed using a specific annealed learning rate toobserve differences in ensembling efficacy under these two methods. Annealedlearning rates are important in general to the training of deep neural networkmodels, as they shake up the status-quo and counter a model's tending towardslocal optima. While both variants show performance exceeding those of built-inAI agents of the game, the known stabilizing effects of double-Q learning areillustrated, and priority experience replay is again validated in itsusefulness by showing immediate results early on in agent development, with thecaveat that value overestimation is accelerated in this case. In addition, someunique behaviors are observed to develop for priority experience replay (PER)and double-Q (DDQ) variants, and snapshot ensembling of both PER and DDQ provesa valuable method for improving performance of the ViZDoom Marine."^^schema:Text ;
    schema:author "Christopher Schulze"^^schema:Person,
        "Marcus Schulze"^^schema:Person ;
    schema:dateModified "2018-01-03T13:49:08Z"^^schema:DateTime ;
    schema:datePublished "2018-01-03T13:49:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "ViZDoom: DRQN with Prioritized Experience Replay, Double-Q Learning, &amp;  Snapshot Ensembling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.01000v1"^^schema:URL .

<1557> a schema:ScholarlyArticle ;
    schema:abstract "Semantic segmentation has achieved remarkable results with high computationalcost and a large number of parameters. However, real-world applications requireefficient inference speed on embedded devices. Most previous works address thechallenge by reducing depth, width and layer capacity of network, which leadsto poor performance. In this paper, we introduce a novel Dense Dual-PathNetwork (DDPNet) for real-time semantic segmentation under resourceconstraints. We design a light-weight and powerful backbone with denseconnectivity to facilitate feature reuse throughout the whole network and theproposed Dual-Path module (DPM) to sufficiently aggregate multi-scale contexts.Meanwhile, a simple and effective framework is built with a skip architectureutilizing the high-resolution feature maps to refine the segmentation outputand an upsampling module leveraging context information from the feature mapsto refine the heatmaps. The proposed DDPNet shows an obvious advantage inbalancing accuracy and speed. Specifically, on Cityscapes test dataset, DDPNetachieves 75.3% mIoU with 52.6 FPS for an input of 1024 X 2048 resolution on asingle GTX 1080Ti card. Compared with other state-of-the-art methods, DDPNetachieves a significant better accuracy with a comparable speed and fewerparameters."^^schema:Text ;
    schema:author "Feilin Liu"^^schema:Person,
        "Junqiao Zhao"^^schema:Person,
        "Xinneng Yang"^^schema:Person,
        "Yan Wu"^^schema:Person ;
    schema:dateModified "2020-10-21T06:11:41Z"^^schema:DateTime ;
    schema:datePublished "2020-10-21T06:11:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Dense Dual-Path Network for Real-time Semantic Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.10778v1"^^schema:URL .

<1558> a schema:ScholarlyArticle ;
    schema:abstract "Successful applications of deep learning (DL) requires large amount ofannotated data. This often restricts the benefits of employing DL to businessesand individuals with large budgets for data-collection and computation.Summarization offers a possible solution by creating much smallerrepresentative datasets that can allow real-time deep learning and analysis ofbig data and thus democratize use of DL. In the proposed work, our aim is toexplore a novel approach to task-specific image corpus summarization usingsemantic information and self-supervision. Our method uses aclassification-based Wasserstein generative adversarial network (CLSWGAN) as afeature generating network. The model also leverages rotational invariance asself-supervision and classification on another task. All these objectives areadded on a features from resnet34 to make it discriminative and robust. Themodel then generates a summary at inference time by using K-means clustering inthe semantic embedding space. Thus, another main advantage of this model isthat it does not need to be retrained each time to obtain summaries ofdifferent lengths which is an issue with current end-to-end models. We alsotest our model efficacy by means of rigorous experiments both qualitatively andquantitatively."^^schema:Text ;
    schema:author "Anurag Singh"^^schema:Person,
        "Deepak Kumar Sharma"^^schema:Person,
        "Sudhir Kumar Sharma"^^schema:Person ;
    schema:dateModified "2021-01-01T08:58:35Z"^^schema:DateTime ;
    schema:datePublished "2020-12-19T10:58:04Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Self-Supervision based Task-Specific Image Collection Summarization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.10657v4"^^schema:URL .

<1559> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we study counterfactual fairness in text classification, whichasks the question: How would the prediction change if the sensitive attributereferenced in the example were different? Toxicity classifiers demonstrate acounterfactual fairness issue by predicting that \"Some people are gay\" is toxicwhile \"Some people are straight\" is nontoxic. We offer a metric, counterfactualtoken fairness (CTF), for measuring this particular form of fairness in textclassifiers, and describe its relationship with group fairness. Further, weoffer three approaches, blindness, counterfactual augmentation, andcounterfactual logit pairing (CLP), for optimizing counterfactual tokenfairness during training, bridging the robustness and fairness literature.Empirically, we find that blindness and CLP address counterfactual tokenfairness. The methods do not harm classifier performance, and have varyingtradeoffs with group fairness. These approaches, both for measurement andoptimization, provide a new path forward for addressing fairness concerns intext classification."^^schema:Text ;
    schema:author "Alex Beutel"^^schema:Person,
        "Ankur Taly"^^schema:Person,
        "Ed H. Chi"^^schema:Person,
        "Nicole Limtiaco"^^schema:Person,
        "Sahaj Garg"^^schema:Person,
        "Vincent Perot"^^schema:Person ;
    schema:dateModified "2019-02-13T19:09:40Z"^^schema:DateTime ;
    schema:datePublished "2018-09-27T16:21:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Counterfactual Fairness in Text Classification through Robustness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10610v2"^^schema:URL .

<156> a schema:ScholarlyArticle ;
    schema:abstract "Even though active learning forms an important pillar of machine learning,deep learning tools are not prevalent within it. Deep learning poses severaldifficulties when used in an active learning setting. First, active learning(AL) methods generally rely on being able to learn and update models from smallamounts of data. Recent advances in deep learning, on the other hand, arenotorious for their dependence on large amounts of data. Second, many ALacquisition functions rely on model uncertainty, yet deep learning methodsrarely represent such model uncertainty. In this paper we combine recentadvances in Bayesian deep learning into the active learning framework in apractical way. We develop an active learning framework for high dimensionaldata, a task which has been extremely challenging so far, with very sparseexisting literature. Taking advantage of specialised models such as Bayesianconvolutional neural networks, we demonstrate our active learning techniqueswith image data, obtaining a significant improvement on existing activelearning approaches. We demonstrate this on both the MNIST dataset, as well asfor skin cancer diagnosis from lesion images (ISIC2016 task)."^^schema:Text ;
    schema:author "Riashat Islam"^^schema:Person,
        "Yarin Gal"^^schema:Person,
        "Zoubin Ghahramani"^^schema:Person ;
    schema:commentCount "339"^^schema:Integer ;
    schema:dateModified "2017-03-08T16:53:57Z"^^schema:DateTime ;
    schema:datePublished "2017-03-08T16:53:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Bayesian Active Learning with Image Data"^^schema:Text ;
    schema:publisher "ICML, 1183-1192"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.02910v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14700234482257382078&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1560> a schema:ScholarlyArticle ;
    schema:abstract "Optimal symbol detection for multiple-input multiple-output (MIMO) systems isknown to be an NP-hard problem. Conventional heuristic algorithms are eithertoo complex to be practical or suffer from poor performance. Recently, severalapproaches tried to address those challenges by implementing the detector as adeep neural network. However, they either still achieve unsatisfyingperformance on practical spatially correlated channels, or are computationallydemanding since they require retraining for each channel realization. In thiswork, we address both issues by training an additional neural network (NN),referred to as the hypernetwork, which takes as input the channel matrix andgenerates the weights of the neural NN-based detector. Results show that theproposed approach achieves near state-of-the-art performance without the needfor re-training."^^schema:Text ;
    schema:author "Fayçal Ait Aoudia"^^schema:Person,
        "Jakob Hoydis"^^schema:Person,
        "Mathieu Goutay"^^schema:Person ;
    schema:dateModified "2020-02-10T07:45:45Z"^^schema:DateTime ;
    schema:datePublished "2020-02-07T13:03:22Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Deep HyperNetwork-Based MIMO Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.02750v2"^^schema:URL .

<1561> a schema:ScholarlyArticle ;
    schema:abstract "Without real bilingual corpus available, unsupervised Neural MachineTranslation (NMT) typically requires pseudo parallel data generated with theback-translation method for the model training. However, due to weaksupervision, the pseudo data inevitably contain noises and errors that will beaccumulated and reinforced in the subsequent training process, leading to badtranslation performance. To address this issue, we introduce phrase basedStatistic Machine Translation (SMT) models which are robust to noisy data, asposterior regularizations to guide the training of unsupervised NMT models inthe iterative back-translation process. Our method starts from SMT models builtwith pre-trained language models and word-level translation tables inferredfrom cross-lingual embeddings. Then SMT and NMT models are optimized jointlyand boost each other incrementally in a unified EM framework. In this way, (1)the negative effect caused by errors in the iterative back-translation processcan be alleviated timely by SMT filtering noises from its phrase tables;meanwhile, (2) NMT can compensate for the deficiency of fluency inherent inSMT. Experiments conducted on en-fr and en-de translation tasks show that ourmethod outperforms the strong baseline and achieves new state-of-the-artunsupervised machine translation performance."^^schema:Text ;
    schema:author "Ming Zhou"^^schema:Person,
        "Shuai Ma"^^schema:Person,
        "Shujie Liu"^^schema:Person,
        "Shuo Ren"^^schema:Person,
        "Zhirui Zhang"^^schema:Person ;
    schema:dateModified "2019-01-14T03:34:27Z"^^schema:DateTime ;
    schema:datePublished "2019-01-14T03:34:27Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Unsupervised Neural Machine Translation with SMT as Posterior  Regularization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.04112v1"^^schema:URL .

<1562> a schema:ScholarlyArticle ;
    schema:abstract "The behavior of users in certain services could be a clue that can be used toinfer their preferences and may be used to make recommendations for otherservices they have never used. However, the cross-domain relationships betweenitems and user consumption patterns are not simple, especially when there arefew or no common users and items across domains. To address this problem, wepropose a content-based cross-domain recommendation method for cold-start usersthat does not require user- and item- overlap. We formulate recommendation asextreme multi-class classification where labels (items) corresponding to theusers are predicted. With this formulation, the problem is reduced to a domainadaptation setting, in which a classifier trained in the source domain isadapted to the target domain. For this, we construct a neural network thatcombines an architecture for domain adaptation, Domain Separation Network, witha denoising autoencoder for item representation. We assess the performance ofour approach in experiments on a pair of data sets collected from movie andnews services of Yahoo! JAPAN and show that our approach outperforms severalbaseline methods including a cross-domain collaborative filtering method."^^schema:Text ;
    schema:author "Hayato Kobayashi"^^schema:Person,
        "Heishiro Kanagawa"^^schema:Person,
        "Nobuyuki Shimizu"^^schema:Person,
        "Taiji Suzuki"^^schema:Person,
        "Yukihiro Tagami"^^schema:Person ;
    schema:dateModified "2018-03-08T09:43:04Z"^^schema:DateTime ;
    schema:datePublished "2018-03-08T09:43:04Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Cross-domain Recommendation via Deep Domain Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.03018v1"^^schema:URL .

<1563> a schema:ScholarlyArticle ;
    schema:abstract "In neural combinatorial optimization (CO), reinforcement learning (RL) canturn a deep neural net into a fast, powerful heuristic solver of NP-hardproblems. This approach has a great potential in practical applications becauseit allows near-optimal solutions to be found without expert guides armed withsubstantial domain knowledge. We introduce Policy Optimization with MultipleOptima (POMO), an end-to-end approach for building such a heuristic solver.POMO is applicable to a wide range of CO problems. It is designed to exploitthe symmetries in the representation of a CO solution. POMO uses a modifiedREINFORCE algorithm that forces diverse rollouts towards all optimal solutions.Empirically, the low-variance baseline of POMO makes RL training fast andstable, and it is more resistant to local minima compared to previousapproaches. We also introduce a new augmentation-based inference method, whichaccompanies POMO nicely. We demonstrate the effectiveness of POMO by solvingthree popular NP-hard problems, namely, traveling salesman (TSP), capacitatedvehicle routing (CVRP), and 0-1 knapsack (KP). For all three, our solver basedon POMO shows a significant improvement in performance over all recent learnedheuristics. In particular, we achieve the optimality gap of 0.14% with TSP100while reducing inference time by more than an order of magnitude."^^schema:Text ;
    schema:author "Byoungjip Kim"^^schema:Person,
        "Iljoo Yoon"^^schema:Person,
        "Jinho Choo"^^schema:Person,
        "Seungjai Min"^^schema:Person,
        "Yeong-Dae Kwon"^^schema:Person,
        "Youngjune Gwon"^^schema:Person ;
    schema:dateModified "2020-12-29T03:09:02Z"^^schema:DateTime ;
    schema:datePublished "2020-10-30T00:57:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "POMO: Policy Optimization with Multiple Optima for Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.16011v2"^^schema:URL .

<1564> a schema:ScholarlyArticle ;
    schema:abstract "End-to-end dialog systems have become very popular because they hold thepromise of learning directly from human to human dialog interaction. Retrievaland Generative methods have been explored in this area with mixed results. Akey element that is missing so far, is the incorporation of a-priori knowledgeabout the task at hand. This knowledge may exist in the form of structured orunstructured information. As a first step towards this direction, we present anovel approach, Knowledge based end-to-end memory networks (KB-memN2N), whichallows special handling of named entities for goal-oriented dialog tasks. Wepresent results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks."^^schema:Text ;
    schema:author "Jatin Ganhotra"^^schema:Person,
        "Lazaros Polymenakos"^^schema:Person ;
    schema:dateModified "2018-04-23T00:47:48Z"^^schema:DateTime ;
    schema:datePublished "2018-04-23T00:47:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Knowledge-based end-to-end memory networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.08204v1"^^schema:URL .

<1565> a schema:ScholarlyArticle ;
    schema:abstract "Modern communication networks have become very complicated and highlydynamic, which makes them hard to model, predict and control. In this paper, wedevelop a novel experience-driven approach that can learn to well control acommunication network from its own experience rather than an accuratemathematical model, just as a human learns a new skill (such as driving,swimming, etc). Specifically, we, for the first time, propose to leverageemerging Deep Reinforcement Learning (DRL) for enabling model-free control incommunication networks; and present a novel and highly effective DRL-basedcontrol framework, DRL-TE, for a fundamental networking problem: TrafficEngineering (TE). The proposed framework maximizes a widely-used utilityfunction by jointly learning network environment and its dynamics, and makingdecisions under the guidance of powerful Deep Neural Networks (DNNs). Wepropose two new techniques, TE-aware exploration and actor-critic-basedprioritized experience replay, to optimize the general DRL frameworkparticularly for TE. To validate and evaluate the proposed framework, weimplemented it in ns-3, and tested it comprehensively with both representativeand randomly generated network topologies. Extensive packet-level simulationresults show that 1) compared to several widely-used baseline methods, DRL-TEsignificantly reduces end-to-end delay and consistently improves the networkutility, while offering better or comparable throughput; 2) DRL-TE is robust tonetwork changes; and 3) DRL-TE consistently outperforms a state-ofthe-art DRLmethod (for continuous control), Deep Deterministic Policy Gradient (DDPG),which, however, does not offer satisfying performance."^^schema:Text ;
    schema:author "Chi Harold Liu"^^schema:Person,
        "Dejun Yang"^^schema:Person,
        "Jian Tang"^^schema:Person,
        "Jingsong Meng"^^schema:Person,
        "Weiyi Zhang"^^schema:Person,
        "Yanzhi Wang"^^schema:Person,
        "Zhiyuan Xu"^^schema:Person ;
    schema:dateModified "2018-01-17T17:09:01Z"^^schema:DateTime ;
    schema:datePublished "2018-01-17T17:09:01Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text ;
    schema:headline "Experience-driven Networking: A Deep Reinforcement Learning based  Approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.05757v1"^^schema:URL .

<1566> a schema:ScholarlyArticle ;
    schema:abstract "The advancement of deep convolutional neural networks (DCNNs) has drivensignificant improvement in the accuracy of recognition systems for manycomputer vision tasks. However, their practical applications are oftenrestricted in resource-constrained environments. In this paper, we introduceprojection convolutional neural networks (PCNNs) with a discrete backpropagation via projection (DBPP) to improve the performance of binarizedneural networks (BNNs). The contributions of our paper include: 1) for thefirst time, the projection function is exploited to efficiently solve thediscrete back propagation problem, which leads to a new highly compressed CNNs(termed PCNNs); 2) by exploiting multiple projections, we learn a set ofdiverse quantized kernels that compress the full-precision kernels in a moreefficient way than those proposed previously; 3) PCNNs achieve the bestclassification performance compared to other state-of-the-art BNNs on theImageNet and CIFAR datasets."^^schema:Text ;
    schema:author "Baochang Zhang"^^schema:Person,
        "Ce Li"^^schema:Person,
        "David Doermann"^^schema:Person,
        "Jianzhuang Liu"^^schema:Person,
        "Jiaxin Gu"^^schema:Person,
        "Jungong Han"^^schema:Person,
        "Xianbin Cao"^^schema:Person ;
    schema:dateModified "2018-12-12T04:46:32Z"^^schema:DateTime ;
    schema:datePublished "2018-11-30T12:10:21Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Projection Convolutional Neural Networks for 1-bit CNNs via Discrete  Back Propagation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.12755v2"^^schema:URL .

<1567> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, the group concept is introduced into multi-agent reinforcementlearning. Agents, in this method, are divided into several groups, each ofwhich completes a specific subtask, cooperating to accomplish the main task. Inorder to exchange information between agents, present methods mainly use thecommunication vector; this can lead to communication redundancy. To solve thisproblem, a MARL based method is proposed on graph clustering. It allows agentsto learn group features adaptively and replaces the communication operation. Inthis approach, agent features are divided into two types, including in-groupand individual features. The generality and differences between agents arerepresented by them, respectively. Based on the graph attention network(GAT),the graph clustering method is introduced to optimize agent group feature.These features are then applied to generate individual Q value. The split lossis presented to distinguish agent features in order to overcome the consistentproblem brought by GAT. The proposed method is easy to be converted into theCTDE framework by using the Kullback-Leibler divergence method. Empiricalresults are evaluated on a challenging set of StarCraft II micromanagementtasks. The result reveals that the proposed method achieves significantperformance improvements in the SMAC domain, and can maintain a greatperformance with the increase in the number of agents."^^schema:Text ;
    schema:author "Chenfei Wang"^^schema:Person,
        "Fubiao Zhang"^^schema:Person,
        "Pan Tang"^^schema:Person,
        "Tianze Zhou"^^schema:Person ;
    schema:dateModified "2020-09-28T02:34:43Z"^^schema:DateTime ;
    schema:datePublished "2020-08-20T07:07:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Multi-Agent Reinforcement Learning with Graph Clustering"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.08808v2"^^schema:URL .

<1568> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) are a cornerstone of the Deep Learningtoolbox and have led to many breakthroughs in Artificial Intelligence. Thesenetworks have mostly been developed for regular Euclidean domains such as thosesupporting images, audio, or video. Because of their success, CNN-based methodsare becoming increasingly popular in Cosmology. Cosmological data often comesas spherical maps, which make the use of the traditional CNNs more complicated.The commonly used pixelization scheme for spherical maps is the HierarchicalEqual Area isoLatitude Pixelisation (HEALPix). We present a spherical CNN foranalysis of full and partial HEALPix maps, which we call DeepSphere. Thespherical CNN is constructed by representing the sphere as a graph. Graphs areversatile data structures that can act as a discrete representation of acontinuous manifold. Using the graph-based representation, we define many ofthe standard CNN operations, such as convolution and pooling. With filtersrestricted to being radial, our convolutions are equivariant to rotation on thesphere, and DeepSphere can be made invariant or equivariant to rotation. Thisway, DeepSphere is a special case of a graph CNN, tailored to the HEALPixsampling of the sphere. This approach is computationally more efficient thanusing spherical harmonics to perform convolutions. We demonstrate the method ona classification problem of weak lensing mass maps from two cosmological modelsand compare the performance of the CNN with that of two baseline classifiers.The results show that the performance of DeepSphere is always superior or equalto both of these baselines. For high noise levels and for data covering only asmaller fraction of the sphere, DeepSphere achieves typically 10% betterclassification accuracy than those baselines. Finally, we show how learnedfilters can be visualized to introspect the neural network."^^schema:Text ;
    schema:author "Michaël Defferrard"^^schema:Person,
        "Nathanaël Perraudin"^^schema:Person,
        "Raphael Sgier"^^schema:Person,
        "Tomasz Kacprzak"^^schema:Person ;
    schema:dateModified "2019-03-26T17:11:17Z"^^schema:DateTime ;
    schema:datePublished "2018-10-29T15:23:18Z"^^schema:DateTime ;
    schema:genre "astro-ph.CO"^^schema:Text,
        "astro-ph.IM"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "DeepSphere: Efficient spherical Convolutional Neural Network with  HEALPix sampling for cosmological applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.12186v2"^^schema:URL .

<1569> a schema:ScholarlyArticle ;
    schema:abstract "Zero-shot learning (ZSL) has received extensive attention recently especiallyin areas of fine-grained object recognition, retrieval, and image captioning.Due to the complete lack of training samples and high requirement of defensetransferability, the ZSL model learned is particularly vulnerable againstadversarial attacks. Recent work also showed adversarially robustgeneralization requires more data. This may significantly affect the robustnessof ZSL. However, very few efforts have been devoted towards this direction. Inthis paper, we take an initial attempt, and propose a generic formulation toprovide a systematical solution (named ATZSL) for learning a robust ZSL model.It is capable of achieving better generalization on various adversarial objectsrecognition while only losing a negligible performance on clean images forunseen classes, by casting ZSL into a min-max optimization problem. To addressit, we design a defensive relation prediction network, which can bridge theseen and unseen class domains via attributes to generalize prediction anddefense strategy. Additionally, our framework can be extended to deal with thepoisoned scenario of unseen class attributes. An extensive group of experimentsare then presented, demonstrating that ATZSL obtains remarkably more favorabletrade-off between model transferability and robustness, over currentlyavailable alternatives under various settings."^^schema:Text ;
    schema:author "Ji Liu"^^schema:Person,
        "Shupeng Gui"^^schema:Person,
        "Xingxing Zhang"^^schema:Person,
        "Yao Zhao"^^schema:Person,
        "Zhenfeng Zhu"^^schema:Person ;
    schema:dateModified "2019-12-10T08:18:08Z"^^schema:DateTime ;
    schema:datePublished "2019-10-24T09:36:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "ATZSL: Defensive Zero-Shot Recognition in the Presence of Adversaries"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.10994v2"^^schema:URL .

<157> a schema:ScholarlyArticle ;
    schema:abstract "Due to object detection's close relationship with video analysis and imageunderstanding, it has attracted much research attention in recent years.Traditional object detection methods are built on handcrafted features andshallow trainable architectures. Their performance easily stagnates byconstructing complex ensembles which combine multiple low-level image featureswith high-level context from object detectors and scene classifiers. With therapid development in deep learning, more powerful tools, which are able tolearn semantic, high-level, deeper features, are introduced to address theproblems existing in traditional architectures. These models behave differentlyin network architecture, training strategy and optimization function, etc. Inthis paper, we provide a review on deep learning based object detectionframeworks. Our review begins with a brief introduction on the history of deeplearning and its representative tool, namely Convolutional Neural Network(CNN). Then we focus on typical generic object detection architectures alongwith some modifications and useful tricks to improve detection performancefurther. As distinct specific detection tasks exhibit differentcharacteristics, we also briefly survey several specific tasks, includingsalient object detection, face detection and pedestrian detection. Experimentalanalyses are also provided to compare various methods and draw some meaningfulconclusions. Finally, several promising directions and tasks are provided toserve as guidelines for future work in both object detection and relevantneural network based learning systems."^^schema:Text ;
    schema:author "Peng Zheng"^^schema:Person,
        "Shou-tao Xu"^^schema:Person,
        "Xindong Wu"^^schema:Person,
        "Zhong-Qiu Zhao"^^schema:Person ;
    schema:commentCount "403"^^schema:Integer ;
    schema:dateModified "2019-04-16T09:24:59Z"^^schema:DateTime ;
    schema:datePublished "2018-07-15T08:16:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Object Detection with Deep Learning: A Review"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 30 (11), 3212-3232"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1807.05511v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13346469121565650680&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1570> a schema:ScholarlyArticle ;
    schema:abstract "Learning complex tasks from scratch is challenging and often impossible forhumans as well as for artificial agents. A curriculum can be used instead,which decomposes a complex task (target task) into a sequence of source tasks(the curriculum). Each source task is a simplified version of the next sourcetask with increasing complexity. Learning then occurs gradually by training oneach source task while using knowledge from the curriculum's prior sourcetasks. In this study, we present a new algorithm that combines curriculumlearning with Hindsight Experience Replay (HER), to learn sequential objectmanipulation tasks for multiple goals and sparse feedback. The algorithmexploits the recurrent structure inherent in many object manipulation tasks andimplements the entire learning process in the original simulation withoutadjusting it to each source task. We have tested our algorithm on threechallenging throwing tasks and show vast improvements compared to vanilla-HER."^^schema:Text ;
    schema:author "Armin Biess"^^schema:Person,
        "Binyamin Manela"^^schema:Person ;
    schema:dateModified "2020-08-21T08:59:28Z"^^schema:DateTime ;
    schema:datePublished "2020-08-21T08:59:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Curriculum Learning with Hindsight Experience Replay for Sequential  Object Manipulation Tasks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.09377v1"^^schema:URL .

<1571> a schema:ScholarlyArticle ;
    schema:abstract "Distributed Gaussian processes (DGPs) are prominent local approximationmethods to scale Gaussian processes (GPs) to large datasets. Instead of aglobal estimation, they train local experts by dividing the training set intosubsets, thus reducing the time complexity. This strategy is based on theconditional independence assumption, which basically means that there is aperfect diversity between the local experts. In practice, however, thisassumption is often violated, and the aggregation of experts leads tosub-optimal and inconsistent solutions. In this paper, we propose a novelapproach for aggregating the Gaussian experts by detecting strong violations ofconditional independence. The dependency between experts is determined by usinga Gaussian graphical model, which yields the precision matrix. The precisionmatrix encodes conditional dependencies between experts and is used to detectstrongly dependent experts and construct an improved aggregation. Using bothsynthetic and real datasets, our experimental evaluations illustrate that ournew method outperforms other state-of-the-art (SOTA) DGP approaches while beingsubstantially more time-efficient than SOTA approaches, which build onindependent experts."^^schema:Text ;
    schema:author "Gjergji Kasneci"^^schema:Person,
        "Hamed Jalali"^^schema:Person ;
    schema:dateModified "2020-10-17T21:49:43Z"^^schema:DateTime ;
    schema:datePublished "2020-10-17T21:49:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Aggregating Dependent Gaussian Experts in Local Approximation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.08873v1"^^schema:URL .

<1572> a schema:ScholarlyArticle ;
    schema:abstract "Autonomous path planning algorithms are significant to planetary explorationrovers, since relying on commands from Earth will heavily reduce theirefficiency of executing exploration missions. This paper proposes a novellearning-based algorithm to deal with global path planning problem forplanetary exploration rovers. Specifically, a novel deep convolutional neuralnetwork with double branches (DB-CNN) is designed and trained, which can planpath directly from orbital images of planetary surfaces without implementingenvironment mapping. Moreover, the planning procedure requires no priorknowledge about planetary surface terrains. Finally, experimental resultsdemonstrate that DB-CNN achieves better performance on global path planning andfaster convergence during training compared with the existing Value IterationNetwork (VIN)."^^schema:Text ;
    schema:author "Ganghui Shen"^^schema:Person,
        "Jiang Zhang"^^schema:Person,
        "Yuanqing Xia"^^schema:Person ;
    schema:dateModified "2018-11-23T15:20:03Z"^^schema:DateTime ;
    schema:datePublished "2018-11-23T15:20:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "A Novel Learning-based Global Path Planning Algorithm for Planetary  Rovers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.10437v1"^^schema:URL .

<1573> a schema:ScholarlyArticle ;
    schema:abstract "Automated computer vision systems have been applied in many domains includingsecurity, law enforcement, and personal devices, but recent reports suggestthat these systems may produce biased results, discriminating against people incertain demographic groups. Diagnosing and understanding the underlying truecauses of model biases, however, are challenging tasks because modern computervision systems rely on complex black-box models whose behaviors are hard todecode. We propose to use an encoder-decoder network developed for imageattribute manipulation to synthesize facial images varying in the dimensions ofgender and race while keeping other signals intact. We use these synthesizedimages to measure counterfactual fairness of commercial computer visionclassifiers by examining the degree to which these classifiers are affected bygender and racial cues controlled in the images, e.g., feminine faces mayelicit higher scores for the concept of nurse and lower scores for STEM-relatedconcepts. We also report the skewed gender representations in an online searchservice on profession-related keywords, which may explain the origin of thebiases encoded in the models."^^schema:Text ;
    schema:author "Jungseock Joo"^^schema:Person,
        "Kimmo Kärkkäinen"^^schema:Person ;
    schema:dateModified "2020-05-21T02:33:28Z"^^schema:DateTime ;
    schema:datePublished "2020-05-21T02:33:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Gender Slopes: Counterfactual Fairness for Computer Vision Models by  Attribute Manipulation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.10430v1"^^schema:URL .

<1574> a schema:ScholarlyArticle ;
    schema:abstract "Recently, end-to-end memory networks have shown promising results on QuestionAnswering task, which encode the past facts into an explicit memory and performreasoning ability by making multiple computational steps on the memory.However, memory networks conduct the reasoning on sentence-level memory tooutput coarse semantic vectors and do not further take any attention mechanismto focus on words, which may lead to the model lose some detail information,especially when the answers are rare or unknown words. In this paper, wepropose a novel Hierarchical Memory Networks, dubbed HMN. First, we encode thepast facts into sentence-level memory and word-level memory respectively. Then,(k)-max pooling is exploited following reasoning module on the sentence-levelmemory to sample the (k) most relevant sentences to a question and feed thesesentences into attention mechanism on the word-level memory to focus the wordsin the selected sentences. Finally, the prediction is jointly learned over theoutputs of the sentence-level reasoning module and the word-level attentionmechanism. The experimental results demonstrate that our approach successfullyconducts answer selection on unknown words and achieves a better performancethan memory networks."^^schema:Text ;
    schema:author "Bo Xu"^^schema:Person,
        "Jiaming Xu"^^schema:Person,
        "Jing Shi"^^schema:Person,
        "Suncong Zheng"^^schema:Person,
        "Yiqun Yao"^^schema:Person ;
    schema:dateModified "2016-09-28T10:03:05Z"^^schema:DateTime ;
    schema:datePublished "2016-09-28T10:03:05Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Hierarchical Memory Networks for Answer Selection on Unknown Words"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1609.08843v1"^^schema:URL .

<1575> a schema:ScholarlyArticle ;
    schema:abstract "Compared with single image based crowd counting, video provides thespatial-temporal information of the crowd that would help improve therobustness of crowd counting. But translation, rotation and scaling of peoplelead to the change of density map of heads between neighbouring frames.Meanwhile, people walking in/out or being occluded in dynamic scenes leads tothe change of head counts. To alleviate these issues in video crowd counting, aLocality-constrained Spatial Transformer Network (LSTN) is proposed.Specifically, we first leverage a Convolutional Neural Networks to estimate thedensity map for each frame. Then to relate the density maps betweenneighbouring frames, a Locality-constrained Spatial Transformer (LST) module isintroduced to estimate the density map of next frame with that of currentframe. To facilitate the performance evaluation, a large-scale video crowdcounting dataset is collected, which contains 15K frames with about 394Kannotated heads captured from 13 different scenes. As far as we know, it is thelargest video crowd counting dataset. Extensive experiments on our dataset andother crowd counting datasets validate the effectiveness of our LSTN for crowdcounting."^^schema:Text ;
    schema:author "Biyun Zhan"^^schema:Person,
        "Bo Hu"^^schema:Person,
        "Shenghua Gao"^^schema:Person,
        "Wandi Cai"^^schema:Person,
        "Yanyan Fang"^^schema:Person ;
    schema:dateModified "2019-07-18T07:25:26Z"^^schema:DateTime ;
    schema:datePublished "2019-07-18T07:25:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Locality-constrained Spatial Transformer Network for Video Crowd  Counting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.07911v1"^^schema:URL .

<1576> a schema:ScholarlyArticle ;
    schema:abstract "In theoretical cognitive science, there is a tension between highlystructured models whose parameters have a direct psychological interpretationand highly complex, general-purpose models whose parameters and representationsare difficult to interpret. The former typically provide more insight intocognition but the latter often perform better. This tension has recentlysurfaced in the realm of educational data mining, where a deep learningapproach to predicting students' performance as they work through a series ofexercises---termed deep knowledge tracing or DKT---has demonstrated a stunningperformance advantage over the mainstay of the field, Bayesian knowledgetracing or BKT. In this article, we attempt to understand the basis for DKT'sadvantage by considering the sources of statistical regularity in the data thatDKT can leverage but which BKT cannot. We hypothesize four forms of regularitythat BKT fails to exploit: recency effects, the contextualized trial sequence,inter-skill similarity, and individual variation in ability. We demonstratethat when BKT is extended to allow it more flexibility in modeling statisticalregularities---using extensions previously proposed in the literature---BKTachieves a level of performance indistinguishable from that of DKT. We arguethat while DKT is a powerful, useful, general-purpose framework for modelingstudent learning, its gains do not come from the discovery of novelrepresentations---the fundamental advantage of deep learning. To answer thequestion posed in our title, knowledge tracing may be a domain that does notrequire `depth'; shallow models like BKT can perform just as well and offer usgreater interpretability and explanatory power."^^schema:Text ;
    schema:author "Michael C. Mozer"^^schema:Person,
        "Mohammad Khajah"^^schema:Person,
        "Robert V. Lindsey"^^schema:Person ;
    schema:dateModified "2016-06-21T04:51:22Z"^^schema:DateTime ;
    schema:datePublished "2016-03-14T04:20:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "How deep is knowledge tracing?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1604.02416v2"^^schema:URL .

<1577> a schema:ScholarlyArticle ;
    schema:abstract "Videos uploaded on social media are often accompanied with textualdescriptions. In building automatic speech recognition (ASR) systems forvideos, we can exploit the contextual information provided by such videometadata. In this paper, we explore ASR lattice rescoring by selectivelyattending to the video descriptions. We first use an attention based method toextract contextual vector representations of video metadata, and use theserepresentations as part of the inputs to a neural language model during latticerescoring. Secondly, we propose a hybrid pointer network approach to explicitlyinterpolate the word probabilities of the word occurrences in metadata. Weperform experimental evaluations on both language modeling and ASR tasks, anddemonstrate that both proposed methods provide performance improvements byselectively leveraging the video metadata."^^schema:Text ;
    schema:author "Chunxi Liu"^^schema:Person,
        "Da-Rong Liu"^^schema:Person,
        "Frank Zhang"^^schema:Person,
        "Gabriel Synnaeve"^^schema:Person,
        "Geoffrey Zweig"^^schema:Person,
        "Yatharth Saraf"^^schema:Person ;
    schema:dateModified "2020-05-15T07:47:33Z"^^schema:DateTime ;
    schema:datePublished "2020-05-15T07:47:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Contextualizing ASR Lattice Rescoring with Hybrid Pointer Network  Language Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.07394v1"^^schema:URL .

<1578> a schema:ScholarlyArticle ;
    schema:abstract "State-of-the-art deep learning systems often require large amounts of dataand computation. For this reason, leveraging known or unknown structure of thedata is paramount. Convolutional neural networks (CNNs) are successful examplesof this principle, their defining characteristic being the shift-equivariance.By sliding a filter over the input, when the input shifts, the response shiftsby the same amount, exploiting the structure of natural images where semanticcontent is independent of absolute pixel positions. This property is essentialto the success of CNNs in audio, image and video recognition tasks. In thisthesis, we extend equivariance to other kinds of transformations, such asrotation and scaling. We propose equivariant models for differenttransformations defined by groups of symmetries. The main contributions are (i)polar transformer networks, achieving equivariance to the group of similaritieson the plane, (ii) equivariant multi-view networks, achieving equivariance tothe group of symmetries of the icosahedron, (iii) spherical CNNs, achievingequivariance to the continuous 3D rotation group, (iv) cross-domain imageembeddings, achieving equivariance to 3D rotations for 2D inputs, and (v)spin-weighted spherical CNNs, generalizing the spherical CNNs and achievingequivariance to 3D rotations for spherical vector fields. Applications includeimage classification, 3D shape classification and retrieval, panoramic imageclassification and segmentation, shape alignment and pose estimation. Whatthese models have in common is that they leverage symmetries in the data toreduce sample and model complexity and improve generalization performance. Theadvantages are more significant on (but not limited to) challenging tasks wheredata is limited or input perturbations such as arbitrary rotations are present."^^schema:Text ;
    schema:author "Carlos Esteves"^^schema:Person ;
    schema:dateModified "2020-12-04T18:46:17Z"^^schema:DateTime ;
    schema:datePublished "2020-12-04T18:46:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Equivariant Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02771v1"^^schema:URL .

<1579> a schema:ScholarlyArticle ;
    schema:abstract "Traffic forecasting is an important factor for the success of intelligenttransportation systems. Deep learning models including convolution neuralnetworks and recurrent neural networks have been applied in traffic forecastingproblems to model the spatial and temporal dependencies. In recent years, tomodel the graph structures in the transportation systems as well as thecontextual information, graph neural networks (GNNs) are introduced as newtools and have achieved the state-of-the-art performance in a series of trafficforecasting problems. In this survey, we review the rapidly growing body ofrecent research using different GNNs, e.g., graph convolutional and graphattention networks, in various traffic forecasting problems, e.g., road trafficflow and speed forecasting, passenger flow forecasting in urban rail transitsystems, demand forecasting in ride-hailing platforms, etc. We also present acollection of open data and source resources for each problem, as well asfuture research directions. To the best of our knowledge, this paper is thefirst comprehensive survey that explores the application of graph neuralnetworks for traffic forecasting problems. We have also created a public Githubrepository to update the latest papers, open data and source resources."^^schema:Text ;
    schema:author "Jiayun Luo"^^schema:Person,
        "Weiwei Jiang"^^schema:Person ;
    schema:dateModified "2021-01-27T02:35:41Z"^^schema:DateTime ;
    schema:datePublished "2021-01-27T02:35:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Graph Neural Network for Traffic Forecasting: A Survey"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.11174v1"^^schema:URL .

<158> a schema:ScholarlyArticle ;
    schema:abstract "The variational autoencoder (VAE; Kingma, Welling (2014)) is a recentlyproposed generative model pairing a top-down generative network with abottom-up recognition network which approximates posterior inference. Ittypically makes strong assumptions about posterior inference, for instance thatthe posterior distribution is approximately factorial, and that its parameterscan be approximated with nonlinear regression from the observations. As we showempirically, the VAE objective can lead to overly simplified representationswhich fail to use the network's entire modeling capacity. We present theimportance weighted autoencoder (IWAE), a generative model with the samearchitecture as the VAE, but which uses a strictly tighter log-likelihood lowerbound derived from importance weighting. In the IWAE, the recognition networkuses multiple samples to approximate the posterior, giving it increasedflexibility to model complex posteriors which do not fit the VAE modelingassumptions. We show empirically that IWAEs learn richer latent spacerepresentations than VAEs, leading to improved test log-likelihood on densityestimation benchmarks."^^schema:Text ;
    schema:author "Roger Grosse"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Yuri Burda"^^schema:Person ;
    schema:commentCount "579"^^schema:Integer ;
    schema:dateModified "2016-11-07T17:29:24Z"^^schema:DateTime ;
    schema:datePublished "2015-09-01T22:33:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Importance Weighted Autoencoders"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.00519v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=403810601333190474&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1580> a schema:ScholarlyArticle ;
    schema:abstract "Understanding the implication of point cloud is still challenging to achievethe goal of classification or segmentation due to the irregular and sparsestructure of point cloud. As we have known, PointNet architecture as aground-breaking work for point cloud which can learn efficiently shape featuresdirectly on unordered 3D point cloud and have achieved favorable performance.However, this model fail to consider the fine-grained semantic information oflocal structure for point cloud. Afterwards, many valuable works are proposedto enhance the performance of PointNet by means of semantic features of localpatch for point cloud. In this paper, a multi-scale receptive fields graphattention network (named after MRFGAT) for point cloud classification isproposed. By focusing on the local fine features of point cloud and applyingmulti attention modules based on channel affinity, the learned feature map forour network can well capture the abundant features information of point cloud.The proposed MRFGAT architecture is tested on ModelNet10 and ModelNet40datasets, and results show it achieves state-of-the-art performance in shapeclassification tasks."^^schema:Text ;
    schema:author "Jian Lu"^^schema:Person,
        "Lei Zhang"^^schema:Person,
        "Li-Yan Wang"^^schema:Person,
        "Xi-An Li"^^schema:Person ;
    schema:dateModified "2020-09-28T13:01:28Z"^^schema:DateTime ;
    schema:datePublished "2020-09-28T13:01:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Multi-scale Receptive Fields Graph Attention Network for Point Cloud  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.13289v1"^^schema:URL .

<1581> a schema:ScholarlyArticle ;
    schema:abstract "Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferringmultiple reward functions from expert demonstrations. Prior work, built onBayesian IRL, is unable to scale to complex environments due to computationalconstraints. This paper contributes a formulation of multi-task IRL in the morecomputationally efficient Maximum Causal Entropy (MCE) IRL framework.Experiments show our approach can perform one-shot imitation learning in agridworld environment that single-task IRL algorithms need hundreds ofdemonstrations to solve. We outline preliminary work using meta-learning toextend our method to the function approximator setting of modern MCE IRLalgorithms. Evaluating on multi-task variants of common simulated roboticsbenchmarks, we discover serious limitations of these IRL algorithms, andconclude with suggestions for further work."^^schema:Text ;
    schema:author "Adam Gleave"^^schema:Person,
        "Oliver Habryka"^^schema:Person ;
    schema:dateModified "2018-07-15T13:58:18Z"^^schema:DateTime ;
    schema:datePublished "2018-05-22T21:57:34Z"^^schema:DateTime ;
    schema:genre "I.2.6"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-task Maximum Entropy Inverse Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.08882v2"^^schema:URL .

<1582> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial networks are the state of the art for generativemodeling in vision, yet are notoriously unstable in practice. This instabilityis further exacerbated with limited training data. However, in the synthesis ofdomains such as medical or satellite imaging, it is often overlooked that theimage label is invariant to global image symmetries (e.g., rotations andreflections). In this work, we improve gradient feedback between generator anddiscriminator using an inductive symmetry prior via group-equivariantconvolutional networks. We replace convolutional layers with equivalentgroup-convolutional layers in both generator and discriminator, allowing forbetter optimization steps and increased expressive power with limited samples.In the process, we extend recent GAN developments to the group-equivariantsetting. We demonstrate the utility of our methods by improving both samplefidelity and diversity in the class-conditional synthesis of a diverse set ofglobally-symmetric imaging modalities."^^schema:Text ;
    schema:author "Antong Chen"^^schema:Person,
        "Neel Dey"^^schema:Person,
        "Soheil Ghafurian"^^schema:Person ;
    schema:dateModified "2020-05-04T17:38:49Z"^^schema:DateTime ;
    schema:datePublished "2020-05-04T17:38:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Group Equivariant Generative Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.01683v1"^^schema:URL .

<1583> a schema:ScholarlyArticle ;
    schema:abstract "Collective decision making processes lie at the heart of many social,political and economic challenges. The classical voter model is awell-established conceptual model to study such processes. In this work, wedefine a new form of adaptive (or co-evolutionary) voter model posed on asimplicial complex, i.e., on a certain class of hypernetworks/hypergraphs. Weuse the persuasion rule along edges of the classical voter model and therecently studied re-wiring rule of edges towards like-minded nodes, andintroduce a new peer pressure rule applied to three nodes connected via a2-simplex. This simplicial adaptive voter model is studied via numericalsimulation. We show that adding the effect of peer pressure to an adaptivevoter model leaves its fragmentation transition, i.e., the transition uponvarying the re-wiring rate from a single majority state into to a fragmentedstate of two different opinion subgraphs, intact. Yet, above and below thefragmentation transition, we observe that the peer pressure has substantialquantitative effects. It accelerates the transition to a single-opinion statebelow the transition and also speeds up the system dynamics towardsfragmentation above the transition. Furthermore, we quantify that there is amultiscale hierarchy in the model leading to the depletion of 2-simplices,before the depletion of active edges. This leads to the conjecture that manyother dynamic network models on simplicial complexes may show a similarbehaviour with respect to the sequential evolution of simplicies of differentdimensions."^^schema:Text ;
    schema:author "Christian Kuehn"^^schema:Person,
        "Leonhard Horstmeyer"^^schema:Person ;
    schema:dateModified "2019-09-12T17:13:22Z"^^schema:DateTime ;
    schema:datePublished "2019-09-12T17:13:22Z"^^schema:DateTime ;
    schema:genre "math.DS"^^schema:Text,
        "math.GN"^^schema:Text,
        "nlin.AO"^^schema:Text,
        "q-bio.PE"^^schema:Text ;
    schema:headline "An adaptive voter model on simplicial complexes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.05812v1"^^schema:URL .

<1584> a schema:ScholarlyArticle ;
    schema:abstract "The framework of normalizing flows provides a general strategy for flexiblevariational inference of posteriors over latent variables. We propose a newtype of normalizing flow, inverse autoregressive flow (IAF), that, in contrastto earlier published flows, scales well to high-dimensional latent spaces. Theproposed flow consists of a chain of invertible transformations, where eachtransformation is based on an autoregressive neural network. In experiments, weshow that IAF significantly improves upon diagonal Gaussian approximateposteriors. In addition, we demonstrate that a novel type of variationalautoencoder, coupled with IAF, is competitive with neural autoregressive modelsin terms of attained log-likelihood on natural images, while allowingsignificantly faster synthesis."^^schema:Text ;
    schema:author "Diederik P. Kingma"^^schema:Person,
        "Ilya Sutskever"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Rafal Jozefowicz"^^schema:Person,
        "Tim Salimans"^^schema:Person,
        "Xi Chen"^^schema:Person ;
    schema:dateModified "2017-01-30T20:36:01Z"^^schema:DateTime ;
    schema:datePublished "2016-06-15T19:46:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improving Variational Inference with Inverse Autoregressive Flow"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1606.04934v2"^^schema:URL .

<1585> a schema:ScholarlyArticle ;
    schema:abstract "This paper describes our system for SemEval-2020 Task 4: CommonsenseValidation and Explanation (Wang et al., 2020). We propose a novelKnowledge-enhanced Graph Attention Network (KEGAT) architecture for this task,leveraging heterogeneous knowledge from both the structured knowledge base(i.e. ConceptNet) and unstructured text to better improve the ability of amachine in commonsense understanding. This model has a powerful commonsenseinference capability via utilizing suitable commonsense incorporation methodsand upgraded data augmentation techniques. Besides, an internal sharingmechanism is cooperated to prohibit our model from insufficient and excessivereasoning for commonsense. As a result, this model performs quite well in bothvalidation and explanation. For instance, it achieves state-of-the-art accuracyin the subtask called Commonsense Explanation (Multi-Choice). We officiallyname the system as ECNU-SenseMaker. Code is publicly available athttps://github.com/ECNU-ICA/ECNU-SenseMaker."^^schema:Text ;
    schema:author "Jie Zhou"^^schema:Person,
        "Liang He"^^schema:Person,
        "Linlin Wang"^^schema:Person,
        "Qian Zhao"^^schema:Person,
        "Siyu Tao"^^schema:Person,
        "Xin Lin"^^schema:Person ;
    schema:dateModified "2020-07-28T13:30:46Z"^^schema:DateTime ;
    schema:datePublished "2020-07-28T13:30:46Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "ECNU-SenseMaker at SemEval-2020 Task 4: Leveraging Heterogeneous  Knowledge Resources for Commonsense Validation and Explanation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.14200v1"^^schema:URL .

<1586> a schema:ScholarlyArticle ;
    schema:abstract "In a dialog system, dialog act recognition and sentiment classification aretwo correlative tasks to capture speakers intentions, where dialog act andsentiment can indicate the explicit and the implicit intentions separately. Thedialog context information (contextual information) and the mutual interactioninformation are two key factors that contribute to the two related tasks.Unfortunately, none of the existing approaches consider the two importantsources of information simultaneously. In this paper, we propose aCo-Interactive Graph Attention Network (Co-GAT) to jointly perform the twotasks. The core module is a proposed co-interactive graph interaction layerwhere a cross-utterances connection and a cross-tasks connection areconstructed and iteratively updated with each other, achieving to consider thetwo types of information simultaneously. Experimental results on two publicdatasets show that our model successfully captures the two sources ofinformation and achieve the state-of-the-art performance.  In addition, we find that the contributions from the contextual and mutualinteraction information do not fully overlap with contextualized wordrepresentations (BERT, Roberta, XLNet)."^^schema:Text ;
    schema:author "Libo Qin"^^schema:Person,
        "Minheng Ni"^^schema:Person,
        "Ting Liu"^^schema:Person,
        "Wanxiang Che"^^schema:Person,
        "Zhouyang Li"^^schema:Person ;
    schema:dateModified "2020-12-24T14:10:24Z"^^schema:DateTime ;
    schema:datePublished "2020-12-24T14:10:24Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act  Recognition and Sentiment Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.13260v1"^^schema:URL .

<1587> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning techniques have been widely applied, achieving state-of-the-artresults in various fields of study. This survey focuses on deep learningsolutions that target learning control policies for robotics applications. Wecarry out our discussions on the two main paradigms for learning control withdeep networks: deep reinforcement learning and imitation learning. For deepreinforcement learning (DRL), we begin from traditional reinforcement learningalgorithms, showing how they are extended to the deep context and effectivemechanisms that could be added on top of the DRL algorithms. We then introducerepresentative works that utilize DRL to solve navigation and manipulationtasks in robotics. We continue our discussion on methods addressing thechallenge of the reality gap for transferring DRL policies trained insimulation to real-world scenarios, and summarize robotics simulation platformsfor conducting DRL research. For imitation leaning, we go through its threemain categories, behavior cloning, inverse reinforcement learning andgenerative adversarial imitation learning, by introducing their formulationsand their corresponding robotics applications. Finally, we discuss the openchallenges and research frontiers."^^schema:Text ;
    schema:author "Jingwei Zhang"^^schema:Person,
        "Joschka Boedecker"^^schema:Person,
        "Lei Tai"^^schema:Person,
        "Ming Liu"^^schema:Person,
        "Wolfram Burgard"^^schema:Person ;
    schema:dateModified "2018-04-09T03:46:53Z"^^schema:DateTime ;
    schema:datePublished "2016-12-21T14:31:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "A Survey of Deep Network Solutions for Learning Control in Robotics:  From Reinforcement to Imitation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1612.07139v4"^^schema:URL .

<1588> a schema:ScholarlyArticle ;
    schema:abstract "To calculate the model accuracy on a computer vision task, e.g., objectrecognition, we usually require a test set composed of test samples and theirground truth labels. Whilst standard usage cases satisfy this requirement, manyreal-world scenarios involve unlabeled test data, rendering common modelevaluation methods infeasible. We investigate this important and under-exploredproblem, Automatic model Evaluation (AutoEval). Specifically, given a labeledtraining set and a model, we aim to estimate the model accuracy on unlabeledtest datasets. We construct a meta-dataset: a dataset comprised of datasetsgenerated from the original training set via various image transformations suchas rotation, background substitution, foreground scaling, etc. As theclassification accuracy of the model on each sample (dataset) is known from theoriginal dataset labels, our task can be solved via regression. Using thefeature statistics to represent the distribution of a sample dataset, we cantrain regression techniques (e.g., a regression neural network) to predictmodel performance. Using synthetic meta-dataset and real-world datasets intraining and testing, respectively, we report reasonable and promisingestimates of the model accuracy. We also provide insights into the applicationscope, limitation, and future directions of AutoEval."^^schema:Text ;
    schema:author "Liang Zheng"^^schema:Person,
        "Weijian Deng"^^schema:Person ;
    schema:dateModified "2020-11-22T13:45:23Z"^^schema:DateTime ;
    schema:datePublished "2020-07-06T17:45:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Are Labels Necessary for Classifier Accuracy Evaluation?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02915v2"^^schema:URL .

<1589> a schema:ScholarlyArticle ;
    schema:abstract "Due to its potential to improve programmer productivity and software quality,automated program repair has been an active topic of research. Newer techniquesharness neural networks to learn directly from examples of buggy programs andtheir fixes. In this work, we consider a recently identified class of bugscalled variable-misuse bugs. The state-of-the-art solution for variable misuseenumerates potential fixes for all possible bug locations in a program, beforeselecting the best prediction. We show that it is beneficial to train a modelthat jointly and directly localizes and repairs variable-misuse bugs. Wepresent multi-headed pointer networks for this purpose, with one head each forlocalization and repair. The experimental results show that the joint modelsignificantly outperforms an enumerative solution that uses a pointer basedmodel for repair alone."^^schema:Text ;
    schema:author "Aditya Kanade"^^schema:Person,
        "David Bieber"^^schema:Person,
        "Marko Vasic"^^schema:Person,
        "Petros Maniatis"^^schema:Person,
        "Rishabh Singh"^^schema:Person ;
    schema:dateModified "2019-04-03T00:57:25Z"^^schema:DateTime ;
    schema:datePublished "2019-04-03T00:57:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Program Repair by Jointly Learning to Localize and Repair"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.01720v1"^^schema:URL .

<159> a schema:ScholarlyArticle ;
    schema:abstract "Generative moment matching network (GMMN) is a deep generative model thatdiffers from Generative Adversarial Network (GAN) by replacing thediscriminator in GAN with a two-sample test based on kernel maximum meandiscrepancy (MMD). Although some theoretical guarantees of MMD have beenstudied, the empirical performance of GMMN is still not as competitive as thatof GAN on challenging and large benchmark datasets. The computationalefficiency of GMMN is also less desirable in comparison with GAN, partially dueto its requirement for a rather large batch size during the training. In thispaper, we propose to improve both the model expressiveness of GMMN and itscomputational efficiency by introducing adversarial kernel learning techniques,as the replacement of a fixed Gaussian kernel in the original GMMN. The newapproach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN.The new distance measure in MMD GAN is a meaningful loss that enjoys theadvantage of weak topology and can be optimized via gradient descent withrelatively small batch sizes. In our evaluation on multiple benchmark datasets,including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GANsignificantly outperforms GMMN, and is competitive with other representativeGAN works."^^schema:Text ;
    schema:author "Barnabás Póczos"^^schema:Person,
        "Chun-Liang Li"^^schema:Person,
        "Wei-Cheng Chang"^^schema:Person,
        "Yiming Yang"^^schema:Person,
        "Yu Cheng"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2017-11-27T14:04:35Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T02:20:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "MMD GAN: Towards Deeper Understanding of Moment Matching Network"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08584v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13688446556700022690&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1590> a schema:ScholarlyArticle ;
    schema:abstract "Gaussian process regression (GPR) is a useful technique to predictcomposition--property relationships in glasses as the method inherentlyprovides the standard deviation of the predictions. However, the techniqueremains restricted to small datasets due to the substantial computational costassociated with it. Here, using a scalable GPR algorithm, namely, kernelinterpolation for scalable structured Gaussian processes (KISS-GP) along withmassively scalable GP (MSGP), we develop composition--property models forinorganic glasses based on a large dataset with more than 100,000 glasscompositions, 37 components, and nine important properties, namely, density,Young's, shear, and bulk moduli, thermal expansion coefficient, Vickers'hardness, refractive index, glass transition temperature, and liquidustemperature. Finally, to accelerate glass design, the models developed here areshared publicly as part of a package, namely, Python for Glass Genomics(PyGGi)."^^schema:Text ;
    schema:author "Hargun Singh"^^schema:Person,
        "Hariprasad Kodamana"^^schema:Person,
        "N. M. Anoop Krishnan"^^schema:Person,
        "R. Ravinder"^^schema:Person,
        "Suresh Bishnoi"^^schema:Person ;
    schema:dateModified "2020-07-06T14:56:48Z"^^schema:DateTime ;
    schema:datePublished "2020-07-06T14:56:48Z"^^schema:DateTime ;
    schema:genre "cond-mat.mtrl-sci"^^schema:Text,
        "physics.comp-ph"^^schema:Text,
        "physics.data-an"^^schema:Text ;
    schema:headline "Scalable Gaussian Processes for Predicting the Properties of Inorganic  Glasses with Large Datasets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02795v1"^^schema:URL .

<1591> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) have been providing the state-of-the-artperformance for learning-related problems involving 2D/3D images in Euclideanspace. However, unlike in the Euclidean space, the shapes of many structures inmedical imaging have a spherical topology in a manifold space, e.g., braincortical or subcortical surfaces represented by triangular meshes, with largeinter-subject and intrasubject variations in vertex number and localconnectivity. Hence, there is no consistent neighborhood definition and thus nostraightforward convolution/transposed convolution operations forcortical/subcortical surface data. In this paper, by leveraging the regular andconsistent geometric structure of the resampled cortical surface mapped ontothe spherical space, we propose a novel convolution filter analogous to thestandard convolution on the image grid. Accordingly, we develop correspondingoperations for convolution, pooling, and transposed convolution for sphericalsurface data and thus construct spherical CNNs. Specifically, we propose theSpherical U-Net architecture by replacing all operations in the standard U-Netwith their spherical operation counterparts. We then apply the Spherical U-Netto two challenging and neuroscientifically important tasks in infant brains:cortical surface parcellation and cortical attribute map developmentprediction. Both applications demonstrate the competitive performance in theaccuracy, computational efficiency, and effectiveness of our proposed SphericalU-Net, in comparison with the state-of-the-art methods."^^schema:Text ;
    schema:author "Dinggang Shen"^^schema:Person,
        "Dingna Duan"^^schema:Person,
        "Fenqiang Zhao"^^schema:Person,
        "Gang Li"^^schema:Person,
        "John H Gilmore"^^schema:Person,
        "Li Wang"^^schema:Person,
        "Shunren Xia"^^schema:Person,
        "Weili Lin"^^schema:Person,
        "Zhengwang Wu"^^schema:Person ;
    schema:dateModified "2019-04-01T15:18:53Z"^^schema:DateTime ;
    schema:datePublished "2019-04-01T15:18:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Spherical U-Net on Cortical Surfaces: Methods and Applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.00906v1"^^schema:URL .

<1592> a schema:ScholarlyArticle ;
    schema:abstract "Tree-structured neural networks have proven to be effective in learningsemantic representations by exploiting syntactic information. In spite of theirsuccess, most existing models suffer from the underfitting problem: theyrecursively use the same shared compositional function throughout the wholecompositional process and lack expressive power due to inability to capture therichness of compositionality. In this paper, we address this issue byintroducing the dynamic compositional neural networks over tree structure(DC-TreeNN), in which the compositional function is dynamically generated by ameta network. The role of meta-network is to capture the metaknowledge acrossthe different compositional rules and formulate them. Experimental results ontwo typical tasks show the effectiveness of the proposed models."^^schema:Text ;
    schema:author "Pengfei Liu"^^schema:Person,
        "Xipeng Qiu"^^schema:Person,
        "Xuanjing Huang"^^schema:Person ;
    schema:dateModified "2017-05-11T13:11:23Z"^^schema:DateTime ;
    schema:datePublished "2017-05-11T13:11:23Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Dynamic Compositional Neural Networks over Tree Structure"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.04153v1"^^schema:URL .

<1593> a schema:ScholarlyArticle ;
    schema:abstract "Neural ordinary differential equations are an attractive option for modellingtemporal dynamics. However, a fundamental issue is that the solution to anordinary differential equation is determined by its initial condition, andthere is no mechanism for adjusting the trajectory based on subsequentobservations. Here, we demonstrate how this may be resolved through thewell-understood mathematics of \\emph{controlled differential equations}. Theresulting \\emph{neural controlled differential equation} model is directlyapplicable to the general setting of partially-observed irregularly-sampledmultivariate time series, and (unlike previous work on this problem) it mayutilise memory-efficient adjoint-based backpropagation even acrossobservations. We demonstrate that our model achieves state-of-the-artperformance against similar (ODE or RNN based) models in empirical studies on arange of datasets. Finally we provide theoretical results demonstratinguniversal approximation, and that our model subsumes alternative ODE models."^^schema:Text ;
    schema:author "James Foster"^^schema:Person,
        "James Morrill"^^schema:Person,
        "Patrick Kidger"^^schema:Person,
        "Terry Lyons"^^schema:Person ;
    schema:dateModified "2020-11-05T17:45:39Z"^^schema:DateTime ;
    schema:datePublished "2020-05-18T17:52:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Controlled Differential Equations for Irregular Time Series"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.08926v2"^^schema:URL .

<1594> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning has recently made significant progress in solvingcomputer games and robotic control tasks. A known problem, though, is thatpolicies overfit to the training environment and may not avoid rare,catastrophic events such as automotive accidents. A classical technique forimproving the robustness of reinforcement learning algorithms is to train on aset of randomized environments, but this approach only guards against commonsituations. Recently, robust adversarial reinforcement learning (RARL) wasdeveloped, which allows efficient applications of random and systematicperturbations by a trained adversary. A limitation of RARL is that only theexpected control objective is optimized; there is no explicit modeling oroptimization of risk. Thus the agents do not consider the probability ofcatastrophic events (i.e., those inducing abnormally large negative reward),except through their effect on the expected objective. In this paper weintroduce risk-averse robust adversarial reinforcement learning (RARARL), usinga risk-averse protagonist and a risk-seeking adversary. We test our approach ona self-driving vehicle controller. We use an ensemble of policy networks tomodel risk as the variance of value functions. We show through experiments thata risk-averse agent is better equipped to handle a risk-seeking adversary, andexperiences substantially fewer crashes compared to agents trained without anadversary."^^schema:Text ;
    schema:author "Daniel Seita"^^schema:Person,
        "John Canny"^^schema:Person,
        "Xinlei Pan"^^schema:Person,
        "Yang Gao"^^schema:Person ;
    schema:dateModified "2019-03-31T23:46:26Z"^^schema:DateTime ;
    schema:datePublished "2019-03-31T23:46:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Risk Averse Robust Adversarial Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.00511v1"^^schema:URL .

<1595> a schema:ScholarlyArticle ;
    schema:abstract "Neural Ordinary Differential Equations (NODEs) are a new class of models thattransform data continuously through infinite-depth architectures. Thecontinuous nature of NODEs has made them particularly suitable for learning thedynamics of complex physical systems. While previous work has mostly beenfocused on first order ODEs, the dynamics of many systems, especially inclassical physics, are governed by second order laws. In this work, we considerSecond Order Neural ODEs (SONODEs). We show how the adjoint sensitivity methodcan be extended to SONODEs and prove that the optimisation of a first ordercoupled ODE is equivalent and computationally more efficient. Furthermore, weextend the theoretical understanding of the broader class of Augmented NODEs(ANODEs) by showing they can also learn higher order dynamics with a minimalnumber of augmented dimensions, but at the cost of interpretability. Thisindicates that the advantages of ANODEs go beyond the extra space offered bythe augmented dimensions, as originally thought. Finally, we compare SONODEsand ANODEs on synthetic and real dynamical systems and demonstrate that theinductive biases of the former generally result in faster training and betterperformance."^^schema:Text ;
    schema:author "Alexander Norcliffe"^^schema:Person,
        "Ben Day"^^schema:Person,
        "Cristian Bodnar"^^schema:Person,
        "Nikola Simidjievski"^^schema:Person,
        "Pietro Liò"^^schema:Person ;
    schema:dateModified "2020-10-21T13:59:14Z"^^schema:DateTime ;
    schema:datePublished "2020-06-12T14:25:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Second Order Behaviour in Augmented Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.07220v2"^^schema:URL .

<1596> a schema:ScholarlyArticle ;
    schema:abstract "We combine density-functional tight-binding (DFTB) with deep tensor neuralnetworks (DTNN) to maximize the strengths of both approaches in predictingstructural, energetic, and vibrational molecular properties. The DTNN is usedto learn a non-linear model for the localized many-body interatomic repulsiveenergy, which so far has been treated in an atom-pairwise manner in DFTB.Substantially improving upon standard DFTB and DTNN, the resultingDFTB-NN$_{\\sf{rep}}$ model yields accurate predictions of atomization andisomerization energies, equilibrium geometries, vibrational frequencies anddihedral rotation profiles for a large variety of organic molecules compared tothe hybrid DFT-PBE0 functional. Our results highlight the high potential ofcombining semi-empirical electronic-structure methods with physically-motivatedmachine learning approaches for predicting localized many-body interactions. Weconclude by discussing future advancements of the DFTB-NN$_{\\sf{rep}}$ approachthat could enable chemically accurate electronic-structure calculations forsystems with tens of thousands of atoms."^^schema:Text ;
    schema:author "Alexandre Tkatchenko"^^schema:Person,
        "Leonardo Medrano Sandonas"^^schema:Person,
        "Martin Stöhr"^^schema:Person ;
    schema:dateModified "2020-06-18T11:12:06Z"^^schema:DateTime ;
    schema:datePublished "2020-06-18T11:12:06Z"^^schema:DateTime ;
    schema:genre "physics.chem-ph"^^schema:Text,
        "physics.comp-ph"^^schema:Text ;
    schema:headline "Accurate Many-Body Repulsive Potentials for Density-Functional  Tight-Binding from Deep Tensor Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.10429v1"^^schema:URL .

<1597> a schema:ScholarlyArticle ;
    schema:abstract "We investigate the use of image-and-spatial transformer networks (ISTNs) totackle domain shift in multi-site medical imaging data. Commonly, domainadaptation (DA) is performed with little regard for explainability of theinter-domain transformation and is often conducted at the feature-level in thelatent space. We employ ISTNs for DA at the image-level which constrainstransformations to explainable appearance and shape changes. Asproof-of-concept we demonstrate that ISTNs can be trained adversarially on aclassification problem with simulated 2D data. For real-data validation, weconstruct two 3D brain MRI datasets from the Cam-CAN and UK Biobank studies toinvestigate domain shift due to acquisition and population differences. We showthat age regression and sex classification models trained on ISTN outputimprove generalization when training on data from one and testing on the othersite."^^schema:Text ;
    schema:author "B. Glocker"^^schema:Person,
        "D. C. Castro"^^schema:Person,
        "D. Rueckert"^^schema:Person,
        "K. Kamnitsas"^^schema:Person,
        "M. de Groot"^^schema:Person,
        "Q. Dou"^^schema:Person,
        "R. M. Summers"^^schema:Person,
        "R. Robinson"^^schema:Person ;
    schema:dateModified "2020-06-30T12:58:41Z"^^schema:DateTime ;
    schema:datePublished "2020-06-30T12:58:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Image-level Harmonization of Multi-Site Data using Image-and-Spatial  Transformer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16741v1"^^schema:URL .

<1598> a schema:ScholarlyArticle ;
    schema:abstract "Using a language model (LM) pretrained on two languages with largemonolingual data in order to initialize an unsupervised neural machinetranslation (UNMT) system yields state-of-the-art results. When limited data isavailable for one language, however, this method leads to poor translations. Wepresent an effective approach that reuses an LM that is pretrained only on thehigh-resource language. The monolingual LM is fine-tuned on both languages andis then used to initialize a UNMT model. To reuse the pretrained LM, we have tomodify its predefined vocabulary, to account for the new language. We thereforepropose a novel vocabulary extension method. Our approach, RE-LM, outperforms acompetitive cross-lingual pretraining model (XLM) in English-Macedonian (En-Mk)and English-Albanian (En-Sq), yielding more than +8.3 BLEU points for all fourtranslation directions."^^schema:Text ;
    schema:author "Alexander Fraser"^^schema:Person,
        "Alexandra Chronopoulou"^^schema:Person,
        "Dario Stojanovski"^^schema:Person ;
    schema:dateModified "2020-10-06T13:54:47Z"^^schema:DateTime ;
    schema:datePublished "2020-09-16T11:37:10Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Reusing a Pretrained Language Model on Languages with Limited Corpora  for Unsupervised NMT"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.07610v3"^^schema:URL .

<1599> a schema:ScholarlyArticle ;
    schema:abstract "Spherical signals are useful mathematical models for data arising in many 3-Dapplications such as LIDAR images, panorama cameras, and optical scanners.Successful processing of spherical signals entails architectures capable ofexploiting their inherent data structure. In particular, sphericalconvolutional neural networks (Spherical CNNs) have shown promising performancein shape analysis and object recognition. In this paper, we focus on analyzingthe properties that Spherical CNNs exhibit as they pertain to the rotationalstructure present in spherical signals. More specifically, we prove that theyare equivariant to rotations and stable to rotation diffeomorphisms. These twoproperties illustrate how Spherical CNNs exploit the rotational structure ofspherical signals, thus offering good generalization and faster learning. Wecorroborate these properties through controlled numerical experiments."^^schema:Text ;
    schema:author "Alejandro Ribeiro"^^schema:Person,
        "Fernando Gama"^^schema:Person,
        "Zhan Gao"^^schema:Person ;
    schema:dateModified "2020-10-12T17:16:07Z"^^schema:DateTime ;
    schema:datePublished "2020-10-12T17:16:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Spherical Convolutional Neural Networks: Stability to Perturbations in  SO(3)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.05865v1"^^schema:URL .

<16> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have enabled progress in a wide variety of applications.Growing the size of the neural network typically results in improved accuracy.As model sizes grow, the memory and compute requirements for training thesemodels also increases. We introduce a technique to train deep neural networksusing half precision floating point numbers. In our technique, weights,activations and gradients are stored in IEEE half-precision format.Half-precision floating numbers have limited numerical range compared tosingle-precision numbers. We propose two techniques to handle this loss ofinformation. Firstly, we recommend maintaining a single-precision copy of theweights that accumulates the gradients after each optimizer step. Thissingle-precision copy is rounded to half-precision format during training.Secondly, we propose scaling the loss appropriately to handle the loss ofinformation with half-precision gradients. We demonstrate that this approachworks for a wide variety of models including convolution neural networks,recurrent neural networks and generative adversarial networks. This techniqueworks for large scale models with more than 100 million parameters trained onlarge datasets. Using this approach, we can reduce the memory consumption ofdeep learning models by nearly 2x. In future processors, we can also expect asignificant computation speedup using half-precision hardware units."^^schema:Text ;
    schema:author "Boris Ginsburg"^^schema:Person,
        "David Garcia"^^schema:Person,
        "Erich Elsen"^^schema:Person,
        "Ganesh Venkatesh"^^schema:Person,
        "Gregory Diamos"^^schema:Person,
        "Hao Wu"^^schema:Person,
        "Jonah Alben"^^schema:Person,
        "Michael Houston"^^schema:Person,
        "Oleksii Kuchaiev"^^schema:Person,
        "Paulius Micikevicius"^^schema:Person,
        "Sharan Narang"^^schema:Person ;
    schema:commentCount "272"^^schema:Integer ;
    schema:dateModified "2018-02-15T20:04:02Z"^^schema:DateTime ;
    schema:datePublished "2017-10-10T17:42:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Mixed Precision Training"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.03740v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18172749567892275222&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<160> a schema:ScholarlyArticle ;
    schema:abstract "Learning embeddings of entities and relations is an efficient and versatilemethod to perform machine learning on relational data such as knowledge graphs.In this work, we propose holographic embeddings (HolE) to learn compositionalvector space representations of entire knowledge graphs. The proposed method isrelated to holographic models of associative memory in that it employs circularcorrelation to create compositional representations. By using correlation asthe compositional operator HolE can capture rich interactions butsimultaneously remains efficient to compute, easy to train, and scalable tovery large datasets. In extensive experiments we show that holographicembeddings are able to outperform state-of-the-art methods for link predictionin knowledge graphs and relational learning benchmark datasets."^^schema:Text ;
    schema:author "Lorenzo Rosasco"^^schema:Person,
        "Maximilian Nickel"^^schema:Person,
        "Tomaso Poggio"^^schema:Person ;
    schema:commentCount "465"^^schema:Integer ;
    schema:dateModified "2015-12-07T18:05:52Z"^^schema:DateTime ;
    schema:datePublished "2015-10-16T16:29:07Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.2.4"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Holographic Embeddings of Knowledge Graphs"^^schema:Text ;
    schema:publisher "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.04935v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18446152877069174052&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1600> a schema:ScholarlyArticle ;
    schema:abstract "We present a 3D capsule module for processing point clouds that isequivariant to 3D rotations and translations, as well as invariant topermutations of the input points. The operator receives a sparse set of localreference frames, computed from an input point cloud and establishes end-to-endtransformation equivariance through a novel dynamic routing procedure onquaternions. Further, we theoretically connect dynamic routing between capsulesto the well-known Weiszfeld algorithm, a scheme for solving \\emph{iterativere-weighted least squares} (IRLS) problems with provable convergenceproperties. It is shown that such group dynamic routing can be interpreted asrobust IRLS rotation averaging on capsule votes, where information is routedbased on the final inlier scores. Based on our operator, we build a capsulenetwork that disentangles geometry from pose, paving the way for moreinformative descriptors and a structured latent space. Our architecture allowsjoint object classification and orientation estimation without explicitsupervision of rotations. We validate our algorithm empirically on commonbenchmark datasets."^^schema:Text ;
    schema:author "Emanuele Menegatti"^^schema:Person,
        "Federico Tombari"^^schema:Person,
        "Jan Eric Lenssen"^^schema:Person,
        "Leonidas Guibas"^^schema:Person,
        "Tolga Birdal"^^schema:Person,
        "Yongheng Zhao"^^schema:Person ;
    schema:dateModified "2020-08-23T13:12:46Z"^^schema:DateTime ;
    schema:datePublished "2019-12-27T13:51:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Quaternion Equivariant Capsule Networks for 3D Point Clouds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.12098v3"^^schema:URL .

<1601> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent Neural Networks (RNNs) have long been the dominant architecture insequence-to-sequence learning. RNNs, however, are inherently sequential modelsthat do not allow parallelization of their computations. Transformers areemerging as a natural alternative to standard RNNs, replacing recurrentcomputations with a multi-head attention mechanism. In this paper, we proposethe `SepFormer', a novel RNN-free Transformer-based neural network for speechseparation. The SepFormer learns short and long-term dependencies with amulti-scale approach that employs transformers. The proposed model matches orovertakes the state-of-the-art (SOTA) performance on the standard WSJ0-2/3mixdatasets. It indeed achieves an SI-SNRi of 20.2 dB on WSJ0-2mix matching theSOTA, and an SI-SNRi of 17.6 dB on WSJ0-3mix, a SOTA result. The SepFormerinherits the parallelization advantages of Transformers and achieves acompetitive performance even when downsampling the encoded representation by afactor of 8. It is thus significantly faster and it is less memory-demandingthan the latest RNN-based systems."^^schema:Text ;
    schema:author "Cem Subakan"^^schema:Person,
        "Jianyuan Zhong"^^schema:Person,
        "Mirco Ravanelli"^^schema:Person,
        "Mirko Bronzi"^^schema:Person,
        "Samuele Cornell"^^schema:Person ;
    schema:dateModified "2020-10-25T16:28:54Z"^^schema:DateTime ;
    schema:datePublished "2020-10-25T16:28:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Attention is All You Need in Speech Separation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13154v1"^^schema:URL .

<1602> a schema:ScholarlyArticle ;
    schema:abstract "Melanoma is a curable aggressive skin cancer if detected early. Typically,the diagnosis involves initial screening with subsequent biopsy andhistopathological examination if necessary. Computer aided diagnosis offers anobjective score that is independent of clinical experience and the potential tolower the workload of a dermatologist. In the recent past, success of deeplearning algorithms in the field of general computer vision has motivatedsuccessful application of supervised deep learning methods in computer aidedmelanoma recognition. However, large quantities of labeled images are requiredto make further improvements on the supervised method. A good annotationgenerally requires clinical and histological confirmation, which requiressignificant effort. In an attempt to alleviate this constraint, we propose touse categorical generative adversarial network to automatically learn thefeature representation of dermoscopy images in an unsupervised andsemi-supervised manner. Thorough experiments on ISIC 2016 skin lesion chal-lenge demonstrate that the proposed feature learning method has achieved anaverage precision score of 0.424 with only 140 labeled images. Moreover, theproposed method is also capable of generating real-world like dermoscopyimages."^^schema:Text ;
    schema:author "Ekta Walia"^^schema:Person,
        "Paul Babyn"^^schema:Person,
        "Xin Yi"^^schema:Person ;
    schema:dateModified "2018-04-10T19:53:53Z"^^schema:DateTime ;
    schema:datePublished "2018-04-10T19:53:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised and semi-supervised learning with Categorical Generative  Adversarial Networks assisted by Wasserstein distance for dermoscopy image  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.03700v1"^^schema:URL .

<1603> a schema:ScholarlyArticle ;
    schema:abstract "Sign Language is used by the deaf community all over world. The workpresented here proposes a novel one-dimensional deep capsule network (CapsNet)architecture for continuous Indian Sign Language recognition by means ofsignals obtained from a custom designed wearable IMU system. The performance ofthe proposed CapsNet architecture is assessed by altering dynamic routingbetween capsule layers. The proposed CapsNet yields improved accuracy values of94% for 3 routings and 92.50% for 5 routings in comparison with theconvolutional neural network (CNN) that yields an accuracy of 87.99%. Improvedlearning of the proposed architecture is also validated by spatial activationsdepicting excited units at the predictive layer. Finally, a novelnon-cooperative pick-and-predict competition is designed between CapsNet andCNN. Higher value of Nash equilibrium for CapsNet as compared to CNN indicatesthe suitability of the proposed approach."^^schema:Text ;
    schema:author "Karush Suri"^^schema:Person,
        "Rinki Gupta"^^schema:Person ;
    schema:dateModified "2020-04-27T01:21:16Z"^^schema:DateTime ;
    schema:datePublished "2020-04-27T01:21:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continuous sign language recognition from wearable IMUs using deep  capsule networks and game theory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.00409v1"^^schema:URL .

<1604> a schema:ScholarlyArticle ;
    schema:abstract "Recently, Convolution Neural Networks (CNNs) obtained huge success innumerous vision tasks. In particular, DenseNets have demonstrated that featurereuse via dense skip connections can effectively alleviate the difficulty oftraining very deep networks and that reusing features generated by the initiallayers in all subsequent layers has strong impact on performance. To feed evenricher information into the network, a novel adaptive Multi-scale ConvolutionAggregation module is presented in this paper. Composed of layers formulti-scale convolutions, trainable cross-scale aggregation, maxout, andconcatenation, this module is highly non-linear and can boost the accuracy ofDenseNet while using much fewer parameters. In addition, due to high modelcomplexity, the network with extremely dense feature reuse is prone tooverfitting. To address this problem, a regularization method named StochasticFeature Reuse is also presented. Through randomly dropping a set of featuremaps to be reused for each mini-batch during the training phase, thisregularization method reduces training costs and prevents co-adaptation.Experimental results on CIFAR-10, CIFAR-100 and SVHN benchmarks demonstratedthe effectiveness of the proposed methods."^^schema:Text ;
    schema:author "Jun Zhou"^^schema:Person,
        "Mingjie Wang"^^schema:Person,
        "Minglun Gong"^^schema:Person,
        "Wendong Mao"^^schema:Person ;
    schema:dateModified "2018-10-02T17:07:35Z"^^schema:DateTime ;
    schema:datePublished "2018-10-02T17:07:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-scale Convolution Aggregation and Stochastic Feature Reuse for  DenseNets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.01373v1"^^schema:URL .

<1605> a schema:ScholarlyArticle ;
    schema:abstract "The performance of traditional compressive sensing-based MRI (CS-MRI)reconstruction is affected by its slow iterative procedure and noise-inducedartefacts. Although many deep learning-based CS-MRI methods have been proposedto mitigate the problems of traditional methods, they have not been able toachieve more robust results at higher acceleration factors. Most of the deeplearning-based CS-MRI methods still can not fully mine the information from thek-space, which leads to unsatisfactory results in the MRI reconstruction. Inthis study, we propose a new deep learning-based CS-MRI reconstruction methodto fully utilise the relationship among sequential MRI slices by couplingWasserstein Generative Adversarial Networks (WGAN) with Recurrent NeuralNetworks. Further development of an attentive unit enables our model toreconstruct more accurate anatomical structures for the MRI data. Byexperimenting on different MRI datasets, we have demonstrated that our methodcan not only achieve better results compared to the state-of-the-arts but canalso effectively reduce residual noise generated during the reconstructionprocess."^^schema:Text ;
    schema:author "Chengjia Wang"^^schema:Person,
        "Guang Yang"^^schema:Person,
        "Heye Zhang"^^schema:Person,
        "Yifeng Guo"^^schema:Person ;
    schema:dateModified "2020-06-23T11:50:21Z"^^schema:DateTime ;
    schema:datePublished "2020-06-23T11:50:21Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Deep Attentive Wasserstein Generative Adversarial Networks for MRI  Reconstruction with Recurrent Context-Awareness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.12915v1"^^schema:URL .

<1606> a schema:ScholarlyArticle ;
    schema:abstract "We propose Logic Tensor Networks: a uniform framework for integratingautomatic learning and reasoning. A logic formalism called Real Logic isdefined on a first-order language whereby formulas have truth-value in theinterval [0,1] and semantics defined concretely on the domain of real numbers.Logical constants are interpreted as feature vectors of real numbers. RealLogic promotes a well-founded integration of deductive reasoning on aknowledge-base and efficient data-driven relational machine learning. We showhow Real Logic can be implemented in deep Tensor Neural Networks with the useof Google's tensorflow primitives. The paper concludes with experimentsapplying Logic Tensor Networks on a simple but representative example ofknowledge completion."^^schema:Text ;
    schema:author "Artur d'Avila Garcez"^^schema:Person,
        "Luciano Serafini"^^schema:Person ;
    schema:dateModified "2016-07-07T12:28:57Z"^^schema:DateTime ;
    schema:datePublished "2016-06-14T15:25:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.LO"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and  Knowledge"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1606.04422v2"^^schema:URL .

<1607> a schema:ScholarlyArticle ;
    schema:abstract "Video-to-video synthesis (vid2vid) aims for converting high-level semanticinputs to photorealistic videos. While existing vid2vid methods can achieveshort-term temporal consistency, they fail to ensure the long-term one. This isbecause they lack knowledge of the 3D world being rendered and generate eachframe only based on the past few frames. To address the limitation, weintroduce a novel vid2vid framework that efficiently and effectively utilizesall past generated frames during rendering. This is achieved by condensing the3D world rendered so far into a physically-grounded estimate of the currentframe, which we call the guidance image. We further propose a novel neuralnetwork architecture to take advantage of the information stored in theguidance images. Extensive experimental results on several challenging datasetsverify the effectiveness of our approach in achieving world consistency - theoutput video is consistent within the entire rendered 3D world.  https://nvlabs.github.io/wc-vid2vid/"^^schema:Text ;
    schema:author "Arun Mallya"^^schema:Person,
        "Karan Sapra"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Ting-Chun Wang"^^schema:Person ;
    schema:dateModified "2020-07-16T17:58:13Z"^^schema:DateTime ;
    schema:datePublished "2020-07-16T17:58:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "World-Consistent Video-to-Video Synthesis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.08509v1"^^schema:URL .

<1608> a schema:ScholarlyArticle ;
    schema:abstract "In Multi-Goal Reinforcement Learning, an agent learns to achieve multiplegoals with a goal-conditioned policy. During learning, the agent first collectsthe trajectories into a replay buffer, and later these trajectories areselected randomly for replay. However, the achieved goals in the replay bufferare often biased towards the behavior policies. From a Bayesian perspective,when there is no prior knowledge about the target goal distribution, the agentshould learn uniformly from diverse achieved goals. Therefore, we first proposea novel multi-goal RL objective based on weighted entropy. This objectiveencourages the agent to maximize the expected return, as well as to achievemore diverse goals. Secondly, we developed a maximum entropy-basedprioritization framework to optimize the proposed objective. For evaluation ofthis framework, we combine it with Deep Deterministic Policy Gradient, bothwith or without Hindsight Experience Replay. On a set of multi-goal robotictasks of OpenAI Gym, we compare our method with other baselines and showpromising improvements in both performance and sample-efficiency."^^schema:Text ;
    schema:author "Rui Zhao"^^schema:Person,
        "Volker Tresp"^^schema:Person,
        "Xudong Sun"^^schema:Person ;
    schema:dateModified "2020-05-24T08:21:11Z"^^schema:DateTime ;
    schema:datePublished "2019-05-21T11:38:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Maximum Entropy-Regularized Multi-Goal Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.08786v3"^^schema:URL .

<1609> a schema:ScholarlyArticle ;
    schema:abstract "Group equivariant neural networks have been explored in the past few yearsand are interesting from theoretical and practical standpoints. They leverageconcepts from group representation theory, non-commutative harmonic analysisand differential geometry that do not often appear in machine learning. Inpractice, they have been shown to reduce sample and model complexity, notablyin challenging tasks where input transformations such as arbitrary rotationsare present. We begin this work with an exposition of group representationtheory and the machinery necessary to define and evaluate integrals andconvolutions on groups. Then, we show applications to recent SO(3) and SE(3)equivariant networks, namely the Spherical CNNs, Clebsch-Gordan Networks, and3D Steerable CNNs. We proceed to discuss two recent theoretical results. Thefirst, by Kondor and Trivedi (ICML'18), shows that a neural network is groupequivariant if and only if it has a convolutional structure. The second, byCohen et al. (NeurIPS'19), generalizes the first to a larger class of networks,with feature maps as fields on homogeneous spaces."^^schema:Text ;
    schema:author "Carlos Esteves"^^schema:Person ;
    schema:dateModified "2020-04-30T02:10:51Z"^^schema:DateTime ;
    schema:datePublished "2020-04-10T17:57:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Theoretical Aspects of Group Equivariant Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.05154v2"^^schema:URL .

<161> a schema:ScholarlyArticle ;
    schema:abstract "We investigate a local reparameterizaton technique for greatly reducing thevariance of stochastic gradients for variational Bayesian inference (SGVB) of aposterior over model parameters, while retaining parallelizability. This localreparameterization translates uncertainty about global parameters into localnoise that is independent across datapoints in the minibatch. Suchparameterizations can be trivially parallelized and have variance that isinversely proportional to the minibatch size, generally leading to much fasterconvergence. Additionally, we explore a connection with dropout: Gaussiandropout objectives correspond to SGVB with local reparameterization, ascale-invariant prior and proportionally fixed posterior variance. Our methodallows inference of more flexibly parameterized posteriors; specifically, wepropose variational dropout, a generalization of Gaussian dropout where thedropout rates are learned, often leading to better models. The method isdemonstrated through several experiments."^^schema:Text ;
    schema:author "Diederik P. Kingma"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Tim Salimans"^^schema:Person ;
    schema:commentCount "534"^^schema:Integer ;
    schema:dateModified "2015-12-20T16:07:38Z"^^schema:DateTime ;
    schema:datePublished "2015-06-08T15:37:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Dropout and the Local Reparameterization Trick"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02557v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5114094121420596303&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1610> a schema:ScholarlyArticle ;
    schema:abstract "In Hindsight Experience Replay (HER), a reinforcement learning agent istrained by treating whatever it has achieved as virtual goals. However, inprevious work, the experience was replayed at random, without considering whichepisode might be the most valuable for learning. In this paper, we develop anenergy-based framework for prioritizing hindsight experience in roboticmanipulation tasks. Our approach is inspired by the work-energy principle inphysics. We define a trajectory energy function as the sum of the transitionenergy of the target object over the trajectory. We hypothesize that replayingepisodes that have high trajectory energy is more effective for reinforcementlearning in robotics. To verify our hypothesis, we designed a framework forhindsight experience prioritization based on the trajectory energy of goalstates. The trajectory energy function takes the potential, kinetic, androtational energy into consideration. We evaluate our Energy-BasedPrioritization (EBP) approach on four challenging robotic manipulation tasks insimulation. Our empirical results show that our proposed method surpassesstate-of-the-art approaches in terms of both performance and sample-efficiencyon all four tasks, without increasing computational time. A video showingexperimental results is available at https://youtu.be/jtsF2tTeUGQ"^^schema:Text ;
    schema:author "Rui Zhao"^^schema:Person,
        "Volker Tresp"^^schema:Person ;
    schema:dateModified "2020-05-24T07:57:13Z"^^schema:DateTime ;
    schema:datePublished "2018-10-02T16:42:35Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Energy-Based Hindsight Experience Prioritization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.01363v5"^^schema:URL .

<1611> a schema:ScholarlyArticle ;
    schema:abstract "Net length is a key proxy metric for optimizing timing and power acrossvarious stages of a standard digital design flow. However, the bulk of netlength information is not available until cell placement, and hence it is asignificant challenge to explicitly consider net length optimization in designstages prior to placement, such as logic synthesis. This work addresses thischallenge by proposing a graph attention network method with customization,called Net2, to estimate individual net length before cell placement. Itsaccuracy-oriented version Net2a achieves about 15% better accuracy than severalprevious works in identifying both long nets and long critical paths. Its fastversion Net2f is more than 1000 times faster than placement while stilloutperforms previous works and other neural network techniques in terms ofvarious accuracy metrics."^^schema:Text ;
    schema:author "Jiang Hu"^^schema:Person,
        "Rongjian Liang"^^schema:Person,
        "Xiaoqing Xu"^^schema:Person,
        "Yiran Chen"^^schema:Person,
        "Yixiao Duan"^^schema:Person,
        "Zhiyao Xie"^^schema:Person ;
    schema:dateModified "2020-11-27T01:47:19Z"^^schema:DateTime ;
    schema:datePublished "2020-11-27T01:47:19Z"^^schema:DateTime ;
    schema:genre "cs.AR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Net2: A Graph Attention Network Method Customized for Pre-Placement Net  Length Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13522v1"^^schema:URL .

<1612> a schema:ScholarlyArticle ;
    schema:abstract "Semantic composition functions have been playing a pivotal role in neuralrepresentation learning of text sequences. In spite of their success, mostexisting models suffer from the underfitting problem: they use the same sharedcompositional function on all the positions in the sequence, thereby lackingexpressive power due to incapacity to capture the richness of compositionality.Besides, the composition functions of different tasks are independent andlearned from scratch. In this paper, we propose a new sharing scheme ofcomposition function across multiple tasks. Specifically, we use a sharedmeta-network to capture the meta-knowledge of semantic composition and generatethe parameters of the task-specific semantic composition models. We conductextensive experiments on two types of tasks, text classification and sequencetagging, which demonstrate the benefits of our approach. Besides, we show thatthe shared meta-knowledge learned by our proposed model can be regarded asoff-the-shelf knowledge and easily transferred to new tasks."^^schema:Text ;
    schema:author "Junkun Chen"^^schema:Person,
        "Pengfei Liu"^^schema:Person,
        "Xipeng Qiu"^^schema:Person,
        "Xuanjing Huang"^^schema:Person ;
    schema:dateModified "2018-02-25T09:01:25Z"^^schema:DateTime ;
    schema:datePublished "2018-02-25T09:01:25Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Meta Multi-Task Learning for Sequence Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.08969v1"^^schema:URL .

<1613> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing allows Intelligent Tutoring Systems to infer which topicsor skills a student has mastered, thus adjusting curriculum accordingly. DeepLearning based models like Deep Knowledge Tracing (DKT) and Dynamic Key-ValueMemory Network (DKVMN) have achieved significant improvements compared withmodels like Bayesian Knowledge Tracing (BKT) and Performance Factors Analysis(PFA). However, these deep learning based models are not as interpretable asother models because the decision-making process learned by deep neuralnetworks is not wholly understood by the research community. In previous work,we critically examined the DKT model, visualizing and analyzing the behaviorsof DKT in high dimensional space. In this work, we extend our original analyseswith a much larger dataset and add discussions about the memory states of theDKVMN model. We discover that Deep Knowledge Tracing has some criticalpitfalls: 1) instead of tracking each skill through time, DKT is more likely tolearn an `ability' model; 2) the recurrent nature of DKT reinforces irrelevantinformation that it uses during the tracking task; 3) an untrained recurrentnetwork can achieve similar results to a trained DKT model, supporting aconclusion that recurrence relations are not properly learned and, instead,improvements are simply a benefit of projection into a high dimensional, sparsevector space. Based on these observations, we propose improvements and futuredirections for conducting knowledge tracing research using deep neural networkmodels."^^schema:Text ;
    schema:author "Eric C. Larson"^^schema:Person,
        "Xinyi Ding"^^schema:Person ;
    schema:dateModified "2021-01-27T11:55:03Z"^^schema:DateTime ;
    schema:datePublished "2021-01-27T11:55:03Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "On the Interpretability of Deep Learning Based Models for Knowledge  Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.11335v1"^^schema:URL .

<1614> a schema:ScholarlyArticle ;
    schema:abstract "As neural network algorithms show high performance in many applications,their efficient inference on mobile and embedded systems are of greatinterests. When a single stream recurrent neural network (RNN) is executed fora personal user in embedded systems, it demands a large amount of DRAM accessesbecause the network size is usually much bigger than the cache size and theweights of an RNN are used only once at each time step. We overcome thisproblem by parallelizing the algorithm and executing it multiple time steps ata time. This approach also reduces the power consumption by lowering the numberof DRAM accesses. QRNN (Quasi Recurrent Neural Networks) and SRU (SimpleRecurrent Unit) based recurrent neural networks are used for implementation.The experiments for SRU showed about 300% and 930% of speed-up when the numbersof multi time steps are 4 and 16, respectively, in an ARM CPU based system."^^schema:Text ;
    schema:author "Jinhwan Park"^^schema:Person,
        "Wonyong Sung"^^schema:Person ;
    schema:dateModified "2018-03-30T09:15:07Z"^^schema:DateTime ;
    schema:datePublished "2018-03-30T09:15:07Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Single Stream Parallelization of Recurrent Neural Networks for Low Power  and Fast Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.11389v1"^^schema:URL .

<1615> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning targets deriving a mapping from states to actions, a.k.a.policy, from expert demonstrations. Existing methods for imitation learningtypically require any actions in the demonstrations to be fully available,which is hard to ensure in real applications. Though algorithms for learningwith unobservable actions have been proposed, they focus solely on stateinformation and overlook the fact that the action sequence could still bepartially available and provide useful information for policy deriving. In thispaper, we propose a novel algorithm called Action-Guided Adversarial ImitationLearning (AGAIL) that learns a policy from demonstrations with incompleteaction sequences, i.e., incomplete demonstrations. The core idea of AGAIL is toseparate demonstrations into state and action trajectories, and train a policywith state trajectories while using actions as auxiliary information to guidethe training whenever applicable. Built upon the Generative AdversarialImitation Learning, AGAIL has three components: a generator, a discriminator,and a guide. The generator learns a policy with rewards provided by thediscriminator, which tries to distinguish state distributions betweendemonstrations and samples generated by the policy. The guide providesadditional rewards to the generator when demonstrated actions for specificstates are available. We compare AGAIL to other methods on benchmark tasks andshow that AGAIL consistently delivers comparable performance to thestate-of-the-art methods even when the action sequence in demonstrations isonly partially available."^^schema:Text ;
    schema:author "Mingfei Sun"^^schema:Person,
        "Xiaojuan Ma"^^schema:Person ;
    schema:dateModified "2019-06-23T06:11:10Z"^^schema:DateTime ;
    schema:datePublished "2019-05-29T10:18:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Imitation Learning from Incomplete Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.12310v3"^^schema:URL .

<1616> a schema:ScholarlyArticle ;
    schema:abstract "The classical approach to measure the expressive power of deep neuralnetworks with piecewise linear activations is based on counting their maximumnumber of linear regions. However, when considering the two different modelswhich are the fully connected and the permutation invariant ones, this measureis unable to distinguish them clearly in term of expressivity. To tackle this,we propose a refined definition of deep neural networks complexity. Instead ofcounting the number of linear regions directly, we first introduce anequivalence relation between the linear functions composing a DNN and thencount those functions relatively to that equivalence relation. We continue witha study of our new complexity measure and verify that it has the good expectedproperties. It is able to distinguish clearly between the two models mentionedabove, it is consistent with the classical measure, and it increasesexponentially with depth. That last point confirms the high expressive power ofdeep networks."^^schema:Text ;
    schema:author "Akiyoshi Sannai"^^schema:Person,
        "Matthieu Cordonnier"^^schema:Person,
        "Yuuki Takai"^^schema:Person ;
    schema:dateModified "2020-10-23T01:46:12Z"^^schema:DateTime ;
    schema:datePublished "2020-10-23T01:46:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Number of Linear Functions Composing Deep Neural Network: Towards  a Refined Definition of Neural Networks Complexity"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.12125v1"^^schema:URL .

<1617> a schema:ScholarlyArticle ;
    schema:abstract "Exploration in environments with sparse feedback remains a challengingresearch problem in reinforcement learning (RL). When the RL agent explores theenvironment randomly, it results in low exploration efficiency, especially inrobotic manipulation tasks with high dimensional continuous state and actionspace. In this paper, we propose a novel method, called AugmentedCuriosity-Driven Experience Replay (ACDER), which leverages (i) a newgoal-oriented curiosity-driven exploration to encourage the agent to pursuenovel and task-relevant states more purposefully and (ii) the dynamic initialstates selection as an automatic exploratory curriculum to further improve thesample-efficiency. Our approach complements Hindsight Experience Replay (HER)by introducing a new way to pursue valuable states. Experiments conducted onfour challenging robotic manipulation tasks with binary rewards, includingReach, Push, Pick&amp;Place and Multi-step Push. The empirical results show thatour proposed method significantly outperforms existing methods in the firstthree basic tasks and also achieves satisfactory performance in multi-steprobotic task learning."^^schema:Text ;
    schema:author "Boyao Li"^^schema:Person,
        "Jiayi Li"^^schema:Person,
        "Ning Lu"^^schema:Person,
        "Shuo Wang"^^schema:Person,
        "Tao Lu"^^schema:Person,
        "Yinghao Cai"^^schema:Person ;
    schema:dateModified "2020-11-16T15:27:15Z"^^schema:DateTime ;
    schema:datePublished "2020-11-16T15:27:15Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "ACDER: Augmented Curiosity-Driven Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.08027v1"^^schema:URL .

<1618> a schema:ScholarlyArticle ;
    schema:abstract "To overcome the poor scalability of convolutional neural network, recurrentattention model(RAM) selectively choose what and where to look on the image. Bydirecting recurrent attention model how to look the image, RAM can be even moresuccessful in that the given clue narrow down the scope of the possible focuszone. In this perspective, this work proposes clued recurrent attention model(CRAM) which add clue or constraint on the RAM better problem solving. CRAMfollows encoder-decoder framework, encoder utilizes recurrent attention modelwith spatial transformer network and decoder which varies depending on thetask. To ensure the performance, CRAM tackles two computer vision task. One isthe image classification task, with clue given as the binary image saliencywhich indicates the approximate location of object. The other is the inpaintingtask, with clue given as binary mask which indicates the occluded part. In bothtasks, CRAM shows better performance than existing methods showing thesuccessful extension of RAM."^^schema:Text ;
    schema:author "Minki Chung"^^schema:Person,
        "Sungzoon Cho"^^schema:Person ;
    schema:dateModified "2018-04-28T19:27:43Z"^^schema:DateTime ;
    schema:datePublished "2018-04-28T19:27:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "CRAM: Clued Recurrent Attention Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.10844v1"^^schema:URL .

<1619> a schema:ScholarlyArticle ;
    schema:abstract "The ability to accurately predict and simulate human driving behavior iscritical for the development of intelligent transportation systems. Traditionalmodeling methods have employed simple parametric models and behavioral cloning.This paper adopts a method for overcoming the problem of cascading errorsinherent in prior approaches, resulting in realistic behavior that is robust totrajectory perturbations. We extend Generative Adversarial Imitation Learningto the training of recurrent policies, and we demonstrate that our modeloutperforms rule-based controllers and maximum likelihood models in realistichighway simulations. Our model both reproduces emergent behavior of humandrivers, such as lane change rate, while maintaining realistic control overlong time horizons."^^schema:Text ;
    schema:author "Alex Kuefler"^^schema:Person,
        "Jeremy Morton"^^schema:Person,
        "Mykel Kochenderfer"^^schema:Person,
        "Tim Wheeler"^^schema:Person ;
    schema:dateModified "2017-01-24T00:59:42Z"^^schema:DateTime ;
    schema:datePublished "2017-01-24T00:59:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Imitating Driver Behavior with Generative Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1701.06699v1"^^schema:URL .

<162> a schema:ScholarlyArticle ;
    schema:abstract "We show that parametric models trained by a stochastic gradient method (SGM)with few iterations have vanishing generalization error. We prove our resultsby arguing that SGM is algorithmically stable in the sense of Bousquet andElisseeff. Our analysis only employs elementary tools from convex andcontinuous optimization. We derive stability bounds for both convex andnon-convex optimization under standard Lipschitz and smoothness assumptions.  Applying our results to the convex case, we provide new insights for whymultiple epochs of stochastic gradient methods generalize well in practice. Inthe non-convex case, we give a new interpretation of common practices in neuralnetworks, and formally show that popular techniques for training large deepmodels are indeed stability-promoting. Our findings conceptually underscore theimportance of reducing training time beyond its obvious benefit."^^schema:Text ;
    schema:author "Benjamin Recht"^^schema:Person,
        "Moritz Hardt"^^schema:Person,
        "Yoram Singer"^^schema:Person ;
    schema:commentCount "455"^^schema:Integer ;
    schema:dateModified "2016-02-07T17:06:58Z"^^schema:DateTime ;
    schema:datePublished "2015-09-03T19:53:40Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Train faster, generalize better: Stability of stochastic gradient  descent"^^schema:Text ;
    schema:publisher "ICML, 1225-1234"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.01240v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4563905800844853958&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1620> a schema:ScholarlyArticle ;
    schema:abstract "We use a continuous depth version of the Residual Network (ResNet) modelknown as Neural ordinary differential equations (NODE) for the purpose ofgalaxy morphology classification. We applied this method to carry outsupervised classification of galaxy images from the Galaxy Zoo 2 dataset, intofive distinct classes, and obtained an accuracy of about 92% for most of theclasses. Through our experiments, we show that NODE not only performs as wellas other deep neural networks, but has additional advantages over them, whichcan prove very useful for next generation surveys. We also compare our resultagainst ResNet. While ResNet and its variants suffer problems, such as timeconsuming architecture selection (e.g. the number of layers) and therequirement of large data for training, NODE does not have these requirements.Through various metrics, we conclude that the performance of NODE matches thatof other models, despite using only one-third of the total number of parametersas compared to these other models."^^schema:Text ;
    schema:author "P. K. Srijith"^^schema:Person,
        "Raghav Gupta"^^schema:Person,
        "Shantanu Desai"^^schema:Person ;
    schema:dateModified "2020-12-14T17:32:06Z"^^schema:DateTime ;
    schema:datePublished "2020-12-14T17:32:06Z"^^schema:DateTime ;
    schema:genre "astro-ph.GA"^^schema:Text,
        "astro-ph.IM"^^schema:Text ;
    schema:headline "Galaxy Morphology Classification using Neural Ordinary Differential  Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.07735v1"^^schema:URL .

<1621> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning is a promising approach to training a dialogmanager, but current methods struggle with the large state and action spaces ofmulti-domain dialog systems. Building upon Deep Q-learning from Demonstrations(DQfD), an algorithm that scores highly in difficult Atari games, we leveragedialog data to guide the agent to successfully respond to a user's requests. Wemake progressively fewer assumptions about the data needed, using labeled,reduced-labeled, and even unlabeled data to train expert demonstrators. Weintroduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us toovercome the domain gap between the datasets and the environment. Experimentsin a challenging multi-domain dialog system framework validate our approaches,and get high success rates even when trained on out-of-domain data."^^schema:Text ;
    schema:author "Gabriel Gordon-Hall"^^schema:Person,
        "Philip John Gorinski"^^schema:Person,
        "Shay B. Cohen"^^schema:Person ;
    schema:dateModified "2020-08-13T16:02:03Z"^^schema:DateTime ;
    schema:datePublished "2020-04-23T10:22:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning Dialog Policies from Weak Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.11054v2"^^schema:URL .

<1622> a schema:ScholarlyArticle ;
    schema:abstract "We propose a transformation network for generating visually-protected imagesfor privacy-preserving DNNs. The proposed transformation network is trained byusing a plain image dataset so that plain images are transformed into visuallyprotected ones. Conventional perceptual encryption methods have a weakvisual-protection performance and some accuracy degradation in imageclassification. In contrast, the proposed network enables us not only tostrongly protect visual information but also to maintain the imageclassification accuracy that using plain images achieves. In an imageclassification experiment, the proposed network is demonstrated to stronglyprotect visual information on plain images without any performance degradationunder the use of CIFAR datasets. In addition, it is shown that the visuallyprotected images are robust against a DNN-based attack, called inversetransformation network attack (ITN-Attack) in an experiment."^^schema:Text ;
    schema:author "Hiroki Ito"^^schema:Person,
        "Hitoshi Kiya"^^schema:Person,
        "Yuma Kinoshita"^^schema:Person ;
    schema:dateModified "2020-08-07T12:58:45Z"^^schema:DateTime ;
    schema:datePublished "2020-08-07T12:58:45Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Image Transformation Network for Privacy-Preserving Deep Neural Networks  and Its Security Evaluation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.03143v1"^^schema:URL .

<1623> a schema:ScholarlyArticle ;
    schema:abstract "Automatic captioning of images is a task that combines the challenges ofimage analysis and text generation. One important aspect in captioning is thenotion of attention: How to decide what to describe and in which order.Inspired by the successes in text analysis and translation, previous work haveproposed the \\textit{transformer} architecture for image captioning. However,the structure between the \\textit{semantic units} in images (usually thedetected regions from object detection model) and sentences (each single word)is different. Limited work has been done to adapt the transformer's internalarchitecture to images. In this work, we introduce the \\textbf{\\textit{imagetransformer}}, which consists of a modified encoding transformer and animplicit decoding transformer, motivated by the relative spatial relationshipbetween image regions. Our design widen the original transformer layer's innerarchitecture to adapt to the structure of images. With only regions feature asinputs, our model achieves new state-of-the-art performance on both MSCOCOoffline and online testing benchmarks."^^schema:Text ;
    schema:author "Bodo Rosenhahn"^^schema:Person,
        "Hamed R. Tavakoli"^^schema:Person,
        "Michael Yang"^^schema:Person,
        "Nicolas Pugeault"^^schema:Person,
        "Sen He"^^schema:Person,
        "Wentong Liao"^^schema:Person ;
    schema:dateModified "2020-10-02T19:26:14Z"^^schema:DateTime ;
    schema:datePublished "2020-04-29T14:30:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Image Captioning through Image Transformer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.14231v2"^^schema:URL .

<1624> a schema:ScholarlyArticle ;
    schema:abstract "Long Short-Term Memory (LSTM) networks are often used to capture temporaldependency patterns. By stacking multi-layer LSTM networks, it can capture evenmore complex patterns. This paper explores the effectiveness of applyingstacked LSTM networks in the time series prediction domain, specifically, thetraffic volume forecasting. Being able to predict traffic volume moreaccurately can result in better planning, thus greatly reduce the operationcost and improve overall efficiency."^^schema:Text ;
    schema:author "Frank Xiao"^^schema:Person ;
    schema:dateModified "2020-11-02T03:09:23Z"^^schema:DateTime ;
    schema:datePublished "2020-11-02T03:09:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Time Series Forecasting with Stacked Long Short-Term Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00697v1"^^schema:URL .

<1625> a schema:ScholarlyArticle ;
    schema:abstract "We show that a neural network with arbitrary depth and non-linearities, withdropout applied before every weight layer, is mathematically equivalent to anapproximation to a well known Bayesian model. This interpretation might offeran explanation to some of dropout's key properties, such as its robustness toover-fitting. Our interpretation allows us to reason about uncertainty in deeplearning, and allows the introduction of the Bayesian machinery into existingdeep learning frameworks in a principled way.  This document is an appendix for the main paper \"Dropout as a BayesianApproximation: Representing Model Uncertainty in Deep Learning\" by Gal andGhahramani, 2015."^^schema:Text ;
    schema:author "Yarin Gal"^^schema:Person,
        "Zoubin Ghahramani"^^schema:Person ;
    schema:dateModified "2016-05-25T18:46:56Z"^^schema:DateTime ;
    schema:datePublished "2015-06-06T14:42:06Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Dropout as a Bayesian Approximation: Appendix"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1506.02157v5"^^schema:URL .

<1626> a schema:ScholarlyArticle ;
    schema:abstract "Recently, many studies show that deep neural networks (DNNs) are susceptibleto adversarial examples. However, in order to convince that adversarialexamples are real threats in real physical world, it is necessary to study andevaluate the adversarial examples in real-world scenarios. In this paper, wepropose a robust and natural physical adversarial example attack methodtargeting object detectors under real-world conditions, which is morechallenging than targeting image classifiers. The generated adversarialexamples are robust to various physical constraints and visually look similarto the original images, thus these adversarial examples are natural to humansand will not cause any suspicions. First, to ensure the robustness of theadversarial examples in real-world conditions, the proposed method exploitsdifferent image transformation functions (Distance, Angle, Illumination,Printing and Photographing), to simulate various physical changes during theiterative optimization of the adversarial examples generation. Second, toconstruct natural adversarial examples, the proposed method uses an adaptivemask to constrain the area and intensities of added perturbations, and utilizesthe real-world perturbation score (RPS) to make the perturbations be similar tothose real noises in physical world. Compared with existing studies, ourgenerated adversarial examples can achieve a high success rate with lessconspicuous perturbations. Experimental results demonstrate that, the generatedadversarial examples are robust under various indoor and outdoor physicalconditions. Finally, the proposed physical adversarial attack method isuniversal and can work in black-box scenarios. The generated adversarialexamples generalize well between different models."^^schema:Text ;
    schema:author "Can He"^^schema:Person,
        "Chengxiang Yuan"^^schema:Person,
        "Jian Wang"^^schema:Person,
        "Mingfu Xue"^^schema:Person,
        "Weiqiang Liu"^^schema:Person ;
    schema:dateModified "2020-11-27T12:03:53Z"^^schema:DateTime ;
    schema:datePublished "2020-11-27T12:03:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Robust and Natural Physical Adversarial Examples for Object Detectors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13692v1"^^schema:URL .

<1627> a schema:ScholarlyArticle ;
    schema:abstract "Machine Comprehension (MC) is a challenging task in Natural LanguageProcessing field, which aims to guide the machine to comprehend a passage andanswer the given question. Many existing approaches on MC task are sufferingthe inefficiency in some bottlenecks, such as insufficient lexicalunderstanding, complex question-passage interaction, incorrect answerextraction and so on. In this paper, we address these problems from theviewpoint of how humans deal with reading tests in a scientific way.Specifically, we first propose a novel lexical gating mechanism to dynamicallycombine the words and characters representations. We then guide the machines toread in an interactive way with attention mechanism and memory network. Finallywe add a checking layer to refine the answer for insurance. The extensiveexperiments on two popular datasets SQuAD and TriviaQA show that our methodexceeds considerable performance than most state-of-the-art solutions at thetime of submission."^^schema:Text ;
    schema:author "Bin Cao"^^schema:Person,
        "Deng Cai"^^schema:Person,
        "Rongqin Yang"^^schema:Person,
        "Xiaofei He"^^schema:Person,
        "Zheqian Chen"^^schema:Person,
        "Zhou Zhao"^^schema:Person ;
    schema:dateModified "2017-10-08T02:51:26Z"^^schema:DateTime ;
    schema:datePublished "2017-10-08T02:51:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Smarnet: Teaching Machines to Read and Comprehend Like Human"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.02772v1"^^schema:URL .

<1628> a schema:ScholarlyArticle ;
    schema:abstract "A long-standing obstacle to progress in deep learning is the problem ofvanishing and exploding gradients. Although, the problem has largely beenovercome via carefully constructed initializations and batch normalization,architectures incorporating skip-connections such as highway and resnetsperform much better than standard feedforward architectures despite well-choseninitialization and batch normalization. In this paper, we identify theshattered gradients problem. Specifically, we show that the correlation betweengradients in standard feedforward networks decays exponentially with depthresulting in gradients that resemble white noise whereas, in contrast, thegradients in architectures with skip-connections are far more resistant toshattering, decaying sublinearly. Detailed empirical evidence is presented insupport of the analysis, on both fully-connected networks and convnets.Finally, we present a new \"looks linear\" (LL) initialization that preventsshattering, with preliminary experiments showing the new initialization allowsto train very deep networks without the addition of skip-connections."^^schema:Text ;
    schema:author "Brian McWilliams"^^schema:Person,
        "David Balduzzi"^^schema:Person,
        "JP Lewis"^^schema:Person,
        "Kurt Wan-Duo Ma"^^schema:Person,
        "Lennox Leary"^^schema:Person,
        "Marcus Frean"^^schema:Person ;
    schema:dateModified "2018-06-06T10:08:21Z"^^schema:DateTime ;
    schema:datePublished "2017-02-28T01:06:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Shattered Gradients Problem: If resnets are the answer, then what is  the question?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.08591v2"^^schema:URL .

<1629> a schema:ScholarlyArticle ;
    schema:abstract "The quality of automatic speech recognition (ASR) is critical to DialogueSystems as ASR errors propagate to and directly impact downstream tasks such aslanguage understanding (LU). In this paper, we propose multi-task neuralapproaches to perform contextual language correction on ASR outputs jointlywith LU to improve the performance of both tasks simultaneously. To measure theeffectiveness of this approach we used a public benchmark, the 2nd DialogueState Tracking (DSTC2) corpus. As a baseline approach, we trained task-specificStatistical Language Models (SLM) and fine-tuned state-of-the-art GeneralizedPre-training (GPT) Language Model to re-rank the n-best ASR hypotheses,followed by a model to identify the dialog act and slots. i) We further trainedranker models using GPT and Hierarchical CNN-RNN models with discriminatorylosses to detect the best output given n-best hypotheses. We extended theseranker models to first select the best ASR output and then identify thedialogue act and slots in an end to end fashion. ii) We also proposed a noveljoint ASR error correction and LU model, a word confusion pointer network(WCN-Ptr) with multi-head self-attention on top, which consumes the wordconfusions populated from the n-best. We show that the error rates of off theshelf ASR and following LU systems can be reduced significantly by 14% relativewith joint models trained using small amounts of in-domain data."^^schema:Text ;
    schema:author "Alexandros Papangelis"^^schema:Person,
        "Chandra Khatri"^^schema:Person,
        "Franziska Bell"^^schema:Person,
        "Gokhan Tur"^^schema:Person,
        "Huaixiu Zheng"^^schema:Person,
        "Hugh Williams"^^schema:Person,
        "Mahdi Namazifar"^^schema:Person,
        "Piero Molino"^^schema:Person,
        "Runze Wang"^^schema:Person,
        "Sai Sumanth Miryala"^^schema:Person,
        "Yue Weng"^^schema:Person ;
    schema:dateModified "2020-01-28T22:09:25Z"^^schema:DateTime ;
    schema:datePublished "2020-01-28T22:09:25Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Joint Contextual Modeling for ASR Correction and Language Understanding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.00750v1"^^schema:URL .

<163> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the value iteration network (VIN): a fully differentiable neuralnetwork with a `planning module' embedded within. VINs can learn to plan, andare suitable for predicting outcomes that involve planning-based reasoning,such as policies for reinforcement learning. Key to our approach is a noveldifferentiable approximation of the value-iteration algorithm, which can berepresented as a convolutional neural network, and trained end-to-end usingstandard backpropagation. We evaluate VIN based policies on discrete andcontinuous path-planning domains, and on a natural-language based search task.We show that by learning an explicit planning computation, VIN policiesgeneralize better to new, unseen domains."^^schema:Text ;
    schema:author "Aviv Tamar"^^schema:Person,
        "Garrett Thomas"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Yi Wu"^^schema:Person ;
    schema:commentCount "344"^^schema:Integer ;
    schema:dateModified "2017-03-20T21:41:51Z"^^schema:DateTime ;
    schema:datePublished "2016-02-09T05:44:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Value Iteration Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02867v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9903414776362829253&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1630> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (DRL) policies have been shown to be deceived byperturbations (e.g., random noise or intensional adversarial attacks) on stateobservations that appear at test time but are unknown during training. Toincrease the robustness of DRL policies, previous approaches assume that theknowledge of adversaries can be added into the training process to achieve thecorresponding generalization ability on these perturbed observations. However,such an assumption not only makes the robustness improvement more expensive butmay also leave a model less effective to other kinds of attacks in the wild. Incontrast, we propose an adversary agnostic robust DRL paradigm that does notrequire learning from adversaries. To this end, we first theoretically derivethat robustness could indeed be achieved independently of the adversaries basedon a policy distillation setting. Motivated by this finding, we propose a newpolicy distillation loss with two terms: 1) a prescription gap maximizationloss aiming at simultaneously maximizing the likelihood of the action selectedby the teacher policy and the entropy over the remaining actions; 2) acorresponding Jacobian regularization loss that minimizes the magnitude of thegradient with respect to the input state. The theoretical analysis shows thatour distillation loss guarantees to increase the prescription gap and theadversarial robustness. Furthermore, experiments on five Atari games firmlyverify the superiority of our approach in terms of boosting adversarialrobustness compared to other state-of-the-art methods."^^schema:Text ;
    schema:author "Abhishek Gupta"^^schema:Person,
        "Xinghua Qu"^^schema:Person,
        "Yew-Soon Ong"^^schema:Person,
        "Zhu Sun"^^schema:Person ;
    schema:dateModified "2020-12-24T06:38:19Z"^^schema:DateTime ;
    schema:datePublished "2020-08-14T06:04:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversary Agnostic Robust Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.06199v2"^^schema:URL .

<1631> a schema:ScholarlyArticle ;
    schema:abstract "Gradient-based approximate inference methods, such as Stein variationalgradient descent (SVGD), provide simple and general-purpose inference enginesfor differentiable continuous distributions. However, existing forms of SVGDcannot be directly applied to discrete distributions. In this work, we fillthis gap by proposing a simple yet general framework that transforms discretedistributions to equivalent piecewise continuous distributions, on which thegradient-free SVGD is applied to perform efficient approximate inference. Theempirical results show that our method outperforms traditional algorithms suchas Gibbs sampling and discontinuous Hamiltonian Monte Carlo on variouschallenging benchmarks of discrete graphical models. We demonstrate that ourmethod provides a promising tool for learning ensembles of binarized neuralnetwork (BNN), outperforming other widely used ensemble methods on learningbinarized AlexNet on CIFAR-10 dataset. In addition, such transform can bestraightforwardly employed in gradient-free kernelized Stein discrepancy toperform goodness-of-fit (GOF) test on discrete distributions. Our proposedmethod outperforms existing GOF test methods for intractable discretedistributions."^^schema:Text ;
    schema:author "Fan Ding"^^schema:Person,
        "Jian Peng"^^schema:Person,
        "Jun Han"^^schema:Person,
        "Lorenzo Torresani"^^schema:Person,
        "Qiang Liu"^^schema:Person,
        "Xianglong Liu"^^schema:Person ;
    schema:dateModified "2020-03-01T22:45:41Z"^^schema:DateTime ;
    schema:datePublished "2020-03-01T22:45:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stein Variational Inference for Discrete Distributions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.00605v1"^^schema:URL .

<1632> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning is an appropriate and successful method to robustlyperform low-level robot control under noisy conditions. Symbolic actionplanning is useful to resolve causal dependencies and to break a causallycomplex problem down into a sequence of simpler high-level actions. A problemwith the integration of both approaches is that action planning is based ondiscrete high-level action- and state spaces, whereas reinforcement learning isusually driven by a continuous reward function. However, recent advances inreinforcement learning, specifically, universal value function approximatorsand hindsight experience replay, have focused on goal-independent methods basedon sparse rewards. In this article, we build on these novel methods tofacilitate the integration of action planning with reinforcement learning byexploiting the reward-sparsity as a bridge between the high-level and low-levelstate- and control spaces. As a result, we demonstrate that the integratedneuro-symbolic method is able to solve object manipulation problems thatinvolve tool use and non-trivial causal dependencies under noisy conditions,exploiting both data and knowledge."^^schema:Text ;
    schema:author "Manfred Eppe"^^schema:Person,
        "Phuong D. H. Nguyen"^^schema:Person,
        "Stefan Wermter"^^schema:Person ;
    schema:dateModified "2019-12-08T14:15:02Z"^^schema:DateTime ;
    schema:datePublished "2019-05-23T14:34:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "From semantics to execution: Integrating action planning with  reinforcement learning for robotic causal problem-solving"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.09683v2"^^schema:URL .

<1633> a schema:ScholarlyArticle ;
    schema:abstract "Gradient-based meta-learning approaches have been successful in few-shotlearning, transfer learning, and a wide range of other domains. Despite itsefficacy and simplicity, the burden of calculating the Hessian matrix withlarge memory footprints is the critical challenge in large-scale applications.To tackle this issue, we propose a simple yet straightforward method to reducethe cost by reusing the same gradient in a window of inner steps. We describethe dynamics of the multi-step estimation in the Lagrangian formalism anddiscuss how to reduce evaluating second-order derivatives estimating thedynamics. To validate our method, we experiment on meta-transfer learning andfew-shot learning tasks for multiple settings. The experiment on meta-transferemphasizes the applicability of training meta-networks, where otherapproximations are limited. For few-shot learning, we evaluate time and memorycomplexities compared with popular baselines. We show that our methodsignificantly reduces training time and memory usage, maintaining competitiveaccuracies, or even outperforming in some cases."^^schema:Text ;
    schema:author "Jin-Hwa Kim"^^schema:Person,
        "Junyoung Park"^^schema:Person,
        "Yongseok Choi"^^schema:Person ;
    schema:dateModified "2020-06-08T00:37:01Z"^^schema:DateTime ;
    schema:datePublished "2020-06-08T00:37:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-step Estimation for Gradient-based Meta-learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04298v1"^^schema:URL .

<1634> a schema:ScholarlyArticle ;
    schema:abstract "SchNetPack is a toolbox for the development and application of deep neuralnetworks to the prediction of potential energy surfaces and otherquantum-chemical properties of molecules and materials. It contains basicbuilding blocks of atomistic neural networks, manages their training andprovides simple access to common benchmark datasets. This allows for an easyimplementation and evaluation of new models. For now, SchNetPack includesimplementations of (weighted) atomcentered symmetry functions and the deeptensor neural network SchNet as well as ready-to-use scripts that allow totrain these models on molecule and material datasets. Based upon the PyTorchdeep learning framework, SchNetPack allows to efficiently apply the neuralnetworks to large datasets with millions of reference calculations as well asparallelize the model across multiple GPUs. Finally, SchNetPack provides aninterface to the Atomic Simulation Environment in order to make trained modelseasily accessible to researchers that are not yet familiar with neuralnetworks."^^schema:Text ;
    schema:author "A. Tkatchenko"^^schema:Person,
        "K. -R. Müller"^^schema:Person,
        "K. Nicoli"^^schema:Person,
        "K. T. Schütt"^^schema:Person,
        "M. Gastegger"^^schema:Person,
        "P. Kessel"^^schema:Person ;
    schema:dateModified "2018-09-04T16:25:45Z"^^schema:DateTime ;
    schema:datePublished "2018-09-04T16:25:45Z"^^schema:DateTime ;
    schema:genre "physics.chem-ph"^^schema:Text,
        "physics.comp-ph"^^schema:Text ;
    schema:headline "SchNetPack: A Deep Learning Toolbox For Atomistic Systems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.01072v1"^^schema:URL .

<1635> a schema:ScholarlyArticle ;
    schema:abstract "With the number of smart devices increasing, the demand for on-devicetext-to-speech (TTS) increases rapidly. In recent years, many prominentEnd-to-End TTS methods have been proposed, and have greatly improved thequality of synthesized speech. However, to ensure the qualified speech, mostTTS systems depend on large and complex neural network models, and it's hard todeploy these TTS systems on-device. In this paper, a small-footprint, fast,stable network for on-device TTS is proposed, named as DeviceTTS. DeviceTTSmakes use of a duration predictor as a bridge between encoder and decoder so asto avoid the problem of words skipping and repeating in Tacotron. As we allknow, model size is a key factor for on-device TTS. For DeviceTTS, DeepFeedforward Sequential Memory Network (DFSMN) is used as the basic component.Moreover, to speed up inference, mix-resolution decoder is proposed for balancethe inference speed and speech quality. Experiences are done with WORLD andLPCNet vocoder. Finally, with only 1.4 million model parameters and 0.099GFLOPS, DeviceTTS achieves comparable performance with Tacotron and FastSpeech.As far as we know, the DeviceTTS can meet the needs of most of the devices inpractical application."^^schema:Text ;
    schema:author "Hao Li"^^schema:Person,
        "Ming Lei"^^schema:Person,
        "Zhiying Huang"^^schema:Person ;
    schema:dateModified "2021-01-15T04:40:17Z"^^schema:DateTime ;
    schema:datePublished "2020-10-29T02:04:09Z"^^schema:DateTime ;
    schema:genre "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device  Text-to-Speech"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.15311v2"^^schema:URL .

<1636> a schema:ScholarlyArticle ;
    schema:abstract "The 2017 ASSISTments Data Mining competition aims to use data from alongitudinal study for predicting a brand-new outcome of students which hadnever been studied before by the educational data mining research community.Specifically, it facilitates research in developing predictive models thatpredict whether the first job of a student out of college belongs to a STEM(the acronym for science, technology, engineering, and mathematics) field. Thisis based on the student's learning history on the ASSISTments blended learningplatform in the form of extensive clickstream data gathered during the middleschool years. To tackle this challenge, we first estimate the expectedknowledge state of students with respect to different mathematical skills usinga deep knowledge tracing (DKT) model and an enhanced DKT (DKT+) model. We thencombine the features corresponding to the DKT/DKT+ expected knowledge statewith other features extracted directly from the student profile in the datasetto train several machine learning models for the STEM/non-STEM job prediction.Our experiments show that models trained with the combined features generallyperform better than the models trained with the student profile alone. Detailedanalysis of the student's knowledge state reveals that, when compared withnon-STEM students, STEM students generally show a higher mastery level and ahigher learning gain in mathematics."^^schema:Text ;
    schema:author "Chun-kit Yeung"^^schema:Person,
        "Dit-yan Yeung"^^schema:Person,
        "Kai Yang"^^schema:Person,
        "Zizheng Lin"^^schema:Person ;
    schema:dateModified "2018-06-06T13:57:47Z"^^schema:DateTime ;
    schema:datePublished "2018-06-06T13:57:47Z"^^schema:DateTime ;
    schema:genre "I.2.6; K.3.m"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Incorporating Features Learned by an Enhanced Deep Knowledge Tracing  Model for STEM/Non-STEM Job Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.03256v1"^^schema:URL .

<1637> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (NMT) is a recently proposed approachfor machine translation which aims to train the model without using any labeleddata. The models proposed for unsupervised NMT often use only one sharedencoder to map the pairs of sentences from different languages to ashared-latent space, which is weak in keeping the unique and internalcharacteristics of each language, such as the style, terminology, and sentencestructure. To address this issue, we introduce an extension by utilizing twoindependent encoders but sharing some partial weights which are responsible forextracting high-level representations of the input sentences. Besides, twodifferent generative adversarial networks (GANs), namely the local GAN andglobal GAN, are proposed to enhance the cross-language translation. With thisnew approach, we achieve significant improvements on English-German,English-French and Chinese-to-English translation tasks."^^schema:Text ;
    schema:author "Bo Xu"^^schema:Person,
        "Feng Wang"^^schema:Person,
        "Wei Chen"^^schema:Person,
        "Zhen Yang"^^schema:Person ;
    schema:dateModified "2018-04-24T14:11:28Z"^^schema:DateTime ;
    schema:datePublished "2018-04-24T14:11:28Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Unsupervised Neural Machine Translation with Weight Sharing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.09057v1"^^schema:URL .

<1638> a schema:ScholarlyArticle ;
    schema:abstract "Spherical convolutional networks have been introduced recently as tools tolearn powerful feature representations of 3D shapes. Spherical CNNs areequivariant to 3D rotations making them ideally suited to applications where 3Ddata may be observed in arbitrary orientations. In this paper we learn 2D imageembeddings with a similar equivariant structure: embedding the image of a 3Dobject should commute with rotations of the object. We introduce a cross-domainembedding from 2D images into a spherical CNN latent space. This embeddingencodes images with 3D shape properties and is equivariant to 3D rotations ofthe observed object. The model is supervised only by target embeddings obtainedfrom a spherical CNN pretrained for 3D shape classification. We show thatlearning a rich embedding for images with appropriate geometric structure issufficient for tackling varied applications, such as relative pose estimationand novel view synthesis, without requiring additional task-specificsupervision."^^schema:Text ;
    schema:author "Ameesh Makadia"^^schema:Person,
        "Avneesh Sud"^^schema:Person,
        "Carlos Esteves"^^schema:Person,
        "Kostas Daniilidis"^^schema:Person,
        "Zhengyi Luo"^^schema:Person ;
    schema:dateModified "2019-05-14T19:21:59Z"^^schema:DateTime ;
    schema:datePublished "2018-12-06T18:51:12Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Cross-Domain 3D Equivariant Image Embeddings"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.02716v2"^^schema:URL .

<1639> a schema:ScholarlyArticle ;
    schema:abstract "We propose to improve trust region policy search with normalizing flowspolicy. We illustrate that when the trust region is constructed by KLdivergence constraints, normalizing flows policy generates samples far from the'center' of the previous policy iterate, which potentially enables betterexploration and helps avoid bad local optima. Through extensive comparisons, weshow that the normalizing flows policy significantly improves upon baselinearchitectures especially on high-dimensional tasks with complex dynamics."^^schema:Text ;
    schema:author "Shipra Agrawal"^^schema:Person,
        "Yunhao Tang"^^schema:Person ;
    schema:dateModified "2019-02-01T14:28:17Z"^^schema:DateTime ;
    schema:datePublished "2018-09-27T03:19:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Boosting Trust Region Policy Optimization by Normalizing Flows Policy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10326v3"^^schema:URL .

<164> a schema:ScholarlyArticle ;
    schema:abstract "We define and address the problem of unsupervised learning of disentangledrepresentations on data generated from independent factors of variation. Wepropose FactorVAE, a method that disentangles by encouraging the distributionof representations to be factorial and hence independent across the dimensions.We show that it improves upon $\\beta$-VAE by providing a better trade-offbetween disentanglement and reconstruction quality. Moreover, we highlight theproblems of a commonly used disentanglement metric and introduce a new metricthat does not suffer from them."^^schema:Text ;
    schema:author "Andriy Mnih"^^schema:Person,
        "Hyunjik Kim"^^schema:Person ;
    schema:commentCount "283"^^schema:Integer ;
    schema:dateModified "2019-07-09T10:43:41Z"^^schema:DateTime ;
    schema:datePublished "2018-02-16T15:43:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Disentangling by Factorising"^^schema:Text ;
    schema:publisher "ICML, 2654-2663"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.05983v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4010663500903508201&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1640> a schema:ScholarlyArticle ;
    schema:abstract "Proximal policy optimization and trust region policy optimization (PPO andTRPO) with actor and critic parametrized by neural networks achieve significantempirical success in deep reinforcement learning. However, due to nonconvexity,the global convergence of PPO and TRPO remains less understood, which separatestheory from practice. In this paper, we prove that a variant of PPO and TRPOequipped with overparametrized neural networks converges to the globallyoptimal policy at a sublinear rate. The key to our analysis is the globalconvergence of infinite-dimensional mirror descent under a notion of one-pointmonotonicity, where the gradient and iterate are instantiated by neuralnetworks. In particular, the desirable representation power and optimizationgeometry induced by the overparametrization of such neural networks allow themto accurately approximate the infinite-dimensional gradient and iterate."^^schema:Text ;
    schema:author "Boyi Liu"^^schema:Person,
        "Qi Cai"^^schema:Person,
        "Zhaoran Wang"^^schema:Person,
        "Zhuoran Yang"^^schema:Person ;
    schema:dateModified "2019-09-11T07:07:35Z"^^schema:DateTime ;
    schema:datePublished "2019-06-25T03:20:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Proximal/Trust Region Policy Optimization Attains Globally  Optimal Policy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.10306v2"^^schema:URL .

<1641> a schema:ScholarlyArticle ;
    schema:abstract "Detecting the emergence of abrupt property changes in time series is achallenging problem. Kernel two-sample test has been studied for this taskwhich makes fewer assumptions on the distributions than traditional parametricapproaches. However, selecting kernels is non-trivial in practice. Althoughkernel selection for two-sample test has been studied, the insufficient samplesin change point detection problem hinder the success of those developed kernelselection algorithms. In this paper, we propose KL-CPD, a novel kernel learningframework for time series CPD that optimizes a lower bound of test power via anauxiliary generative model. With deep kernel parameterization, KL-CPD endowskernel two-sample test with the data-driven kernel to detect different types ofchange-points in real-world applications. The proposed approach significantlyoutperformed other state-of-the-art methods in our comparative evaluation ofbenchmark datasets and simulation studies."^^schema:Text ;
    schema:author "Barnabás Póczos"^^schema:Person,
        "Chun-Liang Li"^^schema:Person,
        "Wei-Cheng Chang"^^schema:Person,
        "Yiming Yang"^^schema:Person ;
    schema:dateModified "2019-01-18T04:06:58Z"^^schema:DateTime ;
    schema:datePublished "2019-01-18T04:06:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Kernel Change-point Detection with Auxiliary Deep Generative Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.06077v1"^^schema:URL .

<1642> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning (RL) has achieved tremendous progress in solvingvarious sequential decision-making problems, e.g., control tasks in robotics.However, RL methods often fail to generalize to safety-critical scenarios sincepolicies are overfitted to training environments. Previously, robustadversarial reinforcement learning (RARL) was proposed to train an adversarialnetwork that applies disturbances to a system, which improves robustness intest scenarios. A drawback of neural-network-based adversaries is thatintegrating system requirements without handcrafting sophisticated rewardsignals is difficult. Safety falsification methods allow one to find a set ofinitial conditions as well as an input sequence, such that the system violatesa given property formulated in temporal logic. In this paper, we proposefalsification-based RARL (FRARL), the first generic framework for integratingtemporal-logic falsification in adversarial learning to improve policyrobustness. With falsification method, we do not need to construct an extrareward function for the adversary. We evaluate our approach on a brakingassistance system and an adaptive cruise control system of autonomous vehicles.Experiments show that policies trained with a falsification-based adversarygeneralize better and show less violation of the safety specification in testscenarios than the ones trained without an adversary or with an adversarialnetwork."^^schema:Text ;
    schema:author "Matthias Althoff"^^schema:Person,
        "Saasha Nair"^^schema:Person,
        "Xiao Wang"^^schema:Person ;
    schema:dateModified "2020-07-17T16:29:31Z"^^schema:DateTime ;
    schema:datePublished "2020-07-01T18:32:05Z"^^schema:DateTime ;
    schema:genre "cs.FL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Falsification-Based Robust Adversarial Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.00691v2"^^schema:URL .

<1643> a schema:ScholarlyArticle ;
    schema:abstract "Smart city improved the quality of life for the citizens by implementinginformation communication technology (ICT) such as the internet of things(IoT). Nevertheless, the smart city is a critical environment that needs tosecure it is network and data from intrusions and attacks. This work proposes ahybrid deep learning (DL) model for cyber threat intelligence (CTI) to improvethreats classification performance based on convolutional neural network (CNN)and quasi-recurrent neural network (QRNN). We use QRNN to provide a real-timethreat classification model. The evaluation results of the proposed modelcompared to the state-of-the-art models show that the proposed modeloutperformed the other models. Therefore, it will help in classifying the smartcity threats in a reasonable time."^^schema:Text ;
    schema:author "Atta-ur-Rahman"^^schema:Person,
        "Najla Al-Taleb"^^schema:Person,
        "Nazar Abbas Saqib"^^schema:Person,
        "Sujata Dash"^^schema:Person ;
    schema:dateModified "2020-07-26T22:39:33Z"^^schema:DateTime ;
    schema:datePublished "2020-07-26T22:39:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text ;
    schema:headline "Cyber Threat Intelligence for Secure Smart City"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13233v1"^^schema:URL .

<1644> a schema:ScholarlyArticle ;
    schema:abstract "Traditional neural architecture search (NAS) has a significant impact incomputer vision by automatically designing network architectures for varioustasks. In this paper, binarized neural architecture search (BNAS), with asearch space of binarized convolutions, is introduced to produce extremelycompressed models to reduce huge computational cost on embedded devices foredge computing. The BNAS calculation is more challenging than NAS due to thelearning inefficiency caused by optimization requirements and the hugearchitecture space, and the performance loss when handling the wild data invarious computing applications. To address these issues, we introduce operationspace reduction and channel sampling into BNAS to significantly reduce the costof searching. This is accomplished through a performance-based strategy that isrobust to wild data, which is further used to abandon less potentialoperations. Furthermore, we introduce the Upper Confidence Bound (UCB) to solve1-bit BNAS. Two optimization methods for binarized neural networks are used tovalidate the effectiveness of our BNAS. Extensive experiments demonstrate thatthe proposed BNAS achieves a comparable performance to NAS on both CIFAR andImageNet databases. An accuracy of $96.53\\%$ vs. $97.22\\%$ is achieved on theCIFAR-10 dataset, but with a significantly compressed model, and a $40\\%$faster search than the state-of-the-art PC-DARTS. On the wild face recognitiontask, our binarized models achieve a performance similar to their correspondingfull-precision models."^^schema:Text ;
    schema:author "Baochang Zhang"^^schema:Person,
        "David Doermann"^^schema:Person,
        "Guodong Guo"^^schema:Person,
        "Hanlin Chen"^^schema:Person,
        "Jianzhuang Liu"^^schema:Person,
        "Li'an Zhuo"^^schema:Person,
        "Rongrong Ji"^^schema:Person,
        "Xiawu Zheng"^^schema:Person ;
    schema:dateModified "2020-09-08T15:51:23Z"^^schema:DateTime ;
    schema:datePublished "2020-09-08T15:51:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Binarized Neural Architecture Search for Efficient Object Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.04247v1"^^schema:URL .

<1645> a schema:ScholarlyArticle ;
    schema:abstract "Crowd behavior understanding is crucial yet challenging across a wide rangeof applications, since crowd behavior is inherently determined by a sequentialdecision-making process based on various factors, such as the pedestrians' owndestinations, interaction with nearby pedestrians and anticipation of upcomingevents. In this paper, we propose a novel framework of Social-Aware GenerativeAdversarial Imitation Learning (SA-GAIL) to mimic the underlyingdecision-making process of pedestrians in crowds. Specifically, we infer thelatent factors of human decision-making process in an unsupervised manner byextending the Generative Adversarial Imitation Learning framework to anticipatefuture paths of pedestrians. Different factors of human decision making aredisentangled with mutual information maximization, with the process modeled bycollision avoidance regularization and Social-Aware LSTMs. Experimental resultsdemonstrate the potential of our framework in disentangling the latentdecision-making factors of pedestrians and stronger abilities in predictingfuture trajectories."^^schema:Text ;
    schema:author "Hang Su"^^schema:Person,
        "Haosheng Zou"^^schema:Person,
        "Jun Zhu"^^schema:Person,
        "Shihong Song"^^schema:Person ;
    schema:dateModified "2018-01-25T13:08:43Z"^^schema:DateTime ;
    schema:datePublished "2018-01-25T13:08:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Understanding Human Behaviors in Crowds by Imitating the Decision-Making  Process"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.08391v1"^^schema:URL .

<1646> a schema:ScholarlyArticle ;
    schema:abstract "Non-intrusive load monitoring (NILM) allows users and energy providers togain insight into home appliance electricity consumption using only thebuilding's smart meter. Most current techniques for NILM are trained usingsignificant amounts of labeled appliances power data. The collection of suchdata is challenging, making data a major bottleneck in creating wellgeneralizing NILM solutions. To help mitigate the data limitations, we presentthe first truly synthetic appliance power signature generator. Our solution,PowerGAN, is based on conditional, progressively growing, 1-D Wassersteingenerative adversarial network (GAN). Using PowerGAN, we are able to synthesisetruly random and realistic appliance power data signatures. We evaluate thesamples generated by PowerGAN in a qualitative way as well as numerically byusing traditional GAN evaluation methods such as the Inception score."^^schema:Text ;
    schema:author "Alon Harell"^^schema:Person,
        "Ivan V. Bajic"^^schema:Person,
        "Richard Jones"^^schema:Person,
        "Stephen Makonin"^^schema:Person ;
    schema:dateModified "2020-07-20T05:10:40Z"^^schema:DateTime ;
    schema:datePublished "2020-07-20T05:10:40Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "PowerGAN: Synthesizing Appliance Power Signatures Using Generative  Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13645v1"^^schema:URL .

<1647> a schema:ScholarlyArticle ;
    schema:abstract "Maximum mean discrepancy (MMD) has been successfully applied to learn deepgenerative models for characterizing a joint distribution of variables viakernel mean embedding. In this paper, we present conditional generative moment-matching networks (CGMMN), which learn a conditional distribution given someinput variables based on a conditional maximum mean discrepancy (CMMD)criterion. The learning is performed by stochastic gradient descent with thegradient calculated by back-propagation. We evaluate CGMMN on a wide range oftasks, including predictive modeling, contextual generation, and Bayesian darkknowledge, which distills knowledge from a Bayesian model by learning arelatively small CGMMN student network. Our results demonstrate competitiveperformance in all the tasks."^^schema:Text ;
    schema:author "Jialian Li"^^schema:Person,
        "Jun Zhu"^^schema:Person,
        "Yong Ren"^^schema:Person,
        "Yucen Luo"^^schema:Person ;
    schema:dateModified "2016-06-14T07:11:29Z"^^schema:DateTime ;
    schema:datePublished "2016-06-14T07:11:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Conditional Generative Moment-Matching Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1606.04218v1"^^schema:URL .

<1648> a schema:ScholarlyArticle ;
    schema:abstract "We show that a critical vulnerability in adversarial imitation is thetendency of discriminator networks to learn spurious associations betweenvisual features and expert labels. When the discriminator focuses ontask-irrelevant features, it does not provide an informative reward signal,leading to poor task performance. We analyze this problem in detail and proposea solution that outperforms standard Generative Adversarial Imitation Learning(GAIL). Our proposed method, Task-Relevant Adversarial Imitation Learning(TRAIL), uses constrained discriminator optimization to learn informativerewards. In comprehensive experiments, we show that TRAIL can solve challengingrobotic manipulation tasks from pixels by imitating human operators withoutaccess to any task rewards, and clearly outperforms comparable baselineimitation agents, including those trained via behaviour cloning andconventional GAIL."^^schema:Text ;
    schema:author "Alexander Novikov"^^schema:Person,
        "David Budden"^^schema:Person,
        "Konrad Zolna"^^schema:Person,
        "Misha Denil"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Scott Reed"^^schema:Person,
        "Sergio Gomez Colmenarejo"^^schema:Person,
        "Serkan Cabi"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:dateModified "2020-11-12T18:30:23Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T16:53:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Task-Relevant Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.01077v2"^^schema:URL .

<1649> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel reinforcement learning algorithm, AlphaNPI, thatincorporates the strengths of Neural Programmer-Interpreters (NPI) andAlphaZero. NPI contributes structural biases in the form of modularity,hierarchy and recursion, which are helpful to reduce sample complexity, improvegeneralization and increase interpretability. AlphaZero contributes powerfulneural network guided search algorithms, which we augment with recursion.AlphaNPI only assumes a hierarchical program specification with sparse rewards:1 when the program execution satisfies the specification, and 0 otherwise.Using this specification, AlphaNPI is able to train NPI models effectively withRL for the first time, completely eliminating the need for strong supervisionin the form of execution traces. The experiments show that AlphaNPI can sort aswell as previous strongly supervised NPI variants. The AlphaNPI agent is alsotrained on a Tower of Hanoi puzzle with two disks and is shown to generalize topuzzles with an arbitrary number of disk"^^schema:Text ;
    schema:author "Alexandre Laterre"^^schema:Person,
        "David Kas"^^schema:Person,
        "Guillaume Ligner"^^schema:Person,
        "Karim Beguir"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Nicolas Perrin"^^schema:Person,
        "Olivier Sigaud"^^schema:Person,
        "Scott Reed"^^schema:Person,
        "Thomas Pierrot"^^schema:Person ;
    schema:dateModified "2019-05-30T10:08:00Z"^^schema:DateTime ;
    schema:datePublished "2019-05-30T10:08:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Learning Compositional Neural Programs with Recursive Tree Search and  Planning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.12941v1"^^schema:URL .

<165> a schema:ScholarlyArticle ;
    schema:abstract "We present sketch-rnn, a recurrent neural network (RNN) able to constructstroke-based drawings of common objects. The model is trained on thousands ofcrude human-drawn images representing hundreds of classes. We outline aframework for conditional and unconditional sketch generation, and describe newrobust training methods for generating coherent sketch drawings in a vectorformat."^^schema:Text ;
    schema:author "David Ha"^^schema:Person,
        "Douglas Eck"^^schema:Person ;
    schema:commentCount "289"^^schema:Integer ;
    schema:dateModified "2017-05-19T16:40:16Z"^^schema:DateTime ;
    schema:datePublished "2017-04-11T18:09:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Neural Representation of Sketch Drawings"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.03477v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2337146750300919321&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1650> a schema:ScholarlyArticle ;
    schema:abstract "Nowadays, digital content is widespread and simply redistributable, eitherlawfully or unlawfully. For example, after images are posted on the internet,other web users can modify them and then repost their versions, therebygenerating near-duplicate images. The presence of near-duplicates affects theperformance of the search engines critically. Computer vision is concerned withthe automatic extraction, analysis and understanding of useful information fromdigital images. The main application of computer vision is image understanding.There are several tasks in image understanding such as feature extraction,object detection, object recognition, image cleaning, image transformation,etc. There is no proper survey in literature related to near duplicatedetection of images. In this paper, we review the state-of-the-art computervision-based approaches and feature extraction methods for the detection ofnear duplicate images. We also discuss the main challenges in this field andhow other researchers addressed those challenges. This review provides researchdirections to the fellow researchers who are interested to work in this field."^^schema:Text ;
    schema:author "G. Kalaiarasi"^^schema:Person,
        "K. K. Thyagharajan"^^schema:Person ;
    schema:dateModified "2020-09-07T16:41:46Z"^^schema:DateTime ;
    schema:datePublished "2020-09-07T16:41:46Z"^^schema:DateTime ;
    schema:genre "I.4.7; I.4.9; I.4.10; I.5.2; I.5.3; I.5.4; I.2.4; I.2.6; I.2.10;&#10;  H.3.1; H.3.3"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "A Review on Near Duplicate Detection of Images using Computer Vision  Techniques"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.03224v1"^^schema:URL .

<1651> a schema:ScholarlyArticle ;
    schema:abstract "In E-commerce advertising, where product recommendations and product ads arepresented to users simultaneously, the traditional setting is to display ads atfixed positions. However, under such a setting, the advertising system losesthe flexibility to control the number and positions of ads, resulting insub-optimal platform revenue and user experience. Consequently, majore-commerce platforms (e.g., Taobao.com) have begun to consider more flexibleways to display ads. In this paper, we investigate the problem of advertisingwith adaptive exposure: can we dynamically determine the number and positionsof ads for each user visit under certain business constraints so that theplatform revenue can be increased? More specifically, we consider two types ofconstraints: request-level constraint ensures user experience for each uservisit, and platform-level constraint controls the overall platform monetizationrate. We model this problem as a Constrained Markov Decision Process withper-state constraint (psCMDP) and propose a constrained two-level reinforcementlearning approach to decompose the original problem into two relativelyindependent sub-problems. To accelerate policy learning, we also devise aconstrained hindsight experience replay mechanism. Experimental evaluations onindustry-scale real-world datasets demonstrate the merits of our approach inboth obtaining higher revenue under the constraints and the effectiveness ofthe constrained hindsight experience replay mechanism."^^schema:Text ;
    schema:author "Chuan Yu"^^schema:Person,
        "Chunjie Chen"^^schema:Person,
        "Han Li"^^schema:Person,
        "Jian Xu"^^schema:Person,
        "Jianye Hao"^^schema:Person,
        "Jun Wang"^^schema:Person,
        "Junqi Jin"^^schema:Person,
        "Kun Gai"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Weixun Wang"^^schema:Person,
        "Xiaotian Hao"^^schema:Person,
        "Yixi Wang"^^schema:Person ;
    schema:dateModified "2019-09-03T01:55:56Z"^^schema:DateTime ;
    schema:datePublished "2018-09-10T06:15:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Adaptive Display Exposure for Real-Time Advertising"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.03149v2"^^schema:URL .

<1652> a schema:ScholarlyArticle ;
    schema:abstract "Neural decoders were shown to outperform classical message passing techniquesfor short BCH codes. In this work, we extend these results to much largerfamilies of algebraic block codes, by performing message passing with graphneural networks. The parameters of the sub-network at each variable-node in theTanner graph are obtained from a hypernetwork that receives the absolute valuesof the current message as input. To add stability, we employ a simplifiedversion of the arctanh activation that is based on a high order Taylorapproximation of this activation function. Our results show that for a largenumber of algebraic block codes, from diverse families of codes (BCH, LDPC,Polar), the decoding obtained with our method outperforms the vanilla beliefpropagation method as well as other learning techniques from the literature."^^schema:Text ;
    schema:author "Eliya Nachmani"^^schema:Person,
        "Lior Wolf"^^schema:Person ;
    schema:dateModified "2019-10-25T12:30:20Z"^^schema:DateTime ;
    schema:datePublished "2019-09-05T21:47:35Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hyper-Graph-Network Decoders for Block Codes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.09036v2"^^schema:URL .

<1653> a schema:ScholarlyArticle ;
    schema:abstract "Echo States Networks (ESN) and Long-Short Term Memory networks (LSTM) are twopopular architectures of Recurrent Neural Networks (RNN) to solve machinelearning task involving sequential data. However, little have been done tocompare their performances and their internal mechanisms on a common task. Inthis work, we trained ESNs and LSTMs on a Cross-Situationnal Learning (CSL)task. This task aims at modelling how infants learn language: they createassociations between words and visual stimuli in order to extract meaning fromwords and sentences. The results are of three kinds: performance comparison,internal dynamics analyses and visualization of latent space. (1) We found thatboth models were able to successfully learn the task: the LSTM reached thelowest error for the basic corpus, but the ESN was quicker to train.Furthermore, the ESN was able to outperform LSTMs on datasets more challengingwithout any further tuning needed. (2) We also conducted an analysis of theinternal units activations of LSTMs and ESNs. Despite the deep differencesbetween both models (trained or fixed internal weights), we were able touncover similar inner mechanisms: both put emphasis on the units encodingaspects of the sentence structure. (3) Moreover, we present Recurrent StatesSpace Visualisations (RSSviz), a method to visualize the structure of latentstate space of RNNs, based on dimension reduction (using UMAP). This techniqueenables us to observe a fractal embedding of sequences in the LSTM. RSSviz isalso useful for the analysis of ESNs (i) to spot difficult examples and (ii) togenerate animated plots showing the evolution of activations across learningstages. Finally, we explore qualitatively how the RSSviz could provide anintuitive visualisation to understand the influence of hyperparameters on thereservoir dynamics prior to ESN training."^^schema:Text ;
    schema:author "Alexandre Variengien"^^schema:Person,
        "Xavier Hinaut"^^schema:Person ;
    schema:dateModified "2020-12-13T16:06:12Z"^^schema:DateTime ;
    schema:datePublished "2020-12-03T08:32:01Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text ;
    schema:headline "A journey in ESN and LSTM visualisations on a language task"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.01748v2"^^schema:URL .

<1654> a schema:ScholarlyArticle ;
    schema:abstract "Generative models and inferential autoencoders mostly make use of $\\ell_2$norm in their optimization objectives. In order to generate perceptually betterimages, this short paper theoretically discusses how to use StructuralSimilarity Index (SSIM) in generative models and inferential autoencoders. Wefirst review SSIM, SSIM distance metrics, and SSIM kernel. We show that theSSIM kernel is a universal kernel and thus can be used in unconditional andconditional generated moment matching networks. Then, we explain how to useSSIM distance in variational and adversarial autoencoders and unconditional andconditional Generative Adversarial Networks (GANs). Finally, we propose to useSSIM distance rather than $\\ell_2$ norm in least squares GAN."^^schema:Text ;
    schema:author "Benyamin Ghojogh"^^schema:Person,
        "Fakhri Karray"^^schema:Person,
        "Mark Crowley"^^schema:Person ;
    schema:dateModified "2020-04-04T05:39:15Z"^^schema:DateTime ;
    schema:datePublished "2020-04-04T05:39:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Theoretical Insights into the Use of Structural Similarity Index In  Generative Models and Inferential Autoencoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.01864v1"^^schema:URL .

<1655> a schema:ScholarlyArticle ;
    schema:abstract "Simulations of particle showers in calorimeters are computationallytime-consuming, as they have to reproduce both energy depositions and theirconsiderable fluctuations. A new approach to ultra-fast simulations aregenerative models where all calorimeter energy depositions are generatedsimultaneously. We use GEANT4 simulations of an electron beam impinging on amulti-layer electromagnetic calorimeter for adversarial training of a generatornetwork and a critic network guided by the Wasserstein distance. The generatoris constraint during the training such that the generated showers show theexpected dependency on the initial energy and the impact position. It producesrealistic calorimeter energy depositions, fluctuations and correlations whichwe demonstrate in distributions of typical calorimeter observables. In mostaspects, we observe that generated calorimeter showers reach the level ofshowers as simulated with the GEANT4 program."^^schema:Text ;
    schema:author "Jonas Glombitza"^^schema:Person,
        "Martin Erdmann"^^schema:Person,
        "Thorben Quast"^^schema:Person ;
    schema:dateModified "2020-02-04T08:26:38Z"^^schema:DateTime ;
    schema:datePublished "2018-07-05T12:05:19Z"^^schema:DateTime ;
    schema:genre "hep-ex"^^schema:Text,
        "physics.ins-det"^^schema:Text ;
    schema:headline "Precise simulation of electromagnetic calorimeter showers using a  Wasserstein Generative Adversarial Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.01954v2"^^schema:URL .

<1656> a schema:ScholarlyArticle ;
    schema:abstract "We consider a system to optimize duration of traffic signals usingmulti-agent deep reinforcement learning and Vehicle-to-Everything (V2X)communication. This system aims at analyzing independent and shared rewards formulti-agents to control duration of traffic lights. A learning agent trafficlight gets information along its lanes within a circular V2X coverage. Theduration cycles of traffic light are modeled as Markov decision Processes. Weinvestigate four variations of reward functions. The first two areunshared-rewards: based on waiting number, and waiting time of vehicles betweentwo cycles of traffic light. The third and fourth functions are: shared-rewardsbased on waiting cars, and waiting time for all agents. Each agent has a memoryfor optimization through target network and prioritized experience replay. Weevaluate multi-agents through the Simulation of Urban MObility (SUMO)simulator. The results prove effectiveness of the proposed system to optimizetraffic signals and reduce average waiting cars to 41.5 % as compared to thetraditional periodic traffic control system."^^schema:Text ;
    schema:author "Azhar Hussain"^^schema:Person,
        "Cao Jiahua"^^schema:Person,
        "Tong Wang"^^schema:Person ;
    schema:dateModified "2020-02-23T07:43:12Z"^^schema:DateTime ;
    schema:datePublished "2020-02-23T07:43:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Optimizing Traffic Lights with Multi-agent Deep Reinforcement Learning  and V2X communication"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.09853v1"^^schema:URL .

<1657> a schema:ScholarlyArticle ;
    schema:abstract "Existing generative adversarial networks (GANs) for speech enhancement solelyrely on the convolution operation, which may obscure temporal dependenciesacross the sequence input. To remedy this issue, we propose a self-attentionlayer adapted from non-local attention, coupled with the convolutional anddeconvolutional layers of a speech enhancement GAN (SEGAN) using raw signalinput. Further, we empirically study the effect of placing the self-attentionlayer at the (de)convolutional layers with varying layer indices as well as atall of them when memory allows. Our experiments show that introducingself-attention to SEGAN leads to consistent improvement across the objectiveevaluation metrics of enhancement performance. Furthermore, applying atdifferent (de)convolutional layers does not significantly alter performance,suggesting that it can be conveniently applied at the highest-level(de)convolutional layer with the smallest memory overhead."^^schema:Text ;
    schema:author "Alfred Mertins"^^schema:Person,
        "Huy Le Nguyen"^^schema:Person,
        "Huy Phan"^^schema:Person,
        "Ian McLoughlin"^^schema:Person,
        "Ngoc Q. K. Duong"^^schema:Person,
        "Oliver Y. Chén"^^schema:Person,
        "Philipp Koch"^^schema:Person ;
    schema:dateModified "2021-02-06T19:51:48Z"^^schema:DateTime ;
    schema:datePublished "2020-10-18T22:59:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Self-Attention Generative Adversarial Network for Speech Enhancement"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.09132v3"^^schema:URL .

<1658> a schema:ScholarlyArticle ;
    schema:abstract "Compared to sequential learning models, graph-based neural networks exhibitsome excellent properties, such as ability capturing global information. Inthis paper, we investigate graph-based neural networks for text classificationproblem. A new framework TensorGCN (tensor graph convolutional networks), ispresented for this task. A text graph tensor is firstly constructed to describesemantic, syntactic, and sequential contextual information. Then, two kinds ofpropagation learning perform on the text graph tensor. The first is intra-graphpropagation used for aggregating information from neighborhood nodes in asingle graph. The second is inter-graph propagation used for harmonizingheterogeneous information between graphs. Extensive experiments are conductedon benchmark datasets, and the results illustrate the effectiveness of ourproposed framework. Our proposed TensorGCN presents an effective way toharmonize and integrate heterogeneous information from different kinds ofgraphs."^^schema:Text ;
    schema:author "Ji Wu"^^schema:Person,
        "Ping Lv"^^schema:Person,
        "Xiao Zhang"^^schema:Person,
        "Xien Liu"^^schema:Person,
        "Xinxin You"^^schema:Person ;
    schema:dateModified "2020-01-12T14:28:33Z"^^schema:DateTime ;
    schema:datePublished "2020-01-12T14:28:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Tensor Graph Convolutional Networks for Text Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.05313v1"^^schema:URL .

<1659> a schema:ScholarlyArticle ;
    schema:abstract "Estimation of distribution algorithms (EDA) are stochastic optimizationalgorithms. EDA establishes a probability model to describe the distribution ofsolution from the perspective of population macroscopically by statisticallearning method, and then randomly samples the probability model to generate anew population. EDA can better solve multi-objective optimal problems (MOPs).However, the performance of EDA decreases in solving many-objective optimalproblems (MaOPs), which contains more than three objectives. Reference VectorGuided Evolutionary Algorithm (RVEA), based on the EDA framework, can bettersolve MaOPs. In our paper, we use the framework of RVEA. However, we generatethe new population by Wasserstein Generative Adversarial Networks-GradientPenalty (WGAN-GP) instead of using crossover and mutation. WGAN-GP haveadvantages of fast convergence, good stability and high sample quality. WGAN-GPlearn the mapping relationship from standard normal distribution to given dataset distribution based on a given data set subject to the same distribution. Itcan quickly generate populations with high diversity and good convergence. Tomeasure the performance, RM-MEDA, MOPSO and NSGA-II are selected to performcomparison experiments over DTLZ and LSMOP test suites with 3-, 5-, 8-, 10- and15-objective."^^schema:Text ;
    schema:author "Yunfan Li"^^schema:Person,
        "Zhenyu Liang"^^schema:Person,
        "Zhongwei Wan"^^schema:Person ;
    schema:dateModified "2020-03-16T03:14:59Z"^^schema:DateTime ;
    schema:datePublished "2020-03-16T03:14:59Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text ;
    schema:headline "Many-Objective Estimation of Distribution Optimization Algorithm Based  on WGAN-GP"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08295v1"^^schema:URL .

<166> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in deep domain adaptation reveal that adversarial learningcan be embedded into deep networks to learn transferable features that reducedistribution discrepancy between the source and target domains. Existing domainadversarial adaptation methods based on single domain discriminator only alignthe source and target data distributions without exploiting the complexmultimode structures. In this paper, we present a multi-adversarial domainadaptation (MADA) approach, which captures multimode structures to enablefine-grained alignment of different data distributions based on multiple domaindiscriminators. The adaptation can be achieved by stochastic gradient descentwith the gradients computed by back-propagation in linear-time. Empiricalevidence demonstrates that the proposed model outperforms state of the artmethods on standard domain adaptation datasets."^^schema:Text ;
    schema:author "Jianmin Wang"^^schema:Person,
        "Mingsheng Long"^^schema:Person,
        "Zhangjie Cao"^^schema:Person,
        "Zhongyi Pei"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:dateModified "2018-09-04T20:54:48Z"^^schema:DateTime ;
    schema:datePublished "2018-09-04T20:54:48Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Multi-Adversarial Domain Adaptation"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1809.02176v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7147882118203212526&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1660> a schema:ScholarlyArticle ;
    schema:abstract "Humans can naturally learn to execute a new task by seeing it performed byother individuals once, and then reproduce it in a variety of configurations.Endowing robots with this ability of imitating humans from third person is avery immediate and natural way of teaching new tasks. Only recently, throughmeta-learning, there have been successful attempts to one-shot imitationlearning from humans; however, these approaches require a lot of humanresources to collect the data in the real world to train the robot. But isthere a way to remove the need for real world human demonstrations duringtraining? We show that with Task-Embedded Control Networks, we can infercontrol polices by embedding human demonstrations that can condition a controlpolicy and achieve one-shot imitation learning. Importantly, we do not use areal human arm to supply demonstrations during training, but instead leveragedomain randomisation in an application that has not been seen before:sim-to-real transfer on humans. Upon evaluating our approach on pushing andplacing tasks in both simulation and in the real world, we show that incomparison to a system that was trained on real-world data we are able toachieve similar results by utilising only simulation data."^^schema:Text ;
    schema:author "Alessandro Bonardi"^^schema:Person,
        "Andrew J. Davison"^^schema:Person,
        "Stephen James"^^schema:Person ;
    schema:dateModified "2019-11-04T10:07:27Z"^^schema:DateTime ;
    schema:datePublished "2019-11-04T10:07:27Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Learning One-Shot Imitation from Humans without Humans"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.01103v1"^^schema:URL .

<1661> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning algorithms can be used to learn a policy from expertdemonstrations without access to a reward signal. However, most existingapproaches are not applicable in multi-agent settings due to the existence ofmultiple (Nash) equilibria and non-stationary environments. We propose a newframework for multi-agent imitation learning for general Markov games, where webuild upon a generalized notion of inverse reinforcement learning. We furtherintroduce a practical multi-agent actor-critic algorithm with good empiricalperformance. Our method can be used to imitate complex behaviors inhigh-dimensional environments with multiple cooperative or competing agents."^^schema:Text ;
    schema:author "Dorsa Sadigh"^^schema:Person,
        "Hongyu Ren"^^schema:Person,
        "Jiaming Song"^^schema:Person,
        "Stefano Ermon"^^schema:Person ;
    schema:dateModified "2018-07-26T03:21:49Z"^^schema:DateTime ;
    schema:datePublished "2018-07-26T03:21:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-Agent Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.09936v1"^^schema:URL .

<1662> a schema:ScholarlyArticle ;
    schema:abstract "Graph attention networks (GATs) have been recognized as powerful tools forlearning in graph structured data. However, how to enable the attentionmechanisms in GATs to smoothly consider both structural and feature informationis still very challenging. In this paper, we propose Graph Joint AttentionNetworks (JATs) to address the aforementioned challenge. Different fromprevious attention-based graph neural networks (GNNs), JATs adopt novel jointattention mechanisms which can automatically determine the relativesignificance between node features and structural coefficients learned fromgraph topology, when computing the attention scores. Therefore, representationsconcerning more structural properties can be inferred by JATs. Besides, wetheoretically analyze the expressive power of JATs and further propose animproved strategy for the joint attention mechanisms that enables JATs to reachthe upper bound of expressive power which every message-passing GNN canultimately achieve, i.e., 1-WL test. JATs can thereby be seen as most powerfulmessage-passing GNNs. The proposed neural architecture has been extensivelytested on widely used benchmarking datasets, and has been compared withstate-of-the-art GNNs for various downstream predictive tasks. Experimentalresults show that JATs achieve state-of-the-art performance on all the testingdatasets."^^schema:Text ;
    schema:author "Lu Bai"^^schema:Person,
        "Tiantian He"^^schema:Person,
        "Yew-Soon Ong"^^schema:Person ;
    schema:dateModified "2021-02-05T12:51:47Z"^^schema:DateTime ;
    schema:datePublished "2021-02-05T12:51:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Graph Joint Attention Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03147v1"^^schema:URL .

<1663> a schema:ScholarlyArticle ;
    schema:abstract "Neural architecture search (NAS) automatically finds the best task-specificneural network topology, outperforming many manual architecture designs.However, it can be prohibitively expensive as the search requires trainingthousands of different networks, while each can last for hours. In this work,we propose the Graph HyperNetwork (GHN) to amortize the search cost: given anarchitecture, it directly generates the weights by running inference on a graphneural network. GHNs model the topology of an architecture and therefore canpredict network performance more accurately than regular hypernetworks andpremature early stopping. To perform NAS, we randomly sample architectures anduse the validation accuracy of networks with GHN generated weights as thesurrogate search signal. GHNs are fast -- they can search nearly 10 timesfaster than other random search methods on CIFAR-10 and ImageNet. GHNs can befurther extended to the anytime prediction setting, where they have foundnetworks with better speed-accuracy tradeoff than the state-of-the-art manualdesigns."^^schema:Text ;
    schema:author "Chris Zhang"^^schema:Person,
        "Mengye Ren"^^schema:Person,
        "Raquel Urtasun"^^schema:Person ;
    schema:dateModified "2020-12-18T18:01:04Z"^^schema:DateTime ;
    schema:datePublished "2018-10-12T22:21:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Graph HyperNetworks for Neural Architecture Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.05749v3"^^schema:URL .

<1664> a schema:ScholarlyArticle ;
    schema:abstract "One of the most complex syntactic representations used in computationallinguistics and NLP are discontinuous constituent trees, crucial forrepresenting all grammatical phenomena of languages such as German. Recentadvances in dependency parsing have shown that Pointer Networks excel inefficiently parsing syntactic relations between words in a sentence. This kindof sequence-to-sequence models achieve outstanding accuracies in buildingnon-projective dependency trees, but its potential has not been proved yet on amore difficult task. We propose a novel neural network architecture that, bymeans of Pointer Networks, is able to generate the most accurate discontinuousconstituent representations to date, even without the need of Part-of-Speechtagging information. To do so, we internally model discontinuous constituentstructures as augmented non-projective dependency structures. The proposedapproach achieves state-of-the-art results on the two widely-used NEGRA andTIGER benchmarks, outperforming previous work by a wide margin."^^schema:Text ;
    schema:author "Carlos Gómez-Rodríguez"^^schema:Person,
        "Daniel Fernández-González"^^schema:Person ;
    schema:dateModified "2020-02-05T15:12:03Z"^^schema:DateTime ;
    schema:datePublished "2020-02-05T15:12:03Z"^^schema:DateTime ;
    schema:genre "68T50"^^schema:Text,
        "I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Discontinuous Constituent Parsing with Pointer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.01824v1"^^schema:URL .

<1665> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel approach to answering sequential questions based onstructured objects such as knowledge bases or tables without using a logicalform as an intermediate representation. We encode tables as graphs using agraph neural network model based on the Transformer architecture. The answersare then selected from the encoded graph using a pointer network. This model isappropriate for processing conversations around structured data, where theattention mechanism that selects the answers to a question can also be used toresolve conversational references. We demonstrate the validity of this approachwith competitive results on the Sequential Question Answering (SQA) task (Iyyeret al., 2017)."^^schema:Text ;
    schema:author "Francesco Piccinno"^^schema:Person,
        "Massimo Nicosia"^^schema:Person,
        "Peter Shaw"^^schema:Person,
        "Thomas Müller"^^schema:Person,
        "Yasemin Altun"^^schema:Person ;
    schema:dateModified "2019-08-30T15:26:44Z"^^schema:DateTime ;
    schema:datePublished "2019-08-30T15:26:44Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Answering Conversational Questions on Structured Data without Logical  Forms"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.11787v1"^^schema:URL .

<1666> a schema:ScholarlyArticle ;
    schema:abstract "Contrary to optical images, Synthetic Aperture Radar (SAR) images are indifferent electromagnetic spectrum where the human visual system is notaccustomed to. Thus, with more and more SAR applications, the demand forenhanced high-quality SAR images has increased considerably. However,high-quality SAR images entail high costs due to the limitations of current SARdevices and their image processing resources. To improve the quality of SARimages and to reduce the costs of their generation, we propose a DialecticalGenerative Adversarial Network (Dialectical GAN) to generate high-quality SARimages. This method is based on the analysis of hierarchical SAR informationand the \"dialectical\" structure of GAN frameworks. As a demonstration, atypical example will be shown where a low-resolution SAR image (e.g., aSentinel-1 image) with large ground coverage is translated into ahigh-resolution SAR image (e.g., a TerraSAR-X image). Three traditionalalgorithms are compared, and a new algorithm is proposed based on a networkframework by combining conditional WGAN-GP (Wasserstein Generative AdversarialNetwork - Gradient Penalty) loss functions and Spatial Gram matrices under therule of dialectics. Experimental results show that the SAR image translationworks very well when we compare the results of our proposed method with theselected traditional methods."^^schema:Text ;
    schema:author "Corneliu Octavian Dumitru"^^schema:Person,
        "Dongyang Ao"^^schema:Person,
        "Gottfried Schwarz"^^schema:Person,
        "Mihai Datcu"^^schema:Person ;
    schema:dateModified "2018-07-20T10:26:32Z"^^schema:DateTime ;
    schema:datePublished "2018-07-20T10:26:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Dialectical GAN for SAR Image Translation: From Sentinel-1 to TerraSAR-X"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.07778v1"^^schema:URL .

<1667> a schema:ScholarlyArticle ;
    schema:abstract "Semi-supervised video object segmentation (semi-VOS) is widely used in manyapplications. This task is tracking class-agnostic objects by a givensegmentation mask. For doing this, various approaches have been developed basedon optical flow, online-learning, and memory networks. These methods show highaccuracy but are hard to be utilized in real-world applications due to slowinference time and tremendous complexity. To resolve this problem, templatematching methods are devised for fast processing speed, sacrificing lots ofperformance. We introduce a novel semi-VOS model based on a temple matchingmethod and a novel temporal consistency loss to reduce the performance gap fromheavy models while expediting inference time a lot. Our temple matching methodconsists of short-term and long-term matching. The short-term matching enhancestarget object localization, while long-term matching improves fine details andhandles object shape-changing through the newly proposed adaptive templateattention module. However, the long-term matching causes error-propagation dueto the inflow of the past estimated results when updating the template. Tomitigate this problem, we also propose a temporal consistency loss for bettertemporal coherence between neighboring frames by adopting the concept of atransition matrix. Our model obtains 79.5% J&amp;F score at the speed of 73.8 FPSon the DAVIS16 benchmark."^^schema:Text ;
    schema:author "Ganesh Venkatesh"^^schema:Person,
        "Hyojin Park"^^schema:Person,
        "Nojun Kwak"^^schema:Person ;
    schema:dateModified "2020-11-09T14:09:54Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T14:09:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "TTVOS: Lightweight Video Object Segmentation with Adaptive Template  Attention Module and Temporal Consistency Loss"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.04445v1"^^schema:URL .

<1668> a schema:ScholarlyArticle ;
    schema:abstract "Multistep traffic forecasting on road networks is a crucial task insuccessful intelligent transportation system applications. To capture thecomplex non-stationary temporal dynamics and spatial dependency in multisteptraffic-condition prediction, we propose a novel deep learning framework namedattention graph convolutional sequence-to-sequence model (AGC-Seq2Seq). In theproposed deep learning framework, spatial and temporal dependencies are modeledthrough the Seq2Seq model and graph convolution network separately, and theattention mechanism along with a newly designed training method based on theSeq2Seq architecture is proposed to overcome the difficulty in multistepprediction and further capture the temporal heterogeneity of traffic pattern.We conduct numerical tests to compare AGC-Seq2Seq with other benchmark modelsusing a real-world dataset. The results indicate that our model yields the bestprediction performance in terms of various prediction error measures.Furthermore, the variation of spatiotemporal correlation of traffic conditionsunder different perdition steps and road segments is revealed throughsensitivity analyses."^^schema:Text ;
    schema:author "Fang He"^^schema:Person,
        "Meng Li"^^schema:Person,
        "Xi Lin"^^schema:Person,
        "Yinhai Wang"^^schema:Person,
        "Zhengchao Zhang"^^schema:Person ;
    schema:dateModified "2018-10-24T08:22:01Z"^^schema:DateTime ;
    schema:datePublished "2018-10-24T08:22:01Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multistep Speed Prediction on Traffic Networks: A Graph Convolutional  Sequence-to-Sequence Learning Approach with Attention Mechanism"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.10237v1"^^schema:URL .

<1669> a schema:ScholarlyArticle ;
    schema:abstract "Making decisions in the presence of a strategic opponent requires one to takeinto account the opponent's ability to actively mask its intended objective. Todescribe such strategic situations, we introduce the non-cooperative inversereinforcement learning (N-CIRL) formalism. The N-CIRL formalism consists of twoagents with completely misaligned objectives, where only one of the agentsknows the true objective function. Formally, we model the N-CIRL formalism as azero-sum Markov game with one-sided incomplete information. Through interactingwith the more informed player, the less informed player attempts to both infer,and act according to, the true objective function. As a result of the one-sidedincomplete information, the multi-stage game can be decomposed into a sequenceof single-stage games expressed by a recursive formula. Solving this recursiveformula yields the value of the N-CIRL game and the more informed player'sequilibrium strategy. Another recursive formula, constructed by forming anauxiliary game, termed the dual game, yields the less informed player'sstrategy. Building upon these two recursive formulas, we develop acomputationally tractable algorithm to approximately solve for the equilibriumstrategies. Finally, we demonstrate the benefits of our N-CIRL formalism overthe existing multi-agent IRL formalism via extensive numerical simulation in anovel cyber security setting."^^schema:Text ;
    schema:author "Erik Miehling"^^schema:Person,
        "Kaiqing Zhang"^^schema:Person,
        "Tamer Başar"^^schema:Person,
        "Xiangyuan Zhang"^^schema:Person ;
    schema:dateModified "2020-01-06T08:56:59Z"^^schema:DateTime ;
    schema:datePublished "2019-11-03T16:59:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.GT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Non-Cooperative Inverse Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04220v2"^^schema:URL .

<167> a schema:ScholarlyArticle ;
    schema:abstract "Deep Convolutional Neural Networks (DCNNs) have recently shown state of theart performance in high level vision tasks, such as image classification andobject detection. This work brings together methods from DCNNs andprobabilistic graphical models for addressing the task of pixel-levelclassification (also called \"semantic image segmentation\"). We show thatresponses at the final layer of DCNNs are not sufficiently localized foraccurate object segmentation. This is due to the very invariance propertiesthat make DCNNs good for high level tasks. We overcome this poor localizationproperty of deep networks by combining the responses at the final DCNN layerwith a fully connected Conditional Random Field (CRF). Qualitatively, our\"DeepLab\" system is able to localize segment boundaries at a level of accuracywhich is beyond previous methods. Quantitatively, our method sets the newstate-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching71.6% IOU accuracy in the test set. We show how these results can be obtainedefficiently: Careful network re-purposing and a novel application of the 'hole'algorithm from the wavelet community allow dense computation of neural netresponses at 8 frames per second on a modern GPU."^^schema:Text ;
    schema:author "Alan L. Yuille"^^schema:Person,
        "George Papandreou"^^schema:Person,
        "Iasonas Kokkinos"^^schema:Person,
        "Kevin Murphy"^^schema:Person,
        "Liang-Chieh Chen"^^schema:Person ;
    schema:commentCount "2496"^^schema:Integer ;
    schema:dateModified "2016-06-07T04:00:08Z"^^schema:DateTime ;
    schema:datePublished "2014-12-22T17:18:33Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Semantic Image Segmentation with Deep Convolutional Nets and Fully  Connected CRFs"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.7062v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12556287530133233148&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1670> a schema:ScholarlyArticle ;
    schema:abstract "Emotional voice conversion (EVC) aims to convert the emotion of speech fromone state to another while preserving the linguistic content and speakeridentity. In this paper, we study the disentanglement and recomposition ofemotional elements in speech through variational autoencoding Wassersteingenerative adversarial network (VAW-GAN). We propose a speaker-dependent EVCframework based on VAW-GAN, that includes two VAW-GAN pipelines, one forspectrum conversion, and another for prosody conversion. We train a spectralencoder that disentangles emotion and prosody (F0) information from spectralfeatures; we also train a prosodic encoder that disentangles emotion modulationof prosody (affective prosody) from linguistic prosody. At run-time, thedecoder of spectral VAW-GAN is conditioned on the output of prosodic VAW-GAN.The vocoder takes the converted spectral and prosodic features to generate thetarget emotional speech. Experiments validate the effectiveness of our proposedmethod in both objective and subjective evaluations."^^schema:Text ;
    schema:author "Berrak Sisman"^^schema:Person,
        "Haizhou Li"^^schema:Person,
        "Kun Zhou"^^schema:Person ;
    schema:dateModified "2020-11-03T08:49:33Z"^^schema:DateTime ;
    schema:datePublished "2020-11-03T08:49:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "VAW-GAN for Disentanglement and Recomposition of Emotional Elements in  Speech"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02314v1"^^schema:URL .

<1671> a schema:ScholarlyArticle ;
    schema:abstract "Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization(PPO) are among the most successful policy gradient approaches in deepreinforcement learning (RL). While these methods achieve state-of-the-artperformance across a wide range of challenging tasks, there is room forimprovement in the stabilization of the policy learning and how the off-policydata are used. In this paper we revisit the theoretical foundations of thesealgorithms and propose a new algorithm which stabilizes the policy improvementthrough a proximity term that constrains the discounted state-action visitationdistribution induced by consecutive policies to be close to one another. Thisproximity term, expressed in terms of the divergence between the visitationdistributions, is learned in an off-policy and adversarial manner. Weempirically show that our proposed method can have a beneficial effect onstability and improve final performance in benchmark high-dimensional controltasks."^^schema:Text ;
    schema:author "Ahmed Touati"^^schema:Person,
        "Amy Zhang"^^schema:Person,
        "Joelle Pineau"^^schema:Person,
        "Pascal Vincent"^^schema:Person ;
    schema:dateModified "2020-06-19T17:04:22Z"^^schema:DateTime ;
    schema:datePublished "2020-03-09T13:05:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stable Policy Optimization via Off-Policy Divergence Regularization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.04108v2"^^schema:URL .

<1672> a schema:ScholarlyArticle ;
    schema:abstract "Deep Residual Networks present a premium in performance in comparison toconventional networks of the same depth and are trainable at extreme depths. Ithas recently been shown that Residual Networks behave like ensembles ofrelatively shallow networks. We show that these ensembles are dynamic: whileinitially the virtual ensemble is mostly at depths lower than half thenetwork's depth, as training progresses, it becomes deeper and deeper. The mainmechanism that controls the dynamic ensemble behavior is the scalingintroduced, e.g., by the Batch Normalization technique. We explain thisbehavior and demonstrate the driving force behind it. As a main tool in ouranalysis, we employ generalized spin glass models, which we also use in orderto study the number of critical points in the optimization of ResidualNetworks."^^schema:Text ;
    schema:author "Etai Littwin"^^schema:Person,
        "Lior Wolf"^^schema:Person ;
    schema:dateModified "2016-11-08T14:17:13Z"^^schema:DateTime ;
    schema:datePublished "2016-11-08T14:17:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "The Loss Surface of Residual Networks: Ensembles and the Role of Batch  Normalization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.02525v1"^^schema:URL .

<1673> a schema:ScholarlyArticle ;
    schema:abstract "This work proposes an extension of neural ordinary differential equations(NODEs) by introducing an additional set of ODE input parameters to NODEs. Thisextension allows NODEs to learn multiple dynamics specified by the inputparameter instances. Our extension is inspired by the concept of parameterizedordinary differential equations, which are widely investigated in computationalscience and engineering contexts, where characteristics of the governingequations vary over the input parameters. We apply the proposed parameterizedNODEs (PNODEs) for learning latent dynamics of complex dynamical processes thatarise in computational physics, which is an essential component for enablingrapid numerical simulations for time-critical physics applications. For this,we propose an encoder-decoder-type framework, which models latent dynamics asPNODEs. We demonstrate the effectiveness of PNODEs with important benchmarkproblems from computational physics."^^schema:Text ;
    schema:author "Eric J. Parish"^^schema:Person,
        "Kookjin Lee"^^schema:Person ;
    schema:dateModified "2020-10-28T00:41:28Z"^^schema:DateTime ;
    schema:datePublished "2020-10-28T00:41:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "physics.comp-ph"^^schema:Text ;
    schema:headline "Parameterized Neural Ordinary Differential Equations: Applications to  Computational Physics Problems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.14685v1"^^schema:URL .

<1674> a schema:ScholarlyArticle ;
    schema:abstract "Novel advanced policy gradient (APG) methods, such as Trust Region policyoptimization and Proximal policy optimization (PPO), have become the dominantreinforcement learning algorithms because of their ease of implementation andgood practical performance. A conventional setup for notoriously difficultqueueing network control problems is a Markov decision problem (MDP) that hasthree features: infinite state space, unbounded costs, and long-run averagecost objective. We extend the theoretical framework of these APG methods forsuch MDP problems. The resulting PPO algorithm is tested on a parallel-serversystem and large-size multiclass queueing networks. The algorithm consistentlygenerates control policies that outperform state-of-art heuristics inliterature in a variety of load conditions from light to heavy traffic. Thesepolicies are demonstrated to be near-optimal when the optimal policy can becomputed.  A key to the successes of our PPO algorithm is the use of three variancereduction techniques in estimating the relative value function via sampling.First, we use a discounted relative value function as an approximation of therelative value function. Second, we propose regenerative simulation to estimatethe discounted relative value function. Finally, we incorporate theapproximating martingale-process method into the regenerative estimator."^^schema:Text ;
    schema:author "J. G. Dai"^^schema:Person,
        "Mark Gluzman"^^schema:Person ;
    schema:dateModified "2020-09-24T21:38:21Z"^^schema:DateTime ;
    schema:datePublished "2020-07-31T01:02:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "math.PR"^^schema:Text ;
    schema:headline "Queueing Network Controls via Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01644v5"^^schema:URL .

<1675> a schema:ScholarlyArticle ;
    schema:abstract "Generative moment matching networks (GMMNs) are suggested for modeling thecross-sectional dependence between stochastic processes. The stochasticprocesses considered are geometric Brownian motions and ARMA-GARCH models.Geometric Brownian motions lead to an application of pricing American basketcall options under dependence and ARMA-GARCH models lead to an application ofsimulating predictive distributions. In both types of applications the benefitof using GMMNs in comparison to parametric dependence models is highlighted andthe fact that GMMNs can produce dependent quasi-random samples with noadditional effort is exploited to obtain variance reduction."^^schema:Text ;
    schema:author "Avinash Prasad"^^schema:Person,
        "Marius Hofert"^^schema:Person,
        "Mu Zhu"^^schema:Person ;
    schema:dateModified "2020-12-15T01:42:23Z"^^schema:DateTime ;
    schema:datePublished "2020-12-15T01:42:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.AP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Applications of multivariate quasi-random sampling with neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.08036v1"^^schema:URL .

<1676> a schema:ScholarlyArticle ;
    schema:abstract "Marginal maximum likelihood (MML) estimation is the preferred approach tofitting item response theory models in psychometrics due to the MML estimator'sconsistency, normality, and efficiency as the sample size tends to infinity.However, state-of-the-art MML estimation procedures such as theMetropolis-Hastings Robbins-Monro (MH-RM) algorithm as well as approximate MMLestimation procedures such as variational inference (VI) are computationallytime-consuming when the sample size and the number of latent factors are verylarge. In this work, we investigate a deep learning-based VI algorithm forexploratory item factor analysis (IFA) that is computationally fast even inlarge data sets with many latent factors. The proposed approach applies a deepartificial neural network model called an importance-weighted autoencoder(IWAE) for exploratory IFA. The IWAE approximates the MML estimator using animportance sampling technique wherein increasing the number ofimportance-weighted (IW) samples drawn during fitting improves theapproximation, typically at the cost of decreased computational efficiency. Weprovide a real data application that recovers results aligning withpsychological theory across random starts. Via simulation studies, we show thatthe IWAE yields more accurate estimates as either the sample size or the numberof IW samples increases (although factor correlation and intercepts estimatesexhibit some bias) and obtains similar results to MH-RM in less time. Oursimulations also suggest that the proposed approach performs similarly to andis potentially faster than constrained joint maximum likelihood estimation, afast procedure that is consistent when the sample size and the number of itemssimultaneously tend to infinity."^^schema:Text ;
    schema:author "Christopher J. Urban"^^schema:Person,
        "Daniel J. Bauer"^^schema:Person ;
    schema:dateModified "2021-02-04T17:29:22Z"^^schema:DateTime ;
    schema:datePublished "2020-01-22T03:02:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Deep Learning Algorithm for High-Dimensional Exploratory Item Factor  Analysis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.07859v4"^^schema:URL .

<1677> a schema:ScholarlyArticle ;
    schema:abstract "Sparse reward is one of the most challenging problems in reinforcementlearning (RL). Hindsight Experience Replay (HER) attempts to address this issueby converting a failed experience to a successful one by relabeling the goals.Despite its effectiveness, HER has limited applicability because it lacks acompact and universal goal representation. We present Augmenting experienCe viaTeacheR's adviCE (ACTRCE), an efficient reinforcement learning technique thatextends the HER framework using natural language as the goal representation. Wefirst analyze the differences among goal representation, and show that ACTRCEcan efficiently solve difficult reinforcement learning problems in challenging3D navigation tasks, whereas HER with non-language goal representation failedto learn. We also show that with language goal representations, the agent cangeneralize to unseen instructions, and even generalize to instructions withunseen lexicons. We further demonstrate it is crucial to use hindsight adviceto solve challenging tasks, and even small amount of advice is sufficient forthe agent to achieve good performance."^^schema:Text ;
    schema:author "Harris Chan"^^schema:Person,
        "Jamie Kiros"^^schema:Person,
        "Jimmy Ba"^^schema:Person,
        "Sanja Fidler"^^schema:Person,
        "Yuhuai Wu"^^schema:Person ;
    schema:dateModified "2019-02-12T18:43:56Z"^^schema:DateTime ;
    schema:datePublished "2019-02-12T18:43:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "ACTRCE: Augmenting Experience via Teacher's Advice For Multi-Goal  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.04546v1"^^schema:URL .

<1678> a schema:ScholarlyArticle ;
    schema:abstract "In an end-to-end dialog system, the aim of dialog state tracking is toaccurately estimate a compact representation of the current dialog status froma sequence of noisy observations produced by the speech recognition and thenatural language understanding modules. This paper introduces a novel method ofdialog state tracking based on the general paradigm of machine reading andproposes to solve it using an End-to-End Memory Network, MemN2N, amemory-enhanced neural network architecture. We evaluate the proposed approachon the second Dialog State Tracking Challenge (DSTC-2) dataset. The corpus hasbeen converted for the occasion in order to frame the hidden state variableinference as a question-answering task based on a sequence of utterancesextracted from a dialog. We show that the proposed tracker gives encouragingresults. Then, we propose to extend the DSTC-2 dataset with specific reasoningcapabilities requirement like counting, list maintenance, yes-no questionanswering and indefinite knowledge management. Finally, we present encouragingresults using our proposed MemN2N based tracking model."^^schema:Text ;
    schema:author "Fei Liu"^^schema:Person,
        "Julien Perez"^^schema:Person ;
    schema:dateModified "2017-03-02T20:17:23Z"^^schema:DateTime ;
    schema:datePublished "2016-06-13T18:09:40Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dialog state tracking, a machine reading approach using Memory Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1606.04052v5"^^schema:URL .

<1679> a schema:ScholarlyArticle ;
    schema:abstract "Tensors are higher-order extensions of matrices. While matrix methods formthe cornerstone of machine learning and data analysis, tensor methods have beengaining increasing traction. However, software support for tensor operations isnot on the same footing. In order to bridge this gap, we have developed\\emph{TensorLy}, a high-level API for tensor methods and deep tensorized neuralnetworks in Python. TensorLy aims to follow the same standards adopted by themain projects of the Python scientific community, and seamlessly integrateswith them. Its BSD license makes it suitable for both academic and commercialapplications. TensorLy's backend system allows users to perform computationswith NumPy, MXNet, PyTorch, TensorFlow and CuPy. They can be scaled on multipleCPU or GPU machines. In addition, using the deep-learning frameworks as backendallows users to easily design and train deep tensorized neural networks.TensorLy is available at https://github.com/tensorly/tensorly"^^schema:Text ;
    schema:author "Anima Anandkumar"^^schema:Person,
        "Jean Kossaifi"^^schema:Person,
        "Maja Pantic"^^schema:Person,
        "Yannis Panagakis"^^schema:Person ;
    schema:dateModified "2018-05-09T13:54:12Z"^^schema:DateTime ;
    schema:datePublished "2016-10-29T18:32:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "TensorLy: Tensor Learning in Python"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1610.09555v2"^^schema:URL .

<168> a schema:ScholarlyArticle ;
    schema:abstract "We propose zoneout, a novel method for regularizing RNNs. At each timestep,zoneout stochastically forces some hidden units to maintain their previousvalues. Like dropout, zoneout uses random noise to train a pseudo-ensemble,improving generalization. But by preserving instead of dropping hidden units,gradient information and state information are more readily propagated throughtime, as in feedforward stochastic depth networks. We perform an empiricalinvestigation of various RNN regularizers, and find that zoneout givessignificant performance improvements across tasks. We achieve competitiveresults with relatively simple models in character- and word-level languagemodelling on the Penn Treebank and Text8 datasets, and combining with recurrentbatch normalization yields state-of-the-art results on permuted sequentialMNIST."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Anirudh Goyal"^^schema:Person,
        "Chris Pal"^^schema:Person,
        "David Krueger"^^schema:Person,
        "János Kramár"^^schema:Person,
        "Mohammad Pezeshki"^^schema:Person,
        "Nan Rosemary Ke"^^schema:Person,
        "Nicolas Ballas"^^schema:Person,
        "Tegan Maharaj"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "203"^^schema:Integer ;
    schema:dateModified "2017-09-22T20:43:09Z"^^schema:DateTime ;
    schema:datePublished "2016-06-03T23:31:47Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.01305v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13800900548977291683&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1680> a schema:ScholarlyArticle ;
    schema:abstract "Crowd simulation, the study of the movement of multiple agents in complexenvironments, presents a unique application domain for machine learning. Onechallenge in crowd simulation is to imitate the movement of expert agents inhighly dense crowds. An imitation model could substitute an expert agent if themodel behaves as good as the expert. This will bring many excitingapplications. However, we believe no prior studies have considered the criticalquestion of how training data and training methods affect imitators when thesemodels are applied to novel scenarios. In this work, a general imitation modelis represented by applying either the Behavior Cloning (BC) training method ora more sophisticated Generative Adversarial Imitation Learning (GAIL) method,on three typical types of data domains: standard benchmarks for evaluatingcrowd models, random sampling of state-action pairs, and egocentric scenariosthat capture local interactions. Simulated results suggest that (i) simplertraining methods are overall better than more complex training methods, (ii)training samples with diverse agent-agent and agent-obstacle interactions arebeneficial for reducing collisions when the trained models are applied to newscenarios. We additionally evaluated our models in their ability to imitatereal world crowd trajectories observed from surveillance videos. Our findingsindicate that models trained on representative scenarios generalize to new,unseen situations observed in real human crowds."^^schema:Text ;
    schema:author "Gang Qiao"^^schema:Person,
        "Honglu Zhou"^^schema:Person,
        "Mubbasir Kapadia"^^schema:Person,
        "Sejong Yoon"^^schema:Person,
        "Vladimir Pavlovic"^^schema:Person ;
    schema:dateModified "2019-10-02T01:25:32Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T01:25:32Z"^^schema:DateTime ;
    schema:genre "cs.MA"^^schema:Text ;
    schema:headline "Scenario Generalization of Data-driven Imitation Models in Crowd  Simulation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00738v1"^^schema:URL .

<1681> a schema:ScholarlyArticle ;
    schema:abstract "We address the problem of 3D rotation equivariance in convolutional neuralnetworks. 3D rotations have been a challenging nuisance in 3D classificationtasks requiring higher capacity and extended data augmentation in order totackle it. We model 3D data with multi-valued spherical functions and wepropose a novel spherical convolutional network that implements exactconvolutions on the sphere by realizing them in the spherical harmonic domain.Resulting filters have local symmetry and are localized by enforcing smoothspectra. We apply a novel pooling on the spectral domain and our operations areindependent of the underlying spherical resolution throughout the network. Weshow that networks with much lower capacity and without requiring dataaugmentation can exhibit performance comparable to the state of the art instandard retrieval and classification benchmarks."^^schema:Text ;
    schema:author "Ameesh Makadia"^^schema:Person,
        "Carlos Esteves"^^schema:Person,
        "Christine Allen-Blanchette"^^schema:Person,
        "Kostas Daniilidis"^^schema:Person ;
    schema:dateModified "2018-09-28T03:19:48Z"^^schema:DateTime ;
    schema:datePublished "2017-11-17T20:49:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning SO(3) Equivariant Representations with Spherical CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.06721v3"^^schema:URL .

<1682> a schema:ScholarlyArticle ;
    schema:abstract "Networks are fundamental to the study of complex systems, ranging from socialcontacts, message transactions, to biological regulations and economicalnetworks. In many realistic applications, these networks may vary over time.Modeling and analyzing such temporal properties is of additional interest as itcan provide a richer characterization of relations between nodes in networks.In this paper, we explore the role of \\emph{graphlets} in networkclassification for both static and temporal networks. Graphlets are smallnon-isomorphic induced subgraphs representing connected patterns in a networkand their frequency can be used to assess network structures. We show thatgraphlet features, which are not captured by state-of-the-art methods, play asignificant role in enhancing the performance of network classification. Tothat end, we propose two novel graphlet-based techniques, \\emph{gl2vec} fornetwork embedding, and \\emph{gl-DCNN} for diffusion-convolutional neuralnetworks. We demonstrate the efficacy and usability of \\emph{gl2vec} and\\emph{gl-DCNN} through extensive experiments using several real-world staticand temporal networks. We find that features learned from graphlets can bringnotable performance increases to state-of-the-art methods in network analysis."^^schema:Text ;
    schema:author "Dave Braines"^^schema:Person,
        "Don Towsley"^^schema:Person,
        "Jian Li"^^schema:Person,
        "Kun Tu"^^schema:Person,
        "Liam Turner"^^schema:Person ;
    schema:dateModified "2020-04-05T17:42:14Z"^^schema:DateTime ;
    schema:datePublished "2018-12-13T15:10:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text ;
    schema:headline "Learning Features of Network Structures Using Graphlets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.05473v3"^^schema:URL .

<1683> a schema:ScholarlyArticle ;
    schema:abstract "Training Neural Ordinary Differential Equations (ODEs) is oftencomputationally expensive. Indeed, computing the forward pass of such modelsinvolves solving an ODE which can become arbitrarily complex during training.Recent works have shown that regularizing the dynamics of the ODE can partiallyalleviate this. In this paper we propose a new regularization technique:randomly sampling the end time of the ODE during training. The proposedregularization is simple to implement, has negligible overhead and is effectiveacross a wide variety of tasks. Further, the technique is orthogonal to severalother methods proposed to regularize the dynamics of ODEs and as such can beused in conjunction with them. We show through experiments on normalizingflows, time series models and image recognition that the proposedregularization can significantly decrease training time and even improveperformance over baseline models."^^schema:Text ;
    schema:author "Arnab Ghosh"^^schema:Person,
        "Emilien Dupont"^^schema:Person,
        "Harkirat Singh Behl"^^schema:Person,
        "Philip H. S. Torr"^^schema:Person,
        "Vinay Namboodiri"^^schema:Person ;
    schema:dateModified "2020-11-02T12:24:43Z"^^schema:DateTime ;
    schema:datePublished "2020-06-18T17:44:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "STEER: Simple Temporal Regularization For Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.10711v3"^^schema:URL .

<1684> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a low-power hardware for efficient deployment ofbinarized neural networks (BNNs) that have been trained for physiologicaldatasets. BNNs constrain weights and feature-map to 1 bit, can pack in as many1-bit weights as the width of a memory entry provides, and can execute multiplemultiply-accumulate (MAC) operations with one fused bit-wise xnor andpopulation-count instruction over aligned packed entries. Our proposed hardwareis scalable with the number of processing engines (PEs) and the memory width,both of which adjustable for the most energy efficient configuration given anapplication. We implement two real case studies including Physical ActivityMonitoring and Stress Detection on our platform, and for each case study on thetarget platform, we seek the optimal PE and memory configurations. Ourimplementation results indicate that a configuration with a good choice ofmemory width and number of PEs can be optimized up to 4x and 2.5x in energyconsumption respectively on Artix-7 FPGA and on 65nm CMOS ASIC implementation.We also show that, generally, wider memories make more efficient BNN processinghardware. To further reduce the energy, we introduce Pool-Skipping techniquethat can skip at least 25% of the operations that are accompanied by a Max-Poollayer in BNNs, leading to a total of 22% operation reduction in the StressDetection case study. Compared to the related works using the same case studieson the same target platform and with the same classification accuracy, ourhardware is respectively 4.5x and 250x more energy efficient for the StressDetection on FPGA and Physical Activity Monitoring on ASIC, respectively."^^schema:Text ;
    schema:author "Hirenkumar Paneliya"^^schema:Person,
        "Mohit Khatwani"^^schema:Person,
        "Morteza Hosseini"^^schema:Person,
        "Tinoosh Mohsenin"^^schema:Person,
        "Uttej Kallakuri"^^schema:Person ;
    schema:dateModified "2019-03-25T12:01:40Z"^^schema:DateTime ;
    schema:datePublished "2019-03-25T12:01:40Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text ;
    schema:headline "Minimizing Classification Energy of Binarized Neural Network Inference  for Wearable Devices"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.11381v1"^^schema:URL .

<1685> a schema:ScholarlyArticle ;
    schema:abstract "Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations(ABSs) to assist terrestrial infrastructure for keeping wireless connectivityin various emergency scenarios. To maximize the coverage rate of N ground users(GUs) by jointly placing multiple ABSs with limited coverage range is known tobe a NP-hard problem with exponential complexity in N. The problem is furthercomplicated when the coverage range becomes irregular due to site-specificblockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D)space. To tackle this challenging problem, this paper applies the DeepReinforcement Learning (DRL) method by 1) representing the state by a coveragebitmap to capture the spatial correlation of GUs/ABSs, whose dimension andassociated neural network complexity is invariant with arbitrarily large N; and2) designing the action and reward for the DRL agent to effectively learn fromthe dynamic interactions with the complicated propagation environmentrepresented by a 3D Terrain Map. Specifically, a novel two-level designapproach is proposed, consisting of a preliminary design based on the dominantline-of-sight (LoS) channel model, and an advanced design to further refine theABS positions based on site-specific LoS/non-LoS channel states. The doubledeep Q-network (DQN) with Prioritized Experience Replay (Prioritized ReplayDDQN) algorithm is applied to train the policy of multi-ABS placement decision.Numerical results show that the proposed approach significantly improves thecoverage rate in complex environment, compared to the benchmark DQN and K-meansalgorithms."^^schema:Text ;
    schema:author "Jiangbin Lyu"^^schema:Person,
        "Jin Qiu"^^schema:Person,
        "Liqun Fu"^^schema:Person ;
    schema:dateModified "2020-02-05T07:53:53Z"^^schema:DateTime ;
    schema:datePublished "2019-11-19T06:35:15Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Placement Optimization of Aerial Base Stations with Deep Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.08111v2"^^schema:URL .

<1686> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay enables online reinforcement learning agents to store andreuse the previous experiences of interacting with the environment. In theoriginal method, the experiences are sampled and replayed uniformly at random.A prior work called prioritized experience replay was developed whereexperiences are prioritized, so as to replay experiences seeming to be moreimportant more frequently. In this paper, we develop a method calleddouble-prioritized state-recycled (DPSR) experience replay, prioritizing theexperiences in both training stage and storing stage, as well as replacing theexperiences in the memory with state recycling to make the best of experiencesthat seem to have low priorities temporarily. We used this method in DeepQ-Networks (DQN), and achieved a state-of-the-art result, outperforming theoriginal method and prioritized experience replay on many Atari games."^^schema:Text ;
    schema:author "Dong Eui Chang"^^schema:Person,
        "Fanchen Bu"^^schema:Person ;
    schema:dateModified "2020-09-21T12:15:24Z"^^schema:DateTime ;
    schema:datePublished "2020-07-08T08:36:41Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Double Prioritized State Recycled Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.03961v3"^^schema:URL .

<1687> a schema:ScholarlyArticle ;
    schema:abstract "Robotic grasping is a crucial area of research as it can result in theacceleration of the automation of several Industries utilizing robots rangingfrom manufacturing to healthcare. Reinforcement learning is the field of studywhere an agent learns a policy to execute an action by exploring and exploitingrewards from an environment. Reinforcement learning can thus be used by theagent to learn how to execute a certain task, in our case grasping an object.We have used the Pick and Place environment provided by OpenAI's Gym toengineer rewards. Hindsight Experience Replay (HER) has shown promising resultswith problems having a sparse reward. In the default configuration of theOpenAI baseline and environment the reward function is calculated using thedistance between the target location and the robot end-effector. By weightingthe cost based on the distance of the end-effector from the goal in the x,y andz-axes we were able to almost halve the learning time compared to the baselinesprovided by OpenAI, an intuitive strategy that further reduced learning time.In this project, we were also able to introduce certain user desiredtrajectories in the learnt policies (city-block / Manhattan trajectories). Thishelps us understand that by engineering the rewards we can tune the agent tolearn policies in a certain way even if it might not be the most optimal but isthe desired manner."^^schema:Text ;
    schema:author "Achyuthan Unni Krishnan"^^schema:Person,
        "Hanshen Yu"^^schema:Person,
        "Raghav Nagpal"^^schema:Person ;
    schema:dateModified "2020-01-11T20:13:28Z"^^schema:DateTime ;
    schema:datePublished "2020-01-11T20:13:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Reward Engineering for Object Pick and Place Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.03792v1"^^schema:URL .

<1688> a schema:ScholarlyArticle ;
    schema:abstract "Non-volatile memory, such as resistive RAM (RRAM), is an emergingenergy-efficient storage, especially for low-power machine learning models onthe edge. It is reported, however, that the bit error rate of RRAMs can be upto 3.3% in the ultra low-power setting, which might be crucial for many usecases. Binary neural networks (BNNs), a resource efficient variant of neuralnetworks (NNs), can tolerate a certain percentage of errors without a loss inaccuracy and demand lower resources in computation and storage. The bit errortolerance (BET) in BNNs can be achieved by flipping the weight signs duringtraining, as proposed by Hirtzlin et al., but their method has a significantdrawback, especially for fully connected neural networks (FCNN): The FCNNsoverfit to the error rate used in training, which leads to low accuracy underlower error rates. In addition, the underlying principles of BET are notinvestigated. In this work, we improve the training for BET of BNNs and aim toexplain this property. We propose straight-through gradient approximation toimprove the weight-sign-flip training, by which BNNs adapt less to the biterror rates. To explain the achieved robustness, we define a metric that aimsto measure BET without fault injection. We evaluate the metric and find that itcorrelates with accuracy over error rate for all FCNNs tested. Finally, weexplore the influence of a novel regularizer that optimizes with respect tothis metric, with the aim of providing a configurable trade-off in accuracy andBET."^^schema:Text ;
    schema:author "Christian Hakert"^^schema:Person,
        "Jian-Jia Chen"^^schema:Person,
        "Katharina Morik"^^schema:Person,
        "Kuan-Hsun Chen"^^schema:Person,
        "Lukas Pfahler"^^schema:Person,
        "Mario Günzel"^^schema:Person,
        "Mikail Yayla"^^schema:Person,
        "Rodion Novkin"^^schema:Person,
        "Sebastian Buschjäger"^^schema:Person ;
    schema:dateModified "2020-02-03T17:38:45Z"^^schema:DateTime ;
    schema:datePublished "2020-02-03T17:38:45Z"^^schema:DateTime ;
    schema:genre "68T05"^^schema:Text,
        "I.2.6; B.7.1"^^schema:Text,
        "cs.ET"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Explainable Bit Error Tolerance of Resistive RAM-Based Binarized  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.00909v1"^^schema:URL .

<1689> a schema:ScholarlyArticle ;
    schema:abstract "Polarimetric thermal to visible face verification entails matching two imagesthat contain significant domain differences. Several recent approaches haveattempted to synthesize visible faces from thermal images for cross-modalmatching. In this paper, we take a different approach in which rather thanfocusing only on synthesizing visible faces from thermal faces, we also proposeto synthesize thermal faces from visible faces. Our intuition is based on thefact that thermal images also contain some discriminative information about theperson for verification. Deep features from a pre-trained Convolutional NeuralNetwork (CNN) are extracted from the original as well as the synthesizedimages. These features are then fused to generate a template which is then usedfor verification. The proposed synthesis network is based on the self-attentiongenerative adversarial network (SAGAN) which essentially allows efficientattention-guided image synthesis. Extensive experiments on the ARL polarimetricthermal face dataset demonstrate that the proposed method achievesstate-of-the-art performance."^^schema:Text ;
    schema:author "Benjamin S. Riggan"^^schema:Person,
        "Nathaniel J. Short"^^schema:Person,
        "Shuowen Hu"^^schema:Person,
        "Vishal M. Patel"^^schema:Person,
        "Xing Di"^^schema:Person ;
    schema:dateModified "2019-04-15T21:58:40Z"^^schema:DateTime ;
    schema:datePublished "2019-04-15T21:58:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Polarimetric Thermal to Visible Face Verification via Self-Attention  Guided Synthesis"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.07344v1"^^schema:URL .

<169> a schema:ScholarlyArticle ;
    schema:abstract "Despite their overwhelming capacity to overfit, deep learning architecturestend to generalize relatively well to unseen data, allowing them to be deployedin practice. However, explaining why this is the case is still an open area ofresearch. One standing hypothesis that is gaining popularity, e.g. Hochreiter &amp;Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of theloss function found by stochastic gradient based methods results in goodgeneralization. This paper argues that most notions of flatness are problematicfor deep models and can not be directly applied to explain generalization.Specifically, when focusing on deep networks with rectifier units, we canexploit the particular geometry of parameter space induced by the inherentsymmetries that these architectures exhibit to build equivalent modelscorresponding to arbitrarily sharper minima. Furthermore, if we allow toreparametrize a function, the geometry of its parameters can change drasticallywithout affecting its generalization properties."^^schema:Text ;
    schema:author "Laurent Dinh"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Samy Bengio"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "246"^^schema:Integer ;
    schema:dateModified "2017-05-15T23:33:19Z"^^schema:DateTime ;
    schema:datePublished "2017-03-15T05:12:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Sharp Minima Can Generalize For Deep Nets"^^schema:Text ;
    schema:publisher "ICML, 1019-1028"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.04933v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4474448870091274183&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1690> a schema:ScholarlyArticle ;
    schema:abstract "The RDF-to-text task has recently gained substantial attention due tocontinuous growth of Linked Data. In contrast to traditional pipeline models,recent studies have focused on neural models, which are now able to convert aset of RDF triples into text in an end-to-end style with promising results.However, English is the only language widely targeted. We address this researchgap by presenting NABU, a multilingual graph-based neural model that verbalizesRDF data to German, Russian, and English. NABU is based on an encoder-decoderarchitecture, uses an encoder inspired by Graph Attention Networks and aTransformer as decoder. Our approach relies on the fact that knowledge graphsare language-agnostic and they hence can be used to generate multilingual text.We evaluate NABU in monolingual and multilingual settings on standardbenchmarking WebNLG datasets. Our results show that NABU outperformsstate-of-the-art approaches on English with 66.21 BLEU, and achieves consistentresults across all languages on the multilingual scenario with 56.04 BLEU."^^schema:Text ;
    schema:author "Axel-Cyrille Ngonga Ngomo"^^schema:Person,
        "Diego Moussallem"^^schema:Person,
        "Dwaraknath Gnaneshwar"^^schema:Person,
        "Thiago Castro Ferreira"^^schema:Person ;
    schema:dateModified "2020-09-21T14:14:05Z"^^schema:DateTime ;
    schema:datePublished "2020-09-16T14:59:06Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "NABU $\\mathrm{-}$ Multilingual Graph-based Neural RDF Verbalizer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.07728v2"^^schema:URL .

<1691> a schema:ScholarlyArticle ;
    schema:abstract "Recent student knowledge modeling algorithms such as Deep Knowledge Tracing(DKT) and Dynamic Key-Value Memory Networks (DKVMN) have been shown to produceaccurate predictions of problem correctness within the same learning system.However, these algorithms do not attempt to directly infer student knowledge.In this paper we present an extension to these algorithms to also inferknowledge. We apply this extension to DKT and DKVMN, resulting in knowledgeestimates that correlate better with a posttest than knowledge estimates fromBayesian Knowledge Tracing (BKT), an algorithm designed to infer knowledge, andanother classic algorithm, Performance Factors Analysis (PFA). We also applyour extension to correctness predictions from BKT and PFA, finding thatknowledge estimates produced with it correlate better with the posttest thanBKT and PFA's standard knowledge estimates. These findings are significantsince the primary aim of education is to prepare students for later experiencesoutside of the immediate learning activity."^^schema:Text ;
    schema:author "Bruce M. McLaren"^^schema:Person,
        "Richard Scruggs"^^schema:Person,
        "Ryan S. Baker"^^schema:Person ;
    schema:dateModified "2020-08-31T19:33:54Z"^^schema:DateTime ;
    schema:datePublished "2019-10-14T14:21:20Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Extending Deep Knowledge Tracing: Inferring Interpretable Knowledge and  Predicting Post-System Performance"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12597v2"^^schema:URL .

<1692> a schema:ScholarlyArticle ;
    schema:abstract "We present an anomaly detection method using Wasserstein generativeadversarial networks (WGANs) on optical galaxy images from the wide-fieldsurvey conducted with the Hyper Suprime-Cam (HSC) on the Subaru Telescope inHawai'i. The WGAN is trained on the entire sample, and learns to generaterealistic HSC-like images that follow the distribution of the training data. Weidentify images which are less well-represented in the generator's latentspace, and which the discriminator flags as less realistic; these are thusanomalous with respect to the rest of the data. We propose a new approach tocharacterize these anomalies based on a convolutional autoencoder (CAE) toreduce the dimensionality of the residual differences between the real andWGAN-reconstructed images. We construct a subsample of ~9,000 highly anomalousimages from our nearly million object sample, and further identify interestinganomalies within these; these include galaxy mergers, tidal features, andextreme star-forming galaxies. The proposed approach could boost unsuperviseddiscovery in the era of big data astrophysics."^^schema:Text ;
    schema:author "Alexie Leauthaud"^^schema:Person,
        "Francois Lanusse"^^schema:Person,
        "Kate Storey-Fisher"^^schema:Person,
        "Marc Huertas-Company"^^schema:Person,
        "Nesar Ramachandra"^^schema:Person,
        "Song Huang"^^schema:Person,
        "Yifei Luo"^^schema:Person ;
    schema:dateModified "2020-12-15T04:16:31Z"^^schema:DateTime ;
    schema:datePublished "2020-12-15T04:16:31Z"^^schema:DateTime ;
    schema:genre "astro-ph.GA"^^schema:Text ;
    schema:headline "Anomaly Detection in Astronomical Images with Generative Adversarial  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.08082v1"^^schema:URL .

<1693> a schema:ScholarlyArticle ;
    schema:abstract "We present new results on learning temporally extended actions forcontinuoustasks, using the options framework (Suttonet al.[1999b], Precup[2000]). In orderto achieve this goal we work with the option-criticarchitecture (Baconet al.[2017])using a deliberation cost and train it withproximal policy optimization (Schulmanet al.[2017]) instead of vanilla policygradient. Results on Mujoco domains arepromising, but lead to interestingquestions aboutwhena given option should beused, an issue directly connected tothe use of initiation sets."^^schema:Text ;
    schema:author "Doina Precup"^^schema:Person,
        "Jean Harb"^^schema:Person,
        "Martin Klissarov"^^schema:Person,
        "Pierre-Luc Bacon"^^schema:Person ;
    schema:dateModified "2017-11-30T00:45:09Z"^^schema:DateTime ;
    schema:datePublished "2017-11-30T00:45:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learnings Options End-to-End for Continuous Action Tasks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1712.00004v1"^^schema:URL .

<1694> a schema:ScholarlyArticle ;
    schema:abstract "We propose a semi-supervised model for detecting anomalies in videosinspiredby the Video Pixel Network [van den Oord et al., 2016]. VPN is aprobabilisticgenerative model based on a deep neural network that estimates thediscrete jointdistribution of raw pixels in video frames. Our model extends theConvolutional-LSTM video encoder part of the VPN with a novel convolutionalbased attentionmechanism. We also modify the Pixel-CNN decoder part of the VPNto a frameinpainting task where a partially masked version of the frame topredict is given asinput. The frame reconstruction error is used as an anomalyindicator. We test ourmodel on a modified version of the moving mnist dataset[Srivastava et al., 2015]. Our model is shown to be effective in detectinganomalies in videos. This approachcould be a component in applicationsrequiring visual common sense."^^schema:Text ;
    schema:author "Itamar Ben-Ari"^^schema:Person,
        "Ravid Shwartz-Ziv"^^schema:Person ;
    schema:dateModified "2018-11-26T08:25:14Z"^^schema:DateTime ;
    schema:datePublished "2018-11-26T08:25:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Attentioned Convolutional LSTM InpaintingNetwork for Anomaly Detection  in Videos"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.10228v1"^^schema:URL .

<1695> a schema:ScholarlyArticle ;
    schema:abstract "Sparse reward problems are one of the biggest challenges in ReinforcementLearning. Goal-directed tasks are one such sparse reward problems where areward signal is received only when the goal is reached. One promising way totrain an agent to perform goal-directed tasks is to use Hindsight Learningapproaches. In these approaches, even when an agent fails to reach the desiredgoal, the agent learns to reach the goal it achieved instead. Doing this overmultiple trajectories while generalizing the policy learned from the achievedgoals, the agent learns a goal conditioned policy to reach any goal. One suchapproach is Hindsight Experience replay which uses an off-policy ReinforcementLearning algorithm to learn a goal conditioned policy. In this approach, areplay of the past transitions happens in a uniformly random fashion. Anotherapproach is to use a Hindsight version of the policy gradients to directlylearn a policy. In this work, we discuss different ways to replay pasttransitions to improve learning in hindsight experience replay focusing onprioritized variants in particular. Also, we implement the Hindsight Policygradient methods to robotic tasks."^^schema:Text ;
    schema:author "Ameet Deshpande"^^schema:Person,
        "Ashutosh Jha"^^schema:Person,
        "Balaraman Ravindran"^^schema:Person,
        "Srikanth Sarma"^^schema:Person ;
    schema:dateModified "2018-11-04T19:40:31Z"^^schema:DateTime ;
    schema:datePublished "2018-09-16T17:07:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improvements on Hindsight Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.06719v2"^^schema:URL .

<1696> a schema:ScholarlyArticle ;
    schema:abstract "This article demontrates that we can apply deep learning to textunderstanding from character-level inputs all the way up to abstract textconcepts, using temporal convolutional networks (ConvNets). We apply ConvNetsto various large-scale datasets, including ontology classification, sentimentanalysis, and text categorization. We show that temporal ConvNets can achieveastonishing performance without the knowledge of words, phrases, sentences andany other syntactic or semantic structures with regards to a human language.Evidence shows that our models can work for both English and Chinese."^^schema:Text ;
    schema:author "Xiang Zhang"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:dateModified "2016-04-04T02:40:48Z"^^schema:DateTime ;
    schema:datePublished "2015-02-05T20:45:19Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Text Understanding from Scratch"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1502.01710v5"^^schema:URL .

<1697> a schema:ScholarlyArticle ;
    schema:abstract "In federated learning, a central server coordinates the training of a singlemodel on a massively distributed network of devices. This setting can benaturally extended to a multi-task learning framework, to handle real-worldfederated datasets that typically show strong statistical heterogeneity amongdevices. Despite federated multi-task learning being shown to be an effectiveparadigm for real-world datasets, it has been applied only on convex models. Inthis work, we introduce VIRTUAL, an algorithm for federated multi-task learningfor general non-convex models. In VIRTUAL the federated network of the serverand the clients is treated as a star-shaped Bayesian network, and learning isperformed on the network using approximated variational inference. We show thatthis method is effective on real-world federated datasets, outperforming thecurrent state-of-the-art for federated learning, and concurrently allowingsparser gradient updates."^^schema:Text ;
    schema:author "Ami Beuret"^^schema:Person,
        "Joachim M. Buhmann"^^schema:Person,
        "Luca Corinzia"^^schema:Person ;
    schema:dateModified "2021-02-04T14:38:06Z"^^schema:DateTime ;
    schema:datePublished "2019-06-14T16:09:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Federated Multi-Task Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.06268v2"^^schema:URL .

<1698> a schema:ScholarlyArticle ;
    schema:abstract "Spatial transformer network has been used in a layered form in conjunctionwith a convolutional network to enable the model to transform data spatially.In this paper, we propose a combined spatial transformer network (STN) and aLong Short-Term Memory network (LSTM) to classify digits in sequences formed byMINST elements. This LSTM-STN model has a top-down attention mechanism profitfrom LSTM layer, so that the STN layer can perform short-term independentelements for the statement in the process of spatial transformation, thusavoiding the distortion that may be caused when the entire sequence isspatially transformed. It also avoids the influence of this distortion on thesubsequent classification process using convolutional neural networks andachieves a single digit error of 1.6\\% compared with 2.2\\% of ConvolutionalNeural Network with STN layer."^^schema:Text ;
    schema:author "Hao Sun"^^schema:Person,
        "Shiyang Feng"^^schema:Person,
        "Tianyue Chen"^^schema:Person ;
    schema:dateModified "2019-01-08T12:08:32Z"^^schema:DateTime ;
    schema:datePublished "2019-01-08T12:08:32Z"^^schema:DateTime ;
    schema:genre "eess.IV"^^schema:Text ;
    schema:headline "Long Short-Term Memory Spatial Transformer Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.02273v1"^^schema:URL .

<1699> a schema:ScholarlyArticle ;
    schema:abstract "The evaluation of higher-order cross-sections is an important component inthe search for new physics, both at hadron colliders and elsewhere. For mostnew physics processes of interest, total cross-sections are known atnext-to-leading order (NLO) in the strong coupling $\\alpha_s$, and oftenbeyond, via either higher-order terms at fixed powers of $\\alpha_s$, ormulti-emission resummation. However, the computation time for such higher-ordercross-sections is prohibitively expensive, and precludes efficient evaluationin parameter-space scans beyond two dimensions. Here we describe the softwaretool $\\textsf{xsec}$, which allows for fast evaluation of cross-sections basedon the use of machine-learning regression, using distributed Gaussian processestrained on a pre-generated sample of parameter points. This first version ofthe code provides all NLO Minimal Supersymmetric Standard Modelstrong-production cross-sections at the LHC, for individual flavour finalstates, evaluated in a fraction of a second. Moreover, it calculates regressionerrors, as well as estimates of errors from higher-order contributions, fromuncertainties in the parton distribution functions, and from the value of$\\alpha_s$. While we focus on a specific phenomenological model ofsupersymmetry, the method readily generalises to any process where it ispossible to generate a sufficient training sample."^^schema:Text ;
    schema:author "Anders Kvellestad"^^schema:Person,
        "Andy Buckley"^^schema:Person,
        "Are Raklev"^^schema:Person,
        "Ingrid A. Vazquez-Holm"^^schema:Person,
        "Jeriek Van den Abeele"^^schema:Person,
        "Jon Vegard Sparre"^^schema:Person,
        "Pat Scott"^^schema:Person ;
    schema:dateModified "2020-12-18T19:00:02Z"^^schema:DateTime ;
    schema:datePublished "2020-06-29T18:01:13Z"^^schema:DateTime ;
    schema:genre "hep-ex"^^schema:Text,
        "hep-ph"^^schema:Text ;
    schema:headline "$\\textsf{Xsec}$: the cross-section evaluation code"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16273v2"^^schema:URL .

<17> a schema:ScholarlyArticle ;
    schema:abstract "Modern recommender systems model people and items by discovering or `teasingapart' the underlying dimensions that encode the properties of items and users'preferences toward them. Critically, such dimensions are uncovered based onuser feedback, often in implicit form (such as purchase histories, browsinglogs, etc.); in addition, some recommender systems make use of sideinformation, such as product attributes, temporal information, or review text.However one important feature that is typically ignored by existingpersonalized recommendation and ranking methods is the visual appearance of theitems being considered. In this paper we propose a scalable factorization modelto incorporate visual signals into predictors of people's opinions, which weapply to a selection of large, real-world datasets. We make use of visualfeatures extracted from product images using (pre-trained) deep networks, ontop of which we learn an additional layer that uncovers the visual dimensionsthat best explain the variation in people's feedback. This not only leads tosignificantly more accurate personalized ranking methods, but also helps toalleviate cold start issues, and qualitatively to analyze the visual dimensionsthat influence people's opinions."^^schema:Text ;
    schema:author "Julian McAuley"^^schema:Person,
        "Ruining He"^^schema:Person ;
    schema:commentCount "307"^^schema:Integer ;
    schema:dateModified "2015-10-06T23:46:15Z"^^schema:DateTime ;
    schema:datePublished "2015-10-06T23:46:15Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.01784v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2037226735051735416&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<170> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a design strategy for neural network macro-architecture based onself-similarity. Repeated application of a simple expansion rule generates deepnetworks whose structural layouts are precisely truncated fractals. Thesenetworks contain interacting subpaths of different lengths, but do not includeany pass-through or residual connections; every internal signal is transformedby a filter and nonlinearity before being seen by subsequent layers. Inexperiments, fractal networks match the excellent performance of standardresidual networks on both CIFAR and ImageNet classification tasks, therebydemonstrating that residual representations may not be fundamental to thesuccess of extremely deep convolutional neural networks. Rather, the key may bethe ability to transition, during training, from effectively shallow to deep.We note similarities with student-teacher behavior and develop drop-path, anatural extension of dropout, to regularize co-adaptation of subpaths infractal architectures. Such regularization allows extraction ofhigh-performance fixed-depth subnetworks. Additionally, fractal networksexhibit an anytime property: shallow subnetworks provide a quick answer, whiledeeper subnetworks, with higher latency, provide a more accurate answer."^^schema:Text ;
    schema:author "Gregory Shakhnarovich"^^schema:Person,
        "Gustav Larsson"^^schema:Person,
        "Michael Maire"^^schema:Person ;
    schema:commentCount "467"^^schema:Integer ;
    schema:dateModified "2017-05-26T18:53:56Z"^^schema:DateTime ;
    schema:datePublished "2016-05-24T20:28:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "FractalNet: Ultra-Deep Neural Networks without Residuals"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07648v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15300779753326541860&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1700> a schema:ScholarlyArticle ;
    schema:abstract "Magnetic activity in stars manifests as dark spots on their surfaces thatmodulate the brightness observed by telescopes. These light curves containimportant information on stellar rotation. However, the accurate estimation ofrotation periods is computationally expensive due to scarce ground truthinformation, noisy data, and large parameter spaces that lead to degeneratesolutions. We harness the power of deep learning and successfully applyConvolutional Neural Networks to regress stellar rotation periods from Keplerlight curves. Geometry-preserving time-series to image transformations of thelight curves serve as inputs to a ResNet-18 based architecture which is trainedthrough transfer learning. The McQuillan catalog of published rotation periodsis used as ansatz to groundtruth. We benchmark the performance of our methodagainst a random forest regressor, a 1D CNN, and the Auto-Correlation Function(ACF) - the current standard to estimate rotation periods. Despite limiting ourinput to fewer data points (1k), our model yields more accurate results andruns 350 times faster than ACF runs on the same number of data points and10,000 times faster than ACF runs on 65k data points. With only minimal featureengineering our approach has impressive accuracy, motivating the application ofdeep learning to regress stellar parameters on an even larger scale"^^schema:Text ;
    schema:author "Andrés Muñoz-Jaramillo"^^schema:Person,
        "Anna Jungbluth"^^schema:Person,
        "Brett Morris"^^schema:Person,
        "Daniel K. Giles"^^schema:Person,
        "J. Emmanuel Johnson"^^schema:Person,
        "Lisseth Gavilan"^^schema:Person,
        "Sairam Sundaresan"^^schema:Person,
        "Stela Ishitani Silva"^^schema:Person,
        "Tansu Daylan"^^schema:Person ;
    schema:dateModified "2020-12-04T02:35:19Z"^^schema:DateTime ;
    schema:datePublished "2020-12-02T07:14:11Z"^^schema:DateTime ;
    schema:genre "astro-ph.SR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "RotNet: Fast and Scalable Estimation of Stellar Rotation Periods Using  Convolutional Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.01985v2"^^schema:URL .

<1701> a schema:ScholarlyArticle ;
    schema:abstract "A quality abstractive summary should not only copy salient source texts assummaries but should also tend to generate new conceptual words to expressconcrete details. Inspired by the popular pointer generatorsequence-to-sequence model, this paper presents a concept pointer network forimproving these aspects of abstractive summarization. The network leveragesknowledge-based, context-aware conceptualizations to derive an extended set ofcandidate concepts. The model then points to the most appropriate choice usingboth the concept set and original source text. This joint approach generatesabstractive summaries with higher-level semantic concepts. The training modelis also optimized in a way that adapts to different data, which is based on anovel method of distantly-supervised learning guided by reference summaries andtesting set. Overall, the proposed approach provides statistically significantimprovements over several state-of-the-art models on both the DUC-2004 andGigaword datasets. A human evaluation of the model's abstractive abilities alsosupports the quality of the summaries produced within this framework."^^schema:Text ;
    schema:author "Gao Yang"^^schema:Person,
        "Huang Heyan"^^schema:Person,
        "Wang Wenbo"^^schema:Person,
        "Zhou Yuxiang"^^schema:Person ;
    schema:dateModified "2019-10-18T16:11:31Z"^^schema:DateTime ;
    schema:datePublished "2019-10-18T16:11:31Z"^^schema:DateTime ;
    schema:genre "68U15, 68T50"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Concept Pointer Network for Abstractive Summarization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.08486v1"^^schema:URL .

<1702> a schema:ScholarlyArticle ;
    schema:abstract "The purpose of this technical report is two-fold. First of all, it introducesa suite of challenging continuous control tasks (integrated with OpenAI Gym)based on currently existing robotics hardware. The tasks include pushing,sliding and pick &amp; place with a Fetch robotic arm as well as in-hand objectmanipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewardsand follow a Multi-Goal Reinforcement Learning (RL) framework in which an agentis told what to do using an additional input.  The second part of the paper presents a set of concrete research ideas forimproving RL algorithms, most of which are related to Multi-Goal RL andHindsight Experience Replay."^^schema:Text ;
    schema:author "Alex Ray"^^schema:Person,
        "Bob McGrew"^^schema:Person,
        "Bowen Baker"^^schema:Person,
        "Glenn Powell"^^schema:Person,
        "Jonas Schneider"^^schema:Person,
        "Josh Tobin"^^schema:Person,
        "Maciek Chociej"^^schema:Person,
        "Marcin Andrychowicz"^^schema:Person,
        "Matthias Plappert"^^schema:Person,
        "Peter Welinder"^^schema:Person,
        "Vikash Kumar"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person ;
    schema:dateModified "2018-03-10T18:11:25Z"^^schema:DateTime ;
    schema:datePublished "2018-02-26T17:20:14Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Multi-Goal Reinforcement Learning: Challenging Robotics Environments and  Request for Research"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1802.09464v2"^^schema:URL .

<1703> a schema:ScholarlyArticle ;
    schema:abstract "Flexible pick-and-place is a fundamental yet challenging task withinrobotics, in particular due to the need of an object model for a simple targetpose definition. In this work, the robot instead learns to pick-and-placeobjects using planar manipulation according to a single, demonstrated goalstate. Our primary contribution lies within combining robot learning ofprimitives, commonly estimated by fully-convolutional neural networks, withone-shot imitation learning. Therefore, we define the place reward as acontrastive loss between real-world measurements and a task-specific noisedistribution. Furthermore, we design our system to learn in a self-supervisedmanner, enabling real-world experiments with up to 25000 pick-and-placeactions. Then, our robot is able to place trained objects with an averageplacement error of 2.7 (0.2) mm and 2.6 (0.8){\\deg}. As our approach does notrequire an object model, the robot is able to generalize to unknown objectswhile keeping a precision of 5.9 (1.1) mm and 4.1 (1.2){\\deg}. We further showa range of emerging behaviors: The robot naturally learns to select the correctobject in the presence of multiple object types, precisely inserts objectswithin a peg game, picks screws out of dense clutter, and infers multiplepick-and-place actions from a single goal state."^^schema:Text ;
    schema:author "Lars Berscheid"^^schema:Person,
        "Pascal Meißner"^^schema:Person,
        "Torsten Kröger"^^schema:Person ;
    schema:dateModified "2020-06-15T12:51:29Z"^^schema:DateTime ;
    schema:datePublished "2020-06-15T12:51:29Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Self-supervised Learning for Precise Pick-and-place without Object Model"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.08373v1"^^schema:URL .

<1704> a schema:ScholarlyArticle ;
    schema:abstract "Intent detection and slot filling are two fundamental tasks for building aspoken language understanding (SLU) system. Multiple deep learning-based jointmodels have demonstrated excellent results on the two tasks. In this paper, wepropose a new joint model with a wheel-graph attention network (Wheel-GAT)which is able to model interrelated connections directly for intent detectionand slot filling. To construct a graph structure for utterances, we createintent nodes, slot nodes, and directed edges. Intent nodes can provideutterance-level semantic information for slot filling, while slot nodes canalso provide local keyword information for intent. Experiments show that ourmodel outperforms multiple baselines on two public datasets. Besides, we alsodemonstrate that using Bidirectional Encoder Representation from Transformer(BERT) model further boosts the performance in the SLU task."^^schema:Text ;
    schema:author "Bi Zeng"^^schema:Person,
        "Pengfei Wei"^^schema:Person,
        "Wenxiong Liao"^^schema:Person ;
    schema:dateModified "2021-02-09T02:37:56Z"^^schema:DateTime ;
    schema:datePublished "2021-02-09T02:37:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Joint Intent Detection and Slot Filling with Wheel-Graph Attention  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.04610v1"^^schema:URL .

<1705> a schema:ScholarlyArticle ;
    schema:abstract "Object detection is a fundamental visual recognition problem in computervision and has been widely studied in the past decades. Visual object detectionaims to find objects of certain target classes with precise localization in agiven image and assign each object instance a corresponding class label. Due tothe tremendous successes of deep learning based image classification, objectdetection techniques using deep learning have been actively studied in recentyears. In this paper, we give a comprehensive survey of recent advances invisual object detection with deep learning. By reviewing a large body of recentrelated work in literature, we systematically analyze the existing objectdetection frameworks and organize the survey into three major parts: (i)detection components, (ii) learning strategies, and (iii) applications &amp;benchmarks. In the survey, we cover a variety of factors affecting thedetection performance in detail, such as detector architectures, featurelearning, proposal generation, sampling strategies, etc. Finally, we discussseveral future directions to facilitate and spur future research for visualobject detection with deep learning. Keywords: Object Detection, Deep Learning,Deep Convolutional Neural Networks"^^schema:Text ;
    schema:author "Doyen Sahoo"^^schema:Person,
        "Steven C. H. Hoi"^^schema:Person,
        "Xiongwei Wu"^^schema:Person ;
    schema:dateModified "2019-08-10T02:54:17Z"^^schema:DateTime ;
    schema:datePublished "2019-08-10T02:54:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Recent Advances in Deep Learning for Object Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.03673v1"^^schema:URL .

<1706> a schema:ScholarlyArticle ;
    schema:abstract "Value Iteration Networks (VINs) have emerged as a popular method toincorporate planning algorithms within deep reinforcement learning, enablingperformance improvements on tasks requiring long-range reasoning andunderstanding of environment dynamics. This came with several limitations,however: the model is not incentivised in any way to perform meaningfulplanning computations, the underlying state space is assumed to be discrete,and the Markov decision process (MDP) is assumed fixed and known. We proposeeXecuted Latent Value Iteration Networks (XLVINs), which combine recentdevelopments across contrastive self-supervised learning, graph representationlearning and neural algorithmic reasoning to alleviate all of the abovelimitations, successfully deploying VIN-style models on generic environments.XLVINs match the performance of VIN-like models when the underlying MDP isdiscrete, fixed and known, and provides significant improvements to model-freebaselines across three general MDP setups."^^schema:Text ;
    schema:author "Andreea Deac"^^schema:Person,
        "Jian Tang"^^schema:Person,
        "Mladen Nikolić"^^schema:Person,
        "Ognjen Milinković"^^schema:Person,
        "Petar Veličković"^^schema:Person,
        "Pierre-Luc Bacon"^^schema:Person ;
    schema:dateModified "2020-12-06T16:59:01Z"^^schema:DateTime ;
    schema:datePublished "2020-10-25T16:04:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "XLVIN: eXecuted Latent Value Iteration Nets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13146v2"^^schema:URL .

<1707> a schema:ScholarlyArticle ;
    schema:abstract "Over past years, the philosophy for designing the artificial intelligencealgorithms has significantly shifted towards automatically extracting thecomposable systems from massive data volumes. This paradigm shift has beenexpedited by the big data booming which enables us to easily access and analyzethe highly large data sets. The most well-known class of big data analysistechniques is called deep learning. These models require significantcomputation power and extremely high memory accesses which necessitate thedesign of novel approaches to reduce the memory access and improve powerefficiency while taking into account the development of domain-specifichardware accelerators to support the current and future data sizes and modelstructures.The current trends for designing application-specific integratedcircuits barely consider the essential requirement for maintaining the complexneural network computation to be resilient in the presence of soft errors. Thesoft errors might strike either memory storage or combinational logic in thehardware accelerator that can affect the architectural behavior such that theprecision of the results fall behind the minimum allowable correctness. In thisstudy, we demonstrate that the impact of soft errors on a customized deeplearning algorithm called Binarized Neural Network might cause drastic imagemisclassification. Our experimental results show that the accuracy of imageclassifier can drastically drop by 76.70% and 19.25% in lfcW1A1 and cnvW1A1networks,respectively across CIFAR-10 and MNIST datasets during the faultinjection for the worst-case scenarios"^^schema:Text ;
    schema:author "Connor Broyles"^^schema:Person,
        "Navid Khoshavi"^^schema:Person,
        "Yu Bi"^^schema:Person ;
    schema:dateModified "2020-04-10T16:15:55Z"^^schema:DateTime ;
    schema:datePublished "2020-04-10T16:15:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Survey on Impact of Transient Faults on BNN Inference Accelerators"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.05915v1"^^schema:URL .

<1708> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the concept of a multi-principal assistance game (MPAG), andcircumvent an obstacle in social choice theory, Gibbard's theorem, by using asufficiently collegial preference inference mechanism. In an MPAG, a singleagent assists N human principals who may have widely different preferences.MPAGs generalize assistance games, also known as cooperative inversereinforcement learning games. We analyze in particular a generalization ofapprenticeship learning in which the humans first perform some work to obtainutility and demonstrate their preferences, and then the robot acts to furthermaximize the sum of human payoffs. We show in this setting that if the game issufficiently collegial, i.e. if the humans are responsible for obtaining asufficient fraction of the rewards through their own actions, then theirpreferences are straightforwardly revealed through their work. This revelationmechanism is non-dictatorial, does not limit the possible outcomes to twoalternatives, and is dominant-strategy incentive-compatible."^^schema:Text ;
    schema:author "Andrew Critch"^^schema:Person,
        "Arnaud Fickinger"^^schema:Person,
        "Dylan Hadfield-Menell"^^schema:Person,
        "Simon Zhuang"^^schema:Person,
        "Stuart Russell"^^schema:Person ;
    schema:dateModified "2020-12-29T00:06:47Z"^^schema:DateTime ;
    schema:datePublished "2020-12-29T00:06:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.GT"^^schema:Text ;
    schema:headline "Multi-Principal Assistance Games: Definition and Collegial Mechanisms"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.14536v1"^^schema:URL .

<1709> a schema:ScholarlyArticle ;
    schema:abstract "It is difficult to be able to imitate well in unknown states from a smallamount of expert data and sampling data. Supervised learning methods such asBehavioral Cloning do not require sampling data, but usually suffer fromdistribution shift. The methods based on reinforcement learning, such asinverse reinforcement learning and generative adversarial imitation learning(GAIL), can learn from only a few expert data. However, they often need tointeract with the environment. Soft Q imitation learning addressed theproblems, and it was shown that it could learn efficiently by combiningBehavioral Cloning and soft Q-learning with constant rewards. In order to makethis algorithm more robust to distribution shift, we propose Discriminator SoftActor Critic (DSAC). It uses a reward function based on adversarial inversereinforcement learning instead of constant rewards. We evaluated it on PyBulletenvironments with only four expert trajectories."^^schema:Text ;
    schema:author "Daichi Nishio"^^schema:Person,
        "Daiki Kuyoshi"^^schema:Person,
        "Satoshi Yamane"^^schema:Person,
        "Toi Tsuneda"^^schema:Person ;
    schema:dateModified "2020-01-31T12:39:52Z"^^schema:DateTime ;
    schema:datePublished "2020-01-19T10:45:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Discriminator Soft Actor Critic without Extrinsic Rewards"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.06808v3"^^schema:URL .

<171> a schema:ScholarlyArticle ;
    schema:abstract "By capturing statistical patterns in large corpora, machine learning hasenabled significant advances in natural language processing, including inmachine translation, question answering, and sentiment analysis. However, foragents to intelligently interact with humans, simply capturing the statisticalpatterns is insufficient. In this paper we investigate if, and how, groundedcompositional language can emerge as a means to achieve goals in multi-agentpopulations. Towards this end, we propose a multi-agent learning environmentand learning methods that bring about emergence of a basic compositionallanguage. This language is represented as streams of abstract discrete symbolsuttered by agents over time, but nonetheless has a coherent structure thatpossesses a defined vocabulary and syntax. We also observe emergence ofnon-verbal communication such as pointing and guiding when languagecommunication is unavailable."^^schema:Text ;
    schema:author "Igor Mordatch"^^schema:Person,
        "Pieter Abbeel"^^schema:Person ;
    schema:commentCount "251"^^schema:Integer ;
    schema:dateModified "2018-07-24T04:13:05Z"^^schema:DateTime ;
    schema:datePublished "2017-03-15T03:30:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Emergence of Grounded Compositional Language in Multi-Agent Populations"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.04908v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13990608325011462923&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1710> a schema:ScholarlyArticle ;
    schema:abstract "The use of machine learning systems to support decision making in healthcareraises questions as to what extent these systems may introduce or exacerbatedisparities in care for historically underrepresented and mistreated groups,due to biases implicitly embedded in observational data in electronic healthrecords. To address this problem in the context of clinical risk predictionmodels, we develop an augmented counterfactual fairness criteria to extend thegroup fairness criteria of equalized odds to an individual level. We do so byrequiring that the same prediction be made for a patient, and a counterfactualpatient resulting from changing a sensitive attribute, if the factual andcounterfactual outcomes do not differ. We investigate the extent to which theaugmented counterfactual fairness criteria may be applied to develop fairmodels for prolonged inpatient length of stay and mortality with observationalelectronic health records data. As the fairness criteria is ill-defined withoutknowledge of the data generating process, we use a variational autoencoder toperform counterfactual inference in the context of an assumed causal graph.While our technique provides a means to trade off maintenance of fairness withreduction in predictive performance in the context of a learned generativemodel, further work is needed to assess the generality of this approach."^^schema:Text ;
    schema:author "Daisy Yi Ding"^^schema:Person,
        "Nigam H. Shah"^^schema:Person,
        "Stephen Pfohl"^^schema:Person,
        "Tony Duan"^^schema:Person ;
    schema:dateModified "2019-07-14T18:44:09Z"^^schema:DateTime ;
    schema:datePublished "2019-07-14T18:44:09Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Counterfactual Reasoning for Fair Clinical Risk Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.06260v1"^^schema:URL .

<1711> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Network (CNN) is intensively implemented to solve superresolution (SR) tasks because of its superior performance. However, the problemof super resolution is still challenging due to the lack of prior knowledge andsmall receptive field of CNN. We propose the Segmentation-Piror Self-AttentionGenerative Adversarial Network (SPSAGAN) to combine segmentation-priors andfeature attentions into a unified framework. This combination is led by acarefully designed weighted addition to balance the influence of feature andsegmentation attentions, so that the network can emphasize textures in the samesegmentation category and meanwhile focus on the long-distance featurerelationship. We also propose a lightweight skip connection architecture calledResidual-in-Residual Sparse Block (RRSB) to further improve thesuper-resolution performance and save computation. Extensive experiments showthat SPSAGAN can generate more realistic and visually pleasing texturescompared to state-of-the-art SFTGAN and ESRGAN on many SR datasets."^^schema:Text ;
    schema:author "Roland Hu"^^schema:Person,
        "Yuxin Zhang"^^schema:Person,
        "Zuquan Zheng"^^schema:Person ;
    schema:dateModified "2020-03-07T02:13:14Z"^^schema:DateTime ;
    schema:datePublished "2020-03-07T02:13:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Super Resolution Using Segmentation-Prior Self-Attention Generative  Adversarial Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03489v1"^^schema:URL .

<1712> a schema:ScholarlyArticle ;
    schema:abstract "Data augmentation is a major component of many machine learning methods withstate-of-the-art performance. Common augmentation strategies work by drawingrandom samples from a space of transformations. Unfortunately, such samplingapproaches are limited in expressivity, as they are unable to scale to richtransformations that depend on numerous parameters due to the curse ofdimensionality. Adversarial examples can be considered as an alternative schemefor data augmentation. By being trained on the most difficult modifications ofthe inputs, the resulting models are then hopefully able to handle other,presumably easier, modifications as well. The advantage of adversarialaugmentation is that it replaces sampling with the use of a single, calculatedperturbation that maximally increases the loss. The downside, however, is thatthese raw adversarial perturbations appear rather unstructured; applying themoften does not produce a natural transformation, contrary to a desirable dataaugmentation technique. To address this, we propose a method to generateadversarial examples that maintain some desired natural structure. We firstconstruct a subspace that only contains perturbations with the desiredstructure. We then project the raw adversarial gradient onto this space toselect a structured transformation that would maximally increase the loss whenapplied. We demonstrate this approach through two types of imagetransformations: photometric and geometric. Furthermore, we show that trainingon such structured adversarial images improves generalization."^^schema:Text ;
    schema:author "Calvin Luo"^^schema:Person,
        "Hossein Mobahi"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:dateModified "2020-11-05T18:07:55Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T18:07:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Data Augmentation via Structured Adversarial Perturbations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03010v1"^^schema:URL .

<1713> a schema:ScholarlyArticle ;
    schema:abstract "Deep generative models have recently shown great promise in imitationlearning for motor control. Given enough data, even supervised approaches cando one-shot imitation learning; however, they are vulnerable to cascadingfailures when the agent trajectory diverges from the demonstrations. Comparedto purely supervised methods, Generative Adversarial Imitation Learning (GAIL)can learn more robust controllers from fewer demonstrations, but is inherentlymode-seeking and more difficult to train. In this paper, we show how to combinethe favourable aspects of these two approaches. The base of our model is a newtype of variational autoencoder on demonstration trajectories that learnssemantic policy embeddings. We show that these embeddings can be learned on a 9DoF Jaco robot arm in reaching tasks, and then smoothly interpolated with aresulting smooth interpolation of reaching behavior. Leveraging these policyrepresentations, we develop a new version of GAIL that (1) is much more robustthan the purely-supervised controller, especially with few demonstrations, and(2) avoids mode collapse, capturing many diverse behaviors when GAIL on its owndoes not. We demonstrate our approach on learning diverse gaits fromdemonstration on a 2D biped and a 62 DoF 3D humanoid in the MuJoCo physicsenvironment."^^schema:Text ;
    schema:author "Greg Wayne"^^schema:Person,
        "Josh Merel"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Scott Reed"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:dateModified "2017-07-14T09:31:26Z"^^schema:DateTime ;
    schema:datePublished "2017-07-10T08:46:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Robust Imitation of Diverse Behaviors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.02747v2"^^schema:URL .

<1714> a schema:ScholarlyArticle ;
    schema:abstract "Person re-identification (re-ID) is a very active area of research incomputer vision, due to the role it plays in video surveillance. Currently,most methods only address the task of matching between colour images. However,in poorly-lit environments CCTV cameras switch to infrared imaging, hencedeveloping a system which can correctly perform matching between infrared andcolour images is a necessity. In this paper, we propose a part-featureextraction network to better focus on subtle, unique signatures on the personwhich are visible across both infrared and colour modalities. To train themodel we propose a novel variant of the domain adversarial feature-learningframework. Through extensive experimentation, we show that our approachoutperforms state-of-the-art methods."^^schema:Text ;
    schema:author "Krystian Mikolajczyk"^^schema:Person,
        "Nima Mohammadi Meshky"^^schema:Person,
        "Sara Iodice"^^schema:Person ;
    schema:dateModified "2020-03-09T15:17:15Z"^^schema:DateTime ;
    schema:datePublished "2020-03-09T15:17:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Domain Adversarial Training for Infrared-colour Person Re-Identification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.04191v1"^^schema:URL .

<1715> a schema:ScholarlyArticle ;
    schema:abstract "Sketching is a randomized dimensionality-reduction method that aims topreserve relevant information in large-scale datasets. Count sketch is a simplepopular sketch which uses a randomized hash function to achieve compression. Inthis paper, we propose a novel extension known as Higher-order Count Sketch(HCS). While count sketch uses a single hash function, HCS uses multiple(smaller) hash functions for sketching. HCS reshapes the input (vector) datainto a higher-order tensor and employs a tensor product of the random hashfunctions to compute the sketch. This results in an exponential saving (withrespect to the order of the tensor) in the memory requirements of the hashfunctions, under certain conditions on the input data. Furthermore, when theinput data itself has an underlying structure in the form of various tensorrepresentations such as the Tucker decomposition, we obtain significantadvantages. We derive efficient (approximate) computation of various tensoroperations such as tensor products and tensor contractions directly on thesketched data. Thus, HCS is the first sketch to fully exploit themulti-dimensional nature of higher-order tensors. We apply HCS to tensorizedneural networks where we replace fully connected layers with sketched tensoroperations. We achieve nearly state of the art accuracy with significantcompression on the image classification benchmark."^^schema:Text ;
    schema:author "Animashree Anandkumar"^^schema:Person,
        "Yang Shi"^^schema:Person ;
    schema:dateModified "2019-11-04T18:35:49Z"^^schema:DateTime ;
    schema:datePublished "2019-01-31T08:26:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Higher-order Count Sketch: Dimensionality Reduction That Retains  Efficient Tensor Operations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.11261v5"^^schema:URL .

<1716> a schema:ScholarlyArticle ;
    schema:abstract "Adaptive optimization methods, which perform local optimization with a metricconstructed from the history of iterates, are becoming increasingly popular fortraining deep neural networks. Examples include AdaGrad, RMSProp, and Adam. Weshow that for simple overparameterized problems, adaptive methods often finddrastically different solutions than gradient descent (GD) or stochasticgradient descent (SGD). We construct an illustrative binary classificationproblem where the data is linearly separable, GD and SGD achieve zero testerror, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close tohalf. We additionally study the empirical generalization capability of adaptivemethods on several state-of-the-art deep learning models. We observe that thesolutions found by adaptive methods generalize worse (often significantlyworse) than SGD, even when these solutions have better training performance.These results suggest that practitioners should reconsider the use of adaptivemethods to train neural networks."^^schema:Text ;
    schema:author "Ashia C. Wilson"^^schema:Person,
        "Benjamin Recht"^^schema:Person,
        "Mitchell Stern"^^schema:Person,
        "Nathan Srebro"^^schema:Person,
        "Rebecca Roelofs"^^schema:Person ;
    schema:dateModified "2018-05-22T00:10:53Z"^^schema:DateTime ;
    schema:datePublished "2017-05-23T14:11:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Marginal Value of Adaptive Gradient Methods in Machine Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.08292v2"^^schema:URL .

<1717> a schema:ScholarlyArticle ;
    schema:abstract "This paper addresses the task of segmenting class-agnostic objects insemi-supervised setting. Although previous detection based methods achieverelatively good performance, these approaches extract the best proposal by agreedy strategy, which may lose the local patch details outside the chosencandidate. In this paper, we propose a novel spatiotemporal graph neuralnetwork (STG-Net) to reconstruct more accurate masks for video objectsegmentation, which captures the local contexts by utilizing all proposals. Inthe spatial graph, we treat object proposals of a frame as nodes and representtheir correlations with an edge weight strategy for mask context aggregation.To capture temporal information from previous frames, we use a memory networkto refine the mask of current frame by retrieving historic masks in a temporalgraph. The joint use of both local patch details and temporal relationshipsallow us to better address the challenges such as object occlusion and missing.Without online learning and fine-tuning, our STG-Net achieves state-of-the-artperformance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, andYouTube-Objects), demonstrating the effectiveness of the proposed approach."^^schema:Text ;
    schema:author "Daizong Liu"^^schema:Person,
        "Pan Zhou"^^schema:Person,
        "Shuangjie Xu"^^schema:Person,
        "Wei Wei"^^schema:Person,
        "Xiao-Yang Liu"^^schema:Person,
        "Zichuan Xu"^^schema:Person ;
    schema:dateModified "2020-12-10T07:57:44Z"^^schema:DateTime ;
    schema:datePublished "2020-12-10T07:57:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video  Object Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.05499v1"^^schema:URL .

<1718> a schema:ScholarlyArticle ;
    schema:abstract "This paper explores a simple regularizer for reinforcement learning byproposing Generative Adversarial Self-Imitation Learning (GASIL), whichencourages the agent to imitate past good trajectories via generativeadversarial imitation learning framework. Instead of directly maximizingrewards, GASIL focuses on reproducing past good trajectories, which canpotentially make long-term credit assignment easier when rewards are sparse anddelayed. GASIL can be easily combined with any policy gradient objective byusing GASIL as a learned shaped reward function. Our experimental results showthat GASIL improves the performance of proximal policy optimization on 2D PointMass and MuJoCo environments with delayed reward and stochastic dynamics."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Junhyuk Oh"^^schema:Person,
        "Satinder Singh"^^schema:Person,
        "Yijie Guo"^^schema:Person ;
    schema:dateModified "2018-12-03T18:21:18Z"^^schema:DateTime ;
    schema:datePublished "2018-12-03T18:21:18Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Adversarial Self-Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.00950v1"^^schema:URL .

<1719> a schema:ScholarlyArticle ;
    schema:abstract "Graph Neural Networks (GNN) have been extensively used to extract meaningfulrepresentations from graph structured data and to perform predictive tasks suchas node classification and link prediction. In recent years, there has been alot of work incorporating edge features along with node features for predictiontasks. One of the main difficulties in using edge features is that they areoften handcrafted, hard to get, specific to a particular domain, and maycontain redundant information. In this work, we present a framework forcreating new edge features, applicable to any domain, via a combination ofself-supervised and unsupervised learning. In addition to this, we useForman-Ricci curvature as an additional edge feature to encapsulate the localgeometry of the graph. We then encode our edge features via a Set Transformerand combine them with node features extracted from popular GNN architecturesfor node classification in an end-to-end training scheme. We validate our workon three biological datasets comprising of single-cell RNA sequencing data ofneurological disease, \\textit{in vitro} SARS-CoV-2 infection, and humanCOVID-19 patients. We demonstrate that our method achieves better performanceon node classification tasks over baseline Graph Attention Network (GAT) andGraph Convolutional Network (GCN) models. Furthermore, given the attentionmechanism on edge and node features, we are able to interpret the cell typesand genes that determine the course and severity of COVID-19, contributing to agrowing list of potential disease biomarkers and therapeutic targets."^^schema:Text ;
    schema:author "Arijit Sehanobish"^^schema:Person,
        "David van Dijk"^^schema:Person,
        "Neal G. Ravindra"^^schema:Person ;
    schema:dateModified "2020-06-23T20:18:22Z"^^schema:DateTime ;
    schema:datePublished "2020-06-23T20:18:22Z"^^schema:DateTime ;
    schema:genre "I.2.4; J.3"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "q-bio.GN"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Self-supervised edge features for improved Graph Neural Network training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.04777v1"^^schema:URL .

<172> a schema:ScholarlyArticle ;
    schema:abstract "Recently, strong results have been demonstrated by Deep Recurrent NeuralNetworks on natural language transduction problems. In this paper we explorethe representational power of these models using synthetic grammars designed toexhibit phenomena similar to those found in real transduction problems such asmachine translation. These experiments lead us to propose new memory-basedrecurrent networks that implement continuously differentiable analogues oftraditional data structures such as Stacks, Queues, and DeQues. We show thatthese architectures exhibit superior generalisation performance to Deep RNNsand are often able to learn the underlying generating algorithms in ourtransduction experiments."^^schema:Text ;
    schema:author "Edward Grefenstette"^^schema:Person,
        "Karl Moritz Hermann"^^schema:Person,
        "Mustafa Suleyman"^^schema:Person,
        "Phil Blunsom"^^schema:Person ;
    schema:commentCount "217"^^schema:Integer ;
    schema:dateModified "2015-11-03T14:07:29Z"^^schema:DateTime ;
    schema:datePublished "2015-06-08T14:23:30Z"^^schema:DateTime ;
    schema:genre "68T05"^^schema:Text,
        "I.5.1; I.2.6; I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning to Transduce with Unbounded Memory"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02516v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6724672567965731171&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1720> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel end-to-end memory network for stance detection, whichjointly (i) predicts whether a document agrees, disagrees, discusses or isunrelated with respect to a given target claim, and also (ii) extracts snippetsof evidence for that prediction. The network operates at the paragraph leveland integrates convolutional and recurrent neural networks, as well as asimilarity matrix as part of the overall architecture. The experimentalevaluation on the Fake News Challenge dataset shows state-of-the-artperformance."^^schema:Text ;
    schema:author "Alessandro Moschitti"^^schema:Person,
        "James Glass"^^schema:Person,
        "Lluis Marquez"^^schema:Person,
        "Mitra Mohtarami"^^schema:Person,
        "Preslav Nakov"^^schema:Person,
        "Ramy Baly"^^schema:Person ;
    schema:dateModified "2018-04-20T12:48:10Z"^^schema:DateTime ;
    schema:datePublished "2018-04-20T12:48:10Z"^^schema:DateTime ;
    schema:genre "68T50"^^schema:Text,
        "I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Automatic Stance Detection Using End-to-End Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.07581v1"^^schema:URL .

<1721> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning is an approach for generating intelligent behavior whenthe cost function is unknown or difficult to specify. Building upon work ininverse reinforcement learning (IRL), Generative Adversarial Imitation Learning(GAIL) aims to provide effective imitation even for problems with large orcontinuous state and action spaces. Driver modeling is one example of a problemwhere the state and action spaces are continuous. Human driving behavior ischaracterized by non-linearity and stochasticity, and the underlying costfunction is unknown. As a result, learning from human driving demonstrations isa promising approach for generating human-like driving behavior. This articledescribes the use of GAIL for learning-based driver modeling. Because drivermodeling is inherently a multi-agent problem, where the interaction betweenagents needs to be modeled, this paper describes a parameter-sharing extensionof GAIL called PS-GAIL to tackle multi-agent driver modeling. In addition, GAILis domain agnostic, making it difficult to encode specific knowledge relevantto driving in the learning process. This paper describes Reward AugmentedImitation Learning (RAIL), which modifies the reward signal to providedomain-specific knowledge to the agent. Finally, human demonstrations aredependent upon latent factors that may not be captured by GAIL. This paperdescribes Burn-InfoGAIL, which allows for disentanglement of latent variabilityin demonstrations. Imitation learning experiments are performed using NGSIM, areal-world highway driving dataset. Experiments show that these modificationsto GAIL can successfully model highway driving behavior, accurately replicatinghuman demonstrations and generating realistic, emergent behavior in the trafficflow arising from the interaction between driving agents."^^schema:Text ;
    schema:author "Alex Kuefler"^^schema:Person,
        "Blake Wulfe"^^schema:Person,
        "Derek Phillips"^^schema:Person,
        "Jeremy Morton"^^schema:Person,
        "Mykel Kochenderfer"^^schema:Person,
        "Ransalu Senanayake"^^schema:Person,
        "Raunak Bhattacharyya"^^schema:Person ;
    schema:dateModified "2020-06-10T05:47:39Z"^^schema:DateTime ;
    schema:datePublished "2020-06-10T05:47:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Modeling Human Driving Behavior through Generative Adversarial Imitation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.06412v1"^^schema:URL .

<1722> a schema:ScholarlyArticle ;
    schema:abstract "Fingerprint recognition is often a game-changing step in establishingevidence against criminals. However, we are increasingly finding that criminalsdeliberately alter their fingerprints in a variety of ways to make it difficultfor technicians and automatic sensors to recognize their fingerprints, makingit tedious for investigators to establish strong evidence against them in aforensic procedure. In this sense, deep learning comes out as a prime candidateto assist in the recognition of damaged fingerprints. In particular,convolution algorithms. In this paper, we focus on the recognition of damagedfingerprints by Convolutional Long Short-Term Memory networks. We present thearchitecture of our model and demonstrate its performance which exceeds 95%accuracy, 99% precision, and approaches 95% recall and 99% AUC."^^schema:Text ;
    schema:author "Jaouhar Fattahi"^^schema:Person,
        "Mohamed Mejri"^^schema:Person ;
    schema:dateModified "2020-12-30T04:51:58Z"^^schema:DateTime ;
    schema:datePublished "2020-12-30T04:51:58Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Damaged Fingerprint Recognition by Convolutional Long Short-Term Memory  Networks for Forensic Purposes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.15041v1"^^schema:URL .

<1723> a schema:ScholarlyArticle ;
    schema:abstract "Networks and their higher order generalizations, such as hypernetworks ormultiplex networks are ever more popular models in the applied sciences.However, methods developed for the study of their structural properties golittle beyond the common name and the heavy reliance of combinatorial tools. Weshow that, in fact, a geometric unifying approach is possible, by viewing themas polyhedral complexes endowed with a simple, yet, the powerful notion ofcurvature - the Forman Ricci curvature. We systematically explore some aspectsrelated to the modeling of weighted and directed hypernetworks and presentexpressive and natural choices involved in their definitions. A benefit of thisapproach is a simple method of structure-preserving embedding of hypernetworksin Euclidean N-space. Furthermore, we introduce a simple and efficient mannerof computing the well established Ollivier-Ricci curvature of a hypernetwork."^^schema:Text ;
    schema:author "Emil Saucan"^^schema:Person,
        "Melanie Weber"^^schema:Person ;
    schema:dateModified "2018-10-17T19:42:22Z"^^schema:DateTime ;
    schema:datePublished "2018-10-17T19:42:22Z"^^schema:DateTime ;
    schema:genre "05C82, 05C75, 05C21, 05C10"^^schema:Text,
        "cs.DM"^^schema:Text,
        "cs.SI"^^schema:Text,
        "stat.AP"^^schema:Text ;
    schema:headline "Forman's Ricci curvature - From networks to hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.07749v1"^^schema:URL .

<1724> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing (KT) has recently been an active research area ofcomputational pedagogy. The task is to model students mastery level ofknowledge based on their responses to the questions in the past, as well aspredict the probabilities that they correctly answer subsequent questions inthe future. A good KT model can not only make students timely aware of theirknowledge states, but also help teachers develop better personalized teachingplans for students. KT tasks were historically solved using statisticalmodeling methods such as Bayesian inference and factor analysis, but recentadvances in deep learning have led to the successive proposals that leveragedeep neural networks, including long short-term memory networks,memory-augmented networks and self-attention networks. While those deep modelsdemonstrate superior performance over the traditional approaches, they allneglect more or less the impact on knowledge states of the most recentquestions answered by students. The forgetting curve theory states that humanmemory retention declines over time, therefore knowledge states should bemostly affected by the recent questions. Based on this observation, we proposea Convolutional Knowledge Tracing (CKT) model in this paper. In addition tomodeling the long-term effect of the entire question-answer sequence, CKT alsostrengthens the short-term effect of recent questions using 3D convolutions,thereby effectively modeling the forgetting curve in the learning process.Extensive experiments show that CKT achieves the new state-of-the-art inpredicting students performance compared with existing models. Using CKT, wegain 1.55 and 2.03 improvements in terms of AUC over DKT and DKVMNrespectively, on the ASSISTments2009 dataset. And on the ASSISTments2015dataset, the corresponding improvements are 1.01 and 1.96 respectively."^^schema:Text ;
    schema:author "Jingyang Hou"^^schema:Person,
        "Mengxia Zhu"^^schema:Person,
        "Shanghui Yang"^^schema:Person,
        "Xuesong Lu"^^schema:Person ;
    schema:dateModified "2020-07-26T15:24:51Z"^^schema:DateTime ;
    schema:datePublished "2020-07-26T15:24:51Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Knowledge Tracing with Convolutions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01169v1"^^schema:URL .

<1725> a schema:ScholarlyArticle ;
    schema:abstract "Crowd counting from unconstrained scene images is a crucial task in manyreal-world applications like urban surveillance and management, but it isgreatly challenged by the camera's perspective that causes huge appearancevariations in people's scales and rotations. Conventional methods address suchchallenges by resorting to fixed multi-scale architectures that are oftenunable to cover the largely varied scales while ignoring the rotationvariations. In this paper, we propose a unified neural network framework, namedDeep Recurrent Spatial-Aware Network, which adaptively addresses the two issuesin a learnable spatial transform module with a region-wise refinement process.Specifically, our framework incorporates a Recurrent Spatial-Aware Refinement(RSAR) module iteratively conducting two components: i) a Spatial TransformerNetwork that dynamically locates an attentional region from the crowd densitymap and transforms it to the suitable scale and rotation for optimal crowdestimation; ii) a Local Refinement Network that refines the density map of theattended region with residual learning. Extensive experiments on fourchallenging benchmarks show the effectiveness of our approach. Specifically,comparing with the existing best-performing methods, we achieve an improvementof 12% on the largest dataset WorldExpo'10 and 22.8% on the most challengingdataset UCF_CC_50."^^schema:Text ;
    schema:author "Guanbin Li"^^schema:Person,
        "Hongjun Wang"^^schema:Person,
        "Liang Lin"^^schema:Person,
        "Lingbo Liu"^^schema:Person,
        "Wanli Ouyang"^^schema:Person ;
    schema:dateModified "2018-07-02T11:21:27Z"^^schema:DateTime ;
    schema:datePublished "2018-07-02T11:21:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Crowd Counting using Deep Recurrent Spatial-Aware Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.00601v1"^^schema:URL .

<1726> a schema:ScholarlyArticle ;
    schema:abstract "The current Air Traffic Management (ATM) system worldwide has reached itslimits in terms of predictability, efficiency and cost effectiveness. Differentinitiatives worldwide propose trajectory-oriented transformations that requirehigh fidelity aircraft trajectory planning and prediction capabilities,supporting the trajectory life cycle at all stages efficiently. Recentlyproposed data-driven trajectory prediction approaches provide promisingresults. In this paper we approach the data-driven trajectory predictionproblem as an imitation learning task, where we aim to imitate experts\"shaping\" the trajectory. Towards this goal we present a comprehensiveframework comprising the Generative Adversarial Imitation Learning state of theart method, in a pipeline with trajectory clustering and classificationmethods. This approach, compared to other approaches, can provide accuratepredictions for the whole trajectory (i.e. with a prediction horizon untilreaching the destination) both at the pre-tactical (i.e. starting at thedeparture airport at a specific time instant) and at the tactical (i.e. fromany state while flying) stages, compared to state of the art approaches."^^schema:Text ;
    schema:author "Alevizos Bastas"^^schema:Person,
        "George A. Vouros"^^schema:Person,
        "Theocharis Kravaris"^^schema:Person ;
    schema:dateModified "2020-05-16T11:53:19Z"^^schema:DateTime ;
    schema:datePublished "2020-05-16T11:53:19Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Data Driven Aircraft Trajectory Prediction with Deep Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.07960v1"^^schema:URL .

<1727> a schema:ScholarlyArticle ;
    schema:abstract "The massive amount of misinformation spreading on the Internet on a dailybasis has enormous negative impacts on societies. Therefore, we need automatedsystems helping fact-checkers in the combat against misinformation. In thispaper, we propose a model prioritizing the claims based on theircheck-worthiness. We use BERT model with additional features includingdomain-specific controversial topics, word embeddings, and others. In ourexperiments, we show that our proposed model outperforms all state-of-the-artmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. Wealso conduct a qualitative analysis to shed light-detecting check-worthyclaims. We suggest requesting rationales behind judgments are needed tounderstand subjective nature of the task and problematic labels."^^schema:Text ;
    schema:author "Busra Guvenen"^^schema:Person,
        "Mucahid Kutlu"^^schema:Person,
        "Yavuz Selim Kartal"^^schema:Person ;
    schema:dateModified "2020-04-17T10:55:07Z"^^schema:DateTime ;
    schema:datePublished "2020-04-17T10:55:07Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on  Check-Worthiness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.08166v1"^^schema:URL .

<1728> a schema:ScholarlyArticle ;
    schema:abstract "We study the performance of Long Short-Term Memory networks for keystrokebiometric authentication at large scale in free-text scenarios. For this weintroduce TypeNet, a Recurrent Neural Network (RNN) trained with a moderatenumber of keystrokes per identity. We evaluate different learning approachesdepending on the loss function (softmax, contrastive, and triplet loss), numberof gallery samples, length of the keystroke sequences, and device type(physical vs touchscreen keyboard). With 5 gallery sequences and test sequencesof length 50, TypeNet achieves state-of-the-art keystroke biometricauthentication performance with an Equal Error Rate of 2.2% and 9.2% forphysical and touchscreen keyboards, respectively, significantly outperformingprevious approaches. Our experiments demonstrate a moderate increase in errorwith up to 100,000 subjects, demonstrating the potential of TypeNet to operateat an Internet scale. We utilize two Aalto University keystroke databases, onecaptured on physical keyboards and the second on mobile devices (touchscreenkeyboards). To the best of our knowledge, both databases are the largestexisting free-text keystroke databases available for research with more than136 million keystrokes from 168,000 subjects in physical keyboards, and 60,000subjects with more than 63 million keystrokes acquired on mobile touchscreens."^^schema:Text ;
    schema:author "Alejandro Acien"^^schema:Person,
        "Aythami Morales"^^schema:Person,
        "John V. Monaco"^^schema:Person,
        "Julian Fierrez"^^schema:Person,
        "Ruben Vera-Rodriguez"^^schema:Person ;
    schema:dateModified "2021-01-14T12:49:09Z"^^schema:DateTime ;
    schema:datePublished "2021-01-14T12:49:09Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "TypeNet: Deep Learning Keystroke Biometrics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.05570v1"^^schema:URL .

<1729> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, fairness has become an important topic in the machinelearning research community. In particular, counterfactual fairness aims atbuilding prediction models which ensure fairness at the most individual level.Rather than globally considering equity over the entire population, the idea isto imagine what any individual would look like with a variation of a givenattribute of interest, such as a different gender or race for instance.Existing approaches rely on Variational Auto-encoding of individuals, usingMaximum Mean Discrepancy (MMD) penalization to limit the statistical dependenceof inferred representations with their corresponding sensitive attributes. Thisenables the simulation of counterfactual samples used for training the targetfair model, the goal being to produce similar outcomes for every alternateversion of any individual. In this work, we propose to rely on an adversarialneural learning approach, that enables more powerful inference than with MMDpenalties, and is particularly better fitted for the continuous setting, wherevalues of sensitive attributes cannot be exhaustively enumerated. Experimentsshow significant improvements in term of counterfactual fairness for both thediscrete and the continuous settings."^^schema:Text ;
    schema:author "Marcin Detyniecki"^^schema:Person,
        "Sylvain Lamprier"^^schema:Person,
        "Vincent Grari"^^schema:Person ;
    schema:dateModified "2020-08-30T09:06:03Z"^^schema:DateTime ;
    schema:datePublished "2020-08-30T09:06:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Learning for Counterfactual Fairness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.13122v1"^^schema:URL .

<173> a schema:ScholarlyArticle ;
    schema:abstract "In recent years there have been many successes of using deep representationsin reinforcement learning. Still, many of these applications use conventionalarchitectures, such as convolutional networks, LSTMs, or auto-encoders. In thispaper, we present a new neural network architecture for model-freereinforcement learning. Our dueling network represents two separate estimators:one for the state value function and one for the state-dependent actionadvantage function. The main benefit of this factoring is to generalizelearning across actions without imposing any change to the underlyingreinforcement learning algorithm. Our results show that this architecture leadsto better policy evaluation in the presence of many similar-valued actions.Moreover, the dueling architecture enables our RL agent to outperform thestate-of-the-art on the Atari 2600 domain."^^schema:Text ;
    schema:author "Hado van Hasselt"^^schema:Person,
        "Marc Lanctot"^^schema:Person,
        "Matteo Hessel"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Tom Schaul"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:commentCount "1169"^^schema:Integer ;
    schema:dateModified "2016-04-05T09:03:06Z"^^schema:DateTime ;
    schema:datePublished "2015-11-20T13:07:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Dueling Network Architectures for Deep Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 1995-2003"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06581v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12521843669488478464&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1730> a schema:ScholarlyArticle ;
    schema:abstract "Bidirectional mapping-based generative models have achieved remarkableperformance for the generalized zero-shot learning (GZSL) recognition bylearning to construct visual features from class semantics and reconstructclass semantics back from generated visual features. The performance of thesemodels relies on the quality of synthesized features. This depends on theability of the model to capture the underlying seen data distribution byrelating semantic-visual spaces, learning discriminative information, andre-purposing the learned distribution to recognize unseen data. This meanslearning the seen-unseen domains joint distribution is crucial for GZSL tasks.However, existing models only learn the underlying distribution of the seendomain as unseen data is inaccessible. In this work, we propose to utilize theavailable unseen class semantics along with seen class semantics and learndual-domain joint distribution through a strong visual-semantic coupling.Therefore, we propose a bidirectional mapping coupled generative adversarialnetwork (BMCoGAN) by extending the coupled generative adversarial network(CoGAN) into a dual-domain learning bidirectional mapping model. We furtherintegrate a Wasserstein generative adversarial optimization to supervise thejoint distribution learning. For retaining distinctive information in thesynthesized visual space and reducing bias towards seen classes, we design anoptimization, which pushes synthesized seen features towards real seen featuresand pulls synthesized unseen features away from real seen features. We evaluateBMCoGAN on several benchmark datasets against contemporary methods and show itssuperior performance. Also, we present ablative analysis to demonstrate theimportance of different components in BMCoGAN."^^schema:Text ;
    schema:author "Ferdous Sohel"^^schema:Person,
        "Guojun Lu"^^schema:Person,
        "Manzur Murshed"^^schema:Person,
        "Shyh Wei Teng"^^schema:Person,
        "Tasfia Shermin"^^schema:Person ;
    schema:dateModified "2020-12-30T06:11:29Z"^^schema:DateTime ;
    schema:datePublished "2020-12-30T06:11:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Bidirectional Mapping Coupled GAN for Generalized Zero-Shot Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.15054v1"^^schema:URL .

<1731> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel learning-based framework for image reconstructionparticularly designed for training without ground truth data, which has threemajor building blocks: energy-based learning, a patch-based Wasserstein lossfunctional, and shared prior learning. In energy-based learning, the parametersof an energy functional composed of a learned data fidelity term and adata-driven regularizer are computed in a mean-field optimal control problem.In the absence of ground truth data, we change the loss functional to apatch-based Wasserstein functional, in which local statistics of the outputimages are compared to uncorrupted reference patches. Finally, in shared priorlearning, both aforementioned optimal control problems are optimizedsimultaneously with shared learned parameters of the regularizer to furtherenhance unsupervised image reconstruction. We derive several timediscretization schemes of the gradient flow and verify their consistency interms of Mosco convergence. In numerous numerical experiments, we demonstratethat the proposed method generates state-of-the-art results for various imagereconstruction applications--even if no ground truth images are available fortraining."^^schema:Text ;
    schema:author "Alexander Effland"^^schema:Person,
        "Erich Kobler"^^schema:Person,
        "Thomas Pinetz"^^schema:Person,
        "Thomas Pock"^^schema:Person ;
    schema:dateModified "2020-11-13T08:54:13Z"^^schema:DateTime ;
    schema:datePublished "2020-11-12T17:56:05Z"^^schema:DateTime ;
    schema:genre "49J15, 65C30, 65K10, 65L09, 68U10"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NA"^^schema:Text,
        "eess.IV"^^schema:Text,
        "math.NA"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Shared Prior Learning of Energy-Based Models for Image Reconstruction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.06539v2"^^schema:URL .

<1732> a schema:ScholarlyArticle ;
    schema:abstract "Our goal is for AI systems to correctly identify and act according to theirhuman user's objectives. Cooperative Inverse Reinforcement Learning (CIRL)formalizes this value alignment problem as a two-player game between a humanand robot, in which only the human knows the parameters of the reward function:the robot needs to learn them as the interaction unfolds. Previous work showedthat CIRL can be solved as a POMDP, but with an action space size exponentialin the size of the reward parameter space. In this work, we exploit a specificproperty of CIRL---the human is a full information agent---to derive anoptimality-preserving modification to the standard Bellman update; this reducesthe complexity of the problem by an exponential factor and allows us to relaxCIRL's assumption of human rationality. We apply this update to a variety ofPOMDP solvers and find that it enables us to scale CIRL to non-trivialproblems, with larger reward parameter spaces, and larger action spaces forboth robot and human. In solutions to these larger problems, the human exhibitspedagogic (teaching) behavior, while the robot interprets it as such andattains higher value for the human."^^schema:Text ;
    schema:author "Anca D. Dragan"^^schema:Person,
        "Dhruv Malik"^^schema:Person,
        "Dylan Hadfield-Menell"^^schema:Person,
        "Jaime F. Fisac"^^schema:Person,
        "Malayandi Palaniappan"^^schema:Person,
        "Stuart Russell"^^schema:Person ;
    schema:dateModified "2018-06-11T06:06:43Z"^^schema:DateTime ;
    schema:datePublished "2018-06-11T06:06:43Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "An Efficient, Generalized Bellman Update For Cooperative Inverse  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.03820v1"^^schema:URL .

<1733> a schema:ScholarlyArticle ;
    schema:abstract "Traditional deep neural nets (NNs) have shown the state-of-the-artperformance in the task of classification in various applications. However, NNshave not considered any types of uncertainty associated with the classprobabilities to minimize risk due to misclassification under uncertainty inreal life. Unlike Bayesian neural nets indirectly infering uncertainty throughweight uncertainties, evidential neural networks (ENNs) have been recentlyproposed to support explicit modeling of the uncertainty of classprobabilities. It treats predictions of an NN as subjective opinions and learnsthe function by collecting the evidence leading to these opinions by adeterministic NN from data. However, an ENN is trained as a black box withoutexplicitly considering different types of inherent data uncertainty, such asvacuity (uncertainty due to a lack of evidence) or dissonance (uncertainty dueto conflicting evidence). This paper presents a new approach, called a {\\emregularized ENN}, that learns an ENN based on regularizations related todifferent characteristics of inherent data uncertainty. Via the experimentswith both synthetic and real-world datasets, we demonstrate that the proposedregularized ENN can better learn of an ENN modeling different types ofuncertainty in the class probabilities for classification tasks."^^schema:Text ;
    schema:author "Feng Chen"^^schema:Person,
        "Jin-Hee Cho"^^schema:Person,
        "Lance Kaplan"^^schema:Person,
        "Xujiang Zhao"^^schema:Person,
        "Yuzhe Ou"^^schema:Person ;
    schema:dateModified "2019-10-15T15:26:20Z"^^schema:DateTime ;
    schema:datePublished "2019-10-15T15:26:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Quantifying Classification Uncertainty using Regularized Evidential  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.06864v1"^^schema:URL .

<1734> a schema:ScholarlyArticle ;
    schema:abstract "We extend trust region policy optimization (TRPO) to multi-agentreinforcement learning (MARL) problems. We show that the policy update of TRPOcan be transformed into a distributed consensus optimization problem formulti-agent cases. By making a series of approximations to the consensusoptimization model, we propose a decentralized MARL algorithm, which we callmulti-agent TRPO (MATRPO). This algorithm can optimize distributed policiesbased on local observations and private rewards. The agents do not need to knowobservations, rewards, policies or value/action-value functions of otheragents. The agents only share a likelihood ratio with their neighbors duringthe training process. The algorithm is fully decentralized andprivacy-preserving. Our experiments on two cooperative games demonstrate itsrobust performance on complicated MARL tasks."^^schema:Text ;
    schema:author "Haibo He"^^schema:Person,
        "Hepeng Li"^^schema:Person ;
    schema:dateModified "2020-10-18T14:41:40Z"^^schema:DateTime ;
    schema:datePublished "2020-10-15T17:49:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Multi-Agent Trust Region Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07916v2"^^schema:URL .

<1735> a schema:ScholarlyArticle ;
    schema:abstract "The pre-trained language models have achieved great successes in variousnatural language understanding (NLU) tasks due to its capacity to capture thedeep contextualized information in text by pre-training on large-scale corpora.In this technical report, we present our practice of pre-training languagemodels named NEZHA (NEural contextualiZed representation for CHinese lAnguageunderstanding) on Chinese corpora and finetuning for the Chinese NLU tasks. Thecurrent version of NEZHA is based on BERT with a collection of provenimprovements, which include Functional Relative Positional Encoding as aneffective positional encoding scheme, Whole Word Masking strategy, MixedPrecision Training and the LAMB Optimizer in training the models. Theexperimental results show that NEZHA achieves the state-of-the-art performanceswhen finetuned on several representative Chinese tasks, including named entityrecognition (People's Daily NER), sentence matching (LCQMC), Chinese sentimentclassification (ChnSenti) and natural language inference (XNLI)."^^schema:Text ;
    schema:author "Jiashu Lin"^^schema:Person,
        "Junqiu Wei"^^schema:Person,
        "Qun Liu"^^schema:Person,
        "Wenyong Huang"^^schema:Person,
        "Xiao Chen"^^schema:Person,
        "Xiaoguang Li"^^schema:Person,
        "Xiaozhe Ren"^^schema:Person,
        "Xin Jiang"^^schema:Person,
        "Yasheng Wang"^^schema:Person,
        "Yi Liao"^^schema:Person ;
    schema:dateModified "2019-09-05T08:52:55Z"^^schema:DateTime ;
    schema:datePublished "2019-08-31T12:08:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "NEZHA: Neural Contextualized Representation for Chinese Language  Understanding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.00204v2"^^schema:URL .

<1736> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial examples contain carefully crafted perturbations that can fooldeep neural networks (DNNs) into making wrong predictions. Enhancing theadversarial robustness of DNNs has gained considerable interest in recentyears. Although image transformation-based defenses were widely considered atan earlier time, most of them have been defeated by adaptive attacks. In thispaper, we propose a new image transformation defense based on error diffusionhalftoning, and combine it with adversarial training to defend againstadversarial examples. Error diffusion halftoning projects an image into a 1-bitspace and diffuses quantization error to neighboring pixels. This process canremove adversarial perturbations from a given image while maintainingacceptable image quality in the meantime in favor of recognition. Experimentalresults demonstrate that the proposed method is able to improve adversarialrobustness even under advanced adaptive attacks, while most of the other imagetransformation-based defenses do not. We show that a proper imagetransformation can still be an effective defense approach."^^schema:Text ;
    schema:author "Shao-Yuan Lo"^^schema:Person,
        "Vishal M. Patel"^^schema:Person ;
    schema:dateModified "2021-01-23T07:55:02Z"^^schema:DateTime ;
    schema:datePublished "2021-01-23T07:55:02Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Error Diffusion Halftoning Against Adversarial Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.09451v1"^^schema:URL .

<1737> a schema:ScholarlyArticle ;
    schema:abstract "Neural language models (NLMs) exist in an accuracy-efficiency tradeoff spacewhere better perplexity typically comes at the cost of greater computationcomplexity. In a software keyboard application on mobile devices, thistranslates into higher power consumption and shorter battery life. This paperrepresents the first attempt, to our knowledge, in exploringaccuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neuralnetworks (QRNNs), we apply pruning techniques to provide a \"knob\" to selectdifferent operating points. In addition, we propose a simple technique torecover some perplexity using a negligible amount of memory. Our empiricalevaluations consider both perplexity as well as energy consumption on aRaspberry Pi, where we demonstrate which methods provide the bestperplexity-power consumption operating point. At one operating point, one ofthe techniques is able to provide energy savings of 40% over the state of theart with only a 17% relative increase in perplexity."^^schema:Text ;
    schema:author "Jimmy Lin"^^schema:Person,
        "Raphael Tang"^^schema:Person ;
    schema:dateModified "2018-09-27T00:41:16Z"^^schema:DateTime ;
    schema:datePublished "2018-09-27T00:41:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Adaptive Pruning of Neural Language Models for Mobile Devices"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10282v1"^^schema:URL .

<1738> a schema:ScholarlyArticle ;
    schema:abstract "We consider a fully cooperative multi-agent system where agents cooperate tomaximize a system's utility in a partial-observable environment. We proposethat multi-agent systems must have the ability to (1) communicate andunderstand the inter-plays between agents and (2) correctly distribute rewardsbased on an individual agent's contribution. In contrast, most work in thissetting considers only one of the above abilities. In this study, we develop anarchitecture that allows for communication among agents and tailors thesystem's reward for each individual agent. Our architecture represents agentcommunication through graph convolution and applies an existing creditassignment structure, counterfactual multi-agent policy gradient (COMA), toassist agents to learn communication by back-propagation. The flexibility ofthe graph structure enables our method to be applicable to a variety ofmulti-agent systems, e.g. dynamic systems that consist of varying numbers ofagents and static systems with a fixed number of agents. We evaluate our methodon a range of tasks, demonstrating the advantage of marrying communication withcredit assignment. In the experiments, our proposed method yields betterperformance than the state-of-art methods, including COMA. Moreover, we showthat the communication strategies offers us insights and interpretability ofthe system's cooperative policies."^^schema:Text ;
    schema:author "Jianyu Su"^^schema:Person,
        "Peter A. Beling"^^schema:Person,
        "Stephen Adams"^^schema:Person ;
    schema:dateModified "2020-12-29T00:57:59Z"^^schema:DateTime ;
    schema:datePublished "2020-04-01T14:36:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Counterfactual Multi-Agent Reinforcement Learning with Graph Convolution  Communication"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.00470v2"^^schema:URL .

<1739> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a method to generate synthetic protein sequences which arepredicted to be resistant to certain antibiotics. We did this using 6,023 genesthat were predicted to be resistant to antibiotics in the intestinal region ofthe human gut and were fed as input to a Wasserstein generative adversarialnetwork (W-GAN) model a variant to the original generative adversarial modelwhich has been known to perform efficiently when it comes to mimicking thedistribution of the real data in order to generate new data which is similar instyle to the original data which was fed as the training data"^^schema:Text ;
    schema:author "Arpit Joshi"^^schema:Person,
        "Prabal Chhibbar"^^schema:Person ;
    schema:dateModified "2019-04-28T11:34:03Z"^^schema:DateTime ;
    schema:datePublished "2019-04-28T11:34:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.GN"^^schema:Text ;
    schema:headline "Generating protein sequences from antibiotic resistance genes data using  Generative Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.13240v1"^^schema:URL .

<174> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a conditional generative model for learning to disentangle thehidden factors of variation within a set of labeled observations, and separatethem into complementary codes. One code summarizes the specified factors ofvariation associated with the labels. The other summarizes the remainingunspecified variability. During training, the only available source ofsupervision comes from our ability to distinguish among different observationsbelonging to the same class. Examples of such observations include images of aset of labeled objects captured at different viewpoints, or recordings of setof speakers dictating multiple phrases. In both instances, the intra-classdiversity is the source of the unspecified factors of variation: each object isobserved at multiple viewpoints, and each speaker dictates multiple phrases.Learning to disentangle the specified factors from the unspecified ones becomeseasier when strong supervision is possible. Suppose that during training, wehave access to pairs of images, where each pair shows two different objectscaptured from the same viewpoint. This source of alignment allows us to solveour task using existing methods. However, labels for the unspecified factorsare usually unavailable in realistic scenarios where data acquisition is notstrictly controlled. We address the problem of disentanglement in this moregeneral setting by combining deep convolutional autoencoders with a form ofadversarial training. Both factors of variation are implicitly captured in theorganization of the learned embedding space, and can be used for solvingsingle-image analogies. Experimental results on synthetic and real datasetsshow that the proposed method is capable of generalizing to unseen classes andintra-class variabilities."^^schema:Text ;
    schema:author "Aditya Ramesh"^^schema:Person,
        "Junbo Zhao"^^schema:Person,
        "Michael Mathieu"^^schema:Person,
        "Pablo Sprechmann"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2016-11-10T16:24:16Z"^^schema:DateTime ;
    schema:datePublished "2016-11-10T16:24:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Disentangling factors of variation in deep representations using  adversarial training"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.03383v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17487472987754617699&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1740> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in combining deep learning and Reinforcement Learning haveshown a promising path for designing new control agents that can learn optimalpolicies for challenging control tasks. These new methods address the mainlimitations of conventional Reinforcement Learning methods such as customizedfeature engineering and small action/state space dimension requirements. Inthis paper, we leverage one of the state-of-the-art Reinforcement Learningmethods, known as Trust Region Policy Optimization, to tackle intersectionmanagement for autonomous vehicles. We show that using this method, we canperform fine-grained acceleration control of autonomous vehicles in a gridstreet plan to achieve a global design objective."^^schema:Text ;
    schema:author "Hamid Mirzaei"^^schema:Person,
        "Tony Givargis"^^schema:Person ;
    schema:dateModified "2017-05-30T02:04:29Z"^^schema:DateTime ;
    schema:datePublished "2017-05-30T02:04:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "Fine-grained acceleration control for autonomous intersection management  using deep reinforcement learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.10432v1"^^schema:URL .

<1741> a schema:ScholarlyArticle ;
    schema:abstract "The learning of domain-invariant representations in the context of domainadaptation with neural networks is considered. We propose a new regularizationmethod that minimizes the discrepancy between domain-specific latent featurerepresentations directly in the hidden activation space. Although some standarddistribution matching approaches exist that can be interpreted as the matchingof weighted sums of moments, e.g. Maximum Mean Discrepancy (MMD), an explicitorder-wise matching of higher order moments has not been considered before. Wepropose to match the higher order central moments of probability distributionsby means of order-wise moment differences. Our model does not requirecomputationally expensive distance and kernel matrix computations. We utilizethe equivalent representation of probability distributions by moment sequencesto define a new distance function, called Central Moment Discrepancy (CMD). Weprove that CMD is a metric on the set of probability distributions on a compactinterval. We further prove that convergence of probability distributions oncompact intervals w.r.t. the new metric implies convergence in distribution ofthe respective random variables. We test our approach on two differentbenchmark data sets for object recognition (Office) and sentiment analysis ofproduct reviews (Amazon reviews). CMD achieves a new state-of-the-artperformance on most domain adaptation tasks of Office and outperforms networkstrained with MMD, Variational Fair Autoencoders and Domain Adversarial NeuralNetworks on Amazon reviews. In addition, a post-hoc parameter sensitivityanalysis shows that the new approach is stable w.r.t. parameter changes in acertain interval. The source code of the experiments is publicly available."^^schema:Text ;
    schema:author "Edwin Lughofer"^^schema:Person,
        "Susanne Saminger-Platz"^^schema:Person,
        "Thomas Grubinger"^^schema:Person,
        "Thomas Natschläger"^^schema:Person,
        "Werner Zellinger"^^schema:Person ;
    schema:dateModified "2019-05-02T07:23:00Z"^^schema:DateTime ;
    schema:datePublished "2017-02-28T15:04:54Z"^^schema:DateTime ;
    schema:genre "68T05"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Central Moment Discrepancy (CMD) for Domain-Invariant Representation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.08811v3"^^schema:URL .

<1742> a schema:ScholarlyArticle ;
    schema:abstract "In compressed sensing, a small number of linear measurements can be used toreconstruct an unknown signal. Existing approaches leverage assumptions on thestructure of these signals, such as sparsity or the availability of agenerative model. A domain-specific generative model can provide a strongerprior and thus allow for recovery with far fewer measurements. However, unlikesparsity-based approaches, existing methods based on generative modelsguarantee exact recovery only over their support, which is typically only asmall subset of the space on which the signals are defined. We proposeSparse-Gen, a framework that allows for sparse deviations from the support set,thereby achieving the best of both worlds by using a domain specific prior andallowing reconstruction over the full space of signals. Theoretically, ourframework provides a new class of signals that can be acquired using compressedsensing, reducing classic sparse vector recovery to a special case and avoidingthe restrictive support due to a generative model prior. Empirically, weobserve consistent improvements in reconstruction accuracy over competingapproaches, especially in the more practical setting of transfer compressedsensing where a generative model for a data-rich, source domain aids sensing ona data-scarce, target domain."^^schema:Text ;
    schema:author "Aditya Grover"^^schema:Person,
        "Manik Dhar"^^schema:Person,
        "Stefano Ermon"^^schema:Person ;
    schema:dateModified "2018-07-31T21:30:28Z"^^schema:DateTime ;
    schema:datePublished "2018-07-04T03:57:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modeling Sparse Deviations for Compressed Sensing using Generative  Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.01442v2"^^schema:URL .

<1743> a schema:ScholarlyArticle ;
    schema:abstract "The option-critic architecture (Bacon, Harb, and Precup 2017) and severalvariants have successfully demonstrated the use of the options frameworkproposed by Sutton et al (Sutton, Precup, and Singh1999) to scale learning andplanning in hierarchical tasks. Although most of these frameworks use entropyas a regularizer to improve exploration, they do not maximize entropy alongwith returns at every time step. (Haarnoja et al., 2018d) recently introducedan off-policy actor critic algorithm in theSoft Actor Critic paper thatmaximize returns while maximizing entropy in a constrained manner thus enablinglearning of robust options in continuous and discrete action spaces In thispaper we adopt the architecture of soft-actor critic to investigate the effectof maximizing entropy of each options and inter-option policy in optionsframework. We derive the soft options improvement theorem and propose a novelsoft-options framework to incorporate maximization of entropy of actions andoptions in a constrained manner. Our experiments show that the modifiedoptions-critic framework generates robust policies which allows fast recoverywhen environment is subjected to perturbations and outperforms vanillaoptions-critic framework in most hierarchical tasks"^^schema:Text ;
    schema:author "Elita Lobo"^^schema:Person,
        "Scott Jordan"^^schema:Person ;
    schema:dateModified "2019-06-11T21:48:19Z"^^schema:DateTime ;
    schema:datePublished "2019-05-23T21:27:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Soft Options Critic"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11222v2"^^schema:URL .

<1744> a schema:ScholarlyArticle ;
    schema:abstract "A fundamental question in deep learning concerns the role played byindividual layers in a deep neural network (DNN) and the transferableproperties of the data representations which they learn. To the extent thatlayers have clear roles, one should be able to optimize them separately usinglayer-wise loss functions. Such loss functions would describe what is the setof good data representations at each depth of the network and provide a targetfor layer-wise greedy optimization (LEGO). Here we derive a novelcorrespondence between Gaussian Processes and SGD trained deep neural networks.Leveraging this correspondence, we derive the Deep Gaussian Layer-wise lossfunctions (DGLs) which, we believe, are the first supervised layer-wise lossfunctions which are both explicit and competitive in terms of accuracy. Beinghighly structured and symmetric, the DGLs provide a promising analytic route tounderstanding the internal representations generated by DNNs."^^schema:Text ;
    schema:author "Oded Ben-David"^^schema:Person,
        "Zohar Ringel"^^schema:Person ;
    schema:dateModified "2019-06-13T11:59:02Z"^^schema:DateTime ;
    schema:datePublished "2019-02-06T19:00:03Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The role of a layer in deep neural networks: a Gaussian Process  perspective"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.02354v3"^^schema:URL .

<1745> a schema:ScholarlyArticle ;
    schema:abstract "In the context of learning to map an input $I$ to a function$h_I:\\mathcal{X}\\to \\mathbb{R}$, two alternative methods are compared: (i) anembedding-based method, which learns a fixed function in which $I$ is encodedas a conditioning signal $e(I)$ and the learned function takes the form $h_I(x)= q(x,e(I))$, and (ii) hypernetworks, in which the weights $\\theta_I$ of thefunction $h_I(x) = g(x;\\theta_I)$ are given by a hypernetwork $f$ as$\\theta_I=f(I)$. In this paper, we define the property of modularity as theability to effectively learn a different function for each input instance $I$.For this purpose, we adopt an expressivity perspective of this property andextend the theory of Devore et al. 1996 and provide a lower bound on thecomplexity (number of trainable parameters) of neural networks as functionapproximators, by eliminating the requirements for the approximation method tobe robust. Our results are then used to compare the complexities of $q$ and$g$, showing that under certain conditions and when letting the functions $e$and $f$ be as large as we wish, $g$ can be smaller than $q$ by orders ofmagnitude. This sheds light on the modularity of hypernetworks in comparisonwith the embedding-based method. Besides, we show that for a structured targetfunction, the overall number of trainable parameters in a hypernetwork issmaller by orders of magnitude than the number of trainable parameters of astandard neural network and an embedding method."^^schema:Text ;
    schema:author "Lior Wolf"^^schema:Person,
        "Tomer Galanti"^^schema:Person ;
    schema:dateModified "2020-11-02T12:22:00Z"^^schema:DateTime ;
    schema:datePublished "2020-02-23T22:51:52Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Modularity of Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.10006v2"^^schema:URL .

<1746> a schema:ScholarlyArticle ;
    schema:abstract "Systematically discovering semantic relationships in text is an important andextensively studied area in Natural Language Processing, with various taskssuch as entailment, semantic similarity, etc. Decomposability of sentence-levelscores via subsequence alignments has been proposed as a way to make modelsmore interpretable. We study the problem of aligning components of sentencesleading to an interpretable model for semantic textual similarity. In thispaper, we introduce a novel pointer network based model with a sentinel gatingfunction to align constituent chunks, which are represented using BERT. Weimprove this base model with a loss function to equally penalize misalignmentsin both sentences, ensuring the alignments are bidirectional. Finally, to guidethe network with structured external knowledge, we introduce first-order logicconstraints based on ConceptNet and syntactic knowledge. The model achieves anF1 score of 97.73 and 96.32 on the benchmark SemEval datasets for the chunkalignment task, showing large improvements over the existing solutions. Sourcecode is available athttps://github.com/manishb89/interpretable_sentence_similarity"^^schema:Text ;
    schema:author "Kalyani Roy"^^schema:Person,
        "Manish Bansal"^^schema:Person,
        "Pawan Goyal"^^schema:Person,
        "Rohan Kumar"^^schema:Person,
        "Subhadeep Maji"^^schema:Person ;
    schema:dateModified "2020-07-15T13:01:44Z"^^schema:DateTime ;
    schema:datePublished "2020-07-15T13:01:44Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Logic Constrained Pointer Networks for Interpretable Textual Similarity"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.07670v1"^^schema:URL .

<1747> a schema:ScholarlyArticle ;
    schema:abstract "The COVID-19 pandemic brought unprecedented levels of disruption to the localand regional transportation networks throughout the United States, especiallythe Motor City: Detroit. That was mainly a result of swift restrictive measuressuch as statewide quarantine and lock-down orders to confine the spread of thevirus. This work is driven by analyzing five types of real-world data sets fromDetroit related to traffic volume, daily cases, weather, social distancingindex, and crashes from January 2019 to June 2020. The primary goal is figuringout the impacts of COVID-19 on the transportation network usage (trafficvolume) and safety (crashes) for the Detroit, exploring the potentialcorrelation between these diverse data features, and determining whether eachtype of data (e.g., traffic volume data) could be a useful factor in theconfirmed-cases prediction. In addition, a deep learning model was developedusing long short-term memory networks to predict the number of confirmed caseswithin the next one week. The model demonstrated a promising prediction resultwith a coefficient of determination (R^2) of up to approximately 0.91.Moreover, in order to provide statistical evaluation measures of confirmed-caseprediction and to quantify the prediction effectiveness of each type of data,the prediction results of six feature groups are presented and analyzed.Furthermore, six essential observations with supporting evidence and analysesare presented. The goal of this paper is to present a proposed approach whichcan be applied, customised, adjusted, and replicated for analysis of the impactof COVID-19 on a transportation network and prediction of the anticipatedCOVID-19 cases using a similar data set obtained for other large cities in theUSA or from around the world."^^schema:Text ;
    schema:author "Tony G. Geara"^^schema:Person,
        "Weisong Shi"^^schema:Person,
        "Yongtao Yao"^^schema:Person ;
    schema:dateModified "2020-08-28T19:08:02Z"^^schema:DateTime ;
    schema:datePublished "2020-08-28T19:08:02Z"^^schema:DateTime ;
    schema:genre "68T09"^^schema:Text,
        "I.2"^^schema:Text,
        "physics.soc-ph"^^schema:Text ;
    schema:headline "Impact of COVID-19 on City-Scale Transportation and Safety: An Early  Experience from Detroit"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.12080v1"^^schema:URL .

<1748> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing is one of the key research areas for empoweringpersonalized education. It is a task to model students' mastery level of aknowledge component (KC) based on their historical learning trajectories. Inrecent years, a recurrent neural network model called deep knowledge tracing(DKT) has been proposed to handle the knowledge tracing task and literature hasshown that DKT generally outperforms traditional methods. However, through ourextensive experimentation, we have noticed two major problems in the DKT model.The first problem is that the model fails to reconstruct the observed input. Asa result, even when a student performs well on a KC, the prediction of thatKC's mastery level decreases instead, and vice versa. Second, the predictedperformance for KCs across time-steps is not consistent. This is undesirableand unreasonable because student's performance is expected to transit graduallyover time. To address these problems, we introduce regularization terms thatcorrespond to reconstruction and waviness to the loss function of the originalDKT model to enhance the consistency in prediction. Experiments show that theregularized loss function effectively alleviates the two problems withoutdegrading the original task of DKT."^^schema:Text ;
    schema:author "Chun-Kit Yeung"^^schema:Person,
        "Dit-Yan Yeung"^^schema:Person ;
    schema:dateModified "2018-06-06T13:41:48Z"^^schema:DateTime ;
    schema:datePublished "2018-06-06T13:41:48Z"^^schema:DateTime ;
    schema:genre "I.2.6; K.3.m"^^schema:Text,
        "cs.AI"^^schema:Text ;
    schema:headline "Addressing Two Problems in Deep Knowledge Tracing via  Prediction-Consistent Regularization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.02180v1"^^schema:URL .

<1749> a schema:ScholarlyArticle ;
    schema:abstract "We provide statistical theory for conditional and unconditional Wassersteingenerative adversarial networks (WGANs) in the framework of dependentobservations. We prove upper bounds for the excess Bayes risk of the WGANestimators with respect to a modified Wasserstein-type distance. Furthermore,we formalize and derive statements on the weak convergence of the estimatorsand use them to develop confidence intervals for new observations. The theoryis applied to the special case of high-dimensional time series forecasting. Weanalyze the behavior of the estimators in simulations based on synthetic dataand investigate a real data example with temperature data. The dependency ofthe data is quantified with absolutely regular beta-mixing coefficients."^^schema:Text ;
    schema:author "Moritz Haas"^^schema:Person,
        "Stefan Richter"^^schema:Person ;
    schema:dateModified "2020-11-05T19:45:59Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T19:45:59Z"^^schema:DateTime ;
    schema:genre "62M45"^^schema:Text,
        "math.ST"^^schema:Text,
        "stat.ML"^^schema:Text,
        "stat.TH"^^schema:Text ;
    schema:headline "Statistical analysis of Wasserstein GANs with applications to time  series forecasting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03074v1"^^schema:URL .

<175> a schema:ScholarlyArticle ;
    schema:abstract "Image super-resolution (SR) is an underdetermined inverse problem, where alarge number of plausible high-resolution images can explain the samedownsampled image. Most current single image SR methods use empirical riskminimisation, often with a pixel-wise mean squared error (MSE) loss. However,the outputs from such methods tend to be blurry, over-smoothed and generallyappear implausible. A more desirable approach would employ Maximum a Posteriori(MAP) inference, preferring solutions that always have a high probability underthe image prior, and thus appear more plausible. Direct MAP estimation for SRis non-trivial, as it requires us to build a model for the image prior fromsamples. Furthermore, MAP inference is often performed via optimisation-basediterative algorithms which don't compare well with the efficiency ofneural-network-based alternatives. Here we introduce new methods for amortisedMAP inference whereby we calculate the MAP estimate directly using aconvolutional neural network. We first introduce a novel neural networkarchitecture that performs a projection to the affine subspace of valid SRsolutions ensuring that the high resolution output of the network is alwaysconsistent with the low resolution input. We show that, using thisarchitecture, the amortised MAP inference problem reduces to minimising thecross-entropy between two distributions, similar to training generative models.We propose three methods to solve this optimisation problem: (1) GenerativeAdversarial Networks (GAN) (2) denoiser-guided SR which backpropagatesgradient-estimates from denoising to train the network, and (3) a baselinemethod using a maximum-likelihood-trained image prior. Our experiments showthat the GAN based approach performs best on real image data. Lastly, weestablish a connection between GANs and amortised variational inference as ine.g. variational autoencoders."^^schema:Text ;
    schema:author "Casper Kaae Sønderby"^^schema:Person,
        "Ferenc Huszár"^^schema:Person,
        "Jose Caballero"^^schema:Person,
        "Lucas Theis"^^schema:Person,
        "Wenzhe Shi"^^schema:Person ;
    schema:commentCount "265"^^schema:Integer ;
    schema:dateModified "2017-02-21T13:08:24Z"^^schema:DateTime ;
    schema:datePublished "2016-10-14T14:58:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Amortised MAP Inference for Image Super-resolution"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.04490v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14286004747394736744&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1750> a schema:ScholarlyArticle ;
    schema:abstract "We present a generic compact computational framework relying on structuredrandom matrices that can be applied to speed up several machine learningalgorithms with almost no loss of accuracy. The applications include new fastLSH-based algorithms, efficient kernel computations via random feature maps,convex optimization algorithms, quantization techniques and many more. Certainmodels of the presented paradigm are even more compressible since they applyonly bit matrices. This makes them suitable for deploying on mobile devices.All our findings come with strong theoretical guarantees. In particular, as abyproduct of the presented techniques and by using relatively newBerry-Esseen-type CLT for random vectors, we give the first theoreticalguarantees for one of the most efficient existing LSH algorithms based on the$\\textbf{HD}_{3}\\textbf{HD}_{2}\\textbf{HD}_{1}$ structured matrix (\"Practicaland Optimal LSH for Angular Distance\"). These guarantees as well as theoreticalresults for other aforementioned applications follow from the same generaltheoretical principle that we present in the paper. Our structured familycontains as special cases all previously considered structured schemes,including the recently introduced $P$-model. Experimental evaluation confirmsthe accuracy and efficiency of TripleSpin matrices."^^schema:Text ;
    schema:author "Anne Morvan"^^schema:Person,
        "Cedric Gouy-Pailler"^^schema:Person,
        "Francois Fagan"^^schema:Person,
        "Jamal Atif"^^schema:Person,
        "Krzysztof Choromanski"^^schema:Person,
        "Tamas Sarlos"^^schema:Person ;
    schema:dateModified "2016-06-06T15:05:31Z"^^schema:DateTime ;
    schema:datePublished "2016-05-29T19:07:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "TripleSpin - a generic compact paradigm for fast machine learning  computations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1605.09046v2"^^schema:URL .

<1751> a schema:ScholarlyArticle ;
    schema:abstract "Matching natural language sentences is central for many applications such asinformation retrieval and question answering. Existing deep models rely on asingle sentence representation or multiple granularity representations formatching. However, such methods cannot well capture the contextualized localinformation in the matching process. To tackle this problem, we present a newdeep architecture to match two sentences with multiple positional sentencerepresentations. Specifically, each positional sentence representation is asentence representation at this position, generated by a bidirectional longshort term memory (Bi-LSTM). The matching score is finally produced byaggregating interactions between these different positional sentencerepresentations, through $k$-Max pooling and a multi-layer perceptron. Ourmodel has several advantages: (1) By using Bi-LSTM, rich context of the wholesentence is leveraged to capture the contextualized local information in eachpositional sentence representation; (2) By matching with multiple positionalsentence representations, it is flexible to aggregate different importantcontextualized local information in a sentence to support the matching; (3)Experiments on different tasks such as question answering and sentencecompletion demonstrate the superiority of our model."^^schema:Text ;
    schema:author "Jiafeng Guo"^^schema:Person,
        "Jun Xu"^^schema:Person,
        "Liang Pang"^^schema:Person,
        "Shengxian Wan"^^schema:Person,
        "Xueqi Cheng"^^schema:Person,
        "Yanyan Lan"^^schema:Person ;
    schema:dateModified "2015-11-26T02:57:54Z"^^schema:DateTime ;
    schema:datePublished "2015-11-26T02:57:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A Deep Architecture for Semantic Matching with Multiple Positional  Sentence Representations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1511.08277v1"^^schema:URL .

<1752> a schema:ScholarlyArticle ;
    schema:abstract "The past several years have seen remarkable progress in generative modelswhich produce convincing samples of images and other modalities. A sharedcomponent of many powerful generative models is a decoder network, a parametricdeep neural net that defines a generative distribution. Examples includevariational autoencoders, generative adversarial networks, and generativemoment matching networks. Unfortunately, it can be difficult to quantify theperformance of these models because of the intractability of log-likelihoodestimation, and inspecting samples can be misleading. We propose to useAnnealed Importance Sampling for evaluating log-likelihoods for decoder-basedmodels and validate its accuracy using bidirectional Monte Carlo. Theevaluation code is provided at https://github.com/tonywu95/eval_gen. Using thistechnique, we analyze the performance of decoder-based models, theeffectiveness of existing log-likelihood estimators, the degree of overfitting,and the degree to which these models miss important modes of the datadistribution."^^schema:Text ;
    schema:author "Roger Grosse"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Yuhuai Wu"^^schema:Person,
        "Yuri Burda"^^schema:Person ;
    schema:dateModified "2017-06-06T22:36:35Z"^^schema:DateTime ;
    schema:datePublished "2016-11-14T07:36:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "On the Quantitative Analysis of Decoder-Based Generative Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.04273v2"^^schema:URL .

<1753> a schema:ScholarlyArticle ;
    schema:abstract "Building systems that autonomously create temporal abstractions from data isa key challenge in scaling learning and planning in reinforcement learning. Onepopular approach for addressing this challenge is the options framework (Suttonet al., 1999). However, only recently in (Bacon et al., 2017) was a policygradient theorem derived for online learning of general purpose options in anend to end fashion. In this work, we extend previous work on this topic thatonly focuses on learning a two-level hierarchy including options and primitiveactions to enable learning simultaneously at multiple resolutions in time. Weachieve this by considering an arbitrarily deep hierarchy of options where highlevel temporally extended options are composed of lower level options withfiner resolutions in time. We extend results from (Bacon et al., 2017) andderive policy gradient theorems for a deep hierarchy of options. Our proposedhierarchical option-critic architecture is capable of learning internalpolicies, termination conditions, and hierarchical compositions over optionswithout the need for any intrinsic rewards or subgoals. Our empirical resultsin both discrete and continuous environments demonstrate the efficiency of ourframework."^^schema:Text ;
    schema:author "Gerald Tesauro"^^schema:Person,
        "Matthew Riemer"^^schema:Person,
        "Miao Liu"^^schema:Person ;
    schema:dateModified "2019-12-31T17:25:40Z"^^schema:DateTime ;
    schema:datePublished "2018-10-27T02:54:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Abstract Options"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.11583v4"^^schema:URL .

<1754> a schema:ScholarlyArticle ;
    schema:abstract "Policy gradient reinforcement learning techniques enable an agent to directlylearn an optimal action policy through the interactions with the environment.Nevertheless, despite its advantages, it sometimes suffers from slowconvergence speed. Inspired by human decision making approach, we work towardenhancing its convergence speed by augmenting the agent to memorize and use therecently learned policies. We apply our method to the trust-region policyoptimization (TRPO), primarily developed for locomotion tasks, and proposefaded-experience (FE) TRPO. To substantiate its effectiveness, we adopt it tolearn continuous power control in an interference channel when only noisylocation information of devices is available. Results indicate that withFE-TRPO it is possible to almost double the learning speed compared to TRPO.Importantly, our method neither increases the learning complexity nor imposesperformance loss."^^schema:Text ;
    schema:author "Halim Yanikomeroglu"^^schema:Person,
        "Mohammad G. Khoshkholgh"^^schema:Person ;
    schema:dateModified "2020-08-04T17:12:29Z"^^schema:DateTime ;
    schema:datePublished "2020-08-04T17:12:29Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Faded-Experience Trust Region Policy Optimization for Model-Free Power  Allocation in Interference Channel"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01705v1"^^schema:URL .

<1755> a schema:ScholarlyArticle ;
    schema:abstract "Defining and reliably finding a canonical orientation for 3D surfaces is keyto many Computer Vision and Robotics applications. This task is commonlyaddressed by handcrafted algorithms exploiting geometric cues deemed asdistinctive and robust by the designer. Yet, one might conjecture that humanslearn the notion of the inherent orientation of 3D objects from experience andthat machines may do so alike. In this work, we show the feasibility oflearning a robust canonical orientation for surfaces represented as pointclouds. Based on the observation that the quintessential property of acanonical orientation is equivariance to 3D rotations, we propose to employSpherical CNNs, a recently introduced machinery that can learn equivariantrepresentations defined on the Special Orthogonal group SO(3). Specifically,spherical correlations compute feature maps whose elements define 3D rotations.Our method learns such feature maps from raw data by a self-supervised trainingprocedure and robustly selects a rotation to transform the input point cloudinto a learned canonical orientation. Thereby, we realize the first end-to-endlearning approach to define and extract the canonical orientation of 3D shapes,which we aptly dub Compass. Experiments on several public datasets prove itseffectiveness at orienting local surface patches as well as whole objects."^^schema:Text ;
    schema:author "Federico Stella"^^schema:Person,
        "Luciano Silva"^^schema:Person,
        "Luigi Di Stefano"^^schema:Person,
        "Marlon Marcon"^^schema:Person,
        "Riccardo Spezialetti"^^schema:Person,
        "Samuele Salti"^^schema:Person ;
    schema:dateModified "2020-11-13T09:25:28Z"^^schema:DateTime ;
    schema:datePublished "2020-11-06T11:43:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Orient Surfaces by Self-supervised Spherical CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03298v2"^^schema:URL .

<1756> a schema:ScholarlyArticle ;
    schema:abstract "We present a learned unsupervised denoising method for arbitrary types ofdata, which we explore on images and one-dimensional signals. The training issolely based on samples of noisy data and examples of noise, which --critically -- do not need to come in pairs. We only need the assumption thatthe noise is independent and additive (although we describe how this can beextended). The method rests on a Wasserstein Generative Adversarial Networksetting, which utilizes two critics and one generator."^^schema:Text ;
    schema:author "Carola-Bibiane Schönlieb"^^schema:Person,
        "Peter Maass"^^schema:Person,
        "Sören Dittmer"^^schema:Person ;
    schema:dateModified "2020-07-03T09:39:25Z"^^schema:DateTime ;
    schema:datePublished "2020-07-03T09:39:25Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.FA"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Ground Truth Free Denoising by Optimal Transport"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.01575v1"^^schema:URL .

<1757> a schema:ScholarlyArticle ;
    schema:abstract "The young massive OB association Cygnus OB2, in the Cygnus X complex, is theclosest (1400 pc) star forming region to the Sun hosting thousands of young lowmass stars and up to 1000 OB stars, among which are some of the most massivestars known in our Galaxy. This region holds great importance for severalfields of modern astrophysics, such as the study of the physical properties ofmassive and young low-mass stars and the feedback provided by massive stars onstar and planet formation process. Cygnus OB2 has been recently observed withChandra/ACIS-I as part of the 1.08Msec Chandra Cygnus OB2 Legacy Project. Thissurvey detected 7924 X-ray sources in a square degree area centered on Cyg OB2.Since a proper classification and study of the observed X-ray sources alsorequires the analysis of their optical and infrared counterparts, we combined alarge and deep set of optical and infrared catalogs available for this regionwith our new X-ray catalog. In this paper we describe the matching procedureand present the combined catalog containing 5703 sources. We also brieflydiscuss the nature of the X-ray sources with optical and infrared counterpartsusing their position in the color-magnitude and color-color diagrams."^^schema:Text ;
    schema:author "D. Garcia-Alvarez"^^schema:Person,
        "E. Flaccomio"^^schema:Person,
        "J. J. Drake"^^schema:Person,
        "M. G. Guarcello"^^schema:Person,
        "N. J. Wright"^^schema:Person,
        "T. Naylor"^^schema:Person,
        "V. L. Kashyap"^^schema:Person ;
    schema:dateModified "2015-01-15T17:48:47Z"^^schema:DateTime ;
    schema:datePublished "2015-01-15T17:48:47Z"^^schema:DateTime ;
    schema:genre "astro-ph.SR"^^schema:Text ;
    schema:headline "Optical and infrared counterparts of the X-ray sources detected in the  Chandra Cygnus OB2 Legacy Survey"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1501.03761v1"^^schema:URL .

<1758> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we analyze if it is possible to distinguish between differentclones of the same bacteria species (Klebsiella pneumoniae) based only onmicroscopic images. It is a challenging task, previously considered impossibledue to the high clones similarity. For this purpose, we apply a multi-stepalgorithm with attention-based multiple instance learning. Except for obtainingaccuracy at the level of 0.9, we introduce extensive interpretability based onCellProfiler and persistence homology, increasing the understandability andtrust in the model."^^schema:Text ;
    schema:author "Adriana Borowa"^^schema:Person,
        "Bartosz Zieliński"^^schema:Person,
        "Dawid Rymarczyk"^^schema:Person,
        "Dorota Ochońska"^^schema:Person,
        "Monika Brzychczy-Włoch"^^schema:Person ;
    schema:dateModified "2020-12-02T13:20:39Z"^^schema:DateTime ;
    schema:datePublished "2020-12-02T13:20:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Classifying bacteria clones using attention-based deep multiple instance  learning interpreted by persistence homology"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.01189v1"^^schema:URL .

<1759> a schema:ScholarlyArticle ;
    schema:abstract "The main purpose of RGB-D salient object detection (SOD) is how to betterintegrate and utilize cross-modal fusion information. In this paper, we explorethese issues from a new perspective. We integrate the features of differentmodalities through densely connected structures and use their mixed features togenerate dynamic filters with receptive fields of different sizes. In the end,we implement a kind of more flexible and efficient multi-scale cross-modalfeature processing, i.e. dynamic dilated pyramid module. In order to make thepredictions have sharper edges and consistent saliency regions, we design ahybrid enhanced loss function to further optimize the results. This lossfunction is also validated to be effective in the single-modal RGB SOD task. Interms of six metrics, the proposed method outperforms the existing twelvemethods on eight challenging benchmark datasets. A large number of experimentsverify the effectiveness of the proposed module and loss function. Our code,model and results are available at \\url{https://github.com/lartpang/HDFNet}."^^schema:Text ;
    schema:author "Huchuan Lu"^^schema:Person,
        "Lihe Zhang"^^schema:Person,
        "Xiaoqi Zhao"^^schema:Person,
        "Youwei Pang"^^schema:Person ;
    schema:dateModified "2020-07-16T09:15:49Z"^^schema:DateTime ;
    schema:datePublished "2020-07-13T07:59:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Hierarchical Dynamic Filtering Network for RGB-D Salient Object  Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.06227v3"^^schema:URL .

<176> a schema:ScholarlyArticle ;
    schema:abstract "We propose sparsemax, a new activation function similar to the traditionalsoftmax, but able to output sparse probabilities. After deriving itsproperties, we show how its Jacobian can be efficiently computed, enabling itsuse in a network trained with backpropagation. Then, we propose a new smoothand convex loss function which is the sparsemax analogue of the logistic loss.We reveal an unexpected connection between this new loss and the Huberclassification loss. We obtain promising empirical results in multi-labelclassification problems and in attention-based neural networks for naturallanguage inference. For the latter, we achieve a similar performance as thetraditional softmax, but with a selective, more compact, attention focus."^^schema:Text ;
    schema:author "André F. T. Martins"^^schema:Person,
        "Ramón Fernandez Astudillo"^^schema:Person ;
    schema:commentCount "190"^^schema:Integer ;
    schema:dateModified "2016-02-08T09:41:36Z"^^schema:DateTime ;
    schema:datePublished "2016-02-05T15:49:02Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label  Classification"^^schema:Text ;
    schema:publisher "ICML, 1614-1623"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02068v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15219879151044186751&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1760> a schema:ScholarlyArticle ;
    schema:abstract "The control of nonlinear dynamical systems remains a major challenge forautonomous agents. Current trends in reinforcement learning (RL) focus oncomplex representations of dynamics and policies, which have yielded impressiveresults in solving a variety of hard control tasks. However, this newsophistication and extremely over-parameterized models have come with the costof an overall reduction in our ability to interpret the resulting policies. Inthis paper, we take inspiration from the control community and apply theprinciples of hybrid switching systems in order to break down complex dynamicsinto simpler components. We exploit the rich representational power ofprobabilistic graphical models and derive an expectation-maximization (EM)algorithm for learning a sequence model to capture the temporal structure ofthe data and automatically decompose nonlinear dynamics into stochasticswitching linear dynamical systems. Moreover, we show how this framework ofswitching models enables extracting hierarchies of Markovian andauto-regressive locally linear controllers from nonlinear experts in animitation learning scenario."^^schema:Text ;
    schema:author "Hany Abdulsamad"^^schema:Person,
        "Jan Peters"^^schema:Person ;
    schema:dateModified "2020-05-12T14:54:33Z"^^schema:DateTime ;
    schema:datePublished "2020-05-04T12:40:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Decomposition of Nonlinear Dynamics and Control for System  Identification and Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.01432v2"^^schema:URL .

<1761> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial imitation learning (GAIL) demonstrates tremendoussuccess in practice, especially when combined with neural networks. Differentfrom reinforcement learning, GAIL learns both policy and reward function fromexpert (human) demonstration. Despite its empirical success, it remains unclearwhether GAIL with neural networks converges to the globally optimal solution.The major difficulty comes from the nonconvex-nonconcave minimax optimizationstructure. To bridge the gap between practice and theory, we analyze agradient-based algorithm with alternating updates and establish its sublinearconvergence to the globally optimal solution. To the best of our knowledge, ouranalysis establishes the global optimality and convergence rate of GAIL withneural networks for the first time."^^schema:Text ;
    schema:author "Qi Cai"^^schema:Person,
        "Yufeng Zhang"^^schema:Person,
        "Zhaoran Wang"^^schema:Person,
        "Zhuoran Yang"^^schema:Person ;
    schema:dateModified "2020-06-25T03:33:18Z"^^schema:DateTime ;
    schema:datePublished "2020-03-08T03:39:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Adversarial Imitation Learning with Neural Networks: Global  Optimality and Convergence Rate"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03709v2"^^schema:URL .

<1762> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we propose a novel approach for generating videos of the sixbasic facial expressions given a neutral face image. We propose to exploit theface geometry by modeling the facial landmarks motion as curves encoded aspoints on a hypersphere. By proposing a conditional version of manifold-valuedWasserstein generative adversarial network (GAN) for motion generation on thehypersphere, we learn the distribution of facial expression dynamics ofdifferent classes, from which we synthesize new facial expression motions. Theresulting motions can be transformed to sequences of landmarks and then toimages sequences by editing the texture information using another conditionalGenerative Adversarial Network. To the best of our knowledge, this is the firstwork that explores manifold-valued representations with GAN to address theproblem of dynamic facial expression generation. We evaluate our proposedapproach both quantitatively and qualitatively on two public datasets;Oulu-CASIA and MUG Facial Expression. Our experimental results demonstrate theeffectiveness of our approach in generating realistic videos with continuousmotion, realistic appearance and identity preservation. We also show theefficiency of our framework for dynamic facial expressions generation, dynamicfacial expression transfer and data augmentation for training improved emotionrecognition models."^^schema:Text ;
    schema:author "Anis Kacem"^^schema:Person,
        "Lahoucine Ballihi"^^schema:Person,
        "Mohamed Daoudi"^^schema:Person,
        "Naima Otberdout"^^schema:Person,
        "Stefano Berretti"^^schema:Person ;
    schema:dateModified "2020-05-28T18:14:42Z"^^schema:DateTime ;
    schema:datePublished "2019-07-23T18:22:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Dynamic Facial Expression Generation on Hilbert Hypersphere with  Conditional Wasserstein Generative Adversarial Nets"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.10087v2"^^schema:URL .

<1763> a schema:ScholarlyArticle ;
    schema:abstract "We present HyperMorph, a learning-based strategy for deformable imageregistration that removes the need to tune important registrationhyperparameters during training. Classical registration methods solve anoptimization problem to find a set of spatial correspondences between twoimages, while learning-based methods leverage a training dataset to learn afunction that generates these correspondences. The quality of the results forboth types of techniques depends greatly on the choice of hyperparameters.Unfortunately, hyperparameter tuning is time-consuming and typically involvestraining many separate models with various hyperparameter values, potentiallyleading to suboptimal results. To address this inefficiency, we introduceamortized hyperparameter learning for image registration, a novel strategy tolearn the effects of hyperparameters on deformation fields. The proposedframework learns a hypernetwork that takes in an input hyperparameter andmodulates a registration network to produce the optimal deformation field forthat hyperparameter value. In effect, this strategy trains a single, rich modelthat enables rapid, fine-grained discovery of hyperparameter values from acontinuous interval at test-time. We demonstrate that this approach can be usedto optimize multiple hyperparameters considerably faster than existing searchstrategies, leading to a reduced computational and human burden and increasedflexibility. We also show that this has several important benefits, includingincreased robustness to initialization and the ability to rapidly identifyoptimal hyperparameter values specific to a registration task, dataset, or evena single anatomical region - all without retraining the HyperMorph model. Ourcode is publicly available at http://voxelmorph.mit.edu."^^schema:Text ;
    schema:author "Adrian V. Dalca"^^schema:Person,
        "Andrew Hoopes"^^schema:Person,
        "Bruce Fischl"^^schema:Person,
        "John Guttag"^^schema:Person,
        "Malte Hoffmann"^^schema:Person ;
    schema:dateModified "2021-01-04T15:39:16Z"^^schema:DateTime ;
    schema:datePublished "2021-01-04T15:39:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "HyperMorph: Amortized Hyperparameter Learning for Image Registration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.01035v1"^^schema:URL .

<1764> a schema:ScholarlyArticle ;
    schema:abstract "The paper proposes an on-line monitoring framework for continuous real-timesafety/security in learning-based control systems (specifically application toa unmanned ground vehicle). We monitor validity of mappings from sensor inputsto actuator commands, controller-focused anomaly detection (CFAM), and fromactuator commands to sensor inputs, system-focused anomaly detection (SFAM).CFAM is an image conditioned energy based generative adversarial network(EBGAN) in which the energy based discriminator distinguishes between properand anomalous actuator commands. SFAM is based on an action condition videoprediction framework to detect anomalies between predicted and observedtemporal evolution of sensor data. We demonstrate the effectiveness of theapproach on our autonomous ground vehicle for indoor environments and onUdacity dataset for outdoor environments."^^schema:Text ;
    schema:author "Anna Choromanska"^^schema:Person,
        "Apoorva Nandini Saridena"^^schema:Person,
        "Farshad Khorrami"^^schema:Person,
        "Naman Patel"^^schema:Person,
        "Prashanth Krishnamurthy"^^schema:Person ;
    schema:dateModified "2018-11-12T03:33:45Z"^^schema:DateTime ;
    schema:datePublished "2018-11-12T03:33:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Learning-Based On-Line Anomaly Monitoring for Assured  Autonomy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.04539v1"^^schema:URL .

<1765> a schema:ScholarlyArticle ;
    schema:abstract "Attention-based end-to-end models such as Listen, Attend and Spell (LAS),simplify the whole pipeline of traditional automatic speech recognition (ASR)systems and become popular in the field of speech recognition. In previouswork, researchers have shown that such architectures can acquire comparableresults to state-of-the-art ASR systems, especially when using a bidirectionalencoder and global soft attention (GSA) mechanism. However, bidirectionalencoder and GSA are two obstacles for real-time speech recognition. In thiswork, we aim to stream LAS baseline by removing the above two obstacles. On theencoder side, we use a latency-controlled (LC) bidirectional structure toreduce the delay of forward computation. Meanwhile, an adaptive monotonicchunk-wise attention (AMoChA) mechanism is proposed to replace GSA for thecalculation of attention weight distribution. Furthermore, we propose twomethods to alleviate the huge performance degradation when combining LC andAMoChA. Finally, we successfully acquire an online LAS model, LC-AMoChA, whichhas only 3.5% relative performance reduction to LAS baseline on our internalMandarin corpus."^^schema:Text ;
    schema:author "Gang Liu"^^schema:Person,
        "Jia Jia"^^schema:Person,
        "Pan Zhou"^^schema:Person,
        "Ruchao Fan"^^schema:Person,
        "Wei Chen"^^schema:Person ;
    schema:dateModified "2019-04-25T09:13:17Z"^^schema:DateTime ;
    schema:datePublished "2018-11-13T12:23:37Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "An Online Attention-based Model for Speech Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.05247v2"^^schema:URL .

<1766> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we propose a novel method for detecting adversarial examples bytraining a binary classifier with both origin data and saliency data. In thecase of image classification model, saliency simply explain how the model makedecisions by identifying significant pixels for prediction. A model shows wrongclassification output always learns wrong features and shows wrong saliency aswell. Our approach shows good performance on detecting adversarialperturbations. We quantitatively evaluate generalization ability of thedetector, showing that detectors trained with strong adversaries perform wellon weak adversaries."^^schema:Text ;
    schema:author "Chiliang Zhang"^^schema:Person,
        "Zhimou Yang"^^schema:Person,
        "Zuochang Ye"^^schema:Person ;
    schema:dateModified "2018-03-23T12:52:28Z"^^schema:DateTime ;
    schema:datePublished "2018-03-23T12:52:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Detecting Adversarial Perturbations with Saliency"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.08773v1"^^schema:URL .

<1767> a schema:ScholarlyArticle ;
    schema:abstract "Developing agents that can perform challenging complex tasks is the goal ofreinforcement learning. The model-free reinforcement learning has beenconsidered as a feasible solution. However, the state of the art research hasbeen to develop increasingly complicated techniques. This increasing complexitymakes the reconstruction difficult. Furthermore, the problem of rewarddependency is still exists. As a result, research on imitation learning, whichlearns policy from a demonstration of experts, has begun to attract attention.Imitation learning directly learns policy based on data on the behavior of theexperts without the explicit reward signal provided by the environment.However, imitation learning tries to optimize policies based on deepreinforcement learning such as trust region policy optimization. As a result,deep reinforcement learning based imitation learning also poses a crisis ofreproducibility. The issue of complex model-free model has receivedconsiderable critical attention. A derivative-free optimization basedreinforcement learning and the simplification on policies obtain competitiveperformance on the dynamic complex tasks. The simplified policies andderivative free methods make algorithm be simple. The reconfiguration ofresearch demo becomes easy. In this paper, we propose an imitation learningmethod that takes advantage of the derivative-free optimization with simplelinear policies. The proposed method performs simple random search in theparameter space of policies and shows computational efficiency. Experiments inthis paper show that the proposed model, without a direct reward signal fromthe environment, obtains competitive performance on the MuJoCo locomotiontasks."^^schema:Text ;
    schema:author "Joongheon Kim"^^schema:Person,
        "MyungJae Shin"^^schema:Person ;
    schema:dateModified "2020-08-21T12:40:03Z"^^schema:DateTime ;
    schema:datePublished "2020-08-21T12:40:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Imitation Learning via Random Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.09450v1"^^schema:URL .

<1768> a schema:ScholarlyArticle ;
    schema:abstract "Images encode both the state of the world and its content. The former isuseful for tasks such as planning and control, and the latter forclassification. The automatic extraction of this information is challengingbecause of the high-dimensionality and entangled encoding inherent to the imagerepresentation. This article introduces two theoretical approaches aimed at theresolution of these challenges. The approaches allow for the interpolation andextrapolation of images from an image sequence by joint estimation of the imagerepresentation and the generators of the sequence dynamics. In the firstapproach, the image representations are learned using probabilistic PCA\\cite{tipping1999probabilistic}. The linear-Gaussian conditional distributionsallow for a closed form analytical description of the latent distributions butassumes the underlying image manifold is a linear subspace. In the secondapproach, the image representations are learned using probabilistic nonlinearPCA which relieves the linear manifold assumption at the cost of requiring avariational approximation of the latent distributions. In both approaches, theunderlying dynamics of the image sequence are modelled explicitly todisentangle them from the image representations. The dynamics themselves aremodelled with Lie group structure which enforces the desirable properties ofsmoothness and composability of inter-image transformations."^^schema:Text ;
    schema:author "Christine Allen-Blanchette"^^schema:Person,
        "Kostas Daniilidis"^^schema:Person ;
    schema:dateModified "2020-12-08T13:28:42Z"^^schema:DateTime ;
    schema:datePublished "2020-12-05T00:07:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Joint Estimation of Image Representations and their Lie Invariants"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02903v2"^^schema:URL .

<1769> a schema:ScholarlyArticle ;
    schema:abstract "Graph Neural Networks(GNNs) are useful deep learning models to deal with thenon-Euclid data. However, recent works show that GNNs are vulnerable toadversarial attacks. Small perturbations can lead to poor performance in manyGNNs, such as Graph attention networks(GATs). Therefore, enhancing therobustness of GNNs is a critical problem.  Robust GAT(RoGAT) is proposed to improve the robustness of GNNs in thispaper, . Note that the original GAT uses the attention mechanism for differentedges but is still sensitive to the perturbation, RoGAT adjusts the edges'weight to adjust the attention scores progressively. Firstly, RoGAT tunes theedges weight based on the assumption that the adjacent nodes should havesimilar nodes. Secondly, RoGAT further tunes the features to eliminatefeature's noises since even for the clean graph, there exists some unreasonabledata. Then, we trained the adjusted GAT model to defense the adversarialattacks. Different experiments against targeted and untargeted attacksdemonstrate that RoGAT outperforms significantly than most the state-of-the-artdefense methods. The implementation of RoGAT based on the DeepRobust repositoryfor adversarial attacks."^^schema:Text ;
    schema:author "Hongxia Wang"^^schema:Person,
        "Xianchen Zhou"^^schema:Person ;
    schema:dateModified "2020-09-28T03:10:09Z"^^schema:DateTime ;
    schema:datePublished "2020-09-28T03:10:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "RoGAT: a robust GNN combined revised GAT with adjusted graphs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.13038v1"^^schema:URL .

<177> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents incremental network quantization (INQ), a novel method,targeting to efficiently convert any pre-trained full-precision convolutionalneural network (CNN) model into a low-precision version whose weights areconstrained to be either powers of two or zero. Unlike existing methods whichare struggled in noticeable accuracy loss, our INQ has the potential to resolvethis issue, as benefiting from two innovations. On one hand, we introduce threeinterdependent operations, namely weight partition, group-wise quantization andre-training. A well-proven measure is employed to divide the weights in eachlayer of a pre-trained CNN model into two disjoint groups. The weights in thefirst group are responsible to form a low-precision base, thus they arequantized by a variable-length encoding method. The weights in the other groupare responsible to compensate for the accuracy loss from the quantization, thusthey are the ones to be re-trained. On the other hand, these three operationsare repeated on the latest re-trained group in an iterative manner until allthe weights are converted into low-precision ones, acting as an incrementalnetwork quantization and accuracy enhancement procedure. Extensive experimentson the ImageNet classification task using almost all known deep CNNarchitectures including AlexNet, VGG-16, GoogleNet and ResNets well testify theefficacy of the proposed method. Specifically, at 5-bit quantization, ourmodels have improved accuracy than the 32-bit floating-point references. TakingResNet-18 as an example, we further show that our quantized models with 4-bit,3-bit and 2-bit ternary weights have improved or very similar accuracy againstits 32-bit floating-point baseline. Besides, impressive results with thecombination of network pruning and INQ are also reported. The code is availableat https://github.com/Zhouaojun/Incremental-Network-Quantization."^^schema:Text ;
    schema:author "Anbang Yao"^^schema:Person,
        "Aojun Zhou"^^schema:Person,
        "Lin Xu"^^schema:Person,
        "Yiwen Guo"^^schema:Person,
        "Yurong Chen"^^schema:Person ;
    schema:commentCount "455"^^schema:Integer ;
    schema:dateModified "2017-08-25T13:21:18Z"^^schema:DateTime ;
    schema:datePublished "2017-02-10T02:30:22Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Incremental Network Quantization: Towards Lossless CNNs with  Low-Precision Weights"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.03044v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10552103322105352604&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1770> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of learning control policies that optimize a rewardfunction while satisfying constraints due to considerations of safety,fairness, or other costs. We propose a new algorithm, Projection-BasedConstrained Policy Optimization (PCPO). This is an iterative method foroptimizing policies in a two-step process: the first step performs a localreward improvement update, while the second step reconciles any constraintviolation by projecting the policy back onto the constraint set. Wetheoretically analyze PCPO and provide a lower bound on reward improvement, andan upper bound on constraint violation, for each policy update. We furthercharacterize the convergence of PCPO based on two different metrics:$\\normltwo$ norm and Kullback-Leibler divergence. Our empirical results overseveral control tasks demonstrate that PCPO achieves superior performance,averaging more than 3.5 times less constraint violation and around 15\\% higherreward compared to state-of-the-art methods."^^schema:Text ;
    schema:author "Justinian Rosca"^^schema:Person,
        "Karthik Narasimhan"^^schema:Person,
        "Peter J. Ramadge"^^schema:Person,
        "Tsung-Yen Yang"^^schema:Person ;
    schema:dateModified "2020-10-07T04:22:45Z"^^schema:DateTime ;
    schema:datePublished "2020-10-07T04:22:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Projection-Based Constrained Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.03152v1"^^schema:URL .

<1771> a schema:ScholarlyArticle ;
    schema:abstract "Neural ordinary differential equations (NODEs) is an invertible neuralnetwork architecture promising for its free-form Jacobian and the availabilityof a tractable Jacobian determinant estimator. Recently, the representationpower of NODEs has been partly uncovered: they form an $L^p$-universalapproximator for continuous maps under certain conditions. However, the$L^p$-universality may fail to guarantee an approximation for the entire inputdomain as it may still hold even if the approximator largely differs from thetarget function on a small region of the input space. To further uncover thepotential of NODEs, we show their stronger approximation property, namely the$\\sup$-universality for approximating a large class of diffeomorphisms. It isshown by leveraging a structure theorem of the diffeomorphism group, and theresult complements the existing literature by establishing a fairly large setof mappings that NODEs can approximate with a stronger guarantee."^^schema:Text ;
    schema:author "Isao Ishikawa"^^schema:Person,
        "Kenta Oono"^^schema:Person,
        "Koichi Tojo"^^schema:Person,
        "Masahiro Ikeda"^^schema:Person,
        "Takeshi Teshima"^^schema:Person ;
    schema:dateModified "2020-12-04T05:53:21Z"^^schema:DateTime ;
    schema:datePublished "2020-12-04T05:53:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.DG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Universal Approximation Property of Neural Ordinary Differential  Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02414v1"^^schema:URL .

<1772> a schema:ScholarlyArticle ;
    schema:abstract "While a diverse collection of continual learning (CL) methods has beenproposed to prevent catastrophic forgetting, a thorough investigation of theireffectiveness for processing sequential data with recurrent neural networks(RNNs) is lacking. Here, we provide the first comprehensive evaluation ofestablished CL methods on a variety of sequential data benchmarks.Specifically, we shed light on the particularities that arise when applyingweight-importance methods, such as elastic weight consolidation, to RNNs. Incontrast to feedforward networks, RNNs iteratively reuse a shared set ofweights and require working memory to process input samples. We show that theperformance of weight-importance methods is not directly affected by the lengthof the processed sequences, but rather by high working memory requirements,which lead to an increased need for stability at the cost of decreasedplasticity for learning subsequent tasks. We additionally provide theoreticalarguments supporting this interpretation by studying linear RNNs. Our studyshows that established CL methods can be successfully ported to the recurrentcase, and that a recent regularization approach based on hypernetworksoutperforms weight-importance methods, thus emerging as a promising candidatefor CL in RNNs. Overall, we provide insights on the differences between CL infeedforward networks and RNNs, while guiding towards effective solutions totackle CL on sequential data."^^schema:Text ;
    schema:author "Alexander Meulemans"^^schema:Person,
        "Benjamin Ehret"^^schema:Person,
        "Benjamin F. Grewe"^^schema:Person,
        "Christian Henning"^^schema:Person,
        "Johannes von Oswald"^^schema:Person,
        "Maria R. Cervera"^^schema:Person ;
    schema:dateModified "2020-10-13T09:13:51Z"^^schema:DateTime ;
    schema:datePublished "2020-06-22T10:05:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continual Learning in Recurrent Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.12109v2"^^schema:URL .

<1773> a schema:ScholarlyArticle ;
    schema:abstract "We introduce CHIME, a cross-passage hierarchical memory network for questionanswering (QA) via text generation. It extends XLNet introducing an auxiliarymemory module consisting of two components: the context memory collectingcross-passage evidences, and the answer memory working as a buffer continuallyrefining the generated answers. Empirically, we show the efficacy of theproposed architecture in the multi-passage generative QA, outperforming thestate-of-the-art baselines with better syntactically well-formed answers andincreased precision in addressing the questions of the AmazonQA review dataset.An additional qualitative analysis revealed the interpretability introduced bythe memory module."^^schema:Text ;
    schema:author "Binyang Li"^^schema:Person,
        "Gabriele Pergola"^^schema:Person,
        "Junru Lu"^^schema:Person,
        "Lin Gui"^^schema:Person,
        "Yulan He"^^schema:Person ;
    schema:dateModified "2020-11-01T14:48:49Z"^^schema:DateTime ;
    schema:datePublished "2020-11-01T14:48:49Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "CHIME: Cross-passage Hierarchical Memory Network for Generative Review  Question Answering"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00519v1"^^schema:URL .

<1774> a schema:ScholarlyArticle ;
    schema:abstract "Complex environments and tasks pose a difficult problem for holisticend-to-end learning approaches. Decomposition of an environment intointeracting controllable and non-controllable objects allows supervisedlearning for non-controllable objects and universal value function approximatorlearning for controllable objects. Such decomposition should lead to a shorterlearning time and better generalisation capability. Here, we considerarcade-game environments as sets of interacting objects (controllable,non-controllable) and propose a set of functional modules that are specializedon mastering different types of interactions in a broad range of environments.The modules utilize regression, supervised learning, and reinforcement learningalgorithms. Results of this case study in different Atari games suggest thathuman-level performance can be achieved by a learning agent within a humanamount of game experience (10-15 minutes game time) when a proper decompositionof an environment or a task is provided. However, automatization of suchdecomposition remains a challenging problem. This case study shows how a modelof a causal structure underlying an environment or a task can benefit learningtime and generalization capability of the agent, and argues in favor ofexploiting modular structure in contrast to using pure end-to-end learningapproaches."^^schema:Text ;
    schema:author "Andrew Melnik"^^schema:Person,
        "Helge Ritter"^^schema:Person,
        "Malte Schilling"^^schema:Person,
        "Sascha Fleer"^^schema:Person ;
    schema:dateModified "2019-01-27T05:06:30Z"^^schema:DateTime ;
    schema:datePublished "2019-01-27T05:06:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modularization of End-to-End Learning: Case Study in Arcade Games"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.09895v1"^^schema:URL .

<1775> a schema:ScholarlyArticle ;
    schema:abstract "As the application of deep learning has expanded to real-world problems withinsufficient volume of training data, transfer learning recently has gainedmuch attention as means of improving the performance in such small-data regime.However, when existing methods are applied between heterogeneous architecturesand tasks, it becomes more important to manage their detailed configurationsand often requires exhaustive tuning on them for the desired performance. Toaddress the issue, we propose a novel transfer learning approach based onmeta-learning that can automatically learn what knowledge to transfer from thesource network to where in the target network. Given source and targetnetworks, we propose an efficient training scheme to learn meta-networks thatdecide (a) which pairs of layers between the source and target networks shouldbe matched for knowledge transfer and (b) which features and how much knowledgefrom each feature should be transferred. We validate our meta-transfer approachagainst recent transfer learning methods on various datasets and networkarchitectures, on which our automated scheme significantly outperforms theprior baselines that find \"what and where to transfer\" in a hand-craftedmanner."^^schema:Text ;
    schema:author "Hankook Lee"^^schema:Person,
        "Jinwoo Shin"^^schema:Person,
        "Sung Ju Hwang"^^schema:Person,
        "Yunhun Jang"^^schema:Person ;
    schema:dateModified "2019-05-15T00:36:49Z"^^schema:DateTime ;
    schema:datePublished "2019-05-15T00:36:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning What and Where to Transfer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.05901v1"^^schema:URL .

<1776> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we present a fully automated lung CT cancer diagnosis system,DeepLung. DeepLung contains two parts, nodule detection and classification.Considering the 3D nature of lung CT data, two 3D networks are designed for thenodule detection and classification respectively. Specifically, a 3D FasterR-CNN is designed for nodule detection with a U-net-like encoder-decoderstructure to effectively learn nodule features. For nodule classification,gradient boosting machine (GBM) with 3D dual path network (DPN) features isproposed. The nodule classification subnetwork is validated on a public datasetfrom LIDC-IDRI, on which it achieves better performance than state-of-the-artapproaches, and surpasses the average performance of four experienced doctors.For the DeepLung system, candidate nodules are detected first by the noduledetection subnetwork, and nodule diagnosis is conducted by the classificationsubnetwork. Extensive experimental results demonstrate the DeepLung iscomparable to the experienced doctors both for the nodule-level andpatient-level diagnosis on the LIDC-IDRI dataset."^^schema:Text ;
    schema:author "Chaochun Liu"^^schema:Person,
        "Wei Fan"^^schema:Person,
        "Wentao Zhu"^^schema:Person,
        "Xiaohui Xie"^^schema:Person ;
    schema:dateModified "2017-09-16T16:18:22Z"^^schema:DateTime ;
    schema:datePublished "2017-09-16T16:18:22Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "DeepLung: 3D Deep Convolutional Nets for Automated Pulmonary Nodule  Detection and Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.05538v1"^^schema:URL .

<1777> a schema:ScholarlyArticle ;
    schema:abstract "Detecting image correspondences by feature matching forms the basis ofnumerous computer vision applications. Several detectors and descriptors havebeen presented in the past, addressing the efficient generation of featuresfrom interest points (keypoints) in an image. In this paper, we investigateeight binary descriptors (AKAZE, BoostDesc, BRIEF, BRISK, FREAK, LATCH, LUCID,and ORB) and eight interest point detector (AGAST, AKAZE, BRISK, FAST,HarrisLapalce, KAZE, ORB, and StarDetector). We have decoupled the detectionand description phase to analyze the interest point detectors and then evaluatethe performance of the pairwise combination of different detectors anddescriptors. We conducted experiments on a standard dataset and analyzed thecomparative performance of each method under different image transformations.We observed that: (1) the FAST, AGAST, ORB detectors were faster and detectedmore keypoints, (2) the AKAZE and KAZE detectors performed better underphotometric changes while ORB was more robust against geometric changes, (3) ingeneral, descriptors performed better when paired with the KAZE and AKAZEdetectors, (4) the BRIEF, LUCID, ORB descriptors were relatively faster, and(5) none of the descriptors did particularly well under geometrictransformations, only BRISK, FREAK, and AKAZE showed reasonable resiliency."^^schema:Text ;
    schema:author "Mircea Nicolescu"^^schema:Person,
        "Monica Nicolescu"^^schema:Person,
        "Pourya Hoseini"^^schema:Person,
        "Shuvo Kumar Paul"^^schema:Person ;
    schema:dateModified "2020-12-08T00:44:36Z"^^schema:DateTime ;
    schema:datePublished "2020-12-08T00:44:36Z"^^schema:DateTime ;
    schema:genre "I.4.10; I.4.0; I.4.7"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Performance Analysis of Keypoint Detectors and Binary Descriptors Under  Varying Degrees of Photometric and Geometric Transformations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.04135v1"^^schema:URL .

<1778> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning (IL) aims to learn a policy from expert demonstrationsthat minimizes the discrepancy between the learner and expert behaviors.Various imitation learning algorithms have been proposed with differentpre-determined divergences to quantify the discrepancy. This naturally givesrise to the following question: Given a set of expert demonstrations, whichdivergence can recover the expert policy more accurately with higher dataefficiency? In this work, we propose $f$-GAIL, a new generative adversarialimitation learning (GAIL) model, that automatically learns a discrepancymeasure from the $f$-divergence family as well as a policy capable of producingexpert-like behaviors. Compared with IL baselines with various predefineddivergence measures, $f$-GAIL learns better policies with higher dataefficiency in six physics-based control tasks."^^schema:Text ;
    schema:author "Xin Zhang"^^schema:Person,
        "Yanhua Li"^^schema:Person,
        "Zhi-Li Zhang"^^schema:Person,
        "Ziming Zhang"^^schema:Person ;
    schema:dateModified "2020-11-19T05:29:20Z"^^schema:DateTime ;
    schema:datePublished "2020-10-02T21:39:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "$f$-GAIL: Learning $f$-Divergence for Generative Adversarial Imitation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.01207v2"^^schema:URL .

<1779> a schema:ScholarlyArticle ;
    schema:abstract "The use of imitation learning to learn a single policy for a complex taskthat has multiple modes or hierarchical structure can be challenging. In fact,previous work has shown that when the modes are known, learning separatepolicies for each mode or sub-task can greatly improve the performance ofimitation learning. In this work, we discover the interaction between sub-tasksfrom their resulting state-action trajectory sequences using a directedgraphical model. We propose a new algorithm based on the generative adversarialimitation learning framework which automatically learns sub-task policies fromunsegmented demonstrations. Our approach maximizes the directed informationflow in the graphical model between sub-task latent variables and theirgenerated trajectories. We also show how our approach connects with theexisting Options framework, which is commonly used to learn hierarchicalpolicies."^^schema:Text ;
    schema:author "Arjun Sharma"^^schema:Person,
        "Kris M. Kitani"^^schema:Person,
        "Mohit Sharma"^^schema:Person,
        "Nicholas Rhinehart"^^schema:Person ;
    schema:dateModified "2019-03-12T02:06:19Z"^^schema:DateTime ;
    schema:datePublished "2018-09-29T18:40:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented  Demonstrations using Directed Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.01266v2"^^schema:URL .

<178> a schema:ScholarlyArticle ;
    schema:abstract "We develop a Deep-Text Recurrent Network (DTRN) that regards scene textreading as a sequence labelling problem. We leverage recent advances of deepconvolutional neural networks to generate an ordered high-level sequence from awhole word image, avoiding the difficult character segmentation problem. Then adeep recurrent model, building on long short-term memory (LSTM), is developedto robustly recognize the generated CNN sequences, departing from most existingapproaches recognising each character independently. Our model has a number ofappealing properties in comparison to existing scene text recognition methods:(i) It can recognise highly ambiguous words by leveraging meaningful contextinformation, allowing it to work reliably without either pre- orpost-processing; (ii) the deep CNN feature is robust to various imagedistortions; (iii) it retains the explicit order information in word image,which is essential to discriminate word strings; (iv) the model does not dependon pre-defined dictionary, and it can process unknown words and arbitrarystrings. Codes for the DTRN will be available."^^schema:Text ;
    schema:author "Chen Change Loy"^^schema:Person,
        "Pan He"^^schema:Person,
        "Weilin Huang"^^schema:Person,
        "Xiaoou Tang"^^schema:Person,
        "Yu Qiao"^^schema:Person ;
    schema:commentCount "167"^^schema:Integer ;
    schema:dateModified "2015-12-20T21:06:23Z"^^schema:DateTime ;
    schema:datePublished "2015-06-14T13:34:10Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Reading Scene Text in Deep Convolutional Sequences"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.04395v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5124474383995369775&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1780> a schema:ScholarlyArticle ;
    schema:author "A Ku"^^schema:Person,
        "A Vaswani"^^schema:Person,
        "D Tran"^^schema:Person,
        "J Uszkoreit"^^schema:Person,
        "L Kaiser"^^schema:Person,
        "N Parmar"^^schema:Person,
        "N Shazeer"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:headline "Image Transformer."^^schema:Text ;
    schema:publisher "ICML, 4052-4061"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7958557148623619738&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1781> a schema:ScholarlyArticle ;
    schema:author "B Linares-Barranco"^^schema:Person,
        "B Zhao"^^schema:Person,
        "H Tang"^^schema:Person,
        "R Ding"^^schema:Person,
        "S Chen"^^schema:Person ;
    schema:commentCount "137"^^schema:Integer ;
    schema:headline "Feedforward Categorization on AER Motion Events Using Cortex-Like Features in a Spiking Neural Network"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 9 (26), 1963-1978"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16950295446361233061&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1782> a schema:ScholarlyArticle ;
    schema:author "B Zhang"^^schema:Person,
        "J Lam"^^schema:Person,
        "S Xu"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Stability Analysis of Distributed Delay Neural Networks Based on Relaxed Lyapunov–Krasovskii Functionals"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 7 (26), 1480-1492"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3824733761502183621&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1783> a schema:ScholarlyArticle ;
    schema:author "A Păun"^^schema:Person,
        "L Pan"^^schema:Person,
        "X Zhang"^^schema:Person ;
    schema:commentCount "146"^^schema:Integer ;
    schema:headline "On the Universality of Axon P Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (11), 2816-2829"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=963057624273124&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1784> a schema:ScholarlyArticle ;
    schema:author "L Wang"^^schema:Person,
        "S Liu"^^schema:Person,
        "Y Shi"^^schema:Person ;
    schema:commentCount "113"^^schema:Integer ;
    schema:headline "An improved fruit fly optimization algorithm and its application to joint replenishment problems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (9), 4310-4323"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13594509379426430626&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1785> a schema:ScholarlyArticle ;
    schema:author "H Kumar"^^schema:Person,
        "R Singh"^^schema:Person,
        "RK Singla"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "An intrusion detection system using network traffic profiling and online sequential extreme learning machine"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (22), 8609-8624"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10372626202332789722&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1786> a schema:ScholarlyArticle ;
    schema:author "H Jung"^^schema:Person,
        "HR Karimi"^^schema:Person,
        "JH Park"^^schema:Person,
        "Y Wei"^^schema:Person,
        "YC Tian"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "Improved Stability and Stabilization Results for Stochastic Synchronization of Continuous-Time Semi-Markovian Jump Neural Networks With Time-Varying Delay"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (6), 2488-2501"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3641021155033380643&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1787> a schema:ScholarlyArticle ;
    schema:author "A Kanade"^^schema:Person,
        "R Gupta"^^schema:Person,
        "S Pal"^^schema:Person,
        "S Shevade"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:headline "DeepFix: Fixing Common C Language Errors by Deep Learning"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11539565163167071632&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1788> a schema:ScholarlyArticle ;
    schema:author "H Zhu"^^schema:Person,
        "J Wang"^^schema:Person,
        "M Long"^^schema:Person,
        "Y Cao"^^schema:Person ;
    schema:commentCount "298"^^schema:Integer ;
    schema:headline "Deep Hashing Network for Efficient Similarity Retrieval"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11984064786314134745&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1789> a schema:ScholarlyArticle ;
    schema:author "H Li"^^schema:Person,
        "J Sun"^^schema:Person,
        "Y Yang"^^schema:Person,
        "Z Xu"^^schema:Person ;
    schema:commentCount "386"^^schema:Integer ;
    schema:headline "Deep ADMM-Net for compressive sensing MRI"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17710018232730379071&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<179> a schema:ScholarlyArticle ;
    schema:abstract "Background: Deep learning models are typically trained using stochasticgradient descent or one of its variants. These methods update the weights usingtheir gradient, estimated from a small fraction of the training data. It hasbeen observed that when using large batch sizes there is a persistentdegradation in generalization performance - known as the \"generalization gap\"phenomena. Identifying the origin of this gap and closing it had remained anopen problem.  Contributions: We examine the initial high learning rate training phase. Wefind that the weight distance from its initialization grows logarithmicallywith the number of weight updates. We therefore propose a \"random walk onrandom landscape\" statistical model which is known to exhibit similar\"ultra-slow\" diffusion behavior. Following this hypothesis we conductedexperiments to show empirically that the \"generalization gap\" stems from therelatively small number of updates rather than the batch size, and can becompletely eliminated by adapting the training regime used. We furtherinvestigate different techniques to train models in the large-batch regime andpresent a novel algorithm named \"Ghost Batch Normalization\" which enablessignificant decrease in the generalization gap without increasing the number ofupdates. To validate our findings we conduct several additional experiments onMNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practicesand beliefs concerning training of deep models and suggest they may not beoptimal to achieve good generalization."^^schema:Text ;
    schema:author "Daniel Soudry"^^schema:Person,
        "Elad Hoffer"^^schema:Person,
        "Itay Hubara"^^schema:Person ;
    schema:commentCount "280"^^schema:Integer ;
    schema:dateModified "2018-01-01T08:49:43Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T13:17:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Train longer, generalize better: closing the generalization gap in large  batch training of neural networks"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08741v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11429742229244735024&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1790> a schema:ScholarlyArticle ;
    schema:author "T Chen"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Synchronization of Linearly Coupled Networks With Delays via Aperiodically Intermittent Pinning Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2396-2407"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1285697294660458099&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1791> a schema:ScholarlyArticle ;
    schema:author "D Zhang"^^schema:Person,
        "J Yang"^^schema:Person,
        "WK Wong"^^schema:Person,
        "Y Xu"^^schema:Person,
        "Z Lai"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Approximate Orthogonal Sparse Embedding for Dimensionality Reduction"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 723-735"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3179949966120695294&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1792> a schema:ScholarlyArticle ;
    schema:author "F Shariff"^^schema:Person,
        "N Abd Rahim"^^schema:Person,
        "WP Hew"^^schema:Person ;
    schema:commentCount "125"^^schema:Integer ;
    schema:headline "Zigbee-based data acquisition system for online monitoring of grid-connected photovoltaic system"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1730-1742"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11436721211666628591&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1793> a schema:ScholarlyArticle ;
    schema:author "R Nagar"^^schema:Person,
        "V Agrawal"^^schema:Person,
        "V Chandwani"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Modeling slump of ready mix concrete using genetic algorithms assisted training of Artificial Neural Networks"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (2), 885-893"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6774928397771215886&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1794> a schema:ScholarlyArticle ;
    schema:author "M Malekipirbazari"^^schema:Person,
        "V Aksakalli"^^schema:Person ;
    schema:commentCount "208"^^schema:Integer ;
    schema:headline "Risk assessment in social lending via random forests"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (10), 4621-4631"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1089955912651827593&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1795> a schema:ScholarlyArticle ;
    schema:author "A Thyagarajan"^^schema:Person,
        "J Mueller"^^schema:Person ;
    schema:commentCount "492"^^schema:Integer ;
    schema:headline "Siamese Recurrent Architectures for Learning Sentence Similarity"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7393466935379636447&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1796> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "F Wang"^^schema:Person,
        "Y Zhang"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "156"^^schema:Integer ;
    schema:headline "Fuzzy Adaptive Quantized Control for a Class of Stochastic Nonlinear Uncertain Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 524-534"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3116623709876866730&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1797> a schema:ScholarlyArticle ;
    schema:author "M Sun"^^schema:Person,
        "X Zhu"^^schema:Person,
        "Y Lin"^^schema:Person,
        "Y Liu"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "1199"^^schema:Integer ;
    schema:headline "Learning Entity and Relation Embeddings for Knowledge Graph Completion"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2549317819510636362&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1798> a schema:ScholarlyArticle ;
    schema:author "J Cao"^^schema:Person,
        "J Luo"^^schema:Person,
        "Y Zhang"^^schema:Person,
        "Z Jin"^^schema:Person ;
    schema:commentCount "154"^^schema:Integer ;
    schema:headline "News Verification by Exploiting Conflicting Social Viewpoints in Microblogs"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12206602126613372517&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1799> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "D Ebner"^^schema:Person,
        "D Golovin"^^schema:Person,
        "D Sculley"^^schema:Person,
        "E Davydov"^^schema:Person,
        "G Holt"^^schema:Person,
        "T Phillips"^^schema:Person ;
    schema:commentCount "287"^^schema:Integer ;
    schema:headline "Hidden technical debt in Machine learning systems"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2255096949091421445&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<18> a schema:ScholarlyArticle ;
    schema:abstract "Very often data we encounter in practice is a collection of matrices ratherthan a single matrix. These multi-block data are naturally linked and henceoften share some common features and at the same time they have their ownindividual features, due to the background in which they are measured andcollected. In this study we proposed a new scheme of common and individualfeature analysis (CIFA) that processes multi-block data in a linked way aimingat discovering and separating their common and individual features. Accordingto whether the number of common features is given or not, two efficientalgorithms were proposed to extract the common basis which is shared by alldata. Then feature extraction is performed on the common and the individualspaces separately by incorporating the techniques such as dimensionalityreduction and blind source separation. We also discussed how the proposed CIFAcan significantly improve the performance of classification and clusteringtasks by exploiting common and individual features of samples respectively. Ourexperimental results show some encouraging features of the proposed methods incomparison to the state-of-the-art methods on synthetic and real data."^^schema:Text ;
    schema:author "Andrzej Cichocki"^^schema:Person,
        "Danilo Mandic"^^schema:Person,
        "Guoxu Zhou"^^schema:Person,
        "Yu Zhang"^^schema:Person ;
    schema:commentCount "113"^^schema:Integer ;
    schema:dateModified "2017-03-12T08:36:27Z"^^schema:DateTime ;
    schema:datePublished "2012-12-17T07:56:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Group Component Analysis for Multiblock Data: Common and Individual  Feature Extraction"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (11), 2426-2439"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1212.3913v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=676869504525254168&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<180> a schema:ScholarlyArticle ;
    schema:abstract "We examine the role of memorization in deep learning, drawing connections tocapacity, generalization, and adversarial robustness. While deep networks arecapable of memorizing noise data, our results suggest that they tend toprioritize learning simple patterns first. In our experiments, we exposequalitative differences in gradient-based optimization of deep neural networks(DNNs) on noise vs. real data. We also demonstrate that for appropriately tunedexplicit regularization (e.g., dropout) we can degrade DNN training performanceon noise datasets without compromising generalization on real data. Ouranalysis suggests that the notions of effective capacity which are datasetindependent are unlikely to explain the generalization performance of deepnetworks when trained with gradient based methods because training data itselfplays an important role in determining the degree of memorization."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Asja Fischer"^^schema:Person,
        "David Krueger"^^schema:Person,
        "Devansh Arpit"^^schema:Person,
        "Emmanuel Bengio"^^schema:Person,
        "Maxinder S. Kanwal"^^schema:Person,
        "Nicolas Ballas"^^schema:Person,
        "Simon Lacoste-Julien"^^schema:Person,
        "Stanisław Jastrzębski"^^schema:Person,
        "Tegan Maharaj"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "329"^^schema:Integer ;
    schema:dateModified "2017-07-01T14:26:51Z"^^schema:DateTime ;
    schema:datePublished "2017-06-16T18:11:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Closer Look at Memorization in Deep Networks"^^schema:Text ;
    schema:publisher "ICML, 233-242"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.05394v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=158427493479385371&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1800> a schema:ScholarlyArticle ;
    schema:author "H Lee"^^schema:Person,
        "K Sohn"^^schema:Person,
        "X Yan"^^schema:Person ;
    schema:commentCount "812"^^schema:Integer ;
    schema:headline "Learning structured output representation using deep conditional generative models"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12314198516266869942&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1801> a schema:ScholarlyArticle ;
    schema:author "H Yang"^^schema:Person,
        "P Shi"^^schema:Person,
        "S Yin"^^schema:Person ;
    schema:commentCount "198"^^schema:Integer ;
    schema:headline "Adaptive Fuzzy Control of Strict-Feedback Nonlinear Time-Delay Systems With Unmodeled Dynamics"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (8), 1926-1938"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9171382263000059491&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1802> a schema:ScholarlyArticle ;
    schema:author "J Wang"^^schema:Person,
        "QL Han"^^schema:Person,
        "XM Zhang"^^schema:Person ;
    schema:commentCount "158"^^schema:Integer ;
    schema:headline "Event-Triggered Generalized Dissipativity Filtering for Neural Networks With Time-Varying Delays"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (1), 77-88"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9494701550830789831&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1803> a schema:ScholarlyArticle ;
    schema:author "DP Kingma"^^schema:Person,
        "I Sutskever"^^schema:Person,
        "M Welling"^^schema:Person,
        "R Jozefowicz"^^schema:Person,
        "T Salimans"^^schema:Person,
        "X Chen"^^schema:Person ;
    schema:commentCount "751"^^schema:Integer ;
    schema:headline "Improved variational inference with inverse autoregressive flow"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9037312380498030932&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1804> a schema:ScholarlyArticle ;
    schema:author "G Tao"^^schema:Person,
        "M Chen"^^schema:Person ;
    schema:commentCount "184"^^schema:Integer ;
    schema:headline "Adaptive Fault-Tolerant Control of Uncertain Nonlinear Large-Scale Systems With Unknown Dead Zone"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (8), 1851-1862"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8006280963177040657&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1805> a schema:ScholarlyArticle ;
    schema:author "AK Nassirtoussi"^^schema:Person,
        "DCL Ngo"^^schema:Person,
        "S Aghabozorgi"^^schema:Person,
        "TY Wah"^^schema:Person ;
    schema:commentCount "182"^^schema:Integer ;
    schema:headline "Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduction Algorithm with semantics and sentiment"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (1), 306-324"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13714052265690336764&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1806> a schema:ScholarlyArticle ;
    schema:author "C Li"^^schema:Person,
        "D Tao"^^schema:Person,
        "J Yu"^^schema:Person,
        "K Zeng"^^schema:Person,
        "R Wang"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Coupled Deep Autoencoder for Single Image Super-Resolution"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (1), 27-37"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3539640316280509482&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1807> a schema:ScholarlyArticle ;
    schema:author "QL Han"^^schema:Person,
        "XM Zhang"^^schema:Person ;
    schema:commentCount "158"^^schema:Integer ;
    schema:headline "A Decentralized Event-Triggered Dissipative Control Scheme for Systems With Multiple Sensors to Sample the System Outputs"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (12), 2745-2757"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7931485594392024893&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1808> a schema:ScholarlyArticle ;
    schema:author "L Zhang"^^schema:Person,
        "P Shi"^^schema:Person,
        "Y Zhao"^^schema:Person,
        "Y Zhu"^^schema:Person ;
    schema:commentCount "155"^^schema:Integer ;
    schema:headline "Resilient Asynchronous $ H_ {\\infty} $ Filtering for Markov Jump Neural Networks With Unideal Measurements and Multiplicative Noises"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 45 (12), 2840-2852"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4177361558398379691&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1809> a schema:ScholarlyArticle ;
    schema:author "L Wang"^^schema:Person,
        "Q Liu"^^schema:Person,
        "S Wu"^^schema:Person,
        "T Tan"^^schema:Person ;
    schema:commentCount "323"^^schema:Integer ;
    schema:headline "Predicting the Next Location: A Recurrent Model with Spatial and Temporal Contexts"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15241477439538586522&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<181> a schema:ScholarlyArticle ;
    schema:abstract "Wooden blocks are a common toy for infants, allowing them to develop motorskills and gain intuition about the physical behavior of the world. In thispaper, we explore the ability of deep feed-forward models to learn suchintuitive physics. Using a 3D game engine, we create small towers of woodenblocks whose stability is randomized and render them collapsing (or remainingupright). This data allows us to train large convolutional network models whichcan accurately predict the outcome, as well as estimating the blocktrajectories. The models are also able to generalize in two important ways: (i)to new physical scenarios, e.g. towers with an additional block and (ii) toimages of real wooden blocks, where it obtains a performance comparable tohuman subjects."^^schema:Text ;
    schema:author "Adam Lerer"^^schema:Person,
        "Rob Fergus"^^schema:Person,
        "Sam Gross"^^schema:Person ;
    schema:commentCount "193"^^schema:Integer ;
    schema:dateModified "2016-03-03T22:59:35Z"^^schema:DateTime ;
    schema:datePublished "2016-03-03T22:59:35Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Learning Physical Intuition of Block Towers by Example"^^schema:Text ;
    schema:publisher "ICML, 430-438"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.01312v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12846348306706460250&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1810> a schema:ScholarlyArticle ;
    schema:author "C Gennaro"^^schema:Person,
        "C Meghini"^^schema:Person,
        "C Vairo"^^schema:Person,
        "F Carrara"^^schema:Person,
        "F Falchi"^^schema:Person,
        "G Amato"^^schema:Person ;
    schema:commentCount "120"^^schema:Integer ;
    schema:headline "Deep learning for decentralized parking lot occupancy detection"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 72, 327-334"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9841087627146390817&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1811> a schema:ScholarlyArticle ;
    schema:author "AM Dai"^^schema:Person,
        "D Ha"^^schema:Person,
        "QV Le"^^schema:Person ;
    schema:commentCount "399"^^schema:Integer ;
    schema:headline "HyperNetworks."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3668354792918495805&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1812> a schema:ScholarlyArticle ;
    schema:author "D Zhang"^^schema:Person,
        "H Xu"^^schema:Person,
        "Y Xu"^^schema:Person,
        "Z Su"^^schema:Person ;
    schema:commentCount "241"^^schema:Integer ;
    schema:headline "Chinese comments sentiment classification based on word2vec and SVMperf"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (4), 1857-1863"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4778307177781104998&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1813> a schema:ScholarlyArticle ;
    schema:author "C Lu"^^schema:Person,
        "L Liu"^^schema:Person,
        "S Wei"^^schema:Person,
        "S Yan"^^schema:Person,
        "Y Wei"^^schema:Person,
        "Y Zhao"^^schema:Person,
        "Z Zhu"^^schema:Person ;
    schema:commentCount "199"^^schema:Integer ;
    schema:headline "Cross-Modal Retrieval With CNN Visual Features: A New Baseline"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (2), 449-460"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15693985676604526859&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1814> a schema:ScholarlyArticle ;
    schema:author "P Moradi"^^schema:Person,
        "S Ahmadian"^^schema:Person ;
    schema:commentCount "120"^^schema:Integer ;
    schema:headline "A reliability-based recommendation method to improve trust-aware recommender systems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (21), 7386-7398"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3038822385361207010&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1815> a schema:ScholarlyArticle ;
    schema:author "B Luo"^^schema:Person,
        "D Liu"^^schema:Person,
        "D Wang"^^schema:Person,
        "T Huang"^^schema:Person ;
    schema:commentCount "134"^^schema:Integer ;
    schema:headline "Model-Free Optimal Tracking Control via Critic-Only Q-Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (10), 2134-2144"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9120712017652103662&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1816> a schema:ScholarlyArticle ;
    schema:author "AC Kot"^^schema:Person,
        "G Yang"^^schema:Person,
        "K Bahrami"^^schema:Person,
        "L Li"^^schema:Person,
        "W Lin"^^schema:Person,
        "X Wang"^^schema:Person ;
    schema:commentCount "155"^^schema:Integer ;
    schema:headline "No-Reference Image Blur Assessment Based on Discrete Orthogonal Moments"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 39-50"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11235338283689956658&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1817> a schema:ScholarlyArticle ;
    schema:author "DT Vo"^^schema:Person,
        "M Zhang"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:headline "Gated Neural Networks for Targeted Sentiment Analysis"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6782780671402038335&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1818> a schema:ScholarlyArticle ;
    schema:author "C Li"^^schema:Person,
        "J Guan"^^schema:Person,
        "M Yang"^^schema:Person,
        "Z Cai"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "Differential evolution with auto-enhanced population diversity."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (2), 302-315"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=18397559365580469983&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1819> a schema:ScholarlyArticle ;
    schema:author "BZ Guo"^^schema:Person,
        "JH Park"^^schema:Person,
        "SM Lee"^^schema:Person,
        "Y Liu"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Nonfragile Exponential Synchronization of Delayed Complex Dynamical Networks With Memory Sampled-Data Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (1), 118-128"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5822804504086480637&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<182> a schema:ScholarlyArticle ;
    schema:abstract "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder-decoder configuration. The bestperforming models also connect the encoder and decoder through an attentionmechanism. We propose a new simple network architecture, the Transformer, basedsolely on attention mechanisms, dispensing with recurrence and convolutionsentirely. Experiments on two machine translation tasks show these models to besuperior in quality while being more parallelizable and requiring significantlyless time to train. Our model achieves 28.4 BLEU on the WMT 2014English-to-German translation task, improving over the existing best results,including ensembles by over 2 BLEU. On the WMT 2014 English-to-Frenchtranslation task, our model establishes a new single-model state-of-the-artBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fractionof the training costs of the best models from the literature. We show that theTransformer generalizes well to other tasks by applying it successfully toEnglish constituency parsing both with large and limited training data."^^schema:Text ;
    schema:author "Aidan N. Gomez"^^schema:Person,
        "Ashish Vaswani"^^schema:Person,
        "Illia Polosukhin"^^schema:Person,
        "Jakob Uszkoreit"^^schema:Person,
        "Llion Jones"^^schema:Person,
        "Lukasz Kaiser"^^schema:Person,
        "Niki Parmar"^^schema:Person,
        "Noam Shazeer"^^schema:Person ;
    schema:commentCount "9885"^^schema:Integer ;
    schema:dateModified "2017-12-06T03:30:32Z"^^schema:DateTime ;
    schema:datePublished "2017-06-12T17:57:34Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Attention Is All You Need"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.03762v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2960712678066186980&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1820> a schema:ScholarlyArticle ;
    schema:author "GH Yang"^^schema:Person,
        "H Liang"^^schema:Person,
        "H Zhang"^^schema:Person,
        "T Feng"^^schema:Person ;
    schema:commentCount "186"^^schema:Integer ;
    schema:headline "Distributed Cooperative Optimal Control for Multiagent Systems on Directed Graphs: An Inverse Optimal Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 7 (45), 1315-1326"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4304226827036538754&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1821> a schema:ScholarlyArticle ;
    schema:author "D Soudry"^^schema:Person,
        "I Hubara"^^schema:Person,
        "M Courbariaux"^^schema:Person,
        "R El-Yaniv"^^schema:Person,
        "Y Bengio"^^schema:Person ;
    schema:commentCount "805"^^schema:Integer ;
    schema:headline "Binarized neural networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=84426770746747327&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1822> a schema:ScholarlyArticle ;
    schema:author "H Liu"^^schema:Person,
        "J Tang"^^schema:Person,
        "S Wang"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Embedded Unsupervised Feature Selection"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8442594212694157197&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1823> a schema:ScholarlyArticle ;
    schema:author "J Zhao"^^schema:Person,
        "K Liu"^^schema:Person,
        "L Xu"^^schema:Person,
        "S Lai"^^schema:Person ;
    schema:commentCount "1212"^^schema:Integer ;
    schema:headline "Recurrent Convolutional Neural Networks for Text Classification"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8378655188698848233&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1824> a schema:ScholarlyArticle ;
    schema:author "DS Modha"^^schema:Person,
        "JV Arthur"^^schema:Person,
        "PA Merolla"^^schema:Person,
        "R Appuswamy"^^schema:Person,
        "SK Esser"^^schema:Person ;
    schema:commentCount "570"^^schema:Integer ;
    schema:headline "Backpropagation for energy-efficient neuromorphic computing"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5837272204553487243&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1825> a schema:ScholarlyArticle ;
    schema:author "G Pau"^^schema:Person,
        "LL Bello"^^schema:Person,
        "M Collotta"^^schema:Person ;
    schema:commentCount "117"^^schema:Integer ;
    schema:headline "A novel approach for dynamic traffic lights management based on Wireless Sensor Networks and multiple fuzzy logic controllers"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (13), 5403-5415"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11780006366391091082&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1826> a schema:ScholarlyArticle ;
    schema:author "D Liu"^^schema:Person,
        "D Wang"^^schema:Person,
        "H He"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "Adaptive Critic Nonlinear Robust Control: A Survey"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (10), 3429-3451"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8732601032917202602&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1827> a schema:ScholarlyArticle ;
    schema:author "QL Han"^^schema:Person,
        "XM Zhang"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "State Estimation for Static Neural Networks With Time-Varying Delays Based on an Improved Reciprocally Convex Inequality"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1376-1381"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9755253657792170138&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1828> a schema:ScholarlyArticle ;
    schema:author "G Ji"^^schema:Person,
        "J Zhao"^^schema:Person,
        "K Liu"^^schema:Person,
        "S He"^^schema:Person ;
    schema:commentCount "156"^^schema:Integer ;
    schema:headline "Distant supervision for relation extraction with sentence-level attention and entity descriptions"^^schema:Text ;
    schema:publisher "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8875957119026247427&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1829> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "L Zou"^^schema:Person,
        "X Liu"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "150"^^schema:Integer ;
    schema:headline "Event-Triggered State Estimation for Complex Networks With Mixed Time Delays via Sampled Data Information: The Continuous-Time Case"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 45 (12), 2804-2815"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16339436823785785533&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<183> a schema:ScholarlyArticle ;
    schema:abstract "The popular Q-learning algorithm is known to overestimate action values undercertain conditions. It was not previously known whether, in practice, suchoverestimations are common, whether they harm performance, and whether they cangenerally be prevented. In this paper, we answer all these questionsaffirmatively. In particular, we first show that the recent DQN algorithm,which combines Q-learning with a deep neural network, suffers from substantialoverestimations in some games in the Atari 2600 domain. We then show that theidea behind the Double Q-learning algorithm, which was introduced in a tabularsetting, can be generalized to work with large-scale function approximation. Wepropose a specific adaptation to the DQN algorithm and show that the resultingalgorithm not only reduces the observed overestimations, as hypothesized, butthat this also leads to much better performance on several games."^^schema:Text ;
    schema:author "Arthur Guez"^^schema:Person,
        "David Silver"^^schema:Person,
        "Hado van Hasselt"^^schema:Person ;
    schema:commentCount "2152"^^schema:Integer ;
    schema:dateModified "2015-12-08T21:19:16Z"^^schema:DateTime ;
    schema:datePublished "2015-09-22T04:40:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning with Double Q-learning"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.06461v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=249468315505163542&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1830> a schema:ScholarlyArticle ;
    schema:author "D Fuchs-Hanusch"^^schema:Person,
        "H Shaheen"^^schema:Person,
        "LG Kaufmann"^^schema:Person,
        "S Samhan"^^schema:Person,
        "SH Zyoud"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "A framework for water loss management in developing countries under fuzzy environment: Integration of Fuzzy AHP with Fuzzy TOPSIS"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 61, 86-105"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16345244801703201488&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1831> a schema:ScholarlyArticle ;
    schema:author "N Sebe"^^schema:Person,
        "X Zhou"^^schema:Person,
        "Y Han"^^schema:Person,
        "Y Yan"^^schema:Person,
        "Y Yang"^^schema:Person,
        "Z Ma"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Semisupervised Feature Selection via Spline Regression for Video Semantic Recognition"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 2 (26), 252-264"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16642041022429140220&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1832> a schema:ScholarlyArticle ;
    schema:author "B Shen"^^schema:Person,
        "H Qiao"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "114"^^schema:Integer ;
    schema:headline "Event-Triggered State Estimation for Discrete-Time Multidelayed Neural Networks With Stochastic Parameters and Incomplete Measurements"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (5), 1152-1163"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3012052207669322614&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1833> a schema:ScholarlyArticle ;
    schema:author "J Wernsing"^^schema:Person,
        "K Laine"^^schema:Person,
        "KE Lauter"^^schema:Person,
        "M Naehrig"^^schema:Person,
        "N Dowlin"^^schema:Person,
        "R Gilad-Bachrach"^^schema:Person ;
    schema:commentCount "568"^^schema:Integer ;
    schema:headline "CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy."^^schema:Text ;
    schema:publisher "ICML, 201-210"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17010836721904772718&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1834> a schema:ScholarlyArticle ;
    schema:author "AK Qin"^^schema:Person,
        "C Zhang"^^schema:Person,
        "KC Tan"^^schema:Person,
        "P Lim"^^schema:Person ;
    schema:commentCount "190"^^schema:Integer ;
    schema:headline "Multiobjective Deep Belief Networks Ensemble for Remaining Useful Life Estimation in Prognostics"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (10), 2306-2318"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10643589135416759347&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1835> a schema:ScholarlyArticle ;
    schema:author "J Huerta"^^schema:Person,
        "J Torres-Sospedra"^^schema:Person,
        "R Montoliu"^^schema:Person,
        "S Trilles"^^schema:Person,
        "Ó Belmonte"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Comprehensive analysis of distance and similarity measures for Wi-Fi fingerprinting indoor positioning systems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (23), 9263-9278"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8131533844623605969&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1836> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "D Wang"^^schema:Person,
        "T Li"^^schema:Person,
        "Z Li"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Output-Feedback Adaptive Neural Control for Stochastic Nonlinear Time-Varying Delay Systems With Unknown Control Directions"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 6 (26), 1188-1201"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11288379275389779757&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1837> a schema:ScholarlyArticle ;
    schema:author "AMA Brifcani"^^schema:Person,
        "AS Eesa"^^schema:Person,
        "Z Orman"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:headline "A novel feature-selection approach based on the cuttlefish optimization algorithm for intrusion detection systems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2670-2679"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4241646169672762376&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1838> a schema:ScholarlyArticle ;
    schema:author "A Bordes"^^schema:Person,
        "J Weston"^^schema:Person,
        "S Chopra"^^schema:Person ;
    schema:commentCount "1187"^^schema:Integer ;
    schema:headline "Memory Networks."^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10019614527293420732&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1839> a schema:ScholarlyArticle ;
    schema:author "L Liu"^^schema:Person,
        "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "167"^^schema:Integer ;
    schema:headline "Neural Networks-Based Adaptive Finite-Time Fault-Tolerant Control for a Class of Strict-Feedback Switched Nonlinear Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 49 (7), 2536-2545"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2463883237184813717&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<184> a schema:ScholarlyArticle ;
    schema:abstract "Sequences have become first class citizens in supervised learning thanks tothe resurgence of recurrent neural networks. Many complex tasks that requiremapping from or to a sequence of observations can now be formulated with thesequence-to-sequence (seq2seq) framework which employs the chain rule toefficiently represent the joint probability of sequences. In many cases,however, variable sized inputs and/or outputs might not be naturally expressedas sequences. For instance, it is not clear how to input a set of numbers intoa model where the task is to sort them; similarly, we do not know how toorganize outputs when they correspond to random variables and the task is tomodel their unknown joint probability. In this paper, we first show usingvarious examples that the order in which we organize input and/or output datamatters significantly when learning an underlying model. We then discuss anextension of the seq2seq framework that goes beyond sequences and handles inputsets in a principled way. In addition, we propose a loss which, by searchingover possible orders during training, deals with the lack of structure ofoutput sets. We show empirical evidence of our claims regarding ordering, andon the modifications to the seq2seq framework on benchmark language modelingand parsing tasks, as well as two artificial tasks -- sorting numbers andestimating the joint probability of unknown graphical models."^^schema:Text ;
    schema:author "Manjunath Kudlur"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "346"^^schema:Integer ;
    schema:dateModified "2016-02-23T22:25:12Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T21:31:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Order Matters: Sequence to sequence for sets"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06391v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16770614183391051493&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1840> a schema:ScholarlyArticle ;
    schema:author "G Ji"^^schema:Person,
        "J Zhao"^^schema:Person,
        "K Liu"^^schema:Person,
        "S He"^^schema:Person ;
    schema:commentCount "190"^^schema:Integer ;
    schema:headline "Knowledge Graph Completion with Adaptive Sparse Transfer Matrix"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9763816683860999453&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1841> a schema:ScholarlyArticle ;
    schema:author "R Xu"^^schema:Person,
        "T Chen"^^schema:Person,
        "X Wang"^^schema:Person,
        "Y He"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:headline "Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 72, 221-230"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1186553886199606075&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1842> a schema:ScholarlyArticle ;
    schema:author "C Zhu"^^schema:Person,
        "D Tao"^^schema:Person,
        "J Yu"^^schema:Person,
        "J Zhang"^^schema:Person,
        "Q Huang"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "Spatial Pyramid-Enhanced NetVLAD With Weighted Triplet Loss for Place Recognition"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 31 (2), 661-674"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16118650295460072663&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1843> a schema:ScholarlyArticle ;
    schema:author "Y Gal"^^schema:Person,
        "Z Ghahramani"^^schema:Person ;
    schema:commentCount "1033"^^schema:Integer ;
    schema:headline "A theoretically grounded application of dropout in recurrent neural networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4962165342258626013&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1844> a schema:ScholarlyArticle ;
    schema:author "G Zhang"^^schema:Person,
        "L Wang"^^schema:Person,
        "Q Yin"^^schema:Person,
        "Y Shen"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Adaptive Synchronization of Memristor-Based Neural Networks with Time-Varying Delays."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (9), 2033-2042"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15824443148924539539&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1845> a schema:ScholarlyArticle ;
    schema:author "B Chen"^^schema:Person,
        "M Sun"^^schema:Person,
        "R Bu"^^schema:Person,
        "W Wu"^^schema:Person,
        "X Di"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "308"^^schema:Integer ;
    schema:headline "PointCNN: convolution on Χ-transformed points"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9461711858418183791&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1846> a schema:ScholarlyArticle ;
    schema:author "L Bottou"^^schema:Person,
        "M Arjovsky"^^schema:Person,
        "S Chintala"^^schema:Person ;
    schema:commentCount "4622"^^schema:Integer ;
    schema:headline "Wasserstein Generative Adversarial Networks."^^schema:Text ;
    schema:publisher "ICML, 214-223"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4029398579301306569&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1847> a schema:ScholarlyArticle ;
    schema:author "A Gal"^^schema:Person,
        "A Kolodny"^^schema:Person,
        "D Di Castro"^^schema:Person,
        "D Soudry"^^schema:Person,
        "S Kvatinsky"^^schema:Person ;
    schema:commentCount "165"^^schema:Integer ;
    schema:headline "Memristor-Based Multilayer Neural Networks With Online Gradient Descent Training"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2408-2421"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=18126746314136651091&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1848> a schema:ScholarlyArticle ;
    schema:author "JC Sun"^^schema:Person,
        "MJ Er"^^schema:Person,
        "N Wang"^^schema:Person,
        "YC Liu"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:headline "Adaptive Robust Online Constructive Fuzzy Control of a Complex Surface Vehicle System"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (7), 1511-1523"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7208956672578605470&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1849> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "309"^^schema:Integer ;
    schema:headline "Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (1), 10-24"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12338722579656817853&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<185> a schema:ScholarlyArticle ;
    schema:abstract "Despite their massive size, successful deep artificial neural networks canexhibit a remarkably small difference between training and test performance.Conventional wisdom attributes small generalization error either to propertiesof the model family, or to the regularization techniques used during training.  Through extensive systematic experiments, we show how these traditionalapproaches fail to explain why large neural networks generalize well inpractice. Specifically, our experiments establish that state-of-the-artconvolutional networks for image classification trained with stochasticgradient methods easily fit a random labeling of the training data. Thisphenomenon is qualitatively unaffected by explicit regularization, and occurseven if we replace the true images by completely unstructured random noise. Wecorroborate these experimental findings with a theoretical construction showingthat simple depth two neural networks already have perfect finite sampleexpressivity as soon as the number of parameters exceeds the number of datapoints as it usually does in practice.  We interpret our experimental findings by comparison with traditional models."^^schema:Text ;
    schema:author "Benjamin Recht"^^schema:Person,
        "Chiyuan Zhang"^^schema:Person,
        "Moritz Hardt"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "1800"^^schema:Integer ;
    schema:dateModified "2017-02-26T19:36:40Z"^^schema:DateTime ;
    schema:datePublished "2016-11-10T22:02:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Understanding deep learning requires rethinking generalization"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.03530v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4613672282544622621&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1850> a schema:ScholarlyArticle ;
    schema:author "A Kumar"^^schema:Person,
        "AK Bhandari"^^schema:Person,
        "GK Singh"^^schema:Person ;
    schema:commentCount "219"^^schema:Integer ;
    schema:headline "Modified artificial bee colony based computationally efficient multilevel thresholding for satellite image segmentation using Kapur’s, Otsu and Tsallis functions"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1573-1601"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13930977735957648438&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1851> a schema:ScholarlyArticle ;
    schema:author "L Jin"^^schema:Person,
        "S Li"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:headline "Kinematic Control of Redundant Manipulators Using Neural Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (10), 2243-2254"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11647911879858680296&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1852> a schema:ScholarlyArticle ;
    schema:author "DW Ho"^^schema:Person,
        "L Li"^^schema:Person,
        "M Liu"^^schema:Person,
        "S Chen"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "Fault-Tolerant Consensus of Multi-Agent System With Distributed Adaptive Protocol."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (10), 2142-2155"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12734685483853399459&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1853> a schema:ScholarlyArticle ;
    schema:author "AG Hauptmann"^^schema:Person,
        "X Chang"^^schema:Person,
        "Y Yang"^^schema:Person,
        "Z Ma"^^schema:Person,
        "Z Zeng"^^schema:Person ;
    schema:commentCount "188"^^schema:Integer ;
    schema:headline "Bi-Level Semantic Representation Analysis for Multimedia Event Detection"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (5), 1180-1197"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1477916441644397173&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1854> a schema:ScholarlyArticle ;
    schema:author "A Onan"^^schema:Person,
        "H Bulut"^^schema:Person,
        "S Korukoğlu"^^schema:Person ;
    schema:commentCount "156"^^schema:Integer ;
    schema:headline "Ensemble of keyword extraction methods and classifiers in text classification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 57, 232-247"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17965918767627044979&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1855> a schema:ScholarlyArticle ;
    schema:author "J Rezaei"^^schema:Person,
        "J Wang"^^schema:Person,
        "L Tavasszy"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:headline "Linking supplier development to supplier segmentation using Best Worst Method"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (23), 9152-9164"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16432206654858100222&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1856> a schema:ScholarlyArticle ;
    schema:author "A Courville"^^schema:Person,
        "J Chung"^^schema:Person,
        "K Goel"^^schema:Person,
        "K Kastner"^^schema:Person,
        "L Dinh"^^schema:Person,
        "Y Bengio"^^schema:Person ;
    schema:commentCount "550"^^schema:Integer ;
    schema:headline "A recurrent latent variable model for sequential data"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10525238791694902592&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1857> a schema:ScholarlyArticle ;
    schema:author "J Zhao"^^schema:Person,
        "L Long"^^schema:Person ;
    schema:commentCount "136"^^schema:Integer ;
    schema:headline "Adaptive Output-Feedback Neural Control of Switched Uncertain Nonlinear Systems With Average Dwell Time"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 7 (26), 1350-1362"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17648133401359697114&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1858> a schema:ScholarlyArticle ;
    schema:author "S Zhang"^^schema:Person,
        "X Li"^^schema:Person,
        "X Zhu"^^schema:Person ;
    schema:commentCount "235"^^schema:Integer ;
    schema:headline "Block-Row Sparse Multiview Multilabel Learning for Image Classification"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 450-461"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14914338184907256470&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1859> a schema:ScholarlyArticle ;
    schema:author "HF Nweke"^^schema:Person,
        "MA Al-garadi"^^schema:Person,
        "UR Alo"^^schema:Person,
        "YW Teh"^^schema:Person ;
    schema:commentCount "154"^^schema:Integer ;
    schema:headline "Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 105, 233-261"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7011933440664974992&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<186> a schema:ScholarlyArticle ;
    schema:abstract "Attention mechanisms in neural networks have proved useful for problems inwhich the input and output do not have fixed dimension. Often there existfeatures that are locally translation invariant and would be valuable fordirecting the model's attention, but previous attentional architectures are notconstructed to learn such features specifically. We introduce an attentionalneural network that employs convolution on the input tokens to detect localtime-invariant and long-range topical attention features in a context-dependentway. We apply this architecture to the problem of extreme summarization ofsource code snippets into short, descriptive function name-like summaries.Using those features, the model sequentially generates a summary bymarginalizing over two attention mechanisms: one that predicts the next summarytoken based on the attention weights of the input tokens and another that isable to copy a code token as-is directly into the summary. We demonstrate ourconvolutional attention neural network's performance on 10 popular Javaprojects showing that it achieves better performance compared to previousattentional mechanisms."^^schema:Text ;
    schema:author "Charles Sutton"^^schema:Person,
        "Hao Peng"^^schema:Person,
        "Miltiadis Allamanis"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2016-05-25T12:18:28Z"^^schema:DateTime ;
    schema:datePublished "2016-02-09T14:36:49Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SE"^^schema:Text ;
    schema:headline "A Convolutional Attention Network for Extreme Summarization of Source  Code"^^schema:Text ;
    schema:publisher "ICML, 2091-2100"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.03001v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4589077170845352419&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1860> a schema:ScholarlyArticle ;
    schema:author "H Ren"^^schema:Person,
        "M Van"^^schema:Person,
        "SS Ge"^^schema:Person ;
    schema:commentCount "135"^^schema:Integer ;
    schema:headline "Finite Time Fault Tolerant Control for Robot Manipulators Using Time Delay Estimation and Continuous Nonsingular Fast Terminal Sliding Mode Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (7), 1681-1693"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11820751544416265268&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1861> a schema:ScholarlyArticle ;
    schema:author "J Cao"^^schema:Person,
        "Q Song"^^schema:Person,
        "W Yu"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Nonsmooth Finite-Time Synchronization of Switched Coupled Neural Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (10), 2360-2371"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6878703981712376440&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1862> a schema:ScholarlyArticle ;
    schema:author "K Deb"^^schema:Person,
        "K Li"^^schema:Person,
        "Q Zhang"^^schema:Person,
        "S Kwong"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Interrelationship-Based Selection for Decomposition Multiobjective Optimization."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (10), 2076-2088"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14846630843512154654&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1863> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "G Wen"^^schema:Person,
        "YJ Liu"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "145"^^schema:Integer ;
    schema:headline "Neural Network-Based Adaptive Leader-Following Consensus Control for a Class of Nonlinear Multiagent State-Delay Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 2151-2160"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10427147211963896558&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1864> a schema:ScholarlyArticle ;
    schema:author "M Abdel-Mottaleb"^^schema:Person,
        "M Haghighat"^^schema:Person,
        "S Zonouz"^^schema:Person ;
    schema:commentCount "253"^^schema:Integer ;
    schema:headline "CloudID: Trustworthy cloud-based and cross-enterprise biometric identification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (21), 7905-7916"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5873018015820122384&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1865> a schema:ScholarlyArticle ;
    schema:author "J Pei"^^schema:Person,
        "J Wang"^^schema:Person,
        "P Cui"^^schema:Person,
        "S Yang"^^schema:Person,
        "W Zhu"^^schema:Person,
        "X Wang"^^schema:Person ;
    schema:commentCount "373"^^schema:Integer ;
    schema:headline "Community Preserving Network Embedding"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4332952790202426210&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1866> a schema:ScholarlyArticle ;
    schema:author "FL Lewis"^^schema:Person,
        "H Modares"^^schema:Person,
        "ZP Jiang"^^schema:Person ;
    schema:commentCount "175"^^schema:Integer ;
    schema:headline "${H} _ {{\\infty}} $ Tracking Control of Completely Unknown Continuous-Time Systems via Off-Policy Reinforcement Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2550-2562"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16353843156597249052&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1867> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "A Carlson"^^schema:Person,
        "E Hruschka"^^schema:Person,
        "J Betteridge"^^schema:Person,
        "P Talukdar"^^schema:Person,
        "TM Mitchell"^^schema:Person,
        "W Cohen"^^schema:Person ;
    schema:commentCount "585"^^schema:Integer ;
    schema:headline "Never-Ending Learning"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=329810162037044102&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1868> a schema:ScholarlyArticle ;
    schema:author "H Yu"^^schema:Person,
        "Z Ji"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "A New Perspective to Graphical Characterization of Multiagent Controllability"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (6), 1471-1483"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5031506133214755964&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1869> a schema:ScholarlyArticle ;
    schema:author "B Gu"^^schema:Person,
        "KY Tay"^^schema:Person,
        "S Li"^^schema:Person,
        "VS Sheng"^^schema:Person,
        "W Romano"^^schema:Person ;
    schema:commentCount "664"^^schema:Integer ;
    schema:headline "Incremental Support Vector Learning for Ordinal Regression"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 7 (26), 1403-1416"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2764746212628831504&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<187> a schema:ScholarlyArticle ;
    schema:abstract "Black box variational inference allows researchers to easily prototype andevaluate an array of models. Recent advances allow such algorithms to scale tohigh dimensions. However, a central question remains: How to specify anexpressive variational distribution that maintains efficient computation? Toaddress this, we develop hierarchical variational models (HVMs). HVMs augment avariational approximation with a prior on its parameters, which allows it tocapture complex structure for both discrete and continuous latent variables.The algorithm we develop is black box, can be used for any HVM, and has thesame computational efficiency as the original approximation. We study HVMs on avariety of deep discrete latent variable models. HVMs generalize otherexpressive variational distributions and maintains higher fidelity to theposterior."^^schema:Text ;
    schema:author "David M. Blei"^^schema:Person,
        "Dustin Tran"^^schema:Person,
        "Rajesh Ranganath"^^schema:Person ;
    schema:commentCount "181"^^schema:Integer ;
    schema:dateModified "2016-05-30T21:16:38Z"^^schema:DateTime ;
    schema:datePublished "2015-11-07T19:01:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Variational Models"^^schema:Text ;
    schema:publisher "ICML, 324-333"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.02386v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11945393107618844933&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1870> a schema:ScholarlyArticle ;
    schema:author "A Bawakid"^^schema:Person,
        "A Fernández"^^schema:Person,
        "F Herrera"^^schema:Person,
        "S Alshomrani"^^schema:Person,
        "S Elhag"^^schema:Person ;
    schema:commentCount "152"^^schema:Integer ;
    schema:headline "On the combination of genetic fuzzy systems and pairwise learning for improving detection rates on Intrusion Detection Systems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (1), 193-202"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5399943164823723217&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1871> a schema:ScholarlyArticle ;
    schema:author "A Zisserman"^^schema:Person,
        "K Kavukcuoglu"^^schema:Person,
        "K Simonyan"^^schema:Person,
        "M Jaderberg"^^schema:Person ;
    schema:commentCount "2964"^^schema:Integer ;
    schema:headline "Spatial transformer networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1662293494062093494&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1872> a schema:ScholarlyArticle ;
    schema:author "D Delen"^^schema:Person,
        "HS Kilic"^^schema:Person,
        "S Zaim"^^schema:Person ;
    schema:commentCount "165"^^schema:Integer ;
    schema:headline "Selecting “The Best” ERP system for SMEs using a combination of ANP and PROMETHEE methods"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2343-2352"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1772638473254959173&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1873> a schema:ScholarlyArticle ;
    schema:author "G Zhang"^^schema:Person,
        "Y Shen"^^schema:Person ;
    schema:commentCount "118"^^schema:Integer ;
    schema:headline "Exponential Stabilization of Memristor-based Chaotic Neural Networks with Time-Varying Delays via Intermittent Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 7 (26), 1431-1441"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15533924222633759898&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1874> a schema:ScholarlyArticle ;
    schema:author "B Chen"^^schema:Person,
        "C Lin"^^schema:Person,
        "H Wang"^^schema:Person,
        "K Liu"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "166"^^schema:Integer ;
    schema:headline "Neural-Based Adaptive Output-Feedback Control for a Class of Nonstrict-Feedback Stochastic Nonlinear Systems."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (9), 1977-1987"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13775773346794351599&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1875> a schema:ScholarlyArticle ;
    schema:author "H Zhang"^^schema:Person,
        "J Wang"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "State Estimation of Discrete-Time Takagi–Sugeno Fuzzy Systems in a Network Environment"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 8 (45), 1525-1536"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11465184284771772600&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1876> a schema:ScholarlyArticle ;
    schema:author "NT Thong"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "HIFCF: An effective hybrid model between picture fuzzy clustering and intuitionistic fuzzy recommender systems for medical diagnosis"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (7), 3682-3701"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7106057000662536788&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1877> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "A Pal"^^schema:Person,
        "C Burgess"^^schema:Person,
        "I Higgins"^^schema:Person,
        "L Matthey"^^schema:Person,
        "M Botvinick"^^schema:Person,
        "S Mohamed"^^schema:Person,
        "X Glorot"^^schema:Person ;
    schema:commentCount "1003"^^schema:Integer ;
    schema:headline "beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9898751721018572733&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1878> a schema:ScholarlyArticle ;
    schema:author "M Zong"^^schema:Person,
        "R Wang"^^schema:Person,
        "S Zhang"^^schema:Person,
        "X Li"^^schema:Person,
        "X Zhu"^^schema:Person ;
    schema:commentCount "244"^^schema:Integer ;
    schema:headline "Efficient kNN Classification With Different Numbers of Nearest Neighbors"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (5), 1774-1785"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15584223188008394238&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1879> a schema:ScholarlyArticle ;
    schema:author "B Romera-Paredes"^^schema:Person,
        "PHS Torr"^^schema:Person ;
    schema:commentCount "585"^^schema:Integer ;
    schema:headline "An embarrassingly simple approach to zero-shot learning."^^schema:Text ;
    schema:publisher "ICML, 2152-2161"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6698468073175201896&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<188> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning about language can be improved by supplying it with specificknowledge and sources of external information. We present here a new version ofthe linked open data resource ConceptNet that is particularly well suited to beused with modern NLP techniques such as word embeddings.  ConceptNet is a knowledge graph that connects words and phrases of naturallanguage with labeled edges. Its knowledge is collected from many sources thatinclude expert-created resources, crowd-sourcing, and games with a purpose. Itis designed to represent the general knowledge involved in understandinglanguage, improving natural language applications by allowing the applicationto better understand the meanings behind the words people use.  When ConceptNet is combined with word embeddings acquired from distributionalsemantics (such as word2vec), it provides applications with understanding thatthey would not acquire from distributional semantics alone, nor from narrowerresources such as WordNet or DBPedia. We demonstrate this with state-of-the-artresults on intrinsic evaluations of word relatedness that translate intoimprovements on applications of word vectors, including solving SAT-styleanalogies."^^schema:Text ;
    schema:author "Catherine Havasi"^^schema:Person,
        "Joshua Chin"^^schema:Person,
        "Robyn Speer"^^schema:Person ;
    schema:commentCount "436"^^schema:Integer ;
    schema:dateModified "2018-12-11T16:27:17Z"^^schema:DateTime ;
    schema:datePublished "2016-12-12T23:54:52Z"^^schema:DateTime ;
    schema:genre "I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.03975v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7089916805257737701&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1880> a schema:ScholarlyArticle ;
    schema:author "C Peng"^^schema:Person,
        "F Yang"^^schema:Person,
        "H Yan"^^schema:Person,
        "H Zhang"^^schema:Person,
        "X Zhan"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Event-Triggered Asynchronous Guaranteed Cost Control for Markov Jump Discrete-Time Neural Networks With Distributed Delay and Channel Fading"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (8), 3588-3598"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4025305690012897914&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1881> a schema:ScholarlyArticle ;
    schema:author "HK Chan"^^schema:Person,
        "TM Choi"^^schema:Person,
        "X Yue"^^schema:Person ;
    schema:commentCount "134"^^schema:Integer ;
    schema:headline "Recent Development in Big Data Analytics for Business Operations and Risk Management"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (1), 81-92"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14665922274578002555&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1882> a schema:ScholarlyArticle ;
    schema:author "D Ding"^^schema:Person,
        "DWC Ho"^^schema:Person,
        "G Wei"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "191"^^schema:Integer ;
    schema:headline "Observer-Based Event-Triggering Consensus Control for Multiagent Systems With Lossy Sensors and Cyber-Attacks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 1936-1947"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=997839643155472486&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1883> a schema:ScholarlyArticle ;
    schema:author "S Sui"^^schema:Person,
        "S Tong"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "293"^^schema:Integer ;
    schema:headline "Adaptive Fuzzy Control Design for Stochastic Nonlinear Switched Systems With Arbitrary Switchings and Unmodeled Dynamics"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (2), 403-414"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1762858003281955903&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1884> a schema:ScholarlyArticle ;
    schema:author "H Shen"^^schema:Person,
        "HR Karimi"^^schema:Person,
        "M Liu"^^schema:Person,
        "Y Wang"^^schema:Person,
        "Z Fang"^^schema:Person ;
    schema:commentCount "123"^^schema:Integer ;
    schema:headline "Fuzzy-Model-Based Sliding Mode Control of Nonlinear Descriptor Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 49 (9), 3409-3419"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15472531132838516556&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1885> a schema:ScholarlyArticle ;
    schema:author "J Patel"^^schema:Person,
        "K Kotecha"^^schema:Person,
        "P Thakkar"^^schema:Person,
        "S Shah"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:headline "Predicting stock market index using fusion of machine learning techniques"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (4), 2162-2172"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5574690047819775287&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1886> a schema:ScholarlyArticle ;
    schema:author "A Zhou"^^schema:Person,
        "L Jiao"^^schema:Person,
        "M Gong"^^schema:Person,
        "Q Zhang"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "124"^^schema:Integer ;
    schema:headline "Adaptive Replacement Strategies for MOEA/D"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 474-486"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7274116979586776695&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1887> a schema:ScholarlyArticle ;
    schema:author "M Jafari"^^schema:Person,
        "P Keshavarzian"^^schema:Person,
        "R Rouhi"^^schema:Person,
        "S Kasaei"^^schema:Person ;
    schema:commentCount "237"^^schema:Integer ;
    schema:headline "Benign and malignant breast tumors classification based on region growing and CNN segmentation"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 990-1002"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=192147639364955697&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1888> a schema:ScholarlyArticle ;
    schema:author "C Deng"^^schema:Person,
        "GB Huang"^^schema:Person,
        "J Tang"^^schema:Person ;
    schema:commentCount "773"^^schema:Integer ;
    schema:headline "Extreme Learning Machine for Multilayer Perceptron"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 809-821"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2125964462288063748&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1889> a schema:ScholarlyArticle ;
    schema:author "G Wei"^^schema:Person,
        "L Wang"^^schema:Person,
        "T Huang"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "136"^^schema:Integer ;
    schema:headline "An Event-Triggered Approach to State Estimation for a Class of Complex Networks With Mixed Time Delays and Nonlinearities"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (11), 2497-2508"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13589341840243987506&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<189> a schema:ScholarlyArticle ;
    schema:abstract "Many image-to-image translation problems are ambiguous, as a single inputimage may correspond to multiple possible outputs. In this work, we aim tomodel a \\emph{distribution} of possible outputs in a conditional generativemodeling setting. The ambiguity of the mapping is distilled in alow-dimensional latent vector, which can be randomly sampled at test time. Agenerator learns to map the given input, combined with this latent code, to theoutput. We explicitly encourage the connection between output and the latentcode to be invertible. This helps prevent a many-to-one mapping from the latentcode to the output during training, also known as the problem of mode collapse,and produces more diverse results. We explore several variants of this approachby employing different training objectives, network architectures, and methodsof injecting the latent code. Our proposed method encourages bijectiveconsistency between the latent encoding and output modes. We present asystematic comparison of our method and other variants on both perceptualrealism and diversity."^^schema:Text ;
    schema:author "Alexei A. Efros"^^schema:Person,
        "Deepak Pathak"^^schema:Person,
        "Eli Shechtman"^^schema:Person,
        "Jun-Yan Zhu"^^schema:Person,
        "Oliver Wang"^^schema:Person,
        "Richard Zhang"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:commentCount "504"^^schema:Integer ;
    schema:dateModified "2018-10-24T00:29:43Z"^^schema:DateTime ;
    schema:datePublished "2017-11-30T18:59:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Toward Multimodal Image-to-Image Translation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.11586v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4719212061533508568&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1890> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "J Qin"^^schema:Person,
        "WX Zheng"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "Exponential synchronization of complex networks of linear systems and nonlinear oscillators: a unified analysis."^^schema:Text ;
    schema:publisher "Ieee Transactions on Neural Networks and Learning Systems 26 (3), 510-521"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6862817924800592149&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1891> a schema:ScholarlyArticle ;
    schema:author "P Liu"^^schema:Person,
        "SM Chen"^^schema:Person ;
    schema:commentCount "152"^^schema:Integer ;
    schema:headline "Group Decision Making Based on Heronian Aggregation Operators of Intuitionistic Fuzzy Numbers"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (9), 2514-2530"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13147657578130841460&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1892> a schema:ScholarlyArticle ;
    schema:author "A Agarwal"^^schema:Person,
        "AM Rather"^^schema:Person,
        "VN Sastry"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:headline "Recurrent neural network and a hybrid model for prediction of stock returns"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (6), 3234-3241"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4289742962730382651&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1893> a schema:ScholarlyArticle ;
    schema:author "S Mei"^^schema:Person,
        "X Zhu"^^schema:Person ;
    schema:commentCount "181"^^schema:Integer ;
    schema:headline "Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16406613591482521678&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1894> a schema:ScholarlyArticle ;
    schema:author "J Guo"^^schema:Person,
        "J Xu"^^schema:Person,
        "L Pang"^^schema:Person,
        "S Wan"^^schema:Person,
        "X Cheng"^^schema:Person,
        "Y Lan"^^schema:Person ;
    schema:commentCount "169"^^schema:Integer ;
    schema:headline "A deep architecture for semantic matching with multiple positional sentence representations"^^schema:Text ;
    schema:publisher "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12938996117084767484&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1895> a schema:ScholarlyArticle ;
    schema:author "J Gao"^^schema:Person,
        "L Wu"^^schema:Person,
        "X Li"^^schema:Person,
        "Y Wang"^^schema:Person ;
    schema:commentCount "114"^^schema:Integer ;
    schema:headline "Deep Attention-Based Spatially Recursive Networks for Fine-Grained Visual Recognition"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 49 (5), 1791-1802"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8045641560495271436&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1896> a schema:ScholarlyArticle ;
    schema:author "P Zhao"^^schema:Person,
        "T Zhang"^^schema:Person ;
    schema:commentCount "220"^^schema:Integer ;
    schema:headline "Stochastic Optimization with Importance Sampling for Regularized Loss Minimization."^^schema:Text ;
    schema:publisher "ICML, 1-9"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7983301616188342677&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1897> a schema:ScholarlyArticle ;
    schema:author "C Yan"^^schema:Person,
        "H Chen"^^schema:Person,
        "J Han"^^schema:Person,
        "N Liu"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "CNNs-Based RGB-D Saliency Detection via Cross-View Transfer and Multiview Fusion"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (11), 3171-3183"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13247944529361241789&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1898> a schema:ScholarlyArticle ;
    schema:author "B Chen"^^schema:Person,
        "C Lin"^^schema:Person,
        "H Zhang"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Observer-Based Adaptive Neural Network Control for Nonlinear Systems in Nonstrict-Feedback Form"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (1), 89-98"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1007201937945294398&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1899> a schema:ScholarlyArticle ;
    schema:author "M Elhoseny"^^schema:Person,
        "MK Hassan"^^schema:Person,
        "N Metawa"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Genetic algorithm based model for optimizing bank lending decisions"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 80, 75-82"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10466581818615935063&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<19> a schema:ScholarlyArticle ;
    schema:abstract "Rectified linear activation units are important components forstate-of-the-art deep convolutional networks. In this paper, we propose a novelS-shaped rectified linear activation unit (SReLU) to learn both convex andnon-convex functions, imitating the multiple function forms given by the twofundamental laws, namely the Webner-Fechner law and the Stevens law, inpsychophysics and neural sciences. Specifically, SReLU consists of threepiecewise linear functions, which are formulated by four learnable parameters.The SReLU is learned jointly with the training of the whole deep networkthrough back propagation. During the training phase, to initialize SReLU indifferent layers, we propose a \"freezing\" method to degenerate SReLU into apredefined leaky rectified linear unit in the initial several training epochsand then adaptively learn the good initial values. SReLU can be universallyused in the existing deep networks with negligible additional parameters andcomputation cost. Experiments with two popular CNN architectures, Network inNetwork and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100,MNIST and ImageNet demonstrate that SReLU achieves remarkable improvementcompared to other activation functions."^^schema:Text ;
    schema:author "Chunyan Xu"^^schema:Person,
        "Jiashi Feng"^^schema:Person,
        "Junjun Xiong"^^schema:Person,
        "Shuicheng Yan"^^schema:Person,
        "Xiaojie Jin"^^schema:Person,
        "Yunchao Wei"^^schema:Person ;
    schema:commentCount "147"^^schema:Integer ;
    schema:dateModified "2015-12-22T10:54:26Z"^^schema:DateTime ;
    schema:datePublished "2015-12-22T10:54:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Learning with S-shaped Rectified Linear Activation Units"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1512.07030v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4300961428502272386&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<190> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a technique for augmenting neural text-to-speech (TTS) withlowdimensional trainable speaker embeddings to generate different voices from asingle model. As a starting point, we show improvements over the twostate-ofthe-art approaches for single-speaker neural TTS: Deep Voice 1 andTacotron. We introduce Deep Voice 2, which is based on a similar pipeline withDeep Voice 1, but constructed with higher performance building blocks anddemonstrates a significant audio quality improvement over Deep Voice 1. Weimprove Tacotron by introducing a post-processing neural vocoder, anddemonstrate a significant audio quality improvement. We then demonstrate ourtechnique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotronon two multi-speaker TTS datasets. We show that a single neural TTS system canlearn hundreds of unique voices from less than half an hour of data perspeaker, while achieving high audio quality synthesis and preserving thespeaker identities almost perfectly."^^schema:Text ;
    schema:author "Andrew Gibiansky"^^schema:Person,
        "Gregory Diamos"^^schema:Person,
        "John Miller"^^schema:Person,
        "Jonathan Raiman"^^schema:Person,
        "Kainan Peng"^^schema:Person,
        "Sercan Arik"^^schema:Person,
        "Wei Ping"^^schema:Person,
        "Yanqi Zhou"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:dateModified "2017-09-20T21:43:18Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T19:53:13Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Deep Voice 2: Multi-Speaker Neural Text-to-Speech"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08947v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=188402189689268087&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1900> a schema:ScholarlyArticle ;
    schema:author "K Bagherifard"^^schema:Person,
        "M Nilashi"^^schema:Person,
        "O Ibrahim"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "A recommender system based on collaborative filtering using ontology and dimensionality reduction techniques"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 92, 507-520"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14913552589391403705&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1901> a schema:ScholarlyArticle ;
    schema:author "HC Liu"^^schema:Person,
        "JX You"^^schema:Person,
        "L Zhen"^^schema:Person,
        "XY You"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Group multi-criteria supplier selection using an extended VIKOR method with interval 2-tuple linguistic information"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (4), 1906-1916"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14265110973220780868&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1902> a schema:ScholarlyArticle ;
    schema:author "A Del Bimbo"^^schema:Person,
        "H Wannous"^^schema:Person,
        "M Daoudi"^^schema:Person,
        "M Devanne"^^schema:Person,
        "P Pala"^^schema:Person,
        "S Berretti"^^schema:Person ;
    schema:commentCount "234"^^schema:Integer ;
    schema:headline "3-D Human Action Recognition by Shape Analysis of Motion Trajectories on Riemannian Manifold"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 7 (45), 1340-1352"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1018900164006669486&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1903> a schema:ScholarlyArticle ;
    schema:author "E Duman"^^schema:Person,
        "N Mahmoudi"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "Detecting credit card fraud by Modified Fisher Discriminant Analysis"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2510-2516"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10666304175933786324&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1904> a schema:ScholarlyArticle ;
    schema:author "A Agrawal"^^schema:Person,
        "A Tripathy"^^schema:Person,
        "SK Rath"^^schema:Person ;
    schema:commentCount "283"^^schema:Integer ;
    schema:headline "Classification of sentiment reviews using n-gram machine learning approach"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 57, 117-126"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5806018994178099141&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1905> a schema:ScholarlyArticle ;
    schema:author "J Xu"^^schema:Person,
        "Z Wu"^^schema:Person ;
    schema:commentCount "181"^^schema:Integer ;
    schema:headline "Possibility Distribution-Based Approach for MAGDM With Hesitant Fuzzy Linguistic Information"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (3), 694-705"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1403102258965219839&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1906> a schema:ScholarlyArticle ;
    schema:author "T Chen"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "148"^^schema:Integer ;
    schema:headline "Synchronization of Nonlinear Coupled Networks via Aperiodically Intermittent Pinning Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 1 (26), 113-126"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6800180454777918681&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1907> a schema:ScholarlyArticle ;
    schema:author "C Wu"^^schema:Person,
        "H Li"^^schema:Person,
        "P Shi"^^schema:Person,
        "Y Gao"^^schema:Person ;
    schema:commentCount "242"^^schema:Integer ;
    schema:headline "Control of Nonlinear Networked Systems With Packet Dropouts: Interval Type-2 Fuzzy Model-Based Approach."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (11), 2378-2389"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14355056941040475293&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1908> a schema:ScholarlyArticle ;
    schema:author "C Guestrin"^^schema:Person,
        "MT Ribeiro"^^schema:Person,
        "S Singh"^^schema:Person ;
    schema:commentCount "330"^^schema:Integer ;
    schema:headline "Anchors: High-Precision Model-Agnostic Explanations"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12826941566394980167&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1909> a schema:ScholarlyArticle ;
    schema:author "QL Han"^^schema:Person,
        "X Ge"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:headline "A Dynamic Event-Triggered Transmission Scheme for Distributed Set-Membership Estimation Over Wireless Sensor Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 49 (1), 171-183"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10391333880524434606&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<191> a schema:ScholarlyArticle ;
    schema:abstract "Note: This paper describes an older version of DeepLIFT. Seehttps://arxiv.org/abs/1704.02685 for the newer version. Original abstractfollows: The purported \"black box\" nature of neural networks is a barrier toadoption in applications where interpretability is essential. Here we presentDeepLIFT (Learning Important FeaTures), an efficient and effective method forcomputing importance scores in a neural network. DeepLIFT compares theactivation of each neuron to its 'reference activation' and assignscontribution scores according to the difference. We apply DeepLIFT to modelstrained on natural images and genomic data, and show significant advantagesover gradient-based methods."^^schema:Text ;
    schema:author "Anna Shcherbina"^^schema:Person,
        "Anshul Kundaje"^^schema:Person,
        "Avanti Shrikumar"^^schema:Person,
        "Peyton Greenside"^^schema:Person ;
    schema:commentCount "605"^^schema:Integer ;
    schema:dateModified "2017-04-11T15:58:48Z"^^schema:DateTime ;
    schema:datePublished "2016-05-05T19:52:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Not Just a Black Box: Learning Important Features Through Propagating  Activation Differences"^^schema:Text ;
    schema:publisher "ICML, 3145-3153"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.01713v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3870608604214378324&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1910> a schema:ScholarlyArticle ;
    schema:author "Q Xu"^^schema:Person,
        "S Cao"^^schema:Person,
        "W Lu"^^schema:Person ;
    schema:commentCount "415"^^schema:Integer ;
    schema:headline "Deep Neural Networks for Learning Graph Representations"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10937373648312619979&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1911> a schema:ScholarlyArticle ;
    schema:author "E Herrera-Viedma"^^schema:Person,
        "Y Dong"^^schema:Person ;
    schema:commentCount "203"^^schema:Integer ;
    schema:headline "Consistency-Driven Automatic Methodology to Set Interval Numerical Scales of 2-Tuple Linguistic Term Sets and Its Use in the Linguistic GDM With Preference Relation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 4 (45), 780-792"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17640189425556392503&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1912> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "C Case"^^schema:Person,
        "D Amodei"^^schema:Person,
        "E Battenberg"^^schema:Person,
        "J Bai"^^schema:Person,
        "R Anubhai"^^schema:Person,
        "S Ananthanarayanan"^^schema:Person ;
    schema:commentCount "1545"^^schema:Integer ;
    schema:headline "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin."^^schema:Text ;
    schema:publisher "ICML, 173-182"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16030706496972570658&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1913> a schema:ScholarlyArticle ;
    schema:author "J Lin"^^schema:Person,
        "Q Wang"^^schema:Person,
        "Y Yuan"^^schema:Person ;
    schema:commentCount "284"^^schema:Integer ;
    schema:headline "Salient Band Selection for Hyperspectral Image Classification via Manifold Ranking"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (6), 1279-1289"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11558011264446474319&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1914> a schema:ScholarlyArticle ;
    schema:author "L Mou"^^schema:Person,
        "X Lu"^^schema:Person,
        "Y Yuan"^^schema:Person ;
    schema:commentCount "156"^^schema:Integer ;
    schema:headline "Scene Recognition by Manifold Regularized Deep Learning Architecture"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2222-2233"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4950291363653408310&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1915> a schema:ScholarlyArticle ;
    schema:author "H Yoo"^^schema:Person,
        "J Son"^^schema:Person,
        "K Sohn"^^schema:Person,
        "S Kim"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Real-time illumination invariant lane detection for lane departure warning system"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (4), 1816-1824"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13703326183975522198&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1916> a schema:ScholarlyArticle ;
    schema:author "B Jiang"^^schema:Person,
        "G Tao"^^schema:Person,
        "M Chen"^^schema:Person ;
    schema:commentCount "218"^^schema:Integer ;
    schema:headline "Dynamic Surface Control Using Neural Networks for a Class of Uncertain Nonlinear Systems With Input Saturation."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (9), 2086-2097"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1894621650203909358&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1917> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "A Stooke"^^schema:Person,
        "D Foote"^^schema:Person,
        "H Tang"^^schema:Person,
        "J Schulman"^^schema:Person,
        "R Houthooft"^^schema:Person,
        "X Chen"^^schema:Person,
        "Y Duan"^^schema:Person ;
    schema:commentCount "273"^^schema:Integer ;
    schema:headline "# Exploration: a study of count-based exploration for deep reinforcement learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7719009312505331345&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1918> a schema:ScholarlyArticle ;
    schema:author "E Cambria"^^schema:Person,
        "F Bisio"^^schema:Person,
        "J Fu"^^schema:Person,
        "S Poria"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:headline "AffectiveSpace 2: Enabling Affective Intuition for Concept-Level Sentiment Analysis"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1320774165426099803&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1919> a schema:ScholarlyArticle ;
    schema:author "G Ke"^^schema:Person,
        "Q Meng"^^schema:Person,
        "Q Ye"^^schema:Person,
        "T Finley"^^schema:Person,
        "T Wang"^^schema:Person,
        "TY Liu"^^schema:Person,
        "W Chen"^^schema:Person,
        "W Ma"^^schema:Person ;
    schema:commentCount "1059"^^schema:Integer ;
    schema:headline "LightGBM: a highly efficient gradient boosting decision tree"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4012588654259138758&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<192> a schema:ScholarlyArticle ;
    schema:abstract "Sentiment analysis of online user generated content is important for manysocial media analytics tasks. Researchers have largely relied on textualsentiment analysis to develop systems to predict political elections, measureeconomic indicators, and so on. Recently, social media users are increasinglyusing images and videos to express their opinions and share their experiences.Sentiment analysis of such large scale visual content can help better extractuser sentiments toward events or topics, such as those in image tweets, so thatprediction of sentiment from visual content is complementary to textualsentiment analysis. Motivated by the needs in leveraging large scale yet noisytraining data to solve the extremely challenging problem of image sentimentanalysis, we employ Convolutional Neural Networks (CNN). We first design asuitable CNN architecture for image sentiment analysis. We obtain half amillion training samples by using a baseline sentiment algorithm to labelFlickr images. To make use of such noisy machine labeled data, we employ aprogressive strategy to fine-tune the deep network. Furthermore, we improve theperformance on Twitter images by inducing domain transfer with a small numberof manually labeled Twitter images. We have conducted extensive experiments onmanually labeled Twitter images. The results show that the proposed CNN canachieve better performance in image sentiment analysis than competingalgorithms."^^schema:Text ;
    schema:author "Hailin Jin"^^schema:Person,
        "Jianchao Yang"^^schema:Person,
        "Jiebo Luo"^^schema:Person,
        "Quanzeng You"^^schema:Person ;
    schema:commentCount "309"^^schema:Integer ;
    schema:dateModified "2015-09-20T18:36:01Z"^^schema:DateTime ;
    schema:datePublished "2015-09-20T18:36:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Robust Image Sentiment Analysis Using Progressively Trained and Domain  Transferred Deep Networks"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.06041v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5622309859830710042&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1920> a schema:ScholarlyArticle ;
    schema:author "AK Kar"^^schema:Person ;
    schema:commentCount "215"^^schema:Integer ;
    schema:headline "Bio inspired computing–A review of algorithms and scope of applications"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 59, 20-32"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17772216584656035140&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1921> a schema:ScholarlyArticle ;
    schema:author "D Hazarika"^^schema:Person,
        "E Cambria"^^schema:Person,
        "K Kwok"^^schema:Person,
        "S Poria"^^schema:Person ;
    schema:commentCount "161"^^schema:Integer ;
    schema:headline "SenticNet 5: Discovering Conceptual Primitives for Sentiment Analysis by Means of Context Embeddings"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2647844372778796373&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1922> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "DA Clifton"^^schema:Person,
        "M Ghassemi"^^schema:Person,
        "MAF Pimentel"^^schema:Person,
        "T Brennan"^^schema:Person,
        "T Naumann"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:headline "A Multivariate Timeseries Modeling Approach to Severity of Illness Assessment and Forecasting in ICU with Sparse, Heterogeneous Clinical Data"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10338394070643862926&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1923> a schema:ScholarlyArticle ;
    schema:author "H Chang"^^schema:Person,
        "Q Zhou"^^schema:Person,
        "T Wei"^^schema:Person,
        "X Bao"^^schema:Person,
        "Y Lu"^^schema:Person ;
    schema:commentCount "201"^^schema:Integer ;
    schema:headline "A semantic approach for text clustering using WordNet and lexical chains"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (4), 2264-2275"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11838841453951955503&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1924> a schema:ScholarlyArticle ;
    schema:author "JH Chen"^^schema:Person,
        "SM Liu"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:headline "A multi-label classification based approach for sentiment classification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1083-1093"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2674218564403525023&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1925> a schema:ScholarlyArticle ;
    schema:author "M Neumann"^^schema:Person,
        "M Zhang"^^schema:Person,
        "Y Chen"^^schema:Person,
        "Z Cui"^^schema:Person ;
    schema:commentCount "251"^^schema:Integer ;
    schema:headline "An End-to-End Deep Learning Architecture for Graph Classification"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5160204402278921313&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1926> a schema:ScholarlyArticle ;
    schema:author "C Chen"^^schema:Person,
        "CLP Chen"^^schema:Person,
        "Y Zhang"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "Adaptive Neural Control for Dual-Arm Coordination of Humanoid Robot With Unknown Nonlinearities in Output Mechanism"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 3 (45), 521-532"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6546176757066961639&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1927> a schema:ScholarlyArticle ;
    schema:author "H Guo"^^schema:Person,
        "P Sobhani"^^schema:Person,
        "XD Zhu"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:headline "Long Short-Term Memory Over Recursive Structures."^^schema:Text ;
    schema:publisher "ICML, 1604-1612"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15043878037627773482&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1928> a schema:ScholarlyArticle ;
    schema:author "F Nie"^^schema:Person,
        "G Cai"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Multi-View Clustering and Semi-Supervised Classification with Adaptive Neighbours"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11092209194439560843&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1929> a schema:ScholarlyArticle ;
    schema:author "H He"^^schema:Person,
        "X Zhong"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "An Event-Triggered ADP Control Approach for Continuous-Time System With Unknown Internal States"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (3), 683-694"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14584711198222530654&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<193> a schema:ScholarlyArticle ;
    schema:abstract "Several recently proposed stochastic optimization methods that have beensuccessfully used in training deep networks such as RMSProp, Adam, Adadelta,Nadam are based on using gradient updates scaled by square roots of exponentialmoving averages of squared past gradients. In many applications, e.g. learningwith large output spaces, it has been empirically observed that thesealgorithms fail to converge to an optimal solution (or a critical point innonconvex settings). We show that one cause for such failures is theexponential moving average used in the algorithms. We provide an explicitexample of a simple convex optimization setting where Adam does not converge tothe optimal solution, and describe the precise problems with the previousanalysis of Adam algorithm. Our analysis suggests that the convergence issuescan be fixed by endowing such algorithms with `long-term memory' of pastgradients, and propose new variants of the Adam algorithm which not only fixthe convergence issues but often also lead to improved empirical performance."^^schema:Text ;
    schema:author "Sanjiv Kumar"^^schema:Person,
        "Sashank J. Reddi"^^schema:Person,
        "Satyen Kale"^^schema:Person ;
    schema:commentCount "732"^^schema:Integer ;
    schema:dateModified "2019-04-19T16:21:38Z"^^schema:DateTime ;
    schema:datePublished "2019-04-19T16:21:38Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Convergence of Adam and Beyond"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1904.09237v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7572152545124305671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1930> a schema:ScholarlyArticle ;
    schema:author "J He"^^schema:Person,
        "MU Rafique"^^schema:Person,
        "S Li"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "149"^^schema:Integer ;
    schema:headline "Distributed Recurrent Neural Networks for Cooperative Control of Manipulators: A Game-Theoretic Perspective"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (2), 415-426"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15650509318957547127&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1931> a schema:ScholarlyArticle ;
    schema:author "C Xiong"^^schema:Person,
        "JJ Corso"^^schema:Person,
        "R Xu"^^schema:Person,
        "W Chen"^^schema:Person ;
    schema:commentCount "166"^^schema:Integer ;
    schema:headline "Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15513282862635843496&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1932> a schema:ScholarlyArticle ;
    schema:author "C Sun"^^schema:Person,
        "W He"^^schema:Person,
        "Y Chen"^^schema:Person,
        "Z Yan"^^schema:Person ;
    schema:commentCount "162"^^schema:Integer ;
    schema:headline "Adaptive Neural Network Control of a Flapping Wing Micro Aerial Vehicle With Disturbance Observer"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (10), 3452-3465"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13987412977677608996&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1933> a schema:ScholarlyArticle ;
    schema:author "A Berneshawi"^^schema:Person,
        "H Ma"^^schema:Person,
        "K Kundu"^^schema:Person,
        "R Urtasun"^^schema:Person,
        "S Fidler"^^schema:Person,
        "X Chen"^^schema:Person,
        "Y Zhu"^^schema:Person ;
    schema:commentCount "410"^^schema:Integer ;
    schema:headline "3D object proposals for accurate object class detection"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12121681220904012842&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1934> a schema:ScholarlyArticle ;
    schema:author "W Li"^^schema:Person,
        "W Xu"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Granular Computing Approach to Two-Way Learning Based on Formal Concept Analysis in Fuzzy Datasets."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 46 (2), 366-379"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5097152900186597309&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1935> a schema:ScholarlyArticle ;
    schema:author "GE Hinton"^^schema:Person,
        "N Frosst"^^schema:Person,
        "S Sabour"^^schema:Person ;
    schema:commentCount "314"^^schema:Integer ;
    schema:headline "Matrix capsules with EM routing."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16246220969925140156&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1936> a schema:ScholarlyArticle ;
    schema:author "J Adamowski"^^schema:Person,
        "MAK Fasaee"^^schema:Person,
        "MR Nikoo"^^schema:Person,
        "S Monghasemi"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "A novel multi criteria decision making model for optimizing time–cost–quality trade-off problems in construction projects"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (6), 3089-3104"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8227482553081377819&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1937> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "J Qin"^^schema:Person,
        "W Fu"^^schema:Person,
        "WX Zheng"^^schema:Person ;
    schema:commentCount "137"^^schema:Integer ;
    schema:headline "Distributed $ k $-Means Algorithm and Fuzzy $ c $-Means Algorithm for Sensor Networks Based on Multiagent Consensus Theory"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (3), 772-783"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12517159062348397859&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1938> a schema:ScholarlyArticle ;
    schema:author "D Prokhorov"^^schema:Person,
        "D Tao"^^schema:Person,
        "J Li"^^schema:Person,
        "X Mei"^^schema:Person ;
    schema:commentCount "207"^^schema:Integer ;
    schema:headline "Deep Neural Network for Structural Prediction and Lane Detection in Traffic Scene"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (3), 690-703"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13243454595888907305&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1939> a schema:ScholarlyArticle ;
    schema:author "E Altman"^^schema:Person,
        "F Barboza"^^schema:Person,
        "H Kimura"^^schema:Person ;
    schema:commentCount "174"^^schema:Integer ;
    schema:headline "Machine learning models and bankruptcy prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 83, 405-417"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10116388326909794276&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<194> a schema:ScholarlyArticle ;
    schema:abstract "We use multilayer Long Short Term Memory (LSTM) networks to learnrepresentations of video sequences. Our model uses an encoder LSTM to map aninput sequence into a fixed length representation. This representation isdecoded using single or multiple decoder LSTMs to perform different tasks, suchas reconstructing the input sequence, or predicting the future sequence. Weexperiment with two kinds of input sequences - patches of image pixels andhigh-level representations (\"percepts\") of video frames extracted using apretrained convolutional net. We explore different design choices such aswhether the decoder LSTMs should condition on the generated output. We analyzethe outputs of the model qualitatively to see how well the model canextrapolate the learned video representation into the future and into the past.We try to visualize and interpret the learned features. We stress test themodel by running it on longer time scales and on out-of-domain data. We furtherevaluate the representations by finetuning them for a supervised learningproblem - human action recognition on the UCF-101 and HMDB-51 datasets. We showthat the representations help improve classification accuracy, especially whenthere are only a few training examples. Even models pretrained on unrelateddatasets (300 hours of YouTube videos) can help action recognition performance."^^schema:Text ;
    schema:author "Elman Mansimov"^^schema:Person,
        "Nitish Srivastava"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person ;
    schema:commentCount "1486"^^schema:Integer ;
    schema:dateModified "2016-01-04T00:42:07Z"^^schema:DateTime ;
    schema:datePublished "2015-02-16T20:00:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Unsupervised Learning of Video Representations using LSTMs"^^schema:Text ;
    schema:publisher "ICML, 843-852"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.04681v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6890473943204323716&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1940> a schema:ScholarlyArticle ;
    schema:author "A Hanjalic"^^schema:Person,
        "HT Shen"^^schema:Person,
        "J Song"^^schema:Person,
        "L Gao"^^schema:Person,
        "X Li"^^schema:Person,
        "Y Guo"^^schema:Person ;
    schema:commentCount "110"^^schema:Integer ;
    schema:headline "From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 30 (10), 3047-3058"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3912146026729323710&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1941> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "G Gordon"^^schema:Person,
        "JJ Lee"^^schema:Person,
        "JK Westlund"^^schema:Person,
        "L Plummer"^^schema:Person,
        "M Martinez"^^schema:Person,
        "S Spaulding"^^schema:Person ;
    schema:commentCount "159"^^schema:Integer ;
    schema:headline "Affective Personalization of a Social Robot Tutor for Children’s Second Language Skills"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2271258327186632686&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1942> a schema:ScholarlyArticle ;
    schema:author "S Jiang"^^schema:Person,
        "S Yang"^^schema:Person ;
    schema:commentCount "124"^^schema:Integer ;
    schema:headline "An Improved Multiobjective Optimization Evolutionary Algorithm Based on Decomposition for Complex Pareto Fronts"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 421-437"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2473636149526740708&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1943> a schema:ScholarlyArticle ;
    schema:author "MC Zhou"^^schema:Person,
        "Q Zhu"^^schema:Person,
        "S Li"^^schema:Person,
        "X Luo"^^schema:Person,
        "Y Xia"^^schema:Person,
        "Z You"^^schema:Person ;
    schema:commentCount "164"^^schema:Integer ;
    schema:headline "A Nonnegative Latent Factor Model for Large-Scale Sparse Matrices in Recommender Systems via Alternating Direction Method"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (3), 579-592"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8877990254295045212&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1944> a schema:ScholarlyArticle ;
    schema:author "Q Meng"^^schema:Person,
        "S Wen"^^schema:Person,
        "T Huang"^^schema:Person,
        "W Yao"^^schema:Person,
        "Z Zeng"^^schema:Person ;
    schema:commentCount "157"^^schema:Integer ;
    schema:headline "Lag Synchronization of Switched Neural Networks via Neural Activation Function and Applications in Image Encryption"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (7), 1493-1502"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7162944831391977659&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1945> a schema:ScholarlyArticle ;
    schema:author "AK Uysal"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "An improved global feature selection scheme for text classification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 43, 82-92"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8401090338451651341&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1946> a schema:ScholarlyArticle ;
    schema:author "X Chang"^^schema:Person,
        "Y Yang"^^schema:Person ;
    schema:commentCount "183"^^schema:Integer ;
    schema:headline "Semisupervised Feature Analysis by Mining Correlations Among Multiple Tasks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (10), 2294-2305"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10480569232565234830&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1947> a schema:ScholarlyArticle ;
    schema:author "AG Hauptmann"^^schema:Person,
        "D Meng"^^schema:Person,
        "L Jiang"^^schema:Person,
        "Q Zhao"^^schema:Person,
        "S Shan"^^schema:Person ;
    schema:commentCount "239"^^schema:Integer ;
    schema:headline "Self-Paced Curriculum Learning"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=18285916768943681789&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1948> a schema:ScholarlyArticle ;
    schema:author "CK Zhang"^^schema:Person,
        "L Jiang"^^schema:Person,
        "M Wu"^^schema:Person,
        "Y He"^^schema:Person ;
    schema:commentCount "154"^^schema:Integer ;
    schema:headline "Stability Analysis for Delayed Neural Networks Considering Both Conservativeness and Complexity"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (7), 1486-1501"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17734636100300723650&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1949> a schema:ScholarlyArticle ;
    schema:author "F Nie"^^schema:Person,
        "H Huang"^^schema:Person,
        "MI Jordan"^^schema:Person,
        "X Wang"^^schema:Person ;
    schema:commentCount "238"^^schema:Integer ;
    schema:headline "The Constrained Laplacian Rank Algorithm for Graph-Based Clustering"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9090176298376935918&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<195> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have achieved impressive supervised classificationperformance in many tasks including image recognition, speech recognition, andsequence to sequence learning. However, this success has not been translated toapplications like question answering that may involve complex arithmetic andlogic reasoning. A major limitation of these models is in their inability tolearn even simple arithmetic and logic operations. For example, it has beenshown that neural networks fail to learn to add two binary numbers reliably. Inthis work, we propose Neural Programmer, an end-to-end differentiable neuralnetwork augmented with a small set of basic arithmetic and logic operations.Neural Programmer can call these augmented operations over several steps,thereby inducing compositional programs that are more complex than the built-inoperations. The model learns from a weak supervision signal which is the resultof execution of the correct program, hence it does not require expensiveannotation of the correct program itself. The decisions of what operations tocall, and what data segments to apply to are inferred by Neural Programmer.Such decisions, during training, are done in a differentiable fashion so thatthe entire network can be trained jointly by gradient descent. We find thattraining the model is difficult, but it can be greatly improved by addingrandom noise to the gradient. On a fairly complex synthetic table-comprehensiondataset, traditional recurrent networks and attentional models perform poorlywhile Neural Programmer typically obtains nearly perfect accuracy."^^schema:Text ;
    schema:author "Arvind Neelakantan"^^schema:Person,
        "Ilya Sutskever"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2016-08-04T18:23:03Z"^^schema:DateTime ;
    schema:datePublished "2015-11-16T06:03:58Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Programmer: Inducing Latent Programs with Gradient Descent"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.04834v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10960563963124584900&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1950> a schema:ScholarlyArticle ;
    schema:author "HN Wu"^^schema:Person,
        "JL Wang"^^schema:Person,
        "SY Ren"^^schema:Person,
        "T Huang"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Pinning Control Strategies for Synchronization of Linearly Coupled Neural Networks With Reaction–Diffusion Terms"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 749-761"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7191471472024326447&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1951> a schema:ScholarlyArticle ;
    schema:author "FJL Iturriaga"^^schema:Person,
        "IP Sanz"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Bankruptcy visualization and prediction using neural networks: A study of US commercial banks"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (6), 2857-2869"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=714404124650977160&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1952> a schema:ScholarlyArticle ;
    schema:author "J Fang"^^schema:Person,
        "Q Wang"^^schema:Person,
        "Y Yuan"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "Online anomaly detection in crowd scenes via structure analysis."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (3), 562-575"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5328684123181084593&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1953> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "J Qiu"^^schema:Person,
        "T Wang"^^schema:Person ;
    schema:commentCount "482"^^schema:Integer ;
    schema:headline "A Combined Adaptive Neural Network and Nonlinear Model Predictive Control for Multirate Networked Industrial Process Control"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (2), 416-425"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4532684887248803721&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1954> a schema:ScholarlyArticle ;
    schema:author "C Lu"^^schema:Person,
        "J Fei"^^schema:Person ;
    schema:commentCount "118"^^schema:Integer ;
    schema:headline "Adaptive Sliding Mode Control of Dynamic Systems Using Double Loop Recurrent Neural Network Structure"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1275-1286"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9312828829937657326&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1955> a schema:ScholarlyArticle ;
    schema:author "H Liao"^^schema:Person,
        "Z Xu"^^schema:Person ;
    schema:commentCount "194"^^schema:Integer ;
    schema:headline "Approaches to manage hesitant fuzzy linguistic information based on the cosine distance and similarity measures for HFLTSs and their application in qualitative decision making"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (12), 5328-5336"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17406655555357104733&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1956> a schema:ScholarlyArticle ;
    schema:author "M Fortunato"^^schema:Person,
        "N Jaitly"^^schema:Person,
        "O Vinyals"^^schema:Person ;
    schema:commentCount "1223"^^schema:Integer ;
    schema:headline "Pointer networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15940812059199267567&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1957> a schema:ScholarlyArticle ;
    schema:author "D Liu"^^schema:Person,
        "D Wang"^^schema:Person,
        "Q Wei"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Reinforcement-Learning-Based Robust Controller Design for Continuous-Time Uncertain Nonlinear Systems Subject to Input Constraints"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 45 (7), 1372-1385"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11503031163543530368&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1958> a schema:ScholarlyArticle ;
    schema:author "JF Cohen"^^schema:Person,
        "K Olsen"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "Knowledge management capabilities and firm performance: A test of universalistic, contingency and complementarity perspectives"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1178-1188"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6827370779133915115&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1959> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "J Qin"^^schema:Person,
        "W Fu"^^schema:Person,
        "WX Zheng"^^schema:Person ;
    schema:commentCount "118"^^schema:Integer ;
    schema:headline "On the Bipartite Consensus for Generic Linear Multiagent Systems With Input Saturation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 1948-1958"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10842616108428139133&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<196> a schema:ScholarlyArticle ;
    schema:abstract "We present a variety of new architectural features and training proceduresthat we apply to the generative adversarial networks (GANs) framework. We focuson two applications of GANs: semi-supervised learning, and the generation ofimages that humans find visually realistic. Unlike most work on generativemodels, our primary goal is not to train a model that assigns high likelihoodto test data, nor do we require the model to be able to learn well withoutusing any labels. Using our new techniques, we achieve state-of-the-art resultsin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generatedimages are of high quality as confirmed by a visual Turing test: our modelgenerates MNIST samples that humans cannot distinguish from real data, andCIFAR-10 samples that yield a human error rate of 21.3%. We also presentImageNet samples with unprecedented resolution and show that our methods enablethe model to learn recognizable features of ImageNet classes."^^schema:Text ;
    schema:author "Alec Radford"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Tim Salimans"^^schema:Person,
        "Vicki Cheung"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person,
        "Xi Chen"^^schema:Person ;
    schema:commentCount "3522"^^schema:Integer ;
    schema:dateModified "2016-06-10T22:53:35Z"^^schema:DateTime ;
    schema:datePublished "2016-06-10T22:53:35Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Improved Techniques for Training GANs"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.03498v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2151481962498772342&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1960> a schema:ScholarlyArticle ;
    schema:author "H Shen"^^schema:Person,
        "HR Karimi"^^schema:Person,
        "J Cheng"^^schema:Person,
        "JH Park"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:headline "A Flexible Terminal Approach to Sampled-Data Exponentially Synchronization of Markovian Neural Networks With Time-Varying Delayed Signals"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (8), 2232-2244"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16399493641700820207&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1961> a schema:ScholarlyArticle ;
    schema:author "A Rostamizadeh"^^schema:Person,
        "A Talwalkar"^^schema:Person,
        "G DeSalvo"^^schema:Person,
        "KG Jamieson"^^schema:Person,
        "L Li"^^schema:Person ;
    schema:commentCount "455"^^schema:Integer ;
    schema:headline "Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10473284631669296057&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1962> a schema:ScholarlyArticle ;
    schema:author "O Montiel"^^schema:Person,
        "R Sepúlveda"^^schema:Person,
        "U Orozco-Rosas"^^schema:Person ;
    schema:commentCount "177"^^schema:Integer ;
    schema:headline "Path planning for mobile robots using Bacterial Potential Field for avoiding static and dynamic obstacles"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (12), 5177-5191"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9969350186552380181&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1963> a schema:ScholarlyArticle ;
    schema:author "J Liu"^^schema:Person,
        "J Zhao"^^schema:Person,
        "L Jiao"^^schema:Person,
        "M Gong"^^schema:Person,
        "Q Miao"^^schema:Person ;
    schema:commentCount "247"^^schema:Integer ;
    schema:headline "Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (1), 125-138"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12784148458876704004&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1964> a schema:ScholarlyArticle ;
    schema:author "B Liu"^^schema:Person,
        "B Ni"^^schema:Person,
        "H Zha"^^schema:Person,
        "J Yan"^^schema:Person,
        "X Yang"^^schema:Person,
        "Z Ren"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:headline "Unsupervised Deep Learning for Optical Flow Estimation"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1486045358557537391&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1965> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "GX Wen"^^schema:Person,
        "YJ Liu"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "318"^^schema:Integer ;
    schema:headline "Observer-Based Adaptive Backstepping Consensus Tracking Control for High-Order Nonlinear Semi-Strict-Feedback Multiagent Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (7), 1591-1601"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5420876959324361530&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1966> a schema:ScholarlyArticle ;
    schema:author "AL Koerich"^^schema:Person,
        "AS Britto Jr"^^schema:Person,
        "EJ Silva Jr"^^schema:Person,
        "LS Oliveira"^^schema:Person,
        "PRL de Almeida"^^schema:Person ;
    schema:commentCount "120"^^schema:Integer ;
    schema:headline "PKLot–A robust dataset for parking lot classification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (11), 4937-4949"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9748225686171293420&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1967> a schema:ScholarlyArticle ;
    schema:author "E Zorarpacı"^^schema:Person,
        "SA Özel"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:headline "A hybrid approach of differential evolution and artificial bee colony for feature selection"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 62, 91-103"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15394103674122300579&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1968> a schema:ScholarlyArticle ;
    schema:author "N Areal"^^schema:Person,
        "N Oliveira"^^schema:Person,
        "P Cortez"^^schema:Person ;
    schema:commentCount "125"^^schema:Integer ;
    schema:headline "The impact of microblogging data for stock market prediction: Using Twitter to predict returns, volatility, trading volume and survey sentiment indices"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 73, 125-144"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1886457579516691674&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1969> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "A Vakali"^^schema:Person,
        "G Sarigiannidis"^^schema:Person,
        "K Diamantaras"^^schema:Person,
        "M Giatsoglou"^^schema:Person,
        "MG Vozalis"^^schema:Person ;
    schema:commentCount "175"^^schema:Integer ;
    schema:headline "Sentiment analysis leveraging emotions and word embeddings"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 69, 214-224"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5239011546115350983&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<197> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) have become the method of choice forlearning problems involving 2D planar images. However, a number of problems ofrecent interest have created a demand for models that can analyze sphericalimages. Examples include omnidirectional vision for drones, robots, andautonomous cars, molecular regression problems, and global weather and climatemodelling. A naive application of convolutional networks to a planar projectionof the spherical signal is destined to fail, because the space-varyingdistortions introduced by such a projection will make translational weightsharing ineffective.  In this paper we introduce the building blocks for constructing sphericalCNNs. We propose a definition for the spherical cross-correlation that is bothexpressive and rotation-equivariant. The spherical correlation satisfies ageneralized Fourier theorem, which allows us to compute it efficiently using ageneralized (non-commutative) Fast Fourier Transform (FFT) algorithm. Wedemonstrate the computational efficiency, numerical accuracy, and effectivenessof spherical CNNs applied to 3D model recognition and atomization energyregression."^^schema:Text ;
    schema:author "Jonas Koehler"^^schema:Person,
        "Mario Geiger"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Taco S. Cohen"^^schema:Person ;
    schema:commentCount "251"^^schema:Integer ;
    schema:dateModified "2018-02-25T13:43:49Z"^^schema:DateTime ;
    schema:datePublished "2018-01-30T18:28:30Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Spherical CNNs"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.10130v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6361332838540502667&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1970> a schema:ScholarlyArticle ;
    schema:author "H Shen"^^schema:Person,
        "J Cao"^^schema:Person,
        "S Huo"^^schema:Person,
        "T Huang"^^schema:Person ;
    schema:commentCount "114"^^schema:Integer ;
    schema:headline "Generalized State Estimation for Markovian Coupled Networks Under Round-Robin Protocol and Redundant Channels"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 49 (4), 1292-1301"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9344700863458243326&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1971> a schema:ScholarlyArticle ;
    schema:author "A Voisin"^^schema:Person,
        "J Robert"^^schema:Person,
        "S Kubler"^^schema:Person,
        "W Derigent"^^schema:Person,
        "Y Le Traon"^^schema:Person ;
    schema:commentCount "188"^^schema:Integer ;
    schema:headline "A state-of the-art survey & testbed of fuzzy AHP (FAHP) applications"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 65, 398-422"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17458037963702539355&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1972> a schema:ScholarlyArticle ;
    schema:author "F Han"^^schema:Person,
        "G Wei"^^schema:Person,
        "W Li"^^schema:Person,
        "Y Liu"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:headline "Weighted Average Consensus-Based Unscented Kalman Filtering"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 558-567"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7766388399978697318&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1973> a schema:ScholarlyArticle ;
    schema:author "A Culotta"^^schema:Person,
        "J Cutler"^^schema:Person,
        "NR Kumar"^^schema:Person ;
    schema:commentCount "135"^^schema:Integer ;
    schema:headline "Predicting the Demographics of Twitter Users from Website Traffic Data"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11884565386113676151&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1974> a schema:ScholarlyArticle ;
    schema:author "S Tong"^^schema:Person,
        "T Li"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "303"^^schema:Integer ;
    schema:headline "Composite Adaptive Fuzzy Output Feedback Control Design for Uncertain Nonlinear Strict-Feedback Systems With Input Saturation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 10 (45), 2299-2308"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11126016292680040348&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1975> a schema:ScholarlyArticle ;
    schema:author "M Wang"^^schema:Person,
        "P Shi"^^schema:Person,
        "Q Zhou"^^schema:Person,
        "Y Tian"^^schema:Person ;
    schema:commentCount "168"^^schema:Integer ;
    schema:headline "Approximation-Based Adaptive Tracking Control for MIMO Nonlinear Systems With Input Saturation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 10 (45), 2119-2128"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9152423360927937516&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1976> a schema:ScholarlyArticle ;
    schema:author "D Duvenaud"^^schema:Person,
        "R Grosse"^^schema:Person,
        "RTQ Chen"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:headline "Isolating sources of disentanglement in VAEs"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11372263911361899725&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1977> a schema:ScholarlyArticle ;
    schema:author "H Zhang"^^schema:Person,
        "J Long"^^schema:Person,
        "K Chen"^^schema:Person,
        "Z Zhang"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "Turning from TF-IDF to TF-IGM for term weighting in text classification"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 66, 245-260"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1827530018832237828&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1978> a schema:ScholarlyArticle ;
    schema:author "J He"^^schema:Person,
        "J Wei"^^schema:Person,
        "K Chen"^^schema:Person,
        "Y Zhou"^^schema:Person,
        "Z Tang"^^schema:Person ;
    schema:commentCount "288"^^schema:Integer ;
    schema:headline "Collaborative filtering and deep learning based recommendation system for cold start items"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 69, 29-39"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4042913562618672398&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1979> a schema:ScholarlyArticle ;
    schema:author "CC Lim"^^schema:Person,
        "F Li"^^schema:Person,
        "L Wu"^^schema:Person,
        "P Shi"^^schema:Person ;
    schema:commentCount "189"^^schema:Integer ;
    schema:headline "Neural Network-Based Passive Filtering for Delayed Neutral-Type Semi-Markovian Jump Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (9), 2101-2114"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16112333675203900673&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<198> a schema:ScholarlyArticle ;
    schema:abstract "Ensembles of neural networks are known to be much more robust and accuratethan individual networks. However, training multiple deep networks for modelaveraging is computationally expensive. In this paper, we propose a method toobtain the seemingly contradictory goal of ensembling multiple neural networksat no additional training cost. We achieve this goal by training a singleneural network, converging to several local minima along its optimization pathand saving the model parameters. To obtain repeated rapid convergence, weleverage recent work on cyclic learning rate schedules. The resultingtechnique, which we refer to as Snapshot Ensembling, is simple, yetsurprisingly effective. We show in a series of experiments that our approach iscompatible with diverse network architectures and learning tasks. Itconsistently yields lower error rates than state-of-the-art single models at noadditional training cost, and compares favorably with traditional networkensembles. On CIFAR-10 and CIFAR-100 our DenseNet Snapshot Ensembles obtainerror rates of 3.4% and 17.4% respectively."^^schema:Text ;
    schema:author "Gao Huang"^^schema:Person,
        "Geoff Pleiss"^^schema:Person,
        "John E. Hopcroft"^^schema:Person,
        "Kilian Q. Weinberger"^^schema:Person,
        "Yixuan Li"^^schema:Person,
        "Zhuang Liu"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2017-04-01T02:42:55Z"^^schema:DateTime ;
    schema:datePublished "2017-04-01T02:42:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Snapshot Ensembles: Train 1, get M for free"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.00109v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13258787322136448860&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1980> a schema:ScholarlyArticle ;
    schema:author "B Gu"^^schema:Person,
        "VS Sheng"^^schema:Person ;
    schema:commentCount "465"^^schema:Integer ;
    schema:headline "A Robust Regularization Path Algorithm for $\\nu $-Support Vector Classification"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (5), 1241-1248"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2255587010986078742&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1981> a schema:ScholarlyArticle ;
    schema:author "L Abdullah"^^schema:Person,
        "N Zulkifli"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Integration of fuzzy AHP and interval type-2 fuzzy DEMATEL: An application to human resource management"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (9), 4397-4409"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9121907470747538188&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1982> a schema:ScholarlyArticle ;
    schema:author "A Alabdulwahab"^^schema:Person,
        "AC Ammari"^^schema:Person,
        "MC Zhou"^^schema:Person,
        "Q Zhu"^^schema:Person,
        "X Luo"^^schema:Person,
        "Y Xia"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (3), 524-537"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9167091987560175986&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1983> a schema:ScholarlyArticle ;
    schema:author "F Nie"^^schema:Person,
        "HT Shen"^^schema:Person,
        "Y Yang"^^schema:Person,
        "Z Ma"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "Multitask Spectral Clustering by Exploring Intertask Correlation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 5 (45), 1069-1080"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4362687232733020671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1984> a schema:ScholarlyArticle ;
    schema:author "B Niu"^^schema:Person,
        "X Zhao"^^schema:Person,
        "X Zheng"^^schema:Person,
        "Y Yin"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Stabilization for a Class of Switched Nonlinear Systems With Novel Average Dwell Time Switching by T–S Fuzzy Modeling"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (8), 1952-1957"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5939713111033042443&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1985> a schema:ScholarlyArticle ;
    schema:author "X Gastaldi"^^schema:Person ;
    schema:commentCount "251"^^schema:Integer ;
    schema:headline "Shake-Shake regularization of 3-branch residual networks."^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5303886259384119804&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1986> a schema:ScholarlyArticle ;
    schema:author "AK Sangaiah"^^schema:Person,
        "G Li"^^schema:Person,
        "GM Asogbon"^^schema:Person,
        "OW Samuel"^^schema:Person,
        "P Fang"^^schema:Person ;
    schema:commentCount "150"^^schema:Integer ;
    schema:headline "An integrated decision support system based on ANN and Fuzzy_AHP for heart failure risk prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 68, 163-172"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14286292843087077413&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1987> a schema:ScholarlyArticle ;
    schema:author "L Wang"^^schema:Person,
        "P Mazumder"^^schema:Person,
        "S Duan"^^schema:Person,
        "X Hu"^^schema:Person,
        "Z Dong"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:headline "Memristor-Based Cellular Nonlinear/Neural Network: Design, Analysis, and Applications"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 6 (26), 1202-1213"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14718407260433415922&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1988> a schema:ScholarlyArticle ;
    schema:author "H Gao"^^schema:Person,
        "H Liu"^^schema:Person,
        "J Tang"^^schema:Person,
        "X Hu"^^schema:Person ;
    schema:commentCount "293"^^schema:Integer ;
    schema:headline "Content-Aware Point of Interest Recommendation on Location-Based Social Networks"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=937854244091464156&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1989> a schema:ScholarlyArticle ;
    schema:author "G Feng"^^schema:Person,
        "L Liu"^^schema:Person,
        "W Hu"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:headline "Output Consensus of Heterogeneous Linear Multi-Agent Systems by Distributed Event-Triggered/Self-Triggered Strategy"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 1914-1924"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6599515256695568728&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<199> a schema:ScholarlyArticle ;
    schema:abstract "Policy gradient methods are an appealing approach in reinforcement learningbecause they directly optimize the cumulative reward and can straightforwardlybe used with nonlinear function approximators such as neural networks. The twomain challenges are the large number of samples typically required, and thedifficulty of obtaining stable and steady improvement despite thenonstationarity of the incoming data. We address the first challenge by usingvalue functions to substantially reduce the variance of policy gradientestimates at the cost of some bias, with an exponentially-weighted estimator ofthe advantage function that is analogous to TD(lambda). We address the secondchallenge by using trust region optimization procedure for both the policy andthe value function, which are represented by neural networks.  Our approach yields strong empirical results on highly challenging 3Dlocomotion tasks, learning running gaits for bipedal and quadrupedal simulatedrobots, and learning a policy for getting the biped to stand up from startingout lying on the ground. In contrast to a body of prior work that useshand-crafted policy representations, our neural network policies map directlyfrom raw kinematics to joint torques. Our algorithm is fully model-free, andthe amount of simulated experience required for the learning tasks on 3D bipedscorresponds to 1-2 weeks of real time."^^schema:Text ;
    schema:author "John Schulman"^^schema:Person,
        "Michael Jordan"^^schema:Person,
        "Philipp Moritz"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "875"^^schema:Integer ;
    schema:dateModified "2018-10-20T18:55:07Z"^^schema:DateTime ;
    schema:datePublished "2015-06-08T11:12:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "High-Dimensional Continuous Control Using Generalized Advantage  Estimation"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02438v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7176097012963036784&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1990> a schema:ScholarlyArticle ;
    schema:author "AA Ewees"^^schema:Person,
        "AE Hassanien"^^schema:Person,
        "M Abd El Aziz"^^schema:Person ;
    schema:commentCount "218"^^schema:Integer ;
    schema:headline "Whale Optimization Algorithm and Moth-Flame Optimization for multilevel thresholding image segmentation"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 83, 242-256"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9730551993702634937&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1991> a schema:ScholarlyArticle ;
    schema:author "A Krause"^^schema:Person,
        "A Singla"^^schema:Person,
        "G Bartók"^^schema:Person,
        "M Meenen"^^schema:Person,
        "M Santoni"^^schema:Person,
        "P Mukerji"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:headline "Incentivizing Users for Balancing Bike Sharing Systems"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6277781100492068339&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1992> a schema:ScholarlyArticle ;
    schema:author "X Zhu"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:headline "Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14420641823870193826&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1993> a schema:ScholarlyArticle ;
    schema:author "G Chen"^^schema:Person,
        "J Lam"^^schema:Person,
        "W Yu"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "113"^^schema:Integer ;
    schema:headline "Finite-Time Consensus of Multiagent Systems With a Switching Protocol"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 853-862"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4757213189072003738&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1994> a schema:ScholarlyArticle ;
    schema:author "J Cao"^^schema:Person,
        "J Liang"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:headline "Exponential Synchronization of Memristive Neural Networks With Delays: Interval Matrix Method"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (8), 1878-1888"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9793887598277192098&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1995> a schema:ScholarlyArticle ;
    schema:author "B Kiumarsi"^^schema:Person,
        "FL Lewis"^^schema:Person,
        "H Modares"^^schema:Person,
        "KG Vamvoudakis"^^schema:Person ;
    schema:commentCount "155"^^schema:Integer ;
    schema:headline "Optimal and Autonomous Control Using Reinforcement Learning: A Survey"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (6), 2042-2062"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9467691225156082250&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1996> a schema:ScholarlyArticle ;
    schema:author "AA Bakar"^^schema:Person,
        "AR Hamdan"^^schema:Person,
        "AS Ghareb"^^schema:Person ;
    schema:commentCount "118"^^schema:Integer ;
    schema:headline "Hybrid feature selection based on enhanced genetic algorithm for text categorization"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 49, 31-47"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15965265259388966063&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1997> a schema:ScholarlyArticle ;
    schema:author "C Yang"^^schema:Person,
        "H Ma"^^schema:Person,
        "L Cheng"^^schema:Person,
        "X Wang"^^schema:Person ;
    schema:commentCount "209"^^schema:Integer ;
    schema:headline "Neural-Learning-Based Telerobot Control With Guaranteed Performance"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (10), 3148-3159"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12806939535618976268&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1998> a schema:ScholarlyArticle ;
    schema:author "B Niu"^^schema:Person,
        "G Zong"^^schema:Person,
        "J Fu"^^schema:Person,
        "Y Liu"^^schema:Person,
        "Z Han"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "Command Filter-Based Adaptive Neural Tracking Controller Design for Uncertain Switched Nonlinear Output-Constrained Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (10), 3160-3171"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16500787949172292112&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<1999> a schema:ScholarlyArticle ;
    schema:author "L Mou"^^schema:Person,
        "X Li"^^schema:Person,
        "X Lu"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Semi-Supervised Multitask Learning for Scene Recognition"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 9 (45), 1967-1976"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10933846689777715349&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in stochastic gradient variational inference have made itpossible to perform variational Bayesian inference with posteriorapproximations containing auxiliary random variables. This enables us toexplore a new synthesis of variational inference and Monte Carlo methods wherewe incorporate one or more steps of MCMC into our variational approximation. Bydoing so we obtain a rich class of inference algorithms bridging the gapbetween variational methods and MCMC, and offering the best of both worlds:fast posterior approximation through the maximization of an explicit objective,with the option of trading off additional computation for additional accuracy.We describe the theoretical foundations that make this possible and show somepromising first results."^^schema:Text ;
    schema:author "Diederik P. Kingma"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Tim Salimans"^^schema:Person ;
    schema:commentCount "331"^^schema:Integer ;
    schema:dateModified "2015-05-19T13:53:13Z"^^schema:DateTime ;
    schema:datePublished "2014-10-23T19:23:53Z"^^schema:DateTime ;
    schema:genre "stat.CO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Markov Chain Monte Carlo and Variational Inference: Bridging the Gap"^^schema:Text ;
    schema:publisher "ICML, 1218-1226"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1410.6460v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1527223141103092286&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<20> a schema:ScholarlyArticle ;
    schema:abstract "We consider an agent's uncertainty about its environment and the problem ofgeneralizing this uncertainty across observations. Specifically, we focus onthe problem of exploration in non-tabular reinforcement learning. Drawinginspiration from the intrinsic motivation literature, we use density models tomeasure uncertainty, and propose a novel algorithm for deriving a pseudo-countfrom an arbitrary density model. This technique enables us to generalizecount-based exploration algorithms to the non-tabular case. We apply our ideasto Atari 2600 games, providing sensible pseudo-counts from raw pixels. Wetransform these pseudo-counts into intrinsic rewards and obtain significantlyimproved exploration in a number of hard games, including the infamouslydifficult Montezuma's Revenge."^^schema:Text ;
    schema:author "David Saxton"^^schema:Person,
        "Georg Ostrovski"^^schema:Person,
        "Marc G. Bellemare"^^schema:Person,
        "Remi Munos"^^schema:Person,
        "Sriram Srinivasan"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:commentCount "555"^^schema:Integer ;
    schema:dateModified "2016-11-07T21:16:21Z"^^schema:DateTime ;
    schema:datePublished "2016-06-06T19:21:32Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unifying Count-Based Exploration and Intrinsic Motivation"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.01868v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7667515176664990362&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<200> a schema:ScholarlyArticle ;
    schema:abstract "Recent work has shown that state-of-the-art classifiers are quite brittle, inthe sense that a small adversarial change of an originally with high confidencecorrectly classified input leads to a wrong classification again with highconfidence. This raises concerns that such classifiers are vulnerable toattacks and calls into question their usage in safety-critical systems. We showin this paper for the first time formal guarantees on the robustness of aclassifier by giving instance-specific lower bounds on the norm of the inputmanipulation required to change the classifier decision. Based on this analysiswe propose the Cross-Lipschitz regularization functional. We show that usingthis form of regularization in kernel methods resp. neural networks improvesthe robustness of the classifier without any loss in prediction performance."^^schema:Text ;
    schema:author "Maksym Andriushchenko"^^schema:Person,
        "Matthias Hein"^^schema:Person ;
    schema:commentCount "198"^^schema:Integer ;
    schema:dateModified "2017-11-05T20:58:09Z"^^schema:DateTime ;
    schema:datePublished "2017-05-23T18:48:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Formal Guarantees on the Robustness of a Classifier against Adversarial  Manipulation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08475v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7126535280922614101&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2000> a schema:ScholarlyArticle ;
    schema:author "J Fang"^^schema:Person,
        "S Lin"^^schema:Person,
        "X Liu"^^schema:Person,
        "Z Xu"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Is extreme learning machine feasible? A theoretical assessment (part I)."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (1), 7-20"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5578021333327583335&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2001> a schema:ScholarlyArticle ;
    schema:author "C Sun"^^schema:Person,
        "W He"^^schema:Person,
        "Z Yin"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Adaptive Neural Network Control of a Marine Vessel With Constraints Using the Asymmetric Barrier Lyapunov Function"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (7), 1641-1651"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1560392588445766894&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2002> a schema:ScholarlyArticle ;
    schema:author "QL Han"^^schema:Person,
        "X Ge"^^schema:Person ;
    schema:commentCount "130"^^schema:Integer ;
    schema:headline "Consensus of Multiagent Systems Subject to Partially Accessible and Overlapping Markovian Network Topologies"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 1807-1819"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3993623736552354639&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2003> a schema:ScholarlyArticle ;
    schema:author "HSH Chung"^^schema:Person,
        "J Zhang"^^schema:Person,
        "JJ Li"^^schema:Person,
        "Y Li"^^schema:Person,
        "Y Zhou"^^schema:Person,
        "YH Shi"^^schema:Person,
        "YJ Gong"^^schema:Person ;
    schema:commentCount "194"^^schema:Integer ;
    schema:headline "Genetic Learning Particle Swarm Optimization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (10), 2277-2290"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17813735694499887906&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2004> a schema:ScholarlyArticle ;
    schema:author "D Duvenaud"^^schema:Person,
        "J Bettencourt"^^schema:Person,
        "RTQ Chen"^^schema:Person,
        "Y Rubanova"^^schema:Person ;
    schema:commentCount "556"^^schema:Integer ;
    schema:headline "Neural ordinary differential equations"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13748354740225969894&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2005> a schema:ScholarlyArticle ;
    schema:author "C Han"^^schema:Person,
        "E Chong"^^schema:Person,
        "FC Park"^^schema:Person ;
    schema:commentCount "238"^^schema:Integer ;
    schema:headline "Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 83, 187-205"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11148564301076667045&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2006> a schema:ScholarlyArticle ;
    schema:author "D Campos"^^schema:Person,
        "J Atkinson"^^schema:Person ;
    schema:commentCount "305"^^schema:Integer ;
    schema:headline "Improving BCI-based emotion recognition by combining EEG feature selection and kernel classifiers"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 47, 35-41"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14742195906335671458&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2007> a schema:ScholarlyArticle ;
    schema:author "KS Moghaddam"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Fuzzy multi-objective model for supplier selection and order allocation in reverse logistics systems under supply and demand uncertainty"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (15-16), 6237-6254"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7736768131812316344&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2008> a schema:ScholarlyArticle ;
    schema:author "B Luo"^^schema:Person,
        "HN Wu"^^schema:Person,
        "T Huang"^^schema:Person ;
    schema:commentCount "196"^^schema:Integer ;
    schema:headline "Off-policy reinforcement learning for H∞ control design."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (1), 65-76"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2704703510847045086&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2009> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "G Tesauro"^^schema:Person,
        "M Yu"^^schema:Person,
        "S Chang"^^schema:Person,
        "S Wang"^^schema:Person,
        "T Klinger"^^schema:Person,
        "W Zhang"^^schema:Person,
        "X Guo"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:headline "R 3: Reinforced Ranker-Reader for Open-Domain Question Answering"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9714335657990475060&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<201> a schema:ScholarlyArticle ;
    schema:abstract "Sequence to sequence learning has recently emerged as a new paradigm insupervised learning. To date, most of its applications focused on only one taskand not much work explored this framework for multiple tasks. This paperexamines three multi-task learning (MTL) settings for sequence to sequencemodels: (a) the oneto-many setting - where the encoder is shared betweenseveral tasks such as machine translation and syntactic parsing, (b) themany-to-one setting - useful when only the decoder can be shared, as in thecase of translation and image caption generation, and (c) the many-to-manysetting - where multiple encoders and decoders are shared, which is the casewith unsupervised objectives and translation. Our results show that training ona small amount of parsing and image caption data can improve the translationquality between English and German by up to 1.5 BLEU points over strongsingle-task baselines on the WMT benchmarks. Furthermore, we have established anew state-of-the-art result in constituent parsing with 93.0 F1. Lastly, wereveal interesting properties of the two unsupervised learning objectives,autoencoder and skip-thought, in the MTL context: autoencoder helps less interms of perplexities but more on BLEU scores compared to skip-thought."^^schema:Text ;
    schema:author "Ilya Sutskever"^^schema:Person,
        "Lukasz Kaiser"^^schema:Person,
        "Minh-Thang Luong"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "546"^^schema:Integer ;
    schema:dateModified "2016-03-01T10:55:58Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T10:24:14Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-task Sequence to Sequence Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06114v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6045967109711129604&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2010> a schema:ScholarlyArticle ;
    schema:author "G Zhai"^^schema:Person,
        "K Gu"^^schema:Person,
        "M Liu"^^schema:Person,
        "W Lin"^^schema:Person ;
    schema:commentCount "221"^^schema:Integer ;
    schema:headline "The Analysis of Image Contrast: From Quality Assessment to Automatic Enhancement"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 284-297"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17619916026689015861&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2011> a schema:ScholarlyArticle ;
    schema:author "FL Chung"^^schema:Person,
        "J Wang"^^schema:Person,
        "P Qian"^^schema:Person,
        "S Wang"^^schema:Person,
        "Y Jiang"^^schema:Person,
        "Z Deng"^^schema:Person ;
    schema:commentCount "168"^^schema:Integer ;
    schema:headline "Collaborative Fuzzy Clustering From Multiple Weighted Views"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 4 (45), 688-701"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9319864879551289109&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2012> a schema:ScholarlyArticle ;
    schema:author "D Huang"^^schema:Person,
        "T Meng"^^schema:Person,
        "W He"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Adaptive Boundary Iterative Learning Control for an Euler–Bernoulli Beam System With Input Constraint"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (5), 1539-1549"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10039970751116961607&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2013> a schema:ScholarlyArticle ;
    schema:author "H Bao"^^schema:Person,
        "J Cao"^^schema:Person,
        "JH Park"^^schema:Person ;
    schema:commentCount "135"^^schema:Integer ;
    schema:headline "Exponential Synchronization of Coupled Stochastic Memristor-Based Neural Networks With Time-Varying Probabilistic Delay Coupling and Impulsive Delay"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (1), 190-201"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11788329361930943502&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2014> a schema:ScholarlyArticle ;
    schema:author "G Guo"^^schema:Person,
        "J Zhang"^^schema:Person,
        "N Yorke-Smith"^^schema:Person ;
    schema:commentCount "301"^^schema:Integer ;
    schema:headline "TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence of User Trust and of Item Ratings"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2901069925650387027&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2015> a schema:ScholarlyArticle ;
    schema:author "F Liao"^^schema:Person,
        "M Liang"^^schema:Person,
        "S Song"^^schema:Person,
        "X Hu"^^schema:Person,
        "Z Li"^^schema:Person ;
    schema:commentCount "107"^^schema:Integer ;
    schema:headline "Evaluate the Malignancy of Pulmonary Nodules Using the 3-D Deep Leaky Noisy-OR Network"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 30 (11), 3484-3495"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8587897185270542255&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2016> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "L Tang"^^schema:Person,
        "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Adaptive NN Controller Design for a Class of Nonlinear MIMO Discrete-Time Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 5 (26), 1007-1018"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16446227864249765905&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2017> a schema:ScholarlyArticle ;
    schema:author "F You"^^schema:Person,
        "G Lie"^^schema:Person,
        "H Wang"^^schema:Person,
        "H Wen"^^schema:Person,
        "J Xu"^^schema:Person,
        "R Zhang"^^schema:Person ;
    schema:commentCount "111"^^schema:Integer ;
    schema:headline "Trajectory planning and tracking control for autonomous lane change maneuver based on the cooperative vehicle infrastructure system"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (14), 5932-5946"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14645239872656401229&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2018> a schema:ScholarlyArticle ;
    schema:author "E Nabil"^^schema:Person ;
    schema:commentCount "124"^^schema:Integer ;
    schema:headline "A Modified Flower Pollination Algorithm for Global Optimization"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 57, 192-203"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17554621836725330441&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2019> a schema:ScholarlyArticle ;
    schema:author "A Cichocki"^^schema:Person,
        "G Zhou"^^schema:Person,
        "J Jin"^^schema:Person,
        "Q Zhao"^^schema:Person,
        "X Wang"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "169"^^schema:Integer ;
    schema:headline "Sparse Bayesian Classification of EEG for Brain–Computer Interface"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (11), 2256-2267"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11692150395795884116&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<202> a schema:ScholarlyArticle ;
    schema:abstract "Parallel implementations of stochastic gradient descent (SGD) have receivedsignificant research attention, thanks to excellent scalability properties ofthis algorithm, and to its efficiency in the context of training deep neuralnetworks. A fundamental barrier for parallelizing large-scale SGD is the factthat the cost of communicating the gradient updates between nodes can be verylarge. Consequently, lossy compression heuristics have been proposed, by whichnodes only communicate quantized gradients. Although effective in practice,these heuristics do not always provably converge, and it is not clear whetherthey are optimal.  In this paper, we propose Quantized SGD (QSGD), a family of compressionschemes which allow the compression of gradient updates at each node, whileguaranteeing convergence under standard assumptions. QSGD allows the user totrade off compression and convergence time: it can communicate a sublinearnumber of bits per iteration in the model dimension, and can achieveasymptotically optimal communication cost. We complement our theoreticalresults with empirical data, showing that QSGD can significantly reducecommunication cost, while being competitive with standard uncompressedtechniques on a variety of real tasks.  In particular, experiments show that gradient quantization applied totraining of deep neural networks for image classification and automated speechrecognition can lead to significant reductions in communication cost, andend-to-end training time. For instance, on 16 GPUs, we are able to train aResNet-152 network on ImageNet 1.8x faster to full accuracy. Of note, we showthat there exist generic parameter settings under which all known networkarchitectures preserve or slightly improve their full accuracy when usingquantization."^^schema:Text ;
    schema:author "Dan Alistarh"^^schema:Person,
        "Demjan Grubic"^^schema:Person,
        "Jerry Li"^^schema:Person,
        "Milan Vojnovic"^^schema:Person,
        "Ryota Tomioka"^^schema:Person ;
    schema:commentCount "287"^^schema:Integer ;
    schema:dateModified "2017-12-06T18:28:32Z"^^schema:DateTime ;
    schema:datePublished "2016-10-07T03:44:34Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.02132v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14481730973283095659&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2020> a schema:ScholarlyArticle ;
    schema:author "KQ Weinberger"^^schema:Person,
        "MJ Kusner"^^schema:Person,
        "NI Kolkin"^^schema:Person,
        "Y Sun"^^schema:Person ;
    schema:commentCount "1093"^^schema:Integer ;
    schema:headline "From Word Embeddings To Document Distances."^^schema:Text ;
    schema:publisher "ICML, 957-966"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6676593072521907897&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2021> a schema:ScholarlyArticle ;
    schema:author "R Sharma"^^schema:Person,
        "RB Pachori"^^schema:Person ;
    schema:commentCount "262"^^schema:Integer ;
    schema:headline "Classification of epileptic seizures in EEG signals based on phase space representation of intrinsic mode functions"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1106-1117"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15571822744026521437&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2022> a schema:ScholarlyArticle ;
    schema:author "A Stojanovic"^^schema:Person,
        "AC Bahnsen"^^schema:Person,
        "B Ottersten"^^schema:Person,
        "D Aouada"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "Feature engineering strategies for credit card fraud detection"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 51, 134-142"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=313798199913080978&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2023> a schema:ScholarlyArticle ;
    schema:author "A Ahmadi"^^schema:Person,
        "GK Venayagamoorthy"^^schema:Person,
        "PK Gautam"^^schema:Person,
        "RK Sharma"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:headline "Dynamic Energy Management System for a Smart Microgrid"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (8), 1643-1656"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5896508304457201072&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2024> a schema:ScholarlyArticle ;
    schema:author "S Sui"^^schema:Person,
        "S Tong"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Observed-Based Adaptive Fuzzy Tracking Control for Switched Nonlinear Systems With Dead-Zone"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 45 (12), 2816-2826"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15833169468353053299&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2025> a schema:ScholarlyArticle ;
    schema:author "A Bouguettaya"^^schema:Person,
        "A Song"^^schema:Person,
        "Q Yu"^^schema:Person,
        "X Liu"^^schema:Person,
        "X Zhou"^^schema:Person ;
    schema:commentCount "165"^^schema:Integer ;
    schema:headline "Efficient agglomerative hierarchical clustering"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2785-2797"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3858415263183357626&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2026> a schema:ScholarlyArticle ;
    schema:author "F Wei"^^schema:Person,
        "L Dong"^^schema:Person,
        "M Zhou"^^schema:Person,
        "S Li"^^schema:Person,
        "Z Cao"^^schema:Person ;
    schema:commentCount "185"^^schema:Integer ;
    schema:headline "Ranking with Recursive Neural Networks and Its Application to Multi-Document Summarization"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14921177152398680276&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2027> a schema:ScholarlyArticle ;
    schema:author "H Wang"^^schema:Person,
        "P Shi"^^schema:Person,
        "PX Liu"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "Observer-Based Fuzzy Adaptive Output-Feedback Control of Stochastic Nonlinear Multiple Time-Delay Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (9), 2568-2578"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9485137990352780477&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2028> a schema:ScholarlyArticle ;
    schema:author "H Chen"^^schema:Person,
        "J Qin"^^schema:Person,
        "L Yu"^^schema:Person,
        "PA Heng"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "166"^^schema:Integer ;
    schema:headline "Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17424517290508074578&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2029> a schema:ScholarlyArticle ;
    schema:author "C Wu"^^schema:Person,
        "H Li"^^schema:Person,
        "HK Lam"^^schema:Person,
        "L Wu"^^schema:Person,
        "Y Gao"^^schema:Person ;
    schema:commentCount "168"^^schema:Integer ;
    schema:headline "Filtering of Interval Type-2 Fuzzy Systems With Intermittent Measurements"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (3), 668-678"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5496670235137242201&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<203> a schema:ScholarlyArticle ;
    schema:abstract "We present a unified framework for learning continuous control policies usingbackpropagation. It supports stochastic control by treating stochasticity inthe Bellman equation as a deterministic function of exogenous noise. Theproduct is a spectrum of general policy gradient algorithms that range frommodel-free methods with value functions to model-based methods without valuefunctions. We use learned models but only require observations from theenvironment in- stead of observations from model-predicted trajectories,minimizing the impact of compounded model errors. We apply these algorithmsfirst to a toy stochastic control problem and then to several physics-basedcontrol problems in simulation. One of these variants, SVG(1), shows theeffectiveness of learning models, value functions, and policies simultaneouslyin continuous domains."^^schema:Text ;
    schema:author "David Silver"^^schema:Person,
        "Greg Wayne"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person,
        "Tom Erez"^^schema:Person,
        "Yuval Tassa"^^schema:Person ;
    schema:commentCount "313"^^schema:Integer ;
    schema:dateModified "2015-10-30T16:07:51Z"^^schema:DateTime ;
    schema:datePublished "2015-10-30T16:07:51Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning Continuous Control Policies by Stochastic Value Gradients"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.09142v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2728724061281364322&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2030> a schema:ScholarlyArticle ;
    schema:author "A Vafadarnikjoo"^^schema:Person,
        "K Govindan"^^schema:Person,
        "R Khodaverdi"^^schema:Person ;
    schema:commentCount "244"^^schema:Integer ;
    schema:headline "Intuitionistic fuzzy based DEMATEL method for developing green practices and performances in a green supply chain"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (20), 7207-7220"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7922955555276864235&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2031> a schema:ScholarlyArticle ;
    schema:author "A Santoro"^^schema:Person,
        "D Wierstra"^^schema:Person,
        "M Botvinick"^^schema:Person,
        "S Bartunov"^^schema:Person,
        "TP Lillicrap"^^schema:Person ;
    schema:commentCount "638"^^schema:Integer ;
    schema:headline "Meta-Learning with Memory-Augmented Neural Networks."^^schema:Text ;
    schema:publisher "ICML, 1842-1850"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13138620707673691473&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2032> a schema:ScholarlyArticle ;
    schema:author "D Perez-Liebana"^^schema:Person,
        "J Togelius"^^schema:Person,
        "S Samothrakis"^^schema:Person,
        "SM Lucas"^^schema:Person,
        "T Schaul"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "General Video Game AI: Competition, Challenges and Opportunities"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1838429092641381650&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2033> a schema:ScholarlyArticle ;
    schema:author "DS Rosenblum"^^schema:Person,
        "L Cheng"^^schema:Person,
        "L Liu"^^schema:Person,
        "Y Jia"^^schema:Person,
        "Y Liu"^^schema:Person ;
    schema:commentCount "185"^^schema:Integer ;
    schema:headline "Recognizing complex activities by a probabilistic interval-based model"^^schema:Text ;
    schema:publisher "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5450151409113208438&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2034> a schema:ScholarlyArticle ;
    schema:author "D Greene"^^schema:Person,
        "D O’Callaghan"^^schema:Person,
        "J Carthy"^^schema:Person,
        "P Cunningham"^^schema:Person ;
    schema:commentCount "113"^^schema:Integer ;
    schema:headline "An analysis of the coherence of descriptors in topic modeling"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (13), 5645-5657"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9710724533423782515&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2035> a schema:ScholarlyArticle ;
    schema:author "KC Tan"^^schema:Person,
        "R Ren"^^schema:Person,
        "T Hung"^^schema:Person ;
    schema:commentCount "130"^^schema:Integer ;
    schema:headline "A Generic Deep-Learning-Based Approach for Automated Surface Inspection"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (3), 929-940"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4694030668583150900&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2036> a schema:ScholarlyArticle ;
    schema:author "C Peng"^^schema:Person,
        "S Ma"^^schema:Person,
        "X Xie"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Observer-Based Non-PDC Control for Networked T–S Fuzzy Systems With an Event-Triggered Communication"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (8), 2279-2287"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14920126425820163996&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2037> a schema:ScholarlyArticle ;
    schema:author "C Ju"^^schema:Person,
        "S Zhang"^^schema:Person,
        "X Li"^^schema:Person,
        "X Wu"^^schema:Person,
        "X Zhu"^^schema:Person ;
    schema:commentCount "229"^^schema:Integer ;
    schema:headline "Robust Joint Graph Sparse Coding for Unsupervised Spectral Feature Selection"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (6), 1263-1275"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4943836691858739248&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2038> a schema:ScholarlyArticle ;
    schema:author "S Tong"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "149"^^schema:Integer ;
    schema:headline "Adaptive Neural Networks Decentralized FTC Design for Nonstrict-Feedback Nonlinear Interconnected Large-Scale Systems Against Actuator Faults"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (11), 2541-2554"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10582372477683333285&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2039> a schema:ScholarlyArticle ;
    schema:author "D Tao"^^schema:Person,
        "F Gao"^^schema:Person,
        "J Yu"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "280"^^schema:Integer ;
    schema:headline "Deep Multimodal Distance Metric Learning Using Click Constraints for Image Ranking"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (12), 4014-4024"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15951051015794159671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<204> a schema:ScholarlyArticle ;
    schema:abstract "Supervised learning on molecules has incredible potential to be useful inchemistry, drug discovery, and materials science. Luckily, several promisingand closely related neural network models invariant to molecular symmetrieshave already been described in the literature. These models learn a messagepassing algorithm and aggregation procedure to compute a function of theirentire input graph. At this point, the next step is to find a particularlyeffective variant of this general approach and apply it to chemical predictionbenchmarks until we either solve them or reach the limits of the approach. Inthis paper, we reformulate existing models into a single common framework wecall Message Passing Neural Networks (MPNNs) and explore additional novelvariations within this framework. Using MPNNs we demonstrate state of the artresults on an important molecular property prediction benchmark; these resultsare strong enough that we believe future work should focus on datasets withlarger molecules or more accurate ground truth labels."^^schema:Text ;
    schema:author "George E. Dahl"^^schema:Person,
        "Justin Gilmer"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Patrick F. Riley"^^schema:Person,
        "Samuel S. Schoenholz"^^schema:Person ;
    schema:commentCount "1151"^^schema:Integer ;
    schema:dateModified "2017-06-12T20:52:56Z"^^schema:DateTime ;
    schema:datePublished "2017-04-04T23:00:44Z"^^schema:DateTime ;
    schema:genre "I.2.6"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Neural Message Passing for Quantum Chemistry"^^schema:Text ;
    schema:publisher "ICML, 1263-1272"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.01212v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6135306581977403485&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2040> a schema:ScholarlyArticle ;
    schema:author "F Nie"^^schema:Person,
        "W Zhu"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:headline "Unsupervised Feature Selection with Structured Graph Optimization"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5611876072729760174&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2041> a schema:ScholarlyArticle ;
    schema:author "B Fielding"^^schema:Person,
        "CP Lim"^^schema:Person,
        "K Mistry"^^schema:Person,
        "L Zhang"^^schema:Person,
        "SC Neoh"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "A Micro-GA Embedded PSO Feature Selection Approach to Intelligent Facial Emotion Recognition"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (6), 1496-1509"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=851495561975717977&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2042> a schema:ScholarlyArticle ;
    schema:author "G Velmurugan"^^schema:Person,
        "J Cao"^^schema:Person,
        "R Rakkiyappan"^^schema:Person ;
    schema:commentCount "160"^^schema:Integer ;
    schema:headline "Existence and uniform stability analysis of fractional-order complex-valued neural networks with time delays."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (1), 84-97"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13770418690197104502&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2043> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "J Li"^^schema:Person,
        "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "260"^^schema:Integer ;
    schema:headline "Neural Network Control-Based Adaptive Learning Design for Nonlinear Systems With Full-State Constraints"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (7), 1562-1571"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6848977424274277779&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2044> a schema:ScholarlyArticle ;
    schema:author "F Bacao"^^schema:Person,
        "G Douzas"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "Effective data generation for imbalanced learning using conditional generative adversarial networks"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 91, 464-471"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17322622248031909034&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2045> a schema:ScholarlyArticle ;
    schema:author "GWH Tan"^^schema:Person,
        "KB Ooi"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:headline "Mobile technology acceptance model: An investigation using mobile users to explore smartphone credit card"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 59, 33-46"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3322085676574141800&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2046> a schema:ScholarlyArticle ;
    schema:author "FL Lewis"^^schema:Person,
        "H Zhang"^^schema:Person,
        "Q Wei"^^schema:Person,
        "R Song"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "Off-Policy Actor-Critic Structure for Optimal Control of Unknown Systems With Disturbances"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (5), 1041-1050"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2019582285688225414&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2047> a schema:ScholarlyArticle ;
    schema:author "I Sutskever"^^schema:Person,
        "R Józefowicz"^^schema:Person,
        "W Zaremba"^^schema:Person ;
    schema:commentCount "1200"^^schema:Integer ;
    schema:headline "An Empirical Exploration of Recurrent Network Architectures."^^schema:Text ;
    schema:publisher "ICML, 2342-2350"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3565461567464548201&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2048> a schema:ScholarlyArticle ;
    schema:author "S Arora"^^schema:Person,
        "T Ma"^^schema:Person,
        "Y Liang"^^schema:Person ;
    schema:commentCount "601"^^schema:Integer ;
    schema:headline "A Simple but Tough-to-Beat Baseline for Sentence Embeddings."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13251134833412792901&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2049> a schema:ScholarlyArticle ;
    schema:author "CC Lim"^^schema:Person,
        "P Shi"^^schema:Person,
        "Y Liu"^^schema:Person,
        "YL Wang"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:headline "Event-Triggered Fault Detection Filter Design for a Continuous-Time Networked Control System"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (12), 3414-3426"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5898993210329262141&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<205> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), amodel that learns an interpretable representation of images. Thisrepresentation is disentangled with respect to transformations such asout-of-plane rotations and lighting variations. The DC-IGN model is composed ofmultiple layers of convolution and de-convolution operators and is trainedusing the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose atraining procedure to encourage neurons in the graphics code layer to representa specific transformation (e.g. pose or light). Given a single input image, ourmodel can generate new images of the same object with variations in pose andlighting. We present qualitative and quantitative results of the model'sefficacy at learning a 3D rendering engine."^^schema:Text ;
    schema:author "Joshua B. Tenenbaum"^^schema:Person,
        "Pushmeet Kohli"^^schema:Person,
        "Tejas D. Kulkarni"^^schema:Person,
        "Will Whitney"^^schema:Person ;
    schema:commentCount "649"^^schema:Integer ;
    schema:dateModified "2015-06-22T02:10:00Z"^^schema:DateTime ;
    schema:datePublished "2015-03-11T04:08:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Deep Convolutional Inverse Graphics Network"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.03167v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17778197936641141684&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2050> a schema:ScholarlyArticle ;
    schema:author "D Zhang"^^schema:Person,
        "J Han"^^schema:Person,
        "L Shao"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (6), 1163-1176"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1520934723336271902&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2051> a schema:ScholarlyArticle ;
    schema:author "C Mu"^^schema:Person,
        "C Sun"^^schema:Person,
        "H He"^^schema:Person,
        "Z Ni"^^schema:Person ;
    schema:commentCount "157"^^schema:Integer ;
    schema:headline "Air-Breathing Hypersonic Vehicle Tracking Control Based on Adaptive Dynamic Programming"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (3), 584-598"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8285038598560851417&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2052> a schema:ScholarlyArticle ;
    schema:author "B Du"^^schema:Person,
        "D Tao"^^schema:Person,
        "J Wu"^^schema:Person,
        "L Zhang"^^schema:Person,
        "W Xiong"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:headline "Stacked Convolutional Denoising Auto-Encoders for Feature Representation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (4), 1017-1027"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17268315241393644282&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2053> a schema:ScholarlyArticle ;
    schema:author "DN Metaxas"^^schema:Person,
        "J Huang"^^schema:Person,
        "L Zhong"^^schema:Person,
        "P Yang"^^schema:Person,
        "Q Liu"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Learning Multiscale Active Facial Patches for Expression Analysis."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (8), 1499-1510"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15789857402312776306&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2054> a schema:ScholarlyArticle ;
    schema:author "D Tao"^^schema:Person,
        "J Yu"^^schema:Person,
        "M Wang"^^schema:Person,
        "Y Rui"^^schema:Person ;
    schema:commentCount "250"^^schema:Integer ;
    schema:headline "Learning to Rank Using User Clicks and Visual Features for Image Retrieval"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 4 (45), 767-779"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17018389738119779156&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2055> a schema:ScholarlyArticle ;
    schema:author "DS Rosenblum"^^schema:Person,
        "L Nie"^^schema:Person,
        "L Zhang"^^schema:Person,
        "Y Liu"^^schema:Person,
        "Y Yan"^^schema:Person ;
    schema:commentCount "215"^^schema:Integer ;
    schema:headline "Fortune Teller: Predicting Your Career Path"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1787210683202844634&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2056> a schema:ScholarlyArticle ;
    schema:author "F Hutter"^^schema:Person,
        "JT Springenberg"^^schema:Person,
        "M Feurer"^^schema:Person ;
    schema:commentCount "223"^^schema:Integer ;
    schema:headline "Initializing Bayesian Hyperparameter Optimization via Meta-Learning"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5848165457175761276&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2057> a schema:ScholarlyArticle ;
    schema:author "J Lin"^^schema:Person,
        "Q Wang"^^schema:Person,
        "Y Yuan"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "Hyperspectral Image Classification via Multitask Joint Sparse Representation and Stepwise MRF Optimization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (12), 2966-2977"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=612581065024843994&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2058> a schema:ScholarlyArticle ;
    schema:author "G Hua"^^schema:Person,
        "L Wang"^^schema:Person,
        "W Tang"^^schema:Person ;
    schema:commentCount "134"^^schema:Integer ;
    schema:headline "How to Train a Compact Binary Neural Network with High Accuracy?"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7786548663200966080&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2059> a schema:ScholarlyArticle ;
    schema:author "LS Coelho"^^schema:Person,
        "S Mirjalili"^^schema:Person,
        "S Saremi"^^schema:Person,
        "SM Mirjalili"^^schema:Person ;
    schema:commentCount "366"^^schema:Integer ;
    schema:headline "Multi-objective grey wolf optimizer: A novel algorithm for multi-criterion optimization"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 47, 106-119"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11882590360204067994&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<206> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a neural network with a recurrent attention model over apossibly large external memory. The architecture is a form of Memory Network(Weston et al., 2015) but unlike the model in that work, it is trainedend-to-end, and hence requires significantly less supervision during training,making it more generally applicable in realistic settings. It can also be seenas an extension of RNNsearch to the case where multiple computational steps(hops) are performed per output symbol. The flexibility of the model allows usto apply it to tasks as diverse as (synthetic) question answering and tolanguage modeling. For the former our approach is competitive with MemoryNetworks, but with less supervision. For the latter, on the Penn TreeBank andText8 datasets our approach demonstrates comparable performance to RNNs andLSTMs. In both cases we show that the key concept of multiple computationalhops yields improved results."^^schema:Text ;
    schema:author "Arthur Szlam"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Rob Fergus"^^schema:Person,
        "Sainbayar Sukhbaatar"^^schema:Person ;
    schema:commentCount "1720"^^schema:Integer ;
    schema:dateModified "2015-11-24T19:41:57Z"^^schema:DateTime ;
    schema:datePublished "2015-03-31T03:05:37Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "End-To-End Memory Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.08895v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9907515383987281804&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2060> a schema:ScholarlyArticle ;
    schema:author "B Park"^^schema:Person,
        "JK Bae"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "Using machine learning algorithms for housing price prediction: The case of Fairfax County, Virginia housing data"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (6), 2928-2934"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14995626408504909542&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2061> a schema:ScholarlyArticle ;
    schema:author "P Cortez"^^schema:Person,
        "P Rita"^^schema:Person,
        "S Moro"^^schema:Person ;
    schema:commentCount "210"^^schema:Integer ;
    schema:headline "Business intelligence in banking: A literature analysis from 2002 to 2013 using text mining and latent Dirichlet allocation"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1314-1324"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14486796401025547677&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2062> a schema:ScholarlyArticle ;
    schema:author "ALI Oliveira"^^schema:Person,
        "JP Nobrega"^^schema:Person,
        "RC Brasileiro"^^schema:Person,
        "RC Cavalcante"^^schema:Person,
        "VLF Souza"^^schema:Person ;
    schema:commentCount "262"^^schema:Integer ;
    schema:headline "Computational Intelligence and Financial Markets: A Survey and Future Directions"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 55, 194-211"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7604609219271464490&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2063> a schema:ScholarlyArticle ;
    schema:author "A Baykasoğlu"^^schema:Person,
        "İ Gölcük"^^schema:Person ;
    schema:commentCount "134"^^schema:Integer ;
    schema:headline "An analysis of DEMATEL approaches for criteria interaction handling within ANP"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 46, 346-366"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5082958143621482099&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2064> a schema:ScholarlyArticle ;
    schema:author "S Kabir"^^schema:Person ;
    schema:commentCount "123"^^schema:Integer ;
    schema:headline "An overview of fault tree analysis and its application in model based dependability analysis"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 77, 114-135"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16193038880129201366&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2065> a schema:ScholarlyArticle ;
    schema:author "HF Yang"^^schema:Person,
        "TS Dillon"^^schema:Person,
        "YPP Chen"^^schema:Person ;
    schema:commentCount "117"^^schema:Integer ;
    schema:headline "Optimized Structure of the Traffic Flow Forecasting Model With a Deep Learning Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (10), 2371-2381"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7090678118619266260&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2066> a schema:ScholarlyArticle ;
    schema:author "S Krishnamoorthy"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Pruning strategies for mining high utility itemsets"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2371-2381"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17720739060982246043&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2067> a schema:ScholarlyArticle ;
    schema:author "H Du"^^schema:Person,
        "H Li"^^schema:Person,
        "HK Lam"^^schema:Person,
        "L Wu"^^schema:Person,
        "Z Chen"^^schema:Person ;
    schema:commentCount "232"^^schema:Integer ;
    schema:headline "Event-Triggered Fault Detection of Nonlinear Networked Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (4), 1041-1052"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5147265763590914612&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2068> a schema:ScholarlyArticle ;
    schema:author "T Harris"^^schema:Person ;
    schema:commentCount "188"^^schema:Integer ;
    schema:headline "Credit scoring using the clustered support vector machine"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (2), 741-750"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9921547592305956707&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2069> a schema:ScholarlyArticle ;
    schema:author "P Shi"^^schema:Person,
        "X Zhao"^^schema:Person,
        "X Zheng"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "Fuzzy Adaptive Control Design and Discretization for a Class of Nonlinear Uncertain Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (6), 1476-1483"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=850264831525323916&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<207> a schema:ScholarlyArticle ;
    schema:abstract "In many machine learning applications, labeled data is scarce and obtainingmore labels is expensive. We introduce a new approach to supervising neuralnetworks by specifying constraints that should hold over the output space,rather than direct examples of input-output pairs. These constraints arederived from prior domain knowledge, e.g., from known laws of physics. Wedemonstrate the effectiveness of this approach on real world and simulatedcomputer vision tasks. We are able to train a convolutional neural network todetect and track objects without any labeled examples. Our approach cansignificantly reduce the need for labeled training data, but introduces newchallenges for encoding prior knowledge into appropriate loss functions."^^schema:Text ;
    schema:author "Russell Stewart"^^schema:Person,
        "Stefano Ermon"^^schema:Person ;
    schema:commentCount "148"^^schema:Integer ;
    schema:dateModified "2016-09-18T23:16:14Z"^^schema:DateTime ;
    schema:datePublished "2016-09-18T23:16:14Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Label-Free Supervision of Neural Networks with Physics and Domain  Knowledge"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.05566v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16817242517861584671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2070> a schema:ScholarlyArticle ;
    schema:author "H Zhang"^^schema:Person,
        "XB Meng"^^schema:Person,
        "XZ Gao"^^schema:Person,
        "Y Liu"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:headline "A novel bat algorithm with habitat selection and Doppler effect in echoes for optimization"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (17-18), 6350-6364"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11655128972314789282&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2071> a schema:ScholarlyArticle ;
    schema:author "D Meng"^^schema:Person,
        "L Du"^^schema:Person,
        "X Cao"^^schema:Person,
        "X Guo"^^schema:Person,
        "X Wei"^^schema:Person ;
    schema:commentCount "181"^^schema:Integer ;
    schema:headline "High Capacity Reversible Data Hiding in Encrypted Images by Patch-Level Sparse Representation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (5), 1132-1143"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1831812351253049133&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2072> a schema:ScholarlyArticle ;
    schema:author "G Xu"^^schema:Person,
        "L Huang"^^schema:Person,
        "S Deng"^^schema:Person,
        "X Wu"^^schema:Person,
        "Z Wu"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "On Deep Learning for Trust-Aware Recommendations in Social Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (5), 1164-1177"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13690135629834919536&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2073> a schema:ScholarlyArticle ;
    schema:author "H Li"^^schema:Person,
        "P Shi"^^schema:Person,
        "R Lu"^^schema:Person,
        "S Xie"^^schema:Person,
        "Y Xu"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:headline "Finite-Time Distributed State Estimation Over Sensor Networks With Round-Robin Protocol and Fading Channels"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (1), 336-345"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16540148762013858009&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2074> a schema:ScholarlyArticle ;
    schema:author "WC Kang"^^schema:Person,
        "WJ Li"^^schema:Person,
        "ZH Zhou"^^schema:Person ;
    schema:commentCount "174"^^schema:Integer ;
    schema:headline "Column Sampling Based Discrete Supervised Hashing"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7890115267922892228&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2075> a schema:ScholarlyArticle ;
    schema:author "C Liu"^^schema:Person,
        "N Liu"^^schema:Person,
        "Y Xia"^^schema:Person,
        "YY Li"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:headline "A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 78, 225-241"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1478171577878735440&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2076> a schema:ScholarlyArticle ;
    schema:author "A Xue"^^schema:Person,
        "H Peng"^^schema:Person,
        "K Xie"^^schema:Person,
        "R Lu"^^schema:Person,
        "Y Xu"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:headline "Asynchronous Dissipative State Estimation for Stochastic Complex Networks With Quantized Jumping Coupling and Uncertain Measurements"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (2), 268-277"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3676122125791537877&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2077> a schema:ScholarlyArticle ;
    schema:author "J Velcin"^^schema:Person,
        "K Shirai"^^schema:Person,
        "TH Nguyen"^^schema:Person ;
    schema:commentCount "268"^^schema:Integer ;
    schema:headline "Sentiment analysis on social media for stock movement prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (24), 9603-9611"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7027442094742868116&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2078> a schema:ScholarlyArticle ;
    schema:author "F Zhu"^^schema:Person,
        "L Shao"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "320"^^schema:Integer ;
    schema:headline "Transfer Learning for Visual Categorization: A Survey"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 5 (26), 1019-1034"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8275702504720659040&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2079> a schema:ScholarlyArticle ;
    schema:author "F Bao"^^schema:Person,
        "Q Dai"^^schema:Person,
        "Y Deng"^^schema:Person,
        "Y Kong"^^schema:Person,
        "Z Ren"^^schema:Person ;
    schema:commentCount "235"^^schema:Integer ;
    schema:headline "Deep Direct Reinforcement Learning for Financial Signal Representation and Trading"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (3), 653-664"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2199091952431880177&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<208> a schema:ScholarlyArticle ;
    schema:abstract "We explore deep reinforcement learning methods for multi-agent domains. Webegin by analyzing the difficulty of traditional algorithms in the multi-agentcase: Q-learning is challenged by an inherent non-stationarity of theenvironment, while policy gradient suffers from a variance that increases asthe number of agents grows. We then present an adaptation of actor-criticmethods that considers action policies of other agents and is able tosuccessfully learn policies that require complex multi-agent coordination.Additionally, we introduce a training regimen utilizing an ensemble of policiesfor each agent that leads to more robust multi-agent policies. We show thestrength of our approach compared to existing methods in cooperative as well ascompetitive scenarios, where agent populations are able to discover variousphysical and informational coordination strategies."^^schema:Text ;
    schema:author "Aviv Tamar"^^schema:Person,
        "Igor Mordatch"^^schema:Person,
        "Jean Harb"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Ryan Lowe"^^schema:Person,
        "Yi Wu"^^schema:Person ;
    schema:commentCount "724"^^schema:Integer ;
    schema:dateModified "2020-03-14T20:33:00Z"^^schema:DateTime ;
    schema:datePublished "2017-06-07T17:35:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02275v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11728876531627940507&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2080> a schema:ScholarlyArticle ;
    schema:author "H Shen"^^schema:Person,
        "JH Park"^^schema:Person,
        "L Zhang"^^schema:Person,
        "Y Zhu"^^schema:Person ;
    schema:commentCount "319"^^schema:Integer ;
    schema:headline "Extended Dissipative State Estimation for Markov Jump Neural Networks With Unreliable Links"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (2), 346-358"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5516430803402666860&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2081> a schema:ScholarlyArticle ;
    schema:author "G Bing"^^schema:Person,
        "G Haixiang"^^schema:Person,
        "G Mingyun"^^schema:Person,
        "H Yuanyue"^^schema:Person,
        "J Shang"^^schema:Person,
        "L Yijing"^^schema:Person ;
    schema:commentCount "498"^^schema:Integer ;
    schema:headline "Learning from class-imbalanced data: Review of methods and applications"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 73, 220-239"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3140069985091518864&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2082> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "CM Pun"^^schema:Person,
        "Y Zhou"^^schema:Person,
        "Z Hua"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:headline "Cascade Chaotic System With Applications"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 9 (45), 2001-2012"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2748287032081264787&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2083> a schema:ScholarlyArticle ;
    schema:author "B Chen"^^schema:Person,
        "C Lin"^^schema:Person,
        "F Wang"^^schema:Person,
        "J Zhang"^^schema:Person,
        "X Meng"^^schema:Person ;
    schema:commentCount "166"^^schema:Integer ;
    schema:headline "Adaptive Neural Network Finite-Time Output Feedback Control of Quantized Nonlinear Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (6), 1839-1848"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13127759836684272591&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2084> a schema:ScholarlyArticle ;
    schema:author "A Boru"^^schema:Person,
        "AT Dosdoğru"^^schema:Person,
        "M Göçken"^^schema:Person,
        "M Özçalıcı"^^schema:Person ;
    schema:commentCount "120"^^schema:Integer ;
    schema:headline "Integrating metaheuristics and Artificial Neural Networks for improved stock price prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 44, 320-331"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7217450796326354330&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2085> a schema:ScholarlyArticle ;
    schema:author "H Zhang"^^schema:Person,
        "L Liu"^^schema:Person,
        "QH Shan"^^schema:Person,
        "Z Wang"^^schema:Person ;
    schema:commentCount "110"^^schema:Integer ;
    schema:headline "Stability Criteria for Recurrent Neural Networks With Time-Varying Delay Based on Secondary Delay Partitioning Method"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2589-2595"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4686029005537209442&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2086> a schema:ScholarlyArticle ;
    schema:author "H Larochelle"^^schema:Person,
        "S Ravi"^^schema:Person ;
    schema:commentCount "848"^^schema:Integer ;
    schema:headline "Optimization as a Model for Few-Shot Learning."^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2802287484729681329&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2087> a schema:ScholarlyArticle ;
    schema:author "A Bhardwaj"^^schema:Person,
        "A Tiwari"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Breast cancer diagnosis using Genetically Optimized Neural Network model"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (10), 4611-4620"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7841563337613021379&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2088> a schema:ScholarlyArticle ;
    schema:author "H Liu"^^schema:Person,
        "J Gu"^^schema:Person,
        "Y Yu"^^schema:Person,
        "Z Huang"^^schema:Person ;
    schema:commentCount "169"^^schema:Integer ;
    schema:headline "An Efficient Method for Traffic Sign Recognition Based on Extreme Learning Machine"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (4), 920-933"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13785057192993694434&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2089> a schema:ScholarlyArticle ;
    schema:author "J Patel"^^schema:Person,
        "K Kotecha"^^schema:Person,
        "P Thakkar"^^schema:Person,
        "S Shah"^^schema:Person ;
    schema:commentCount "449"^^schema:Integer ;
    schema:headline "Predicting stock and stock price index movement using Trend Deterministic Data Preparation and machine learning techniques"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (1), 259-268"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10852067915249324496&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<209> a schema:ScholarlyArticle ;
    schema:abstract "We propose a method for learning expressive energy-based policies forcontinuous states and actions, which has been feasible only in tabular domainsbefore. We apply our method to learning maximum entropy policies, resultinginto a new algorithm, called soft Q-learning, that expresses the optimal policyvia a Boltzmann distribution. We use the recently proposed amortized Steinvariational gradient descent to learn a stochastic sampling network thatapproximates samples from this distribution. The benefits of the proposedalgorithm include improved exploration and compositionality that allowstransferring skills between tasks, which we confirm in simulated experimentswith swimming and walking robots. We also draw a connection to actor-criticmethods, which can be viewed performing approximate inference on thecorresponding energy-based model."^^schema:Text ;
    schema:author "Haoran Tang"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Tuomas Haarnoja"^^schema:Person ;
    schema:commentCount "369"^^schema:Integer ;
    schema:dateModified "2017-07-21T20:25:54Z"^^schema:DateTime ;
    schema:datePublished "2017-02-27T07:16:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Reinforcement Learning with Deep Energy-Based Policies"^^schema:Text ;
    schema:publisher "ICML, 1352-1361"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.08165v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10187244454208251417&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2090> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "DJ Li"^^schema:Person,
        "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "154"^^schema:Integer ;
    schema:headline "Neural Controller Design-Based Adaptive Control for Nonlinear MIMO Systems With Unknown Hysteresis Inputs"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 9-19"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4149334991282681935&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2091> a schema:ScholarlyArticle ;
    schema:author "H Li"^^schema:Person,
        "HK Lam"^^schema:Person,
        "L Wu"^^schema:Person,
        "Y Gao"^^schema:Person ;
    schema:commentCount "190"^^schema:Integer ;
    schema:headline "Fault detection for TS fuzzy time-delay systems: delta operator and input-output methods."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (2), 229-241"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8679883137105648946&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2092> a schema:ScholarlyArticle ;
    schema:author "KB Ooi"^^schema:Person,
        "LY Leong"^^schema:Person,
        "TS Hew"^^schema:Person,
        "VH Lee"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:headline "An SEM–artificial-neural-network analysis of the relationships between SERVPERF, customer satisfaction and loyalty among low-cost and full-service airline"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (19), 6620-6634"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3942581368609339637&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2093> a schema:ScholarlyArticle ;
    schema:author "C Fermuller"^^schema:Person,
        "Y Aloimonos"^^schema:Person,
        "Y Li"^^schema:Person,
        "Y Yang"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Robot Learning Manipulation Action Plans by\" Watching\" Unconstrained Videos from the World Wide Web"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10530416624799735095&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2094> a schema:ScholarlyArticle ;
    schema:author "JM Tomczak"^^schema:Person,
        "M Zięba"^^schema:Person,
        "SK Tomczak"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Ensemble boosted trees with synthetic features generation in application to bankruptcy prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 58, 93-101"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17819897814601971460&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2095> a schema:ScholarlyArticle ;
    schema:author "K Lu"^^schema:Person,
        "L Liu"^^schema:Person,
        "L Shao"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "163"^^schema:Integer ;
    schema:headline "Learning Spatio-Temporal Representations for Action Recognition: A Genetic Programming Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 158-170"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16311027906315028284&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2096> a schema:ScholarlyArticle ;
    schema:author "H Yan"^^schema:Person,
        "J Lu"^^schema:Person,
        "X Zhou"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Prototype-Based Discriminative Feature Learning for Kinship Verification."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (11), 2535-2545"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7776468140595259818&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2097> a schema:ScholarlyArticle ;
    schema:author "F Dweiri"^^schema:Person,
        "S Kumar"^^schema:Person,
        "SA Khan"^^schema:Person,
        "V Jain"^^schema:Person ;
    schema:commentCount "212"^^schema:Integer ;
    schema:headline "Designing an integrated AHP based decision support system for supplier selection in automotive industry"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 62, 273-283"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16940395383927853783&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2098> a schema:ScholarlyArticle ;
    schema:author "BIP Rubinstein"^^schema:Person,
        "J Bailey"^^schema:Person,
        "J He"^^schema:Person,
        "R Zhang"^^schema:Person ;
    schema:commentCount "127"^^schema:Integer ;
    schema:headline "Identifying At-Risk Students in Massive Open Online Courses"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3675734962501745230&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2099> a schema:ScholarlyArticle ;
    schema:author "CA Ronao"^^schema:Person,
        "SB Cho"^^schema:Person ;
    schema:commentCount "439"^^schema:Integer ;
    schema:headline "Human activity recognition with smartphone sensors using deep learning neural networks"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 59, 235-244"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4770771192678993599&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<21> a schema:ScholarlyArticle ;
    schema:abstract "Planning has been very successful for control tasks with known environmentdynamics. To leverage planning in unknown environments, the agent needs tolearn the dynamics from interactions with the world. However, learning dynamicsmodels that are accurate enough for planning has been a long-standingchallenge, especially in image-based domains. We propose the Deep PlanningNetwork (PlaNet), a purely model-based agent that learns the environmentdynamics from images and chooses actions through fast online planning in latentspace. To achieve high performance, the dynamics model must accurately predictthe rewards ahead for multiple time steps. We approach this using a latentdynamics model with both deterministic and stochastic transition components.Moreover, we propose a multi-step variational inference objective that we namelatent overshooting. Using only pixel observations, our agent solves continuouscontrol tasks with contact dynamics, partial observability, and sparse rewards,which exceed the difficulty of tasks that were previously solved by planningwith learned models. PlaNet uses substantially fewer episodes and reaches finalperformance close to and sometimes higher than strong model-free algorithms."^^schema:Text ;
    schema:author "Danijar Hafner"^^schema:Person,
        "David Ha"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Ian Fischer"^^schema:Person,
        "James Davidson"^^schema:Person,
        "Ruben Villegas"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:dateModified "2019-06-04T18:13:09Z"^^schema:DateTime ;
    schema:datePublished "2018-11-12T04:30:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Latent Dynamics for Planning from Pixels"^^schema:Text ;
    schema:publisher "ICML, 2555-2565"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1811.04551v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15406315513072250791&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<210> a schema:ScholarlyArticle ;
    schema:abstract "Learning in adversarial settings is becoming an important task forapplication domains where attackers may inject malicious data into the trainingset to subvert normal operation of data-driven technologies. Feature selectionhas been widely used in machine learning for security applications to improvegeneralization and computational efficiency, although it is not clear whetherits use may be beneficial or even counterproductive when training data arepoisoned by intelligent attackers. In this work, we shed light on this issue byproviding a framework to investigate the robustness of popular featureselection methods, including LASSO, ridge regression and the elastic net. Ourresults on malware detection show that feature selection methods can besignificantly compromised under attack (we can reduce LASSO to almost randomchoices of feature sets by careful insertion of less than 5% poisoned trainingsamples), highlighting the need for specific countermeasures."^^schema:Text ;
    schema:author "Battista Biggio"^^schema:Person,
        "Claudia Eckert"^^schema:Person,
        "Fabio Roli"^^schema:Person,
        "Gavin Brown"^^schema:Person,
        "Giorgio Fumera"^^schema:Person,
        "Huang Xiao"^^schema:Person ;
    schema:commentCount "180"^^schema:Integer ;
    schema:dateModified "2018-04-21T10:18:46Z"^^schema:DateTime ;
    schema:datePublished "2018-04-21T10:18:46Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.GT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Is feature selection secure against training data poisoning?"^^schema:Text ;
    schema:publisher "ICML, 1689-1698"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.07933v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1517576158054536968&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2100> a schema:ScholarlyArticle ;
    schema:author "A Cichocki"^^schema:Person,
        "B Wang"^^schema:Person,
        "G Zhou"^^schema:Person,
        "J Jin"^^schema:Person,
        "X Wang"^^schema:Person,
        "Y Wang"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "113"^^schema:Integer ;
    schema:headline "Multi-kernel extreme learning machine for EEG classification in brain-computer interfaces"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 96, 302-310"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9393105038454606996&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2101> a schema:ScholarlyArticle ;
    schema:author "D Tao"^^schema:Person,
        "J Gui"^^schema:Person,
        "S Ji"^^schema:Person,
        "T Tan"^^schema:Person,
        "Z Sun"^^schema:Person ;
    schema:commentCount "161"^^schema:Integer ;
    schema:headline "Feature Selection Based on Structured Sparsity: A Comprehensive Study"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (7), 1490-1507"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1332515293635580819&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2102> a schema:ScholarlyArticle ;
    schema:author "A Casanova"^^schema:Person,
        "A Romero"^^schema:Person,
        "G Cucurull"^^schema:Person,
        "P Liò"^^schema:Person,
        "P Velickovic"^^schema:Person,
        "Y Bengio"^^schema:Person ;
    schema:commentCount "1580"^^schema:Integer ;
    schema:headline "Graph Attention Networks."^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5609128480281463225&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2103> a schema:ScholarlyArticle ;
    schema:author "J Liu"^^schema:Person,
        "K Qin"^^schema:Person,
        "M Gong"^^schema:Person,
        "P Zhang"^^schema:Person ;
    schema:commentCount "109"^^schema:Integer ;
    schema:headline "A Deep Convolutional Coupling Network for Change Detection Based on Heterogeneous Optical and Radar Images"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (3), 545-559"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15044710783765599610&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2104> a schema:ScholarlyArticle ;
    schema:author "B Xu"^^schema:Person,
        "C Yang"^^schema:Person,
        "Y Pan"^^schema:Person ;
    schema:commentCount "235"^^schema:Integer ;
    schema:headline "Global Neural Dynamic Surface Tracking Control of Strict-Feedback Systems With Application to Hypersonic Flight Vehicle"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (10), 2563-2575"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17406253389759883582&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2105> a schema:ScholarlyArticle ;
    schema:author "H Luan"^^schema:Person,
        "J Jia"^^schema:Person,
        "M Sun"^^schema:Person,
        "R Xie"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "257"^^schema:Integer ;
    schema:headline "Representation Learning of Knowledge Graphs with Entity Descriptions"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7918668133764568492&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2106> a schema:ScholarlyArticle ;
    schema:author "R Cheng"^^schema:Person,
        "Y Jin"^^schema:Person ;
    schema:commentCount "286"^^schema:Integer ;
    schema:headline "A Competitive Swarm Optimizer for Large Scale Optimization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 2 (45), 191-204"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11459274454635864340&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2107> a schema:ScholarlyArticle ;
    schema:author "B Zhang"^^schema:Person,
        "F Qian"^^schema:Person,
        "J Cao"^^schema:Person,
        "J Kurths"^^schema:Person,
        "QL Han"^^schema:Person,
        "W He"^^schema:Person ;
    schema:commentCount "185"^^schema:Integer ;
    schema:headline "Leader-Following Consensus of Nonlinear Multiagent Systems With Stochastic Sampling"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (2), 327-338"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9453664241315055914&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2108> a schema:ScholarlyArticle ;
    schema:author "N Ahmed"^^schema:Person,
        "R Rossi"^^schema:Person ;
    schema:commentCount "580"^^schema:Integer ;
    schema:headline "The Network Data Repository with Interactive Graph Analytics and Visualization"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5576118795538167875&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2109> a schema:ScholarlyArticle ;
    schema:author "G Wei"^^schema:Person,
        "J Wang"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "A comparative study of robust efficiency analysis and Data Envelopment Analysis with imprecise data"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 81, 28-38"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5502450700324601496&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<211> a schema:ScholarlyArticle ;
    schema:abstract "We present the Neural Physics Engine (NPE), a framework for learningsimulators of intuitive physics that naturally generalize across variableobject count and different scene configurations. We propose a factorization ofa physical scene into composable object-based representations and a neuralnetwork architecture whose compositional structure factorizes object dynamicsinto pairwise interactions. Like a symbolic physics engine, the NPE is endowedwith generic notions of objects and their interactions; realized as a neuralnetwork, it can be trained via stochastic gradient descent to adapt to specificobject properties and dynamics of different worlds. We evaluate the efficacy ofour approach on simple rigid body dynamics in two-dimensional worlds. Bycomparing to less structured architectures, we show that the NPE'scompositional representation of the structure in physical interactions improvesits ability to predict movement, generalize across variable object count anddifferent scene configurations, and infer latent properties of objects such asmass."^^schema:Text ;
    schema:author "Antonio Torralba"^^schema:Person,
        "Joshua B. Tenenbaum"^^schema:Person,
        "Michael B. Chang"^^schema:Person,
        "Tomer Ullman"^^schema:Person ;
    schema:commentCount "220"^^schema:Integer ;
    schema:dateModified "2017-03-04T17:44:06Z"^^schema:DateTime ;
    schema:datePublished "2016-12-01T16:39:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Compositional Object-Based Approach to Learning Physical Dynamics"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.00341v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9706972547667418204&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2110> a schema:ScholarlyArticle ;
    schema:author "DWC Ho"^^schema:Person,
        "J Cao"^^schema:Person,
        "L Li"^^schema:Person,
        "W Xu"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:headline "Event-Triggered Schemes on Leader-Following Consensus of General Linear Multiagent Systems Under Different Topologies"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (1), 212-223"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=112000445458391006&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2111> a schema:ScholarlyArticle ;
    schema:author "C Liu"^^schema:Person,
        "C Zhang"^^schema:Person,
        "G Almpanidis"^^schema:Person,
        "X Zhang"^^schema:Person ;
    schema:commentCount "145"^^schema:Integer ;
    schema:headline "An up-to-date comparison of state-of-the-art classification algorithms"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 82, 128-150"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9237966459220621829&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2112> a schema:ScholarlyArticle ;
    schema:author "D Zhang"^^schema:Person,
        "J Yang"^^schema:Person,
        "J You"^^schema:Person,
        "Y Xu"^^schema:Person,
        "Z Zhong"^^schema:Person ;
    schema:commentCount "107"^^schema:Integer ;
    schema:headline "A New Discriminative Sparse Representation Method for Robust Face Recognition via $ l_ {2} $ Regularization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (10), 2233-2242"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15846317792211860224&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2113> a schema:ScholarlyArticle ;
    schema:author "MS Memon"^^schema:Person,
        "SI Mari"^^schema:Person,
        "YH Lee"^^schema:Person ;
    schema:commentCount "123"^^schema:Integer ;
    schema:headline "Group multi-criteria supplier selection using combined grey systems theory and uncertainty theory"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (21), 7951-7959"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12066373772355785684&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2114> a schema:ScholarlyArticle ;
    schema:author "B Khayambashi"^^schema:Person,
        "M Javanmardi"^^schema:Person,
        "M Karbasian"^^schema:Person,
        "Y Beikkhakhian"^^schema:Person ;
    schema:commentCount "137"^^schema:Integer ;
    schema:headline "The application of ISM model in evaluating agile suppliers selection criteria and ranking suppliers using fuzzy TOPSIS-AHP methods"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (15-16), 6224-6236"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13213673189903283736&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2115> a schema:ScholarlyArticle ;
    schema:author "S Yi"^^schema:Person,
        "X You"^^schema:Person,
        "YM Cheung"^^schema:Person,
        "YY Tang"^^schema:Person,
        "Z He"^^schema:Person ;
    schema:commentCount "174"^^schema:Integer ;
    schema:headline "Robust Object Tracking via Key Patch Sparse Representation"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (2), 354-364"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15643372067752107493&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2116> a schema:ScholarlyArticle ;
    schema:author "D Van den Poel"^^schema:Person,
        "M Ballings"^^schema:Person,
        "N Hespeels"^^schema:Person,
        "R Gryp"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:headline "Evaluating multiple classifiers for stock price direction prediction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (20), 7046-7056"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9867439326510468071&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2117> a schema:ScholarlyArticle ;
    schema:author "H Li"^^schema:Person,
        "H Wang"^^schema:Person,
        "P Shi"^^schema:Person,
        "Q Zhou"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:headline "Adaptive Neural Tracking Control for a Class of Nonlinear Systems With Dynamic Uncertainties."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 47 (10), 3075-3087"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5670997868010554926&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2118> a schema:ScholarlyArticle ;
    schema:author "W He"^^schema:Person,
        "Y Dong"^^schema:Person ;
    schema:commentCount "284"^^schema:Integer ;
    schema:headline "Adaptive Fuzzy Neural Network Control for a Constrained Robot Using Impedance Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1174-1186"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9754727230080925567&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2119> a schema:ScholarlyArticle ;
    schema:author "F Nie"^^schema:Person,
        "H Huang"^^schema:Person,
        "J Huang"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "182"^^schema:Integer ;
    schema:headline "Large-Scale Multi-View Spectral Clustering via Bipartite Graph"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5097865738576234936&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<212> a schema:ScholarlyArticle ;
    schema:abstract "State-of-the-art methods for learning cross-lingual word embeddings haverelied on bilingual dictionaries or parallel corpora. Recent studies showedthat the need for parallel data supervision can be alleviated withcharacter-level information. While these methods showed encouraging results,they are not on par with their supervised counterparts and are limited to pairsof languages sharing a common alphabet. In this work, we show that we can builda bilingual dictionary between two languages without using any parallelcorpora, by aligning monolingual word embedding spaces in an unsupervised way.Without using any character information, our model even outperforms existingsupervised methods on cross-lingual tasks for some language pairs. Ourexperiments demonstrate that our method works very well also for distantlanguage pairs, like English-Russian or English-Chinese. We finally describeexperiments on the English-Esperanto low-resource language pair, on which thereonly exists a limited amount of parallel data, to show the potential impact ofour method in fully unsupervised machine translation. Our code, embeddings anddictionaries are publicly available."^^schema:Text ;
    schema:author "Alexis Conneau"^^schema:Person,
        "Guillaume Lample"^^schema:Person,
        "Hervé Jégou"^^schema:Person,
        "Ludovic Denoyer"^^schema:Person,
        "Marc'Aurelio Ranzato"^^schema:Person ;
    schema:commentCount "658"^^schema:Integer ;
    schema:dateModified "2018-01-30T14:41:51Z"^^schema:DateTime ;
    schema:datePublished "2017-10-11T14:24:28Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Word Translation Without Parallel Data"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.04087v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10646845124593498896&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2120> a schema:ScholarlyArticle ;
    schema:author "B Gu"^^schema:Person,
        "VS Sheng"^^schema:Person,
        "X Sun"^^schema:Person ;
    schema:commentCount "336"^^schema:Integer ;
    schema:headline "Structural Minimax Probability Machine"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (7), 1646-1656"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17995193379361454253&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2121> a schema:ScholarlyArticle ;
    schema:author "L Jin"^^schema:Person,
        "S Li"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "110"^^schema:Integer ;
    schema:headline "Integration-Enhanced Zhang Neural Network for Real-Time-Varying Matrix Inversion in the Presence of Various Kinds of Noises"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (12), 2615-2627"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4418191425649571883&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2122> a schema:ScholarlyArticle ;
    schema:author "L Ding"^^schema:Person,
        "QL Han"^^schema:Person,
        "X Ge"^^schema:Person,
        "XM Zhang"^^schema:Person ;
    schema:commentCount "297"^^schema:Integer ;
    schema:headline "An Overview of Recent Advances in Event-Triggered Consensus of Multiagent Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (4), 1110-1123"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17516065164751753388&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2123> a schema:ScholarlyArticle ;
    schema:author "JA Bilmes"^^schema:Person,
        "K Livescu"^^schema:Person,
        "R Arora"^^schema:Person,
        "W Wang"^^schema:Person ;
    schema:commentCount "428"^^schema:Integer ;
    schema:headline "On Deep Multi-View Representation Learning."^^schema:Text ;
    schema:publisher "ICML, 1083-1092"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9056558950588383944&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2124> a schema:ScholarlyArticle ;
    schema:author "L Wang"^^schema:Person,
        "T Chen"^^schema:Person,
        "Y Zeng"^^schema:Person ;
    schema:commentCount "329"^^schema:Integer ;
    schema:headline "Back propagation neural network with adaptive differential evolution algorithm for time series forecasting"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (2), 855-863"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12459375852477026433&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2125> a schema:ScholarlyArticle ;
    schema:author "H Chen"^^schema:Person,
        "J Qin"^^schema:Person,
        "PA Heng"^^schema:Person,
        "Q Dou"^^schema:Person,
        "X Wang"^^schema:Person ;
    schema:commentCount "144"^^schema:Integer ;
    schema:headline "Mitosis Detection in Breast Cancer Histology Images via Deep Cascaded Networks"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5574904701613475175&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2126> a schema:ScholarlyArticle ;
    schema:author "AM Abdel-Zaher"^^schema:Person,
        "AM Eldeib"^^schema:Person ;
    schema:commentCount "233"^^schema:Integer ;
    schema:headline "Breast cancer classification using deep belief networks"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 46, 139-144"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3684030169754702199&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2127> a schema:ScholarlyArticle ;
    schema:author "J Razmi"^^schema:Person,
        "M Abdollahi"^^schema:Person,
        "M Arvan"^^schema:Person ;
    schema:commentCount "130"^^schema:Integer ;
    schema:headline "An integrated approach for supplier portfolio selection: Lean or agile?"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (1), 679-690"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16410261863631202358&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2128> a schema:ScholarlyArticle ;
    schema:author "K Sohn"^^schema:Person ;
    schema:commentCount "428"^^schema:Integer ;
    schema:headline "Improved deep metric learning with multi-class N-pair loss objective"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12886354739576660748&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2129> a schema:ScholarlyArticle ;
    schema:author "MZA Nazri"^^schema:Person,
        "WL Al-Yaseen"^^schema:Person,
        "ZA Othman"^^schema:Person ;
    schema:commentCount "157"^^schema:Integer ;
    schema:headline "Multi-level hybrid support vector machine and extreme learning machine based on modified K-means for intrusion detection system"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 67, 296-303"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16421414437107278290&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<213> a schema:ScholarlyArticle ;
    schema:abstract "PixelCNNs are a recently proposed class of powerful generative models withtractable likelihood. Here we discuss our implementation of PixelCNNs which wemake available at https://github.com/openai/pixel-cnn. Our implementationcontains a number of modifications to the original model that both simplify itsstructure and improve its performance. 1) We use a discretized logistic mixturelikelihood on the pixels, rather than a 256-way softmax, which we find to speedup training. 2) We condition on whole pixels, rather than R/G/B sub-pixels,simplifying the model structure. 3) We use downsampling to efficiently capturestructure at multiple resolutions. 4) We introduce additional short-cutconnections to further speed up optimization. 5) We regularize the model usingdropout. Finally, we present state-of-the-art log likelihood results onCIFAR-10 to demonstrate the usefulness of these modifications."^^schema:Text ;
    schema:author "Andrej Karpathy"^^schema:Person,
        "Diederik P. Kingma"^^schema:Person,
        "Tim Salimans"^^schema:Person,
        "Xi Chen"^^schema:Person ;
    schema:commentCount "337"^^schema:Integer ;
    schema:dateModified "2017-01-19T17:29:06Z"^^schema:DateTime ;
    schema:datePublished "2017-01-19T17:29:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture  Likelihood and Other Modifications"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.05517v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3764972270987352239&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2130> a schema:ScholarlyArticle ;
    schema:author "D Pamučar"^^schema:Person,
        "G Ćirović"^^schema:Person ;
    schema:commentCount "205"^^schema:Integer ;
    schema:headline "The selection of transport and handling resources in logistics centers using Multi-Attributive Border Approximation area Comparison (MABAC)"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (6), 3016-3028"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14228183778339765099&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2131> a schema:ScholarlyArticle ;
    schema:author "CA Iglesias"^^schema:Person,
        "I Corcuera-Platas"^^schema:Person,
        "JF Sánchez-Rada"^^schema:Person,
        "O Araque"^^schema:Person ;
    schema:commentCount "200"^^schema:Integer ;
    schema:headline "Enhancing deep learning sentiment analysis with ensemble techniques in social applications"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 77, 236-246"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15292059441894995609&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2132> a schema:ScholarlyArticle ;
    schema:author "S Tong"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "229"^^schema:Integer ;
    schema:headline "Adaptive Fuzzy Output-Feedback Stabilization Control for a Class of Switched Nonstrict-Feedback Nonlinear Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (4), 1007-1016"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16103099921481693028&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2133> a schema:ScholarlyArticle ;
    schema:author "M Bennasar"^^schema:Person,
        "R Setchi"^^schema:Person,
        "Y Hicks"^^schema:Person ;
    schema:commentCount "270"^^schema:Integer ;
    schema:headline "Feature selection using Joint Mutual Information Maximisation"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (22), 8520-8532"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1743947334553460683&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2134> a schema:ScholarlyArticle ;
    schema:author "D Zhang"^^schema:Person,
        "K Zhang"^^schema:Person,
        "KM Lam"^^schema:Person,
        "L Zhang"^^schema:Person ;
    schema:commentCount "247"^^schema:Integer ;
    schema:headline "A Level Set Approach to Image Segmentation With Intensity Inhomogeneity"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (2), 546-557"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=18227489507458213261&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2135> a schema:ScholarlyArticle ;
    schema:author "A Klein"^^schema:Person,
        "F Hutter"^^schema:Person,
        "JT Springenberg"^^schema:Person,
        "K Eggensperger"^^schema:Person,
        "M Blum"^^schema:Person,
        "M Feurer"^^schema:Person ;
    schema:commentCount "736"^^schema:Integer ;
    schema:headline "Efficient and robust automated machine learning"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11834086689942643321&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2136> a schema:ScholarlyArticle ;
    schema:author "JR Castro"^^schema:Person,
        "MA Sanchez"^^schema:Person,
        "O Castillo"^^schema:Person ;
    schema:commentCount "161"^^schema:Integer ;
    schema:headline "Generalized Type-2 Fuzzy Systems for controlling a mobile robot and a performance comparison with Interval Type-2 and Type-1 Fuzzy Systems"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (14), 5904-5914"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17011565443028310947&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2137> a schema:ScholarlyArticle ;
    schema:author "J Wu"^^schema:Person,
        "M Gong"^^schema:Person,
        "SS Ge"^^schema:Person,
        "W Chen"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:headline "Globally Stable Adaptive Backstepping Neural Network Control for Uncertain Strict-Feedback Systems With Tracking Accuracy Known a Priori."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (9), 1842-1854"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4769691329778606349&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2138> a schema:ScholarlyArticle ;
    schema:author "B Chen"^^schema:Person,
        "C Lin"^^schema:Person,
        "J Yu"^^schema:Person,
        "P Shi"^^schema:Person,
        "W Dong"^^schema:Person ;
    schema:commentCount "151"^^schema:Integer ;
    schema:headline "Neural network-based adaptive dynamic surface control for permanent magnet synchronous motors."^^schema:Text ;
    schema:publisher "Ieee Transactions on Neural Networks and Learning Systems 26 (3), 640-645"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3758572293856788254&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2139> a schema:ScholarlyArticle ;
    schema:author "A Kumar"^^schema:Person,
        "AK Bhandari"^^schema:Person,
        "GK Singh"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:headline "Tsallis entropy based multilevel thresholding for colored satellite image segmentation using evolutionary algorithms"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (22), 8707-8730"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=1584370641269444399&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<214> a schema:ScholarlyArticle ;
    schema:abstract "Recent work on fairness in machine learning has focused on variousstatistical discrimination criteria and how they trade off. Most of thesecriteria are observational: They depend only on the joint distribution ofpredictor, protected attribute, features, and outcome. While convenient to workwith, observational criteria have severe inherent limitations that prevent themfrom resolving matters of fairness conclusively.  Going beyond observational criteria, we frame the problem of discriminationbased on protected attributes in the language of causal reasoning. Thisviewpoint shifts attention from \"What is the right fairness criterion?\" to\"What do we want to assume about the causal data generating process?\" Throughthe lens of causality, we make several contributions. First, we crisplyarticulate why and when observational criteria fail, thus formalizing what wasbefore a matter of opinion. Second, our approach exposes previously ignoredsubtleties and why they are fundamental to the problem. Finally, we put forwardnatural causal non-discrimination criteria and develop algorithms that satisfythem."^^schema:Text ;
    schema:author "Bernhard Schölkopf"^^schema:Person,
        "Dominik Janzing"^^schema:Person,
        "Giambattista Parascandolo"^^schema:Person,
        "Mateo Rojas-Carulla"^^schema:Person,
        "Moritz Hardt"^^schema:Person,
        "Niki Kilbertus"^^schema:Person ;
    schema:commentCount "213"^^schema:Integer ;
    schema:dateModified "2018-01-21T16:39:51Z"^^schema:DateTime ;
    schema:datePublished "2017-06-08T19:50:56Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Avoiding Discrimination through Causal Reasoning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02744v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1456063515469711783&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2140> a schema:ScholarlyArticle ;
    schema:author "J Kurths"^^schema:Person,
        "T Huang"^^schema:Person,
        "W Zhang"^^schema:Person,
        "Y Tang"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Sampled-Data Consensus of Linear Multi-agent Systems With Packet Losses"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (11), 2516-2527"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13177323917799771312&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2141> a schema:ScholarlyArticle ;
    schema:author "G Feng"^^schema:Person,
        "L Liu"^^schema:Person,
        "W Hu"^^schema:Person ;
    schema:commentCount "319"^^schema:Integer ;
    schema:headline "Consensus of Linear Multi-Agent Systems by Distributed Event-Triggered Strategy"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 148-157"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=882167876042644973&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2142> a schema:ScholarlyArticle ;
    schema:author "D Yue"^^schema:Person,
        "H Zhang"^^schema:Person,
        "X Xie"^^schema:Person,
        "Y Xue"^^schema:Person ;
    schema:commentCount "209"^^schema:Integer ;
    schema:headline "Control Synthesis of Discrete-Time T–S Fuzzy Systems via a Multi-Instant Homogenous Polynomial Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (3), 630-640"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10050274590690665535&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2143> a schema:ScholarlyArticle ;
    schema:author "D Horgan"^^schema:Person,
        "D Silver"^^schema:Person,
        "K Gregor"^^schema:Person,
        "T Schaul"^^schema:Person ;
    schema:commentCount "373"^^schema:Integer ;
    schema:headline "Universal Value Function Approximators."^^schema:Text ;
    schema:publisher "ICML, 1312-1320"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=861364408827501200&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2144> a schema:ScholarlyArticle ;
    schema:author "B Oztaysi"^^schema:Person,
        "C Kahraman"^^schema:Person,
        "M Yavuz"^^schema:Person,
        "SC Onar"^^schema:Person ;
    schema:commentCount "131"^^schema:Integer ;
    schema:headline "Multi-criteria evaluation of alternative-fuel vehicles via a hierarchical hesitant fuzzy linguistic model"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (5), 2835-2848"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=18124556751291634865&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2145> a schema:ScholarlyArticle ;
    schema:author "C He"^^schema:Person,
        "D Parra"^^schema:Person,
        "K Verbert"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:headline "Interactive recommender systems: A survey of the state of the art and future research challenges and opportunities"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 56, 9-27"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5944712075212492662&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2146> a schema:ScholarlyArticle ;
    schema:author "D Liu"^^schema:Person,
        "H Lin"^^schema:Person,
        "Q Wei"^^schema:Person ;
    schema:commentCount "182"^^schema:Integer ;
    schema:headline "Value Iteration Adaptive Dynamic Programming for Optimal Control of Discrete-Time Nonlinear Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (3), 840-853"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14736648866814975855&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2147> a schema:ScholarlyArticle ;
    schema:author "A Sahoo"^^schema:Person,
        "H Xu"^^schema:Person,
        "S Jagannathan"^^schema:Person ;
    schema:commentCount "128"^^schema:Integer ;
    schema:headline "Neural Network-Based Event-Triggered State Feedback Control of Nonlinear Continuous-Time Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (3), 497-509"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=17892589400698292584&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2148> a schema:ScholarlyArticle ;
    schema:author "GH Yang"^^schema:Person,
        "XJ Li"^^schema:Person ;
    schema:commentCount "133"^^schema:Integer ;
    schema:headline "FLS-Based Adaptive Synchronization Control of Complex Dynamical Networks With Nonlinear Couplings and State-Dependent Uncertainties"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (1), 171-180"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5589590228200122364&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2149> a schema:ScholarlyArticle ;
    schema:author "P Yan"^^schema:Person,
        "Q Wei"^^schema:Person,
        "R Song"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:headline "Data-Driven Zero-Sum Neuro-Optimal Control for a Class of Continuous-Time Unknown Nonlinear Systems With Disturbance Using ADP"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (2), 444-458"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12245254904141192492&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<215> a schema:ScholarlyArticle ;
    schema:abstract "We suggest a loss for learning deep embeddings. The new loss does notintroduce parameters that need to be tuned and results in very good embeddingsacross a range of datasets and problems. The loss is computed by estimating twodistribution of similarities for positive (matching) and negative(non-matching) sample pairs, and then computing the probability of a positivepair to have a lower similarity score than a negative pair based on theestimated similarity distributions. We show that such operations can beperformed in a simple and piecewise-differentiable manner using 1D histogramswith soft assignment operations. This makes the proposed loss suitable forlearning deep embeddings using stochastic optimization. In the experiments, thenew loss performs favourably compared to recently proposed alternatives."^^schema:Text ;
    schema:author "Evgeniya Ustinova"^^schema:Person,
        "Victor Lempitsky"^^schema:Person ;
    schema:commentCount "205"^^schema:Integer ;
    schema:dateModified "2016-11-02T21:48:32Z"^^schema:DateTime ;
    schema:datePublished "2016-11-02T21:48:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning Deep Embeddings with Histogram Loss"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.00822v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6994791028704777674&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2150> a schema:ScholarlyArticle ;
    schema:author "G Hu"^^schema:Person,
        "G Wen"^^schema:Person,
        "J Cao"^^schema:Person,
        "W Yu"^^schema:Person,
        "X Yu"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:headline "Pinning Synchronization of Directed Networks With Switching Topologies: A Multiple Lyapunov Functions Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 26 (12), 3239-3250"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=9024059438689090053&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2151> a schema:ScholarlyArticle ;
    schema:author "M Sun"^^schema:Person,
        "TS Chua"^^schema:Person,
        "Y Liu"^^schema:Person,
        "Z Liu"^^schema:Person ;
    schema:commentCount "313"^^schema:Integer ;
    schema:headline "Topical Word Embeddings"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4213564948684610102&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2152> a schema:ScholarlyArticle ;
    schema:author "D Tao"^^schema:Person,
        "W Hou"^^schema:Person,
        "X Gao"^^schema:Person,
        "X Li"^^schema:Person ;
    schema:commentCount "242"^^schema:Integer ;
    schema:headline "Blind Image Quality Assessment via Deep Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 6 (26), 1275-1286"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13145362675480475429&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2153> a schema:ScholarlyArticle ;
    schema:author "I Yildirim"^^schema:Person,
        "J Wu"^^schema:Person,
        "JB Tenenbaum"^^schema:Person,
        "JJ Lim"^^schema:Person,
        "WT Freeman"^^schema:Person ;
    schema:commentCount "210"^^schema:Integer ;
    schema:headline "Galileo: perceiving physical object properties by integrating a physics engine with deep learning"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=13801231000054551969&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2154> a schema:ScholarlyArticle ;
    schema:author "B Kiumarsi"^^schema:Person,
        "FL Lewis"^^schema:Person ;
    schema:commentCount "116"^^schema:Integer ;
    schema:headline "Actor-critic-based optimal tracking for partially unknown nonlinear discrete-time systems."^^schema:Text ;
    schema:publisher "IEEE transactions on neural networks and learning systems 26 (1), 140-151"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11556515514744565865&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2155> a schema:ScholarlyArticle ;
    schema:author "CLP Chen"^^schema:Person,
        "DJ Li"^^schema:Person,
        "L Tang"^^schema:Person,
        "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "166"^^schema:Integer ;
    schema:headline "Reinforcement Learning Design-Based Adaptive Tracking Control With Less Learning Parameters for Nonlinear Discrete-Time MIMO Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 1 (26), 165-176"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6589926845532464779&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2156> a schema:ScholarlyArticle ;
    schema:author "CW Chen"^^schema:Person,
        "G Zhai"^^schema:Person,
        "K Gu"^^schema:Person,
        "W Lin"^^schema:Person,
        "W Zhang"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "140"^^schema:Integer ;
    schema:headline "No-Reference Quality Metric of Contrast-Distorted Images Based on Information Maximization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (12), 4559-4565"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8871801239842850423&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2157> a schema:ScholarlyArticle ;
    schema:author "E Cambria"^^schema:Person,
        "H Peng"^^schema:Person,
        "Y Ma"^^schema:Person ;
    schema:commentCount "191"^^schema:Integer ;
    schema:headline "Targeted Aspect-Based Sentiment Analysis via Embedding Commonsense Knowledge into an Attentive LSTM"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6992790790705744467&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2158> a schema:ScholarlyArticle ;
    schema:author "A Heydari"^^schema:Person,
        "M ali Tavakoli"^^schema:Person,
        "N Salim"^^schema:Person,
        "Z Heydari"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:headline "Detection of review spam: A survey"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (7), 3634-3642"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12307936909734683170&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2159> a schema:ScholarlyArticle ;
    schema:author "AC Courville"^^schema:Person,
        "J Sotelo"^^schema:Person,
        "JF Santos"^^schema:Person,
        "K Kastner"^^schema:Person,
        "K Kumar"^^schema:Person,
        "S Mehri"^^schema:Person,
        "Y Bengio"^^schema:Person ;
    schema:commentCount "236"^^schema:Integer ;
    schema:headline "Char2Wav: End-to-End Speech Synthesis."^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=6778319284287669999&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<216> a schema:ScholarlyArticle ;
    schema:abstract "The goal of precipitation nowcasting is to predict the future rainfallintensity in a local region over a relatively short period of time. Very fewprevious studies have examined this crucial and challenging weather forecastingproblem from the machine learning perspective. In this paper, we formulateprecipitation nowcasting as a spatiotemporal sequence forecasting problem inwhich both the input and the prediction target are spatiotemporal sequences. Byextending the fully connected LSTM (FC-LSTM) to have convolutional structuresin both the input-to-state and state-to-state transitions, we propose theconvolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable modelfor the precipitation nowcasting problem. Experiments show that our ConvLSTMnetwork captures spatiotemporal correlations better and consistentlyoutperforms FC-LSTM and the state-of-the-art operational ROVER algorithm forprecipitation nowcasting."^^schema:Text ;
    schema:author "Dit-Yan Yeung"^^schema:Person,
        "Hao Wang"^^schema:Person,
        "Wai-kin Wong"^^schema:Person,
        "Wang-chun Woo"^^schema:Person,
        "Xingjian Shi"^^schema:Person,
        "Zhourong Chen"^^schema:Person ;
    schema:commentCount "2059"^^schema:Integer ;
    schema:dateModified "2015-09-19T11:02:03Z"^^schema:DateTime ;
    schema:datePublished "2015-06-13T03:19:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Convolutional LSTM Network: A Machine Learning Approach for  Precipitation Nowcasting"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.04214v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5469943753756181884&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2160> a schema:ScholarlyArticle ;
    schema:author "G Pan"^^schema:Person,
        "K Jia"^^schema:Person,
        "M Lu"^^schema:Person,
        "Y Wang"^^schema:Person,
        "Y Zhang"^^schema:Person,
        "Z Wu"^^schema:Person ;
    schema:commentCount "118"^^schema:Integer ;
    schema:headline "Accelerometer-Based Gait Recognition by Sparse Representation of Signature Points With Clusters"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 9 (45), 1864-1875"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7443664043250578116&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2161> a schema:ScholarlyArticle ;
    schema:author "J Gao"^^schema:Person,
        "L Wu"^^schema:Person,
        "X Lin"^^schema:Person,
        "Y Wang"^^schema:Person ;
    schema:commentCount "147"^^schema:Integer ;
    schema:headline "Multiview Spectral Clustering via Structured Low-Rank Matrix Factorization"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (10), 4833-4843"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12137295393631125931&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2162> a schema:ScholarlyArticle ;
    schema:author "AC Wilson"^^schema:Person,
        "B Recht"^^schema:Person,
        "M Stern"^^schema:Person,
        "N Srebro"^^schema:Person,
        "R Roelofs"^^schema:Person ;
    schema:commentCount "444"^^schema:Integer ;
    schema:headline "The marginal value of adaptive gradient methods in machine learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14847173290255149613&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2163> a schema:ScholarlyArticle ;
    schema:author "M Chadli"^^schema:Person,
        "P Shi"^^schema:Person,
        "RK Agarwal"^^schema:Person,
        "Y Zhang"^^schema:Person ;
    schema:commentCount "187"^^schema:Integer ;
    schema:headline "Mixed H-Infinity and Passive Filtering for Discrete Fuzzy Neural Networks With Stochastic Jumps and Time Delays"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 903-909"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14812176235116050940&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2164> a schema:ScholarlyArticle ;
    schema:author "AKM Khairuzzaman"^^schema:Person,
        "S Chaudhury"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:headline "Multilevel thresholding using grey wolf optimizer for image segmentation"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 86, 64-76"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=4789838863705342426&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2165> a schema:ScholarlyArticle ;
    schema:author "S Tong"^^schema:Person,
        "T Li"^^schema:Person,
        "Y Li"^^schema:Person ;
    schema:commentCount "295"^^schema:Integer ;
    schema:headline "Adaptive fuzzy output feedback dynamic surface control of interconnected nonlinear pure-feedback systems."^^schema:Text ;
    schema:publisher "IEEE transactions on cybernetics 45 (1), 138-149"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15517278243520257301&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2166> a schema:ScholarlyArticle ;
    schema:author "D Enke"^^schema:Person,
        "X Zhong"^^schema:Person ;
    schema:commentCount "158"^^schema:Integer ;
    schema:headline "Forecasting daily stock market return using dimensionality reduction"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 67, 126-139"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2556532614247637544&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2167> a schema:ScholarlyArticle ;
    schema:author "B Zoph"^^schema:Person,
        "G Bender"^^schema:Person,
        "PJ Kindermans"^^schema:Person,
        "QV Le"^^schema:Person,
        "V Vasudevan"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:headline "Understanding and Simplifying One-Shot Architecture Search."^^schema:Text ;
    schema:publisher "ICML, 549-558"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=7510080748852519361&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2168> a schema:ScholarlyArticle ;
    schema:author "G Cooper"^^schema:Person,
        "M Hauskrecht"^^schema:Person,
        "MP Naeini"^^schema:Person ;
    schema:commentCount "158"^^schema:Integer ;
    schema:headline "Obtaining Well Calibrated Probabilities Using Bayesian Binning"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=3987320718107039587&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2169> a schema:ScholarlyArticle ;
    schema:author "H Jain"^^schema:Person,
        "K Bhatia"^^schema:Person,
        "M Varma"^^schema:Person,
        "P Jain"^^schema:Person,
        "P Kar"^^schema:Person ;
    schema:commentCount "273"^^schema:Integer ;
    schema:headline "Sparse local embeddings for extreme multi-label classification"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=8638863549992326608&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<217> a schema:ScholarlyArticle ;
    schema:abstract "In this work we aim to solve a large collection of tasks using a singlereinforcement learning agent with a single set of parameters. A key challengeis to handle the increased amount of data and extended training time. We havedeveloped a new distributed agent IMPALA (Importance Weighted Actor-LearnerArchitecture) that not only uses resources more efficiently in single-machinetraining but also scales to thousands of machines without sacrificing dataefficiency or resource utilisation. We achieve stable learning at highthroughput by combining decoupled acting and learning with a novel off-policycorrection method called V-trace. We demonstrate the effectiveness of IMPALAfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from theDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all availableAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Ourresults show that IMPALA is able to achieve better performance than previousagents with less data, and crucially exhibits positive transfer between tasksas a result of its multi-task approach."^^schema:Text ;
    schema:author "Hubert Soyer"^^schema:Person,
        "Iain Dunning"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Lasse Espeholt"^^schema:Person,
        "Remi Munos"^^schema:Person,
        "Shane Legg"^^schema:Person,
        "Tim Harley"^^schema:Person,
        "Tom Ward"^^schema:Person,
        "Vlad Firoiu"^^schema:Person,
        "Volodymir Mnih"^^schema:Person,
        "Yotam Doron"^^schema:Person ;
    schema:commentCount "373"^^schema:Integer ;
    schema:dateModified "2018-06-28T06:54:39Z"^^schema:DateTime ;
    schema:datePublished "2018-02-05T18:47:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "IMPALA: Scalable Distributed Deep-RL with Importance Weighted  Actor-Learner Architectures"^^schema:Text ;
    schema:publisher "ICML, 1406-1415"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.01561v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14673826846490570917&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2170> a schema:ScholarlyArticle ;
    schema:author "D Fuchs-Hanusch"^^schema:Person,
        "SH Zyoud"^^schema:Person ;
    schema:commentCount "153"^^schema:Integer ;
    schema:headline "A bibliometric-based survey on AHP and TOPSIS techniques"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 78, 158-181"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16375153069610433818&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2171> a schema:ScholarlyArticle ;
    schema:author "..."^^schema:Person,
        "A Rodríguez-González"^^schema:Person,
        "LO Colombo-Mendoza"^^schema:Person,
        "R Valencia-García"^^schema:Person ;
    schema:commentCount "148"^^schema:Integer ;
    schema:headline "RecomMetz: A context-aware knowledge-based mobile recommender system for movie showtimes"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (3), 1202-1222"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=146977218533402098&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2172> a schema:ScholarlyArticle ;
    schema:author "WH Chen"^^schema:Person,
        "WX Zheng"^^schema:Person,
        "X Lu"^^schema:Person ;
    schema:commentCount "110"^^schema:Integer ;
    schema:headline "Impulsive Stabilization and Impulsive Synchronization of Discrete-Time Delayed Neural Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 4 (26), 734-748"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=2655881312093203448&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2173> a schema:ScholarlyArticle ;
    schema:author "A Wu"^^schema:Person,
        "Z Zeng"^^schema:Person ;
    schema:commentCount "117"^^schema:Integer ;
    schema:headline "Global Mittag–Leffler Stabilization of Fractional-Order Memristive Neural Networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (1), 206-217"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=15771801477981829018&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2174> a schema:ScholarlyArticle ;
    schema:author "H Yang"^^schema:Person,
        "I King"^^schema:Person,
        "MR Lyu"^^schema:Person,
        "S Zhao"^^schema:Person,
        "T Zhao"^^schema:Person ;
    schema:commentCount "136"^^schema:Integer ;
    schema:headline "STELLAR: Spatial-Temporal Latent Ranking for Successive Point-of-Interest Recommendation"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=14286358053162903287&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2175> a schema:ScholarlyArticle ;
    schema:author "DP Kingma"^^schema:Person,
        "P Dhariwal"^^schema:Person ;
    schema:commentCount "545"^^schema:Integer ;
    schema:headline "Glow: generative flow with invertible 1× 1 convolutions"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=5834689841973227263&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2176> a schema:ScholarlyArticle ;
    schema:author "H Wang"^^schema:Person,
        "K Liu"^^schema:Person,
        "X Liu"^^schema:Person ;
    schema:commentCount "149"^^schema:Integer ;
    schema:headline "Robust Adaptive Neural Tracking Control for a Class of Stochastic Nonlinear Interconnected Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (3), 510-523"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=12823084259380373762&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2177> a schema:ScholarlyArticle ;
    schema:author "S Tong"^^schema:Person,
        "YJ Liu"^^schema:Person ;
    schema:commentCount "200"^^schema:Integer ;
    schema:headline "Adaptive NN Tracking Control of Uncertain Nonlinear Discrete-Time Systems With Nonaffine Dead-Zone Input"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 3 (45), 497-505"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=10761901456947506340&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2178> a schema:ScholarlyArticle ;
    schema:author "A Gómez-Rodríguez"^^schema:Person,
        "FJ Rodríguez-Martínez"^^schema:Person,
        "L Otero-Cerdeira"^^schema:Person ;
    schema:commentCount "288"^^schema:Integer ;
    schema:headline "Ontology matching: A literature review"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (2), 949-971"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=16027094851791230983&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2179> a schema:ScholarlyArticle ;
    schema:author "J Fisher"^^schema:Person,
        "L Rochester"^^schema:Person,
        "NY Hammerla"^^schema:Person,
        "P Andras"^^schema:Person,
        "R Walker"^^schema:Person,
        "T Ploetz"^^schema:Person ;
    schema:commentCount "137"^^schema:Integer ;
    schema:headline "PD Disease State Assessment in Naturalistic Environments Using Deep Learning"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11895807980625649930&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<218> a schema:ScholarlyArticle ;
    schema:abstract "Automatically generating coherent and semantically meaningful text has manyapplications in machine translation, dialogue systems, image captioning, etc.Recently, by combining with policy gradient, Generative Adversarial Nets (GAN)that use a discriminative model to guide the training of the generative modelas a reinforcement learning policy has shown promising results in textgeneration. However, the scalar guiding signal is only available after theentire text has been generated and lacks intermediate information about textstructure during the generative process. As such, it limits its success whenthe length of the generated text samples is long (more than 20 words). In thispaper, we propose a new framework, called LeakGAN, to address the problem forlong text generation. We allow the discriminative net to leak its ownhigh-level extracted features to the generative net to further help theguidance. The generator incorporates such informative signals into allgeneration steps through an additional Manager module, which takes theextracted features of current generated words and outputs a latent vector toguide the Worker module for next-word generation. Our extensive experiments onsynthetic data and various real-world tasks with Turing test demonstrate thatLeakGAN is highly effective in long text generation and also improves theperformance in short text generation scenarios. More importantly, without anysupervision, LeakGAN would be able to implicitly learn sentence structures onlythrough the interaction between Manager and Worker."^^schema:Text ;
    schema:author "Han Cai"^^schema:Person,
        "Jiaxian Guo"^^schema:Person,
        "Jun Wang"^^schema:Person,
        "Sidi Lu"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Yong Yu"^^schema:Person ;
    schema:commentCount "162"^^schema:Integer ;
    schema:dateModified "2017-12-08T18:53:52Z"^^schema:DateTime ;
    schema:datePublished "2017-09-24T13:35:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Long Text Generation via Adversarial Training with Leaked Information"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.08624v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10032525507167574810&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<2180> a schema:ScholarlyArticle ;
    schema:author "DWC Ho"^^schema:Person,
        "X Yang"^^schema:Person ;
    schema:commentCount "152"^^schema:Integer ;
    schema:headline "Synchronization of Delayed Memristive Neural Networks: Robust Analysis Approach"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (12), 3377-3387"^^schema:Periodical ;
    schema:url "http://scholar.google.com/scholar?oi=bibs&cluster=11803524490943752881&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<219> a schema:ScholarlyArticle ;
    schema:abstract "A capsule is a group of neurons whose activity vector represents theinstantiation parameters of a specific type of entity such as an object or anobject part. We use the length of the activity vector to represent theprobability that the entity exists and its orientation to represent theinstantiation parameters. Active capsules at one level make predictions, viatransformation matrices, for the instantiation parameters of higher-levelcapsules. When multiple predictions agree, a higher level capsule becomesactive. We show that a discrimininatively trained, multi-layer capsule systemachieves state-of-the-art performance on MNIST and is considerably better thana convolutional net at recognizing highly overlapping digits. To achieve theseresults we use an iterative routing-by-agreement mechanism: A lower-levelcapsule prefers to send its output to higher level capsules whose activityvectors have a big scalar product with the prediction coming from thelower-level capsule."^^schema:Text ;
    schema:author "Geoffrey E Hinton"^^schema:Person,
        "Nicholas Frosst"^^schema:Person,
        "Sara Sabour"^^schema:Person ;
    schema:commentCount "1620"^^schema:Integer ;
    schema:dateModified "2017-11-07T19:26:38Z"^^schema:DateTime ;
    schema:datePublished "2017-10-26T17:49:04Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Dynamic Routing Between Capsules"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.09829v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5914955692202761908&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<22> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a margin-based multiclass generalization bound for neuralnetworks that scales with their margin-normalized \"spectral complexity\": theirLipschitz constant, meaning the product of the spectral norms of the weightmatrices, times a certain correction factor. This bound is empiricallyinvestigated for a standard AlexNet network trained with SGD on the mnist andcifar10 datasets, with both original and random labels; the bound, theLipschitz constants, and the excess risks are all in direct correlation,suggesting both that SGD selects predictors whose complexity scales with thedifficulty of the learning task, and secondly that the presented bound issensitive to this complexity."^^schema:Text ;
    schema:author "Dylan J. Foster"^^schema:Person,
        "Matus Telgarsky"^^schema:Person,
        "Peter Bartlett"^^schema:Person ;
    schema:commentCount "380"^^schema:Integer ;
    schema:dateModified "2017-12-05T06:08:38Z"^^schema:DateTime ;
    schema:datePublished "2017-06-26T17:43:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Spectrally-normalized margin bounds for neural networks"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.08498v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16170177050810544440&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<220> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in neural variational inference have spawned a renaissance indeep latent variable models. In this paper we introduce a generic variationalinference framework for generative and conditional models of text. Whiletraditional variational methods derive an analytic approximation for theintractable distributions over latent variables, here we construct an inferencenetwork conditioned on the discrete text input to provide the variationaldistribution. We validate this framework on two very different text modellingapplications, generative document modelling and supervised question answering.Our neural variational document model combines a continuous stochastic documentrepresentation with a bag-of-words generative model and achieves the lowestreported perplexities on two standard test corpora. The neural answer selectionmodel employs a stochastic representation layer within an attention mechanismto extract the semantics between a question and answer pair. On two questionanswering benchmarks this model exceeds all previous published benchmarks."^^schema:Text ;
    schema:author "Lei Yu"^^schema:Person,
        "Phil Blunsom"^^schema:Person,
        "Yishu Miao"^^schema:Person ;
    schema:commentCount "323"^^schema:Integer ;
    schema:dateModified "2016-06-04T06:41:58Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T01:23:28Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Variational Inference for Text Processing"^^schema:Text ;
    schema:publisher "ICML, 1727-1736"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06038v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7999736886109588436&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<221> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a new model for extracting an interpretable sentenceembedding by introducing self-attention. Instead of using a vector, we use a2-D matrix to represent the embedding, with each row of the matrix attending ona different part of the sentence. We also propose a self-attention mechanismand a special regularization term for the model. As a side effect, theembedding comes with an easy way of visualizing what specific parts of thesentence are encoded into the embedding. We evaluate our model on 3 differenttasks: author profiling, sentiment classification, and textual entailment.Results show that our model yields a significant performance gain compared toother sentence embedding methods in all of the 3 tasks."^^schema:Text ;
    schema:author "Bing Xiang"^^schema:Person,
        "Bowen Zhou"^^schema:Person,
        "Cicero Nogueira dos Santos"^^schema:Person,
        "Minwei Feng"^^schema:Person,
        "Mo Yu"^^schema:Person,
        "Yoshua Bengio"^^schema:Person,
        "Zhouhan Lin"^^schema:Person ;
    schema:commentCount "893"^^schema:Integer ;
    schema:dateModified "2017-03-09T04:42:30Z"^^schema:DateTime ;
    schema:datePublished "2017-03-09T04:42:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A Structured Self-attentive Sentence Embedding"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.03130v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3666844900655302515&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<222> a schema:ScholarlyArticle ;
    schema:abstract "In this work we propose a novel interpretation of residual networks showingthat they can be seen as a collection of many paths of differing length.Moreover, residual networks seem to enable very deep networks by leveragingonly the short paths during training. To support this observation, we rewriteresidual networks as an explicit collection of paths. Unlike traditionalmodels, paths through residual networks vary in length. Further, a lesion studyreveals that these paths show ensemble-like behavior in the sense that they donot strongly depend on each other. Finally, and most surprising, most paths areshorter than one might expect, and only the short paths are needed duringtraining, as longer paths do not contribute any gradient. For example, most ofthe gradient in a residual network with 110 layers comes from paths that areonly 10-34 layers deep. Our results reveal one of the key characteristics thatseem to enable the training of very deep networks: Residual networks avoid thevanishing gradient problem by introducing short paths which can carry gradientthroughout the extent of very deep networks."^^schema:Text ;
    schema:author "Andreas Veit"^^schema:Person,
        "Michael Wilber"^^schema:Person,
        "Serge Belongie"^^schema:Person ;
    schema:commentCount "455"^^schema:Integer ;
    schema:dateModified "2016-10-27T00:43:58Z"^^schema:DateTime ;
    schema:datePublished "2016-05-20T16:44:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Residual Networks Behave Like Ensembles of Relatively Shallow Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06431v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17069814828377193048&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<223> a schema:ScholarlyArticle ;
    schema:abstract "We apply basic statistical reasoning to signal reconstruction by machinelearning -- learning to map corrupted observations to clean signals -- with asimple and powerful conclusion: it is possible to learn to restore images byonly looking at corrupted examples, at performance at and sometimes exceedingtraining using clean data, without explicit image priors or likelihood modelsof the corruption. In practice, we show that a single model learns photographicnoise removal, denoising synthetic Monte Carlo images, and reconstruction ofundersampled MRI scans -- all corrupted by different processes -- based onnoisy data only."^^schema:Text ;
    schema:author "Jaakko Lehtinen"^^schema:Person,
        "Jacob Munkberg"^^schema:Person,
        "Jon Hasselgren"^^schema:Person,
        "Miika Aittala"^^schema:Person,
        "Samuli Laine"^^schema:Person,
        "Tero Karras"^^schema:Person,
        "Timo Aila"^^schema:Person ;
    schema:commentCount "225"^^schema:Integer ;
    schema:dateModified "2018-10-29T10:29:23Z"^^schema:DateTime ;
    schema:datePublished "2018-03-12T11:07:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Noise2Noise: Learning Image Restoration without Clean Data"^^schema:Text ;
    schema:publisher "ICML, 2971-2980"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.04189v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16764673643469433149&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<224> a schema:ScholarlyArticle ;
    schema:abstract "Generative models in vision have seen rapid progress due to algorithmicimprovements and the availability of high-quality image datasets. In thispaper, we offer contributions in both these areas to enable similar progress inaudio modeling. First, we detail a powerful new WaveNet-style autoencoder modelthat conditions an autoregressive decoder on temporal codes learned from theraw audio waveform. Second, we introduce NSynth, a large-scale and high-qualitydataset of musical notes that is an order of magnitude larger than comparablepublic datasets. Using NSynth, we demonstrate improved qualitative andquantitative performance of the WaveNet autoencoder over a well-tuned spectralautoencoder baseline. Finally, we show that the model learns a manifold ofembeddings that allows for morphing between instruments, meaningfullyinterpolating in timbre to create new types of sounds that are realistic andexpressive."^^schema:Text ;
    schema:author "Adam Roberts"^^schema:Person,
        "Cinjon Resnick"^^schema:Person,
        "Douglas Eck"^^schema:Person,
        "Jesse Engel"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Mohammad Norouzi"^^schema:Person,
        "Sander Dieleman"^^schema:Person ;
    schema:commentCount "221"^^schema:Integer ;
    schema:dateModified "2017-04-05T06:34:22Z"^^schema:DateTime ;
    schema:datePublished "2017-04-05T06:34:22Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text ;
    schema:headline "Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders"^^schema:Text ;
    schema:publisher "ICML, 1068-1077"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.01279v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5597311454772920979&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<225> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we perform unsupervised learning of representations bymaximizing mutual information between an input and the output of a deep neuralnetwork encoder. Importantly, we show that structure matters: incorporatingknowledge about locality of the input to the objective can greatly influence arepresentation's suitability for downstream tasks. We further controlcharacteristics of the representation by matching to a prior distributionadversarially. Our method, which we call Deep InfoMax (DIM), outperforms anumber of popular unsupervised learning methods and competes withfully-supervised learning on several classification tasks. DIM opens newavenues for unsupervised learning of representations and is an important steptowards flexible formulations of representation-learning objectives forspecific end-goals."^^schema:Text ;
    schema:author "Adam Trischler"^^schema:Person,
        "Alex Fedorov"^^schema:Person,
        "Karan Grewal"^^schema:Person,
        "Phil Bachman"^^schema:Person,
        "R Devon Hjelm"^^schema:Person,
        "Samuel Lavoie-Marchildon"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "266"^^schema:Integer ;
    schema:dateModified "2019-02-22T18:38:15Z"^^schema:DateTime ;
    schema:datePublished "2018-08-20T19:52:51Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning deep representations by mutual information estimation and  maximization"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1808.06670v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9102831258285751412&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<226> a schema:ScholarlyArticle ;
    schema:abstract "In few-shot classification, we are interested in learning algorithms thattrain a classifier from only a handful of labeled examples. Recent progress infew-shot classification has featured meta-learning, in which a parameterizedmodel for a learning algorithm is defined and trained on episodes representingdifferent classification problems, each with a small labeled training set andits corresponding test set. In this work, we advance this few-shotclassification paradigm towards a scenario where unlabeled examples are alsoavailable within each episode. We consider two situations: one where allunlabeled examples are assumed to belong to the same set of classes as thelabeled examples of the episode, as well as the more challenging situationwhere examples from other distractor classes are also provided. To address thisparadigm, we propose novel extensions of Prototypical Networks (Snell et al.,2017) that are augmented with the ability to use unlabeled examples whenproducing prototypes. These models are trained in an end-to-end way onepisodes, to learn to leverage the unlabeled examples successfully. We evaluatethese methods on versions of the Omniglot and miniImageNet benchmarks, adaptedto this new framework augmented with unlabeled examples. We also propose a newsplit of ImageNet, consisting of a large set of classes, with a hierarchicalstructure. Our experiments confirm that our Prototypical Networks can learn toimprove their predictions due to unlabeled examples, much like asemi-supervised algorithm would."^^schema:Text ;
    schema:author "Eleni Triantafillou"^^schema:Person,
        "Hugo Larochelle"^^schema:Person,
        "Jake Snell"^^schema:Person,
        "Joshua B. Tenenbaum"^^schema:Person,
        "Kevin Swersky"^^schema:Person,
        "Mengye Ren"^^schema:Person,
        "Richard S. Zemel"^^schema:Person,
        "Sachin Ravi"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2018-03-02T01:07:49Z"^^schema:DateTime ;
    schema:datePublished "2018-03-02T01:07:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Meta-Learning for Semi-Supervised Few-Shot Classification"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.00676v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=798380540199769906&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<227> a schema:ScholarlyArticle ;
    schema:abstract "Spatiotemporal forecasting has various applications in neuroscience, climateand transportation domain. Traffic forecasting is one canonical example of suchlearning task. The task is challenging due to (1) complex spatial dependency onroad networks, (2) non-linear temporal dynamics with changing road conditionsand (3) inherent difficulty of long-term forecasting. To address thesechallenges, we propose to model the traffic flow as a diffusion process on adirected graph and introduce Diffusion Convolutional Recurrent Neural Network(DCRNN), a deep learning framework for traffic forecasting that incorporatesboth spatial and temporal dependency in the traffic flow. Specifically, DCRNNcaptures the spatial dependency using bidirectional random walks on the graph,and the temporal dependency using the encoder-decoder architecture withscheduled sampling. We evaluate the framework on two real-world large scaleroad network traffic datasets and observe consistent improvement of 12% - 15%over state-of-the-art baselines."^^schema:Text ;
    schema:author "Cyrus Shahabi"^^schema:Person,
        "Rose Yu"^^schema:Person,
        "Yaguang Li"^^schema:Person,
        "Yan Liu"^^schema:Person ;
    schema:commentCount "330"^^schema:Integer ;
    schema:dateModified "2018-02-22T19:52:51Z"^^schema:DateTime ;
    schema:datePublished "2017-07-06T18:20:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic  Forecasting"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.01926v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6301301566407555232&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<228> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we propose to apply trust region optimization to deepreinforcement learning using a recently proposed Kronecker-factoredapproximation to the curvature. We extend the framework of natural policygradient and propose to optimize both the actor and the critic usingKronecker-factored approximate curvature (K-FAC) with trust region; hence wecall our method Actor Critic using Kronecker-Factored Trust Region (ACKTR). Tothe best of our knowledge, this is the first scalable trust region naturalgradient method for actor-critic methods. It is also a method that learnsnon-trivial tasks in continuous control as well as discrete control policiesdirectly from raw pixel inputs. We tested our approach across discrete domainsin Atari games as well as continuous domains in the MuJoCo environment. Withthe proposed methods, we are able to achieve higher rewards and a 2- to 3-foldimprovement in sample efficiency on average, compared to previousstate-of-the-art on-policy actor-critic methods. Code is available athttps://github.com/openai/baselines"^^schema:Text ;
    schema:author "Elman Mansimov"^^schema:Person,
        "Jimmy Ba"^^schema:Person,
        "Roger Grosse"^^schema:Person,
        "Shun Liao"^^schema:Person,
        "Yuhuai Wu"^^schema:Person ;
    schema:commentCount "279"^^schema:Integer ;
    schema:dateModified "2017-08-18T11:16:36Z"^^schema:DateTime ;
    schema:datePublished "2017-08-17T06:14:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Scalable trust-region method for deep reinforcement learning using  Kronecker-factored approximation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.05144v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7666242084036831847&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<229> a schema:ScholarlyArticle ;
    schema:abstract "We explore efficient neural architecture search methods and show that asimple yet powerful evolutionary algorithm can discover new architectures withexcellent performance. Our approach combines a novel hierarchical geneticrepresentation scheme that imitates the modularized design pattern commonlyadopted by human experts, and an expressive search space that supports complextopologies. Our algorithm efficiently discovers architectures that outperform alarge number of manually designed models for image classification, obtainingtop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, whichis competitive with the best existing neural architecture search approaches. Wealso present results using random search, achieving 0.3% less top-1 accuracy onCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36hours down to 1 hour."^^schema:Text ;
    schema:author "Chrisantha Fernando"^^schema:Person,
        "Hanxiao Liu"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Oriol Vinyals"^^schema:Person ;
    schema:commentCount "333"^^schema:Integer ;
    schema:dateModified "2018-02-22T22:31:30Z"^^schema:DateTime ;
    schema:datePublished "2017-11-01T16:46:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Representations for Efficient Architecture Search"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00436v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8727964422666186494&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<23> a schema:ScholarlyArticle ;
    schema:abstract "Semi-supervised learning methods based on generative adversarial networks(GANs) obtained strong empirical results, but it is not clear 1) how thediscriminator benefits from joint training with a generator, and 2) why goodsemi-supervised classification performance and a good generator cannot beobtained at the same time. Theoretically, we show that given the discriminatorobjective, good semisupervised learning indeed requires a bad generator, andpropose the definition of a preferred generator. Empirically, we derive a novelformulation based on our analysis that substantially improves over featurematching GANs, obtaining state-of-the-art results on multiple benchmarkdatasets."^^schema:Text ;
    schema:author "Fan Yang"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "William W. Cohen"^^schema:Person,
        "Zhilin Yang"^^schema:Person,
        "Zihang Dai"^^schema:Person ;
    schema:commentCount "221"^^schema:Integer ;
    schema:dateModified "2017-11-03T17:18:43Z"^^schema:DateTime ;
    schema:datePublished "2017-05-27T07:53:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Good Semi-supervised Learning that Requires a Bad GAN"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.09783v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9678350544464313908&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<230> a schema:ScholarlyArticle ;
    schema:abstract "Style transfer is an important problem in natural language processing (NLP).However, the progress in language style transfer is lagged behind otherdomains, such as computer vision, mainly because of the lack of parallel dataand principle evaluation metrics. In this paper, we propose to learn styletransfer with non-parallel data. We explore two models to achieve this goal,and the key idea behind the proposed models is to learn separate contentrepresentations and style representations using adversarial networks. We alsopropose novel evaluation metrics which measure two aspects of style transfer:transfer strength and content preservation. We access our models and theevaluation metrics on two tasks: paper-news title transfer, andpositive-negative review transfer. Results show that the proposed contentpreservation metric is highly correlate to human judgments, and the proposedmodels are able to generate sentences with higher style transfer strength andsimilar content preservation score comparing to auto-encoder."^^schema:Text ;
    schema:author "Dongyan Zhao"^^schema:Person,
        "Nanyun Peng"^^schema:Person,
        "Rui Yan"^^schema:Person,
        "Xiaoye Tan"^^schema:Person,
        "Zhenxin Fu"^^schema:Person ;
    schema:commentCount "177"^^schema:Integer ;
    schema:dateModified "2017-11-27T07:46:16Z"^^schema:DateTime ;
    schema:datePublished "2017-11-18T13:33:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Style Transfer in Text: Exploration and Evaluation"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.06861v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9103690709456613215&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<231> a schema:ScholarlyArticle ;
    schema:abstract "Batch Normalization is quite effective at accelerating and improving thetraining of deep models. However, its effectiveness diminishes when thetraining minibatches are small, or do not consist of independent samples. Wehypothesize that this is due to the dependence of model layer inputs on all theexamples in the minibatch, and different activations being produced betweentraining and inference. We propose Batch Renormalization, a simple andeffective extension to ensure that the training and inference models generatethe same outputs that depend on individual examples rather than the entireminibatch. Models trained with Batch Renormalization perform substantiallybetter than batchnorm when training with small or non-i.i.d. minibatches. Atthe same time, Batch Renormalization retains the benefits of batchnorm such asinsensitivity to initialization and training efficiency."^^schema:Text ;
    schema:author "Sergey Ioffe"^^schema:Person ;
    schema:commentCount "203"^^schema:Integer ;
    schema:dateModified "2017-03-30T17:58:32Z"^^schema:DateTime ;
    schema:datePublished "2017-02-10T18:27:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Batch Renormalization: Towards Reducing Minibatch Dependence in  Batch-Normalized Models"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.03275v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7372640422096944906&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<232> a schema:ScholarlyArticle ;
    schema:abstract "One major obstacle towards AI is the poor ability of models to solve newproblems quicker, and without forgetting previously acquired knowledge. Tobetter understand this issue, we study the problem of continual learning, wherethe model observes, once and one by one, examples concerning a sequence oftasks. First, we propose a set of metrics to evaluate models learning over acontinuum of data. These metrics characterize models not only by their testaccuracy, but also in terms of their ability to transfer knowledge acrosstasks. Second, we propose a model for continual learning, called GradientEpisodic Memory (GEM) that alleviates forgetting, while allowing beneficialtransfer of knowledge to previous tasks. Our experiments on variants of theMNIST and CIFAR-100 datasets demonstrate the strong performance of GEM whencompared to the state-of-the-art."^^schema:Text ;
    schema:author "David Lopez-Paz"^^schema:Person,
        "Marc'Aurelio Ranzato"^^schema:Person ;
    schema:commentCount "311"^^schema:Integer ;
    schema:dateModified "2017-11-04T13:11:18Z"^^schema:DateTime ;
    schema:datePublished "2017-06-26T14:53:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Gradient Episodic Memory for Continual Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.08840v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17788496987696818587&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<233> a schema:ScholarlyArticle ;
    schema:abstract "Model-free deep reinforcement learning (RL) methods have been successful in awide variety of simulated domains. However, a major obstacle facing deep RL inthe real world is their high sample complexity. Batch policy gradient methodsoffer stable learning, but at the cost of high variance, which often requireslarge batches. TD-style methods, such as off-policy actor-critic andQ-learning, are more sample-efficient but biased, and often require costlyhyperparameter sweeps to stabilize. In this work, we aim to develop methodsthat combine the stability of policy gradients with the efficiency ofoff-policy RL. We present Q-Prop, a policy gradient method that uses a Taylorexpansion of the off-policy critic as a control variate. Q-Prop is both sampleefficient and stable, and effectively combines the benefits of on-policy andoff-policy methods. We analyze the connection between Q-Prop and existingmodel-free algorithms, and use control variate theory to derive two variants ofQ-Prop with conservative and aggressive adaptation. We show that conservativeQ-Prop provides substantial gains in sample efficiency over trust region policyoptimization (TRPO) with generalized advantage estimation (GAE), and improvesstability over deep deterministic policy gradient (DDPG), the state-of-the-arton-policy and off-policy methods, on OpenAI Gym's MuJoCo continuous controlenvironments."^^schema:Text ;
    schema:author "Richard E. Turner"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Shixiang Gu"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person,
        "Zoubin Ghahramani"^^schema:Person ;
    schema:commentCount "213"^^schema:Integer ;
    schema:dateModified "2017-02-27T21:48:25Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T20:09:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02247v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9727184745997671136&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<234> a schema:ScholarlyArticle ;
    schema:abstract "Universal style transfer aims to transfer arbitrary visual styles to contentimages. Existing feed-forward based methods, while enjoying the inferenceefficiency, are mainly limited by inability of generalizing to unseen styles orcompromised visual quality. In this paper, we present a simple yet effectivemethod that tackles these limitations without training on any pre-definedstyles. The key ingredient of our method is a pair of feature transforms,whitening and coloring, that are embedded to an image reconstruction network.The whitening and coloring transforms reflect a direct matching of featurecovariance of the content image to a given style image, which shares similarspirits with the optimization of Gram matrix based cost in neural styletransfer. We demonstrate the effectiveness of our algorithm by generatinghigh-quality stylized images with comparisons to a number of recent methods. Wealso analyze our method by visualizing the whitened features and synthesizingtextures via simple feature coloring."^^schema:Text ;
    schema:author "Chen Fang"^^schema:Person,
        "Jimei Yang"^^schema:Person,
        "Ming-Hsuan Yang"^^schema:Person,
        "Xin Lu"^^schema:Person,
        "Yijun Li"^^schema:Person,
        "Zhaowen Wang"^^schema:Person ;
    schema:commentCount "227"^^schema:Integer ;
    schema:dateModified "2017-11-17T18:30:43Z"^^schema:DateTime ;
    schema:datePublished "2017-05-23T06:10:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Universal Style Transfer via Feature Transforms"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08086v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7001062204457348357&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<235> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks (DNNs) have demonstrated dominating performance in manyfields; since AlexNet, networks used in practice are going wider and deeper. Onthe theoretical side, a long line of works has been focusing on training neuralnetworks with one hidden layer. The theory of multi-layer networks remainslargely unsettled.  In this work, we prove why stochastic gradient descent (SGD) can find$\\textit{global minima}$ on the training objective of DNNs in$\\textit{polynomial time}$. We only make two assumptions: the inputs arenon-degenerate and the network is over-parameterized. The latter means thenetwork width is sufficiently large: $\\textit{polynomial}$ in $L$, the numberof layers and in $n$, the number of samples.  Our key technique is to derive that, in a sufficiently large neighborhood ofthe random initialization, the optimization landscape is almost-convex andsemi-smooth even with ReLU activations. This implies an equivalence betweenover-parameterized neural networks and neural tangent kernel (NTK) in thefinite (and polynomial) width setting.  As concrete examples, starting from randomly initialized weights, we provethat SGD can attain 100% training accuracy in classification tasks, or minimizeregression loss in linear convergence speed, with running time polynomial in$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,and to any smooth and possibly non-convex loss functions. In terms of networkarchitectures, our theory at least applies to fully-connected neural networks,convolutional neural networks (CNN), and residual neural networks (ResNet)."^^schema:Text ;
    schema:author "Yuanzhi Li"^^schema:Person,
        "Zeyuan Allen-Zhu"^^schema:Person,
        "Zhao Song"^^schema:Person ;
    schema:commentCount "278"^^schema:Integer ;
    schema:dateModified "2019-06-17T06:39:04Z"^^schema:DateTime ;
    schema:datePublished "2018-11-09T15:16:13Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Convergence Theory for Deep Learning via Over-Parameterization"^^schema:Text ;
    schema:publisher "ICML, 242-252"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1811.03962v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2380732574076098684&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<236> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks have proven effective at solving difficult problems butdesigning their architectures can be challenging, even for image classificationproblems alone. Our goal is to minimize human participation, so we employevolutionary algorithms to discover such networks automatically. Despitesignificant computational requirements, we show that it is now possible toevolve models with accuracies within the range of those published in the lastyear. Specifically, we employ simple evolutionary techniques at unprecedentedscales to discover models for the CIFAR-10 and CIFAR-100 datasets, startingfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% forensemble) and 77.0%, respectively. To do this, we use novel and intuitivemutation operators that navigate large search spaces; we stress that no humanparticipation is required once evolution starts and that the output is afully-trained model. Throughout this work, we place special emphasis on therepeatability of results, the variability in the outcomes and the computationalrequirements."^^schema:Text ;
    schema:author "Alex Kurakin"^^schema:Person,
        "Andrew Selle"^^schema:Person,
        "Esteban Real"^^schema:Person,
        "Jie Tan"^^schema:Person,
        "Quoc Le"^^schema:Person,
        "Saurabh Saxena"^^schema:Person,
        "Sherry Moore"^^schema:Person,
        "Yutaka Leon Suematsu"^^schema:Person ;
    schema:commentCount "605"^^schema:Integer ;
    schema:dateModified "2017-06-11T08:42:28Z"^^schema:DateTime ;
    schema:datePublished "2017-03-03T05:41:30Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.5.1; I.5.2"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Large-Scale Evolution of Image Classifiers"^^schema:Text ;
    schema:publisher "ICML, 2902-2911"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01041v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2681013556507309683&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<237> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of stochastic optimization for deep learning in theparallel computing environment under communication constraints. A new algorithmis proposed in this setting where the communication and coordination of workamong concurrent processes (local workers), is based on an elastic force whichlinks the parameters they compute with a center variable stored by theparameter server (master). The algorithm enables the local workers to performmore exploration, i.e. the algorithm allows the local variables to fluctuatefurther from the center variable by reducing the amount of communicationbetween local workers and the master. We empirically demonstrate that in thedeep learning setting, due to the existence of many local optima, allowing moreexploration can lead to the improved performance. We propose synchronous andasynchronous variants of the new algorithm. We provide the stability analysisof the asynchronous variant in the round-robin scheme and compare it with themore common parallelized method ADMM. We show that the stability of EASGD isguaranteed when a simple stability condition is satisfied, which is not thecase for ADMM. We additionally propose the momentum-based version of ouralgorithm that can be applied in both synchronous and asynchronous settings.Asynchronous variant of the algorithm is applied to train convolutional neuralnetworks for image classification on the CIFAR and ImageNet datasets.Experiments demonstrate that the new algorithm accelerates the training of deeparchitectures compared to DOWNPOUR and other common baseline approaches andfurthermore is very communication efficient."^^schema:Text ;
    schema:author "Anna Choromanska"^^schema:Person,
        "Sixin Zhang"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "356"^^schema:Integer ;
    schema:dateModified "2015-10-25T12:12:52Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T13:22:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep learning with Elastic Averaging SGD"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6651v8"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18355366617755570418&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<238> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents OptNet, a network architecture that integratesoptimization problems (here, specifically in the form of quadratic programs) asindividual layers in larger end-to-end trainable deep networks. These layersencode constraints and complex dependencies between the hidden states thattraditional convolutional and fully-connected layers often cannot capture. Inthis paper, we explore the foundations for such an architecture: we show howtechniques from sensitivity analysis, bilevel optimization, and implicitdifferentiation can be used to exactly differentiate through these layers andwith respect to layer parameters; we develop a highly efficient solver forthese layers that exploits fast GPU-based batch solves within a primal-dualinterior point method, and which provides backpropagation gradients withvirtually no additional cost on top of the solve; and we highlight theapplication of these approaches in several problems. In one notable example, weshow that the method is capable of learning to play mini-Sudoku (4x4) givenjust input and output games, with no a priori information about the rules ofthe game; this highlights the ability of our architecture to learn hardconstraints better than other neural architectures."^^schema:Text ;
    schema:author "Brandon Amos"^^schema:Person,
        "J. Zico Kolter"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:dateModified "2019-10-14T18:03:26Z"^^schema:DateTime ;
    schema:datePublished "2017-03-01T18:58:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "OptNet: Differentiable Optimization as a Layer in Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 136-145"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00443v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9740292310844529830&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<239> a schema:ScholarlyArticle ;
    schema:abstract "Many recent Markov chain Monte Carlo (MCMC) samplers leverage continuousdynamics to define a transition kernel that efficiently explores a targetdistribution. In tandem, a focus has been on devising scalable variants thatsubsample the data and use stochastic gradients in place of full-data gradientsin the dynamic simulations. However, such stochastic gradient MCMC samplershave lagged behind their full-data counterparts in terms of the complexity ofdynamics considered since proving convergence in the presence of the stochasticgradient noise is non-trivial. Even with simple dynamics, significant physicalintuition is often required to modify the dynamical system to account for thestochastic gradient noise. In this paper, we provide a general recipe forconstructing MCMC samplers--including stochastic gradient versions--based oncontinuous Markov processes specified via two matrices. We constructively provethat the framework is complete. That is, any continuous Markov process thatprovides samples from the target distribution can be written in our framework.We show how previous continuous-dynamic samplers can be trivially \"reinvented\"in our framework, avoiding the complicated sampler-specific proofs. We likewiseuse our recipe to straightforwardly propose a new state-adaptive sampler:stochastic gradient Riemann Hamiltonian Monte Carlo (SGRHMC). Our experimentson simulated data and a streaming Wikipedia analysis demonstrate that theproposed SGRHMC sampler inherits the benefits of Riemann HMC, with thescalability of stochastic gradient methods."^^schema:Text ;
    schema:author "Emily B. Fox"^^schema:Person,
        "Tianqi Chen"^^schema:Person,
        "Yi-An Ma"^^schema:Person ;
    schema:commentCount "223"^^schema:Integer ;
    schema:dateModified "2015-11-01T00:18:32Z"^^schema:DateTime ;
    schema:datePublished "2015-06-15T18:32:37Z"^^schema:DateTime ;
    schema:genre "math.ST"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text,
        "stat.TH"^^schema:Text ;
    schema:headline "A Complete Recipe for Stochastic Gradient MCMC"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.04696v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13273505320087374669&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<24> a schema:ScholarlyArticle ;
    schema:abstract "Matrix completion is a basic machine learning problem that has wideapplications, especially in collaborative filtering and recommender systems.Simple non-convex optimization algorithms are popular and effective inpractice. Despite recent progress in proving various non-convex algorithmsconverge from a good initial point, it remains unclear why random or arbitraryinitialization suffices in practice. We prove that the commonly used non-convexobjective function for \\textit{positive semidefinite} matrix completion has nospurious local minima --- all local minima must also be global. Therefore, manypopular optimization algorithms such as (stochastic) gradient descent canprovably solve positive semidefinite matrix completion with \\textit{arbitrary}initialization in polynomial time. The result can be generalized to the settingwhen the observed entries contain noise. We believe that our main proofstrategy can be useful for understanding geometric properties of otherstatistical problems involving partial or noisy observations."^^schema:Text ;
    schema:author "Jason D. Lee"^^schema:Person,
        "Rong Ge"^^schema:Person,
        "Tengyu Ma"^^schema:Person ;
    schema:commentCount "399"^^schema:Integer ;
    schema:dateModified "2018-07-22T05:20:12Z"^^schema:DateTime ;
    schema:datePublished "2016-05-24T02:53:27Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Matrix Completion has No Spurious Local Minimum"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07272v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14724299708943701856&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<240> a schema:ScholarlyArticle ;
    schema:abstract "Domain adaptation is critical for success in new, unseen environments.Adversarial adaptation models applied in feature spaces discover domaininvariant representations, but are difficult to visualize and sometimes fail tocapture pixel-level and low-level domain shifts. Recent work has shown thatgenerative adversarial networks combined with cycle-consistency constraints aresurprisingly effective at mapping images between domains, even without the useof aligned image pairs. We propose a novel discriminatively-trainedCycle-Consistent Adversarial Domain Adaptation model. CyCADA adaptsrepresentations at both the pixel-level and feature-level, enforcescycle-consistency while leveraging a task loss, and does not require alignedpairs. Our model can be applied in a variety of visual recognition andprediction settings. We show new state-of-the-art results across multipleadaptation tasks, including digit classification and semantic segmentation ofroad scenes demonstrating transfer from synthetic to real world domains."^^schema:Text ;
    schema:author "Alexei A. Efros"^^schema:Person,
        "Eric Tzeng"^^schema:Person,
        "Judy Hoffman"^^schema:Person,
        "Jun-Yan Zhu"^^schema:Person,
        "Kate Saenko"^^schema:Person,
        "Phillip Isola"^^schema:Person,
        "Taesung Park"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:commentCount "708"^^schema:Integer ;
    schema:dateModified "2017-12-29T05:00:37Z"^^schema:DateTime ;
    schema:datePublished "2017-11-08T23:54:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "CyCADA: Cycle-Consistent Adversarial Domain Adaptation"^^schema:Text ;
    schema:publisher "ICML, 1994-2003"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.03213v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12837244440606171486&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<241> a schema:ScholarlyArticle ;
    schema:abstract "The cost of large scale data collection and annotation often makes theapplication of machine learning algorithms to new tasks or datasetsprohibitively expensive. One approach circumventing this cost is trainingmodels on synthetic data where annotations are provided automatically. Despitetheir appeal, such models often fail to generalize from synthetic to realimages, necessitating domain adaptation algorithms to manipulate these modelsbefore they can be successfully applied. Existing approaches focus either onmapping representations from one domain to the other, or on learning to extractfeatures that are invariant to the domain from which they were extracted.However, by focusing only on creating a mapping or shared representationbetween the two domains, they ignore the individual characteristics of eachdomain. We suggest that explicitly modeling what is unique to each domain canimprove a model's ability to extract domain-invariant features. Inspired bywork on private-shared component analysis, we explicitly learn to extract imagerepresentations that are partitioned into two subspaces: one component which isprivate to each domain and one which is shared across domains. Our model istrained not only to perform the task we care about in the source domain, butalso to use the partitioned representation to reconstruct the images from bothdomains. Our novel architecture results in a model that outperforms thestate-of-the-art on a range of unsupervised domain adaptation scenarios andadditionally produces visualizations of the private and shared representationsenabling interpretation of the domain adaptation process."^^schema:Text ;
    schema:author "Dilip Krishnan"^^schema:Person,
        "Dumitru Erhan"^^schema:Person,
        "George Trigeorgis"^^schema:Person,
        "Konstantinos Bousmalis"^^schema:Person,
        "Nathan Silberman"^^schema:Person ;
    schema:commentCount "573"^^schema:Integer ;
    schema:dateModified "2016-08-22T00:12:27Z"^^schema:DateTime ;
    schema:datePublished "2016-08-22T00:12:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Domain Separation Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.06019v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6506097335216287854&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<242> a schema:ScholarlyArticle ;
    schema:abstract "We consider the following problem: There is a set of items (e.g., movies) anda group of agents (e.g., passengers on a plane); each agent has some intrinsicutility for each of the items. Our goal is to pick a set of $K$ items thatmaximize the total derived utility of all the agents (i.e., in our example weare to pick $K$ movies that we put on the plane's entertainment system).However, the actual utility that an agent derives from a given item is only afraction of its intrinsic one, and this fraction depends on how the agent ranksthe item among the chosen, available, ones. We provide a formal specificationof the model and provide concrete examples and settings where it is applicable.We show that the problem is hard in general, but we show a number oftractability results for its natural special cases."^^schema:Text ;
    schema:author "Jerome Lang"^^schema:Person,
        "Piotr Faliszewski"^^schema:Person,
        "Piotr Skowron"^^schema:Person ;
    schema:commentCount "134"^^schema:Integer ;
    schema:dateModified "2016-01-08T19:51:00Z"^^schema:DateTime ;
    schema:datePublished "2014-02-13T07:14:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.GT"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Finding a Collective Set of Items: From Proportional Multirepresentation  to Group Recommendation"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1402.3044v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=860117861628466866&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<243> a schema:ScholarlyArticle ;
    schema:abstract "We adapt the ideas underlying the success of Deep Q-Learning to thecontinuous action domain. We present an actor-critic, model-free algorithmbased on the deterministic policy gradient that can operate over continuousaction spaces. Using the same learning algorithm, network architecture andhyper-parameters, our algorithm robustly solves more than 20 simulated physicstasks, including classic problems such as cartpole swing-up, dexterousmanipulation, legged locomotion and car driving. Our algorithm is able to findpolicies whose performance is competitive with those found by a planningalgorithm with full access to the dynamics of the domain and its derivatives.We further demonstrate that for many of the tasks the algorithm can learnpolicies end-to-end: directly from raw pixel inputs."^^schema:Text ;
    schema:author "Alexander Pritzel"^^schema:Person,
        "Daan Wierstra"^^schema:Person,
        "David Silver"^^schema:Person,
        "Jonathan J. Hunt"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Timothy P. Lillicrap"^^schema:Person,
        "Tom Erez"^^schema:Person,
        "Yuval Tassa"^^schema:Person ;
    schema:commentCount "3683"^^schema:Integer ;
    schema:dateModified "2019-07-05T10:47:27Z"^^schema:DateTime ;
    schema:datePublished "2015-09-09T23:01:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continuous control with deep reinforcement learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.02971v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4133004576987558805&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<244> a schema:ScholarlyArticle ;
    schema:abstract "Although the latest high-end smartphone has powerful CPU and GPU, runningdeeper convolutional neural networks (CNNs) for complex tasks such as ImageNetclassification on mobile devices is challenging. To deploy deep CNNs on mobiledevices, we present a simple and effective scheme to compress the entire CNN,which we call one-shot whole network compression. The proposed scheme consistsof three steps: (1) rank selection with variational Bayesian matrixfactorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuningto recover accumulated loss of accuracy, and each step can be easilyimplemented using publicly available tools. We demonstrate the effectiveness ofthe proposed scheme by testing the performance of various compressed CNNs(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significantreductions in model size, runtime, and energy consumption are obtained, at thecost of small loss in accuracy. In addition, we address the importantimplementation level issue on 1?1 convolution, which is a key operation ofinception module of GoogLeNet as well as CNNs compressed by our proposedscheme."^^schema:Text ;
    schema:author "Dongjun Shin"^^schema:Person,
        "Eunhyeok Park"^^schema:Person,
        "Lu Yang"^^schema:Person,
        "Sungjoo Yoo"^^schema:Person,
        "Taelim Choi"^^schema:Person,
        "Yong-Deok Kim"^^schema:Person ;
    schema:commentCount "470"^^schema:Integer ;
    schema:dateModified "2016-02-24T11:52:12Z"^^schema:DateTime ;
    schema:datePublished "2015-11-20T09:20:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Compression of Deep Convolutional Neural Networks for Fast and Low Power  Mobile Applications"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06530v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=271868299753778474&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<245> a schema:ScholarlyArticle ;
    schema:abstract "Text classification is an important and classical problem in natural languageprocessing. There have been a number of studies that applied convolutionalneural networks (convolution on regular grid, e.g., sequence) toclassification. However, only a limited number of studies have explored themore flexible graph convolutional neural networks (convolution on non-grid,e.g., arbitrary graph) for the task. In this work, we propose to use graphconvolutional networks for text classification. We build a single text graphfor a corpus based on word co-occurrence and document word relations, thenlearn a Text Graph Convolutional Network (Text GCN) for the corpus. Our TextGCN is initialized with one-hot representation for word and document, it thenjointly learns the embeddings for both words and documents, as supervised bythe known class labels for documents. Our experimental results on multiplebenchmark datasets demonstrate that a vanilla Text GCN without any externalword embeddings or knowledge outperforms state-of-the-art methods for textclassification. On the other hand, Text GCN also learns predictive word anddocument embeddings. In addition, experimental results show that theimprovement of Text GCN over state-of-the-art comparison methods become moreprominent as we lower the percentage of training data, suggesting therobustness of Text GCN to less training data in text classification."^^schema:Text ;
    schema:author "Chengsheng Mao"^^schema:Person,
        "Liang Yao"^^schema:Person,
        "Yuan Luo"^^schema:Person ;
    schema:commentCount "138"^^schema:Integer ;
    schema:dateModified "2018-11-13T05:23:40Z"^^schema:DateTime ;
    schema:datePublished "2018-09-15T09:13:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Graph Convolutional Networks for Text Classification"^^schema:Text ;
    schema:publisher "Proceedings of the AAAI Conference on Artificial Intelligence 33, 7370-7377"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1809.05679v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8652850659505697306&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<246> a schema:ScholarlyArticle ;
    schema:abstract "We describe a new training methodology for generative adversarial networks.The key idea is to grow both the generator and discriminator progressively:starting from a low resolution, we add new layers that model increasingly finedetails as training progresses. This both speeds the training up and greatlystabilizes it, allowing us to produce images of unprecedented quality, e.g.,CelebA images at 1024^2. We also propose a simple way to increase the variationin generated images, and achieve a record inception score of 8.80 inunsupervised CIFAR10. Additionally, we describe several implementation detailsthat are important for discouraging unhealthy competition between the generatorand discriminator. Finally, we suggest a new metric for evaluating GAN results,both in terms of image quality and variation. As an additional contribution, weconstruct a higher-quality version of the CelebA dataset."^^schema:Text ;
    schema:author "Jaakko Lehtinen"^^schema:Person,
        "Samuli Laine"^^schema:Person,
        "Tero Karras"^^schema:Person,
        "Timo Aila"^^schema:Person ;
    schema:commentCount "1819"^^schema:Integer ;
    schema:dateModified "2018-02-26T15:33:34Z"^^schema:DateTime ;
    schema:datePublished "2017-10-27T15:28:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Progressive Growing of GANs for Improved Quality, Stability, and  Variation"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.10196v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11486098150916361186&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<247> a schema:ScholarlyArticle ;
    schema:abstract "With a goal of understanding what drives generalization in deep networks, weconsider several recently suggested explanations, including norm-based control,sharpness and robustness. We study how these measures can ensuregeneralization, highlighting the importance of scale normalization, and makinga connection between sharpness and PAC-Bayes theory. We then investigate howwell the measures explain different observed phenomena."^^schema:Text ;
    schema:author "Behnam Neyshabur"^^schema:Person,
        "David McAllester"^^schema:Person,
        "Nathan Srebro"^^schema:Person,
        "Srinadh Bhojanapalli"^^schema:Person ;
    schema:commentCount "349"^^schema:Integer ;
    schema:dateModified "2017-07-06T17:10:40Z"^^schema:DateTime ;
    schema:datePublished "2017-06-27T17:20:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Exploring Generalization in Deep Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.08947v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16285731102067380229&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<248> a schema:ScholarlyArticle ;
    schema:abstract "Training of large-scale deep neural networks is often constrained by theavailable computational resources. We study the effect of limited precisiondata representation and computation on neural network training. Within thecontext of low-precision fixed-point computations, we observe the roundingscheme to play a crucial role in determining the network's behavior duringtraining. Our results show that deep networks can be trained using only 16-bitwide fixed-point number representation when using stochastic rounding, andincur little to no degradation in the classification accuracy. We alsodemonstrate an energy-efficient hardware accelerator that implementslow-precision fixed-point arithmetic with stochastic rounding."^^schema:Text ;
    schema:author "Ankur Agrawal"^^schema:Person,
        "Kailash Gopalakrishnan"^^schema:Person,
        "Pritish Narayanan"^^schema:Person,
        "Suyog Gupta"^^schema:Person ;
    schema:commentCount "1092"^^schema:Integer ;
    schema:dateModified "2015-02-09T16:37:29Z"^^schema:DateTime ;
    schema:datePublished "2015-02-09T16:37:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Learning with Limited Numerical Precision"^^schema:Text ;
    schema:publisher "ICML, 1737-1746"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02551v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14109789955727767115&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<249> a schema:ScholarlyArticle ;
    schema:abstract "Gaussian state space models have been used for decades as generative modelsof sequential data. They admit an intuitive probabilistic interpretation, havea simple functional form, and enjoy widespread adoption. We introduce a unifiedalgorithm to efficiently learn a broad class of linear and non-linear statespace models, including variants where the emission and transitiondistributions are modeled by deep neural networks. Our learning algorithmsimultaneously learns a compiled inference network and the generative model,leveraging a structured variational approximation parameterized by recurrentneural networks to mimic the posterior distribution. We apply the learningalgorithm to both synthetic and real-world datasets, demonstrating itsscalability and versatility. We find that using the structured approximation tothe posterior results in models with significantly higher held-out likelihood."^^schema:Text ;
    schema:author "David Sontag"^^schema:Person,
        "Rahul G. Krishnan"^^schema:Person,
        "Uri Shalit"^^schema:Person ;
    schema:commentCount "179"^^schema:Integer ;
    schema:dateModified "2016-12-05T19:10:10Z"^^schema:DateTime ;
    schema:datePublished "2016-09-30T19:53:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Structured Inference Networks for Nonlinear State Space Models"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.09869v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17763269236884701463&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<25> a schema:ScholarlyArticle ;
    schema:abstract "Graph Neural Networks (GNNs) are an effective framework for representationlearning of graphs. GNNs follow a neighborhood aggregation scheme, where therepresentation vector of a node is computed by recursively aggregating andtransforming representation vectors of its neighboring nodes. Many GNN variantshave been proposed and have achieved state-of-the-art results on both node andgraph classification tasks. However, despite GNNs revolutionizing graphrepresentation learning, there is limited understanding of theirrepresentational properties and limitations. Here, we present a theoreticalframework for analyzing the expressive power of GNNs to capture different graphstructures. Our results characterize the discriminative power of popular GNNvariants, such as Graph Convolutional Networks and GraphSAGE, and show thatthey cannot learn to distinguish certain simple graph structures. We thendevelop a simple architecture that is provably the most expressive among theclass of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphismtest. We empirically validate our theoretical findings on a number of graphclassification benchmarks, and demonstrate that our model achievesstate-of-the-art performance."^^schema:Text ;
    schema:author "Jure Leskovec"^^schema:Person,
        "Keyulu Xu"^^schema:Person,
        "Stefanie Jegelka"^^schema:Person,
        "Weihua Hu"^^schema:Person ;
    schema:commentCount "523"^^schema:Integer ;
    schema:dateModified "2019-02-22T19:15:54Z"^^schema:DateTime ;
    schema:datePublished "2018-10-01T17:11:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "How Powerful are Graph Neural Networks?"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1810.00826v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9955904491400591671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<250> a schema:ScholarlyArticle ;
    schema:abstract "We learn rich natural sound representations by capitalizing on large amountsof unlabeled sound data collected in the wild. We leverage the naturalsynchronization between vision and sound to learn an acoustic representationusing two-million unlabeled videos. Unlabeled video has the advantage that itcan be economically acquired at massive scales, yet contains useful signalsabout natural sound. We propose a student-teacher training procedure whichtransfers discriminative visual knowledge from well established visualrecognition models into the sound modality using unlabeled video as a bridge.Our sound representation yields significant performance improvements over thestate-of-the-art results on standard benchmarks for acoustic scene/objectclassification. Visualizations suggest some high-level semantics automaticallyemerge in the sound network, even though it is trained without ground truthlabels."^^schema:Text ;
    schema:author "Antonio Torralba"^^schema:Person,
        "Carl Vondrick"^^schema:Person,
        "Yusuf Aytar"^^schema:Person ;
    schema:commentCount "472"^^schema:Integer ;
    schema:dateModified "2016-10-27T20:23:39Z"^^schema:DateTime ;
    schema:datePublished "2016-10-27T20:23:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text ;
    schema:headline "SoundNet: Learning Sound Representations from Unlabeled Video"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.09001v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10397330204607504126&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<251> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the \"exponential linear unit\" (ELU) which speeds up learning indeep neural networks and leads to higher classification accuracies. Likerectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs(PReLUs), ELUs alleviate the vanishing gradient problem via the identity forpositive values. However, ELUs have improved learning characteristics comparedto the units with other activation functions. In contrast to ReLUs, ELUs havenegative values which allows them to push mean unit activations closer to zerolike batch normalization but with lower computational complexity. Mean shiftstoward zero speed up learning by bringing the normal gradient closer to theunit natural gradient because of a reduced bias shift effect. While LReLUs andPReLUs have negative values, too, they do not ensure a noise-robustdeactivation state. ELUs saturate to a negative value with smaller inputs andthereby decrease the forward propagated variation and information. Therefore,ELUs code the degree of presence of particular phenomena in the input, whilethey do not quantitatively model the degree of their absence. In experiments,ELUs lead not only to faster learning, but also to significantly bettergeneralization performance than ReLUs and LReLUs on networks with more than 5layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks withbatch normalization while batch normalization does not improve ELU networks.ELU networks are among the top 10 reported CIFAR-10 results and yield the bestpublished result on CIFAR-100, without resorting to multi-view evaluation ormodel averaging. On ImageNet, ELU networks considerably speed up learningcompared to a ReLU network with the same architecture, obtaining less than 10%classification error for a single crop, single model network."^^schema:Text ;
    schema:author "Djork-Arné Clevert"^^schema:Person,
        "Sepp Hochreiter"^^schema:Person,
        "Thomas Unterthiner"^^schema:Person ;
    schema:commentCount "2436"^^schema:Integer ;
    schema:dateModified "2016-02-22T07:02:58Z"^^schema:DateTime ;
    schema:datePublished "2015-11-23T15:58:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Fast and Accurate Deep Network Learning by Exponential Linear Units  (ELUs)"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.07289v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13103600599147838489&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<252> a schema:ScholarlyArticle ;
    schema:abstract "Clinical medical data, especially in the intensive care unit (ICU), consistof multivariate time series of observations. For each patient visit (orepisode), sensor data and lab test results are recorded in the patient'sElectronic Health Record (EHR). While potentially containing a wealth ofinsights, the data is difficult to mine effectively, owing to varying length,irregular sampling and missing data. Recurrent Neural Networks (RNNs),particularly those using Long Short-Term Memory (LSTM) hidden units, arepowerful and increasingly popular models for learning from sequence data. Theyeffectively model varying length sequences and capture long range dependencies.We present the first study to empirically evaluate the ability of LSTMs torecognize patterns in multivariate time series of clinical measurements.Specifically, we consider multilabel classification of diagnoses, training amodel to classify 128 diagnoses given 13 frequently but irregularly sampledclinical measurements. First, we establish the effectiveness of a simple LSTMnetwork for modeling clinical data. Then we demonstrate a straightforward andeffective training strategy in which we replicate targets at each sequencestep. Trained only on raw time series, our models outperform several strongbaselines, including a multilayer perceptron trained on hand-engineeredfeatures."^^schema:Text ;
    schema:author "Charles Elkan"^^schema:Person,
        "David C. Kale"^^schema:Person,
        "Randall Wetzel"^^schema:Person,
        "Zachary C. Lipton"^^schema:Person ;
    schema:commentCount "635"^^schema:Integer ;
    schema:dateModified "2017-03-21T21:29:50Z"^^schema:DateTime ;
    schema:datePublished "2015-11-11T21:01:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Learning to Diagnose with LSTM Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.03677v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8027693791853042695&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<253> a schema:ScholarlyArticle ;
    schema:abstract "Gatys et al. recently introduced a neural algorithm that renders a contentimage in the style of another image, achieving so-called style transfer.However, their framework requires a slow iterative optimization process, whichlimits its practical application. Fast approximations with feed-forward neuralnetworks have been proposed to speed up neural style transfer. Unfortunately,the speed improvement comes at a cost: the network is usually tied to a fixedset of styles and cannot adapt to arbitrary new styles. In this paper, wepresent a simple yet effective approach that for the first time enablesarbitrary style transfer in real-time. At the heart of our method is a noveladaptive instance normalization (AdaIN) layer that aligns the mean and varianceof the content features with those of the style features. Our method achievesspeed comparable to the fastest existing approach, without the restriction to apre-defined set of styles. In addition, our approach allows flexible usercontrols such as content-style trade-off, style interpolation, color &amp; spatialcontrols, all using a single feed-forward neural network."^^schema:Text ;
    schema:author "Serge Belongie"^^schema:Person,
        "Xun Huang"^^schema:Person ;
    schema:commentCount "672"^^schema:Integer ;
    schema:dateModified "2017-07-30T09:32:17Z"^^schema:DateTime ;
    schema:datePublished "2017-03-20T17:51:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Arbitrary Style Transfer in Real-time with Adaptive Instance  Normalization"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.06868v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6462913724934880335&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<254> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial examples are malicious inputs designed to fool machine learningmodels. They often transfer from one model to another, allowing attackers tomount black box attacks without knowledge of the target model's parameters.Adversarial training is the process of explicitly training a model onadversarial examples, in order to make it more robust to attack or to reduceits test error on clean inputs. So far, adversarial training has primarily beenapplied to small problems. In this research, we apply adversarial training toImageNet. Our contributions include: (1) recommendations for how to succesfullyscale adversarial training to large models and datasets, (2) the observationthat adversarial training confers robustness to single-step attack methods, (3)the finding that multi-step attack methods are somewhat less transferable thansingle-step attack methods, so single-step attacks are the best for mountingblack-box attacks, and (4) resolution of a \"label leaking\" effect that causesadversarially trained models to perform better on adversarial examples than onclean examples, because the adversarial example construction process uses thetrue label and the model can learn to exploit regularities in the constructionprocess."^^schema:Text ;
    schema:author "Alexey Kurakin"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "922"^^schema:Integer ;
    schema:dateModified "2017-02-11T00:15:46Z"^^schema:DateTime ;
    schema:datePublished "2016-11-04T01:11:02Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Machine Learning at Scale"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01236v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8221212997031548134&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<255> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we are interested in generalizing convolutional neural networks(CNNs) from low-dimensional regular grids, where image, video and speech arerepresented, to high-dimensional irregular domains, such as social networks,brain connectomes or words' embedding, represented by graphs. We present aformulation of CNNs in the context of spectral graph theory, which provides thenecessary mathematical background and efficient numerical schemes to designfast localized convolutional filters on graphs. Importantly, the proposedtechnique offers the same linear computational complexity and constant learningcomplexity as classical CNNs, while being universal to any graph structure.Experiments on MNIST and 20NEWS demonstrate the ability of this novel deeplearning system to learn local, stationary, and compositional features ongraphs."^^schema:Text ;
    schema:author "Michaël Defferrard"^^schema:Person,
        "Pierre Vandergheynst"^^schema:Person,
        "Xavier Bresson"^^schema:Person ;
    schema:commentCount "2027"^^schema:Integer ;
    schema:dateModified "2017-02-05T17:04:39Z"^^schema:DateTime ;
    schema:datePublished "2016-06-30T07:42:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Convolutional Neural Networks on Graphs with Fast Localized Spectral  Filtering"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.09375v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18205894503371115148&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<256> a schema:ScholarlyArticle ;
    schema:abstract "Is it possible to maximize a monotone submodular function faster than thewidely used lazy greedy algorithm (also known as accelerated greedy), both intheory and practice? In this paper, we develop the first linear-time algorithmfor maximizing a general monotone submodular function subject to a cardinalityconstraint. We show that our randomized algorithm, STOCHASTIC-GREEDY, canachieve a $(1-1/e-\\varepsilon)$ approximation guarantee, in expectation, to theoptimum solution in time linear in the size of the data and independent of thecardinality constraint. We empirically demonstrate the effectiveness of ouralgorithm on submodular functions arising in data summarization, includingtraining large-scale kernel methods, exemplar-based clustering, and sensorplacement. We observe that STOCHASTIC-GREEDY practically achieves the sameutility value as lazy greedy but runs much faster. More surprisingly, weobserve that in many practical scenarios STOCHASTIC-GREEDY does not evaluatethe whole fraction of data points even once and still achievesindistinguishable results compared to lazy greedy."^^schema:Text ;
    schema:author "Amin Karbasi"^^schema:Person,
        "Andreas Krause"^^schema:Person,
        "Ashwinkumar Badanidiyuru"^^schema:Person,
        "Baharan Mirzasoleiman"^^schema:Person,
        "Jan Vondrak"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:dateModified "2014-11-28T13:06:54Z"^^schema:DateTime ;
    schema:datePublished "2014-09-28T18:06:23Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Lazier Than Lazy Greedy"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1409.7938v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8147030613819583144&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<257> a schema:ScholarlyArticle ;
    schema:abstract "We propose an efficient method for approximating natural gradient descent inneural networks which we call Kronecker-Factored Approximate Curvature (K-FAC).K-FAC is based on an efficiently invertible approximation of a neural network'sFisher information matrix which is neither diagonal nor low-rank, and in somecases is completely non-sparse. It is derived by approximating various largeblocks of the Fisher (corresponding to entire layers) as being the Kroneckerproduct of two much smaller matrices. While only several times more expensiveto compute than the plain stochastic gradient, the updates produced by K-FACmake much more progress optimizing the objective, which results in an algorithmthat can be much faster than stochastic gradient descent with momentum inpractice. And unlike some previously proposed approximatenatural-gradient/Newton methods which use high-quality non-diagonal curvaturematrices (such as Hessian-free optimization), K-FAC works very well in highlystochastic optimization regimes. This is because the cost of storing andinverting K-FAC's approximation to the curvature matrix does not depend on theamount of data used to estimate it, which is a feature typically associatedonly with diagonal or low-rank approximations to the curvature matrix."^^schema:Text ;
    schema:author "James Martens"^^schema:Person,
        "Roger Grosse"^^schema:Person ;
    schema:commentCount "314"^^schema:Integer ;
    schema:dateModified "2020-06-08T01:28:58Z"^^schema:DateTime ;
    schema:datePublished "2015-03-19T08:30:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Optimizing Neural Networks with Kronecker-factored Approximate Curvature"^^schema:Text ;
    schema:publisher "ICML, 2408-2417"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.05671v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11551045348725818062&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<258> a schema:ScholarlyArticle ;
    schema:abstract "We explore a recently proposed Variational Dropout technique that provided anelegant Bayesian interpretation to Gaussian Dropout. We extend VariationalDropout to the case when dropout rates are unbounded, propose a way to reducethe variance of the gradient estimator and report first experimental resultswith individual dropout rates per weight. Interestingly, it leads to extremelysparse solutions both in fully-connected and convolutional layers. This effectis similar to automatic relevance determination effect in empirical Bayes buthas a number of advantages. We reduce the number of parameters up to 280 timeson LeNet architectures and up to 68 times on VGG-like networks with anegligible decrease of accuracy."^^schema:Text ;
    schema:author "Arsenii Ashukha"^^schema:Person,
        "Dmitry Molchanov"^^schema:Person,
        "Dmitry Vetrov"^^schema:Person ;
    schema:commentCount "311"^^schema:Integer ;
    schema:dateModified "2017-06-13T11:01:55Z"^^schema:DateTime ;
    schema:datePublished "2017-01-19T10:44:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Dropout Sparsifies Deep Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 2498-2507"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.05369v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11014728550012194230&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<259> a schema:ScholarlyArticle ;
    schema:abstract "We describe a simple neural language model that relies only oncharacter-level inputs. Predictions are still made at the word-level. Our modelemploys a convolutional neural network (CNN) and a highway network overcharacters, whose output is given to a long short-term memory (LSTM) recurrentneural network language model (RNN-LM). On the English Penn Treebank the modelis on par with the existing state-of-the-art despite having 60% fewerparameters. On languages with rich morphology (Arabic, Czech, French, German,Spanish, Russian), the model outperforms word-level/morpheme-level LSTMbaselines, again with fewer parameters. The results suggest that on manylanguages, character inputs are sufficient for language modeling. Analysis ofword representations obtained from the character composition part of the modelreveals that the model is able to encode, from characters only, both semanticand orthographic information."^^schema:Text ;
    schema:author "Alexander M. Rush"^^schema:Person,
        "David Sontag"^^schema:Person,
        "Yacine Jernite"^^schema:Person,
        "Yoon Kim"^^schema:Person ;
    schema:commentCount "1278"^^schema:Integer ;
    schema:dateModified "2015-12-01T22:59:24Z"^^schema:DateTime ;
    schema:datePublished "2015-08-26T19:25:34Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Character-Aware Neural Language Models"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1508.06615v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3272758346108198795&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<26> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial networks (GAN) are a powerful subclass of generativemodels. Despite a very rich research activity leading to numerous interestingGAN algorithms, it is still very hard to assess which algorithm(s) performbetter than others. We conduct a neutral, multi-faceted large-scale empiricalstudy on state-of-the art models and evaluation measures. We find that mostmodels can reach similar scores with enough hyperparameter optimization andrandom restarts. This suggests that improvements can arise from a highercomputational budget and tuning more than fundamental algorithmic changes. Toovercome some limitations of the current metrics, we also propose several datasets on which precision and recall can be computed. Our experimental resultssuggest that future GAN research should be based on more systematic andobjective evaluation procedures. Finally, we did not find evidence that any ofthe tested algorithms consistently outperforms the non-saturating GANintroduced in \\cite{goodfellow2014generative}."^^schema:Text ;
    schema:author "Karol Kurach"^^schema:Person,
        "Marcin Michalski"^^schema:Person,
        "Mario Lucic"^^schema:Person,
        "Olivier Bousquet"^^schema:Person,
        "Sylvain Gelly"^^schema:Person ;
    schema:commentCount "363"^^schema:Integer ;
    schema:dateModified "2018-10-29T15:34:15Z"^^schema:DateTime ;
    schema:datePublished "2017-11-28T15:19:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Are GANs Created Equal? A Large-Scale Study"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.10337v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3229217754457345915&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<260> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial training provides a means of regularizing supervised learningalgorithms while virtual adversarial training is able to extend supervisedlearning algorithms to the semi-supervised setting. However, both methodsrequire making small perturbations to numerous entries of the input vector,which is inappropriate for sparse high-dimensional inputs such as one-hot wordrepresentations. We extend adversarial and virtual adversarial training to thetext domain by applying perturbations to the word embeddings in a recurrentneural network rather than to the original input itself. The proposed methodachieves state of the art results on multiple benchmark semi-supervised andpurely supervised tasks. We provide visualizations and analysis showing thatthe learned word embeddings have improved in quality and that while training,the model is less prone to overfitting."^^schema:Text ;
    schema:author "Andrew M. Dai"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Takeru Miyato"^^schema:Person ;
    schema:commentCount "275"^^schema:Integer ;
    schema:dateModified "2017-05-06T20:16:03Z"^^schema:DateTime ;
    schema:datePublished "2016-05-25T04:25:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Training Methods for Semi-Supervised Text Classification"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07725v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6594257289645930121&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<261> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a generic scheme for accelerating first-order optimizationmethods in the sense of Nesterov, which builds upon a new analysis of theaccelerated proximal point algorithm. Our approach consists of minimizing aconvex objective by approximately solving a sequence of well-chosen auxiliaryproblems, leading to faster convergence. This strategy applies to a large classof algorithms, including gradient descent, block coordinate descent, SAG, SAGA,SDCA, SVRG, Finito/MISO, and their proximal variants. For all of these methods,we provide acceleration and explicit support for non-strongly convexobjectives. In addition to theoretical speed-up, we also show that accelerationis useful in practice, especially for ill-conditioned problems where we measuresignificant improvements."^^schema:Text ;
    schema:author "Hongzhou Lin"^^schema:Person,
        "Julien Mairal"^^schema:Person,
        "Zaid Harchaoui"^^schema:Person ;
    schema:commentCount "318"^^schema:Integer ;
    schema:dateModified "2015-10-25T10:57:08Z"^^schema:DateTime ;
    schema:datePublished "2015-06-06T19:49:48Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text ;
    schema:headline "A Universal Catalyst for First-Order Optimization"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02186v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1451579851477033920&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<262> a schema:ScholarlyArticle ;
    schema:abstract "Temporal abstraction is key to scaling up learning and planning inreinforcement learning. While planning with temporally extended actions is wellunderstood, creating such abstractions autonomously from data has remainedchallenging. We tackle this problem in the framework of options [Sutton, Precup&amp; Singh, 1999; Precup, 2000]. We derive policy gradient theorems for optionsand propose a new option-critic architecture capable of learning both theinternal policies and the termination conditions of options, in tandem with thepolicy over options, and without the need to provide any additional rewards orsubgoals. Experimental results in both discrete and continuous environmentsshowcase the flexibility and efficiency of the framework."^^schema:Text ;
    schema:author "Doina Precup"^^schema:Person,
        "Jean Harb"^^schema:Person,
        "Pierre-Luc Bacon"^^schema:Person ;
    schema:commentCount "384"^^schema:Integer ;
    schema:dateModified "2016-12-03T02:47:51Z"^^schema:DateTime ;
    schema:datePublished "2016-09-16T17:05:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "The Option-Critic Architecture"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.05140v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=107676057328336895&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<263> a schema:ScholarlyArticle ;
    schema:abstract "In statistical relational learning, the link prediction problem is key toautomatically understand the structure of large knowledge bases. As in previousstudies, we propose to solve this problem through latent factorization.However, here we make use of complex valued embeddings. The composition ofcomplex embeddings can handle a large variety of binary relations, among themsymmetric and antisymmetric relations. Compared to state-of-the-art models suchas Neural Tensor Network and Holographic Embeddings, our approach based oncomplex embeddings is arguably simpler, as it only uses the Hermitian dotproduct, the complex counterpart of the standard dot product between realvectors. Our approach is scalable to large datasets as it remains linear inboth space and time, while consistently outperforming alternative approaches onstandard link prediction benchmarks."^^schema:Text ;
    schema:author "Guillaume Bouchard"^^schema:Person,
        "Johannes Welbl"^^schema:Person,
        "Sebastian Riedel"^^schema:Person,
        "Théo Trouillon"^^schema:Person,
        "Éric Gaussier"^^schema:Person ;
    schema:commentCount "542"^^schema:Integer ;
    schema:dateModified "2016-06-20T22:52:48Z"^^schema:DateTime ;
    schema:datePublished "2016-06-20T22:52:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Complex Embeddings for Simple Link Prediction"^^schema:Text ;
    schema:publisher "ICML, 2071-2080"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.06357v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3538792764263491534&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<264> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of off-policy value evaluation in reinforcement learning(RL), where one aims to estimate the value of a new policy based on datacollected by a different policy. This problem is often a critical step whenapplying RL in real-world problems. Despite its importance, existing generalmethods either have uncontrolled bias or suffer high variance. In this work, weextend the doubly robust estimator for bandits to sequential decision-makingproblems, which gets the best of both worlds: it is guaranteed to be unbiasedand can have a much lower variance than the popular importance samplingestimators. We demonstrate the estimator's accuracy in several benchmarkproblems, and illustrate its use as a subroutine in safe policy improvement. Wealso provide theoretical results on the hardness of the problem, and show thatour estimator can match the lower bound in certain scenarios."^^schema:Text ;
    schema:author "Lihong Li"^^schema:Person,
        "Nan Jiang"^^schema:Person ;
    schema:commentCount "198"^^schema:Integer ;
    schema:dateModified "2016-05-26T15:43:08Z"^^schema:DateTime ;
    schema:datePublished "2015-11-11T22:59:51Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Doubly Robust Off-policy Value Evaluation for Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 652-661"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.03722v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5974463330118879206&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<265> a schema:ScholarlyArticle ;
    schema:abstract "Link prediction for knowledge graphs is the task of predicting missingrelationships between entities. Previous work on link prediction has focused onshallow, fast models which can scale to large knowledge graphs. However, thesemodels learn less expressive features than deep, multi-layer models -- whichpotentially limits performance. In this work, we introduce ConvE, a multi-layerconvolutional network model for link prediction, and report state-of-the-artresults for several established datasets. We also show that the model is highlyparameter efficient, yielding the same performance as DistMult and R-GCN with8x and 17x fewer parameters. Analysis of our model suggests that it isparticularly effective at modelling nodes with high indegree -- which arecommon in highly-connected, complex knowledge graphs such as Freebase andYAGO3. In addition, it has been noted that the WN18 and FB15k datasets sufferfrom test set leakage, due to inverse relations from the training set beingpresent in the test set -- however, the extent of this issue has so far notbeen quantified. We find this problem to be severe: a simple rule-based modelcan achieve state-of-the-art results on both WN18 and FB15k. To ensure thatmodels are evaluated on datasets where simply exploiting inverse relationscannot yield competitive results, we investigate and validate several commonlyused datasets -- deriving robust variants where necessary. We then performexperiments on these robust datasets for our own and several previouslyproposed models and find that ConvE achieves state-of-the-art Mean ReciprocalRank across most datasets."^^schema:Text ;
    schema:author "Pasquale Minervini"^^schema:Person,
        "Pontus Stenetorp"^^schema:Person,
        "Sebastian Riedel"^^schema:Person,
        "Tim Dettmers"^^schema:Person ;
    schema:commentCount "349"^^schema:Integer ;
    schema:dateModified "2018-07-04T09:53:46Z"^^schema:DateTime ;
    schema:datePublished "2017-07-05T17:18:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Convolutional 2D Knowledge Graph Embeddings"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.01476v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18086027355742564589&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<266> a schema:ScholarlyArticle ;
    schema:abstract "Recent neural network sequence models with softmax classifiers have achievedtheir best language modeling performance only with very large hidden states andlarge vocabularies. Even then they struggle to predict rare or unseen wordseven if the context makes the prediction unambiguous. We introduce the pointersentinel mixture architecture for neural sequence models which has the abilityto either reproduce a word from the recent context or produce a word from astandard softmax classifier. Our pointer sentinel-LSTM model achieves state ofthe art language modeling performance on the Penn Treebank (70.9 perplexity)while using far fewer parameters than a standard softmax LSTM. In order toevaluate how well language models can exploit longer contexts and deal withmore realistic vocabularies and larger corpora we also introduce the freelyavailable WikiText corpus."^^schema:Text ;
    schema:author "Caiming Xiong"^^schema:Person,
        "James Bradbury"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Stephen Merity"^^schema:Person ;
    schema:commentCount "517"^^schema:Integer ;
    schema:dateModified "2016-09-26T04:06:13Z"^^schema:DateTime ;
    schema:datePublished "2016-09-26T04:06:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Pointer Sentinel Mixture Models"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.07843v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17812832384777278922&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<267> a schema:ScholarlyArticle ;
    schema:abstract "Gradient-based meta-learning techniques are both widely applicable andproficient at solving challenging few-shot learning and fast adaptationproblems. However, they have practical difficulties when operating onhigh-dimensional parameter spaces in extreme low-data regimes. We show that itis possible to bypass these limitations by learning a data-dependent latentgenerative representation of model parameters, and performing gradient-basedmeta-learning in this low-dimensional latent space. The resulting approach,latent embedding optimization (LEO), decouples the gradient-based adaptationprocedure from the underlying high-dimensional space of model parameters. Ourevaluation shows that LEO can achieve state-of-the-art performance on thecompetitive miniImageNet and tieredImageNet few-shot classification tasks.Further analysis indicates LEO is able to capture uncertainty in the data, andcan perform adaptation more effectively by optimizing in latent space."^^schema:Text ;
    schema:author "Andrei A. Rusu"^^schema:Person,
        "Dushyant Rao"^^schema:Person,
        "Jakub Sygnowski"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Raia Hadsell"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Simon Osindero"^^schema:Person ;
    schema:commentCount "211"^^schema:Integer ;
    schema:dateModified "2019-03-26T13:36:45Z"^^schema:DateTime ;
    schema:datePublished "2018-07-16T16:35:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Meta-Learning with Latent Embedding Optimization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1807.05960v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11552536411545683614&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<268> a schema:ScholarlyArticle ;
    schema:abstract "Verifying the robustness property of a general Rectified Linear Unit (ReLU)network is an NP-complete problem [Katz, Barrett, Dill, Julian and KochenderferCAV17]. Although finding the exact minimum adversarial distortion is hard,giving a certified lower bound of the minimum distortion is possible. Currentavailable methods of computing such a bound are either time-consuming ordelivering low quality bounds that are too loose to be useful. In this paper,we exploit the special structure of ReLU networks and provide twocomputationally efficient algorithms Fast-Lin and Fast-Lip that are able tocertify non-trivial lower bounds of minimum distortions, by bounding the ReLUunits with appropriate linear functions Fast-Lin, or by bounding the localLipschitz constant Fast-Lip. Experiments show that (1) our proposed methodsdeliver bounds close to (the gap is 2-3X) exact minimum distortion found byReluplex in small MNIST networks while our algorithms are more than 10,000times faster; (2) our methods deliver similar quality of bounds (the gap iswithin 35% and usually around 10%; sometimes our bounds are even better) forlarger networks compared to the methods based on solving linear programmingproblems but our algorithms are 33-14,000 times faster; (3) our method iscapable of solving large MNIST and CIFAR networks up to 7 layers with more than10,000 neurons within tens of seconds on a single CPU core.  In addition, we show that, in fact, there is no polynomial time algorithmthat can approximately find the minimum $\\ell_1$ adversarial distortion of aReLU network with a $0.99\\ln n$ approximation ratio unless$\\mathsf{NP}$=$\\mathsf{P}$, where $n$ is the number of neurons in the network."^^schema:Text ;
    schema:author "Cho-Jui Hsieh"^^schema:Person,
        "Duane Boning"^^schema:Person,
        "Hongge Chen"^^schema:Person,
        "Huan Zhang"^^schema:Person,
        "Inderjit S. Dhillon"^^schema:Person,
        "Luca Daniel"^^schema:Person,
        "Tsui-Wei Weng"^^schema:Person,
        "Zhao Song"^^schema:Person ;
    schema:commentCount "175"^^schema:Integer ;
    schema:dateModified "2018-10-02T08:25:08Z"^^schema:DateTime ;
    schema:datePublished "2018-04-25T17:47:56Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Fast Computation of Certified Robustness for ReLU Networks"^^schema:Text ;
    schema:publisher "ICML, 5273-5282"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.09699v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13154362274812885800&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<269> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning has proven itself as a successful set of models for learninguseful semantic representations of data. These, however, are mostly implicitlylearned as part of a classification task. In this paper we propose the tripletnetwork model, which aims to learn useful representations by distancecomparisons. A similar model was defined by Wang et al. (2014), tailor made forlearning a ranking for image information retrieval. Here we demonstrate usingvarious datasets that our model learns a better representation than that of itsimmediate competitor, the Siamese network. We also discuss future possibleusage as a framework for unsupervised learning."^^schema:Text ;
    schema:author "Elad Hoffer"^^schema:Person,
        "Nir Ailon"^^schema:Person ;
    schema:commentCount "734"^^schema:Integer ;
    schema:dateModified "2018-12-04T15:35:35Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T07:34:50Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep metric learning using Triplet network"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6622v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3566033986180947389&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<27> a schema:ScholarlyArticle ;
    schema:abstract "We propose a deep neural network for the prediction of future frames innatural video sequences. To effectively handle complex evolution of pixels invideos, we propose to decompose the motion and content, two key componentsgenerating dynamics in videos. Our model is built upon the Encoder-DecoderConvolutional Neural Network and Convolutional LSTM for pixel-level prediction,which independently capture the spatial layout of an image and thecorresponding temporal dynamics. By independently modeling motion and content,predicting the next frame reduces to converting the extracted content featuresinto the next frame content by the identified motion features, which simplifiesthe task of prediction. Our model is end-to-end trainable over multiple timesteps, and naturally learns to decompose motion and content without separatetraining. We evaluate the proposed network architecture on human activityvideos using KTH, Weizmann action, and UCF-101 datasets. We showstate-of-the-art performance in comparison to recent approaches. To the best ofour knowledge, this is the first end-to-end trainable network architecture withmotion and content separation to model the spatiotemporal dynamics forpixel-level future prediction in natural videos."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Jimei Yang"^^schema:Person,
        "Ruben Villegas"^^schema:Person,
        "Seunghoon Hong"^^schema:Person,
        "Xunyu Lin"^^schema:Person ;
    schema:commentCount "252"^^schema:Integer ;
    schema:dateModified "2018-01-08T01:21:32Z"^^schema:DateTime ;
    schema:datePublished "2017-06-25T04:18:12Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Decomposing Motion and Content for Natural Video Sequence Prediction"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.08033v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10892353807026411567&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<270> a schema:ScholarlyArticle ;
    schema:abstract "Current neural network-based classifiers are susceptible to adversarialexamples even in the black-box setting, where the attacker only has queryaccess to the model. In practice, the threat model for real-world systems isoften more restrictive than the typical black-box model where the adversary canobserve the full output of the network on arbitrarily many chosen inputs. Wedefine three realistic threat models that more accurately characterize manyreal-world classifiers: the query-limited setting, the partial-informationsetting, and the label-only setting. We develop new attacks that foolclassifiers under these more restrictive threat models, where previous methodswould be impractical or ineffective. We demonstrate that our methods areeffective against an ImageNet classifier under our proposed threat models. Wealso demonstrate a targeted black-box attack against a commercial classifier,overcoming the challenges of limited query access, partial information, andother practical issues to break the Google Cloud Vision API."^^schema:Text ;
    schema:author "Andrew Ilyas"^^schema:Person,
        "Anish Athalye"^^schema:Person,
        "Jessy Lin"^^schema:Person,
        "Logan Engstrom"^^schema:Person ;
    schema:commentCount "237"^^schema:Integer ;
    schema:dateModified "2018-07-11T13:51:00Z"^^schema:DateTime ;
    schema:datePublished "2018-04-23T17:46:34Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Black-box Adversarial Attacks with Limited Queries and Information"^^schema:Text ;
    schema:publisher "ICML, 2142-2151"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.08598v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15556405409493863238&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<271> a schema:ScholarlyArticle ;
    schema:abstract "We show the existence of a Locality-Sensitive Hashing (LSH) family for theangular distance that yields an approximate Near Neighbor Search algorithm withthe asymptotically optimal running time exponent. Unlike earlier algorithmswith this property (e.g., Spherical LSH [Andoni, Indyk, Nguyen, Razenshteyn2014], [Andoni, Razenshteyn 2015]), our algorithm is also practical, improvingupon the well-studied hyperplane LSH [Charikar, 2002] in practice. We alsointroduce a multiprobe version of this algorithm, and conduct experimentalevaluation on real and synthetic data sets.  We complement the above positive results with a fine-grained lower bound forthe quality of any LSH family for angular distance. Our lower bound impliesthat the above LSH family exhibits a trade-off between evaluation time andquality that is close to optimal for a natural class of LSH functions."^^schema:Text ;
    schema:author "Alexandr Andoni"^^schema:Person,
        "Ilya Razenshteyn"^^schema:Person,
        "Ludwig Schmidt"^^schema:Person,
        "Piotr Indyk"^^schema:Person,
        "Thijs Laarhoven"^^schema:Person ;
    schema:commentCount "258"^^schema:Integer ;
    schema:dateModified "2015-09-09T19:24:33Z"^^schema:DateTime ;
    schema:datePublished "2015-09-09T19:24:33Z"^^schema:DateTime ;
    schema:genre "cs.CG"^^schema:Text,
        "cs.DS"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Practical and Optimal LSH for Angular Distance"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.02897v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11203696302950509806&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<272> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we present a new way of predicting the performance of areinforcement learning policy given historical data that may have beengenerated by a different policy. The ability to evaluate a policy fromhistorical data is important for applications where the deployment of a badpolicy can be dangerous or costly. We show empirically that our algorithmproduces estimates that often have orders of magnitude lower mean squared errorthan existing methods---it makes more efficient use of the available data. Ournew estimator is based on two advances: an extension of the doubly robustestimator (Jiang and Li, 2015), and a new way to mix between model basedestimates and importance sampling based estimates."^^schema:Text ;
    schema:author "Emma Brunskill"^^schema:Person,
        "Philip S. Thomas"^^schema:Person ;
    schema:commentCount "184"^^schema:Integer ;
    schema:dateModified "2016-04-04T15:56:52Z"^^schema:DateTime ;
    schema:datePublished "2016-04-04T15:56:52Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 2139-2148"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1604.00923v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6145775850954387286&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<273> a schema:ScholarlyArticle ;
    schema:abstract "Three-dimensional geometric data offer an excellent domain for studyingrepresentation learning and generative modeling. In this paper, we look atgeometric data represented as point clouds. We introduce a deep AutoEncoder(AE) network with state-of-the-art reconstruction quality and generalizationability. The learned representations outperform existing methods on 3Drecognition tasks and enable shape editing via simple algebraic manipulations,such as semantic part editing, shape analogies and shape interpolation, as wellas shape completion. We perform a thorough study of different generative modelsincluding GANs operating on the raw point clouds, significantly improved GANstrained in the fixed latent space of our AEs, and Gaussian Mixture Models(GMMs). To quantitatively evaluate generative models we introduce measures ofsample fidelity and diversity based on matchings between sets of point clouds.Interestingly, our evaluation of generalization, fidelity and diversity revealsthat GMMs trained in the latent space of our AEs yield the best resultsoverall."^^schema:Text ;
    schema:author "Ioannis Mitliagkas"^^schema:Person,
        "Leonidas Guibas"^^schema:Person,
        "Olga Diamanti"^^schema:Person,
        "Panos Achlioptas"^^schema:Person ;
    schema:commentCount "224"^^schema:Integer ;
    schema:dateModified "2018-06-12T04:27:00Z"^^schema:DateTime ;
    schema:datePublished "2017-07-08T03:44:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Representations and Generative Models for 3D Point Clouds"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.02392v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12802077524133497194&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<274> a schema:ScholarlyArticle ;
    schema:abstract "The lack of reliable data in developing countries is a major obstacle tosustainable development, food security, and disaster relief. Poverty data, forexample, is typically scarce, sparse in coverage, and labor-intensive toobtain. Remote sensing data such as high-resolution satellite imagery, on theother hand, is becoming increasingly available and inexpensive. Unfortunately,such data is highly unstructured and currently no techniques exist toautomatically extract useful insights to inform policy decisions and helpdirect humanitarian efforts. We propose a novel machine learning approach toextract large-scale socioeconomic indicators from high-resolution satelliteimagery. The main challenge is that training data is very scarce, making itdifficult to apply modern techniques such as Convolutional Neural Networks(CNN). We therefore propose a transfer learning approach where nighttime lightintensities are used as a data-rich proxy. We train a fully convolutional CNNmodel to predict nighttime lights from daytime imagery, simultaneously learningfeatures that are useful for poverty prediction. The model learns filtersidentifying different terrains and man-made structures, including roads,buildings, and farmlands, without any supervision beyond nighttime lights. Wedemonstrate that these learned features are highly informative for povertymapping, even approaching the predictive performance of survey data collectedin the field."^^schema:Text ;
    schema:author "David Lobell"^^schema:Person,
        "Marshall Burke"^^schema:Person,
        "Michael Xie"^^schema:Person,
        "Neal Jean"^^schema:Person,
        "Stefano Ermon"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:dateModified "2016-02-27T23:21:48Z"^^schema:DateTime ;
    schema:datePublished "2015-10-01T03:04:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.CY"^^schema:Text ;
    schema:headline "Transfer Learning from Deep Features for Remote Sensing and Poverty  Mapping"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.00098v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17072828246968526595&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<275> a schema:ScholarlyArticle ;
    schema:abstract "The expressive power of neural networks is important for understanding deeplearning. Most existing works consider this problem from the view of the depthof a network. In this paper, we study how width affects the expressiveness ofneural networks. Classical results state that depth-bounded (e.g. depth-$2$)networks with suitable activation functions are universal approximators. Weshow a universal approximation theorem for width-bounded ReLU networks:width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universalapproximators. Moreover, except for a measure zero set, all functions cannot beapproximated by width-$n$ ReLU networks, which exhibits a phase transition.Several recent works demonstrate the benefits of depth by proving thedepth-efficiency of neural networks. That is, there are classes of deepnetworks which cannot be realized by any shallow network whose size is no morethan an exponential bound. Here we pose the dual question on thewidth-efficiency of ReLU networks: Are there wide networks that cannot berealized by narrow networks whose size is not substantially larger? We showthat there exist classes of wide networks which cannot be realized by anynarrow network whose depth is no more than a polynomial bound. On the otherhand, we demonstrate by extensive experiments that narrow networks whose sizeexceed the polynomial bound by a constant factor can approximate wide andshallow network with high accuracy. Our results provide more comprehensiveevidence that depth is more effective than width for the expressiveness of ReLUnetworks."^^schema:Text ;
    schema:author "Feicheng Wang"^^schema:Person,
        "Hongming Pu"^^schema:Person,
        "Liwei Wang"^^schema:Person,
        "Zhiqiang Hu"^^schema:Person,
        "Zhou Lu"^^schema:Person ;
    schema:commentCount "211"^^schema:Integer ;
    schema:dateModified "2017-11-01T08:50:32Z"^^schema:DateTime ;
    schema:datePublished "2017-09-08T05:00:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "The Expressive Power of Neural Networks: A View from the Width"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.02540v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11989002681809936407&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<276> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of designing models for machine learning tasks definedon \\emph{sets}. In contrast to traditional approach of operating on fixeddimensional vectors, we consider objective functions defined on sets that areinvariant to permutations. Such problems are widespread, ranging fromestimation of population statistics \\cite{poczos13aistats}, to anomalydetection in piezometer data of embankment dams \\cite{Jung15Exploration}, tocosmology \\cite{Ntampaka16Dynamical,Ravanbakhsh16ICML1}. Our main theoremcharacterizes the permutation invariant functions and provides a family offunctions to which any permutation invariant objective function must belong.This family of functions has a special structure which enables us to design adeep network architecture that can operate on sets and which can be deployed ona variety of scenarios including both unsupervised and supervised learningtasks. We also derive the necessary and sufficient conditions for permutationequivariance in deep models. We demonstrate the applicability of our method onpopulation statistic estimation, point cloud classification, set expansion, andoutlier detection."^^schema:Text ;
    schema:author "Alexander Smola"^^schema:Person,
        "Barnabas Poczos"^^schema:Person,
        "Manzil Zaheer"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Satwik Kottur"^^schema:Person,
        "Siamak Ravanbakhsh"^^schema:Person ;
    schema:commentCount "535"^^schema:Integer ;
    schema:dateModified "2018-04-14T18:54:19Z"^^schema:DateTime ;
    schema:datePublished "2017-03-10T21:02:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Sets"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.06114v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2295404778383262980&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<277> a schema:ScholarlyArticle ;
    schema:abstract "We develop a first line of attack for solving programming competition-styleproblems from input-output examples using deep learning. The approach is totrain a neural network to predict properties of the program that generated theoutputs from the inputs. We use the neural network's predictions to augmentsearch techniques from the programming languages community, includingenumerative search and an SMT-based solver. Empirically, we show that ourapproach leads to an order of magnitude speedup over the strong non-augmentedbaselines and a Recurrent Neural Network approach, and that we are able tosolve problems of difficulty comparable to the simplest problems on programmingcompetition websites."^^schema:Text ;
    schema:author "Alexander L. Gaunt"^^schema:Person,
        "Daniel Tarlow"^^schema:Person,
        "Marc Brockschmidt"^^schema:Person,
        "Matej Balog"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person ;
    schema:commentCount "248"^^schema:Integer ;
    schema:dateModified "2017-03-08T11:50:33Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T11:09:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "DeepCoder: Learning to Write Programs"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01989v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14663434925594619820&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<278> a schema:ScholarlyArticle ;
    schema:abstract "For many applications of reinforcement learning it can be more convenient tospecify both a reward function and constraints, rather than trying to designbehavior through the reward function. For example, systems that physicallyinteract with or around humans should satisfy safety constraints. Recentadvances in policy search algorithms (Mnih et al., 2016, Schulman et al., 2015,Lillicrap et al., 2016, Levine et al., 2016) have enabled new capabilities inhigh-dimensional control, but do not consider the constrained setting.  We propose Constrained Policy Optimization (CPO), the first general-purposepolicy search algorithm for constrained reinforcement learning with guaranteesfor near-constraint satisfaction at each iteration. Our method allows us totrain neural network policies for high-dimensional control while makingguarantees about policy behavior all throughout training. Our guarantees arebased on a new theoretical result, which is of independent interest: we prove abound relating the expected returns of two policies to an average divergencebetween them. We demonstrate the effectiveness of our approach on simulatedrobot locomotion tasks where the agent must satisfy constraints motivated bysafety."^^schema:Text ;
    schema:author "Aviv Tamar"^^schema:Person,
        "David Held"^^schema:Person,
        "Joshua Achiam"^^schema:Person,
        "Pieter Abbeel"^^schema:Person ;
    schema:commentCount "227"^^schema:Integer ;
    schema:dateModified "2017-05-30T10:07:31Z"^^schema:DateTime ;
    schema:datePublished "2017-05-30T10:07:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Constrained Policy Optimization"^^schema:Text ;
    schema:publisher "ICML, 22-31"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10528v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6114366704163518185&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<279> a schema:ScholarlyArticle ;
    schema:abstract "Most state-of-the-art scene text detection algorithms are deep learning basedmethods that depend on bounding box regression and perform at least two kindsof predictions: text/non-text classification and location regression.Regression plays a key role in the acquisition of bounding boxes in thesemethods, but it is not indispensable because text/non-text prediction can alsobe considered as a kind of semantic segmentation that contains full locationinformation in itself. However, text instances in scene images often lie veryclose to each other, making them very difficult to separate via semanticsegmentation. Therefore, instance segmentation is needed to address thisproblem. In this paper, PixelLink, a novel scene text detection algorithm basedon instance segmentation, is proposed. Text instances are first segmented outby linking pixels within the same instance together. Text bounding boxes arethen extracted directly from the segmentation result without locationregression. Experiments show that, compared with regression-based methods,PixelLink can achieve better or comparable performance on several benchmarks,while requiring many fewer training iterations and less training data."^^schema:Text ;
    schema:author "Dan Deng"^^schema:Person,
        "Deng Cai"^^schema:Person,
        "Haifeng Liu"^^schema:Person,
        "Xuelong Li"^^schema:Person ;
    schema:commentCount "170"^^schema:Integer ;
    schema:dateModified "2018-01-04T11:48:21Z"^^schema:DateTime ;
    schema:datePublished "2018-01-04T11:48:21Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "PixelLink: Detecting Scene Text via Instance Segmentation"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.01315v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5813094506011573938&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<28> a schema:ScholarlyArticle ;
    schema:abstract "We propose a neural sequence-to-sequence model for direction following, atask that is essential to realizing effective autonomous agents. Ouralignment-based encoder-decoder model with long short-term memory recurrentneural networks (LSTM-RNN) translates natural language instructions to actionsequences based upon a representation of the observable world state. Weintroduce a multi-level aligner that empowers our model to focus on sentence\"regions\" salient to the current world state by using multiple abstractions ofthe input sentence. In contrast to existing methods, our model uses nospecialized linguistic resources (e.g., parsers) or task-specific annotations(e.g., seed lexicons). It is therefore generalizable, yet still achieves thebest results reported to-date on a benchmark single-sentence dataset andcompetitive results for the limited-training multi-sentence setting. We analyzeour model through a series of ablations that elucidate the contributions of theprimary components of our model."^^schema:Text ;
    schema:author "Hongyuan Mei"^^schema:Person,
        "Matthew R. Walter"^^schema:Person,
        "Mohit Bansal"^^schema:Person ;
    schema:commentCount "135"^^schema:Integer ;
    schema:dateModified "2015-12-17T17:57:42Z"^^schema:DateTime ;
    schema:datePublished "2015-06-12T18:05:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to  Action Sequences"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.04089v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14897263214206352510&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<280> a schema:ScholarlyArticle ;
    schema:abstract "We examine gradient descent on unregularized logistic regression problems,with homogeneous linear predictors on linearly separable datasets. We show thepredictor converges to the direction of the max-margin (hard margin SVM)solution. The result also generalizes to other monotone decreasing lossfunctions with an infimum at infinity, to multi-class problems, and to traininga weight layer in a deep network in a certain restricted setting. Furthermore,we show this convergence is very slow, and only logarithmic in the convergenceof the loss itself. This can help explain the benefit of continuing to optimizethe logistic or cross-entropy loss even after the training error is zero andthe training loss is extremely small, and, as we show, even if the validationloss increases. Our methodology can also aid in understanding implicitregularization n more complex models and with other optimization methods."^^schema:Text ;
    schema:author "Daniel Soudry"^^schema:Person,
        "Elad Hoffer"^^schema:Person,
        "Mor Shpigel Nacson"^^schema:Person,
        "Nathan Srebro"^^schema:Person,
        "Suriya Gunasekar"^^schema:Person ;
    schema:commentCount "218"^^schema:Integer ;
    schema:dateModified "2018-12-28T10:51:36Z"^^schema:DateTime ;
    schema:datePublished "2017-10-27T21:47:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Implicit Bias of Gradient Descent on Separable Data"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.10345v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8363232294125339657&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<281> a schema:ScholarlyArticle ;
    schema:abstract "Autoregressive models are among the best performing neural densityestimators. We describe an approach for increasing the flexibility of anautoregressive model, based on modelling the random numbers that the model usesinternally when generating data. By constructing a stack of autoregressivemodels, each modelling the random numbers of the next model in the stack, weobtain a type of normalizing flow suitable for density estimation, which wecall Masked Autoregressive Flow. This type of flow is closely related toInverse Autoregressive Flow and is a generalization of Real NVP. MaskedAutoregressive Flow achieves state-of-the-art performance in a range ofgeneral-purpose density estimation tasks."^^schema:Text ;
    schema:author "George Papamakarios"^^schema:Person,
        "Iain Murray"^^schema:Person,
        "Theo Pavlakou"^^schema:Person ;
    schema:commentCount "288"^^schema:Integer ;
    schema:dateModified "2018-06-14T10:28:12Z"^^schema:DateTime ;
    schema:datePublished "2017-05-19T15:42:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Masked Autoregressive Flow for Density Estimation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.07057v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11200642106543542089&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<282> a schema:ScholarlyArticle ;
    schema:abstract "The key idea behind the unsupervised learning of disentangled representationsis that real-world data is generated by a few explanatory factors of variationwhich can be recovered by unsupervised learning algorithms. In this paper, weprovide a sober look at recent progress in the field and challenge some commonassumptions. We first theoretically show that the unsupervised learning ofdisentangled representations is fundamentally impossible without inductivebiases on both the models and the data. Then, we train more than 12000 modelscovering most prominent methods and evaluation metrics in a reproduciblelarge-scale experimental study on seven different data sets. We observe thatwhile the different methods successfully enforce properties ``encouraged'' bythe corresponding losses, well-disentangled models seemingly cannot beidentified without supervision. Furthermore, increased disentanglement does notseem to lead to a decreased sample complexity of learning for downstream tasks.Our results suggest that future work on disentanglement learning should beexplicit about the role of inductive biases and (implicit) supervision,investigate concrete benefits of enforcing disentanglement of the learnedrepresentations, and consider a reproducible experimental setup coveringseveral data sets."^^schema:Text ;
    schema:author "Bernhard Schölkopf"^^schema:Person,
        "Francesco Locatello"^^schema:Person,
        "Gunnar Rätsch"^^schema:Person,
        "Mario Lucic"^^schema:Person,
        "Olivier Bachem"^^schema:Person,
        "Stefan Bauer"^^schema:Person,
        "Sylvain Gelly"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:dateModified "2019-06-18T08:58:18Z"^^schema:DateTime ;
    schema:datePublished "2018-11-29T18:10:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Challenging Common Assumptions in the Unsupervised Learning of  Disentangled Representations"^^schema:Text ;
    schema:publisher "ICML, 4114-4124"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1811.12359v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15156765665179946120&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<283> a schema:ScholarlyArticle ;
    schema:abstract "The choice of approximate posterior distribution is one of the core problemsin variational inference. Most applications of variational inference employsimple families of posterior approximations in order to allow for efficientinference, focusing on mean-field or other simple structured approximations.This restriction has a significant impact on the quality of inferences madeusing variational methods. We introduce a new approach for specifying flexible,arbitrarily complex and scalable approximate posterior distributions. Ourapproximations are distributions constructed through a normalizing flow,whereby a simple initial density is transformed into a more complex one byapplying a sequence of invertible transformations until a desired level ofcomplexity is attained. We use this view of normalizing flows to developcategories of finite and infinitesimal flows and provide a unified view ofapproaches for constructing rich posterior approximations. We demonstrate thatthe theoretical advantages of having posteriors that better match the trueposterior, combined with the scalability of amortized variational approaches,provides a clear improvement in performance and applicability of variationalinference."^^schema:Text ;
    schema:author "Danilo Jimenez Rezende"^^schema:Person,
        "Shakir Mohamed"^^schema:Person ;
    schema:commentCount "988"^^schema:Integer ;
    schema:dateModified "2016-06-14T09:01:36Z"^^schema:DateTime ;
    schema:datePublished "2015-05-21T15:36:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Inference with Normalizing Flows"^^schema:Text ;
    schema:publisher "ICML, 1530-1538"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.05770v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6765826181105442087&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<284> a schema:ScholarlyArticle ;
    schema:abstract "Visual question answering (VQA) is challenging because it requires asimultaneous understanding of both visual content of images and textual contentof questions. To support the VQA task, we need to find good solutions for thefollowing three issues: 1) fine-grained feature representations for both theimage and the question; 2) multi-modal feature fusion that is able to capturethe complex interactions between multi-modal features; 3) automatic answerprediction that is able to consider the complex correlations between multiplediverse answers for the same question. For fine-grained image and questionrepresentations, a `co-attention' mechanism is developed by using a deep neuralnetwork architecture to jointly learn the attentions for both the image and thequestion, which can allow us to reduce the irrelevant features effectively andobtain more discriminative features for image and question representations. Formulti-modal feature fusion, a generalized Multi-modal Factorized High-orderpooling approach (MFH) is developed to achieve more effective fusion ofmulti-modal features by exploiting their correlations sufficiently, which canfurther result in superior VQA performance as compared with thestate-of-the-art approaches. For answer prediction, the KL (Kullback-Leibler)divergence is used as the loss function to achieve precise characterization ofthe complex correlations between multiple diverse answers with the same orsimilar meaning, which can allow us to achieve faster convergence rate andobtain slightly better accuracy on answer prediction. A deep neural networkarchitecture is designed to integrate all these aforementioned modules into aunified model for achieving superior VQA performance. With an ensemble of ourMFH models, we achieve the state-of-the-art performance on the large-scale VQAdatasets and win the runner-up in VQA Challenge 2017."^^schema:Text ;
    schema:author "Chenchao Xiang"^^schema:Person,
        "Dacheng Tao"^^schema:Person,
        "Jianping Fan"^^schema:Person,
        "Jun Yu"^^schema:Person,
        "Zhou Yu"^^schema:Person ;
    schema:commentCount "142"^^schema:Integer ;
    schema:dateModified "2019-05-16T04:16:57Z"^^schema:DateTime ;
    schema:datePublished "2017-08-10T09:09:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Beyond Bilinear: Generalized Multimodal Factorized High-order Pooling  for Visual Question Answering"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (12), 5947-5959"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.03619v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12743862933043798233&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<285> a schema:ScholarlyArticle ;
    schema:abstract "How can we explain the predictions of a black-box model? In this paper, weuse influence functions -- a classic technique from robust statistics -- totrace a model's prediction through the learning algorithm and back to itstraining data, thereby identifying training points most responsible for a givenprediction. To scale up influence functions to modern machine learningsettings, we develop a simple, efficient implementation that requires onlyoracle access to gradients and Hessian-vector products. We show that even onnon-convex and non-differentiable models where the theory breaks down,approximations to influence functions can still provide valuable information.On linear models and convolutional neural networks, we demonstrate thatinfluence functions are useful for multiple purposes: understanding modelbehavior, debugging models, detecting dataset errors, and even creatingvisually-indistinguishable training-set attacks."^^schema:Text ;
    schema:author "Pang Wei Koh"^^schema:Person,
        "Percy Liang"^^schema:Person ;
    schema:commentCount "715"^^schema:Integer ;
    schema:dateModified "2020-12-29T22:40:43Z"^^schema:DateTime ;
    schema:datePublished "2017-03-14T21:07:01Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Understanding Black-box Predictions via Influence Functions"^^schema:Text ;
    schema:publisher "ICML, 1885-1894"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.04730v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3459384850898992895&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<286> a schema:ScholarlyArticle ;
    schema:abstract "We reinterpret multiplicative noise in neural networks as auxiliary randomvariables that augment the approximate posterior in a variational setting forBayesian neural networks. We show that through this interpretation it is bothefficient and straightforward to improve the approximation by employingnormalizing flows while still allowing for local reparametrizations and atractable lower bound. In experiments we show that with this new approximationwe can significantly improve upon classical mean field for Bayesian neuralnetworks on both predictive accuracy as well as predictive uncertainty."^^schema:Text ;
    schema:author "Christos Louizos"^^schema:Person,
        "Max Welling"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:dateModified "2017-06-12T21:05:58Z"^^schema:DateTime ;
    schema:datePublished "2017-03-06T16:39:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multiplicative Normalizing Flows for Variational Bayesian Neural  Networks"^^schema:Text ;
    schema:publisher "ICML, 2218-2227"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01961v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1022009274958609654&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<287> a schema:ScholarlyArticle ;
    schema:abstract "Few-shot learning has become essential for producing models that generalizefrom few examples. In this work, we identify that metric scaling and metrictask conditioning are important to improve the performance of few-shotalgorithms. Our analysis reveals that simple metric scaling completely changesthe nature of few-shot algorithm parameter updates. Metric scaling providesimprovements up to 14% in accuracy for certain metrics on the mini-Imagenet5-way 5-shot classification task. We further propose a simple and effective wayof conditioning a learner on the task sample set, resulting in learning atask-dependent metric space. Moreover, we propose and empirically test apractical end-to-end optimization procedure based on auxiliary task co-trainingto learn a task-dependent metric space. The resulting few-shot learning modelbased on the task-dependent scaled metric achieves state of the art onmini-Imagenet. We confirm these results on another few-shot dataset that weintroduce in this paper based on CIFAR100. Our code is publicly available athttps://github.com/ElementAI/TADAM."^^schema:Text ;
    schema:author "Alexandre Lacoste"^^schema:Person,
        "Boris N. Oreshkin"^^schema:Person,
        "Pau Rodriguez"^^schema:Person ;
    schema:commentCount "202"^^schema:Integer ;
    schema:dateModified "2019-01-25T18:47:30Z"^^schema:DateTime ;
    schema:datePublished "2018-05-23T20:17:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "TADAM: Task dependent adaptive metric for improved few-shot learning"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.10123v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15025574335418226526&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<288> a schema:ScholarlyArticle ;
    schema:abstract "We consider incorporating topic information into the sequence-to-sequenceframework to generate informative and interesting responses for chatbots. Tothis end, we propose a topic aware sequence-to-sequence (TA-Seq2Seq) model. Themodel utilizes topics to simulate prior knowledge of human that guides them toform informative and interesting responses in conversation, and leverages thetopic information in generation by a joint attention mechanism and a biasedgeneration probability. The joint attention mechanism summarizes the hiddenvectors of an input message as context vectors by message attention,synthesizes topic vectors by topic attention from the topic words of themessage obtained from a pre-trained LDA model, and let these vectors jointlyaffect the generation of words in decoding. To increase the possibility oftopic words appearing in responses, the model modifies the generationprobability of topic words by adding an extra probability item to bias theoverall distribution. Empirical study on both automatic evaluation metrics andhuman annotations shows that TA-Seq2Seq can generate more informative andinteresting responses, and significantly outperform the-state-of-the-artresponse generation models."^^schema:Text ;
    schema:author "Chen Xing"^^schema:Person,
        "Jie Liu"^^schema:Person,
        "Ming Zhou"^^schema:Person,
        "Wei Wu"^^schema:Person,
        "Wei-Ying Ma"^^schema:Person,
        "Yalou Huang"^^schema:Person,
        "Yu Wu"^^schema:Person ;
    schema:commentCount "233"^^schema:Integer ;
    schema:dateModified "2016-09-19T02:09:13Z"^^schema:DateTime ;
    schema:datePublished "2016-06-21T05:47:59Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Topic Aware Neural Response Generation"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.08340v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17700327900700043147&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<289> a schema:ScholarlyArticle ;
    schema:abstract "This work explores conditional image generation with a new image densitymodel based on the PixelCNN architecture. The model can be conditioned on anyvector, including descriptive labels or tags, or latent embeddings created byother networks. When conditioned on class labels from the ImageNet database,the model is able to generate diverse, realistic scenes representing distinctanimals, objects, landscapes and structures. When conditioned on an embeddingproduced by a convolutional network given a single image of an unseen face, itgenerates a variety of new portraits of the same person with different facialexpressions, poses and lighting conditions. We also show that conditionalPixelCNN can serve as a powerful decoder in an image autoencoder. Additionally,the gated convolutional layers in the proposed model improve the log-likelihoodof PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet,with greatly reduced computational cost."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Alex Graves"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Lasse Espeholt"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person,
        "Oriol Vinyals"^^schema:Person ;
    schema:commentCount "991"^^schema:Integer ;
    schema:dateModified "2016-06-18T15:44:24Z"^^schema:DateTime ;
    schema:datePublished "2016-06-16T19:40:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Conditional Image Generation with PixelCNN Decoders"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.05328v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8587297613215686995&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<29> a schema:ScholarlyArticle ;
    schema:abstract "The deep reinforcement learning community has made several independentimprovements to the DQN algorithm. However, it is unclear which of theseextensions are complementary and can be fruitfully combined. This paperexamines six extensions to the DQN algorithm and empirically studies theircombination. Our experiments show that the combination providesstate-of-the-art performance on the Atari 2600 benchmark, both in terms of dataefficiency and final performance. We also provide results from a detailedablation study that shows the contribution of each component to overallperformance."^^schema:Text ;
    schema:author "Bilal Piot"^^schema:Person,
        "Dan Horgan"^^schema:Person,
        "David Silver"^^schema:Person,
        "Georg Ostrovski"^^schema:Person,
        "Hado van Hasselt"^^schema:Person,
        "Joseph Modayil"^^schema:Person,
        "Matteo Hessel"^^schema:Person,
        "Mohammad Azar"^^schema:Person,
        "Tom Schaul"^^schema:Person,
        "Will Dabney"^^schema:Person ;
    schema:commentCount "570"^^schema:Integer ;
    schema:dateModified "2017-10-06T07:45:46Z"^^schema:DateTime ;
    schema:datePublished "2017-10-06T07:45:46Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Rainbow: Combining Improvements in Deep Reinforcement Learning"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.02298v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4556984714514611653&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<290> a schema:ScholarlyArticle ;
    schema:abstract "Restart techniques are common in gradient-free optimization to deal withmultimodal functions. Partial warm restarts are also gaining popularity ingradient-based optimization to improve the rate of convergence in acceleratedgradient schemes to deal with ill-conditioned functions. In this paper, wepropose a simple warm restart technique for stochastic gradient descent toimprove its anytime performance when training deep neural networks. Weempirically study its performance on the CIFAR-10 and CIFAR-100 datasets, wherewe demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively.We also demonstrate its advantages on a dataset of EEG recordings and on adownsampled version of the ImageNet dataset. Our source code is available athttps://github.com/loshchil/SGDR"^^schema:Text ;
    schema:author "Frank Hutter"^^schema:Person,
        "Ilya Loshchilov"^^schema:Person ;
    schema:commentCount "869"^^schema:Integer ;
    schema:dateModified "2017-05-03T16:28:09Z"^^schema:DateTime ;
    schema:datePublished "2016-08-13T13:46:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "SGDR: Stochastic Gradient Descent with Warm Restarts"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.03983v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9496349859848656559&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<291> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a framework to tackle combinatorial optimization problemsusing neural networks and reinforcement learning. We focus on the travelingsalesman problem (TSP) and train a recurrent network that, given a set of citycoordinates, predicts a distribution over different city permutations. Usingnegative tour length as the reward signal, we optimize the parameters of therecurrent network using a policy gradient method. We compare learning thenetwork parameters on a set of training graphs against learning them onindividual test graphs. Despite the computational expense, without muchengineering and heuristic designing, Neural Combinatorial Optimization achievesclose to optimal results on 2D Euclidean graphs with up to 100 nodes. Appliedto the KnapSack, another NP-hard problem, the same method obtains optimalsolutions for instances with up to 200 items."^^schema:Text ;
    schema:author "Hieu Pham"^^schema:Person,
        "Irwan Bello"^^schema:Person,
        "Mohammad Norouzi"^^schema:Person,
        "Quoc V. Le"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "311"^^schema:Integer ;
    schema:dateModified "2017-01-12T23:55:36Z"^^schema:DateTime ;
    schema:datePublished "2016-11-29T23:22:39Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Combinatorial Optimization with Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.09940v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13936411244086798707&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<292> a schema:ScholarlyArticle ;
    schema:abstract "Many tasks in AI require the collaboration of multiple agents. Typically, thecommunication protocol between agents is manually specified and not alteredduring training. In this paper we explore a simple neural model, calledCommNet, that uses continuous communication for fully cooperative tasks. Themodel consists of multiple agents and the communication between them is learnedalongside their policy. We apply this model to a diverse set of tasks,demonstrating the ability of the agents to learn to communicate amongstthemselves, yielding improved performance over non-communicative agents andbaselines. In some cases, it is possible to interpret the language devised bythe agents, revealing simple but effective strategies for solving the task athand."^^schema:Text ;
    schema:author "Arthur Szlam"^^schema:Person,
        "Rob Fergus"^^schema:Person,
        "Sainbayar Sukhbaatar"^^schema:Person ;
    schema:commentCount "422"^^schema:Integer ;
    schema:dateModified "2016-10-31T17:29:58Z"^^schema:DateTime ;
    schema:datePublished "2016-05-25T05:33:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Multiagent Communication with Backpropagation"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07736v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5233243549252503864&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<293> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose to equip Generative Adversarial Networks with theability to produce direct energy estimates for samples.Specifically, we proposea flexible adversarial training framework, and prove this framework not onlyensures the generator converges to the true data distribution, but also enablesthe discriminator to retain the density information at the global optimal. Wederive the analytic form of the induced solution, and analyze the properties.In order to make the proposed framework trainable in practice, we introduce twoeffective approximation techniques. Empirically, the experiment results closelymatch our theoretical analysis, verifying the discriminator is able to recoverthe energy of data distribution."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Amjad Almahairi"^^schema:Person,
        "Eduard Hovy"^^schema:Person,
        "Philip Bachman"^^schema:Person,
        "Zihang Dai"^^schema:Person ;
    schema:commentCount "770"^^schema:Integer ;
    schema:dateModified "2017-02-24T01:38:09Z"^^schema:DateTime ;
    schema:datePublished "2017-02-06T16:30:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Calibrating Energy-based Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.01691v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15426746467469595309&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<294> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose novel strategies for neutral vector variabledecorrelation. Two fundamental invertible transformations, namely serialnonlinear transformation and parallel nonlinear transformation, are proposed tocarry out the decorrelation. For a neutral vector variable, which is notmultivariate Gaussian distributed, the conventional principal componentanalysis (PCA) cannot yield mutually independent scalar variables. With the twoproposed transformations, a highly negatively correlated neutral vector can betransformed to a set of mutually independent scalar variables with the samedegrees of freedom. We also evaluate the decorrelation performances for thevectors generated from a single Dirichlet distribution and a mixture ofDirichlet distributions. The mutual independence is verified with the distancecorrelation measurement. The advantages of the proposed decorrelationstrategies are intensively studied and demonstrated with synthesized data andpractical application evaluations."^^schema:Text ;
    schema:author "Arne Leijon"^^schema:Person,
        "Jing-Hao Xue"^^schema:Person,
        "Jun Guo"^^schema:Person,
        "Zhanyu Ma"^^schema:Person,
        "Zhen Yang"^^schema:Person,
        "Zheng-Hua Tan"^^schema:Person ;
    schema:commentCount "115"^^schema:Integer ;
    schema:dateModified "2017-05-30T09:53:11Z"^^schema:DateTime ;
    schema:datePublished "2017-05-30T09:53:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Decorrelation of Neutral Vector Variables: Theory and Applications"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (1), 129-143"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10524v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8968952400382235129&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<295> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised learning of probabilistic models is a central yet challengingproblem in machine learning. Specifically, designing models with tractablelearning, sampling, inference and evaluation is crucial in solving this task.We extend the space of such models using real-valued non-volume preserving(real NVP) transformations, a set of powerful invertible and learnabletransformations, resulting in an unsupervised learning algorithm with exactlog-likelihood computation, exact sampling, exact inference of latentvariables, and an interpretable latent space. We demonstrate its ability tomodel natural images on four datasets through sampling, log-likelihoodevaluation and latent variable manipulations."^^schema:Text ;
    schema:author "Jascha Sohl-Dickstein"^^schema:Person,
        "Laurent Dinh"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "737"^^schema:Integer ;
    schema:dateModified "2017-02-27T23:21:10Z"^^schema:DateTime ;
    schema:datePublished "2016-05-27T21:24:32Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Density estimation using Real NVP"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.08803v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6875639475985157714&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<296> a schema:ScholarlyArticle ;
    schema:abstract "Neural architecture search (NAS) has a great impact by automaticallydesigning effective neural network architectures. However, the prohibitivecomputational demand of conventional NAS algorithms (e.g. $10^4$ GPU hours)makes it difficult to \\emph{directly} search the architectures on large-scaletasks (e.g. ImageNet). Differentiable NAS can reduce the cost of GPU hours viaa continuous representation of network architecture but suffers from the highGPU memory consumption issue (grow linearly w.r.t. candidate set size). As aresult, they need to utilize~\\emph{proxy} tasks, such as training on a smallerdataset, or learning with only a few blocks, or training just for a few epochs.These architectures optimized on proxy tasks are not guaranteed to be optimalon the target task. In this paper, we present \\emph{ProxylessNAS} that can\\emph{directly} learn the architectures for large-scale target tasks and targethardware platforms. We address the high memory consumption issue ofdifferentiable NAS and reduce the computational cost (GPU hours and GPU memory)to the same level of regular training while still allowing a large candidateset. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness ofdirectness and specialization. On CIFAR-10, our model achieves 2.08\\% testerror with only 5.7M parameters, better than the previous state-of-the-artarchitecture AmoebaNet-B, while using 6$\\times$ fewer parameters. On ImageNet,our model achieves 3.1\\% better top-1 accuracy than MobileNetV2, while being1.2$\\times$ faster with measured GPU latency. We also apply ProxylessNAS tospecialize neural architectures for hardware with direct hardware metrics (e.g.latency) and provide insights for efficient CNN architecture design."^^schema:Text ;
    schema:author "Han Cai"^^schema:Person,
        "Ligeng Zhu"^^schema:Person,
        "Song Han"^^schema:Person ;
    schema:commentCount "355"^^schema:Integer ;
    schema:dateModified "2019-02-23T01:36:47Z"^^schema:DateTime ;
    schema:datePublished "2018-12-02T05:29:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "ProxylessNAS: Direct Neural Architecture Search on Target Task and  Hardware"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1812.00332v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18033301425061747520&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<297> a schema:ScholarlyArticle ;
    schema:abstract "In recent years increasingly complex architectures for deep convolutionnetworks (DCNs) have been proposed to boost the performance on imagerecognition tasks. However, the gains in performance have come at a cost ofsubstantial increase in computation and model storage resources. Fixed pointimplementation of DCNs has the potential to alleviate some of thesecomplexities and facilitate potential deployment on embedded hardware. In thispaper, we propose a quantizer design for fixed point implementation of DCNs. Weformulate and solve an optimization problem to identify optimal fixed pointbit-width allocation across DCN layers. Our experiments show that in comparisonto equal bit-width settings, the fixed point DCNs with optimized bit widthallocation offer &gt;20% reduction in the model size without any loss in accuracyon CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhancethe accuracy of fixed point DCNs beyond that of the original floating pointmodel. In doing so, we report a new state-of-the-art fixed point performance of6.78% error-rate on CIFAR-10 benchmark."^^schema:Text ;
    schema:author "Darryl D. Lin"^^schema:Person,
        "Sachin S. Talathi"^^schema:Person,
        "V. Sreekanth Annapureddy"^^schema:Person ;
    schema:commentCount "407"^^schema:Integer ;
    schema:dateModified "2016-06-02T06:21:42Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T21:37:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Fixed Point Quantization of Deep Convolutional Networks"^^schema:Text ;
    schema:publisher "ICML, 2849-2858"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06393v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14355326039529078697&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<298> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks are widely used in machine learning applications.However, the deployment of large neural networks models can be difficult todeploy on mobile devices with limited power budgets. To solve this problem, wepropose Trained Ternary Quantization (TTQ), a method that can reduce theprecision of weights in neural networks to ternary values. This method has verylittle accuracy degradation and can even improve the accuracy of some models(32, 44, 56-layer ResNet) on CIFAR-10 and AlexNet on ImageNet. And our AlexNetmodel is trained from scratch, which means it's as easy as to train normal fullprecision model. We highlight our trained quantization method that can learnboth ternary values and ternary assignment. During inference, only ternaryvalues (2-bit weights) and scaling factors are needed, therefore our models arenearly 16x smaller than full-precision models. Our ternary models can also beviewed as sparse binary weight networks, which can potentially be acceleratedwith custom circuit. Experiments on CIFAR-10 show that the ternary modelsobtained by trained quantization method outperform full-precision models ofResNet-32,44,56 by 0.04%, 0.16%, 0.36%, respectively. On ImageNet, our modeloutperforms full-precision AlexNet model by 0.3% of Top-1 accuracy andoutperforms previous ternary models by 3%."^^schema:Text ;
    schema:author "Chenzhuo Zhu"^^schema:Person,
        "Huizi Mao"^^schema:Person,
        "Song Han"^^schema:Person,
        "William J. Dally"^^schema:Person ;
    schema:commentCount "520"^^schema:Integer ;
    schema:dateModified "2017-02-23T06:52:28Z"^^schema:DateTime ;
    schema:datePublished "2016-12-04T05:00:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Trained Ternary Quantization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.01064v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12956735651240747861&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<299> a schema:ScholarlyArticle ;
    schema:abstract "The design of good heuristics or approximation algorithms for NP-hardcombinatorial optimization problems often requires significant specializedknowledge and trial-and-error. Can we automate this challenging, tediousprocess, and learn the algorithms instead? In many real-world applications, itis typically the case that the same optimization problem is solved again andagain on a regular basis, maintaining the same problem structure but differingin the data. This provides an opportunity for learning heuristic algorithmsthat exploit the structure of such recurring problems. In this paper, wepropose a unique combination of reinforcement learning and graph embedding toaddress this challenge. The learned greedy policy behaves like a meta-algorithmthat incrementally constructs a solution, and the action is determined by theoutput of a graph embedding network capturing the current state of thesolution. We show that our framework can be applied to a diverse range ofoptimization problems over graphs, and learns effective algorithms for theMinimum Vertex Cover, Maximum Cut and Traveling Salesman problems."^^schema:Text ;
    schema:author "Bistra Dilkina"^^schema:Person,
        "Elias B. Khalil"^^schema:Person,
        "Hanjun Dai"^^schema:Person,
        "Le Song"^^schema:Person,
        "Yuyu Zhang"^^schema:Person ;
    schema:commentCount "305"^^schema:Integer ;
    schema:dateModified "2018-02-21T19:47:20Z"^^schema:DateTime ;
    schema:datePublished "2017-04-05T23:08:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Combinatorial Optimization Algorithms over Graphs"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.01665v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6935751850601868852&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<3> a schema:ScholarlyArticle ;
    schema:abstract "With rapid progress and significant successes in a wide spectrum ofapplications, deep learning is being applied in many safety-criticalenvironments. However, deep neural networks have been recently found vulnerableto well-designed input samples, called adversarial examples. Adversarialexamples are imperceptible to human but can easily fool deep neural networks inthe testing/deploying stage. The vulnerability to adversarial examples becomesone of the major risks for applying deep neural networks in safety-criticalenvironments. Therefore, attacks and defenses on adversarial examples drawgreat attention. In this paper, we review recent findings on adversarialexamples for deep neural networks, summarize the methods for generatingadversarial examples, and propose a taxonomy of these methods. Under thetaxonomy, applications for adversarial examples are investigated. We furtherelaborate on countermeasures for adversarial examples and explore thechallenges and the potential solutions."^^schema:Text ;
    schema:author "Pan He"^^schema:Person,
        "Qile Zhu"^^schema:Person,
        "Xiaolin Li"^^schema:Person,
        "Xiaoyong Yuan"^^schema:Person ;
    schema:commentCount "400"^^schema:Integer ;
    schema:dateModified "2018-07-07T02:32:57Z"^^schema:DateTime ;
    schema:datePublished "2017-12-19T18:44:07Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Examples: Attacks and Defenses for Deep Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 30 (9), 2805-2824"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.07107v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4187134806050974749&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<30> a schema:ScholarlyArticle ;
    schema:abstract "Sequential models achieve state-of-the-art results in audio, visual andtextual domains with respect to both estimating the data distribution andgenerating high-quality samples. Efficient sampling for this class of modelshas however remained an elusive problem. With a focus on text-to-speechsynthesis, we describe a set of general techniques for reducing sampling timewhile maintaining high output quality. We first describe a single-layerrecurrent neural network, the WaveRNN, with a dual softmax layer that matchesthe quality of the state-of-the-art WaveNet model. The compact form of thenetwork makes it possible to generate 24kHz 16-bit audio 4x faster than realtime on a GPU. Second, we apply a weight pruning technique to reduce the numberof weights in the WaveRNN. We find that, for a constant number of parameters,large sparse networks perform better than small dense networks and thisrelationship holds for sparsity levels beyond 96%. The small number of weightsin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobileCPU in real time. Finally, we propose a new generation scheme based onsubscaling that folds a long sequence into a batch of shorter sequences andallows one to generate multiple samples at once. The Subscale WaveRNN produces16 samples per step without loss of quality and offers an orthogonal method forincreasing sampling efficiency."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Edward Lockhart"^^schema:Person,
        "Erich Elsen"^^schema:Person,
        "Florian Stimberg"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person,
        "Norman Casagrande"^^schema:Person,
        "Sander Dieleman"^^schema:Person,
        "Seb Noury"^^schema:Person ;
    schema:commentCount "189"^^schema:Integer ;
    schema:dateModified "2018-06-25T19:45:25Z"^^schema:DateTime ;
    schema:datePublished "2018-02-23T08:20:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Efficient Neural Audio Synthesis"^^schema:Text ;
    schema:publisher "ICML, 2415-2424"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.08435v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14599728628710698803&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<300> a schema:ScholarlyArticle ;
    schema:abstract "Machine translation has recently achieved impressive performance thanks torecent advances in deep learning and the availability of large-scale parallelcorpora. There have been numerous attempts to extend these successes tolow-resource language pairs, yet requiring tens of thousands of parallelsentences. In this work, we take this research direction to the extreme andinvestigate whether it is possible to learn to translate even without anyparallel data. We propose a model that takes sentences from monolingual corporain two different languages and maps them into the same latent space. Bylearning to reconstruct in both languages from this shared feature space, themodel effectively learns to translate without using any labeled data. Wedemonstrate our model on two widely used datasets and two language pairs,reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-Frenchdatasets, without using even a single parallel sentence at training time."^^schema:Text ;
    schema:author "Alexis Conneau"^^schema:Person,
        "Guillaume Lample"^^schema:Person,
        "Ludovic Denoyer"^^schema:Person,
        "Marc'Aurelio Ranzato"^^schema:Person ;
    schema:commentCount "428"^^schema:Integer ;
    schema:dateModified "2018-04-13T13:30:28Z"^^schema:DateTime ;
    schema:datePublished "2017-10-31T18:31:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Unsupervised Machine Translation Using Monolingual Corpora Only"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00043v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=682955820897938264&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<301> a schema:ScholarlyArticle ;
    schema:abstract "This paper deals with the unsupervised domain adaptation problem, where onewants to estimate a prediction function $f$ in a given target domain withoutany labeled sample by exploiting the knowledge available from a source domainwhere labels are known. Our work makes the following assumption: there exists anon-linear transformation between the joint feature/label space distributionsof the two domain $\\mathcal{P}_s$ and $\\mathcal{P}_t$. We propose a solution ofthis problem with optimal transport, that allows to recover an estimated target$\\mathcal{P}^f_t=(X,f(X))$ by optimizing simultaneously the optimal couplingand $f$. We show that our method corresponds to the minimization of a bound onthe target error, and provide an efficient algorithmic solution, for whichconvergence is proved. The versatility of our approach, both in terms of classof hypothesis or loss functions is demonstrated with real world classificationand regression problems, for which we reach or surpass state-of-the-artresults."^^schema:Text ;
    schema:author "Alain Rakotomamonjy"^^schema:Person,
        "Amaury Habrard"^^schema:Person,
        "Nicolas Courty"^^schema:Person,
        "Rémi Flamary"^^schema:Person ;
    schema:commentCount "367"^^schema:Integer ;
    schema:dateModified "2017-10-22T12:16:35Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T16:34:41Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Joint Distribution Optimal Transportation for Domain Adaptation"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08848v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3838459407382849555&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<302> a schema:ScholarlyArticle ;
    schema:abstract "Machine comprehension (MC), answering a query about a given contextparagraph, requires modeling complex interactions between the context and thequery. Recently, attention mechanisms have been successfully extended to MC.Typically these methods use attention to focus on a small portion of thecontext and summarize it with a fixed-size vector, couple attentionstemporally, and/or often form a uni-directional attention. In this paper weintroduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stagehierarchical process that represents the context at different levels ofgranularity and uses bi-directional attention flow mechanism to obtain aquery-aware context representation without early summarization. Ourexperimental evaluations show that our model achieves the state-of-the-artresults in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail clozetest."^^schema:Text ;
    schema:author "Ali Farhadi"^^schema:Person,
        "Aniruddha Kembhavi"^^schema:Person,
        "Hannaneh Hajishirzi"^^schema:Person,
        "Minjoon Seo"^^schema:Person ;
    schema:commentCount "1032"^^schema:Integer ;
    schema:dateModified "2018-06-21T10:53:20Z"^^schema:DateTime ;
    schema:datePublished "2016-11-05T04:49:00Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Bidirectional Attention Flow for Machine Comprehension"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01603v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=199178676793208244&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<303> a schema:ScholarlyArticle ;
    schema:abstract "We present a framework for efficient inference in structured image modelsthat explicitly reason about objects. We achieve this by performingprobabilistic inference using a recurrent neural network that attends to sceneelements and processes them one at a time. Crucially, the model itself learnsto choose the appropriate number of inference steps. We use this scheme tolearn to perform inference in partially specified 2D models (variable-sizedvariational auto-encoders) and fully specified 3D models (probabilisticrenderers). We show that such models learn to identify multiple objects -counting, locating and classifying the elements of a scene - without anysupervision, e.g., decomposing 3D images with various numbers of objects in asingle forward pass of a neural network. We further show that the networksproduce accurate inferences when compared to supervised counterparts, and thattheir structure leads to improved generalization."^^schema:Text ;
    schema:author "David Szepesvari"^^schema:Person,
        "Geoffrey E. Hinton"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "S. M. Ali Eslami"^^schema:Person,
        "Theophane Weber"^^schema:Person,
        "Yuval Tassa"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:dateModified "2016-08-12T16:05:08Z"^^schema:DateTime ;
    schema:datePublished "2016-03-28T21:59:08Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Attend, Infer, Repeat: Fast Scene Understanding with Generative Models"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.08575v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17841381849984749111&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<304> a schema:ScholarlyArticle ;
    schema:abstract "Learning to predict multi-label outputs is challenging, but in many problemsthere is a natural metric on the outputs that can be used to improvepredictions. In this paper we develop a loss function for multi-label learning,based on the Wasserstein distance. The Wasserstein distance provides a naturalnotion of dissimilarity for probability measures. Although optimizing withrespect to the exact Wasserstein distance is costly, recent work has describeda regularized approximation that is efficiently computed. We describe anefficient learning algorithm based on this regularization, as well as a novelextension of the Wasserstein distance from probability measures to unnormalizedmeasures. We also describe a statistical learning bound for the loss. TheWasserstein loss can encourage smoothness of the predictions with respect to achosen metric on the output space. We demonstrate this property on a real-datatag prediction problem, using the Yahoo Flickr Creative Commons dataset,outperforming a baseline that doesn't use the metric."^^schema:Text ;
    schema:author "Charlie Frogner"^^schema:Person,
        "Chiyuan Zhang"^^schema:Person,
        "Hossein Mobahi"^^schema:Person,
        "Mauricio Araya-Polo"^^schema:Person,
        "Tomaso Poggio"^^schema:Person ;
    schema:commentCount "248"^^schema:Integer ;
    schema:dateModified "2015-12-30T01:08:11Z"^^schema:DateTime ;
    schema:datePublished "2015-06-17T19:36:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning with a Wasserstein Loss"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.05439v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12544095470577774181&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<305> a schema:ScholarlyArticle ;
    schema:abstract "Face verification remains a challenging problem in very complex conditionswith large variations such as pose, illumination, expression, and occlusions.This problem is exacerbated when we rely unrealistically on a single trainingdata source, which is often insufficient to cover the intrinsically complexface variations. This paper proposes a principled multi-task learning approachbased on Discriminative Gaussian Process Latent Variable Model, namedGaussianFace, to enrich the diversity of training data. In comparison toexisting methods, our model exploits additional data from multiplesource-domains to improve the generalization performance of face verificationin an unknown target-domain. Importantly, our model can adapt automatically tocomplex data distributions, and therefore can well capture complex facevariations inherent in multiple sources. Extensive experiments demonstrate theeffectiveness of the proposed model in learning from diverse data sources andgeneralize to unseen domain. Specifically, the accuracy of our algorithmachieves an impressive accuracy rate of 98.52% on the well-known andchallenging Labeled Faces in the Wild (LFW) benchmark. For the first time, thehuman-level performance in face verification (97.53%) on LFW is surpassed."^^schema:Text ;
    schema:author "Chaochao Lu"^^schema:Person,
        "Xiaoou Tang"^^schema:Person ;
    schema:commentCount "270"^^schema:Integer ;
    schema:dateModified "2014-12-20T03:37:36Z"^^schema:DateTime ;
    schema:datePublished "2014-04-15T07:51:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Surpassing Human-Level Face Verification Performance on LFW with  GaussianFace"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1404.3840v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11575983753307386058&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<306> a schema:ScholarlyArticle ;
    schema:abstract "Effective training of deep neural networks suffers from two main issues. Thefirst is that the parameter spaces of these models exhibit pathologicalcurvature. Recent methods address this problem by using adaptivepreconditioning for Stochastic Gradient Descent (SGD). These methods improveconvergence by adapting to the local geometry of parameter space. A secondissue is overfitting, which is typically addressed by early stopping. However,recent work has demonstrated that Bayesian model averaging mitigates thisproblem. The posterior can be sampled by using Stochastic Gradient LangevinDynamics (SGLD). However, the rapidly changing curvature renders default SGLDmethods inefficient. Here, we propose combining adaptive preconditioners withSGLD. In support of this idea, we give theoretical properties on asymptoticconvergence and predictive risk. We also provide empirical results for LogisticRegression, Feedforward Neural Nets, and Convolutional Neural Nets,demonstrating that our preconditioned SGLD method gives state-of-the-artperformance on these models."^^schema:Text ;
    schema:author "Changyou Chen"^^schema:Person,
        "Chunyuan Li"^^schema:Person,
        "David Carlson"^^schema:Person,
        "Lawrence Carin"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:dateModified "2015-12-23T23:45:03Z"^^schema:DateTime ;
    schema:datePublished "2015-12-23T23:45:03Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural  Networks"^^schema:Text ;
    schema:publisher "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1512.07666v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7279308262670948916&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<307> a schema:ScholarlyArticle ;
    schema:abstract "Understanding the 3D world is a fundamental problem in computer vision.However, learning a good representation of 3D objects is still an open problemdue to the high dimensionality of the data and many factors of variationinvolved. In this work, we investigate the task of single-view 3D objectreconstruction from a learning agent's perspective. We formulate the learningprocess as an interaction between 3D and 2D representations and propose anencoder-decoder network with a novel projection loss defined by the perspectivetransformation. More importantly, the projection loss enables the unsupervisedlearning using 2D observation without explicit 3D supervision. We demonstratethe ability of the model in generating 3D volume from a single 2D image withthree sets of experiments: (1) learning from single-class objects; (2) learningfrom multi-class objects and (3) testing on novel object classes. Results showsuperior performance and better generalization ability for 3D objectreconstruction when the projection loss is involved."^^schema:Text ;
    schema:author "Ersin Yumer"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Jimei Yang"^^schema:Person,
        "Xinchen Yan"^^schema:Person,
        "Yijie Guo"^^schema:Person ;
    schema:commentCount "314"^^schema:Integer ;
    schema:dateModified "2017-08-13T02:40:50Z"^^schema:DateTime ;
    schema:datePublished "2016-12-01T05:51:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Perspective Transformer Nets: Learning Single-View 3D Object  Reconstruction without 3D Supervision"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.00814v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13986075700848568161&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<308> a schema:ScholarlyArticle ;
    schema:abstract "In hyperspectral remote sensing data mining, it is important to take intoaccount of both spectral and spatial information, such as the spectralsignature, texture feature and morphological property, to improve theperformances, e.g., the image classification accuracy. In a featurerepresentation point of view, a nature approach to handle this situation is toconcatenate the spectral and spatial features into a single but highdimensional vector and then apply a certain dimension reduction techniquedirectly on that concatenated vector before feed it into the subsequentclassifier. However, multiple features from various domains definitely havedifferent physical meanings and statistical properties, and thus suchconcatenation hasn't efficiently explore the complementary properties amongdifferent features, which should benefit for boost the featurediscriminability. Furthermore, it is also difficult to interpret thetransformed results of the concatenated vector. Consequently, finding aphysically meaningful consensus low dimensional feature representation oforiginal multiple features is still a challenging task. In order to address thethese issues, we propose a novel feature learning framework, i.e., thesimultaneous spectral-spatial feature selection and extraction algorithm, forhyperspectral images spectral-spatial feature representation andclassification. Specifically, the proposed method learns a latent lowdimensional subspace by projecting the spectral-spatial feature into a commonfeature space, where the complementary information has been effectivelyexploited, and simultaneously, only the most significant original features havebeen transformed. Encouraging experimental results on three public availablehyperspectral remote sensing datasets confirm that our proposed method iseffective and efficient."^^schema:Text ;
    schema:author "Bo Du"^^schema:Person,
        "Dacheng Tao"^^schema:Person,
        "Lefei Zhang"^^schema:Person,
        "Qian Zhang"^^schema:Person,
        "Xin Huang"^^schema:Person,
        "Yuan Yan Tang"^^schema:Person ;
    schema:commentCount "122"^^schema:Integer ;
    schema:dateModified "2019-04-08T12:05:59Z"^^schema:DateTime ;
    schema:datePublished "2019-04-08T12:05:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Simultaneous Spectral-Spatial Feature Selection and Extraction for  Hyperspectral Images"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 48 (1), 16-28"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1904.03982v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10288918583770083724&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<309> a schema:ScholarlyArticle ;
    schema:abstract "The capacity of a neural network to absorb information is limited by itsnumber of parameters. Conditional computation, where parts of the network areactive on a per-example basis, has been proposed in theory as a way ofdramatically increasing model capacity without a proportional increase incomputation. In practice, however, there are significant algorithmic andperformance challenges. In this work, we address these challenges and finallyrealize the promise of conditional computation, achieving greater than 1000ximprovements in model capacity with only minor losses in computationalefficiency on modern GPU clusters. We introduce a Sparsely-GatedMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forwardsub-networks. A trainable gating network determines a sparse combination ofthese experts to use for each example. We apply the MoE to the tasks oflanguage modeling and machine translation, where model capacity is critical forabsorbing the vast quantities of knowledge available in the training corpora.We present model architectures in which a MoE with up to 137 billion parametersis applied convolutionally between stacked LSTM layers. On large languagemodeling and machine translation benchmarks, these models achieve significantlybetter results than state-of-the-art at lower computational cost."^^schema:Text ;
    schema:author "Andy Davis"^^schema:Person,
        "Azalia Mirhoseini"^^schema:Person,
        "Geoffrey Hinton"^^schema:Person,
        "Jeff Dean"^^schema:Person,
        "Krzysztof Maziarz"^^schema:Person,
        "Noam Shazeer"^^schema:Person,
        "Quoc Le"^^schema:Person ;
    schema:commentCount "456"^^schema:Integer ;
    schema:dateModified "2017-01-23T18:10:00Z"^^schema:DateTime ;
    schema:datePublished "2017-01-23T18:10:00Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.06538v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15166356379734033992&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<31> a schema:ScholarlyArticle ;
    schema:abstract "Deep nets generalize well despite having more parameters than the number oftraining samples. Recent works try to give an explanation using PAC-Bayes andMargin-based analyses, but do not as yet result in sample complexity boundsbetter than naive parameter counting. The current paper shows generalizationbounds that're orders of magnitude better in practice. These rely upon newsuccinct reparametrizations of the trained net --- a compression that isexplicit and efficient. These yield generalization bounds via a simplecompression-based framework introduced here. Our results also provide sometheoretical justification for widespread empirical success in compressing deepnets. Analysis of correctness of our compression relies upon some newlyidentified \\textquotedblleft noise stability\\textquotedblright properties oftrained deep nets, which are also experimentally verified. The study of theseproperties and resulting generalization bounds are also extended toconvolutional nets, which had eluded earlier attempts on provinggeneralization."^^schema:Text ;
    schema:author "Behnam Neyshabur"^^schema:Person,
        "Rong Ge"^^schema:Person,
        "Sanjeev Arora"^^schema:Person,
        "Yi Zhang"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2018-11-26T19:31:00Z"^^schema:DateTime ;
    schema:datePublished "2018-02-14T19:38:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Stronger generalization bounds for deep nets via a compression approach"^^schema:Text ;
    schema:publisher "ICML, 254-263"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.05296v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2741843082009546935&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<310> a schema:ScholarlyArticle ;
    schema:abstract "To scale Gaussian processes (GPs) to large data sets we introduce the robustBayesian Committee Machine (rBCM), a practical and scalable product-of-expertsmodel for large-scale distributed GP regression. Unlike state-of-the-art sparseGP approximations, the rBCM is conceptually simple and does not rely oninducing or variational parameters. The key idea is to recursively distributecomputations to independent computational units and, subsequently, recombinethem to form an overall result. Efficient closed-form inference allows forstraightforward parallelisation and distributed computations with a smallmemory footprint. The rBCM is independent of the computational graph and can beused on heterogeneous computing infrastructures, ranging from laptops toclusters. With sufficient computing resources our distributed GP model canhandle arbitrarily large data sets."^^schema:Text ;
    schema:author "Jun Wei Ng"^^schema:Person,
        "Marc Peter Deisenroth"^^schema:Person ;
    schema:commentCount "199"^^schema:Integer ;
    schema:dateModified "2015-05-22T06:46:11Z"^^schema:DateTime ;
    schema:datePublished "2015-02-10T10:31:41Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Distributed Gaussian Processes"^^schema:Text ;
    schema:publisher "ICML, 1481-1490"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02843v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12328519706788425295&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<311> a schema:ScholarlyArticle ;
    schema:abstract "Efficient simulation of the Navier-Stokes equations for fluid flow is a longstanding problem in applied mathematics, for which state-of-the-art methodsrequire large compute resources. In this work, we propose a data-drivenapproach that leverages the approximation power of deep-learning with theprecision of standard solvers to obtain fast and highly realistic simulations.Our method solves the incompressible Euler equations using the standardoperator splitting method, in which a large sparse linear system with many freeparameters must be solved. We use a Convolutional Network with a highlytailored architecture, trained using a novel unsupervised learning framework tosolve the linear system. We present real-time 2D and 3D simulations thatoutperform recently proposed data-driven methods; the obtained results arerealistic and show good generalization properties."^^schema:Text ;
    schema:author "Jonathan Tompson"^^schema:Person,
        "Ken Perlin"^^schema:Person,
        "Kristofer Schlachter"^^schema:Person,
        "Pablo Sprechmann"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2017-06-22T17:28:58Z"^^schema:DateTime ;
    schema:datePublished "2016-07-13T05:57:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Accelerating Eulerian Fluid Simulation With Convolutional Networks"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.03597v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9137335732064258642&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<312> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning tools have gained tremendous attention in applied machinelearning. However such tools for regression and classification do not capturemodel uncertainty. In comparison, Bayesian models offer a mathematicallygrounded framework to reason about model uncertainty, but usually come with aprohibitive computational cost. In this paper we develop a new theoreticalframework casting dropout training in deep neural networks (NNs) as approximateBayesian inference in deep Gaussian processes. A direct result of this theorygives us tools to model uncertainty with dropout NNs -- extracting informationfrom existing models that has been thrown away so far. This mitigates theproblem of representing uncertainty in deep learning without sacrificing eithercomputational complexity or test accuracy. We perform an extensive study of theproperties of dropout's uncertainty. Various network architectures andnon-linearities are assessed on tasks of regression and classification, usingMNIST as an example. We show a considerable improvement in predictivelog-likelihood and RMSE compared to existing state-of-the-art methods, andfinish by using dropout's uncertainty in deep reinforcement learning."^^schema:Text ;
    schema:author "Yarin Gal"^^schema:Person,
        "Zoubin Ghahramani"^^schema:Person ;
    schema:commentCount "2029"^^schema:Integer ;
    schema:dateModified "2016-10-04T16:50:26Z"^^schema:DateTime ;
    schema:datePublished "2015-06-06T12:30:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dropout as a Bayesian Approximation: Representing Model Uncertainty in  Deep Learning"^^schema:Text ;
    schema:publisher "ICML, 1050-1059"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.02142v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13759824860264424817&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<313> a schema:ScholarlyArticle ;
    schema:abstract "The recently proposed Temporal Ensembling has achieved state-of-the-artresults in several semi-supervised learning benchmarks. It maintains anexponential moving average of label predictions on each training example, andpenalizes predictions that are inconsistent with this target. However, becausethe targets change only once per epoch, Temporal Ensembling becomes unwieldywhen learning large datasets. To overcome this problem, we propose MeanTeacher, a method that averages model weights instead of label predictions. Asan additional benefit, Mean Teacher improves test accuracy and enables trainingwith fewer labels than Temporal Ensembling. Without changing the networkarchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250labels, outperforming Temporal Ensembling trained with 1000 labels. We alsoshow that a good network architecture is crucial to performance. Combining MeanTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labelsfrom 35.24% to 9.11%."^^schema:Text ;
    schema:author "Antti Tarvainen"^^schema:Person,
        "Harri Valpola"^^schema:Person ;
    schema:commentCount "480"^^schema:Integer ;
    schema:dateModified "2018-04-16T10:39:11Z"^^schema:DateTime ;
    schema:datePublished "2017-03-06T09:34:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Mean teachers are better role models: Weight-averaged consistency  targets improve semi-supervised deep learning results"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01780v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3256042804843589088&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<314> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a new semi-supervised framework with convolutional neuralnetworks (CNNs) for text categorization. Unlike the previous approaches thatrely on word embeddings, our method learns embeddings of small text regionsfrom unlabeled data for integration into a supervised CNN. The proposed schemefor embedding learning is based on the idea of two-view semi-supervisedlearning, which is intended to be useful for the task of interest even thoughthe training is done on unlabeled data. Our models achieve better results thanprevious approaches on sentiment classification and topic classification tasks."^^schema:Text ;
    schema:author "Rie Johnson"^^schema:Person,
        "Tong Zhang"^^schema:Person ;
    schema:commentCount "252"^^schema:Integer ;
    schema:dateModified "2015-11-01T15:26:16Z"^^schema:DateTime ;
    schema:datePublished "2015-04-06T10:42:07Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Semi-supervised Convolutional Neural Networks for Text Categorization  via Region Embedding"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1504.01255v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3888849217733730450&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<315> a schema:ScholarlyArticle ;
    schema:abstract "The increasingly photorealistic sample quality of generative image modelssuggests their feasibility in applications beyond image generation. We presentthe Neural Photo Editor, an interface that leverages the power of generativeneural networks to make large, semantically coherent changes to existingimages. To tackle the challenge of achieving accurate reconstructions withoutloss of feature quality, we introduce the Introspective Adversarial Network, anovel hybridization of the VAE and GAN. Our model efficiently captureslong-range dependencies through use of a computational block based onweight-shared dilated convolutions, and improves generalization performancewith Orthogonal Regularization, a novel weight regularization method. Wevalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samplesand reconstructions with high visual fidelity."^^schema:Text ;
    schema:author "Andrew Brock"^^schema:Person,
        "J. M. Ritchie"^^schema:Person,
        "Nick Weston"^^schema:Person,
        "Theodore Lim"^^schema:Person ;
    schema:commentCount "238"^^schema:Integer ;
    schema:dateModified "2017-02-06T18:46:50Z"^^schema:DateTime ;
    schema:datePublished "2016-09-22T18:07:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Photo Editing with Introspective Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.07093v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13506818224034936115&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<316> a schema:ScholarlyArticle ;
    schema:abstract "We study nonconvex finite-sum problems and analyze stochastic variancereduced gradient (SVRG) methods for them. SVRG and related methods haverecently surged into prominence for convex optimization given their edge overstochastic gradient descent (SGD); but their theoretical analysis almostexclusively assumes convexity. In contrast, we prove non-asymptotic rates ofconvergence (to stationary points) of SVRG for nonconvex optimization, and showthat it is provably faster than SGD and gradient descent. We also analyze asubclass of nonconvex problems on which SVRG attains linear convergence to theglobal optimum. We extend our analysis to mini-batch variants of SVRG, showing(theoretical) linear speedup due to mini-batching in parallel settings."^^schema:Text ;
    schema:author "Ahmed Hefny"^^schema:Person,
        "Alex Smola"^^schema:Person,
        "Barnabas Poczos"^^schema:Person,
        "Sashank J. Reddi"^^schema:Person,
        "Suvrit Sra"^^schema:Person ;
    schema:commentCount "341"^^schema:Integer ;
    schema:dateModified "2016-04-04T23:08:20Z"^^schema:DateTime ;
    schema:datePublished "2016-03-19T23:37:38Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stochastic Variance Reduction for Nonconvex Optimization"^^schema:Text ;
    schema:publisher "ICML, 314-323"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.06160v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11798684571364229600&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<317> a schema:ScholarlyArticle ;
    schema:abstract "Recently, convolutional neural networks (CNNs) have been used as a powerfultool to solve many problems of machine learning and computer vision. In thispaper, we aim to provide insight on the property of convolutional neuralnetworks, as well as a generic method to improve the performance of many CNNarchitectures. Specifically, we first examine existing CNN models and observean intriguing property that the filters in the lower layers form pairs (i.e.,filters with opposite phase). Inspired by our observation, we propose a novel,simple yet effective activation scheme called concatenated ReLU (CRelu) andtheoretically analyze its reconstruction property in CNNs. We integrate CReluinto several state-of-the-art CNN architectures and demonstrate improvement intheir recognition performance on CIFAR-10/100 and ImageNet datasets with fewertrainable parameters. Our results suggest that better understanding of theproperties of CNNs can lead to significant performance improvement with asimple modification."^^schema:Text ;
    schema:author "Diogo Almeida"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Kihyuk Sohn"^^schema:Person,
        "Wenling Shang"^^schema:Person ;
    schema:commentCount "262"^^schema:Integer ;
    schema:dateModified "2016-07-19T05:18:36Z"^^schema:DateTime ;
    schema:datePublished "2016-03-16T18:17:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Understanding and Improving Convolutional Neural Networks via  Concatenated Rectified Linear Units"^^schema:Text ;
    schema:publisher "ICML, 2217-2225"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.05201v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6969201205550299393&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<318> a schema:ScholarlyArticle ;
    schema:abstract "Some machine learning applications involve training data that is sensitive,such as the medical histories of patients in a clinical trial. A model mayinadvertently and implicitly store some of its training data; careful analysisof the model may therefore reveal sensitive information.  To address this problem, we demonstrate a generally applicable approach toproviding strong privacy guarantees for training data: Private Aggregation ofTeacher Ensembles (PATE). The approach combines, in a black-box fashion,multiple models trained with disjoint datasets, such as records from differentsubsets of users. Because they rely directly on sensitive data, these modelsare not published, but instead used as \"teachers\" for a \"student\" model. Thestudent learns to predict an output chosen by noisy voting among all of theteachers, and cannot directly access an individual teacher or the underlyingdata or parameters. The student's privacy properties can be understood bothintuitively (since no single teacher and thus no single dataset dictates thestudent's training) and formally, in terms of differential privacy. Theseproperties hold even if an adversary can not only query the student but alsoinspect its internal workings.  Compared with previous work, the approach imposes only weak assumptions onhow teachers are trained: it applies to any model, including non-convex modelslike DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST andSVHN thanks to an improved privacy analysis and semi-supervised learning."^^schema:Text ;
    schema:author "Ian Goodfellow"^^schema:Person,
        "Kunal Talwar"^^schema:Person,
        "Martín Abadi"^^schema:Person,
        "Nicolas Papernot"^^schema:Person,
        "Úlfar Erlingsson"^^schema:Person ;
    schema:commentCount "292"^^schema:Integer ;
    schema:dateModified "2017-03-03T18:56:43Z"^^schema:DateTime ;
    schema:datePublished "2016-10-18T19:37:37Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Semi-supervised Knowledge Transfer for Deep Learning from Private  Training Data"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.05755v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7453137533162499463&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<319> a schema:ScholarlyArticle ;
    schema:abstract "This paper shows that a perturbed form of gradient descent converges to asecond-order stationary point in a number iterations which depends onlypoly-logarithmically on dimension (i.e., it is almost \"dimension-free\"). Theconvergence rate of this procedure matches the well-known convergence rate ofgradient descent to first-order stationary points, up to log factors. When allsaddle points are non-degenerate, all second-order stationary points are localminima, and our result thus shows that perturbed gradient descent can escapesaddle points almost for free. Our results can be directly applied to manymachine learning applications, including deep learning. As a particularconcrete example of such an application, we show that our results can be useddirectly to establish sharp global convergence rates for matrix factorization.Our results rely on a novel characterization of the geometry around saddlepoints, which may be of independent interest to the non-convex optimizationcommunity."^^schema:Text ;
    schema:author "Chi Jin"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Praneeth Netrapalli"^^schema:Person,
        "Rong Ge"^^schema:Person,
        "Sham M. Kakade"^^schema:Person ;
    schema:commentCount "365"^^schema:Integer ;
    schema:dateModified "2017-03-02T18:35:24Z"^^schema:DateTime ;
    schema:datePublished "2017-03-02T18:35:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "How to Escape Saddle Points Efficiently"^^schema:Text ;
    schema:publisher "ICML, 1724-1732"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00887v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4868890107031817813&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<32> a schema:ScholarlyArticle ;
    schema:abstract "Under the framework of graph-based learning, the key to robust subspaceclustering and subspace learning is to obtain a good similarity graph thateliminates the effects of errors and retains only connections between the datapoints from the same subspace (i.e., intra-subspace data points). Recent worksachieve good performance by modeling errors into their objective functions toremove the errors from the inputs. However, these approaches face thelimitations that the structure of errors should be known prior and a complexconvex problem must be solved. In this paper, we present a novel method toeliminate the effects of the errors from the projection space (representation)rather than from the input space. We first prove that $\\ell_1$-, $\\ell_2$-,$\\ell_{\\infty}$-, and nuclear-norm based linear projection spaces share theproperty of Intra-subspace Projection Dominance (IPD), i.e., the coefficientsover intra-subspace data points are larger than those over inter-subspace datapoints. Based on this property, we introduce a method to construct a sparsesimilarity graph, called L2-Graph. The subspace clustering and subspacelearning algorithms are developed upon L2-Graph. Experiments show that L2-Graphalgorithms outperform the state-of-the-art methods for feature extraction,image clustering, and motion segmentation in terms of accuracy, robustness, andtime efficiency."^^schema:Text ;
    schema:author "Huajin Tang"^^schema:Person,
        "Xi Peng"^^schema:Person,
        "Zhang Yi"^^schema:Person,
        "Zhiding Yu"^^schema:Person ;
    schema:commentCount "126"^^schema:Integer ;
    schema:dateModified "2015-01-17T12:00:47Z"^^schema:DateTime ;
    schema:datePublished "2012-09-05T01:36:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Constructing the L2-Graph for Robust Subspace Learning and Subspace  Clustering"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 47 (4), 1053-1066"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1209.0841v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12238625670556584082&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<320> a schema:ScholarlyArticle ;
    schema:abstract "We combine Riemannian geometry with the mean field theory of high dimensionalchaos to study the nature of signal propagation in generic, deep neuralnetworks with random weights. Our results reveal an order-to-chaos expressivityphase transition, with networks in the chaotic phase computing nonlinearfunctions whose global curvature grows exponentially with depth but not width.We prove this generic class of deep random functions cannot be efficientlycomputed by any shallow network, going beyond prior work restricted to theanalysis of single functions. Moreover, we formalize and quantitativelydemonstrate the long conjectured idea that deep networks can disentangle highlycurved manifolds in input space into flat manifolds in hidden space. Ourtheoretical analysis of the expressive power of deep networks broadly appliesto arbitrary nonlinearities, and provides a quantitative underpinning forpreviously abstract notions about the geometry of deep functions."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Maithra Raghu"^^schema:Person,
        "Subhaneil Lahiri"^^schema:Person,
        "Surya Ganguli"^^schema:Person ;
    schema:commentCount "248"^^schema:Integer ;
    schema:dateModified "2016-06-17T18:13:20Z"^^schema:DateTime ;
    schema:datePublished "2016-06-16T19:59:57Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Exponential expressivity in deep neural networks through transient chaos"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.05340v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10408494153995210425&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<321> a schema:ScholarlyArticle ;
    schema:abstract "The move from hand-designed features to learned features in machine learninghas been wildly successful. In spite of this, optimization algorithms are stilldesigned by hand. In this paper we show how the design of an optimizationalgorithm can be cast as a learning problem, allowing the algorithm to learn toexploit structure in the problems of interest in an automatic way. Our learnedalgorithms, implemented by LSTMs, outperform generic, hand-designed competitorson the tasks for which they are trained, and also generalize well to new taskswith similar structure. We demonstrate this on a number of tasks, includingsimple convex problems, training neural networks, and styling images withneural art."^^schema:Text ;
    schema:author "Brendan Shillingford"^^schema:Person,
        "David Pfau"^^schema:Person,
        "Marcin Andrychowicz"^^schema:Person,
        "Matthew W. Hoffman"^^schema:Person,
        "Misha Denil"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Sergio Gomez"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:commentCount "793"^^schema:Integer ;
    schema:dateModified "2016-11-30T16:45:45Z"^^schema:DateTime ;
    schema:datePublished "2016-06-14T17:49:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning to learn by gradient descent by gradient descent"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.04474v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17211876730630533152&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<322> a schema:ScholarlyArticle ;
    schema:abstract "We propose a hierarchical approach for making long-term predictions of futureframes. To avoid inherent compounding errors in recursive pixel-levelprediction, we propose to first estimate high-level structure in the inputframes, then predict how that structure evolves in the future, and finally byobserving a single frame from the past and the predicted high-level structure,we construct the future frames without having to observe any of the pixel-levelpredictions. Long-term video prediction is difficult to perform by recurrentlyobserving the predicted frames because the small errors in pixel spaceexponentially amplify as predictions are made deeper into the future. Ourapproach prevents pixel-level error propagation from happening by removing theneed to observe the predicted frames. Our model is built with a combination ofLSTM and analogy based encoder-decoder convolutional neural networks, whichindependently predict the video structure and generate the future frames,respectively. In experiments, our model is evaluated on the Human3.6M and PennAction datasets on the task of long-term pixel-level video prediction of humansperforming actions and demonstrate significantly better results than thestate-of-the-art."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Jimei Yang"^^schema:Person,
        "Ruben Villegas"^^schema:Person,
        "Sungryull Sohn"^^schema:Person,
        "Xunyu Lin"^^schema:Person,
        "Yuliang Zou"^^schema:Person ;
    schema:commentCount "195"^^schema:Integer ;
    schema:dateModified "2018-01-08T01:24:36Z"^^schema:DateTime ;
    schema:datePublished "2017-04-19T17:25:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Generate Long-term Future via Hierarchical Prediction"^^schema:Text ;
    schema:publisher "ICML, 3560-3569"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.05831v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=307545796405932708&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<323> a schema:ScholarlyArticle ;
    schema:abstract "One-hot CNN (convolutional neural network) has been shown to be effective fortext categorization (Johnson &amp; Zhang, 2015). We view it as a special case of ageneral framework which jointly trains a linear model with a non-linear featuregenerator consisting of `text region embedding + pooling'. Under thisframework, we explore a more sophisticated region embedding method using LongShort-Term Memory (LSTM). LSTM can embed text regions of variable (and possiblylarge) sizes, whereas the region size needs to be fixed in a CNN. We seekeffective and efficient use of LSTM for this purpose in the supervised andsemi-supervised settings. The best results were obtained by combining regionembeddings in the form of LSTM and convolution layers trained on unlabeleddata. The results indicate that on this task, embeddings of text regions, whichcan convey complex concepts, are more useful than embeddings of single words inisolation. We report performances exceeding the previous best results on fourbenchmark datasets."^^schema:Text ;
    schema:author "Rie Johnson"^^schema:Person,
        "Tong Zhang"^^schema:Person ;
    schema:commentCount "171"^^schema:Integer ;
    schema:dateModified "2016-05-26T15:26:34Z"^^schema:DateTime ;
    schema:datePublished "2016-02-07T14:05:58Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Supervised and Semi-Supervised Text Categorization using LSTM for Region  Embeddings"^^schema:Text ;
    schema:publisher "ICML, 526-534"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02373v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=734642960293024734&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<324> a schema:ScholarlyArticle ;
    schema:abstract "Policies for complex visual tasks have been successfully learned with deepreinforcement learning, using an approach called deep Q-networks (DQN), butrelatively large (task-specific) networks and extensive training are needed toachieve good performance. In this work, we present a novel method called policydistillation that can be used to extract the policy of a reinforcement learningagent and train a new network that performs at the expert level while beingdramatically smaller and more efficient. Furthermore, the same method can beused to consolidate multiple task-specific policies into a single policy. Wedemonstrate these claims using the Atari domain and show that the multi-taskdistilled agent outperforms the single-task teachers as well as ajointly-trained DQN agent."^^schema:Text ;
    schema:author "Andrei A. Rusu"^^schema:Person,
        "Caglar Gulcehre"^^schema:Person,
        "Guillaume Desjardins"^^schema:Person,
        "James Kirkpatrick"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Raia Hadsell"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Sergio Gomez Colmenarejo"^^schema:Person,
        "Volodymyr Mnih"^^schema:Person ;
    schema:commentCount "259"^^schema:Integer ;
    schema:dateModified "2016-01-07T18:43:03Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T18:38:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Policy Distillation"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06295v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7257674603698705150&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<325> a schema:ScholarlyArticle ;
    schema:abstract "Asynchronous parallel implementations of stochastic gradient (SG) have beenbroadly used in solving deep neural network and received many successes inpractice recently. However, existing theories cannot explain their convergenceand speedup properties, mainly due to the nonconvexity of most deep learningformulations and the asynchronous parallel mechanism. To fill the gaps intheory and provide theoretical supports, this paper studies two asynchronousparallel implementations of SG: one is on the computer network and the other ison the shared memory system. We establish an ergodic convergence rate$O(1/\\sqrt{K})$ for both algorithms and prove that the linear speedup isachievable if the number of workers is bounded by $\\sqrt{K}$ ($K$ is the totalnumber of iterations). Our results generalize and improve existing analysis forconvex minimization."^^schema:Text ;
    schema:author "Ji Liu"^^schema:Person,
        "Xiangru Lian"^^schema:Person,
        "Yijun Huang"^^schema:Person,
        "Yuncheng Li"^^schema:Person ;
    schema:commentCount "257"^^schema:Integer ;
    schema:dateModified "2019-04-18T18:25:04Z"^^schema:DateTime ;
    schema:datePublished "2015-06-27T08:41:50Z"^^schema:DateTime ;
    schema:genre "cs.NA"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.08272v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14750704835510307295&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<326> a schema:ScholarlyArticle ;
    schema:abstract "The blind application of machine learning runs the risk of amplifying biasespresent in data. Such a danger is facing us with word embedding, a popularframework to represent text data as vectors which has been used in many machinelearning and natural language processing tasks. We show that even wordembeddings trained on Google News articles exhibit female/male genderstereotypes to a disturbing extent. This raises concerns because theirwidespread use, as we describe, often tends to amplify these biases.Geometrically, gender bias is first shown to be captured by a direction in theword embedding. Second, gender neutral words are shown to be linearly separablefrom gender definition words in the word embedding. Using these properties, weprovide a methodology for modifying an embedding to remove gender stereotypes,such as the association between between the words receptionist and female,while maintaining desired associations such as between the words queen andfemale. We define metrics to quantify both direct and indirect gender biases inembeddings, and develop algorithms to \"debias\" the embedding. Usingcrowd-worker evaluation as well as standard benchmarks, we empiricallydemonstrate that our algorithms significantly reduce gender bias in embeddingswhile preserving the its useful properties such as the ability to clusterrelated concepts and to solve analogy tasks. The resulting embeddings can beused in applications without amplifying gender bias."^^schema:Text ;
    schema:author "Adam Kalai"^^schema:Person,
        "James Zou"^^schema:Person,
        "Kai-Wei Chang"^^schema:Person,
        "Tolga Bolukbasi"^^schema:Person,
        "Venkatesh Saligrama"^^schema:Person ;
    schema:commentCount "822"^^schema:Integer ;
    schema:dateModified "2016-07-21T22:26:20Z"^^schema:DateTime ;
    schema:datePublished "2016-07-21T22:26:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word  Embeddings"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.06520v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1143892262062010100&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<327> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks are a powerful tool for modeling sequential data,but the dependence of each timestep's computation on the previous timestep'soutput limits parallelism and makes RNNs unwieldy for very long sequences. Weintroduce quasi-recurrent neural networks (QRNNs), an approach to neuralsequence modeling that alternates convolutional layers, which apply in parallelacross timesteps, and a minimalist recurrent pooling function that applies inparallel across channels. Despite lacking trainable recurrent layers, stackedQRNNs have better predictive accuracy than stacked LSTMs of the same hiddensize. Due to their increased parallelism, they are up to 16 times faster attrain and test time. Experiments on language modeling, sentimentclassification, and character-level neural machine translation demonstratethese advantages and underline the viability of QRNNs as a basic building blockfor a variety of sequence tasks."^^schema:Text ;
    schema:author "Caiming Xiong"^^schema:Person,
        "James Bradbury"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Stephen Merity"^^schema:Person ;
    schema:commentCount "256"^^schema:Integer ;
    schema:dateModified "2016-11-21T20:52:34Z"^^schema:DateTime ;
    schema:datePublished "2016-11-05T00:31:25Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Quasi-Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01576v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4062513269935809949&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<328> a schema:ScholarlyArticle ;
    schema:abstract "Humans have an impressive ability to reason about new concepts andexperiences from just a single example. In particular, humans have an abilityfor one-shot generalization: an ability to encounter a new concept, understandits structure, and then be able to generate compelling alternative variationsof the concept. We develop machine learning systems with this importantcapacity by developing new deep generative models, models that combine therepresentational power of deep learning with the inferential power of Bayesianreasoning. We develop a class of sequential generative models that are built onthe principles of feedback and attention. These two characteristics lead togenerative models that are among the state-of-the art in density estimation andimage generation. We demonstrate the one-shot generalization ability of ourmodels using three tasks: unconditional sampling, generating new exemplars of agiven concept, and generating new exemplars of a family of concepts. In allcases our models are able to generate compelling and diverse samples---havingseen new examples just once---providing an important class of general-purposemodels for one-shot machine learning."^^schema:Text ;
    schema:author "Daan Wierstra"^^schema:Person,
        "Danilo Jimenez Rezende"^^schema:Person,
        "Ivo Danihelka"^^schema:Person,
        "Karol Gregor"^^schema:Person,
        "Shakir Mohamed"^^schema:Person ;
    schema:commentCount "180"^^schema:Integer ;
    schema:dateModified "2016-05-25T12:57:19Z"^^schema:DateTime ;
    schema:datePublished "2016-03-16T14:10:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "One-Shot Generalization in Deep Generative Models"^^schema:Text ;
    schema:publisher "ICML, 1521-1529"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.05106v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16418227374416270076&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<329> a schema:ScholarlyArticle ;
    schema:abstract "Several deep learning models have been proposed for question answering.However, due to their single-pass nature, they have no way to recover fromlocal maxima corresponding to incorrect answers. To address this problem, weintroduce the Dynamic Coattention Network (DCN) for question answering. The DCNfirst fuses co-dependent representations of the question and the document inorder to focus on relevant parts of both. Then a dynamic pointing decoderiterates over potential answer spans. This iterative procedure enables themodel to recover from initial local maxima corresponding to incorrect answers.On the Stanford question answering dataset, a single DCN model improves theprevious state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains80.4% F1."^^schema:Text ;
    schema:author "Caiming Xiong"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Victor Zhong"^^schema:Person ;
    schema:commentCount "433"^^schema:Integer ;
    schema:dateModified "2018-03-06T22:45:53Z"^^schema:DateTime ;
    schema:datePublished "2016-11-05T04:53:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Dynamic Coattention Networks For Question Answering"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01604v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7601883970857280608&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<33> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (RL) methods generally engage in exploratorybehavior through noise injection in the action space. An alternative is to addnoise directly to the agent's parameters, which can lead to more consistentexploration and a richer set of behaviors. Methods such as evolutionarystrategies use parameter perturbations, but discard all temporal structure inthe process and require significantly more samples. Combining parameter noisewith traditional RL methods allows to combine the best of both worlds. Wedemonstrate that both off- and on-policy methods benefit from this approachthrough experimental comparison of DQN, DDPG, and TRPO on high-dimensionaldiscrete action environments as well as continuous control tasks. Our resultsshow that RL with parameter noise learns more efficiently than traditional RLwith action space noise and evolutionary strategies individually."^^schema:Text ;
    schema:author "Marcin Andrychowicz"^^schema:Person,
        "Matthias Plappert"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Prafulla Dhariwal"^^schema:Person,
        "Rein Houthooft"^^schema:Person,
        "Richard Y. Chen"^^schema:Person,
        "Szymon Sidor"^^schema:Person,
        "Tamim Asfour"^^schema:Person,
        "Xi Chen"^^schema:Person ;
    schema:commentCount "273"^^schema:Integer ;
    schema:dateModified "2018-01-31T09:05:10Z"^^schema:DateTime ;
    schema:datePublished "2017-06-06T18:09:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Parameter Space Noise for Exploration"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.01905v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5517640716015156114&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<330> a schema:ScholarlyArticle ;
    schema:abstract "Forecasting the flow of crowds is of great importance to traffic managementand public safety, yet a very challenging task affected by many complexfactors, such as inter-region traffic, events and weather. In this paper, wepropose a deep-learning-based approach, called ST-ResNet, to collectivelyforecast the in-flow and out-flow of crowds in each and every region through acity. We design an end-to-end structure of ST-ResNet based on unique propertiesof spatio-temporal data. More specifically, we employ the framework of theresidual neural networks to model the temporal closeness, period, and trendproperties of the crowd traffic, respectively. For each property, we design abranch of residual convolutional units, each of which models the spatialproperties of the crowd traffic. ST-ResNet learns to dynamically aggregate theoutput of the three residual neural networks based on data, assigning differentweights to different branches and regions. The aggregation is further combinedwith external factors, such as weather and day of the week, to predict thefinal traffic of crowds in each and every region. We evaluate ST-ResNet basedon two types of crowd flows in Beijing and NYC, finding that its performanceexceeds six well-know methods."^^schema:Text ;
    schema:author "Dekang Qi"^^schema:Person,
        "Junbo Zhang"^^schema:Person,
        "Yu Zheng"^^schema:Person ;
    schema:commentCount "551"^^schema:Integer ;
    schema:dateModified "2017-01-10T09:53:16Z"^^schema:DateTime ;
    schema:datePublished "2016-10-01T03:56:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows  Prediction"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.00081v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10585174952970430867&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<331> a schema:ScholarlyArticle ;
    schema:abstract "Confidence calibration -- the problem of predicting probability estimatesrepresentative of the true correctness likelihood -- is important forclassification models in many applications. We discover that modern neuralnetworks, unlike those from a decade ago, are poorly calibrated. Throughextensive experiments, we observe that depth, width, weight decay, and BatchNormalization are important factors influencing calibration. We evaluate theperformance of various post-processing calibration methods on state-of-the-artarchitectures with image and document classification datasets. Our analysis andexperiments not only offer insights into neural network learning, but alsoprovide a simple and straightforward recipe for practical settings: on mostdatasets, temperature scaling -- a single-parameter variant of Platt Scaling --is surprisingly effective at calibrating predictions."^^schema:Text ;
    schema:author "Chuan Guo"^^schema:Person,
        "Geoff Pleiss"^^schema:Person,
        "Kilian Q. Weinberger"^^schema:Person,
        "Yu Sun"^^schema:Person ;
    schema:commentCount "672"^^schema:Integer ;
    schema:dateModified "2017-08-03T13:29:46Z"^^schema:DateTime ;
    schema:datePublished "2017-06-14T17:33:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "On Calibration of Modern Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1321-1330"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.04599v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13350219683390288487&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<332> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a new, efficient, principled and backpropagation-compatiblealgorithm for learning a probability distribution on the weights of a neuralnetwork, called Bayes by Backprop. It regularises the weights by minimising acompression cost, known as the variational free energy or the expected lowerbound on the marginal likelihood. We show that this principled kind ofregularisation yields comparable performance to dropout on MNISTclassification. We then demonstrate how the learnt uncertainty in the weightscan be used to improve generalisation in non-linear regression problems, andhow this weight uncertainty can be used to drive the exploration-exploitationtrade-off in reinforcement learning."^^schema:Text ;
    schema:author "Charles Blundell"^^schema:Person,
        "Daan Wierstra"^^schema:Person,
        "Julien Cornebise"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person ;
    schema:commentCount "935"^^schema:Integer ;
    schema:dateModified "2015-05-21T14:07:23Z"^^schema:DateTime ;
    schema:datePublished "2015-05-20T15:39:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Weight Uncertainty in Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1613-1622"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.05424v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14542735200645169180&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<333> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of stochastic optimization for deep learning in theparallel computing environment under communication constraints. A new algorithmis proposed in this setting where the communication and coordination of workamong concurrent processes (local workers), is based on an elastic force whichlinks the parameters they compute with a center variable stored by theparameter server (master). The algorithm enables the local workers to performmore exploration, i.e. the algorithm allows the local variables to fluctuatefurther from the center variable by reducing the amount of communicationbetween local workers and the master. We empirically demonstrate that in thedeep learning setting, due to the existence of many local optima, allowing moreexploration can lead to the improved performance. We propose synchronous andasynchronous variants of the new algorithm. We provide the stability analysisof the asynchronous variant in the round-robin scheme and compare it with themore common parallelized method ADMM. We show that the stability of EASGD isguaranteed when a simple stability condition is satisfied, which is not thecase for ADMM. We additionally propose the momentum-based version of ouralgorithm that can be applied in both synchronous and asynchronous settings.Asynchronous variant of the algorithm is applied to train convolutional neuralnetworks for image classification on the CIFAR and ImageNet datasets.Experiments demonstrate that the new algorithm accelerates the training of deeparchitectures compared to DOWNPOUR and other common baseline approaches andfurthermore is very communication efficient."^^schema:Text ;
    schema:author "Anna Choromanska"^^schema:Person,
        "Sixin Zhang"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "356"^^schema:Integer ;
    schema:dateModified "2015-10-25T12:12:52Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T13:22:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep learning with Elastic Averaging SGD"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6651v8"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18355366617755570418&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<334> a schema:ScholarlyArticle ;
    schema:abstract "We introduce associative embedding, a novel method for supervisingconvolutional neural networks for the task of detection and grouping. A numberof computer vision problems can be framed in this manner including multi-personpose estimation, instance segmentation, and multi-object tracking. Usually thegrouping of detections is achieved with multi-stage pipelines, instead wepropose an approach that teaches a network to simultaneously output detectionsand group assignments. This technique can be easily integrated into anystate-of-the-art network architecture that produces pixel-wise predictions. Weshow how to apply this method to both multi-person pose estimation and instancesegmentation and report state-of-the-art performance for multi-person pose onthe MPII and MS-COCO datasets."^^schema:Text ;
    schema:author "Alejandro Newell"^^schema:Person,
        "Jia Deng"^^schema:Person,
        "Zhiao Huang"^^schema:Person ;
    schema:commentCount "259"^^schema:Integer ;
    schema:dateModified "2017-06-09T16:13:48Z"^^schema:DateTime ;
    schema:datePublished "2016-11-16T20:04:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Associative Embedding: End-to-End Learning for Joint Detection and  Grouping"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.05424v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17872365231417177678&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<335> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we present a simple, highly efficient and modularized Dual PathNetwork (DPN) for image classification which presents a new topology ofconnection paths internally. By revealing the equivalence of thestate-of-the-art Residual Network (ResNet) and Densely Convolutional Network(DenseNet) within the HORNN framework, we find that ResNet enables featurere-usage while DenseNet enables new features exploration which are bothimportant for learning good representations. To enjoy the benefits from bothpath topologies, our proposed Dual Path Network shares common features whilemaintaining the flexibility to explore new features through dual patharchitectures. Extensive experiments on three benchmark datasets, ImagNet-1k,Places365 and PASCAL VOC, clearly demonstrate superior performance of theproposed DPN over state-of-the-arts. In particular, on the ImagNet-1k dataset,a shallow DPN surpasses the best ResNeXt-101(64x4d) with 26% smaller modelsize, 25% less computational cost and 8% lower memory consumption, and a deeperDPN (DPN-131) further pushes the state-of-the-art single model performance withabout 2 times faster training speed. Experiments on the Places365 large-scalescene dataset, PASCAL VOC detection dataset, and PASCAL VOC segmentationdataset also demonstrate its consistently better performance than DenseNet,ResNet and the latest ResNeXt model over various applications."^^schema:Text ;
    schema:author "Huaxin Xiao"^^schema:Person,
        "Jianan Li"^^schema:Person,
        "Jiashi Feng"^^schema:Person,
        "Shuicheng Yan"^^schema:Person,
        "Xiaojie Jin"^^schema:Person,
        "Yunpeng Chen"^^schema:Person ;
    schema:commentCount "383"^^schema:Integer ;
    schema:dateModified "2017-08-01T01:15:57Z"^^schema:DateTime ;
    schema:datePublished "2017-07-06T04:05:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Dual Path Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.01629v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11426486763420133960&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<336> a schema:ScholarlyArticle ;
    schema:abstract "Model-free reinforcement learning has been successfully applied to a range ofchallenging problems, and has recently been extended to handle large neuralnetwork policies and value functions. However, the sample complexity ofmodel-free algorithms, particularly when using high-dimensional functionapproximators, tends to limit their applicability to physical systems. In thispaper, we explore algorithms and representations to reduce the samplecomplexity of deep reinforcement learning for continuous control tasks. Wepropose two complementary techniques for improving the efficiency of suchalgorithms. First, we derive a continuous variant of the Q-learning algorithm,which we call normalized adantage functions (NAF), as an alternative to themore commonly used policy gradient and actor-critic methods. NAF representationallows us to apply Q-learning with experience replay to continuous tasks, andsubstantially improves performance on a set of simulated robotic control tasks.To further improve the efficiency of our approach, we explore the use oflearned models for accelerating model-free reinforcement learning. We show thatiteratively refitted local linear models are especially effective for this, anddemonstrate substantially faster learning on domains where such models areapplicable."^^schema:Text ;
    schema:author "Ilya Sutskever"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Shixiang Gu"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person ;
    schema:commentCount "553"^^schema:Integer ;
    schema:dateModified "2016-03-02T15:28:25Z"^^schema:DateTime ;
    schema:datePublished "2016-03-02T15:28:25Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "Continuous Deep Q-Learning with Model-based Acceleration"^^schema:Text ;
    schema:publisher "ICML, 2829-2838"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.00748v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11808487067838603398&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<337> a schema:ScholarlyArticle ;
    schema:abstract "As a new way of training generative models, Generative Adversarial Nets (GAN)that uses a discriminative model to guide the training of the generative modelhas enjoyed considerable success in generating real-valued data. However, ithas limitations when the goal is for generating sequences of discrete tokens. Amajor reason lies in that the discrete outputs from the generative model makeit difficult to pass the gradient update from the discriminative model to thegenerative model. Also, the discriminative model can only assess a completesequence, while for a partially generated sequence, it is non-trivial tobalance its current score and the future one once the entire sequence has beengenerated. In this paper, we propose a sequence generation framework, calledSeqGAN, to solve the problems. Modeling the data generator as a stochasticpolicy in reinforcement learning (RL), SeqGAN bypasses the generatordifferentiation problem by directly performing gradient policy update. The RLreward signal comes from the GAN discriminator judged on a complete sequence,and is passed back to the intermediate state-action steps using Monte Carlosearch. Extensive experiments on synthetic data and real-world tasksdemonstrate significant improvements over strong baselines."^^schema:Text ;
    schema:author "Jun Wang"^^schema:Person,
        "Lantao Yu"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Yong Yu"^^schema:Person ;
    schema:commentCount "1020"^^schema:Integer ;
    schema:dateModified "2017-08-25T16:22:57Z"^^schema:DateTime ;
    schema:datePublished "2016-09-18T11:42:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.05473v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13783508915327278077&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<338> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks are vulnerable to adversarial examples and researchers haveproposed many heuristic attack and defense mechanisms. We address this problemthrough the principled lens of distributionally robust optimization, whichguarantees performance under adversarial input perturbations. By considering aLagrangian penalty formulation of perturbing the underlying data distributionin a Wasserstein ball, we provide a training procedure that augments modelparameter updates with worst-case perturbations of training data. For smoothlosses, our procedure provably achieves moderate levels of robustness withlittle computational or statistical cost relative to empirical riskminimization. Furthermore, our statistical guarantees allow us to efficientlycertify robustness for the population loss. For imperceptible perturbations,our method matches or outperforms heuristic approaches."^^schema:Text ;
    schema:author "Aman Sinha"^^schema:Person,
        "Hongseok Namkoong"^^schema:Person,
        "John Duchi"^^schema:Person,
        "Riccardo Volpi"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2020-05-01T07:29:34Z"^^schema:DateTime ;
    schema:datePublished "2017-10-29T07:27:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Certifying Some Distributional Robustness with Principled Adversarial  Training"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.10571v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5504610656672947417&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<339> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH),as well as its practical variant SARAH+, as a novel approach to the finite-summinimization problems. Different from the vanilla SGD and other modernstochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simplerecursive framework for updating stochastic gradient estimates; when comparingto SAG/SAGA, SARAH does not require a storage of past gradients. The linearconvergence rate of SARAH is proven under strong convexity assumption. We alsoprove a linear convergence rate (in the strongly convex case) for an inner loopof SARAH, the property that SVRG does not possess. Numerical experimentsdemonstrate the efficiency of our algorithm."^^schema:Text ;
    schema:author "Jie Liu"^^schema:Person,
        "Katya Scheinberg"^^schema:Person,
        "Lam M. Nguyen"^^schema:Person,
        "Martin Takáč"^^schema:Person ;
    schema:commentCount "171"^^schema:Integer ;
    schema:dateModified "2017-06-03T07:30:20Z"^^schema:DateTime ;
    schema:datePublished "2017-03-01T02:08:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "SARAH: A Novel Method for Machine Learning Problems Using Stochastic  Recursive Gradient"^^schema:Text ;
    schema:publisher "ICML, 2613-2621"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00102v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15168434346098746144&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<34> a schema:ScholarlyArticle ;
    schema:abstract "Matching two texts is a fundamental problem in many natural languageprocessing tasks. An effective way is to extract meaningful matching patternsfrom words, phrases, and sentences to produce the matching score. Inspired bythe success of convolutional neural network in image recognition, where neuronscan capture many complicated patterns based on the extracted elementary visualpatterns such as oriented edges and corners, we propose to model text matchingas the problem of image recognition. Firstly, a matching matrix whose entriesrepresent the similarities between words is constructed and viewed as an image.Then a convolutional neural network is utilized to capture rich matchingpatterns in a layer-by-layer way. We show that by resembling the compositionalhierarchies of patterns in image recognition, our model can successfullyidentify salient signals such as n-gram and n-term matchings. Experimentalresults demonstrate its superiority against the baselines."^^schema:Text ;
    schema:author "Jiafeng Guo"^^schema:Person,
        "Jun Xu"^^schema:Person,
        "Liang Pang"^^schema:Person,
        "Shengxian Wan"^^schema:Person,
        "Xueqi Cheng"^^schema:Person,
        "Yanyan Lan"^^schema:Person ;
    schema:commentCount "245"^^schema:Integer ;
    schema:dateModified "2016-02-20T02:55:11Z"^^schema:DateTime ;
    schema:datePublished "2016-02-20T02:55:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Text Matching as Image Recognition"^^schema:Text ;
    schema:publisher "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.06359v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2007424235086924671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<340> a schema:ScholarlyArticle ;
    schema:abstract "Recent work has shown local convergence of GAN training for absolutelycontinuous data and generator distributions. In this paper, we show that therequirement of absolute continuity is necessary: we describe a simple yetprototypical counterexample showing that in the more realistic case ofdistributions that are not absolutely continuous, unregularized GAN training isnot always convergent. Furthermore, we discuss regularization strategies thatwere recently proposed to stabilize GAN training. Our analysis shows that GANtraining with instance noise or zero-centered gradient penalties converges. Onthe other hand, we show that Wasserstein-GANs and WGAN-GP with a finite numberof discriminator updates per generator update do not always converge to theequilibrium point. We discuss these results, leading us to a new explanationfor the stability problems of GAN training. Based on our analysis, we extendour convergence results to more general GANs and prove local convergence forsimplified gradient penalties even if the generator and data distribution lieon lower dimensional manifolds. We find these penalties to work well inpractice and use them to learn high-resolution generative image models for avariety of datasets with little hyperparameter tuning."^^schema:Text ;
    schema:author "Andreas Geiger"^^schema:Person,
        "Lars Mescheder"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person ;
    schema:commentCount "304"^^schema:Integer ;
    schema:dateModified "2018-07-31T16:28:15Z"^^schema:DateTime ;
    schema:datePublished "2018-01-13T09:42:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.GT"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Which Training Methods for GANs do actually Converge?"^^schema:Text ;
    schema:publisher "ICML, 3478-3487"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.04406v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11334901664651510839&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<341> a schema:ScholarlyArticle ;
    schema:abstract "Traditional dialog systems used in goal-oriented applications require a lotof domain-specific handcrafting, which hinders scaling up to new domains.End-to-end dialog systems, in which all components are trained from the dialogsthemselves, escape this limitation. But the encouraging success recentlyobtained in chit-chat dialog may not carry over to goal-oriented settings. Thispaper proposes a testbed to break down the strengths and shortcomings ofend-to-end dialog systems in goal-oriented applications. Set in the context ofrestaurant reservation, our tasks require manipulating sentences and symbols,so as to properly conduct conversations, issue API calls and use the outputs ofsuch calls. We show that an end-to-end dialog system based on Memory Networkscan reach promising, yet imperfect, performance and learn to performnon-trivial operations. We confirm those results by comparing our system to ahand-crafted slot-filling baseline on data from the second Dialog StateTracking Challenge (Henderson et al., 2014a). We show similar result patternson data extracted from an online concierge service."^^schema:Text ;
    schema:author "Antoine Bordes"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Y-Lan Boureau"^^schema:Person ;
    schema:commentCount "504"^^schema:Integer ;
    schema:dateModified "2017-03-30T23:02:22Z"^^schema:DateTime ;
    schema:datePublished "2016-05-24T23:09:58Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Learning End-to-End Goal-Oriented Dialog"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07683v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14624523216814088198&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<342> a schema:ScholarlyArticle ;
    schema:abstract "Large CNNs have delivered impressive performance in various computer visionapplications. But the storage and computation requirements make it problematicfor deploying these models on mobile devices. Recently, tensor decompositionshave been used for speeding up CNNs. In this paper, we further develop thetensor decomposition technique. We propose a new algorithm for computing thelow-rank tensor decomposition for removing the redundancy in the convolutionkernels. The algorithm finds the exact global optimizer of the decompositionand is more effective than iterative methods. Based on the decomposition, wefurther propose a new method for training low-rank constrained CNNs fromscratch. Interestingly, while achieving a significant speedup, sometimes thelow-rank constrained CNNs delivers significantly better performance than theirnon-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rankNIN model achieves $91.31\\%$ accuracy (without data augmentation), which alsoimproves upon state-of-the-art result. We evaluated the proposed method onCIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 isreduced by half while the performance is still comparable. Empirical successsuggests that low-rank tensor decompositions can be a very useful tool forspeeding up large CNNs."^^schema:Text ;
    schema:author "Cheng Tai"^^schema:Person,
        "Tong Xiao"^^schema:Person,
        "Weinan E"^^schema:Person,
        "Xiaogang Wang"^^schema:Person,
        "Yi Zhang"^^schema:Person ;
    schema:commentCount "236"^^schema:Integer ;
    schema:dateModified "2016-02-14T03:46:09Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T06:13:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Convolutional neural networks with low-rank regularization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06067v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=21602892819366205&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<343> a schema:ScholarlyArticle ;
    schema:abstract "Recent work has demonstrated that deep neural networks are vulnerable toadversarial examples---inputs that are almost indistinguishable from naturaldata and yet classified incorrectly by the network. In fact, some of the latestfindings suggest that the existence of adversarial attacks may be an inherentweakness of deep learning models. To address this problem, we study theadversarial robustness of neural networks through the lens of robustoptimization. This approach provides us with a broad and unifying view on muchof the prior work on this topic. Its principled nature also enables us toidentify methods for both training and attacking neural networks that arereliable and, in a certain sense, universal. In particular, they specify aconcrete security guarantee that would protect against any adversary. Thesemethods let us train networks with significantly improved resistance to a widerange of adversarial attacks. They also suggest the notion of security againsta first-order adversary as a natural and broad security guarantee. We believethat robustness against such well-defined classes of adversaries is animportant stepping stone towards fully resistant deep learning models. Code andpre-trained models are available at https://github.com/MadryLab/mnist_challengeand https://github.com/MadryLab/cifar10_challenge."^^schema:Text ;
    schema:author "Adrian Vladu"^^schema:Person,
        "Aleksandar Makelov"^^schema:Person,
        "Aleksander Madry"^^schema:Person,
        "Dimitris Tsipras"^^schema:Person,
        "Ludwig Schmidt"^^schema:Person ;
    schema:commentCount "1791"^^schema:Integer ;
    schema:dateModified "2019-09-04T18:53:10Z"^^schema:DateTime ;
    schema:datePublished "2017-06-19T17:53:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Deep Learning Models Resistant to Adversarial Attacks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.06083v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14165082781627851489&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<344> a schema:ScholarlyArticle ;
    schema:abstract "Advances in deep reinforcement learning have allowed autonomous agents toperform well on Atari games, often outperforming humans, using only raw pixelsto make their decisions. However, most of these games take place in 2Denvironments that are fully observable to the agent. In this paper, we presentthe first architecture to tackle 3D environments in first-person shooter games,that involve partially observable states. Typically, deep reinforcementlearning methods only utilize visual input for training. We present a method toaugment these models to exploit game feature information such as the presenceof enemies or items, during the training phase. Our model is trained tosimultaneously learn these features along with minimizing a Q-learningobjective, which is shown to dramatically improve the training speed andperformance of our agent. Our architecture is also modularized to allowdifferent models to be independently trained for different phases of the game.We show that the proposed architecture substantially outperforms built-in AIagents of the game as well as humans in deathmatch scenarios."^^schema:Text ;
    schema:author "Devendra Singh Chaplot"^^schema:Person,
        "Guillaume Lample"^^schema:Person ;
    schema:commentCount "306"^^schema:Integer ;
    schema:dateModified "2018-01-29T15:13:59Z"^^schema:DateTime ;
    schema:datePublished "2016-09-18T17:52:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Playing FPS Games with Deep Reinforcement Learning"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.05521v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11485614925940495388&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<345> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, supervised learning with convolutional networks (CNNs) hasseen huge adoption in computer vision applications. Comparatively, unsupervisedlearning with CNNs has received less attention. In this work we hope to helpbridge the gap between the success of CNNs for supervised learning andunsupervised learning. We introduce a class of CNNs called deep convolutionalgenerative adversarial networks (DCGANs), that have certain architecturalconstraints, and demonstrate that they are a strong candidate for unsupervisedlearning. Training on various image datasets, we show convincing evidence thatour deep convolutional adversarial pair learns a hierarchy of representationsfrom object parts to scenes in both the generator and discriminator.Additionally, we use the learned features for novel tasks - demonstrating theirapplicability as general image representations."^^schema:Text ;
    schema:author "Alec Radford"^^schema:Person,
        "Luke Metz"^^schema:Person,
        "Soumith Chintala"^^schema:Person ;
    schema:commentCount "6544"^^schema:Integer ;
    schema:dateModified "2016-01-07T23:09:39Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T22:50:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Representation Learning with Deep Convolutional Generative  Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06434v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3321343160055675528&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<346> a schema:ScholarlyArticle ;
    schema:abstract "Ongoing innovations in recurrent neural network architectures have provided asteady influx of apparently state-of-the-art results on language modellingbenchmarks. However, these have been evaluated using differing code bases andlimited computational resources, which represent uncontrolled sources ofexperimental variation. We reevaluate several popular architectures andregularisation methods with large-scale automatic black-box hyperparametertuning and arrive at the somewhat surprising conclusion that standard LSTMarchitectures, when properly regularised, outperform more recent models. Weestablish a new state of the art on the Penn Treebank and Wikitext-2 corpora,as well as strong baselines on the Hutter Prize dataset."^^schema:Text ;
    schema:author "Chris Dyer"^^schema:Person,
        "Gábor Melis"^^schema:Person,
        "Phil Blunsom"^^schema:Person ;
    schema:commentCount "271"^^schema:Integer ;
    schema:dateModified "2017-11-20T17:57:58Z"^^schema:DateTime ;
    schema:datePublished "2017-07-18T12:35:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "On the State of the Art of Evaluation in Neural Language Models"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.05589v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10520579957359692654&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<347> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3Dvideos to segment them. They have a fixed input size and typically perceiveonly small local contexts of the pixels to be classified as foreground orbackground. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceivethe entire spatio-temporal context of each pixel in a few sweeps through allpixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despitethese theoretical advantages, however, unlike CNNs, previous MD-LSTM variantswere hard to parallelize on GPUs. Here we re-arrange the traditional cuboidorder of computations in MD-LSTM in pyramidal fashion. The resultingPyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks ofbrain slice images. PyraMiD-LSTM achieved best known pixel-wise brain imagesegmentation results on MRBrainS13 (and competitive results on EM-ISBI12)."^^schema:Text ;
    schema:author "Juergen Schmidhuber"^^schema:Person,
        "Marcus Liwicki"^^schema:Person,
        "Marijn F. Stollenga"^^schema:Person,
        "Wonmin Byeon"^^schema:Person ;
    schema:commentCount "219"^^schema:Integer ;
    schema:dateModified "2015-06-24T16:26:51Z"^^schema:DateTime ;
    schema:datePublished "2015-06-24T16:26:51Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical  Volumetric Image Segmentation"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.07452v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3236346698623785406&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<348> a schema:ScholarlyArticle ;
    schema:abstract "With the success of new computational architectures for visual processing,such as convolutional neural networks (CNN) and access to image databases withmillions of labeled examples (e.g., ImageNet, Places), the state of the art incomputer vision is advancing rapidly. One important factor for continuedprogress is to understand the representations that are learned by the innerlayers of these deep architectures. Here we show that object detectors emergefrom training CNNs to perform scene classification. As scenes are composed ofobjects, the CNN for scene classification automatically discovers meaningfulobjects detectors, representative of the learned scene categories. With objectdetectors emerging as a result of learning to recognize scenes, our workdemonstrates that the same network can perform both scene recognition andobject localization in a single forward-pass, without ever having beenexplicitly taught the notion of objects."^^schema:Text ;
    schema:author "Aditya Khosla"^^schema:Person,
        "Agata Lapedriza"^^schema:Person,
        "Antonio Torralba"^^schema:Person,
        "Aude Oliva"^^schema:Person,
        "Bolei Zhou"^^schema:Person ;
    schema:commentCount "736"^^schema:Integer ;
    schema:dateModified "2015-04-15T19:06:41Z"^^schema:DateTime ;
    schema:datePublished "2014-12-22T01:14:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Object Detectors Emerge in Deep Scene CNNs"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6856v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=889391300182990037&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<349> a schema:ScholarlyArticle ;
    schema:abstract "Deep networks have been successfully applied to learn transferable featuresfor adapting models from a source domain to a different target domain. In thispaper, we present joint adaptation networks (JAN), which learn a transfernetwork by aligning the joint distributions of multiple domain-specific layersacross domains based on a joint maximum mean discrepancy (JMMD) criterion.Adversarial training strategy is adopted to maximize JMMD such that thedistributions of the source and target domains are made more distinguishable.Learning can be performed by stochastic gradient descent with the gradientscomputed by back-propagation in linear-time. Experiments testify that our modelyields state of the art results on standard datasets."^^schema:Text ;
    schema:author "Han Zhu"^^schema:Person,
        "Jianmin Wang"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Mingsheng Long"^^schema:Person ;
    schema:commentCount "595"^^schema:Integer ;
    schema:dateModified "2017-08-17T07:35:59Z"^^schema:DateTime ;
    schema:datePublished "2016-05-21T12:56:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Transfer Learning with Joint Adaptation Networks"^^schema:Text ;
    schema:publisher "ICML, 2208-2217"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06636v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3758970819381872485&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<35> a schema:ScholarlyArticle ;
    schema:abstract "While most approaches to automatically recognizing entailment relations haveused classifiers employing hand engineered features derived from complexnatural language processing pipelines, in practice their performance has beenonly slightly better than bag-of-word pair classifiers using only lexicalsimilarity. The only attempt so far to build an end-to-end differentiableneural network for entailment failed to outperform such a simple similarityclassifier. In this paper, we propose a neural model that reads two sentencesto determine entailment using long short-term memory units. We extend thismodel with a word-by-word neural attention mechanism that encourages reasoningover entailments of pairs of words and phrases. Furthermore, we present aqualitative analysis of attention weights produced by this model, demonstratingsuch reasoning capabilities. On a large entailment dataset this modeloutperforms the previous best neural model and a classifier with engineeredfeatures by a substantial margin. It is the first generic end-to-enddifferentiable system that achieves state-of-the-art accuracy on a textualentailment dataset."^^schema:Text ;
    schema:author "Edward Grefenstette"^^schema:Person,
        "Karl Moritz Hermann"^^schema:Person,
        "Phil Blunsom"^^schema:Person,
        "Tim Rocktäschel"^^schema:Person,
        "Tomáš Kočiský"^^schema:Person ;
    schema:commentCount "582"^^schema:Integer ;
    schema:dateModified "2016-03-01T10:32:06Z"^^schema:DateTime ;
    schema:datePublished "2015-09-22T16:08:24Z"^^schema:DateTime ;
    schema:genre "68T50"^^schema:Text,
        "I.2.6; I.2.7"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Reasoning about Entailment with Neural Attention"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.06664v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11797670977640238669&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<350> a schema:ScholarlyArticle ;
    schema:abstract "Attentional, RNN-based encoder-decoder models for abstractive summarizationhave achieved good performance on short input and output sequences. For longerdocuments and summaries however these models often include repetitive andincoherent phrases. We introduce a neural network model with a novelintra-attention that attends over the input and continuously generated outputseparately, and a new training method that combines standard supervised wordprediction and reinforcement learning (RL). Models trained only with supervisedlearning often exhibit \"exposure bias\" - they assume ground truth is providedat each step during training. However, when standard word prediction iscombined with the global sequence prediction training of RL the resultingsummaries become more readable. We evaluate this model on the CNN/Daily Mailand New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on theCNN/Daily Mail dataset, an improvement over previous state-of-the-art models.Human evaluation also shows that our model produces higher quality summaries."^^schema:Text ;
    schema:author "Caiming Xiong"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Romain Paulus"^^schema:Person ;
    schema:commentCount "641"^^schema:Integer ;
    schema:dateModified "2017-11-13T20:11:26Z"^^schema:DateTime ;
    schema:datePublished "2017-05-11T17:39:35Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "A Deep Reinforced Model for Abstractive Summarization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.04304v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=439043726958667778&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<351> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a general-purpose conditioning method for neural networks calledFiLM: Feature-wise Linear Modulation. FiLM layers influence neural networkcomputation via a simple, feature-wise affine transformation based onconditioning information. We show that FiLM layers are highly effective forvisual reasoning - answering image-related questions which require amulti-step, high-level process - a task which has proven difficult for standarddeep learning methods that do not explicitly model reasoning. Specifically, weshow on visual reasoning tasks that FiLM layers 1) halve state-of-the-art errorfor the CLEVR benchmark, 2) modulate features in a coherent manner, 3) arerobust to ablations and architectural modifications, and 4) generalize well tochallenging, new data from few examples or even zero-shot."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Ethan Perez"^^schema:Person,
        "Florian Strub"^^schema:Person,
        "Harm de Vries"^^schema:Person,
        "Vincent Dumoulin"^^schema:Person ;
    schema:commentCount "327"^^schema:Integer ;
    schema:dateModified "2017-12-18T21:25:53Z"^^schema:DateTime ;
    schema:datePublished "2017-09-22T17:54:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "FiLM: Visual Reasoning with a General Conditioning Layer"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.07871v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14710363985853844282&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<352> a schema:ScholarlyArticle ;
    schema:abstract "Learning to predict future images from a video sequence involves theconstruction of an internal representation that models the image evolutionaccurately, and therefore, to some degree, its content and dynamics. This iswhy pixel-space video prediction may be viewed as a promising avenue forunsupervised feature learning. In addition, while optical flow has been a verystudied problem in computer vision for a long time, future frame prediction israrely approached. Still, many vision applications could benefit from theknowledge of the next frames of videos, that does not require the complexity oftracking every pixel trajectories. In this work, we train a convolutionalnetwork to generate future frames given an input sequence. To deal with theinherently blurry predictions obtained from the standard Mean Squared Error(MSE) loss function, we propose three different and complementary featurelearning strategies: a multi-scale architecture, an adversarial trainingmethod, and an image gradient difference loss function. We compare ourpredictions to different published results based on recurrent neural networkson the UCF101 dataset"^^schema:Text ;
    schema:author "Camille Couprie"^^schema:Person,
        "Michael Mathieu"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "1072"^^schema:Integer ;
    schema:dateModified "2016-02-26T22:10:30Z"^^schema:DateTime ;
    schema:datePublished "2015-11-17T15:36:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep multi-scale video prediction beyond mean square error"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05440v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2726105701998692678&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<353> a schema:ScholarlyArticle ;
    schema:abstract "Cooperative multi-agent systems can be naturally used to model many realworld problems, such as network packet routing and the coordination ofautonomous vehicles. There is a great need for new reinforcement learningmethods that can efficiently learn decentralised policies for such systems. Tothis end, we propose a new multi-agent actor-critic method calledcounterfactual multi-agent (COMA) policy gradients. COMA uses a centralisedcritic to estimate the Q-function and decentralised actors to optimise theagents' policies. In addition, to address the challenges of multi-agent creditassignment, it uses a counterfactual baseline that marginalises out a singleagent's action, while keeping the other agents' actions fixed. COMA also uses acritic representation that allows the counterfactual baseline to be computedefficiently in a single forward pass. We evaluate COMA in the testbed ofStarCraft unit micromanagement, using a decentralised variant with significantpartial observability. COMA significantly improves average performance overother multi-agent actor-critic methods in this setting, and the best performingagents are competitive with state-of-the-art centralised controllers that getaccess to the full state."^^schema:Text ;
    schema:author "Gregory Farquhar"^^schema:Person,
        "Jakob Foerster"^^schema:Person,
        "Nantas Nardelli"^^schema:Person,
        "Shimon Whiteson"^^schema:Person,
        "Triantafyllos Afouras"^^schema:Person ;
    schema:commentCount "404"^^schema:Integer ;
    schema:dateModified "2017-12-14T14:50:34Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T18:52:17Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Counterfactual Multi-Agent Policy Gradients"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08926v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2943188170099558937&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<354> a schema:ScholarlyArticle ;
    schema:abstract "An emerging design principle in deep learning is that each layer of a deepartificial neural network should be able to easily express the identitytransformation. This idea not only motivated various normalization techniques,such as \\emph{batch normalization}, but was also key to the immense success of\\emph{residual networks}.  In this work, we put the principle of \\emph{identity parameterization} on amore solid theoretical footing alongside further empirical progress. We firstgive a strikingly simple proof that arbitrarily deep linear residual networkshave no spurious local optima. The same result for linear feed-forward networksin their standard parameterization is substantially more delicate. Second, weshow that residual networks with ReLu activations have universal finite-sampleexpressivity in the sense that the network can represent any function of itssample provided that the model has more parameters than the sample size.  Directly inspired by our theory, we experiment with a radically simpleresidual architecture consisting of only residual convolutional layers and ReLuactivations, but no batch normalization, dropout, or max pool. Our modelimproves significantly on previous all-convolutional networks on the CIFAR10,CIFAR100, and ImageNet classification benchmarks."^^schema:Text ;
    schema:author "Moritz Hardt"^^schema:Person,
        "Tengyu Ma"^^schema:Person ;
    schema:commentCount "207"^^schema:Integer ;
    schema:dateModified "2018-07-20T04:38:23Z"^^schema:DateTime ;
    schema:datePublished "2016-11-14T02:44:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Identity Matters in Deep Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.04231v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13607975019730988794&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<355> a schema:ScholarlyArticle ;
    schema:abstract "We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence modelfor extractive summarization of documents and show that it achieves performancebetter than or comparable to state-of-the-art. Our model has the additionaladvantage of being very interpretable, since it allows visualization of itspredictions broken up by abstract features such as information content,salience and novelty. Another novel contribution of our work is abstractivetraining of our extractive model that can train on human generated referencesummaries alone, eliminating the need for sentence-level extractive labels."^^schema:Text ;
    schema:author "Bowen Zhou"^^schema:Person,
        "Feifei Zhai"^^schema:Person,
        "Ramesh Nallapati"^^schema:Person ;
    schema:commentCount "430"^^schema:Integer ;
    schema:dateModified "2016-11-14T02:44:14Z"^^schema:DateTime ;
    schema:datePublished "2016-11-14T02:44:14Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "SummaRuNNer: A Recurrent Neural Network based Sequence Model for  Extractive Summarization of Documents"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.04230v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15743603261336170924&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<356> a schema:ScholarlyArticle ;
    schema:abstract "We systematically explore regularizing neural networks by penalizing lowentropy output distributions. We show that penalizing low entropy outputdistributions, which has been shown to improve exploration in reinforcementlearning, acts as a strong regularizer in supervised learning. Furthermore, weconnect a maximum entropy based confidence penalty to label smoothing throughthe direction of the KL divergence. We exhaustively evaluate the proposedconfidence penalty and label smoothing on 6 common benchmarks: imageclassification (MNIST and Cifar-10), language modeling (Penn Treebank), machinetranslation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ).We find that both label smoothing and the confidence penalty improvestate-of-the-art models across benchmarks without modifying existinghyperparameters, suggesting the wide applicability of these regularizers."^^schema:Text ;
    schema:author "Gabriel Pereyra"^^schema:Person,
        "Geoffrey Hinton"^^schema:Person,
        "George Tucker"^^schema:Person,
        "Jan Chorowski"^^schema:Person,
        "Łukasz Kaiser"^^schema:Person ;
    schema:commentCount "332"^^schema:Integer ;
    schema:dateModified "2017-01-23T18:35:28Z"^^schema:DateTime ;
    schema:datePublished "2017-01-23T18:35:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Regularizing Neural Networks by Penalizing Confident Output  Distributions"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.06548v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17169779076640319067&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<357> a schema:ScholarlyArticle ;
    schema:abstract "We decompose the evidence lower bound to show the existence of a termmeasuring the total correlation between latent variables. We use this tomotivate our $\\beta$-TCVAE (Total Correlation Variational Autoencoder), arefinement of the state-of-the-art $\\beta$-VAE objective for learningdisentangled representations, requiring no additional hyperparameters duringtraining. We further propose a principled classifier-free measure ofdisentanglement called the mutual information gap (MIG). We perform extensivequantitative and qualitative experiments, in both restricted and non-restrictedsettings, and show a strong relation between total correlation anddisentanglement, when the latent variables model is trained using ourframework."^^schema:Text ;
    schema:author "David Duvenaud"^^schema:Person,
        "Ricky T. Q. Chen"^^schema:Person,
        "Roger Grosse"^^schema:Person,
        "Xuechen Li"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2019-04-23T17:20:14Z"^^schema:DateTime ;
    schema:datePublished "2018-02-14T03:48:06Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Isolating Sources of Disentanglement in Variational Autoencoders"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.04942v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11372263911361899725&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<358> a schema:ScholarlyArticle ;
    schema:abstract "We describe an approach for unsupervised learning of a generic, distributedsentence encoder. Using the continuity of text from books, we train anencoder-decoder model that tries to reconstruct the surrounding sentences of anencoded passage. Sentences that share semantic and syntactic properties arethus mapped to similar vector representations. We next introduce a simplevocabulary expansion method to encode words that were not seen as part oftraining, allowing us to expand our vocabulary to a million words. Aftertraining our model, we extract and evaluate our vectors with linear models on 8tasks: semantic relatedness, paraphrase detection, image-sentence ranking,question-type classification and 4 benchmark sentiment and subjectivitydatasets. The end result is an off-the-shelf encoder that can produce highlygeneric sentence representations that are robust and perform well in practice.We will make our encoder publicly available."^^schema:Text ;
    schema:author "Antonio Torralba"^^schema:Person,
        "Raquel Urtasun"^^schema:Person,
        "Richard S. Zemel"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Ryan Kiros"^^schema:Person,
        "Sanja Fidler"^^schema:Person,
        "Yukun Zhu"^^schema:Person ;
    schema:commentCount "1734"^^schema:Integer ;
    schema:dateModified "2015-06-22T19:33:40Z"^^schema:DateTime ;
    schema:datePublished "2015-06-22T19:33:40Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Skip-Thought Vectors"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.06726v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10194299428367499234&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<359> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, deep neural network approaches have been widely adopted formachine learning tasks, including classification. However, they were shown tobe vulnerable to adversarial perturbations: carefully crafted smallperturbations can cause misclassification of legitimate images. We proposeDefense-GAN, a new framework leveraging the expressive capability of generativemodels to defend deep neural networks against such attacks. Defense-GAN istrained to model the distribution of unperturbed images. At inference time, itfinds a close output to a given image which does not contain the adversarialchanges. This output is then fed to the classifier. Our proposed method can beused with any classification model and does not modify the classifier structureor training procedure. It can also be used as a defense against any attack asit does not assume knowledge of the process for generating the adversarialexamples. We empirically show that Defense-GAN is consistently effectiveagainst different attack methods and improves on existing defense strategies.Our code has been made publicly available athttps://github.com/kabkabm/defensegan"^^schema:Text ;
    schema:author "Maya Kabkab"^^schema:Person,
        "Pouya Samangouei"^^schema:Person,
        "Rama Chellappa"^^schema:Person ;
    schema:commentCount "403"^^schema:Integer ;
    schema:dateModified "2018-05-18T00:20:52Z"^^schema:DateTime ;
    schema:datePublished "2018-05-17T05:38:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using  Generative Models"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.06605v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4356922002684962280&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<36> a schema:ScholarlyArticle ;
    schema:abstract "This paper provides an extensive study on the availability of imagerepresentations based on convolutional networks (ConvNets) for the task ofvisual instance retrieval. Besides the choice of convolutional layers, wepresent an efficient pipeline exploiting multi-scale schemes to extract localfeatures, in particular, by taking geometric invariance into explicit account,i.e. positions, scales and spatial consistency. In our experiments using fivestandard image retrieval datasets, we demonstrate that generic ConvNet imagerepresentations can outperform other state-of-the-art methods if they areextracted appropriately."^^schema:Text ;
    schema:author "Ali Sharif Razavian"^^schema:Person,
        "Atsuto Maki"^^schema:Person,
        "Josephine Sullivan"^^schema:Person,
        "Stefan Carlsson"^^schema:Person ;
    schema:commentCount "306"^^schema:Integer ;
    schema:dateModified "2016-05-09T08:54:31Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T01:32:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Visual Instance Retrieval with Deep Convolutional Networks"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6574v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15265580461229792889&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<360> a schema:ScholarlyArticle ;
    schema:abstract "Many problems in real-world applications involve predicting several randomvariables which are statistically related. Markov random fields (MRFs) are agreat mathematical tool to encode such relationships. The goal of this paper isto combine MRFs with deep learning algorithms to estimate complexrepresentations while taking into account the dependencies between the outputrandom variables. Towards this goal, we propose a training algorithm that isable to learn structured models jointly with deep features that form the MRFpotentials. Our approach is efficient as it blends learning and inference andmakes use of GPU acceleration. We demonstrate the effectiveness of ouralgorithm in the tasks of predicting words from noisy images, as well asmulti-class classification of Flickr photographs. We show that joint learningof the deep features and the MRF parameters results in significant performancegains."^^schema:Text ;
    schema:author "Alan L. Yuille"^^schema:Person,
        "Alexander G. Schwing"^^schema:Person,
        "Liang-Chieh Chen"^^schema:Person,
        "Raquel Urtasun"^^schema:Person ;
    schema:commentCount "212"^^schema:Integer ;
    schema:dateModified "2015-04-27T21:11:32Z"^^schema:DateTime ;
    schema:datePublished "2014-07-09T15:54:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Learning Deep Structured Models"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1407.2538v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4006467637565747418&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<361> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial examples are perturbed inputs designed to fool machine learningmodels. Adversarial training injects such examples into training data toincrease robustness. To scale this technique to large datasets, perturbationsare crafted using fast single-step methods that maximize a linear approximationof the model's loss. We show that this form of adversarial training convergesto a degenerate global minimum, wherein small curvature artifacts near the datapoints obfuscate a linear approximation of the loss. The model thus learns togenerate weak perturbations, rather than defend against strong ones. As aresult, we find that adversarial training remains vulnerable to black-boxattacks, where we transfer perturbations computed on undefended models, as wellas to a powerful novel single-step attack that escapes the non-smooth vicinityof the input data via a small random step. We further introduce EnsembleAdversarial Training, a technique that augments training data withperturbations transferred from other models. On ImageNet, Ensemble AdversarialTraining yields models with strong robustness to black-box attacks. Inparticular, our most robust model won the first round of the NIPS 2017competition on Defenses against Adversarial Attacks. However, subsequent workfound that more elaborate black-box attacks could significantly enhancetransferability and reduce the accuracy of our models."^^schema:Text ;
    schema:author "Alexey Kurakin"^^schema:Person,
        "Dan Boneh"^^schema:Person,
        "Florian Tramèr"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Nicolas Papernot"^^schema:Person,
        "Patrick McDaniel"^^schema:Person ;
    schema:commentCount "832"^^schema:Integer ;
    schema:dateModified "2020-04-26T22:20:25Z"^^schema:DateTime ;
    schema:datePublished "2017-05-19T21:56:43Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Ensemble Adversarial Training: Attacks and Defenses"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.07204v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10511209374384426640&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<362> a schema:ScholarlyArticle ;
    schema:abstract "We consider the fundamental problem in non-convex optimization of efficientlyreaching a stationary point. In contrast to the convex case, in the longhistory of this basic problem, the only known theoretical results onfirst-order non-convex optimization remain to be full gradient descent thatconverges in $O(1/\\varepsilon)$ iterations for smooth objectives, andstochastic gradient descent that converges in $O(1/\\varepsilon^2)$ iterationsfor objectives that are sum of smooth functions.  We provide the first improvement in this line of research. Our result isbased on the variance reduction trick recently introduced to convexoptimization, as well as a brand new analysis of variance reduction that issuitable for non-convex optimization. For objectives that are sum of smoothfunctions, our first-order minibatch stochastic method converges with an$O(1/\\varepsilon)$ rate, and is faster than full gradient descent by$\\Omega(n^{1/3})$.  We demonstrate the effectiveness of our methods on empirical riskminimizations with non-convex loss functions and training neural nets."^^schema:Text ;
    schema:author "Elad Hazan"^^schema:Person,
        "Zeyuan Allen-Zhu"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2016-08-25T02:34:00Z"^^schema:DateTime ;
    schema:datePublished "2016-03-17T19:55:12Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variance Reduction for Faster Non-Convex Optimization"^^schema:Text ;
    schema:publisher "ICML, 699-707"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.05643v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16191703712221356547&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<363> a schema:ScholarlyArticle ;
    schema:abstract "An important problem for both graphics and vision is to synthesize novelviews of a 3D object from a single image. This is particularly challenging dueto the partial observability inherent in projecting a 3D object onto the imagespace, and the ill-posedness of inferring object shape and pose. However, wecan train a neural network to address the problem if we restrict our attentionto specific object categories (in our case faces and chairs) for which we cangather ample training data. In this paper, we propose a novel recurrentconvolutional encoder-decoder network that is trained end-to-end on the task ofrendering rotated objects starting from a single image. The recurrent structureallows our model to capture long-term dependencies along a sequence oftransformations. We demonstrate the quality of its predictions for human faceson the Multi-PIE dataset and for a dataset of 3D chair models, and also showits ability to disentangle latent factors of variation (e.g., identity andpose) without using full supervision."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Jimei Yang"^^schema:Person,
        "Ming-Hsuan Yang"^^schema:Person,
        "Scott Reed"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:dateModified "2016-01-05T00:08:09Z"^^schema:DateTime ;
    schema:datePublished "2016-01-05T00:08:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Weakly-supervised Disentangling with Recurrent Transformations for 3D  View Synthesis"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1601.00706v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9366321653656639999&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<364> a schema:ScholarlyArticle ;
    schema:abstract "We introduce BilBOWA (Bilingual Bag-of-Words without Alignments), a simpleand computationally-efficient model for learning bilingual distributedrepresentations of words which can scale to large monolingual datasets and doesnot require word-aligned parallel training data. Instead it trains directly onmonolingual data and extracts a bilingual signal from a smaller set of raw-textsentence-aligned data. This is achieved using a novel sampled bag-of-wordscross-lingual objective, which is used to regularize two noise-contrastivelanguage models for efficient cross-lingual feature learning. We show thatbilingual embeddings learned using the proposed model outperformstate-of-the-art methods on a cross-lingual document classification task aswell as a lexical translation task on WMT11 data."^^schema:Text ;
    schema:author "Greg Corrado"^^schema:Person,
        "Stephan Gouws"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "301"^^schema:Integer ;
    schema:dateModified "2016-02-04T05:51:59Z"^^schema:DateTime ;
    schema:datePublished "2014-10-09T13:41:18Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "BilBOWA: Fast Bilingual Distributed Representations without Word  Alignments"^^schema:Text ;
    schema:publisher "ICML, 748-756"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1410.2455v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2719170563629478824&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<365> a schema:ScholarlyArticle ;
    schema:abstract "Several machine learning models, including neural networks, consistentlymisclassify adversarial examples---inputs formed by applying small butintentionally worst-case perturbations to examples from the dataset, such thatthe perturbed input results in the model outputting an incorrect answer withhigh confidence. Early attempts at explaining this phenomenon focused onnonlinearity and overfitting. We argue instead that the primary cause of neuralnetworks' vulnerability to adversarial perturbation is their linear nature.This explanation is supported by new quantitative results while giving thefirst explanation of the most intriguing fact about them: their generalizationacross architectures and training sets. Moreover, this view yields a simple andfast method of generating adversarial examples. Using this approach to provideexamples for adversarial training, we reduce the test set error of a maxoutnetwork on the MNIST dataset."^^schema:Text ;
    schema:author "Christian Szegedy"^^schema:Person,
        "Ian J. Goodfellow"^^schema:Person,
        "Jonathon Shlens"^^schema:Person ;
    schema:commentCount "4827"^^schema:Integer ;
    schema:dateModified "2015-03-20T20:19:16Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T01:17:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Explaining and Harnessing Adversarial Examples"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6572v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14908107896544813002&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<366> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a method to stabilize Generative Adversarial Networks (GANs) bydefining the generator objective with respect to an unrolled optimization ofthe discriminator. This allows training to be adjusted between using theoptimal discriminator in the generator's objective, which is ideal butinfeasible in practice, and using the current value of the discriminator, whichis often unstable and leads to poor solutions. We show how this techniquesolves the common problem of mode collapse, stabilizes training of GANs withcomplex recurrent generators, and increases diversity and coverage of the datadistribution by the generator."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "David Pfau"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Luke Metz"^^schema:Person ;
    schema:commentCount "1012"^^schema:Integer ;
    schema:dateModified "2017-05-12T23:52:12Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T16:42:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unrolled Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02163v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14141685069487796752&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<367> a schema:ScholarlyArticle ;
    schema:abstract "Current work in lexical distributed representations maps each word to a pointvector in low-dimensional space. Mapping instead to a density provides manyinteresting advantages, including better capturing uncertainty about arepresentation and its relationships, expressing asymmetries more naturallythan dot product or cosine similarity, and enabling more expressiveparameterization of decision boundaries. This paper advocates for density-baseddistributed embeddings and presents a method for learning representations inthe space of Gaussian distributions. We compare performance on various wordembedding benchmarks, investigate the ability of these embeddings to modelentailment and other asymmetric relationships, and explore novel properties ofthe representation."^^schema:Text ;
    schema:author "Andrew McCallum"^^schema:Person,
        "Luke Vilnis"^^schema:Person ;
    schema:commentCount "234"^^schema:Integer ;
    schema:dateModified "2015-05-01T10:14:58Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T07:42:40Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Word Representations via Gaussian Embedding"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6623v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4128677461296445631&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<368> a schema:ScholarlyArticle ;
    schema:abstract "Most modern convolutional neural networks (CNNs) used for object recognitionare built using the same principles: Alternating convolution and max-poolinglayers followed by a small number of fully connected layers. We re-evaluate thestate of the art for object recognition from small images with convolutionalnetworks, questioning the necessity of different components in the pipeline. Wefind that max-pooling can simply be replaced by a convolutional layer withincreased stride without loss in accuracy on several image recognitionbenchmarks. Following this finding -- and building on other recent work forfinding simple network structures -- we propose a new architecture thatconsists solely of convolutional layers and yields competitive or state of theart performance on several object recognition datasets (CIFAR-10, CIFAR-100,ImageNet). To analyze the network we introduce a new variant of the\"deconvolution approach\" for visualizing features learned by CNNs, which can beapplied to a broader range of network structures than existing approaches."^^schema:Text ;
    schema:author "Alexey Dosovitskiy"^^schema:Person,
        "Jost Tobias Springenberg"^^schema:Person,
        "Martin Riedmiller"^^schema:Person,
        "Thomas Brox"^^schema:Person ;
    schema:commentCount "2175"^^schema:Integer ;
    schema:dateModified "2015-04-13T07:58:17Z"^^schema:DateTime ;
    schema:datePublished "2014-12-21T16:16:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Striving for Simplicity: The All Convolutional Net"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6806v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18200872134920294831&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<369> a schema:ScholarlyArticle ;
    schema:abstract "Reasoning about objects, relations, and physics is central to humanintelligence, and a key goal of artificial intelligence. Here we introduce theinteraction network, a model which can reason about how objects in complexsystems interact, supporting dynamical predictions, as well as inferences aboutthe abstract properties of the system. Our model takes graphs as input,performs object- and relation-centric reasoning in a way that is analogous to asimulation, and is implemented using deep neural networks. We evaluate itsability to reason about several challenging physical domains: n-body problems,rigid-body collision, and non-rigid dynamics. Our results show it can betrained to accurately simulate the physical trajectories of dozens of objectsover thousands of time steps, estimate abstract quantities such as energy, andgeneralize automatically to systems with different numbers and configurationsof objects and relations. Our interaction network implementation is the firstgeneral-purpose, learnable physics engine, and a powerful general framework forreasoning about object and relations in a wide variety of complex real-worlddomains."^^schema:Text ;
    schema:author "Danilo Rezende"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Matthew Lai"^^schema:Person,
        "Peter W. Battaglia"^^schema:Person,
        "Razvan Pascanu"^^schema:Person ;
    schema:commentCount "469"^^schema:Integer ;
    schema:dateModified "2016-12-01T12:34:54Z"^^schema:DateTime ;
    schema:datePublished "2016-12-01T12:34:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Interaction Networks for Learning about Objects, Relations and Physics"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.00222v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17057667931848922246&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<37> a schema:ScholarlyArticle ;
    schema:abstract "Gradient descent training techniques are remarkably successful in traininganalog-valued artificial neural networks (ANNs). Such training techniques,however, do not transfer easily to spiking networks due to the spike generationhard non-linearity and the discrete nature of spike communication. We show thatin a feedforward spiking network that uses a temporal coding scheme whereinformation is encoded in spike times instead of spike rates, the networkinput-output relation is differentiable almost everywhere. Moreover, thisrelation is piece-wise linear after a transformation of variables. Methods fortraining ANNs thus carry directly to the training of such spiking networks aswe show when training on the permutation invariant MNIST task. In contrast torate-based spiking networks that are often used to approximate the behavior ofANNs, the networks we present spike much more sparsely and their behavior cannot be directly approximated by conventional ANNs. Our results highlight a newapproach for controlling the behavior of spiking networks with realistictemporal dynamics, opening up the potential for using these networks to processspike patterns with complex temporal information."^^schema:Text ;
    schema:author "Hesham Mostafa"^^schema:Person ;
    schema:commentCount "112"^^schema:Integer ;
    schema:dateModified "2017-08-16T16:15:20Z"^^schema:DateTime ;
    schema:datePublished "2016-06-27T08:58:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Supervised learning based on temporal coding in spiking neural networks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (7), 3227-3235"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.08165v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11642829514204190384&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<370> a schema:ScholarlyArticle ;
    schema:abstract "Many interesting problems in machine learning are being revisited with newdeep learning tools. For graph-based semisupervised learning, a recentimportant development is graph convolutional networks (GCNs), which nicelyintegrate local vertex features and graph topology in the convolutional layers.Although the GCN model compares favorably with other state-of-the-art methods,its mechanisms are not clear and it still requires a considerable amount oflabeled data for validation and model selection. In this paper, we developdeeper insights into the GCN model and address its fundamental limits. First,we show that the graph convolution of the GCN model is actually a special formof Laplacian smoothing, which is the key reason why GCNs work, but it alsobrings potential concerns of over-smoothing with many convolutional layers.Second, to overcome the limits of the GCN model with shallow architectures, wepropose both co-training and self-training approaches to train GCNs. Ourapproaches significantly improve GCNs in learning with very few labels, andexempt them from requiring additional labels for validation. Extensiveexperiments on benchmarks have verified our theory and proposals."^^schema:Text ;
    schema:author "Qimai Li"^^schema:Person,
        "Xiao-Ming Wu"^^schema:Person,
        "Zhichao Han"^^schema:Person ;
    schema:commentCount "276"^^schema:Integer ;
    schema:dateModified "2018-01-22T15:24:24Z"^^schema:DateTime ;
    schema:datePublished "2018-01-22T15:24:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deeper Insights into Graph Convolutional Networks for Semi-Supervised  Learning"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.07606v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6910084038111478554&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<371> a schema:ScholarlyArticle ;
    schema:abstract "We propose coupled generative adversarial network (CoGAN) for learning ajoint distribution of multi-domain images. In contrast to the existingapproaches, which require tuples of corresponding images in different domainsin the training set, CoGAN can learn a joint distribution without any tuple ofcorresponding images. It can learn a joint distribution with just samples drawnfrom the marginal distributions. This is achieved by enforcing a weight-sharingconstraint that limits the network capacity and favors a joint distributionsolution over a product of marginal distributions one. We apply CoGAN toseveral joint distribution learning tasks, including learning a jointdistribution of color and depth images, and learning a joint distribution offace images with different attributes. For each task it successfully learns thejoint distribution without any tuple of corresponding images. We alsodemonstrate its applications to domain adaptation and image transformation."^^schema:Text ;
    schema:author "Ming-Yu Liu"^^schema:Person,
        "Oncel Tuzel"^^schema:Person ;
    schema:commentCount "844"^^schema:Integer ;
    schema:dateModified "2016-09-20T17:01:49Z"^^schema:DateTime ;
    schema:datePublished "2016-06-24T01:20:06Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Coupled Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.07536v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9131569704953326400&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<372> a schema:ScholarlyArticle ;
    schema:abstract "This paper introduces DeepBach, a graphical model aimed at modelingpolyphonic music and specifically hymn-like pieces. We claim that, after beingtrained on the chorale harmonizations by Johann Sebastian Bach, our model iscapable of generating highly convincing chorales in the style of Bach.DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with anadapted representation of musical data. This is in contrast with many automaticmusic composition approaches which tend to compose music sequentially. Ourmodel is also steerable in the sense that a user can constrain the generationby imposing positional constraints such as notes, rhythms or cadences in thegenerated score. We also provide a plugin on top of the MuseScore music editormaking the interaction with DeepBach easy to use."^^schema:Text ;
    schema:author "Frank Nielsen"^^schema:Person,
        "François Pachet"^^schema:Person,
        "Gaëtan Hadjeres"^^schema:Person ;
    schema:commentCount "188"^^schema:Integer ;
    schema:dateModified "2017-06-17T17:25:58Z"^^schema:DateTime ;
    schema:datePublished "2016-12-03T19:17:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.SD"^^schema:Text ;
    schema:headline "DeepBach: a Steerable Model for Bach Chorales Generation"^^schema:Text ;
    schema:publisher "ICML, 1362-1371"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.01010v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5309798703109779304&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<373> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new approach to the problem of optimizing autoencoders for lossyimage compression. New media formats, changing hardware technology, as well asdiverse requirements and content types create a need for compression algorithmswhich are more flexible than existing codecs. Autoencoders have the potentialto address this need, but are difficult to optimize directly due to theinherent non-differentiabilty of the compression loss. We here show thatminimal changes to the loss are sufficient to train deep autoencoderscompetitive with JPEG 2000 and outperforming recently proposed approaches basedon RNNs. Our network is furthermore computationally efficient thanks to asub-pixel architecture, which makes it suitable for high-resolution images.This is in contrast to previous work on autoencoders for compression usingcoarser approximations, shallower architectures, computationally expensivemethods, or focusing on small images."^^schema:Text ;
    schema:author "Andrew Cunningham"^^schema:Person,
        "Ferenc Huszár"^^schema:Person,
        "Lucas Theis"^^schema:Person,
        "Wenzhe Shi"^^schema:Person ;
    schema:commentCount "343"^^schema:Integer ;
    schema:dateModified "2017-03-01T17:13:47Z"^^schema:DateTime ;
    schema:datePublished "2017-03-01T17:13:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Lossy Image Compression with Compressive Autoencoders"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00395v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13226490013777095959&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<374> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we argue for the fundamental importance of the valuedistribution: the distribution of the random return received by a reinforcementlearning agent. This is in contrast to the common approach to reinforcementlearning which models the expectation of this return, or value. Although thereis an established body of literature studying the value distribution, thus farit has always been used for a specific purpose such as implementing risk-awarebehaviour. We begin with theoretical results in both the policy evaluation andcontrol settings, exposing a significant distributional instability in thelatter. We then use the distributional perspective to design a new algorithmwhich applies Bellman's equation to the learning of approximate valuedistributions. We evaluate our algorithm using the suite of games from theArcade Learning Environment. We obtain both state-of-the-art results andanecdotal evidence demonstrating the importance of the value distribution inapproximate reinforcement learning. Finally, we combine theoretical andempirical evidence to highlight the ways in which the value distributionimpacts learning in the approximate setting."^^schema:Text ;
    schema:author "Marc G. Bellemare"^^schema:Person,
        "Rémi Munos"^^schema:Person,
        "Will Dabney"^^schema:Person ;
    schema:commentCount "381"^^schema:Integer ;
    schema:dateModified "2017-07-21T13:21:54Z"^^schema:DateTime ;
    schema:datePublished "2017-07-21T13:21:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Distributional Perspective on Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 449-458"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.06887v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16746050446953182873&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<375> a schema:ScholarlyArticle ;
    schema:abstract "We propose a generative model for robust tensor factorization in the presenceof both missing data and outliers. The objective is to explicitly infer theunderlying low-CP-rank tensor capturing the global information and a sparsetensor capturing the local information (also considered as outliers), thusproviding the robust predictive distribution over missing entries. Thelow-CP-rank tensor is modeled by multilinear interactions between multiplelatent factors on which the column sparsity is enforced by a hierarchicalprior, while the sparse tensor is modeled by a hierarchical view of Student-$t$distribution that associates an individual hyperparameter with each elementindependently. For model learning, we develop an efficient closed-formvariational inference under a fully Bayesian treatment, which can effectivelyprevent the overfitting problem and scales linearly with data size. In contrastto existing related works, our method can perform model selection automaticallyand implicitly without need of tuning parameters. More specifically, it candiscover the groundtruth of CP rank and automatically adapt the sparsityinducing priors to various types of outliers. In addition, the tradeoff betweenthe low-rank approximation and the sparse representation can be optimized inthe sense of maximum model evidence. The extensive experiments and comparisonswith many state-of-the-art algorithms on both synthetic and real-world datasetsdemonstrate the superiorities of our method from several perspectives."^^schema:Text ;
    schema:author "Andrzej Cichocki"^^schema:Person,
        "Guoxu Zhou"^^schema:Person,
        "Liqing Zhang"^^schema:Person,
        "Qibin Zhao"^^schema:Person,
        "Shun-ichi Amari"^^schema:Person ;
    schema:commentCount "109"^^schema:Integer ;
    schema:dateModified "2015-04-16T05:36:23Z"^^schema:DateTime ;
    schema:datePublished "2014-10-09T08:50:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Bayesian Robust Tensor Factorization for Incomplete Multiway Data"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (4), 736-748"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1410.2386v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3736451354071696313&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<376> a schema:ScholarlyArticle ;
    schema:abstract "Many natural language processing applications use language models to generatetext. These models are typically trained to predict the next word in asequence, given the previous words and some context such as an image. However,at test time the model is expected to generate the entire sequence fromscratch. This discrepancy makes generation brittle, as errors may accumulatealong the way. We address this issue by proposing a novel sequence leveltraining algorithm that directly optimizes the metric used at test time, suchas BLEU or ROUGE. On three different tasks, our approach outperforms severalstrong baselines for greedy generation. The method is also competitive whenthese baselines employ beam search, while being several times faster."^^schema:Text ;
    schema:author "Marc'Aurelio Ranzato"^^schema:Person,
        "Michael Auli"^^schema:Person,
        "Sumit Chopra"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person ;
    schema:commentCount "822"^^schema:Integer ;
    schema:dateModified "2016-05-06T21:18:46Z"^^schema:DateTime ;
    schema:datePublished "2015-11-20T19:25:54Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Sequence Level Training with Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06732v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4877899442083611721&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<377> a schema:ScholarlyArticle ;
    schema:abstract "Sequential data often possesses a hierarchical structure with complexdependencies between subsequences, such as found between the utterances in adialogue. In an effort to model this kind of generative process, we propose aneural network-based generative architecture, with latent stochastic variablesthat span a variable number of time steps. We apply the proposed model to thetask of dialogue response generation and compare it with recent neural networkarchitectures. We evaluate the model performance through automatic evaluationmetrics and by carrying out a human evaluation. The experiments demonstratethat our model improves upon recently proposed models and that the latentvariables facilitate the generation of long outputs and maintain the context."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Alessandro Sordoni"^^schema:Person,
        "Iulian Vlad Serban"^^schema:Person,
        "Joelle Pineau"^^schema:Person,
        "Laurent Charlin"^^schema:Person,
        "Ryan Lowe"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "597"^^schema:Integer ;
    schema:dateModified "2016-06-14T02:21:04Z"^^schema:DateTime ;
    schema:datePublished "2016-05-19T17:59:02Z"^^schema:DateTime ;
    schema:genre "I.5.1; I.2.7"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A Hierarchical Latent Variable Encoder-Decoder Model for Generating  Dialogues"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06069v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7853689277795107592&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<378> a schema:ScholarlyArticle ;
    schema:abstract "Numerous important problems can be framed as learning from graph data. Wepropose a framework for learning convolutional neural networks for arbitrarygraphs. These graphs may be undirected, directed, and with both discrete andcontinuous node and edge attributes. Analogous to image-based convolutionalnetworks that operate on locally connected regions of the input, we present ageneral approach to extracting locally connected regions from graphs. Usingestablished benchmark data sets, we demonstrate that the learned featurerepresentations are competitive with state of the art graph kernels and thattheir computation is highly efficient."^^schema:Text ;
    schema:author "Konstantin Kutzkov"^^schema:Person,
        "Mathias Niepert"^^schema:Person,
        "Mohamed Ahmed"^^schema:Person ;
    schema:commentCount "870"^^schema:Integer ;
    schema:dateModified "2016-06-08T11:40:13Z"^^schema:DateTime ;
    schema:datePublished "2016-05-17T18:13:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Convolutional Neural Networks for Graphs"^^schema:Text ;
    schema:publisher "ICML, 2014-2023"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.05273v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9917957179670149192&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<379> a schema:ScholarlyArticle ;
    schema:abstract "The choice of activation functions in deep networks has a significant effecton the training dynamics and task performance. Currently, the most successfuland widely-used activation function is the Rectified Linear Unit (ReLU).Although various hand-designed alternatives to ReLU have been proposed, nonehave managed to replace it due to inconsistent gains. In this work, we proposeto leverage automatic search techniques to discover new activation functions.Using a combination of exhaustive and reinforcement learning-based search, wediscover multiple novel activation functions. We verify the effectiveness ofthe searches by conducting an empirical evaluation with the best discoveredactivation function. Our experiments show that the best discovered activationfunction, $f(x) = x \\cdot \\text{sigmoid}(\\beta x)$, which we name Swish, tendsto work better than ReLU on deeper models across a number of challengingdatasets. For example, simply replacing ReLUs with Swish units improves top-1classification accuracy on ImageNet by 0.9\\% for Mobile NASNet-A and 0.6\\% forInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make iteasy for practitioners to replace ReLUs with Swish units in any neural network."^^schema:Text ;
    schema:author "Barret Zoph"^^schema:Person,
        "Prajit Ramachandran"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "517"^^schema:Integer ;
    schema:dateModified "2017-10-27T17:45:21Z"^^schema:DateTime ;
    schema:datePublished "2017-10-16T18:05:45Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Searching for Activation Functions"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.05941v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=665017396840630897&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<38> a schema:ScholarlyArticle ;
    schema:abstract "This article offers an empirical exploration on the use of character-levelconvolutional networks (ConvNets) for text classification. We constructedseveral large-scale datasets to show that character-level convolutionalnetworks could achieve state-of-the-art or competitive results. Comparisons areoffered against traditional models such as bag of words, n-grams and theirTFIDF variants, and deep learning models such as word-based ConvNets andrecurrent neural networks."^^schema:Text ;
    schema:author "Junbo Zhao"^^schema:Person,
        "Xiang Zhang"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "2294"^^schema:Integer ;
    schema:dateModified "2016-04-04T02:34:30Z"^^schema:DateTime ;
    schema:datePublished "2015-09-04T22:31:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Character-level Convolutional Networks for Text Classification"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.01626v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5819400392657163601&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<380> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we propose a novel recurrent neural network (RNN) architecture.The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach ofstacking multiple recurrent layers by allowing and controlling signals flowingfrom upper recurrent layers to lower layers using a global gating unit for eachpair of layers. The recurrent signals exchanged between layers are gatedadaptively based on the previous hidden states and the current input. Weevaluated the proposed GF-RNN with different types of recurrent units, such astanh, long short-term memory and gated recurrent units, on the tasks ofcharacter-level language modeling and Python program evaluation. Our empiricalevaluation of different RNN units, revealed that in both tasks, the GF-RNNoutperforms the conventional approaches to build deep stacked RNNs. We suggestthat the improvement arises because the GF-RNN can adaptively assign differentlayers to different timescales and layer-to-layer interactions (including thetop-down ones which are not usually present in a stacked RNN) by learning togate these interactions."^^schema:Text ;
    schema:author "Caglar Gulcehre"^^schema:Person,
        "Junyoung Chung"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "553"^^schema:Integer ;
    schema:dateModified "2015-06-17T06:26:21Z"^^schema:DateTime ;
    schema:datePublished "2015-02-09T05:25:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gated Feedback Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 2067-2075"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02367v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9646941875979474208&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<381> a schema:ScholarlyArticle ;
    schema:abstract "One of the challenges in modeling cognitive events from electroencephalogram(EEG) data is finding representations that are invariant to inter- andintra-subject differences, as well as to inherent noise associated with suchdata. Herein, we propose a novel approach for learning such representationsfrom multi-channel EEG time-series, and demonstrate its advantages in thecontext of mental load classification task. First, we transform EEG activitiesinto a sequence of topology-preserving multi-spectral images, as opposed tostandard EEG analysis techniques that ignore such spatial information. Next, wetrain a deep recurrent-convolutional network inspired by state-of-the-art videoclassification to learn robust representations from the sequence of images. Theproposed approach is designed to preserve the spatial, spectral, and temporalstructure of EEG which leads to finding features that are less sensitive tovariations and distortions within each dimension. Empirical evaluation on thecognitive load classification task demonstrated significant improvements inclassification accuracy over current state-of-the-art approaches in this field."^^schema:Text ;
    schema:author "Irina Rish"^^schema:Person,
        "Mohammed Yeasin"^^schema:Person,
        "Noel Codella"^^schema:Person,
        "Pouya Bashivan"^^schema:Person ;
    schema:commentCount "343"^^schema:Integer ;
    schema:dateModified "2016-02-29T21:33:45Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T23:29:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Representations from EEG with Deep Recurrent-Convolutional  Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06448v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4319242413507858773&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<382> a schema:ScholarlyArticle ;
    schema:abstract "Recent deep learning approaches for representation learning on graphs followa neighborhood aggregation procedure. We analyze some important properties ofthese models, and propose a strategy to overcome those. In particular, therange of \"neighboring\" nodes that a node's representation draws from stronglydepends on the graph structure, analogous to the spread of a random walk. Toadapt to local neighborhood properties and tasks, we explore an architecture --jumping knowledge (JK) networks -- that flexibly leverages, for each node,different neighborhood ranges to enable better structure-aware representation.In a number of experiments on social, bioinformatics and citation networks, wedemonstrate that our model achieves state-of-the-art performance. Furthermore,combining the JK framework with models like Graph Convolutional Networks,GraphSAGE and Graph Attention Networks consistently improves those models'performance."^^schema:Text ;
    schema:author "Chengtao Li"^^schema:Person,
        "Ken-ichi Kawarabayashi"^^schema:Person,
        "Keyulu Xu"^^schema:Person,
        "Stefanie Jegelka"^^schema:Person,
        "Tomohiro Sonobe"^^schema:Person,
        "Yonglong Tian"^^schema:Person ;
    schema:commentCount "181"^^schema:Integer ;
    schema:dateModified "2018-06-25T19:52:28Z"^^schema:DateTime ;
    schema:datePublished "2018-06-09T19:49:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Representation Learning on Graphs with Jumping Knowledge Networks"^^schema:Text ;
    schema:publisher "ICML, 5449-5458"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1806.03536v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12324071567307935777&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<383> a schema:ScholarlyArticle ;
    schema:abstract "We provide a new proof of the linear convergence of the alternating directionmethod of multipliers (ADMM) when one of the objective terms is stronglyconvex. Our proof is based on a framework for analyzing optimization algorithmsintroduced in Lessard et al. (2014), reducing algorithm convergence toverifying the stability of a dynamical system. This approach generalizes anumber of existing results and obviates any assumptions about specific choicesof algorithm parameters. On a numerical example, we demonstrate that minimizingthe derived bound on the convergence rate provides a practical approach toselecting algorithm parameters for particular ADMM instances. We complement ourupper bound by constructing a nearly-matching lower bound on the worst-caserate of convergence."^^schema:Text ;
    schema:author "Andrew Packard"^^schema:Person,
        "Benjamin Recht"^^schema:Person,
        "Laurent Lessard"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Robert Nishihara"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:dateModified "2015-05-19T03:20:51Z"^^schema:DateTime ;
    schema:datePublished "2015-02-06T20:01:58Z"^^schema:DateTime ;
    schema:genre "cs.NA"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "A General Analysis of the Convergence of ADMM"^^schema:Text ;
    schema:publisher "ICML, 343-352"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02009v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9935674567319083530&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<384> a schema:ScholarlyArticle ;
    schema:abstract "We present diffusion-convolutional neural networks (DCNNs), a new model forgraph-structured data. Through the introduction of a diffusion-convolutionoperation, we show how diffusion-based representations can be learned fromgraph-structured data and used as an effective basis for node classification.DCNNs have several attractive qualities, including a latent representation forgraphical data that is invariant under isomorphism, as well as polynomial-timeprediction and learning that can be represented as tensor operations andefficiently implemented on the GPU. Through several experiments with realstructured datasets, we demonstrate that DCNNs are able to outperformprobabilistic relational models and kernel-on-graph methods at relational nodeclassification tasks."^^schema:Text ;
    schema:author "Don Towsley"^^schema:Person,
        "James Atwood"^^schema:Person ;
    schema:commentCount "418"^^schema:Integer ;
    schema:dateModified "2016-07-08T15:05:17Z"^^schema:DateTime ;
    schema:datePublished "2015-11-06T16:09:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Diffusion-Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.02136v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17241458867032154450&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<385> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we take a fresh look at some old and new algorithms foroff-policy, return-based reinforcement learning. Expressing these in a commonform, we derive a novel algorithm, Retrace($\\lambda$), with three desiredproperties: (1) it has low variance; (2) it safely uses samples collected fromany behaviour policy, whatever its degree of \"off-policyness\"; and (3) it isefficient as it makes the best use of samples collected from near on-policybehaviour policies. We analyze the contractive nature of the related operatorunder both off-policy policy evaluation and control settings and derive onlinesample-based algorithms. We believe this is the first return-based off-policycontrol algorithm converging a.s. to $Q^*$ without the GLIE assumption (Greedyin the Limit with Infinite Exploration). As a corollary, we prove theconvergence of Watkins' Q($\\lambda$), which was an open problem since 1989. Weillustrate the benefits of Retrace($\\lambda$) on a standard suite of Atari 2600games."^^schema:Text ;
    schema:author "Anna Harutyunyan"^^schema:Person,
        "Marc G. Bellemare"^^schema:Person,
        "Rémi Munos"^^schema:Person,
        "Tom Stepleton"^^schema:Person ;
    schema:commentCount "278"^^schema:Integer ;
    schema:dateModified "2016-11-07T21:26:31Z"^^schema:DateTime ;
    schema:datePublished "2016-06-08T17:34:13Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Safe and Efficient Off-Policy Reinforcement Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.02647v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10236232618386583112&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<386> a schema:ScholarlyArticle ;
    schema:abstract "Automatic synthesis of realistic images from text would be interesting anduseful, but current AI systems are still far from this goal. However, in recentyears generic and powerful recurrent neural network architectures have beendeveloped to learn discriminative text feature representations. Meanwhile, deepconvolutional generative adversarial networks (GANs) have begun to generatehighly compelling images of specific categories, such as faces, album covers,and room interiors. In this work, we develop a novel deep architecture and GANformulation to effectively bridge these advances in text and image model- ing,translating visual concepts from characters to pixels. We demonstrate thecapability of our model to generate plausible images of birds and flowers fromdetailed text descriptions."^^schema:Text ;
    schema:author "Bernt Schiele"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Lajanugen Logeswaran"^^schema:Person,
        "Scott Reed"^^schema:Person,
        "Xinchen Yan"^^schema:Person,
        "Zeynep Akata"^^schema:Person ;
    schema:commentCount "1528"^^schema:Integer ;
    schema:dateModified "2016-06-05T13:39:27Z"^^schema:DateTime ;
    schema:datePublished "2016-05-17T23:09:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Generative Adversarial Text to Image Synthesis"^^schema:Text ;
    schema:publisher "ICML, 1060-1069"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.05396v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8255440757806230750&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<387> a schema:ScholarlyArticle ;
    schema:abstract "While humans easily recognize relations between data from different domainswithout any supervision, learning to automatically discover them is in generalvery challenging and needs many ground-truth pairs that illustrate therelations. To avoid costly pairing, we address the task of discoveringcross-domain relations given unpaired data. We propose a method based ongenerative adversarial networks that learns to discover relations betweendifferent domains (DiscoGAN). Using the discovered relations, our proposednetwork successfully transfers style from one domain to another whilepreserving key attributes such as orientation and face identity. Source codefor official implementation is publicly availablehttps://github.com/SKTBrain/DiscoGAN"^^schema:Text ;
    schema:author "Hyunsoo Kim"^^schema:Person,
        "Jiwon Kim"^^schema:Person,
        "Jung Kwon Lee"^^schema:Person,
        "Moonsu Cha"^^schema:Person,
        "Taeksoo Kim"^^schema:Person ;
    schema:commentCount "908"^^schema:Integer ;
    schema:dateModified "2017-05-15T05:04:38Z"^^schema:DateTime ;
    schema:datePublished "2017-03-15T14:53:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Discover Cross-Domain Relations with Generative Adversarial  Networks"^^schema:Text ;
    schema:publisher "ICML, 1857-1865"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.05192v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=463778412690777341&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<388> a schema:ScholarlyArticle ;
    schema:abstract "We seek to automate the design of molecules based on specific chemicalproperties. In computational terms, this task involves continuous embedding andgeneration of molecular graphs. Our primary contribution is the directrealization of molecular graphs, a task previously approached by generatinglinear SMILES strings instead of graphs. Our junction tree variationalautoencoder generates molecular graphs in two phases, by first generating atree-structured scaffold over chemical substructures, and then combining theminto a molecule with a graph message passing network. This approach allows usto incrementally expand molecules while maintaining chemical validity at everystep. We evaluate our model on multiple tasks ranging from molecular generationto optimization. Across these tasks, our model outperforms previousstate-of-the-art baselines by a significant margin."^^schema:Text ;
    schema:author "Regina Barzilay"^^schema:Person,
        "Tommi Jaakkola"^^schema:Person,
        "Wengong Jin"^^schema:Person ;
    schema:commentCount "220"^^schema:Integer ;
    schema:dateModified "2019-03-29T14:44:43Z"^^schema:DateTime ;
    schema:datePublished "2018-02-12T21:19:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Junction Tree Variational Autoencoder for Molecular Graph Generation"^^schema:Text ;
    schema:publisher "ICML, 2328-2337"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.04364v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14713480171095443338&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<389> a schema:ScholarlyArticle ;
    schema:abstract "Motivated by vision-based reinforcement learning (RL) problems, in particularAtari games from the recent benchmark Aracade Learning Environment (ALE), weconsider spatio-temporal prediction problems where future (image-)frames aredependent on control variables or actions as well as previous frames. While notcomposed of natural scenes, frames in Atari games are high-dimensional in size,can involve tens of objects with one or more objects being controlled by theactions directly and many other objects being influenced indirectly, caninvolve entry and departure of objects, and can involve deep partialobservability. We propose and evaluate two deep neural network architecturesthat consist of encoding, action-conditional transformation, and decodinglayers based on convolutional neural networks and recurrent neural networks.Experimental results show that the proposed architectures are able to generatevisually-realistic frames that are also useful for control over approximately100-step action-conditional futures in some games. To the best of ourknowledge, this paper is the first to make and evaluate long-term predictionson high-dimensional video conditioned by control inputs."^^schema:Text ;
    schema:author "Honglak Lee"^^schema:Person,
        "Junhyuk Oh"^^schema:Person,
        "Richard Lewis"^^schema:Person,
        "Satinder Singh"^^schema:Person,
        "Xiaoxiao Guo"^^schema:Person ;
    schema:commentCount "559"^^schema:Integer ;
    schema:dateModified "2015-12-22T04:26:54Z"^^schema:DateTime ;
    schema:datePublished "2015-07-31T04:43:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Action-Conditional Video Prediction using Deep Networks in Atari Games"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.08750v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7752998563568486920&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<39> a schema:ScholarlyArticle ;
    schema:abstract "In a variety of problems originating in supervised, unsupervised, andreinforcement learning, the loss function is defined by an expectation over acollection of random variables, which might be part of a probabilistic model orthe external world. Estimating the gradient of this loss function, usingsamples, lies at the core of gradient-based learning algorithms for theseproblems. We introduce the formalism of stochastic computationgraphs---directed acyclic graphs that include both deterministic functions andconditional probability distributions---and describe how to easily andautomatically derive an unbiased estimator of the loss function's gradient. Theresulting algorithm for computing the gradient estimator is a simplemodification of the standard backpropagation algorithm. The generic scheme wepropose unifies estimators derived in variety of prior work, along withvariance-reduction techniques therein. It could assist researchers indeveloping intricate models involving a combination of stochastic anddeterministic operations, enabling, for example, attention, memory, and controlactions."^^schema:Text ;
    schema:author "John Schulman"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Theophane Weber"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:dateModified "2016-01-05T19:56:22Z"^^schema:DateTime ;
    schema:datePublished "2015-06-17T09:32:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Gradient Estimation Using Stochastic Computation Graphs"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.05254v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8425134619086007830&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<390> a schema:ScholarlyArticle ;
    schema:abstract "Few prior works study deep learning on point sets. PointNet by Qi et al. is apioneer in this direction. However, by design PointNet does not capture localstructures induced by the metric space points live in, limiting its ability torecognize fine-grained patterns and generalizability to complex scenes. In thiswork, we introduce a hierarchical neural network that applies PointNetrecursively on a nested partitioning of the input point set. By exploitingmetric space distances, our network is able to learn local features withincreasing contextual scales. With further observation that point sets areusually sampled with varying densities, which results in greatly decreasedperformance for networks trained on uniform densities, we propose novel setlearning layers to adaptively combine features from multiple scales.Experiments show that our network called PointNet++ is able to learn deep pointset features efficiently and robustly. In particular, results significantlybetter than state-of-the-art have been obtained on challenging benchmarks of 3Dpoint clouds."^^schema:Text ;
    schema:author "Charles R. Qi"^^schema:Person,
        "Hao Su"^^schema:Person,
        "Leonidas J. Guibas"^^schema:Person,
        "Li Yi"^^schema:Person ;
    schema:commentCount "1458"^^schema:Integer ;
    schema:dateModified "2017-06-07T23:37:44Z"^^schema:DateTime ;
    schema:datePublished "2017-06-07T23:37:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric  Space"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02413v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12360107934915291237&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<391> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks are used in many state-of-the-art systems for machineperception. Once a network is trained to do a specific task, e.g., birdclassification, it cannot easily be trained to do new tasks, e.g.,incrementally learning to recognize additional bird species or learning anentirely different task such as flower recognition. When new tasks are added,typical deep neural networks are prone to catastrophically forgetting previoustasks. Networks that are capable of assimilating new information incrementally,much like how humans form new memories over time, will be more efficient thanre-training the model from scratch each time a new task needs to be learned.There have been multiple attempts to develop schemes that mitigate catastrophicforgetting, but these methods have not been directly compared, the tests usedto evaluate them vary considerably, and these methods have only been evaluatedon small-scale problems (e.g., MNIST). In this paper, we introduce new metricsand benchmarks for directly comparing five different mechanisms designed tomitigate catastrophic forgetting in neural networks: regularization,ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments onreal-world images and sounds show that the mechanism(s) that are critical foroptimal performance vary based on the incremental training paradigm and type ofdata being used, but they all demonstrate that the catastrophic forgettingproblem has yet to be solved."^^schema:Text ;
    schema:author "Angelina Abitino"^^schema:Person,
        "Christopher Kanan"^^schema:Person,
        "Marc McClure"^^schema:Person,
        "Ronald Kemker"^^schema:Person,
        "Tyler Hayes"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:dateModified "2017-11-09T14:53:07Z"^^schema:DateTime ;
    schema:datePublished "2017-08-07T11:18:43Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Measuring Catastrophic Forgetting in Neural Networks"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.02072v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1358572155151187767&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<392> a schema:ScholarlyArticle ;
    schema:abstract "The purported \"black box\" nature of neural networks is a barrier to adoptionin applications where interpretability is essential. Here we present DeepLIFT(Deep Learning Important FeaTures), a method for decomposing the outputprediction of a neural network on a specific input by backpropagating thecontributions of all neurons in the network to every feature of the input.DeepLIFT compares the activation of each neuron to its 'reference activation'and assigns contribution scores according to the difference. By optionallygiving separate consideration to positive and negative contributions, DeepLIFTcan also reveal dependencies which are missed by other approaches. Scores canbe computed efficiently in a single backward pass. We apply DeepLIFT to modelstrained on MNIST and simulated genomic data, and show significant advantagesover gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides:bit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code:http://goo.gl/RM8jvH."^^schema:Text ;
    schema:author "Anshul Kundaje"^^schema:Person,
        "Avanti Shrikumar"^^schema:Person,
        "Peyton Greenside"^^schema:Person ;
    schema:commentCount "605"^^schema:Integer ;
    schema:dateModified "2019-10-12T22:13:28Z"^^schema:DateTime ;
    schema:datePublished "2017-04-10T02:23:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning Important Features Through Propagating Activation Differences"^^schema:Text ;
    schema:publisher "ICML, 3145-3153"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.02685v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3870608604214378324&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<393> a schema:ScholarlyArticle ;
    schema:abstract "Deep-layered models trained on a large number of labeled samples boost theaccuracy of many tasks. It is important to apply such models to differentdomains because collecting many labeled samples in various domains isexpensive. In unsupervised domain adaptation, one needs to train a classifierthat works well on a target domain when provided with labeled source samplesand unlabeled target samples. Although many methods aim to match thedistributions of source and target samples, simply matching the distributioncannot ensure accuracy on the target domain. To learn discriminativerepresentations for the target domain, we assume that artificially labelingtarget samples can result in a good representation. Tri-training leveragesthree classifiers equally to give pseudo-labels to unlabeled samples, but themethod does not assume labeling samples generated from a different domain.Inthis paper, we propose an asymmetric tri-training method for unsuperviseddomain adaptation, where we assign pseudo-labels to unlabeled samples and trainneural networks as if they are true labels. In our work, we use three networksasymmetrically. By asymmetric, we mean that two networks are used to labelunlabeled target samples and one network is trained by the samples to obtaintarget-discriminative representations. We evaluate our method on digitrecognition and sentiment analysis datasets. Our proposed method achievesstate-of-the-art performance on the benchmark digit recognition datasets ofdomain adaptation."^^schema:Text ;
    schema:author "Kuniaki Saito"^^schema:Person,
        "Tatsuya Harada"^^schema:Person,
        "Yoshitaka Ushiku"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2017-05-13T05:44:03Z"^^schema:DateTime ;
    schema:datePublished "2017-02-27T17:48:17Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Asymmetric Tri-training for Unsupervised Domain Adaptation"^^schema:Text ;
    schema:publisher "ICML, 2988-2997"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.08400v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4676245797797796956&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<394> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, graph neural networks (GNNs) have emerged as a powerfulneural architecture to learn vector representations of nodes and graphs in asupervised, end-to-end fashion. Up to now, GNNs have only been evaluatedempirically---showing promising results. The following work investigates GNNsfrom a theoretical point of view and relates them to the $1$-dimensionalWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs havethe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based onthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs($k$-GNNs), which can take higher-order graph structures at multiple scalesinto account. These higher-order structures play an essential role in thecharacterization of social networks and molecule graphs. Our experimentalevaluation confirms our theoretical findings as well as confirms thathigher-order information is useful in the task of graph classification andregression."^^schema:Text ;
    schema:author "Christopher Morris"^^schema:Person,
        "Gaurav Rattan"^^schema:Person,
        "Jan Eric Lenssen"^^schema:Person,
        "Martin Grohe"^^schema:Person,
        "Martin Ritzert"^^schema:Person,
        "Matthias Fey"^^schema:Person,
        "William L. Hamilton"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:dateModified "2020-02-14T15:55:24Z"^^schema:DateTime ;
    schema:datePublished "2018-10-04T14:31:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the AAAI Conference on Artificial Intelligence 33, 4602-4609"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1810.02244v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13309831317058857316&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<395> a schema:ScholarlyArticle ;
    schema:abstract "We propose a probabilistic video model, the Video Pixel Network (VPN), thatestimates the discrete joint distribution of the raw pixel values in a video.The model and the neural architecture reflect the time, space and colorstructure of video tensors and encode it as a four-dimensional dependencychain. The VPN approaches the best possible performance on the Moving MNISTbenchmark, a leap over the previous state of the art, and the generated videosshow only minor deviations from the ground truth. The VPN also producesdetailed samples on the action-conditional Robotic Pushing benchmark andgeneralizes to the motion of novel objects."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Alex Graves"^^schema:Person,
        "Ivo Danihelka"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person,
        "Oriol Vinyals"^^schema:Person ;
    schema:commentCount "233"^^schema:Integer ;
    schema:dateModified "2016-10-03T13:06:40Z"^^schema:DateTime ;
    schema:datePublished "2016-10-03T13:06:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Video Pixel Networks"^^schema:Text ;
    schema:publisher "ICML, 1771-1779"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.00527v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7561856894820666460&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<396> a schema:ScholarlyArticle ;
    schema:abstract "Syntactic constituency parsing is a fundamental problem in natural languageprocessing and has been the subject of intensive research and engineering fordecades. As a result, the most accurate parsers are domain specific, complex,and inefficient. In this paper we show that the domain agnosticattention-enhanced sequence-to-sequence model achieves state-of-the-art resultson the most widely used syntactic constituency parsing dataset, when trained ona large synthetic corpus that was annotated using existing parsers. It alsomatches the performance of standard parsers when trained only on a smallhuman-annotated dataset, which shows that this model is highly data-efficient,in contrast to sequence-to-sequence models without the attention mechanism. Ourparser is also fast, processing over a hundred sentences per second with anunoptimized CPU implementation."^^schema:Text ;
    schema:author "Geoffrey Hinton"^^schema:Person,
        "Ilya Sutskever"^^schema:Person,
        "Lukasz Kaiser"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Slav Petrov"^^schema:Person,
        "Terry Koo"^^schema:Person ;
    schema:commentCount "781"^^schema:Integer ;
    schema:dateModified "2015-06-09T22:41:07Z"^^schema:DateTime ;
    schema:datePublished "2014-12-23T17:16:24Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Grammar as a Foreign Language"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.7449v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12237083531601847428&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<397> a schema:ScholarlyArticle ;
    schema:abstract "Deep Neural Networks (DNNs) have demonstrated impressive performance incomplex machine learning tasks such as image classification or speechrecognition. However, due to their multi-layer nonlinear structure, they arenot transparent, i.e., it is hard to grasp what makes them arrive at aparticular classification or recognition decision given a new unseen datasample. Recently, several approaches have been proposed enabling one tounderstand and interpret the reasoning embodied in a DNN for a single testimage. These methods quantify the ''importance'' of individual pixels wrt theclassification decision and allow a visualization in terms of a heatmap inpixel/input space. While the usefulness of heatmaps can be judged subjectivelyby a human, an objective quality measure is missing. In this paper we present ageneral methodology based on region perturbation for evaluating orderedcollections of pixels such as heatmaps. We compare heatmaps computed by threedifferent methods on the SUN397, ILSVRC2012 and MIT Places data sets. Our mainresult is that the recently proposed Layer-wise Relevance Propagation (LRP)algorithm qualitatively and quantitatively provides a better explanation ofwhat made a DNN arrive at a particular classification decision than thesensitivity-based approach or the deconvolution method. We provide theoreticalarguments to explain this result and discuss its practical implications.Finally, we investigate the use of heatmaps for unsupervised assessment ofneural network performance."^^schema:Text ;
    schema:author "Alexander Binder"^^schema:Person,
        "Grégoire Montavon"^^schema:Person,
        "Klaus-Robert Müller"^^schema:Person,
        "Sebastian Bach"^^schema:Person,
        "Wojciech Samek"^^schema:Person ;
    schema:commentCount "351"^^schema:Integer ;
    schema:dateModified "2015-09-21T17:36:22Z"^^schema:DateTime ;
    schema:datePublished "2015-09-21T17:36:22Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Evaluating the visualization of what a Deep Neural Network has learned"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 28 (11), 2660-2673"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.06321v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7349251395468541741&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<398> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of detecting out-of-distribution images in neuralnetworks. We propose ODIN, a simple and effective method that does not requireany change to a pre-trained neural network. Our method is based on theobservation that using temperature scaling and adding small perturbations tothe input can separate the softmax score distributions between in- andout-of-distribution images, allowing for more effective detection. We show in aseries of experiments that ODIN is compatible with diverse networkarchitectures and datasets. It consistently outperforms the baseline approachby a large margin, establishing a new state-of-the-art performance on thistask. For example, ODIN reduces the false positive rate from the baseline 34.7%to 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is95%."^^schema:Text ;
    schema:author "R. Srikant"^^schema:Person,
        "Shiyu Liang"^^schema:Person,
        "Yixuan Li"^^schema:Person ;
    schema:commentCount "238"^^schema:Integer ;
    schema:dateModified "2020-08-30T16:50:36Z"^^schema:DateTime ;
    schema:datePublished "2017-06-08T17:43:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Enhancing The Reliability of Out-of-distribution Image Detection in  Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02690v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7536099354022278878&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<399> a schema:ScholarlyArticle ;
    schema:abstract "Image-generating machine learning models are typically trained with lossfunctions based on distance in the image space. This often leads toover-smoothed results. We propose a class of loss functions, which we call deepperceptual similarity metrics (DeePSiM), that mitigate this problem. Instead ofcomputing distances in the image space, we compute distances between imagefeatures extracted by deep neural networks. This metric better reflectsperceptually similarity of images and thus leads to better results. We showthree applications: autoencoder training, a modification of a variationalautoencoder, and inversion of deep convolutional networks. In all cases, thegenerated images look sharp and resemble natural images."^^schema:Text ;
    schema:author "Alexey Dosovitskiy"^^schema:Person,
        "Thomas Brox"^^schema:Person ;
    schema:commentCount "585"^^schema:Integer ;
    schema:dateModified "2016-02-09T09:36:36Z"^^schema:DateTime ;
    schema:datePublished "2016-02-08T16:50:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Generating Images with Perceptual Similarity Metrics based on Deep  Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02644v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1915913556489044934&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<4> a schema:ScholarlyArticle ;
    schema:abstract "Federated learning poses new statistical and systems challenges in trainingmachine learning models over distributed networks of devices. In this work, weshow that multi-task learning is naturally suited to handle the statisticalchallenges of this setting, and propose a novel systems-aware optimizationmethod, MOCHA, that is robust to practical systems issues. Our method andtheory for the first time consider issues of high communication cost,stragglers, and fault tolerance for distributed multi-task learning. Theresulting method achieves significant speedups compared to alternatives in thefederated setting, as we demonstrate through simulations on real-worldfederated datasets."^^schema:Text ;
    schema:author "Ameet Talwalkar"^^schema:Person,
        "Chao-Kai Chiang"^^schema:Person,
        "Maziar Sanjabi"^^schema:Person,
        "Virginia Smith"^^schema:Person ;
    schema:commentCount "261"^^schema:Integer ;
    schema:dateModified "2018-02-27T07:29:26Z"^^schema:DateTime ;
    schema:datePublished "2017-05-30T06:20:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Federated Multi-Task Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10467v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2729989706953112243&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<40> a schema:ScholarlyArticle ;
    schema:abstract "For sophisticated reinforcement learning (RL) systems to interact usefullywith real-world environments, we need to communicate complex goals to thesesystems. In this work, we explore goals defined in terms of (non-expert) humanpreferences between pairs of trajectory segments. We show that this approachcan effectively solve complex RL tasks without access to the reward function,including Atari games and simulated robot locomotion, while providing feedbackon less than one percent of our agent's interactions with the environment. Thisreduces the cost of human oversight far enough that it can be practicallyapplied to state-of-the-art RL systems. To demonstrate the flexibility of ourapproach, we show that we can successfully train complex novel behaviors withabout an hour of human time. These behaviors and environments are considerablymore complex than any that have been previously learned from human feedback."^^schema:Text ;
    schema:author "Dario Amodei"^^schema:Person,
        "Jan Leike"^^schema:Person,
        "Miljan Martic"^^schema:Person,
        "Paul Christiano"^^schema:Person,
        "Shane Legg"^^schema:Person,
        "Tom B. Brown"^^schema:Person ;
    schema:commentCount "296"^^schema:Integer ;
    schema:dateModified "2017-07-13T20:18:41Z"^^schema:DateTime ;
    schema:datePublished "2017-06-12T17:23:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.HC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep reinforcement learning from human preferences"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.03741v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16666410803638838470&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<400> a schema:ScholarlyArticle ;
    schema:abstract "Relational reasoning is a central component of generally intelligentbehavior, but has proven difficult for neural networks to learn. In this paperwe describe how to use Relation Networks (RNs) as a simple plug-and-play moduleto solve problems that fundamentally hinge on relational reasoning. We testedRN-augmented networks on three tasks: visual question answering using achallenging dataset called CLEVR, on which we achieve state-of-the-art,super-human performance; text-based question answering using the bAbI suite oftasks; and complex reasoning about dynamic physical systems. Then, using acurated dataset called Sort-of-CLEVR we show that powerful convolutionalnetworks do not have a general capacity to solve relational questions, but cangain this capacity when augmented with RNs. Our work shows how a deep learningarchitecture equipped with an RN module can implicitly discover and learn toreason about entities and their relations."^^schema:Text ;
    schema:author "Adam Santoro"^^schema:Person,
        "David G. T. Barrett"^^schema:Person,
        "David Raposo"^^schema:Person,
        "Mateusz Malinowski"^^schema:Person,
        "Peter Battaglia"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Timothy Lillicrap"^^schema:Person ;
    schema:commentCount "699"^^schema:Integer ;
    schema:dateModified "2017-06-05T17:17:18Z"^^schema:DateTime ;
    schema:datePublished "2017-06-05T17:17:18Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A simple neural network module for relational reasoning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.01427v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7624683168776555686&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<401> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we present an on-manifold sequence-to-sequence learningapproach to motion estimation using visual and inertial sensors. It is to thebest of our knowledge the first end-to-end trainable method for visual-inertialodometry which performs fusion of the data at an intermediatefeature-representation level. Our method has numerous advantages overtraditional approaches. Specifically, it eliminates the need for tedious manualsynchronization of the camera and IMU as well as eliminating the need formanual calibration between the IMU and camera. A further advantage is that ourmodel naturally and elegantly incorporates domain specific information whichsignificantly mitigates drift. We show that our approach is competitive withstate-of-the-art traditional methods when accurate calibration data isavailable and can be trained to outperform them in the presence of calibrationand synchronization errors."^^schema:Text ;
    schema:author "Andrew Markham"^^schema:Person,
        "Hongkai Wen"^^schema:Person,
        "Niki Trigoni"^^schema:Person,
        "Ronald Clark"^^schema:Person,
        "Sen Wang"^^schema:Person ;
    schema:commentCount "145"^^schema:Integer ;
    schema:dateModified "2017-04-02T17:11:53Z"^^schema:DateTime ;
    schema:datePublished "2017-01-29T13:34:22Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning  Problem"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.08376v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7432089327423732629&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<402> a schema:ScholarlyArticle ;
    schema:abstract "We consider a generic convex optimization problem associated with regularizedempirical risk minimization of linear predictors. The problem structure allowsus to reformulate it as a convex-concave saddle point problem. We propose astochastic primal-dual coordinate (SPDC) method, which alternates betweenmaximizing over a randomly chosen dual variable and minimizing over the primalvariable. An extrapolation step on the primal variable is performed to obtainaccelerated convergence rate. We also develop a mini-batch version of the SPDCmethod which facilitates parallel computing, and an extension with weightedsampling probabilities on the dual variables, which has a better complexitythan uniform sampling on unnormalized data. Both theoretically and empirically,we show that the SPDC method has comparable or better performance than severalstate-of-the-art optimization methods."^^schema:Text ;
    schema:author "Lin Xiao"^^schema:Person,
        "Yuchen Zhang"^^schema:Person ;
    schema:commentCount "184"^^schema:Integer ;
    schema:dateModified "2015-09-09T05:37:23Z"^^schema:DateTime ;
    schema:datePublished "2014-09-10T21:25:22Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk  Minimization"^^schema:Text ;
    schema:publisher "ICML, 353-361"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1409.3257v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14588707342837179622&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<403> a schema:ScholarlyArticle ;
    schema:abstract "We present a new model DrNET that learns disentangled image representationsfrom video. Our approach leverages the temporal coherence of video and a noveladversarial loss to learn a representation that factorizes each frame into astationary part and a temporally varying component. The disentangledrepresentation can be used for a range of tasks. For example, applying astandard LSTM to the time-vary components enables prediction of future frames.We evaluate our approach on a range of synthetic and real videos, demonstratingthe ability to coherently generate hundreds of steps into the future."^^schema:Text ;
    schema:author "Emily Denton"^^schema:Person,
        "Vighnesh Birodkar"^^schema:Person ;
    schema:commentCount "253"^^schema:Integer ;
    schema:dateModified "2017-05-31T02:12:19Z"^^schema:DateTime ;
    schema:datePublished "2017-05-31T02:12:19Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unsupervised Learning of Disentangled Representations from Video"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10915v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9768655920777432327&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<404> a schema:ScholarlyArticle ;
    schema:abstract "Neural network architectures with memory and attention mechanisms exhibitcertain reasoning capabilities required for question answering. One sucharchitecture, the dynamic memory network (DMN), obtained high accuracy on avariety of language tasks. However, it was not shown whether the architectureachieves strong results for question answering when supporting facts are notmarked during training or whether it could be applied to other modalities suchas images. Based on an analysis of the DMN, we propose several improvements toits memory and input modules. Together with these changes we introduce a novelinput module for images in order to be able to answer visual questions. Our newDMN+ model improves the state of the art on both the Visual Question Answeringdataset and the \\babi-10k text question-answering dataset without supportingfact supervision."^^schema:Text ;
    schema:author "Caiming Xiong"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Stephen Merity"^^schema:Person ;
    schema:commentCount "512"^^schema:Integer ;
    schema:dateModified "2016-03-04T10:40:28Z"^^schema:DateTime ;
    schema:datePublished "2016-03-04T10:40:28Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Dynamic Memory Networks for Visual and Textual Question Answering"^^schema:Text ;
    schema:publisher "ICML, 2397-2406"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.01417v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8393808929765185624&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<405> a schema:ScholarlyArticle ;
    schema:abstract "The pre-dominant approach to language modeling to date is based on recurrentneural networks. Their success on this task is often linked to their ability tocapture unbounded context. In this paper we develop a finite context approachthrough stacked convolutions, which can be more efficient since they allowparallelization over sequential tokens. We propose a novel simplified gatingmechanism that outperforms Oord et al (2016) and investigate the impact of keyarchitectural decisions. The proposed approach achieves state-of-the-art on theWikiText-103 benchmark, even though it features long-term dependencies, as wellas competitive results on the Google Billion Words benchmark. Our model reducesthe latency to score a sentence by an order of magnitude compared to arecurrent baseline. To our knowledge, this is the first time a non-recurrentapproach is competitive with strong recurrent models on these large scalelanguage tasks."^^schema:Text ;
    schema:author "Angela Fan"^^schema:Person,
        "David Grangier"^^schema:Person,
        "Michael Auli"^^schema:Person,
        "Yann N. Dauphin"^^schema:Person ;
    schema:commentCount "733"^^schema:Integer ;
    schema:dateModified "2017-09-08T22:26:49Z"^^schema:DateTime ;
    schema:datePublished "2016-12-23T20:32:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Language Modeling with Gated Convolutional Networks"^^schema:Text ;
    schema:publisher "ICML, 933-941"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.08083v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15192587613931188105&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<406> a schema:ScholarlyArticle ;
    schema:abstract "Imitation learning has been commonly applied to solve different tasks inisolation. This usually requires either careful feature engineering, or asignificant number of samples. This is far from what we desire: ideally, robotsshould be able to learn from very few demonstrations of any given task, andinstantly generalize to new situations of the same task, without requiringtask-specific engineering. In this paper, we propose a meta-learning frameworkfor achieving such capability, which we call one-shot imitation learning.  Specifically, we consider the setting where there is a very large set oftasks, and each task has many instantiations. For example, a task could be tostack all blocks on a table into a single tower, another task could be to placeall blocks on a table into two-block towers, etc. In each case, differentinstances of the task would consist of different sets of blocks with differentinitial states. At training time, our algorithm is presented with pairs ofdemonstrations for a subset of all tasks. A neural net is trained that takes asinput one demonstration and the current state (which initially is the initialstate of the other demonstration of the pair), and outputs an action with thegoal that the resulting sequence of states and actions matches as closely aspossible with the second demonstration. At test time, a demonstration of asingle instance of a new task is presented, and the neural net is expected toperform well on new instances of this new task. The use of soft attentionallows the model to generalize to conditions and tasks unseen in the trainingdata. We anticipate that by training this model on a much greater variety oftasks and settings, we will obtain a general system that can turn anydemonstrations into robust policies that can accomplish an overwhelming varietyof tasks.  Videos available at https://bit.ly/nips2017-oneshot ."^^schema:Text ;
    schema:author "Bradly C. Stadie"^^schema:Person,
        "Ilya Sutskever"^^schema:Person,
        "Jonas Schneider"^^schema:Person,
        "Jonathan Ho"^^schema:Person,
        "Marcin Andrychowicz"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "329"^^schema:Integer ;
    schema:dateModified "2017-12-04T21:53:23Z"^^schema:DateTime ;
    schema:datePublished "2017-03-21T17:22:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "One-Shot Imitation Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.07326v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3870865527815598360&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<407> a schema:ScholarlyArticle ;
    schema:abstract "The ability of the Generative Adversarial Networks (GANs) framework to learngenerative models mapping from simple latent distributions to arbitrarilycomplex data distributions has been demonstrated empirically, with compellingresults showing that the latent space of such generators captures semanticvariation in the data distribution. Intuitively, models trained to predictthese semantic latent representations given data may serve as useful featurerepresentations for auxiliary problems where semantics are relevant. However,in their existing form, GANs have no means of learning the inverse mapping --projecting data back into the latent space. We propose Bidirectional GenerativeAdversarial Networks (BiGANs) as a means of learning this inverse mapping, anddemonstrate that the resulting learned feature representation is useful forauxiliary supervised discrimination tasks, competitive with contemporaryapproaches to unsupervised and self-supervised feature learning."^^schema:Text ;
    schema:author "Jeff Donahue"^^schema:Person,
        "Philipp Krähenbühl"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:commentCount "845"^^schema:Integer ;
    schema:dateModified "2017-04-03T20:34:36Z"^^schema:DateTime ;
    schema:datePublished "2016-05-31T19:37:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Feature Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.09782v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10661655492543733137&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<408> a schema:ScholarlyArticle ;
    schema:abstract "Understanding the flow of information in Deep Neural Networks (DNNs) is achallenging problem that has gain increasing attention over the last few years.While several methods have been proposed to explain network predictions, therehave been only a few attempts to compare them from a theoretical perspective.What is more, no exhaustive empirical comparison has been performed in thepast. In this work, we analyze four gradient-based attribution methods andformally prove conditions of equivalence and approximation between them. Byreformulating two of these methods, we construct a unified framework whichenables a direct comparison, as well as an easier implementation. Finally, wepropose a novel evaluation metric, called Sensitivity-n and test thegradient-based attribution methods alongside with a simple perturbation-basedattribution method on several datasets in the domains of image and textclassification, using various network architectures."^^schema:Text ;
    schema:author "Cengiz Öztireli"^^schema:Person,
        "Enea Ceolini"^^schema:Person,
        "Marco Ancona"^^schema:Person,
        "Markus Gross"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:dateModified "2018-03-07T10:49:28Z"^^schema:DateTime ;
    schema:datePublished "2017-11-16T14:19:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards better understanding of gradient-based attribution methods for  Deep Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.06104v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7129422820232184089&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<409> a schema:ScholarlyArticle ;
    schema:abstract "We present a systematic approach for achieving fairness in a binaryclassification setting. While we focus on two well-known quantitativedefinitions of fairness, our approach encompasses many other previously studieddefinitions as special cases. The key idea is to reduce fair classification toa sequence of cost-sensitive classification problems, whose solutions yield arandomized classifier with the lowest (empirical) error subject to the desiredconstraints. We introduce two reductions that work for any representation ofthe cost-sensitive classifier and compare favorably to prior baselines on avariety of data sets, while overcoming several of their disadvantages."^^schema:Text ;
    schema:author "Alekh Agarwal"^^schema:Person,
        "Alina Beygelzimer"^^schema:Person,
        "Hanna Wallach"^^schema:Person,
        "John Langford"^^schema:Person,
        "Miroslav Dudík"^^schema:Person ;
    schema:commentCount "213"^^schema:Integer ;
    schema:dateModified "2018-07-16T15:06:37Z"^^schema:DateTime ;
    schema:datePublished "2018-03-06T22:39:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "A Reductions Approach to Fair Classification"^^schema:Text ;
    schema:publisher "ICML, 60-69"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.02453v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16870675827052455946&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<41> a schema:ScholarlyArticle ;
    schema:abstract "Two-stream Convolutional Networks (ConvNets) have shown strong performancefor human action recognition in videos. Recently, Residual Networks (ResNets)have arisen as a new technique to train extremely deep architectures. In thispaper, we introduce spatiotemporal ResNets as a combination of these twoapproaches. Our novel architecture generalizes ResNets for the spatiotemporaldomain by introducing residual connections in two ways. First, we injectresidual connections between the appearance and motion pathways of a two-streamarchitecture to allow spatiotemporal interaction between the two streams.Second, we transform pretrained image ConvNets into spatiotemporal networks byequipping these with learnable convolutional filters that are initialized astemporal residual connections and operate on adjacent feature maps in time.This approach slowly increases the spatiotemporal receptive field as the depthof the model increases and naturally integrates image ConvNet designprinciples. The whole model is trained end-to-end to allow hierarchicallearning of complex spatiotemporal features. We evaluate our novelspatiotemporal ResNet using two widely used action recognition benchmarks whereit exceeds the previous state-of-the-art."^^schema:Text ;
    schema:author "Axel Pinz"^^schema:Person,
        "Christoph Feichtenhofer"^^schema:Person,
        "Richard P. Wildes"^^schema:Person ;
    schema:commentCount "546"^^schema:Integer ;
    schema:dateModified "2016-11-07T16:17:16Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T16:17:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Spatiotemporal Residual Networks for Video Action Recognition"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02155v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17812047066454194940&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<410> a schema:ScholarlyArticle ;
    schema:abstract "This paper addresses the scalability challenge of architecture search byformulating the task in a differentiable manner. Unlike conventional approachesof applying evolution or reinforcement learning over a discrete andnon-differentiable search space, our method is based on the continuousrelaxation of the architecture representation, allowing efficient search of thearchitecture using gradient descent. Extensive experiments on CIFAR-10,ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels indiscovering high-performance convolutional architectures for imageclassification and recurrent architectures for language modeling, while beingorders of magnitude faster than state-of-the-art non-differentiable techniques.Our implementation has been made publicly available to facilitate furtherresearch on efficient architecture search algorithms."^^schema:Text ;
    schema:author "Hanxiao Liu"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Yiming Yang"^^schema:Person ;
    schema:commentCount "681"^^schema:Integer ;
    schema:dateModified "2019-04-23T06:29:32Z"^^schema:DateTime ;
    schema:datePublished "2018-06-24T00:06:13Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DARTS: Differentiable Architecture Search"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1806.09055v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=895422516420751823&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<411> a schema:ScholarlyArticle ;
    schema:abstract "The effort devoted to hand-crafting neural network image classifiers hasmotivated the use of architecture search to discover them automatically.Although evolutionary algorithms have been repeatedly applied to neural networktopologies, the image classifiers thus discovered have remained inferior tohuman-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---thatsurpasses hand-designs for the first time. To do this, we modify the tournamentselection evolutionary algorithm by introducing an age property to favor theyounger genotypes. Matching size, AmoebaNet-A has comparable accuracy tocurrent state-of-the-art ImageNet models discovered with more complexarchitecture-search methods. Scaled to larger size, AmoebaNet-A sets a newstate-of-the-art 83.9% / 96.6% top-5 ImageNet accuracy. In a controlledcomparison against a well known reinforcement learning algorithm, we giveevidence that evolution can obtain results faster with the same hardware,especially at the earlier stages of the search. This is relevant when fewercompute resources are available. Evolution is, thus, a simple method toeffectively discover high-quality architectures."^^schema:Text ;
    schema:author "Alok Aggarwal"^^schema:Person,
        "Esteban Real"^^schema:Person,
        "Quoc V Le"^^schema:Person,
        "Yanping Huang"^^schema:Person ;
    schema:commentCount "632"^^schema:Integer ;
    schema:dateModified "2019-02-16T23:28:16Z"^^schema:DateTime ;
    schema:datePublished "2018-02-05T18:20:52Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.5.1; I.5.2"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Regularized Evolution for Image Classifier Architecture Search"^^schema:Text ;
    schema:publisher "Proceedings of the AAAI Conference on Artificial Intelligence 33, 4780-4789"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.01548v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6463563114710686585&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<412> a schema:ScholarlyArticle ;
    schema:abstract "Adversarial learning has been embedded into deep networks to learndisentangled and transferable representations for domain adaptation. Existingadversarial domain adaptation methods may not effectively align differentdomains of multimodal distributions native in classification problems. In thispaper, we present conditional adversarial domain adaptation, a principledframework that conditions the adversarial adaptation models on discriminativeinformation conveyed in the classifier predictions. Conditional domainadversarial networks (CDANs) are designed with two novel conditioningstrategies: multilinear conditioning that captures the cross-covariance betweenfeature representations and classifier predictions to improve thediscriminability, and entropy conditioning that controls the uncertainty ofclassifier predictions to guarantee the transferability. With theoreticalguarantees and a few lines of codes, the approach has exceeded state-of-the-artresults on five datasets."^^schema:Text ;
    schema:author "Jianmin Wang"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Mingsheng Long"^^schema:Person,
        "Zhangjie Cao"^^schema:Person ;
    schema:commentCount "215"^^schema:Integer ;
    schema:dateModified "2018-12-29T16:43:57Z"^^schema:DateTime ;
    schema:datePublished "2017-05-26T00:50:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Conditional Adversarial Domain Adaptation"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.10667v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=951003799487024572&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<413> a schema:ScholarlyArticle ;
    schema:abstract "Although Generative Adversarial Networks achieve state-of-the-art results ona variety of generative tasks, they are regarded as highly unstable and proneto miss modes. We argue that these bad behaviors of GANs are due to the veryparticular functional shape of the trained discriminators in high dimensionalspaces, which can easily make training stuck or push probability mass in thewrong direction, towards that of higher concentration than that of the datagenerating distribution. We introduce several ways of regularizing theobjective, which can dramatically stabilize the training of GAN models. We alsoshow that our regularizers can help the fair distribution of probability massacross the modes of the data generating distribution, during the early phasesof training and thus providing a unified solution to the missing modes problem."^^schema:Text ;
    schema:author "Athul Paul Jacob"^^schema:Person,
        "Tong Che"^^schema:Person,
        "Wenjie Li"^^schema:Person,
        "Yanran Li"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "277"^^schema:Integer ;
    schema:dateModified "2017-03-02T06:28:13Z"^^schema:DateTime ;
    schema:datePublished "2016-12-07T07:45:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Mode Regularized Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.02136v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8235362476181771248&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<414> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we consider regression problems with one-hidden-layer neuralnetworks (1NNs). We distill some properties of activation functions that leadto $\\mathit{local~strong~convexity}$ in the neighborhood of the ground-truthparameters for the 1NN squared-loss objective. Most popular nonlinearactivation functions satisfy the distilled properties, including rectifiedlinear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activationfunctions that are also smooth, we show $\\mathit{local~linear~convergence}$guarantees of gradient descent under a resampling rule. For homogeneousactivations, we show tensor methods are able to initialize the parameters tofall into the local strong convexity region. As a result, tensor initializationfollowed by gradient descent is guaranteed to recover the ground truth withsample complexity $ d \\cdot \\log(1/\\epsilon) \\cdot \\mathrm{poly}(k,\\lambda )$and computational complexity $n\\cdot d \\cdot \\mathrm{poly}(k,\\lambda) $ forsmooth homogeneous activations with high probability, where $d$ is thedimension of the input, $k$ ($k\\leq d$) is the number of hidden nodes,$\\lambda$ is a conditioning property of the ground-truth parameter matrixbetween the input layer and the hidden layer, $\\epsilon$ is the targetedprecision and $n$ is the number of samples. To the best of our knowledge, thisis the first work that provides recovery guarantees for 1NNs with both samplecomplexity and computational complexity $\\mathit{linear}$ in the inputdimension and $\\mathit{logarithmic}$ in the precision."^^schema:Text ;
    schema:author "Inderjit S. Dhillon"^^schema:Person,
        "Kai Zhong"^^schema:Person,
        "Peter L. Bartlett"^^schema:Person,
        "Prateek Jain"^^schema:Person,
        "Zhao Song"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:dateModified "2017-06-10T02:56:39Z"^^schema:DateTime ;
    schema:datePublished "2017-06-10T02:56:39Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Recovery Guarantees for One-hidden-layer Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 4140-4149"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.03175v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11965390343759936388&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<415> a schema:ScholarlyArticle ;
    schema:abstract "Deep generative models have been wildly successful at learning coherentlatent representations for continuous data such as video and audio. However,generative modeling of discrete data such as arithmetic expressions andmolecular structures still poses significant challenges. Crucially,state-of-the-art methods often produce outputs that are not valid. We make thekey observation that frequently, discrete data can be represented as a parsetree from a context-free grammar. We propose a variational autoencoder whichencodes and decodes directly to and from these parse trees, ensuring thegenerated outputs are always valid. Surprisingly, we show that not only doesour model more often generate valid outputs, it also learns a more coherentlatent space in which nearby points decode to similar discrete outputs. Wedemonstrate the effectiveness of our learned models by showing their improvedperformance in Bayesian optimization for symbolic regression and molecularsynthesis."^^schema:Text ;
    schema:author "Brooks Paige"^^schema:Person,
        "José Miguel Hernández-Lobato"^^schema:Person,
        "Matt J. Kusner"^^schema:Person ;
    schema:commentCount "243"^^schema:Integer ;
    schema:dateModified "2017-03-06T15:36:37Z"^^schema:DateTime ;
    schema:datePublished "2017-03-06T15:36:37Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Grammar Variational Autoencoder"^^schema:Text ;
    schema:publisher "ICML, 1945-1954"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01925v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4080460899049502885&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<416> a schema:ScholarlyArticle ;
    schema:abstract "With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, undercomparable experiment settings, XLNet outperforms BERT on 20 tasks, often by alarge margin, including question answering, natural language inference,sentiment analysis, and document ranking."^^schema:Text ;
    schema:author "Jaime Carbonell"^^schema:Person,
        "Quoc V. Le"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Yiming Yang"^^schema:Person,
        "Zhilin Yang"^^schema:Person,
        "Zihang Dai"^^schema:Person ;
    schema:commentCount "855"^^schema:Integer ;
    schema:dateModified "2020-01-02T12:48:08Z"^^schema:DateTime ;
    schema:datePublished "2019-06-19T17:35:48Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "XLNet: Generalized Autoregressive Pretraining for Language Understanding"^^schema:Text ;
    schema:publisher "NeurIPS, 5754-5764"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1906.08237v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14487406216105917109&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<417> a schema:ScholarlyArticle ;
    schema:abstract "Although end-to-end Neural Machine Translation (NMT) has achieved remarkableprogress in the past two years, it suffers from a major drawback: translationsgenerated by NMT systems often lack of adequacy. It has been widely observedthat NMT tends to repeatedly translate some source words while mistakenlyignoring other words. To alleviate this problem, we propose a novelencoder-decoder-reconstructor framework for NMT. The reconstructor,incorporated into the NMT model, manages to reconstruct the input sourcesentence from the hidden layer of the output target sentence, to ensure thatthe information in the source side is transformed to the target side as much aspossible. Experiments show that the proposed framework significantly improvesthe adequacy of NMT output and achieves superior translation result overstate-of-the-art NMT and statistical MT systems."^^schema:Text ;
    schema:author "Hang Li"^^schema:Person,
        "Lifeng Shang"^^schema:Person,
        "Xiaohua Liu"^^schema:Person,
        "Yang Liu"^^schema:Person,
        "Zhaopeng Tu"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:dateModified "2016-11-21T09:47:22Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T02:03:55Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Neural Machine Translation with Reconstruction"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01874v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1310099558617172101&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<418> a schema:ScholarlyArticle ;
    schema:abstract "In many real-world scenarios, rewards extrinsic to the agent are extremelysparse, or absent altogether. In such cases, curiosity can serve as anintrinsic reward signal to enable the agent to explore its environment andlearn skills that might be useful later in its life. We formulate curiosity asthe error in an agent's ability to predict the consequence of its own actionsin a visual feature space learned by a self-supervised inverse dynamics model.Our formulation scales to high-dimensional continuous state spaces like images,bypasses the difficulties of directly predicting pixels, and, critically,ignores the aspects of the environment that cannot affect the agent. Theproposed approach is evaluated in two environments: VizDoom and Super MarioBros. Three broad settings are investigated: 1) sparse extrinsic reward, wherecuriosity allows for far fewer interactions with the environment to reach thegoal; 2) exploration with no extrinsic reward, where curiosity pushes the agentto explore more efficiently; and 3) generalization to unseen scenarios (e.g.new levels of the same game) where the knowledge gained from earlier experiencehelps the agent explore new places much faster than starting from scratch. Demovideo and code available at https://pathak22.github.io/noreward-rl/"^^schema:Text ;
    schema:author "Alexei A. Efros"^^schema:Person,
        "Deepak Pathak"^^schema:Person,
        "Pulkit Agrawal"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:commentCount "678"^^schema:Integer ;
    schema:dateModified "2017-05-15T17:56:22Z"^^schema:DateTime ;
    schema:datePublished "2017-05-15T17:56:22Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Curiosity-driven Exploration by Self-supervised Prediction"^^schema:Text ;
    schema:publisher "ICML, 2778-2787"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.05363v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9379743003299559904&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<419> a schema:ScholarlyArticle ;
    schema:abstract "One of the mysteries in the success of neural networks is randomlyinitialized first order methods like gradient descent can achieve zero trainingloss even though the objective function is non-convex and non-smooth. Thispaper demystifies this surprising phenomenon for two-layer fully connected ReLUactivated neural networks. For an $m$ hidden node shallow neural network withReLU activation and $n$ training data, we show as long as $m$ is large enoughand no two inputs are parallel, randomly initialized gradient descent convergesto a globally optimal solution at a linear convergence rate for the quadraticloss function.  Our analysis relies on the following observation: over-parameterization andrandom initialization jointly restrict every weight vector to be close to itsinitialization for all iterations, which allows us to exploit a strongconvexity-like property to show that gradient descent converges at a globallinear rate to the global optimum. We believe these insights are also useful inanalyzing deep models and other first order methods."^^schema:Text ;
    schema:author "Aarti Singh"^^schema:Person,
        "Barnabas Poczos"^^schema:Person,
        "Simon S. Du"^^schema:Person,
        "Xiyu Zhai"^^schema:Person ;
    schema:commentCount "279"^^schema:Integer ;
    schema:dateModified "2019-02-05T01:59:59Z"^^schema:DateTime ;
    schema:datePublished "2018-10-04T04:47:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gradient Descent Provably Optimizes Over-parameterized Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1810.02054v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8128763459913409987&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<42> a schema:ScholarlyArticle ;
    schema:abstract "We propose an algorithm for meta-learning that is model-agnostic, in thesense that it is compatible with any model trained with gradient descent andapplicable to a variety of different learning problems, includingclassification, regression, and reinforcement learning. The goal ofmeta-learning is to train a model on a variety of learning tasks, such that itcan solve new learning tasks using only a small number of training samples. Inour approach, the parameters of the model are explicitly trained such that asmall number of gradient steps with a small amount of training data from a newtask will produce good generalization performance on that task. In effect, ourmethod trains the model to be easy to fine-tune. We demonstrate that thisapproach leads to state-of-the-art performance on two few-shot imageclassification benchmarks, produces good results on few-shot regression, andaccelerates fine-tuning for policy gradient reinforcement learning with neuralnetwork policies."^^schema:Text ;
    schema:author "Chelsea Finn"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "1834"^^schema:Integer ;
    schema:dateModified "2017-07-18T16:45:29Z"^^schema:DateTime ;
    schema:datePublished "2017-03-09T18:58:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"^^schema:Text ;
    schema:publisher "ICML, 1126-1135"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.03400v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17278604844873996878&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<420> a schema:ScholarlyArticle ;
    schema:abstract "Neural machine translation is a recently proposed approach to machinetranslation. Unlike the traditional statistical machine translation, the neuralmachine translation aims at building a single neural network that can bejointly tuned to maximize the translation performance. The models proposedrecently for neural machine translation often belong to a family ofencoder-decoders and consists of an encoder that encodes a source sentence intoa fixed-length vector from which a decoder generates a translation. In thispaper, we conjecture that the use of a fixed-length vector is a bottleneck inimproving the performance of this basic encoder-decoder architecture, andpropose to extend this by allowing a model to automatically (soft-)search forparts of a source sentence that are relevant to predicting a target word,without having to form these parts as a hard segment explicitly. With this newapproach, we achieve a translation performance comparable to the existingstate-of-the-art phrase-based system on the task of English-to-Frenchtranslation. Furthermore, qualitative analysis reveals that the(soft-)alignments found by the model agree well with our intuition."^^schema:Text ;
    schema:author "Dzmitry Bahdanau"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "13000"^^schema:Integer ;
    schema:dateModified "2016-05-19T21:53:22Z"^^schema:DateTime ;
    schema:datePublished "2014-09-01T16:33:02Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Machine Translation by Jointly Learning to Align and Translate"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1409.0473v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9430221802571417838&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<421> a schema:ScholarlyArticle ;
    schema:abstract "We show that generating English Wikipedia articles can be approached as amulti- document summarization of source documents. We use extractivesummarization to coarsely identify salient information and a neural abstractivemodel to generate the article. For the abstractive model, we introduce adecoder-only architecture that can scalably attend to very long sequences, muchlonger than typical encoder- decoder architectures used in sequencetransduction. We show that this model can generate fluent, coherentmulti-sentence paragraphs and even whole Wikipedia articles. When givenreference documents, we show it can extract relevant factual information asreflected in perplexity, ROUGE scores and human evaluations."^^schema:Text ;
    schema:author "Ben Goodrich"^^schema:Person,
        "Etienne Pot"^^schema:Person,
        "Lukasz Kaiser"^^schema:Person,
        "Mohammad Saleh"^^schema:Person,
        "Noam Shazeer"^^schema:Person,
        "Peter J. Liu"^^schema:Person,
        "Ryan Sepassi"^^schema:Person ;
    schema:commentCount "212"^^schema:Integer ;
    schema:dateModified "2018-01-30T20:07:01Z"^^schema:DateTime ;
    schema:datePublished "2018-01-30T20:07:01Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Generating Wikipedia by Summarizing Long Sequences"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.10198v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9480555348664414627&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<422> a schema:ScholarlyArticle ;
    schema:abstract "Pattern recognition and machine learning techniques have been increasinglyadopted in adversarial settings such as spam, intrusion and malware detection,although their security against well-crafted attacks that aim to evadedetection by manipulating data at test time has not yet been thoroughlyassessed. While previous work has been mainly focused on devisingadversary-aware classification algorithms to counter evasion attempts, only fewauthors have considered the impact of using reduced feature sets on classifiersecurity against the same attacks. An interesting, preliminary result is thatclassifier security to evasion may be even worsened by the application offeature selection. In this paper, we provide a more detailed investigation ofthis aspect, shedding some light on the security properties of featureselection against evasion attacks. Inspired by previous work on adversary-awareclassifiers, we propose a novel adversary-aware feature selection model thatcan improve classifier security against evasion attacks, by incorporatingspecific assumptions on the adversary's data manipulation strategy. We focus onan efficient, wrapper-based implementation of our approach, and experimentallyvalidate its soundness on different application examples, including spam andmalware detection."^^schema:Text ;
    schema:author "Battista Biggio"^^schema:Person,
        "Daniel S. Yeung"^^schema:Person,
        "Fabio Roli"^^schema:Person,
        "Fei Zhang"^^schema:Person,
        "Patrick P. K. Chan"^^schema:Person ;
    schema:commentCount "141"^^schema:Integer ;
    schema:dateModified "2020-05-25T15:05:51Z"^^schema:DateTime ;
    schema:datePublished "2020-05-25T15:05:51Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Feature Selection against Evasion Attacks"^^schema:Text ;
    schema:publisher "IEEE Transactions on Cybernetics 46 (3), 766-777"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/2005.12154v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1282505468086475104&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<423> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks (RNNs) are notoriously difficult to train. When theeigenvalues of the hidden to hidden weight matrix deviate from absolute value1, optimization becomes difficult due to the well studied issue of vanishingand exploding gradients, especially when trying to learn long-termdependencies. To circumvent this problem, we propose a new architecture thatlearns a unitary weight matrix, with eigenvalues of absolute value exactly 1.The challenge we address is that of parametrizing unitary matrices in a waythat does not require expensive computations (such as eigendecomposition) aftereach weight update. We construct an expressive unitary weight matrix bycomposing several structured matrices that act as building blocks withparameters to be learned. Optimization with this parameterization becomesfeasible only when considering hidden states in the complex domain. Wedemonstrate the potential of this architecture by achieving state of the artresults in several hard tasks involving very long-term dependencies."^^schema:Text ;
    schema:author "Amar Shah"^^schema:Person,
        "Martin Arjovsky"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "352"^^schema:Integer ;
    schema:dateModified "2016-05-25T23:34:38Z"^^schema:DateTime ;
    schema:datePublished "2015-11-20T00:37:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unitary Evolution Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1120-1128"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06464v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5030720785335451277&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<424> a schema:ScholarlyArticle ;
    schema:abstract "Semi-supervised learning (SSL) provides a powerful framework for leveragingunlabeled data when labels are limited or expensive to obtain. SSL algorithmsbased on deep neural networks have recently proven successful on standardbenchmark tasks. However, we argue that these benchmarks fail to address manyissues that these algorithms would face in real-world applications. Aftercreating a unified reimplementation of various widely-used SSL techniques, wetest them in a suite of experiments designed to address these issues. We findthat the performance of simple baselines which do not use unlabeled data isoften underreported, that SSL methods differ in sensitivity to the amount oflabeled and unlabeled data, and that performance can degrade substantially whenthe unlabeled dataset contains out-of-class examples. To help guide SSLresearch towards real-world applicability, we make our unified reimplementionand evaluation platform publicly available."^^schema:Text ;
    schema:author "Augustus Odena"^^schema:Person,
        "Avital Oliver"^^schema:Person,
        "Colin Raffel"^^schema:Person,
        "Ekin D. Cubuk"^^schema:Person,
        "Ian J. Goodfellow"^^schema:Person ;
    schema:commentCount "226"^^schema:Integer ;
    schema:dateModified "2019-06-17T11:48:53Z"^^schema:DateTime ;
    schema:datePublished "2018-04-24T17:54:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.09170v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15456844754123849487&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<425> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we present a method for learning a discriminative classifierfrom unlabeled or partially labeled data. Our approach is based on an objectivefunction that trades-off mutual information between observed examples and theirpredicted categorical class distribution, against robustness of the classifierto an adversarial generative model. The resulting algorithm can either beinterpreted as a natural generalization of the generative adversarial networks(GAN) framework or as an extension of the regularized information maximization(RIM) framework to robust classification against an optimal adversary. Weempirically evaluate our method - which we dub categorical generativeadversarial networks (or CatGAN) - on synthetic data as well as on challengingimage classification tasks, demonstrating the robustness of the learnedclassifiers. We further qualitatively assess the fidelity of samples generatedby the adversarial generator that is learned alongside the discriminativeclassifier, and identify links between the CatGAN objective and discriminativeclustering algorithms (such as RIM)."^^schema:Text ;
    schema:author "Jost Tobias Springenberg"^^schema:Person ;
    schema:commentCount "465"^^schema:Integer ;
    schema:dateModified "2016-04-30T21:23:46Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T21:26:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unsupervised and Semi-supervised Learning with Categorical Generative  Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06390v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3077106609105382524&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<426> a schema:ScholarlyArticle ;
    schema:abstract "We describe an image compression method, consisting of a nonlinear analysistransformation, a uniform quantizer, and a nonlinear synthesis transformation.The transforms are constructed in three successive stages of convolutionallinear filters and nonlinear activation functions. Unlike most convolutionalneural networks, the joint nonlinearity is chosen to implement a form of localgain control, inspired by those used to model biological neurons. Using avariant of stochastic gradient descent, we jointly optimize the entire modelfor rate-distortion performance over a database of training images, introducinga continuous proxy for the discontinuous loss function arising from thequantizer. Under certain conditions, the relaxed loss function may beinterpreted as the log likelihood of a generative model, as implemented by avariational autoencoder. Unlike these models, however, the compression modelmust operate at any given point along the rate-distortion curve, as specifiedby a trade-off parameter. Across an independent set of test images, we findthat the optimized method generally exhibits better rate-distortion performancethan the standard JPEG and JPEG 2000 compression methods. More importantly, weobserve a dramatic improvement in visual quality for all images at all bitrates, which is supported by objective quality estimates using MS-SSIM."^^schema:Text ;
    schema:author "Eero P. Simoncelli"^^schema:Person,
        "Johannes Ballé"^^schema:Person,
        "Valero Laparra"^^schema:Person ;
    schema:commentCount "354"^^schema:Integer ;
    schema:dateModified "2017-03-03T14:53:13Z"^^schema:DateTime ;
    schema:datePublished "2016-11-05T21:39:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.IT"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "End-to-end Optimized Image Compression"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01704v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1152338433659809765&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<427> a schema:ScholarlyArticle ;
    schema:abstract "A number of recent works have proposed attention models for Visual QuestionAnswering (VQA) that generate spatial maps highlighting image regions relevantto answering the question. In this paper, we argue that in addition to modeling\"where to look\" or visual attention, it is equally important to model \"whatwords to listen to\" or question attention. We present a novel co-attentionmodel for VQA that jointly reasons about image and question attention. Inaddition, our model reasons about the question (and consequently the image viathe co-attention mechanism) in a hierarchical fashion via a novel 1-dimensionalconvolution neural networks (CNN). Our model improves the state-of-the-art onthe VQA dataset from 60.3% to 60.5%, and from 61.6% to 63.3% on the COCO-QAdataset. By using ResNet, the performance is further improved to 62.1% for VQAand 65.4% for COCO-QA."^^schema:Text ;
    schema:author "Devi Parikh"^^schema:Person,
        "Dhruv Batra"^^schema:Person,
        "Jianwei Yang"^^schema:Person,
        "Jiasen Lu"^^schema:Person ;
    schema:commentCount "744"^^schema:Integer ;
    schema:dateModified "2017-01-19T05:03:33Z"^^schema:DateTime ;
    schema:datePublished "2016-05-31T22:02:01Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Hierarchical Question-Image Co-Attention for Visual Question Answering"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.00061v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15146345852176060026&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<428> a schema:ScholarlyArticle ;
    schema:abstract "There are two major types of uncertainty one can model. Aleatoric uncertaintycaptures noise inherent in the observations. On the other hand, epistemicuncertainty accounts for uncertainty in the model -- uncertainty which can beexplained away given enough data. Traditionally it has been difficult to modelepistemic uncertainty in computer vision, but with new Bayesian deep learningtools this is now possible. We study the benefits of modeling epistemic vs.aleatoric uncertainty in Bayesian deep learning models for vision tasks. Forthis we present a Bayesian deep learning framework combining input-dependentaleatoric uncertainty together with epistemic uncertainty. We study modelsunder the framework with per-pixel semantic segmentation and depth regressiontasks. Further, our explicit uncertainty formulation leads to new lossfunctions for these tasks, which can be interpreted as learned attenuation.This makes the loss more robust to noisy data, also giving new state-of-the-artresults on segmentation and depth regression benchmarks."^^schema:Text ;
    schema:author "Alex Kendall"^^schema:Person,
        "Yarin Gal"^^schema:Person ;
    schema:commentCount "960"^^schema:Integer ;
    schema:dateModified "2017-10-05T13:04:51Z"^^schema:DateTime ;
    schema:datePublished "2017-03-15T07:27:12Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "What Uncertainties Do We Need in Bayesian Deep Learning for Computer  Vision?"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.04977v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6063636260641358531&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<429> a schema:ScholarlyArticle ;
    schema:abstract "We present Deep Voice, a production-quality text-to-speech system constructedentirely from deep neural networks. Deep Voice lays the groundwork for trulyend-to-end neural speech synthesis. The system comprises five major buildingblocks: a segmentation model for locating phoneme boundaries, agrapheme-to-phoneme conversion model, a phoneme duration prediction model, afundamental frequency prediction model, and an audio synthesis model. For thesegmentation model, we propose a novel way of performing phoneme boundarydetection with deep neural networks using connectionist temporal classification(CTC) loss. For the audio synthesis model, we implement a variant of WaveNetthat requires fewer parameters and trains faster than the original. By using aneural network for each component, our system is simpler and more flexible thantraditional text-to-speech systems, where each component requires laboriousfeature engineering and extensive domain expertise. Finally, we show thatinference with our system can be performed faster than real time and describeoptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400xspeedups over existing implementations."^^schema:Text ;
    schema:author "Adam Coates"^^schema:Person,
        "Andrew Gibiansky"^^schema:Person,
        "Andrew Ng"^^schema:Person,
        "Gregory Diamos"^^schema:Person,
        "John Miller"^^schema:Person,
        "Jonathan Raiman"^^schema:Person,
        "Mike Chrzanowski"^^schema:Person,
        "Mohammad Shoeybi"^^schema:Person,
        "Sercan O. Arik"^^schema:Person,
        "Shubho Sengupta"^^schema:Person,
        "Xian Li"^^schema:Person,
        "Yongguo Kang"^^schema:Person ;
    schema:commentCount "292"^^schema:Integer ;
    schema:dateModified "2017-03-07T23:09:23Z"^^schema:DateTime ;
    schema:datePublished "2017-02-25T03:11:04Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.SD"^^schema:Text ;
    schema:headline "Deep Voice: Real-time Neural Text-to-Speech"^^schema:Text ;
    schema:publisher "ICML, 195-204"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.07825v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11354813425104850759&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<43> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks are powerful and flexible models that work well for manydifficult learning tasks in image, speech and natural language understanding.Despite their success, neural networks are still hard to design. In this paper,we use a recurrent network to generate the model descriptions of neuralnetworks and train this RNN with reinforcement learning to maximize theexpected accuracy of the generated architectures on a validation set. On theCIFAR-10 dataset, our method, starting from scratch, can design a novel networkarchitecture that rivals the best human-invented architecture in terms of testset accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is0.09 percent better and 1.05x faster than the previous state-of-the-art modelthat used a similar architectural scheme. On the Penn Treebank dataset, ourmodel can compose a novel recurrent cell that outperforms the widely-used LSTMcell, and other state-of-the-art baselines. Our cell achieves a test setperplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better thanthe previous state-of-the-art model. The cell can also be transferred to thecharacter language modeling task on PTB and achieves a state-of-the-artperplexity of 1.214."^^schema:Text ;
    schema:author "Barret Zoph"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "1657"^^schema:Integer ;
    schema:dateModified "2017-02-15T05:28:05Z"^^schema:DateTime ;
    schema:datePublished "2016-11-05T00:41:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural Architecture Search with Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01578v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4164896773666247762&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<430> a schema:ScholarlyArticle ;
    schema:abstract "We demonstrate a new deep learning autoencoder network, trained by anonnegativity constraint algorithm (NCAE), that learns features which showpart-based representation of data. The learning algorithm is based onconstraining negative weights. The performance of the algorithm is assessedbased on decomposing data into parts and its prediction performance is testedon three standard image data sets and one text dataset. The results indicatethat the nonnegativity constraint forces the autoencoder to learn features thatamount to a part-based representation of data, while improving sparsity andreconstruction quality in comparison with the traditional sparse autoencoderand Nonnegative Matrix Factorization. It is also shown that this newly acquiredrepresentation improves the prediction performance of a deep neural network."^^schema:Text ;
    schema:author "Ehsan Hosseini-Asl"^^schema:Person,
        "Jacek M. Zurada"^^schema:Person,
        "Olfa Nasraoui"^^schema:Person ;
    schema:commentCount "139"^^schema:Integer ;
    schema:dateModified "2016-01-12T05:33:03Z"^^schema:DateTime ;
    schema:datePublished "2016-01-12T05:33:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Learning of Part-based Representation of Data Using Sparse  Autoencoders with Nonnegativity Constraints"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (12), 2486-2498"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1601.02733v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15650513078438307377&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<431> a schema:ScholarlyArticle ;
    schema:abstract "The zero-shot paradigm exploits vector-based word representations extractedfrom text corpora with unsupervised methods to learn general mapping functionsfrom other feature spaces onto word space, where the words associated to thenearest neighbours of the mapped vectors are used as their linguistic labels.We show that the neighbourhoods of the mapped elements are strongly polluted byhubs, vectors that tend to be near a high proportion of items, pushing theircorrect labels down the neighbour list. After illustrating the problemempirically, we propose a simple method to correct it by taking the proximitydistribution of potential neighbours across many mapped vectors into account.We show that this correction leads to consistent improvements in realisticzero-shot experiments in the cross-lingual, image labeling and image retrievaldomains."^^schema:Text ;
    schema:author "Angeliki Lazaridou"^^schema:Person,
        "Georgiana Dinu"^^schema:Person,
        "Marco Baroni"^^schema:Person ;
    schema:commentCount "249"^^schema:Integer ;
    schema:dateModified "2015-04-15T13:10:07Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T01:03:46Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Improving zero-shot learning by mitigating the hubness problem"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6568v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4810137765860435505&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<432> a schema:ScholarlyArticle ;
    schema:abstract "We introduce techniques for rapidly transferring the information stored inone neural net into another neural net. The main purpose is to accelerate thetraining of a significantly larger neural net. During real-world workflows, oneoften trains very many different neural networks during the experimentation anddesign process. This is a wasteful process in which each new model is trainedfrom scratch. Our Net2Net technique accelerates the experimentation process byinstantaneously transferring the knowledge from a previous network to each newdeeper or wider network. Our techniques are based on the concept offunction-preserving transformations between neural network specifications. Thisdiffers from previous approaches to pre-training that altered the functionrepresented by a neural net when adding layers to it. Using our knowledgetransfer mechanism to add depth to Inception modules, we demonstrate a newstate of the art accuracy rating on the ImageNet dataset."^^schema:Text ;
    schema:author "Ian Goodfellow"^^schema:Person,
        "Jonathon Shlens"^^schema:Person,
        "Tianqi Chen"^^schema:Person ;
    schema:commentCount "315"^^schema:Integer ;
    schema:dateModified "2016-04-23T23:14:39Z"^^schema:DateTime ;
    schema:datePublished "2015-11-18T02:09:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Net2Net: Accelerating Learning via Knowledge Transfer"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05641v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2686528528183414981&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<433> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we consider the consensus problem of hybrid multi-agentsystem. First, the hybrid multi-agent system is proposed which is composed ofcontinuous-time and discrete-time dynamic agents. Then, three kinds ofconsensus protocols are presented for hybrid multi-agent system. The analysistool developed in this paper is based on the matrix theory and graph theory.With different restrictions of the sampling period, some necessary andsufficient conditions are established for solving the consensus of hybridmulti-agent system. The consensus states are also obtained under differentprotocols. Finally, simulation examples are provided to demonstrate theeffectiveness of our theoretical results."^^schema:Text ;
    schema:author "Jingying Ma"^^schema:Person,
        "Long Wang"^^schema:Person,
        "Yuanshi Zheng"^^schema:Person ;
    schema:commentCount "169"^^schema:Integer ;
    schema:dateModified "2015-12-10T09:34:22Z"^^schema:DateTime ;
    schema:datePublished "2015-12-10T09:34:22Z"^^schema:DateTime ;
    schema:genre "cs.SY"^^schema:Text ;
    schema:headline "Consensus of Hybrid Multi-agent Systems"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1359-1365"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1512.03189v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5829776190810116561&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<434> a schema:ScholarlyArticle ;
    schema:abstract "The diversity of painting styles represents a rich visual vocabulary for theconstruction of an image. The degree to which one may learn and parsimoniouslycapture this visual vocabulary measures our understanding of the higher levelfeatures of paintings, if not images in general. In this work we investigatethe construction of a single, scalable deep network that can parsimoniouslycapture the artistic style of a diversity of paintings. We demonstrate thatsuch a network generalizes across a diversity of artistic styles by reducing apainting to a point in an embedding space. Importantly, this model permits auser to explore new painting styles by arbitrarily combining the styles learnedfrom individual paintings. We hope that this work provides a useful steptowards building rich models of paintings and offers a window on to thestructure of the learned representation of artistic style."^^schema:Text ;
    schema:author "Jonathon Shlens"^^schema:Person,
        "Manjunath Kudlur"^^schema:Person,
        "Vincent Dumoulin"^^schema:Person ;
    schema:commentCount "424"^^schema:Integer ;
    schema:dateModified "2017-02-09T16:29:09Z"^^schema:DateTime ;
    schema:datePublished "2016-10-24T20:06:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Learned Representation For Artistic Style"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.07629v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7122040962029266183&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<435> a schema:ScholarlyArticle ;
    schema:abstract "Learning an algorithm from examples is a fundamental problem that has beenwidely studied. Recently it has been addressed using neural networks, inparticular by Neural Turing Machines (NTMs). These are fully differentiablecomputers that use backpropagation to learn their own programming. Despitetheir appeal NTMs have a weakness that is caused by their sequential nature:they are not parallel and are are hard to train due to their large depth whenunfolded.  We present a neural network architecture to address this problem: the NeuralGPU. It is based on a type of convolutional gated recurrent unit and, like theNTM, is computationally universal. Unlike the NTM, the Neural GPU is highlyparallel which makes it easier to train and efficient to run.  An essential property of algorithms is their ability to handle inputs ofarbitrary size. We show that the Neural GPU can be trained on short instancesof an algorithmic task and successfully generalize to long instances. Weverified it on a number of tasks including long addition and longmultiplication of numbers represented in binary. We train the Neural GPU onnumbers with upto 20 bits and observe no errors whatsoever while testing it,even on much longer numbers.  To achieve these results we introduce a technique for training deep recurrentnetworks: parameter sharing relaxation. We also found a small amount of dropoutand gradient noise to have a large positive effect on learning andgeneralization."^^schema:Text ;
    schema:author "Ilya Sutskever"^^schema:Person,
        "Łukasz Kaiser"^^schema:Person ;
    schema:commentCount "215"^^schema:Integer ;
    schema:dateModified "2016-03-15T00:20:54Z"^^schema:DateTime ;
    schema:datePublished "2015-11-25T21:17:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural GPUs Learn Algorithms"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.08228v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16991695263235885456&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<436> a schema:ScholarlyArticle ;
    schema:abstract "Learning useful representations without supervision remains a key challengein machine learning. In this paper, we propose a simple yet powerful generativemodel that learns such discrete representations. Our model, the VectorQuantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways:the encoder network outputs discrete, rather than continuous, codes; and theprior is learnt rather than static. In order to learn a discrete latentrepresentation, we incorporate ideas from vector quantisation (VQ). Using theVQ method allows the model to circumvent issues of \"posterior collapse\" --where the latents are ignored when they are paired with a powerfulautoregressive decoder -- typically observed in the VAE framework. Pairingthese representations with an autoregressive prior, the model can generate highquality images, videos, and speech as well as doing high quality speakerconversion and unsupervised learning of phonemes, providing further evidence ofthe utility of the learnt representations."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Oriol Vinyals"^^schema:Person ;
    schema:commentCount "354"^^schema:Integer ;
    schema:dateModified "2018-05-30T14:58:27Z"^^schema:DateTime ;
    schema:datePublished "2017-11-02T21:14:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Neural Discrete Representation Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00937v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9141153084529999933&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<437> a schema:ScholarlyArticle ;
    schema:abstract "The reparameterization trick enables optimizing large scale stochasticcomputation graphs via gradient descent. The essence of the trick is torefactor each stochastic node into a differentiable function of its parametersand a random variable with fixed distribution. After refactoring, the gradientsof the loss propagated by the chain rule through the graph are low varianceunbiased estimators of the gradients of the expected loss. While manycontinuous random variables have such reparameterizations, discrete randomvariables lack useful reparameterizations due to the discontinuous nature ofdiscrete states. In this work we introduce Concrete randomvariables---continuous relaxations of discrete random variables. The Concretedistribution is a new family of distributions with closed form densities and asimple reparameterization. Whenever a discrete stochastic node of a computationgraph can be refactored into a one-hot bit representation that is treatedcontinuously, Concrete stochastic nodes can be used with automaticdifferentiation to produce low-variance biased gradients of objectives(including objectives that depend on the log-probability of latent stochasticnodes) on the corresponding discrete graph. We demonstrate the effectiveness ofConcrete relaxations on density estimation and structured prediction tasksusing neural networks."^^schema:Text ;
    schema:author "Andriy Mnih"^^schema:Person,
        "Chris J. Maddison"^^schema:Person,
        "Yee Whye Teh"^^schema:Person ;
    schema:commentCount "846"^^schema:Integer ;
    schema:dateModified "2017-03-05T16:59:44Z"^^schema:DateTime ;
    schema:datePublished "2016-11-02T18:25:40Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Concrete Distribution: A Continuous Relaxation of Discrete Random  Variables"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.00712v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16482228288411412158&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<438> a schema:ScholarlyArticle ;
    schema:abstract "Variational Autoencoders are powerful models for unsupervised learning.However deep models with several layers of dependent stochastic variables aredifficult to train which limits the improvements obtained using these highlyexpressive models. We propose a new inference model, the Ladder VariationalAutoencoder, that recursively corrects the generative distribution by a datadependent approximate likelihood in a process resembling the recently proposedLadder Network. We show that this model provides state of the art predictivelog-likelihood and tighter log-likelihood lower bound compared to the purelybottom-up inference in layered Variational Autoencoders and other generativemodels. We provide a detailed analysis of the learned hierarchical latentrepresentation and show that our new inference model is qualitatively differentand utilizes a deeper more distributed hierarchy of latent variables. Finally,we observe that batch normalization and deterministic warm-up (graduallyturning on the KL-term) are crucial for training variational models with manystochastic layers."^^schema:Text ;
    schema:author "Casper Kaae Sønderby"^^schema:Person,
        "Lars Maaløe"^^schema:Person,
        "Ole Winther"^^schema:Person,
        "Søren Kaae Sønderby"^^schema:Person,
        "Tapani Raiko"^^schema:Person ;
    schema:commentCount "337"^^schema:Integer ;
    schema:dateModified "2016-05-27T09:05:10Z"^^schema:DateTime ;
    schema:datePublished "2016-02-06T17:32:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Ladder Variational Autoencoders"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02282v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1323199474868567922&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<439> a schema:ScholarlyArticle ;
    schema:abstract "Bellemare et al. (2016) introduced the notion of a pseudo-count, derived froma density model, to generalize count-based exploration to non-tabularreinforcement learning. This pseudo-count was used to generate an explorationbonus for a DQN agent and combined with a mixed Monte Carlo update wassufficient to achieve state of the art on the Atari 2600 game Montezuma'sRevenge. We consider two questions left open by their work: First, howimportant is the quality of the density model for exploration? Second, whatrole does the Monte Carlo update play in exploration? We answer the firstquestion by demonstrating the use of PixelCNN, an advanced neural density modelfor images, to supply a pseudo-count. In particular, we examine the intrinsicdifficulties in adapting Bellemare et al.'s approach when assumptions about themodel are violated. The result is a more practical and general algorithmrequiring no special apparatus. We combine PixelCNN pseudo-counts withdifferent agent architectures to dramatically improve the state of the art onseveral hard Atari games. One surprising finding is that the mixed Monte Carloupdate is a powerful facilitator of exploration in the sparsest of settings,including Montezuma's Revenge."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Georg Ostrovski"^^schema:Person,
        "Marc G. Bellemare"^^schema:Person,
        "Remi Munos"^^schema:Person ;
    schema:commentCount "219"^^schema:Integer ;
    schema:dateModified "2017-06-14T13:56:28Z"^^schema:DateTime ;
    schema:datePublished "2017-03-03T19:07:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Count-Based Exploration with Neural Density Models"^^schema:Text ;
    schema:publisher "ICML, 2721-2730"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01310v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7236095966352642924&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<44> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks have demonstrated high accuracy on varioustasks in recent years. However, they are extremely vulnerable to adversarialexamples. For example, imperceptible perturbations added to clean images cancause convolutional neural networks to fail. In this paper, we propose toutilize randomization at inference time to mitigate adversarial effects.Specifically, we use two randomization operations: random resizing, whichresizes the input images to a random size, and random padding, which pads zerosaround the input images in a random manner. Extensive experiments demonstratethat the proposed randomization method is very effective at defending againstboth single-step and iterative attacks. Our method provides the followingadvantages: 1) no additional training or fine-tuning, 2) very few additionalcomputations, 3) compatible with other adversarial defense methods. Bycombining the proposed randomization method with an adversarially trainedmodel, it achieves a normalized score of 0.924 (ranked No.2 among 107 defenseteams) in the NIPS 2017 adversarial examples defense challenge, which is farbetter than using adversarial training alone with a normalized score of 0.773(ranked No.56). The code is public available athttps://github.com/cihangxie/NIPS2017_adv_challenge_defense."^^schema:Text ;
    schema:author "Alan Yuille"^^schema:Person,
        "Cihang Xie"^^schema:Person,
        "Jianyu Wang"^^schema:Person,
        "Zhishuai Zhang"^^schema:Person,
        "Zhou Ren"^^schema:Person ;
    schema:commentCount "292"^^schema:Integer ;
    schema:dateModified "2018-02-28T22:39:15Z"^^schema:DateTime ;
    schema:datePublished "2017-11-06T16:22:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Mitigating Adversarial Effects Through Randomization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.01991v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1119418123159333221&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<440> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised image-to-image translation aims at learning a joint distributionof images in different domains by using images from the marginal distributionsin individual domains. Since there exists an infinite set of jointdistributions that can arrive the given marginal distributions, one could infernothing about the joint distribution from the marginal distributions withoutadditional assumptions. To address the problem, we make a shared-latent spaceassumption and propose an unsupervised image-to-image translation frameworkbased on Coupled GANs. We compare the proposed framework with competingapproaches and present high quality image translation results on variouschallenging unsupervised image translation tasks, including street scene imagetranslation, animal image translation, and face image translation. We alsoapply the proposed framework to domain adaptation and achieve state-of-the-artperformance on benchmark datasets. Code and additional results are available inhttps://github.com/mingyuliutw/unit ."^^schema:Text ;
    schema:author "Jan Kautz"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Thomas Breuel"^^schema:Person ;
    schema:commentCount "1057"^^schema:Integer ;
    schema:dateModified "2018-07-23T03:39:28Z"^^schema:DateTime ;
    schema:datePublished "2017-03-02T16:29:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Image-to-Image Translation Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00848v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14169741715291172305&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<441> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks (NNs) are powerful black box predictors that haverecently achieved impressive performance on a wide spectrum of tasks.Quantifying predictive uncertainty in NNs is a challenging and yet unsolvedproblem. Bayesian NNs, which learn a distribution over weights, are currentlythe state-of-the-art for estimating predictive uncertainty; however theserequire significant modifications to the training procedure and arecomputationally expensive compared to standard (non-Bayesian) NNs. We proposean alternative to Bayesian NNs that is simple to implement, readilyparallelizable, requires very little hyperparameter tuning, and yields highquality predictive uncertainty estimates. Through a series of experiments onclassification and regression benchmarks, we demonstrate that our methodproduces well-calibrated uncertainty estimates which are as good or better thanapproximate Bayesian NNs. To assess robustness to dataset shift, we evaluatethe predictive uncertainty on test examples from known and unknowndistributions, and show that our method is able to express higher uncertaintyon out-of-distribution examples. We demonstrate the scalability of our methodby evaluating predictive uncertainty estimates on ImageNet."^^schema:Text ;
    schema:author "Alexander Pritzel"^^schema:Person,
        "Balaji Lakshminarayanan"^^schema:Person,
        "Charles Blundell"^^schema:Person ;
    schema:commentCount "732"^^schema:Integer ;
    schema:dateModified "2017-11-04T01:33:43Z"^^schema:DateTime ;
    schema:datePublished "2016-12-05T18:54:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Simple and Scalable Predictive Uncertainty Estimation using Deep  Ensembles"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.01474v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15810892316109997085&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<442> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) excel at creating realistic imageswith complex models for which maximum likelihood is infeasible. However, theconvergence of GAN training has still not been proved. We propose a twotime-scale update rule (TTUR) for training GANs with stochastic gradientdescent on arbitrary GAN loss functions. TTUR has an individual learning ratefor both the discriminator and the generator. Using the theory of stochasticapproximation, we prove that the TTUR converges under mild assumptions to astationary local Nash equilibrium. The convergence carries over to the popularAdam optimization, for which we prove that it follows the dynamics of a heavyball with friction and thus prefers flat minima in the objective landscape. Forthe evaluation of the performance of GANs at image generation, we introduce the\"Fr\\'echet Inception Distance\" (FID) which captures the similarity of generatedimages to real ones better than the Inception Score. In experiments, TTURimproves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUNBedrooms, and the One Billion Word Benchmark."^^schema:Text ;
    schema:author "Bernhard Nessler"^^schema:Person,
        "Hubert Ramsauer"^^schema:Person,
        "Martin Heusel"^^schema:Person,
        "Sepp Hochreiter"^^schema:Person,
        "Thomas Unterthiner"^^schema:Person ;
    schema:commentCount "1554"^^schema:Integer ;
    schema:dateModified "2018-01-12T14:05:44Z"^^schema:DateTime ;
    schema:datePublished "2017-06-26T17:45:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash  Equilibrium"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.08500v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15143899073250151317&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<443> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we propose a novel model for unconditional audio generationbased on generating one audio sample at a time. We show that our model, whichprofits from combining memory-less modules, namely autoregressive multilayerperceptrons, and stateful recurrent neural networks in a hierarchical structureis able to capture underlying sources of variations in the temporal sequencesover very long time spans, on three datasets of different nature. Humanevaluation on the generated samples indicate that our model is preferred overcompeting models. We also show how each component of the model contributes tothe exhibited performance."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Ishaan Gulrajani"^^schema:Person,
        "Jose Sotelo"^^schema:Person,
        "Kundan Kumar"^^schema:Person,
        "Rithesh Kumar"^^schema:Person,
        "Shubham Jain"^^schema:Person,
        "Soroush Mehri"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "292"^^schema:Integer ;
    schema:dateModified "2017-02-11T20:04:46Z"^^schema:DateTime ;
    schema:datePublished "2016-12-22T23:28:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.SD"^^schema:Text ;
    schema:headline "SampleRNN: An Unconditional End-to-End Neural Audio Generation Model"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.07837v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18296195672519025121&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<444> a schema:ScholarlyArticle ;
    schema:abstract "Perception and expression of emotion are key factors to the success ofdialogue systems or conversational agents. However, this problem has not beenstudied in large-scale conversation generation so far. In this paper, wepropose Emotional Chatting Machine (ECM) that can generate appropriateresponses not only in content (relevant and grammatical) but also in emotion(emotionally consistent). To the best of our knowledge, this is the first workthat addresses the emotion factor in large-scale conversation generation. ECMaddresses the factor using three new mechanisms that respectively (1) modelsthe high-level abstraction of emotion expressions by embedding emotioncategories, (2) captures the change of implicit internal emotion states, and(3) uses explicit emotion expressions with an external emotion vocabulary.Experiments show that the proposed model can generate responses appropriate notonly in content but also in emotion."^^schema:Text ;
    schema:author "Bing Liu"^^schema:Person,
        "Hao Zhou"^^schema:Person,
        "Minlie Huang"^^schema:Person,
        "Tianyang Zhang"^^schema:Person,
        "Xiaoyan Zhu"^^schema:Person ;
    schema:commentCount "250"^^schema:Integer ;
    schema:dateModified "2018-06-01T03:38:59Z"^^schema:DateTime ;
    schema:datePublished "2017-04-04T15:44:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Emotional Chatting Machine: Emotional Conversation Generation with  Internal and External Memory"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.01074v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13075172936856719627&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<445> a schema:ScholarlyArticle ;
    schema:abstract "Techniques for automatically designing deep neural network architectures suchas reinforcement learning based approaches have recently shown promisingresults. However, their success is based on vast computational resources (e.g.hundreds of GPUs), making them difficult to be widely used. A noticeablelimitation is that they still design and train each network from scratch duringthe exploration of the architecture space, which is highly inefficient. In thispaper, we propose a new framework toward efficient architecture search byexploring the architecture space based on the current network and reusing itsweights. We employ a reinforcement learning agent as the meta-controller, whoseaction is to grow the network depth or layer width with function-preservingtransformations. As such, the previously validated networks can be reused forfurther exploration, thus saves a large amount of computational cost. We applyour method to explore the architecture space of the plain convolutional neuralnetworks (no skip-connections, branching etc.) on image benchmark datasets(CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our methodcan design highly competitive networks that outperform existing networks usingthe same design scheme. On CIFAR-10, our model without skip-connectionsachieves 4.23\\% test error rate, exceeding a vast majority of modernarchitectures and approaching DenseNet. Furthermore, by applying our method toexplore the DenseNet architecture space, we are able to achieve more accuratenetworks with fewer parameters."^^schema:Text ;
    schema:author "Han Cai"^^schema:Person,
        "Jun Wang"^^schema:Person,
        "Tianyao Chen"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Yong Yu"^^schema:Person ;
    schema:commentCount "195"^^schema:Integer ;
    schema:dateModified "2017-11-21T08:38:04Z"^^schema:DateTime ;
    schema:datePublished "2017-07-16T12:39:02Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Efficient Architecture Search by Network Transformation"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.04873v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2416480494986570854&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<446> a schema:ScholarlyArticle ;
    schema:abstract "Most distributed machine learning systems nowadays, including TensorFlow andCNTK, are built in a centralized fashion. One bottleneck of centralizedalgorithms lies on high communication cost on the central node. Motivated bythis, we ask, can decentralized algorithms be faster than its centralizedcounterpart?  Although decentralized PSGD (D-PSGD) algorithms have been studied by thecontrol community, existing analysis and theory do not show any advantage overcentralized PSGD (C-PSGD) algorithms, simply assuming the application scenariowhere only the decentralized network is available. In this paper, we study aD-PSGD algorithm and provide the first theoretical analysis that indicates aregime in which decentralized algorithms might outperform centralizedalgorithms for distributed stochastic gradient descent. This is because D-PSGDhas comparable total computational complexities to C-PSGD but requires muchless communication cost on the busiest node. We further conduct an empiricalstudy to validate our theoretical analysis across multiple frameworks (CNTK andTorch), different network configurations, and computation platforms up to 112GPUs. On network configurations with low bandwidth or high latency, D-PSGD canbe up to one order of magnitude faster than its well-optimized centralizedcounterparts."^^schema:Text ;
    schema:author "Ce Zhang"^^schema:Person,
        "Cho-Jui Hsieh"^^schema:Person,
        "Huan Zhang"^^schema:Person,
        "Ji Liu"^^schema:Person,
        "Wei Zhang"^^schema:Person,
        "Xiangru Lian"^^schema:Person ;
    schema:commentCount "219"^^schema:Integer ;
    schema:dateModified "2017-09-11T04:21:43Z"^^schema:DateTime ;
    schema:datePublished "2017-05-25T05:58:17Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Can Decentralized Algorithms Outperform Centralized Algorithms? A Case  Study for Decentralized Parallel Stochastic Gradient Descent"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.09056v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18334580252706636011&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<447> a schema:ScholarlyArticle ;
    schema:abstract "Large-scale distributed training requires significant communication bandwidthfor gradient exchange that limits the scalability of multi-node training, andrequires expensive high-bandwidth network infrastructure. The situation getseven worse with distributed training on mobile devices (federated learning),which suffers from higher latency, lower throughput, and intermittent poorconnections. In this paper, we find 99.9% of the gradient exchange indistributed SGD is redundant, and propose Deep Gradient Compression (DGC) togreatly reduce the communication bandwidth. To preserve accuracy duringcompression, DGC employs four methods: momentum correction, local gradientclipping, momentum factor masking, and warm-up training. We have applied DeepGradient Compression to image classification, speech recognition, and languagemodeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, andLibrispeech Corpus. On these scenarios, Deep Gradient Compression achieves agradient compression ratio from 270x to 600x without losing accuracy, cuttingthe gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from488MB to 0.74MB. Deep gradient compression enables large-scale distributedtraining on inexpensive commodity 1Gbps Ethernet and facilitates distributedtraining on mobile. Code is available at:https://github.com/synxlin/deep-gradient-compression."^^schema:Text ;
    schema:author "Huizi Mao"^^schema:Person,
        "Song Han"^^schema:Person,
        "William J. Dally"^^schema:Person,
        "Yu Wang"^^schema:Person,
        "Yujun Lin"^^schema:Person ;
    schema:commentCount "298"^^schema:Integer ;
    schema:dateModified "2020-06-23T03:28:30Z"^^schema:DateTime ;
    schema:datePublished "2017-12-05T19:48:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Gradient Compression: Reducing the Communication Bandwidth for  Distributed Training"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.01887v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2485379403852124678&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<448> a schema:ScholarlyArticle ;
    schema:abstract "Compression and computational efficiency in deep learning have become aproblem of great significance. In this work, we argue that the most principledand effective way to attack this problem is by adopting a Bayesian point ofview, where through sparsity inducing priors we prune large parts of thenetwork. We introduce two novelties in this paper: 1) we use hierarchicalpriors to prune nodes instead of individual weights, and 2) we use theposterior uncertainties to determine the optimal fixed point precision toencode the weights. Both factors significantly contribute to achieving thestate of the art in terms of compression rates, while still staying competitivewith methods designed to optimize for speed or energy efficiency."^^schema:Text ;
    schema:author "Christos Louizos"^^schema:Person,
        "Karen Ullrich"^^schema:Person,
        "Max Welling"^^schema:Person ;
    schema:commentCount "232"^^schema:Integer ;
    schema:dateModified "2017-11-06T12:46:40Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T09:07:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Bayesian Compression for Deep Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08665v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12642526032245768258&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<449> a schema:ScholarlyArticle ;
    schema:abstract "The recently proposed Temporal Ensembling has achieved state-of-the-artresults in several semi-supervised learning benchmarks. It maintains anexponential moving average of label predictions on each training example, andpenalizes predictions that are inconsistent with this target. However, becausethe targets change only once per epoch, Temporal Ensembling becomes unwieldywhen learning large datasets. To overcome this problem, we propose MeanTeacher, a method that averages model weights instead of label predictions. Asan additional benefit, Mean Teacher improves test accuracy and enables trainingwith fewer labels than Temporal Ensembling. Without changing the networkarchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250labels, outperforming Temporal Ensembling trained with 1000 labels. We alsoshow that a good network architecture is crucial to performance. Combining MeanTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labelsfrom 35.24% to 9.11%."^^schema:Text ;
    schema:author "Antti Tarvainen"^^schema:Person,
        "Harri Valpola"^^schema:Person ;
    schema:commentCount "480"^^schema:Integer ;
    schema:dateModified "2018-04-16T10:39:11Z"^^schema:DateTime ;
    schema:datePublished "2017-03-06T09:34:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Mean teachers are better role models: Weight-averaged consistency  targets improve semi-supervised deep learning results"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.01780v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3256042804843589088&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<45> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning models are often susceptible to adversarial perturbations oftheir inputs. Even small perturbations can cause state-of-the-art classifierswith high \"standard\" accuracy to produce an incorrect prediction with highconfidence. To better understand this phenomenon, we study adversarially robustlearning from the viewpoint of generalization. We show that already in a simplenatural data model, the sample complexity of robust learning can besignificantly larger than that of \"standard\" learning. This gap is informationtheoretic and holds irrespective of the training algorithm or the model family.We complement our theoretical results with experiments on popular imageclassification datasets and show that a similar gap exists here as well. Wepostulate that the difficulty of training robust classifiers stems, at leastpartially, from this inherently larger sample complexity."^^schema:Text ;
    schema:author "Aleksander Mądry"^^schema:Person,
        "Dimitris Tsipras"^^schema:Person,
        "Kunal Talwar"^^schema:Person,
        "Ludwig Schmidt"^^schema:Person,
        "Shibani Santurkar"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2018-05-02T05:24:33Z"^^schema:DateTime ;
    schema:datePublished "2018-04-30T15:55:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarially Robust Generalization Requires More Data"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.11285v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11617408739335906297&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<450> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we present the mQA model, which is able to answer questionsabout the content of an image. The answer can be a sentence, a phrase or asingle word. Our model contains four components: a Long Short-Term Memory(LSTM) to extract the question representation, a Convolutional Neural Network(CNN) to extract the visual representation, an LSTM for storing the linguisticcontext in an answer, and a fusing component to combine the information fromthe first three components and generate the answer. We construct a FreestyleMultilingual Image Question Answering (FM-IQA) dataset to train and evaluateour mQA model. It contains over 150,000 images and 310,000 freestyle Chinesequestion-answer pairs and their English translations. The quality of thegenerated answers of our mQA model on this dataset is evaluated by human judgesthrough a Turing Test. Specifically, we mix the answers provided by humans andour model. The human judges need to distinguish our model from the human. Theywill also provide a score (i.e. 0, 1, 2, the larger the better) indicating thequality of the answer. We propose strategies to monitor the quality of thisevaluation process. The experiments show that in 64.7% of cases, the humanjudges cannot distinguish our model from humans. The average score is 1.454(1.918 for human). The details of this work, including the FM-IQA dataset, canbe found on the project page: http://idl.baidu.com/FM-IQA.html"^^schema:Text ;
    schema:author "Haoyuan Gao"^^schema:Person,
        "Jie Zhou"^^schema:Person,
        "Junhua Mao"^^schema:Person,
        "Lei Wang"^^schema:Person,
        "Wei Xu"^^schema:Person,
        "Zhiheng Huang"^^schema:Person ;
    schema:commentCount "362"^^schema:Integer ;
    schema:dateModified "2015-11-02T21:12:15Z"^^schema:DateTime ;
    schema:datePublished "2015-05-21T06:09:36Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.2.7; I.2.10"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Are You Talking to a Machine? Dataset and Methods for Multilingual Image  Question Answering"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.05612v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14623509836487873093&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<451> a schema:ScholarlyArticle ;
    schema:abstract "We show that training of generative adversarial network (GAN) may not havegood generalization properties; e.g., training may appear successful but thetrained distribution may be far from target distribution in standard metrics.However, generalization does occur for a weaker metric called neural netdistance. It is also shown that an approximate pure equilibrium exists in thediscriminator/generator game for a special class of generators with naturaltraining objectives when generator capacity and training set sizes aremoderate.  This existence of equilibrium inspires MIX+GAN protocol, which can becombined with any existing GAN training, and empirically shown to improve someof them."^^schema:Text ;
    schema:author "Rong Ge"^^schema:Person,
        "Sanjeev Arora"^^schema:Person,
        "Tengyu Ma"^^schema:Person,
        "Yi Zhang"^^schema:Person,
        "Yingyu Liang"^^schema:Person ;
    schema:commentCount "309"^^schema:Integer ;
    schema:dateModified "2017-08-01T19:51:56Z"^^schema:DateTime ;
    schema:datePublished "2017-03-02T01:14:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generalization and Equilibrium in Generative Adversarial Nets (GANs)"^^schema:Text ;
    schema:publisher "ICML, 224-232"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00573v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11124082639758751800&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<452> a schema:ScholarlyArticle ;
    schema:abstract "We investigate the task of building open domain, conversational dialoguesystems based on large dialogue corpora using generative models. Generativemodels produce system responses that are autonomously generated word-by-word,opening up the possibility for realistic, flexible interactions. In support ofthis goal, we extend the recently proposed hierarchical recurrentencoder-decoder neural network to the dialogue domain, and demonstrate thatthis model is competitive with state-of-the-art neural language models andback-off n-gram models. We investigate the limitations of this and similarapproaches, and show how its performance can be improved by bootstrapping thelearning from a larger question-answer pair corpus and from pretrained wordembeddings."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Alessandro Sordoni"^^schema:Person,
        "Iulian V. Serban"^^schema:Person,
        "Joelle Pineau"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "1067"^^schema:Integer ;
    schema:dateModified "2016-04-06T23:20:41Z"^^schema:DateTime ;
    schema:datePublished "2015-07-17T00:21:39Z"^^schema:DateTime ;
    schema:genre "I.5.1; I.2.7"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Building End-To-End Dialogue Systems Using Generative Hierarchical  Neural Network Models"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.04808v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2745297076509838691&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<453> a schema:ScholarlyArticle ;
    schema:abstract "We present region-based, fully convolutional networks for accurate andefficient object detection. In contrast to previous region-based detectors suchas Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds oftimes, our region-based detector is fully convolutional with almost allcomputation shared on the entire image. To achieve this goal, we proposeposition-sensitive score maps to address a dilemma betweentranslation-invariance in image classification and translation-variance inobject detection. Our method can thus naturally adopt fully convolutional imageclassifier backbones, such as the latest Residual Networks (ResNets), forobject detection. We show competitive results on the PASCAL VOC datasets (e.g.,83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result isachieved at a test-time speed of 170ms per image, 2.5-20x faster than theFaster R-CNN counterpart. Code is made publicly available at:https://github.com/daijifeng001/r-fcn"^^schema:Text ;
    schema:author "Jian Sun"^^schema:Person,
        "Jifeng Dai"^^schema:Person,
        "Kaiming He"^^schema:Person,
        "Yi Li"^^schema:Person ;
    schema:commentCount "2676"^^schema:Integer ;
    schema:dateModified "2016-06-21T15:28:57Z"^^schema:DateTime ;
    schema:datePublished "2016-05-20T15:50:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "R-FCN: Object Detection via Region-based Fully Convolutional Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06409v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14880935744314366653&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<454> a schema:ScholarlyArticle ;
    schema:abstract "A novel variational autoencoder is developed to model images, as well asassociated labels or captions. The Deep Generative Deconvolutional Network(DGDN) is used as a decoder of the latent image features, and a deepConvolutional Neural Network (CNN) is used as an image encoder; the CNN is usedto approximate a distribution for the latent DGDN features/code. The latentcode is also linked to generative models for labels (Bayesian support vectormachine) or captions (recurrent neural network). When predicting alabel/caption for a new image at test, averaging is performed across thedistribution of latent codes; this is computationally efficient as aconsequence of the learned CNN-based encoder. Since the framework is capable ofmodeling the image in the presence/absence of associated labels/captions, a newsemi-supervised setting is manifested for CNN learning with images; theframework even allows unsupervised CNN learning, based on images alone."^^schema:Text ;
    schema:author "Andrew Stevens"^^schema:Person,
        "Chunyuan Li"^^schema:Person,
        "Lawrence Carin"^^schema:Person,
        "Ricardo Henao"^^schema:Person,
        "Xin Yuan"^^schema:Person,
        "Yunchen Pu"^^schema:Person,
        "Zhe Gan"^^schema:Person ;
    schema:commentCount "325"^^schema:Integer ;
    schema:dateModified "2016-09-28T15:56:15Z"^^schema:DateTime ;
    schema:datePublished "2016-09-28T15:56:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Autoencoder for Deep Learning of Images, Labels and Captions"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.08976v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6882187919491425397&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<455> a schema:ScholarlyArticle ;
    schema:abstract "The Teacher Forcing algorithm trains recurrent networks by supplying observedsequence values as inputs during training and using the network's ownone-step-ahead predictions to do multi-step sampling. We introduce theProfessor Forcing algorithm, which uses adversarial domain adaptation toencourage the dynamics of the recurrent network to be the same when trainingthe network and when sampling from the network over multiple time steps. Weapply Professor Forcing to language modeling, vocal synthesis on raw waveforms,handwriting generation, and image generation. Empirically we find thatProfessor Forcing acts as a regularizer, improving test likelihood on characterlevel Penn Treebank and sequential MNIST. We also find that the modelqualitatively improves samples, especially when sampling for a large number oftime steps. This is supported by human evaluation of sample quality. Trade-offsbetween Professor Forcing and Scheduled Sampling are discussed. We produceT-SNEs showing that Professor Forcing successfully makes the dynamics of thenetwork during training and sampling more similar."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Alex Lamb"^^schema:Person,
        "Anirudh Goyal"^^schema:Person,
        "Saizheng Zhang"^^schema:Person,
        "Ying Zhang"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "267"^^schema:Integer ;
    schema:dateModified "2016-10-27T23:54:31Z"^^schema:DateTime ;
    schema:datePublished "2016-10-27T23:54:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Professor Forcing: A New Algorithm for Training Recurrent Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.09038v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17198780094986434106&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<456> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay lets online reinforcement learning agents remember andreuse experiences from the past. In prior work, experience transitions wereuniformly sampled from a replay memory. However, this approach simply replaystransitions at the same frequency that they were originally experienced,regardless of their significance. In this paper we develop a framework forprioritizing experience, so as to replay important transitions more frequently,and therefore learn more efficiently. We use prioritized experience replay inDeep Q-Networks (DQN), a reinforcement learning algorithm that achievedhuman-level performance across many Atari games. DQN with prioritizedexperience replay achieves a new state-of-the-art, outperforming DQN withuniform replay on 41 out of 49 games."^^schema:Text ;
    schema:author "David Silver"^^schema:Person,
        "Ioannis Antonoglou"^^schema:Person,
        "John Quan"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:commentCount "1312"^^schema:Integer ;
    schema:dateModified "2016-02-25T17:55:31Z"^^schema:DateTime ;
    schema:datePublished "2015-11-18T20:54:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Prioritized Experience Replay"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05952v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10780652695290317509&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<457> a schema:ScholarlyArticle ;
    schema:abstract "One of the challenges in the study of generative adversarial networks is theinstability of its training. In this paper, we propose a novel weightnormalization technique called spectral normalization to stabilize the trainingof the discriminator. Our new normalization technique is computationally lightand easy to incorporate into existing implementations. We tested the efficacyof spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and weexperimentally confirmed that spectrally normalized GANs (SN-GANs) is capableof generating images of better or equal quality relative to the previoustraining stabilization techniques."^^schema:Text ;
    schema:author "Masanori Koyama"^^schema:Person,
        "Takeru Miyato"^^schema:Person,
        "Toshiki Kataoka"^^schema:Person,
        "Yuichi Yoshida"^^schema:Person ;
    schema:commentCount "1167"^^schema:Integer ;
    schema:dateModified "2018-02-16T14:41:39Z"^^schema:DateTime ;
    schema:datePublished "2018-02-16T14:41:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Spectral Normalization for Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.05957v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=973410365172845184&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<458> a schema:ScholarlyArticle ;
    schema:abstract "A good dialogue agent should have the ability to interact with users by bothresponding to questions and by asking questions, and importantly to learn fromboth types of interaction. In this work, we explore this direction by designinga simulator and a set of synthetic tasks in the movie domain that allow suchinteractions between a learner and a teacher. We investigate how a learner canbenefit from asking questions in both offline and online reinforcement learningsettings, and demonstrate that the learner improves when asking questions.Finally, real experiments with Mechanical Turk validate the approach. Our workrepresents a first step in developing such end-to-end learned interactivedialogue agents."^^schema:Text ;
    schema:author "Alexander H. Miller"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Jiwei Li"^^schema:Person,
        "Marc'Aurelio Ranzato"^^schema:Person,
        "Sumit Chopra"^^schema:Person ;
    schema:commentCount "247"^^schema:Integer ;
    schema:dateModified "2017-02-13T17:30:42Z"^^schema:DateTime ;
    schema:datePublished "2016-12-15T05:46:27Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Learning through Dialogue Interactions by Asking Questions"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.04936v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16142141925331698351&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<459> a schema:ScholarlyArticle ;
    schema:abstract "We propose a general modeling and inference framework that composesprobabilistic graphical models with deep learning methods and combines theirrespective strengths. Our model family augments graphical structure in latentvariables with neural network observation models. For inference, we extendvariational autoencoders to use graphical model approximating distributionswith recognition networks that output conjugate potentials. All components ofthese models are learned simultaneously with a single objective, giving ascalable algorithm that leverages stochastic variational inference, naturalgradients, graphical model message passing, and the reparameterization trick.We illustrate this framework with several example models and an application tomouse behavioral phenotyping."^^schema:Text ;
    schema:author "Alexander B. Wiltschko"^^schema:Person,
        "David Duvenaud"^^schema:Person,
        "Matthew J. Johnson"^^schema:Person,
        "Ryan P. Adams"^^schema:Person,
        "Sandeep R. Datta"^^schema:Person ;
    schema:commentCount "270"^^schema:Integer ;
    schema:dateModified "2017-07-07T16:00:42Z"^^schema:DateTime ;
    schema:datePublished "2016-03-20T22:01:02Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Composing graphical models with neural networks for structured  representations and fast inference"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.06277v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12286587149980999415&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<46> a schema:ScholarlyArticle ;
    schema:abstract "Model-based reinforcement learning (RL) algorithms can attain excellentsample efficiency, but often lag behind the best model-free algorithms in termsof asymptotic performance. This is especially true with high-capacityparametric function approximators, such as deep networks. In this paper, westudy how to bridge this gap, by employing uncertainty-aware dynamics models.We propose a new algorithm called probabilistic ensembles with trajectorysampling (PETS) that combines uncertainty-aware deep network dynamics modelswith sampling-based uncertainty propagation. Our comparison to state-of-the-artmodel-based and model-free deep RL algorithms shows that our approach matchesthe asymptotic performance of model-free algorithms on several challengingbenchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125times fewer samples than Soft Actor Critic and Proximal Policy Optimizationrespectively on the half-cheetah task)."^^schema:Text ;
    schema:author "Kurtland Chua"^^schema:Person,
        "Roberto Calandra"^^schema:Person,
        "Rowan McAllister"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "208"^^schema:Integer ;
    schema:dateModified "2018-11-02T17:19:02Z"^^schema:DateTime ;
    schema:datePublished "2018-05-30T17:55:21Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning in a Handful of Trials using Probabilistic  Dynamics Models"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.12114v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6248399848380977147&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<460> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (RL) has achieved several high profile successesin difficult decision-making problems. However, these algorithms typicallyrequire a huge amount of data before they reach reasonable performance. Infact, their performance during learning can be extremely poor. This may beacceptable for a simulator, but it severely limits the applicability of deep RLto many real-world tasks, where the agent must learn in the real environment.In this paper we study a setting where the agent may access data from previouscontrol of the system. We present an algorithm, Deep Q-learning fromDemonstrations (DQfD), that leverages small sets of demonstration data tomassively accelerate the learning process even from relatively small amounts ofdemonstration data and is able to automatically assess the necessary ratio ofdemonstration data while learning thanks to a prioritized replay mechanism.DQfD works by combining temporal difference updates with supervisedclassification of the demonstrator's actions. We show that DQfD has betterinitial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN)as it starts with better scores on the first million steps on 41 of 42 gamesand on average it takes PDD DQN 83 million steps to catch up to DQfD'sperformance. DQfD learns to out-perform the best demonstration given in 14 of42 games. In addition, DQfD leverages human demonstrations to achievestate-of-the-art results for 11 games. Finally, we show that DQfD performsbetter than three related algorithms for incorporating demonstration data intoDQN."^^schema:Text ;
    schema:author "Andrew Sendonaris"^^schema:Person,
        "Audrunas Gruslys"^^schema:Person,
        "Bilal Piot"^^schema:Person,
        "Dan Horgan"^^schema:Person,
        "Gabriel Dulac-Arnold"^^schema:Person,
        "Ian Osband"^^schema:Person,
        "Joel Z. Leibo"^^schema:Person,
        "John Agapiou"^^schema:Person,
        "John Quan"^^schema:Person,
        "Marc Lanctot"^^schema:Person,
        "Matej Vecerik"^^schema:Person,
        "Olivier Pietquin"^^schema:Person,
        "Todd Hester"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:commentCount "284"^^schema:Integer ;
    schema:dateModified "2017-11-22T21:18:31Z"^^schema:DateTime ;
    schema:datePublished "2017-04-12T12:44:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Q-learning from Demonstrations"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.03732v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6225249527608914570&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<461> a schema:ScholarlyArticle ;
    schema:abstract "There is intense interest in applying machine learning to problems of causalinference in fields such as healthcare, economics and education. In particular,individual-level causal inference has important applications such as precisionmedicine. We give a new theoretical analysis and family of algorithms forpredicting individual treatment effect (ITE) from observational data, under theassumption known as strong ignorability. The algorithms learn a \"balanced\"representation such that the induced treated and control distributions looksimilar. We give a novel, simple and intuitive generalization-error boundshowing that the expected ITE estimation error of a representation is boundedby a sum of the standard generalization-error of that representation and thedistance between the treated and control distributions induced by therepresentation. We use Integral Probability Metrics to measure distancesbetween distributions, deriving explicit bounds for the Wasserstein and MaximumMean Discrepancy (MMD) distances. Experiments on real and simulated data showthe new algorithms match or outperform the state-of-the-art."^^schema:Text ;
    schema:author "David Sontag"^^schema:Person,
        "Fredrik D. Johansson"^^schema:Person,
        "Uri Shalit"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:dateModified "2017-05-16T15:11:15Z"^^schema:DateTime ;
    schema:datePublished "2016-06-13T14:40:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Estimating individual treatment effect: generalization bounds and  algorithms"^^schema:Text ;
    schema:publisher "ICML, 3076-3085"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.03976v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6525552873144020693&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<462> a schema:ScholarlyArticle ;
    schema:abstract "Dynamics of human body skeletons convey significant information for humanaction recognition. Conventional approaches for modeling skeletons usually relyon hand-crafted parts or traversal rules, thus resulting in limited expressivepower and difficulties of generalization. In this work, we propose a novelmodel of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks(ST-GCN), which moves beyond the limitations of previous methods byautomatically learning both the spatial and temporal patterns from data. Thisformulation not only leads to greater expressive power but also strongergeneralization capability. On two large datasets, Kinetics and NTU-RGBD, itachieves substantial improvements over mainstream methods."^^schema:Text ;
    schema:author "Dahua Lin"^^schema:Person,
        "Sijie Yan"^^schema:Person,
        "Yuanjun Xiong"^^schema:Person ;
    schema:commentCount "464"^^schema:Integer ;
    schema:dateModified "2018-01-25T07:17:02Z"^^schema:DateTime ;
    schema:datePublished "2018-01-23T09:48:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action  Recognition"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.07455v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6585893634007378631&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<463> a schema:ScholarlyArticle ;
    schema:abstract "Many real-world problems, such as network packet routing and urban trafficcontrol, are naturally modeled as multi-agent reinforcement learning (RL)problems. However, existing multi-agent RL methods typically scale poorly inthe problem size. Therefore, a key challenge is to translate the success ofdeep learning on single-agent RL to the multi-agent setting. A major stumblingblock is that independent Q-learning, the most popular multi-agent RL method,introduces nonstationarity that makes it incompatible with the experiencereplay memory on which deep Q-learning relies. This paper proposes two methodsthat address this problem: 1) using a multi-agent variant of importancesampling to naturally decay obsolete data and 2) conditioning each agent'svalue function on a fingerprint that disambiguates the age of the data sampledfrom the replay memory. Results on a challenging decentralised variant ofStarCraft unit micromanagement confirm that these methods enable the successfulcombination of experience replay with multi-agent RL."^^schema:Text ;
    schema:author "Gregory Farquhar"^^schema:Person,
        "Jakob Foerster"^^schema:Person,
        "Nantas Nardelli"^^schema:Person,
        "Philip H. S. Torr"^^schema:Person,
        "Pushmeet Kohli"^^schema:Person,
        "Shimon Whiteson"^^schema:Person,
        "Triantafyllos Afouras"^^schema:Person ;
    schema:commentCount "237"^^schema:Integer ;
    schema:dateModified "2018-05-21T08:24:02Z"^^schema:DateTime ;
    schema:datePublished "2017-02-28T17:56:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Stabilising Experience Replay for Deep Multi-Agent Reinforcement  Learning"^^schema:Text ;
    schema:publisher "ICML, 1146-1155"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.08887v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16652030977272114047&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<464> a schema:ScholarlyArticle ;
    schema:abstract "In many real-world settings, a team of agents must coordinate their behaviourwhile acting in a decentralised way. At the same time, it is often possible totrain the agents in a centralised fashion in a simulated or laboratory setting,where global state information is available and communication constraints arelifted. Learning joint action-values conditioned on extra state information isan attractive way to exploit centralised learning, but the best strategy forthen extracting decentralised policies is unclear. Our solution is QMIX, anovel value-based method that can train decentralised policies in a centralisedend-to-end fashion. QMIX employs a network that estimates joint action-valuesas a complex non-linear combination of per-agent values that condition only onlocal observations. We structurally enforce that the joint-action value ismonotonic in the per-agent values, which allows tractable maximisation of thejoint action-value in off-policy learning, and guarantees consistency betweenthe centralised and decentralised policies. We evaluate QMIX on a challengingset of StarCraft II micromanagement tasks, and show that QMIX significantlyoutperforms existing value-based multi-agent reinforcement learning methods."^^schema:Text ;
    schema:author "Christian Schroeder de Witt"^^schema:Person,
        "Gregory Farquhar"^^schema:Person,
        "Jakob Foerster"^^schema:Person,
        "Mikayel Samvelyan"^^schema:Person,
        "Shimon Whiteson"^^schema:Person,
        "Tabish Rashid"^^schema:Person ;
    schema:commentCount "179"^^schema:Integer ;
    schema:dateModified "2018-06-06T17:58:09Z"^^schema:DateTime ;
    schema:datePublished "2018-03-30T14:23:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent  Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 4292-4301"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.11485v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11167932629570793337&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<465> a schema:ScholarlyArticle ;
    schema:abstract "Nowadays, the number of layers and of neurons in each layer of a deep networkare typically set manually. While very deep and wide networks have proveneffective in general, they come at a high memory and computation cost, thusmaking them impractical for constrained platforms. These networks, however, areknown to have many redundant parameters, and could thus, in principle, bereplaced by more compact architectures. In this paper, we introduce an approachto automatically determining the number of neurons in each layer of a deepnetwork during learning. To this end, we propose to make use of structuredsparsity during learning. More precisely, we use a group sparsity regularizeron the parameters of the network, where each group is defined to act on asingle neuron. Starting from an overcomplete network, we show that our approachcan reduce the number of parameters by up to 80\\% while retaining or evenimproving the network accuracy."^^schema:Text ;
    schema:author "Jose M Alvarez"^^schema:Person,
        "Mathieu Salzmann"^^schema:Person ;
    schema:commentCount "209"^^schema:Integer ;
    schema:dateModified "2018-10-11T07:18:09Z"^^schema:DateTime ;
    schema:datePublished "2016-11-19T07:18:17Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning the Number of Neurons in Deep Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.06321v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7560041967181663482&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<466> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have proven remarkably effective at solving manyclassification problems, but have been criticized recently for two majorweaknesses: the reasons behind their predictions are uninterpretable, and thepredictions themselves can often be fooled by small adversarial perturbations.These problems pose major obstacles for the adoption of neural networks indomains that require security or transparency. In this work, we evaluate theeffectiveness of defenses that differentiably penalize the degree to whichsmall changes in inputs can alter model predictions. Across multiple attacks,architectures, defenses, and datasets, we find that neural networks trainedwith this input gradient regularization exhibit robustness to transferredadversarial examples generated to fool all of the other models. We also findthat adversarial examples generated to fool gradient-regularized models foolall other models equally well, and actually lead to more \"legitimate,\"interpretable misclassifications as rated by people (which we confirm in ahuman subject experiment). Finally, we demonstrate that regularizing inputgradients makes them more naturally interpretable as rationales for modelpredictions. We conclude by discussing this relationship betweeninterpretability and robustness in deep neural networks."^^schema:Text ;
    schema:author "Andrew Slavin Ross"^^schema:Person,
        "Finale Doshi-Velez"^^schema:Person ;
    schema:commentCount "161"^^schema:Integer ;
    schema:dateModified "2017-11-26T15:20:46Z"^^schema:DateTime ;
    schema:datePublished "2017-11-26T15:20:46Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Improving the Adversarial Robustness and Interpretability of Deep Neural  Networks by Regularizing their Input Gradients"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.09404v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10549843532884126759&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<467> a schema:ScholarlyArticle ;
    schema:abstract "In a traditional convolutional layer, the learned filters stay fixed aftertraining. In contrast, we introduce a new framework, the Dynamic FilterNetwork, where filters are generated dynamically conditioned on an input. Weshow that this architecture is a powerful one, with increased flexibilitythanks to its adaptive nature, yet without an excessive increase in the numberof model parameters. A wide variety of filtering operations can be learned thisway, including local spatial transformations, but also others like selective(de)blurring or adaptive feature extraction. Moreover, multiple such layers canbe combined, e.g. in a recurrent architecture. We demonstrate the effectivenessof the dynamic filter network on the tasks of video and stereo prediction, andreach state-of-the-art performance on the moving MNIST dataset with a muchsmaller model. By visualizing the learned filters, we illustrate that thenetwork has picked up flow information by only looking at unlabelled trainingdata. This suggests that the network can be used to pretrain networks forvarious supervised tasks in an unsupervised way, like optical flow and depthestimation."^^schema:Text ;
    schema:author "Bert De Brabandere"^^schema:Person,
        "Luc Van Gool"^^schema:Person,
        "Tinne Tuytelaars"^^schema:Person,
        "Xu Jia"^^schema:Person ;
    schema:commentCount "350"^^schema:Integer ;
    schema:dateModified "2016-06-06T15:39:10Z"^^schema:DateTime ;
    schema:datePublished "2016-05-31T15:29:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Dynamic Filter Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.09673v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6402271951989310264&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<468> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Nets (GANs) have shown promise in image generation andsemi-supervised learning (SSL). However, existing GANs in SSL have twoproblems: (1) the generator and the discriminator (i.e. the classifier) may notbe optimal at the same time; and (2) the generator cannot control the semanticsof the generated samples. The problems essentially arise from the two-playerformulation, where a single discriminator shares incompatible roles ofidentifying fake samples and predicting labels and it only estimates the datawithout considering the labels. To address the problems, we present triplegenerative adversarial net (Triple-GAN), which consists of three players---agenerator, a discriminator and a classifier. The generator and the classifiercharacterize the conditional distributions between images and labels, and thediscriminator solely focuses on identifying fake image-label pairs. We designcompatible utilities to ensure that the distributions characterized by theclassifier and the generator both converge to the data distribution. Ourresults on various datasets demonstrate that Triple-GAN as a unified model cansimultaneously (1) achieve the state-of-the-art classification results amongdeep generative models, and (2) disentangle the classes and styles of the inputand transfer smoothly in the data space via interpolation in the latent spaceclass-conditionally."^^schema:Text ;
    schema:author "Bo Zhang"^^schema:Person,
        "Chongxuan Li"^^schema:Person,
        "Jun Zhu"^^schema:Person,
        "Kun Xu"^^schema:Person ;
    schema:commentCount "199"^^schema:Integer ;
    schema:dateModified "2017-11-05T17:25:11Z"^^schema:DateTime ;
    schema:datePublished "2017-03-07T09:26:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Triple Generative Adversarial Nets"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.02291v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1723215698193163728&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<469> a schema:ScholarlyArticle ;
    schema:abstract "There has been a lot of recent interest in designing neural network models toestimate a distribution from a set of examples. We introduce a simplemodification for autoencoder neural networks that yields powerful generativemodels. Our method masks the autoencoder's parameters to respect autoregressiveconstraints: each input is reconstructed only from previous inputs in a givenordering. Constrained this way, the autoencoder outputs can be interpreted as aset of conditional probabilities, and their product, the full jointprobability. We can also train a single network that can decompose the jointprobability in multiple different orderings. Our simple framework can beapplied to multiple architectures, including deep ones. Vectorizedimplementations, such as on GPUs, are simple and fast. Experiments demonstratethat this approach is competitive with state-of-the-art tractable distributionestimators. At test time, the method is significantly faster and scales betterthan other autoregressive estimators."^^schema:Text ;
    schema:author "Hugo Larochelle"^^schema:Person,
        "Iain Murray"^^schema:Person,
        "Karol Gregor"^^schema:Person,
        "Mathieu Germain"^^schema:Person ;
    schema:commentCount "273"^^schema:Integer ;
    schema:dateModified "2015-06-05T14:37:32Z"^^schema:DateTime ;
    schema:datePublished "2015-02-12T02:06:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "MADE: Masked Autoencoder for Distribution Estimation"^^schema:Text ;
    schema:publisher "ICML, 881-889"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.03509v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3269243854142729843&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<47> a schema:ScholarlyArticle ;
    schema:abstract "We propose an online visual tracking algorithm by learning discriminativesaliency map using Convolutional Neural Network (CNN). Given a CNN pre-trainedon a large-scale image repository in offline, our algorithm takes outputs fromhidden layers of the network as feature descriptors since they show excellentrepresentation performance in various general visual recognition problems. Thefeatures are used to learn discriminative target appearance models using anonline Support Vector Machine (SVM). In addition, we construct target-specificsaliency map by backpropagating CNN features with guidance of the SVM, andobtain the final tracking result in each frame based on the appearance modelgeneratively constructed with the saliency map. Since the saliency mapvisualizes spatial configuration of target effectively, it improves targetlocalization accuracy and enable us to achieve pixel-level target segmentation.We verify the effectiveness of our tracking algorithm through extensiveexperiment on a challenging benchmark, where our method illustrates outstandingperformance compared to the state-of-the-art tracking algorithms."^^schema:Text ;
    schema:author "Bohyung Han"^^schema:Person,
        "Seunghoon Hong"^^schema:Person,
        "Suha Kwak"^^schema:Person,
        "Tackgeun You"^^schema:Person ;
    schema:commentCount "586"^^schema:Integer ;
    schema:dateModified "2015-02-24T13:10:32Z"^^schema:DateTime ;
    schema:datePublished "2015-02-24T13:10:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Online Tracking by Learning Discriminative Saliency Map with  Convolutional Neural Network"^^schema:Text ;
    schema:publisher "ICML, 597-606"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.06796v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8452657516733607725&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<470> a schema:ScholarlyArticle ;
    schema:abstract "We propose a reparameterization of LSTM that brings the benefits of batchnormalization to recurrent neural networks. Whereas previous works only applybatch normalization to the input-to-hidden transformation of RNNs, wedemonstrate that it is both possible and beneficial to batch-normalize thehidden-to-hidden transition, thereby reducing internal covariate shift betweentime steps. We evaluate our proposal on various sequential problems such assequence classification, language modeling and question answering. Ourempirical results show that our batch-normalized LSTM consistently leads tofaster convergence and improved generalization."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "César Laurent"^^schema:Person,
        "Nicolas Ballas"^^schema:Person,
        "Tim Cooijmans"^^schema:Person,
        "Çağlar Gülçehre"^^schema:Person ;
    schema:commentCount "312"^^schema:Integer ;
    schema:dateModified "2017-02-28T00:59:42Z"^^schema:DateTime ;
    schema:datePublished "2016-03-30T02:57:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Recurrent Batch Normalization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.09025v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16437445141311981298&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<471> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning can impact people with legal or ethical consequences when itis used to automate decisions in areas such as insurance, lending, hiring, andpredictive policing. In many of these scenarios, previous decisions have beenmade that are unfairly biased against certain subpopulations, for example thoseof a particular race, gender, or sexual orientation. Since this past data maybe biased, machine learning predictors must account for this to avoidperpetuating or creating discriminatory practices. In this paper, we develop aframework for modeling fairness using tools from causal inference. Ourdefinition of counterfactual fairness captures the intuition that a decision isfair towards an individual if it is the same in (a) the actual world and (b) acounterfactual world where the individual belonged to a different demographicgroup. We demonstrate our framework on a real-world problem of fair predictionof success in law school."^^schema:Text ;
    schema:author "Chris Russell"^^schema:Person,
        "Joshua R. Loftus"^^schema:Person,
        "Matt J. Kusner"^^schema:Person,
        "Ricardo Silva"^^schema:Person ;
    schema:commentCount "348"^^schema:Integer ;
    schema:dateModified "2018-03-08T11:23:13Z"^^schema:DateTime ;
    schema:datePublished "2017-03-20T17:18:57Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Counterfactual Fairness"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.06856v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13115459093902017069&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<472> a schema:ScholarlyArticle ;
    schema:abstract "A large fraction of Internet traffic is now driven by requests from mobiledevices with relatively small screens and often stringent bandwidthrequirements. Due to these factors, it has become the norm for moderngraphics-heavy websites to transmit low-resolution, low-bytecount imagepreviews (thumbnails) as part of the initial page load process to improveapparent page responsiveness. Increasing thumbnail compression beyond thecapabilities of existing codecs is therefore a current research focus, as anybyte savings will significantly enhance the experience of mobile device users.Toward this end, we propose a general framework for variable-rate imagecompression and a novel architecture based on convolutional and deconvolutionalLSTM recurrent networks. Our models address the main issues that have preventedautoencoder neural networks from competing with existing image compressionalgorithms: (1) our networks only need to be trained once (not per-image),regardless of input image dimensions and the desired compression rate; (2) ournetworks are progressive, meaning that the more bits are sent, the moreaccurate the image reconstruction; and (3) the proposed architecture is atleast as efficient as a standard purpose-trained autoencoder for a given numberof bits. On a large-scale benchmark of 32$\\times$32 thumbnails, our LSTM-basedapproaches provide better visual quality than (headerless) JPEG, JPEG2000 andWebP, with a storage size that is reduced by 10% or more."^^schema:Text ;
    schema:author "Damien Vincent"^^schema:Person,
        "David Minnen"^^schema:Person,
        "George Toderici"^^schema:Person,
        "Michele Covell"^^schema:Person,
        "Rahul Sukthankar"^^schema:Person,
        "Sean M. O'Malley"^^schema:Person,
        "Shumeet Baluja"^^schema:Person,
        "Sung Jin Hwang"^^schema:Person ;
    schema:commentCount "233"^^schema:Integer ;
    schema:dateModified "2016-03-01T22:13:44Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T07:50:46Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Variable Rate Image Compression with Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06085v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4340654873051667262&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<473> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of learning deep generative models from data. Weformulate a method that generates an independent sample via a singlefeedforward pass through a multilayer perceptron, as in the recently proposedgenerative adversarial networks (Goodfellow et al., 2014). Training agenerative adversarial network, however, requires careful optimization of adifficult minimax program. Instead, we utilize a technique from statisticalhypothesis testing known as maximum mean discrepancy (MMD), which leads to asimple objective that can be interpreted as matching all orders of statisticsbetween a dataset and samples from the model, and can be trained bybackpropagation. We further boost the performance of this approach by combiningour generative network with an auto-encoder network, using MMD to learn togenerate codes that can then be decoded to produce samples. We show that thecombination of these techniques yields excellent generative models compared tobaseline approaches as measured on MNIST and the Toronto Face Database."^^schema:Text ;
    schema:author "Kevin Swersky"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Yujia Li"^^schema:Person ;
    schema:commentCount "460"^^schema:Integer ;
    schema:dateModified "2015-02-10T02:54:58Z"^^schema:DateTime ;
    schema:datePublished "2015-02-10T02:54:58Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Moment Matching Networks"^^schema:Text ;
    schema:publisher "ICML, 1718-1727"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02761v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18115566463777766587&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<474> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks currently demonstrate state-of-the-art performance inseveral domains. At the same time, models of this class are very demanding interms of computational resources. In particular, a large amount of memory isrequired by commonly used fully-connected layers, making it hard to use themodels on low-end devices and stopping the further increase of the model size.In this paper we convert the dense weight matrices of the fully-connectedlayers to the Tensor Train format such that the number of parameters is reducedby a huge factor and at the same time the expressive power of the layer ispreserved. In particular, for the Very Deep VGG networks we report thecompression factor of the dense weight matrix of a fully-connected layer up to200000 times leading to the compression factor of the whole network up to 7times."^^schema:Text ;
    schema:author "Alexander Novikov"^^schema:Person,
        "Anton Osokin"^^schema:Person,
        "Dmitry Podoprikhin"^^schema:Person,
        "Dmitry Vetrov"^^schema:Person ;
    schema:commentCount "387"^^schema:Integer ;
    schema:dateModified "2015-12-20T11:44:05Z"^^schema:DateTime ;
    schema:datePublished "2015-09-22T12:31:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Tensorizing Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.06569v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15959182859518738418&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<475> a schema:ScholarlyArticle ;
    schema:abstract "While depth tends to improve network performances, it also makesgradient-based training more difficult since deeper networks tend to be morenon-linear. The recently proposed knowledge distillation approach is aimed atobtaining small and fast-to-execute models, and it has shown that a studentnetwork could imitate the soft output of a larger teacher network or ensembleof networks. In this paper, we extend this idea to allow the training of astudent that is deeper and thinner than the teacher, using not only the outputsbut also the intermediate representations learned by the teacher as hints toimprove the training process and final performance of the student. Because thestudent intermediate hidden layer will generally be smaller than the teacher'sintermediate hidden layer, additional parameters are introduced to map thestudent hidden layer to the prediction of the teacher hidden layer. This allowsone to train deeper students that can generalize better or run faster, atrade-off that is controlled by the chosen student capacity. For example, onCIFAR-10, a deep student network with almost 10.4 times less parametersoutperforms a larger, state-of-the-art teacher network."^^schema:Text ;
    schema:author "Adriana Romero"^^schema:Person,
        "Antoine Chassang"^^schema:Person,
        "Carlo Gatta"^^schema:Person,
        "Nicolas Ballas"^^schema:Person,
        "Samira Ebrahimi Kahou"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "1065"^^schema:Integer ;
    schema:dateModified "2015-03-27T11:52:28Z"^^schema:DateTime ;
    schema:datePublished "2014-12-19T22:40:51Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "FitNets: Hints for Thin Deep Nets"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6550v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10225516876101179571&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<476> a schema:ScholarlyArticle ;
    schema:abstract "Interactions among people or objects are often dynamic in nature and can berepresented as a sequence of networks, each providing a snapshot of theinteractions over a brief period of time. An important task in analyzing suchevolving networks is change-point detection, in which we both identify thetimes at which the large-scale pattern of interactions changes fundamentallyand quantify how large and what kind of change occurred. Here, we formalize forthe first time the network change-point detection problem within an onlineprobabilistic learning framework and introduce a method that can reliably solveit. This method combines a generalized hierarchical random graph model with aBayesian hypothesis test to quantitatively determine if, when, and preciselyhow a change point has occurred. We analyze the detectability of our methodusing synthetic data with known change points of different types andmagnitudes, and show that this method is more accurate than several previouslyused alternatives. Applied to two high-resolution evolving social networks,this method identifies a sequence of change points that align with knownexternal \"shocks\" to these networks."^^schema:Text ;
    schema:author "Aaron Clauset"^^schema:Person,
        "Leto Peel"^^schema:Person ;
    schema:commentCount "161"^^schema:Integer ;
    schema:dateModified "2014-11-14T19:40:26Z"^^schema:DateTime ;
    schema:datePublished "2014-03-05T02:28:38Z"^^schema:DateTime ;
    schema:genre "cs.SI"^^schema:Text,
        "physics.soc-ph"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Detecting change points in the large-scale structure of evolving  networks"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1403.0989v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14760901904113071948&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<477> a schema:ScholarlyArticle ;
    schema:abstract "Consider learning a policy from example expert behavior, without interactionwith the expert or access to reinforcement signal. One approach is to recoverthe expert's cost function with inverse reinforcement learning, then extract apolicy from that cost function with reinforcement learning. This approach isindirect and can be slow. We propose a new general framework for directlyextracting a policy from data, as if it were obtained by reinforcement learningfollowing inverse reinforcement learning. We show that a certain instantiationof our framework draws an analogy between imitation learning and generativeadversarial networks, from which we derive a model-free imitation learningalgorithm that obtains significant performance gains over existing model-freemethods in imitating complex behaviors in large, high-dimensional environments."^^schema:Text ;
    schema:author "Jonathan Ho"^^schema:Person,
        "Stefano Ermon"^^schema:Person ;
    schema:commentCount "778"^^schema:Integer ;
    schema:dateModified "2016-06-10T20:51:29Z"^^schema:DateTime ;
    schema:datePublished "2016-06-10T20:51:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.03476v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9944023855119495996&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<478> a schema:ScholarlyArticle ;
    schema:abstract "Rapid advances of hardware-based technologies during the past decades haveopened up new possibilities for Life scientists to gather multimodal data invarious application domains (e.g., Omics, Bioimaging, Medical Imaging, and[Brain/Body]-Machine Interfaces), thus generating novel opportunities fordevelopment of dedicated data intensive machine learning techniques. Overall,recent research in Deep learning (DL), Reinforcement learning (RL), and theircombination (Deep RL) promise to revolutionize Artificial Intelligence. Thegrowth in computational power accompanied by faster and increased data storageand declining computing costs have already allowed scientists in various fieldsto apply these techniques on datasets that were previously intractable fortheir size and complexity. This review article provides a comprehensive surveyon the application of DL, RL, and Deep RL techniques in mining Biological data.In addition, we compare performances of DL techniques when applied to differentdatasets across various application domains. Finally, we outline open issues inthis challenging research area and discuss future development perspectives."^^schema:Text ;
    schema:author "Amir Hussain"^^schema:Person,
        "M. Shamim Kaiser"^^schema:Person,
        "Mufti Mahmud"^^schema:Person,
        "Stefano Vassanelli"^^schema:Person ;
    schema:commentCount "178"^^schema:Integer ;
    schema:dateModified "2018-01-07T07:06:20Z"^^schema:DateTime ;
    schema:datePublished "2017-11-10T19:06:46Z"^^schema:DateTime ;
    schema:genre "A.1, I.2, I.5, J.3"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Applications of Deep Learning and Reinforcement Learning to Biological  Data"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (6), 2063-2079"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.03985v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10338561298388727665&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<479> a schema:ScholarlyArticle ;
    schema:abstract "Many classes of images exhibit rotational symmetry. Convolutional neuralnetworks are sometimes trained using data augmentation to exploit this, butthey are still required to learn the rotation equivariance properties from thedata. Encoding these properties into the network architecture, as we arealready used to doing for translation equivariance by using convolutionallayers, could result in a more efficient use of the parameter budget byrelieving the model from learning them. We introduce four operations which canbe inserted into neural network models as layers, and which can be combined tomake these models partially equivariant to rotations. They also enableparameter sharing across different orientations. We evaluate the effect ofthese architectural modifications on three datasets which exhibit rotationalsymmetry and demonstrate improved performance with smaller models."^^schema:Text ;
    schema:author "Jeffrey De Fauw"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Sander Dieleman"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:dateModified "2016-05-26T11:47:18Z"^^schema:DateTime ;
    schema:datePublished "2016-02-08T17:37:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Exploiting Cyclic Symmetry in Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1889-1898"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.02660v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7548774008979787811&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<48> a schema:ScholarlyArticle ;
    schema:abstract "Bilinear models provide rich representations compared with linear models.They have been applied in various visual tasks, such as object recognition,segmentation, and visual question-answering, to get state-of-the-artperformances taking advantage of the expanded representations. However,bilinear representations tend to be high-dimensional, limiting theapplicability to computationally complex tasks. We propose low-rank bilinearpooling using Hadamard product for an efficient attention mechanism ofmultimodal learning. We show that our model outperforms compact bilinearpooling in visual question-answering tasks with the state-of-the-art results onthe VQA dataset, having a better parsimonious property."^^schema:Text ;
    schema:author "Byoung-Tak Zhang"^^schema:Person,
        "Jeonghee Kim"^^schema:Person,
        "Jin-Hwa Kim"^^schema:Person,
        "Jung-Woo Ha"^^schema:Person,
        "Kyoung-Woon On"^^schema:Person,
        "Woosang Lim"^^schema:Person ;
    schema:commentCount "280"^^schema:Integer ;
    schema:dateModified "2017-03-26T16:22:47Z"^^schema:DateTime ;
    schema:datePublished "2016-10-14T04:29:52Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Hadamard Product for Low-rank Bilinear Pooling"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.04325v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11247536386590839195&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<480> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a convolutional neural network that operates directly on graphs.These networks allow end-to-end learning of prediction pipelines whose inputsare graphs of arbitrary size and shape. The architecture we present generalizesstandard molecular feature extraction methods based on circular fingerprints.We show that these data-driven features are more interpretable, and have betterpredictive performance on a variety of tasks."^^schema:Text ;
    schema:author "Alán Aspuru-Guzik"^^schema:Person,
        "David Duvenaud"^^schema:Person,
        "Dougal Maclaurin"^^schema:Person,
        "Jorge Aguilera-Iparraguirre"^^schema:Person,
        "Rafael Gómez-Bombarelli"^^schema:Person,
        "Ryan P. Adams"^^schema:Person,
        "Timothy Hirzel"^^schema:Person ;
    schema:commentCount "1303"^^schema:Integer ;
    schema:dateModified "2015-11-03T17:18:32Z"^^schema:DateTime ;
    schema:datePublished "2015-09-30T18:33:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Convolutional Networks on Graphs for Learning Molecular Fingerprints"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1509.09292v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13332347053275193739&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<481> a schema:ScholarlyArticle ;
    schema:abstract "At initialization, artificial neural networks (ANNs) are equivalent toGaussian processes in the infinite-width limit, thus connecting them to kernelmethods. We prove that the evolution of an ANN during training can also bedescribed by a kernel: during gradient descent on the parameters of an ANN, thenetwork function $f_\\theta$ (which maps input vectors to output vectors)follows the kernel gradient of the functional cost (which is convex, incontrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel(NTK). This kernel is central to describe the generalization features of ANNs.While the NTK is random at initialization and varies during training, in theinfinite-width limit it converges to an explicit limiting kernel and it staysconstant during training. This makes it possible to study the training of ANNsin function space instead of parameter space. Convergence of the training canthen be related to the positive-definiteness of the limiting NTK. We prove thepositive-definiteness of the limiting NTK when the data is supported on thesphere and the non-linearity is non-polynomial. We then focus on the setting ofleast-squares regression and show that in the infinite-width limit, the networkfunction $f_\\theta$ follows a linear differential equation during training. Theconvergence is fastest along the largest kernel principal components of theinput data with respect to the NTK, hence suggesting a theoretical motivationfor early stopping. Finally we study the NTK numerically, observe its behaviorfor wide networks, and compare it to the infinite-width limit."^^schema:Text ;
    schema:author "Arthur Jacot"^^schema:Person,
        "Clément Hongler"^^schema:Person,
        "Franck Gabriel"^^schema:Person ;
    schema:commentCount "332"^^schema:Integer ;
    schema:dateModified "2020-02-10T08:39:09Z"^^schema:DateTime ;
    schema:datePublished "2018-06-20T06:35:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.PR"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1806.07572v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15521977800069603597&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<482> a schema:ScholarlyArticle ;
    schema:abstract "We consider the two related problems of detecting if an example ismisclassified or out-of-distribution. We present a simple baseline thatutilizes probabilities from softmax distributions. Correctly classifiedexamples tend to have greater maximum softmax probabilities than erroneouslyclassified and out-of-distribution examples, allowing for their detection. Weassess performance by defining several tasks in computer vision, naturallanguage processing, and automatic speech recognition, showing theeffectiveness of this baseline across all. We then show the baseline cansometimes be surpassed, demonstrating the room for future research on theseunderexplored detection tasks."^^schema:Text ;
    schema:author "Dan Hendrycks"^^schema:Person,
        "Kevin Gimpel"^^schema:Person ;
    schema:commentCount "362"^^schema:Integer ;
    schema:dateModified "2018-10-03T07:32:57Z"^^schema:DateTime ;
    schema:datePublished "2016-10-07T04:06:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A Baseline for Detecting Misclassified and Out-of-Distribution Examples  in Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.02136v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14505244835813531476&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<483> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks (RNNs), such as long short-term memory networks(LSTMs), serve as a fundamental building block for many sequence learningtasks, including machine translation, language modeling, and questionanswering. In this paper, we consider the specific problem of word-levellanguage modeling and investigate strategies for regularizing and optimizingLSTM-based models. We propose the weight-dropped LSTM which uses DropConnect onhidden-to-hidden weights as a form of recurrent regularization. Further, weintroduce NT-ASGD, a variant of the averaged stochastic gradient method,wherein the averaging trigger is determined using a non-monotonic condition asopposed to being tuned by the user. Using these and other regularizationstrategies, we achieve state-of-the-art word level perplexities on two datasets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring theeffectiveness of a neural cache in conjunction with our proposed model, weachieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and52.0 on WikiText-2."^^schema:Text ;
    schema:author "Nitish Shirish Keskar"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Stephen Merity"^^schema:Person ;
    schema:commentCount "508"^^schema:Integer ;
    schema:dateModified "2017-08-07T16:03:44Z"^^schema:DateTime ;
    schema:datePublished "2017-08-07T16:03:44Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Regularizing and Optimizing LSTM Language Models"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.02182v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10613038919449342432&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<484> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of learning general-purpose, paraphrastic sentenceembeddings based on supervision from the Paraphrase Database (Ganitkevitch etal., 2013). We compare six compositional architectures, evaluating them onannotated textual similarity datasets drawn both from the same distribution asthe training data and from a wide range of other domains. We find that the mostcomplex architectures, such as long short-term memory (LSTM) recurrent neuralnetworks, perform best on the in-domain data. However, in out-of-domainscenarios, simple architectures such as word averaging vastly outperform LSTMs.Our simplest averaging model is even competitive with systems tuned for theparticular tasks while also being extremely efficient and easy to use.  In order to better understand how these architectures compare, we conductfurther experiments on three supervised NLP tasks: sentence similarity,entailment, and sentiment classification. We again find that the word averagingmodels perform well for sentence similarity and entailment, outperformingLSTMs. However, on sentiment classification, we find that the LSTM performsvery strongly-even recording new state-of-the-art performance on the StanfordSentiment Treebank.  We then demonstrate how to combine our pretrained sentence embeddings withthese supervised tasks, using them both as a prior and as a black box featureextractor. This leads to performance rivaling the state of the art on the SICKsimilarity and entailment tasks. We release all of our resources to theresearch community with the hope that they can serve as the new baseline forfurther work on universal sentence embeddings."^^schema:Text ;
    schema:author "John Wieting"^^schema:Person,
        "Karen Livescu"^^schema:Person,
        "Kevin Gimpel"^^schema:Person,
        "Mohit Bansal"^^schema:Person ;
    schema:commentCount "397"^^schema:Integer ;
    schema:dateModified "2016-03-04T20:54:30Z"^^schema:DateTime ;
    schema:datePublished "2015-11-25T20:52:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Towards Universal Paraphrastic Sentence Embeddings"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.08198v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8275054724533958638&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<485> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of 3D object generation. We propose a novel framework,namely 3D Generative Adversarial Network (3D-GAN), which generates 3D objectsfrom a probabilistic space by leveraging recent advances in volumetricconvolutional networks and generative adversarial nets. The benefits of ourmodel are three-fold: first, the use of an adversarial criterion, instead oftraditional heuristic criteria, enables the generator to capture objectstructure implicitly and to synthesize high-quality 3D objects; second, thegenerator establishes a mapping from a low-dimensional probabilistic space tothe space of 3D objects, so that we can sample objects without a referenceimage or CAD models, and explore the 3D object manifold; third, the adversarialdiscriminator provides a powerful 3D shape descriptor which, learned withoutsupervision, has wide applications in 3D object recognition. Experimentsdemonstrate that our method generates high-quality 3D objects, and ourunsupervisedly learned features achieve impressive performance on 3D objectrecognition, comparable with those of supervised learning methods."^^schema:Text ;
    schema:author "Chengkai Zhang"^^schema:Person,
        "Jiajun Wu"^^schema:Person,
        "Joshua B. Tenenbaum"^^schema:Person,
        "Tianfan Xue"^^schema:Person,
        "William T. Freeman"^^schema:Person ;
    schema:commentCount "849"^^schema:Integer ;
    schema:dateModified "2017-01-04T18:35:52Z"^^schema:DateTime ;
    schema:datePublished "2016-10-24T19:53:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning a Probabilistic Latent Space of Object Shapes via 3D  Generative-Adversarial Modeling"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.07584v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1838944634579790374&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<486> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning has become a ubiquitous technology to improve machineintelligence. However, most of the existing deep models are structurally verycomplex, making them difficult to be deployed on the mobile platforms withlimited computational power. In this paper, we propose a novel networkcompression method called dynamic network surgery, which can remarkably reducethe network complexity by making on-the-fly connection pruning. Unlike theprevious methods which accomplish this task in a greedy way, we properlyincorporate connection splicing into the whole process to avoid incorrectpruning and make it as a continual network maintenance. The effectiveness ofour method is proved with experiments. Without any accuracy loss, our methodcan efficiently compress the number of parameters in LeNet-5 and AlexNet by afactor of $\\bm{108}\\times$ and $\\bm{17.7}\\times$ respectively, proving that itoutperforms the recent pruning method by considerable margins. Code and somemodels are available at https://github.com/yiwenguo/Dynamic-Network-Surgery."^^schema:Text ;
    schema:author "Anbang Yao"^^schema:Person,
        "Yiwen Guo"^^schema:Person,
        "Yurong Chen"^^schema:Person ;
    schema:commentCount "438"^^schema:Integer ;
    schema:dateModified "2016-11-10T00:17:25Z"^^schema:DateTime ;
    schema:datePublished "2016-08-16T06:23:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Dynamic Network Surgery for Efficient DNNs"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.04493v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8401919167089401684&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<487> a schema:ScholarlyArticle ;
    schema:abstract "Model-free deep reinforcement learning (RL) algorithms have been demonstratedon a range of challenging decision making and control tasks. However, thesemethods typically suffer from two major challenges: very high sample complexityand brittle convergence properties, which necessitate meticulous hyperparametertuning. Both of these challenges severely limit the applicability of suchmethods to complex, real-world domains. In this paper, we propose softactor-critic, an off-policy actor-critic deep RL algorithm based on the maximumentropy reinforcement learning framework. In this framework, the actor aims tomaximize expected reward while also maximizing entropy. That is, to succeed atthe task while acting as randomly as possible. Prior deep RL methods based onthis framework have been formulated as Q-learning methods. By combiningoff-policy updates with a stable stochastic actor-critic formulation, ourmethod achieves state-of-the-art performance on a range of continuous controlbenchmark tasks, outperforming prior on-policy and off-policy methods.Furthermore, we demonstrate that, in contrast to other off-policy algorithms,our approach is very stable, achieving very similar performance acrossdifferent random seeds."^^schema:Text ;
    schema:author "Aurick Zhou"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Tuomas Haarnoja"^^schema:Person ;
    schema:commentCount "698"^^schema:Integer ;
    schema:dateModified "2018-08-08T21:27:08Z"^^schema:DateTime ;
    schema:datePublished "2018-01-04T09:50:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement  Learning with a Stochastic Actor"^^schema:Text ;
    schema:publisher "ICML, 1856-1865"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.01290v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13282174879342015249&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<488> a schema:ScholarlyArticle ;
    schema:abstract "We apply recurrent neural networks (RNN) on a new domain, namely recommendersystems. Real-life recommender systems often face the problem of having to baserecommendations only on short session-based data (e.g. a small sportswarewebsite) instead of long user histories (as in the case of Netflix). In thissituation the frequently praised matrix factorization approaches are notaccurate. This problem is usually overcome in practice by resorting toitem-to-item recommendations, i.e. recommending similar items. We argue that bymodeling the whole session, more accurate recommendations can be provided. Wetherefore propose an RNN-based approach for session-based recommendations. Ourapproach also considers practical aspects of the task and introduces severalmodifications to classic RNNs such as a ranking loss function that make it moreviable for this specific problem. Experimental results on two data-sets showmarked improvements over widely used approaches."^^schema:Text ;
    schema:author "Alexandros Karatzoglou"^^schema:Person,
        "Balázs Hidasi"^^schema:Person,
        "Domonkos Tikk"^^schema:Person,
        "Linas Baltrunas"^^schema:Person ;
    schema:commentCount "635"^^schema:Integer ;
    schema:dateModified "2016-03-29T14:52:58Z"^^schema:DateTime ;
    schema:datePublished "2015-11-21T23:42:59Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Session-based Recommendations with Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06939v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10894551747136395106&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<489> a schema:ScholarlyArticle ;
    schema:abstract "Conventional methods of 3D object generative modeling learn volumetricpredictions using deep networks with 3D convolutional operations, which aredirect analogies to classical 2D ones. However, these methods arecomputationally wasteful in attempt to predict 3D shapes, where information isrich only on the surfaces. In this paper, we propose a novel 3D generativemodeling framework to efficiently generate object shapes in the form of densepoint clouds. We use 2D convolutional operations to predict the 3D structurefrom multiple viewpoints and jointly apply geometric reasoning with 2Dprojection optimization. We introduce the pseudo-renderer, a differentiablemodule to approximate the true rendering operation, to synthesize novel depthmaps for optimization. Experimental results for single-image 3D objectreconstruction tasks show that we outperforms state-of-the-art methods in termsof shape similarity and prediction density."^^schema:Text ;
    schema:author "Chen Kong"^^schema:Person,
        "Chen-Hsuan Lin"^^schema:Person,
        "Simon Lucey"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:dateModified "2017-06-21T17:56:59Z"^^schema:DateTime ;
    schema:datePublished "2017-06-21T17:56:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning Efficient Point Cloud Generation for Dense 3D Object  Reconstruction"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.07036v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5371374397764333012&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<49> a schema:ScholarlyArticle ;
    schema:abstract "Recent results suggest that state-of-the-art saliency models perform far fromoptimal in predicting fixations. This lack in performance has been attributedto an inability to model the influence of high-level image features such asobjects. Recent seminal advances in applying deep neural networks to tasks likeobject recognition suggests that they are able to capture this kind ofstructure. However, the enormous amount of training data necessary to trainthese networks makes them difficult to apply directly to saliency prediction.We present a novel way of reusing existing neural networks that have beenpretrained on the task of object recognition in models of fixation prediction.Using the well-known network of Krizhevsky et al. (2012), we come up with a newsaliency model that significantly outperforms all state-of-the-art models onthe MIT Saliency Benchmark. We show that the structure of this network allowsnew insights in the psychophysics of fixation selection and potentially theirneural implementation. To train our network, we build on recent work on themodeling of saliency as point processes."^^schema:Text ;
    schema:author "Lucas Theis"^^schema:Person,
        "Matthias Bethge"^^schema:Person,
        "Matthias Kümmerer"^^schema:Person ;
    schema:commentCount "273"^^schema:Integer ;
    schema:dateModified "2015-04-09T09:48:11Z"^^schema:DateTime ;
    schema:datePublished "2014-11-04T20:56:51Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "q-bio.NC"^^schema:Text,
        "stat.AP"^^schema:Text ;
    schema:headline "Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on  ImageNet"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1411.1045v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4166856723638300289&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<490> a schema:ScholarlyArticle ;
    schema:abstract "Recommender systems use algorithms to provide users with product or servicerecommendations. Recently, these systems have been using machine learningalgorithms from the field of artificial intelligence. However, choosing asuitable machine learning algorithm for a recommender system is difficultbecause of the number of algorithms described in the literature. Researchersand practitioners developing recommender systems are left with littleinformation about the current approaches in algorithm usage. Moreover, thedevelopment of a recommender system using a machine learning algorithm oftenhas problems and open questions that must be evaluated, so software engineersknow where to focus research efforts. This paper presents a systematic reviewof the literature that analyzes the use of machine learning algorithms inrecommender systems and identifies research opportunities for softwareengineering research. The study concludes that Bayesian and decision treealgorithms are widely used in recommender systems because of their relativesimplicity, and that requirement and design phases of recommender systemdevelopment appear to offer opportunities for further research."^^schema:Text ;
    schema:author "Donald Cowan"^^schema:Person,
        "Ivens Portugal"^^schema:Person,
        "Paulo Alencar"^^schema:Person ;
    schema:commentCount "204"^^schema:Integer ;
    schema:dateModified "2016-02-24T18:58:32Z"^^schema:DateTime ;
    schema:datePublished "2015-11-17T03:14:46Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SE"^^schema:Text ;
    schema:headline "The Use of Machine Learning Algorithms in Recommender Systems: A  Systematic Review"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 97, 205-227"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05263v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11285524639657957777&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<491> a schema:ScholarlyArticle ;
    schema:abstract "This paper introduces a new encoder-decoder architecture that is trained toreconstruct images by disentangling the salient information of the image andthe values of attributes directly in the latent space. As a result, aftertraining, our model can generate different realistic versions of an input imageby varying the attribute values. By using continuous attribute values, we canchoose how much a specific attribute is perceivable in the generated image.This property could allow for applications where users can modify an imageusing sliding knobs, like faders on a mixing console, to change the facialexpression of a portrait, or to update the color of some objects. Compared tothe state-of-the-art which mostly relies on training adversarial networks inpixel space by altering attribute values at train time, our approach results inmuch simpler training schemes and nicely scales to multiple attributes. Wepresent evidence that our model can significantly change the perceived value ofthe attributes while preserving the naturalness of images."^^schema:Text ;
    schema:author "Antoine Bordes"^^schema:Person,
        "Guillaume Lample"^^schema:Person,
        "Ludovic Denoyer"^^schema:Person,
        "Marc'Aurelio Ranzato"^^schema:Person,
        "Neil Zeghidour"^^schema:Person,
        "Nicolas Usunier"^^schema:Person ;
    schema:commentCount "238"^^schema:Integer ;
    schema:dateModified "2018-01-28T16:12:14Z"^^schema:DateTime ;
    schema:datePublished "2017-06-01T17:48:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Fader Networks: Manipulating Images by Sliding Attributes"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.00409v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7253031520963581223&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<492> a schema:ScholarlyArticle ;
    schema:abstract "We propose a criterion for discrimination against a specified sensitiveattribute in supervised learning, where the goal is to predict some targetbased on available features. Assuming data about the predictor, target, andmembership in the protected group are available, we show how to optimallyadjust any learned predictor so as to remove discrimination according to ourdefinition. Our framework also improves incentives by shifting the cost of poorclassification from disadvantaged groups to the decision maker, who can respondby improving the classification accuracy.  In line with other studies, our notion is oblivious: it depends only on thejoint statistics of the predictor, the target and the protected attribute, butnot on interpretation of individualfeatures. We study the inherent limits ofdefining and identifying biases based on such oblivious measures, outliningwhat can and cannot be inferred from different oblivious tests.  We illustrate our notion using a case study of FICO credit scores."^^schema:Text ;
    schema:author "Eric Price"^^schema:Person,
        "Moritz Hardt"^^schema:Person,
        "Nathan Srebro"^^schema:Person ;
    schema:commentCount "937"^^schema:Integer ;
    schema:dateModified "2016-10-07T20:16:29Z"^^schema:DateTime ;
    schema:datePublished "2016-10-07T20:16:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Equality of Opportunity in Supervised Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.02413v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2062984936384963570&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<493> a schema:ScholarlyArticle ;
    schema:abstract "We present an approach to training neural networks to generate sequencesusing actor-critic methods from reinforcement learning (RL). Currentlog-likelihood training methods are limited by the discrepancy between theirtraining and testing modes, as models must generate tokens conditioned on theirprevious guesses rather than the ground-truth tokens. We address this problemby introducing a \\textit{critic} network that is trained to predict the valueof an output token, given the policy of an \\textit{actor} network. This resultsin a training procedure that is much closer to the test phase, and allows us todirectly optimize for a task-specific score such as BLEU. Crucially, since weleverage these techniques in the supervised learning setting rather than thetraditional RL setting, we condition the critic network on the ground-truthoutput. We show that our method leads to improved performance on both asynthetic task, and for German-English machine translation. Our analysis pavesthe way for such methods to be applied in natural language generation tasks,such as machine translation, caption generation, and dialogue modelling."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Anirudh Goyal"^^schema:Person,
        "Dzmitry Bahdanau"^^schema:Person,
        "Joelle Pineau"^^schema:Person,
        "Kelvin Xu"^^schema:Person,
        "Philemon Brakel"^^schema:Person,
        "Ryan Lowe"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "348"^^schema:Integer ;
    schema:dateModified "2017-03-03T15:43:52Z"^^schema:DateTime ;
    schema:datePublished "2016-07-24T20:05:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "An Actor-Critic Algorithm for Sequence Prediction"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.07086v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5228204938243984917&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<494> a schema:ScholarlyArticle ;
    schema:abstract "Despite the recent achievements in machine learning, we are still very farfrom achieving real artificial intelligence. In this paper, we discuss thelimitations of standard deep learning approaches and show that some of theselimitations can be overcome by learning how to grow the complexity of a modelin a structured way. Specifically, we study the simplest sequence predictionproblems that are beyond the scope of what is learnable with standard recurrentnetworks, algorithmically generated sequences which can only be learned bymodels which have the capacity to count and to memorize sequences. We show thatsome basic algorithms can be learned from sequential data using a recurrentnetwork associated with a trainable memory."^^schema:Text ;
    schema:author "Armand Joulin"^^schema:Person,
        "Tomas Mikolov"^^schema:Person ;
    schema:commentCount "290"^^schema:Integer ;
    schema:dateModified "2015-06-01T20:37:55Z"^^schema:DateTime ;
    schema:datePublished "2015-03-03T16:50:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1503.01007v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3528545098584451867&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<495> a schema:ScholarlyArticle ;
    schema:abstract "Large deep neural networks are powerful, but exhibit undesirable behaviorssuch as memorization and sensitivity to adversarial examples. In this work, wepropose mixup, a simple learning principle to alleviate these issues. Inessence, mixup trains a neural network on convex combinations of pairs ofexamples and their labels. By doing so, mixup regularizes the neural network tofavor simple linear behavior in-between training examples. Our experiments onthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets showthat mixup improves the generalization of state-of-the-art neural networkarchitectures. We also find that mixup reduces the memorization of corruptlabels, increases the robustness to adversarial examples, and stabilizes thetraining of generative adversarial networks."^^schema:Text ;
    schema:author "David Lopez-Paz"^^schema:Person,
        "Hongyi Zhang"^^schema:Person,
        "Moustapha Cisse"^^schema:Person,
        "Yann N. Dauphin"^^schema:Person ;
    schema:commentCount "782"^^schema:Integer ;
    schema:dateModified "2018-04-27T21:39:25Z"^^schema:DateTime ;
    schema:datePublished "2017-10-25T18:30:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "mixup: Beyond Empirical Risk Minimization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.09412v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12669856454801555406&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<496> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new formulation for pruning convolutional kernels in neuralnetworks to enable efficient inference. We interleave greedy criteria-basedpruning with fine-tuning by backpropagation - a computationally efficientprocedure that maintains good generalization in the pruned network. We proposea new criterion based on Taylor expansion that approximates the change in thecost function induced by pruning network parameters. We focus on transferlearning, where large pretrained networks are adapted to specialized tasks. Theproposed criterion demonstrates superior performance compared to othercriteria, e.g. the norm of kernel weights or feature map activation, forpruning large CNNs after adaptation to fine-grained classification tasks(Birds-200 and Flowers-102) relaying only on the first order gradientinformation. We also show that pruning can lead to more than 10x theoretical(5x practical) reduction in adapted 3D-convolutional filters with a small dropin accuracy in a recurrent gesture classifier. Finally, we show results for thelarge-scale ImageNet dataset to emphasize the flexibility of our approach."^^schema:Text ;
    schema:author "Jan Kautz"^^schema:Person,
        "Pavlo Molchanov"^^schema:Person,
        "Stephen Tyree"^^schema:Person,
        "Tero Karras"^^schema:Person,
        "Timo Aila"^^schema:Person ;
    schema:commentCount "636"^^schema:Integer ;
    schema:dateModified "2017-06-08T19:53:26Z"^^schema:DateTime ;
    schema:datePublished "2016-11-19T22:48:30Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Pruning Convolutional Neural Networks for Resource Efficient Inference"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.06440v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13741786010220230474&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<497> a schema:ScholarlyArticle ;
    schema:abstract "Many machine learning algorithms are vulnerable to almost imperceptibleperturbations of their inputs. So far it was unclear how much risk adversarialperturbations carry for the safety of real-world machine learning applicationsbecause most methods used to generate such perturbations rely either ondetailed model information (gradient-based attacks) or on confidence scoressuch as class probabilities (score-based attacks), neither of which areavailable in most real-world scenarios. In many such cases one currently needsto retreat to transfer-based attacks which rely on cumbersome substitutemodels, need access to the training data and can be defended against. Here weemphasise the importance of attacks which solely rely on the final modeldecision. Such decision-based attacks are (1) applicable to real-worldblack-box models such as autonomous cars, (2) need less knowledge and areeasier to apply than transfer-based attacks and (3) are more robust to simpledefences than gradient- or score-based attacks. Previous attacks in thiscategory were limited to simple models or simple datasets. Here we introducethe Boundary Attack, a decision-based attack that starts from a largeadversarial perturbation and then seeks to reduce the perturbation whilestaying adversarial. The attack is conceptually simple, requires close to nohyperparameter tuning, does not rely on substitute models and is competitivewith the best gradient-based attacks in standard computer vision tasks likeImageNet. We apply the attack on two black-box algorithms from Clarifai.com.The Boundary Attack in particular and the class of decision-based attacks ingeneral open new avenues to study the robustness of machine learning models andraise new questions regarding the safety of deployed machine learning systems.An implementation of the attack is available as part of Foolbox athttps://github.com/bethgelab/foolbox ."^^schema:Text ;
    schema:author "Jonas Rauber"^^schema:Person,
        "Matthias Bethge"^^schema:Person,
        "Wieland Brendel"^^schema:Person ;
    schema:commentCount "294"^^schema:Integer ;
    schema:dateModified "2018-02-16T14:40:42Z"^^schema:DateTime ;
    schema:datePublished "2017-12-12T11:36:26Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box  Machine Learning Models"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.04248v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1222517566911879461&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<498> a schema:ScholarlyArticle ;
    schema:abstract "State-of-the-art models for semantic segmentation are based on adaptations ofconvolutional networks that had originally been designed for imageclassification. However, dense prediction and image classification arestructurally different. In this work, we develop a new convolutional networkmodule that is specifically designed for dense prediction. The presented moduleuses dilated convolutions to systematically aggregate multi-scale contextualinformation without losing resolution. The architecture is based on the factthat dilated convolutions support exponential expansion of the receptive fieldwithout loss of resolution or coverage. We show that the presented contextmodule increases the accuracy of state-of-the-art semantic segmentationsystems. In addition, we examine the adaptation of image classificationnetworks to dense prediction and show that simplifying the adapted network canincrease accuracy."^^schema:Text ;
    schema:author "Fisher Yu"^^schema:Person,
        "Vladlen Koltun"^^schema:Person ;
    schema:commentCount "3314"^^schema:Integer ;
    schema:dateModified "2016-04-30T18:19:37Z"^^schema:DateTime ;
    schema:datePublished "2015-11-23T07:32:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Multi-Scale Context Aggregation by Dilated Convolutions"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.07122v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=381540638710125131&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<499> a schema:ScholarlyArticle ;
    schema:abstract "It is common practice to decay the learning rate. Here we show one canusually obtain the same learning curve on both training and test sets byinstead increasing the batch size during training. This procedure is successfulfor stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum,and Adam. It reaches equivalent test accuracies after the same number oftraining epochs, but with fewer parameter updates, leading to greaterparallelism and shorter training times. We can further reduce the number ofparameter updates by increasing the learning rate $\\epsilon$ and scaling thebatch size $B \\propto \\epsilon$. Finally, one can increase the momentumcoefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightlyreduce the test accuracy. Crucially, our techniques allow us to repurposeexisting training schedules for large batch training with no hyper-parametertuning. We train ResNet-50 on ImageNet to $76.1\\%$ validation accuracy in under30 minutes."^^schema:Text ;
    schema:author "Chris Ying"^^schema:Person,
        "Pieter-Jan Kindermans"^^schema:Person,
        "Quoc V. Le"^^schema:Person,
        "Samuel L. Smith"^^schema:Person ;
    schema:commentCount "330"^^schema:Integer ;
    schema:dateModified "2018-02-24T00:16:12Z"^^schema:DateTime ;
    schema:datePublished "2017-11-01T18:04:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Don't Decay the Learning Rate, Increase the Batch Size"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00489v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3840223745264283290&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<5> a schema:ScholarlyArticle ;
    schema:abstract "Recent work in unsupervised representation learning has focused on learningdeep directed latent-variable models. Fitting these models by maximizing themarginal likelihood or evidence is typically intractable, thus a commonapproximation is to maximize the evidence lower bound (ELBO) instead. However,maximum likelihood training (whether exact or approximate) does not necessarilyresult in a good latent representation, as we demonstrate both theoreticallyand empirically. In particular, we derive variational lower and upper bounds onthe mutual information between the input and the latent variable, and use thesebounds to derive a rate-distortion curve that characterizes the tradeoffbetween compression and reconstruction accuracy. Using this framework, wedemonstrate that there is a family of models with identical ELBO, but differentquantitative and qualitative characteristics. Our framework also suggests asimple new method to ensure that latent variable models with powerfulstochastic decoders do not ignore their latent code."^^schema:Text ;
    schema:author "Alexander A. Alemi"^^schema:Person,
        "Ben Poole"^^schema:Person,
        "Ian Fischer"^^schema:Person,
        "Joshua V. Dillon"^^schema:Person,
        "Kevin Murphy"^^schema:Person,
        "Rif A. Saurous"^^schema:Person ;
    schema:commentCount "173"^^schema:Integer ;
    schema:dateModified "2018-02-13T20:54:38Z"^^schema:DateTime ;
    schema:datePublished "2017-11-01T17:58:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Fixing a Broken ELBO"^^schema:Text ;
    schema:publisher "ICML, 159-168"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00464v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=841461541918895515&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<50> a schema:ScholarlyArticle ;
    schema:abstract "Inspired by recent work in machine translation and object detection, weintroduce an attention based model that automatically learns to describe thecontent of images. We describe how we can train this model in a deterministicmanner using standard backpropagation techniques and stochastically bymaximizing a variational lower bound. We also show through visualization howthe model is able to automatically learn to fix its gaze on salient objectswhile generating the corresponding words in the output sequence. We validatethe use of attention with state-of-the-art performance on three benchmarkdatasets: Flickr8k, Flickr30k and MS COCO."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Jimmy Ba"^^schema:Person,
        "Kelvin Xu"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Ryan Kiros"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "5300"^^schema:Integer ;
    schema:dateModified "2016-04-19T16:43:09Z"^^schema:DateTime ;
    schema:datePublished "2015-02-10T19:18:29Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Show, Attend and Tell: Neural Image Caption Generation with Visual  Attention"^^schema:Text ;
    schema:publisher "ICML, 2048-2057"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.03044v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9471583366007765258&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<500> a schema:ScholarlyArticle ;
    schema:abstract "Establishing correspondence between shapes is a fundamental problem ingeometry processing, arising in a wide variety of applications. The problem isespecially difficult in the setting of non-isometric deformations, as well asin the presence of topological noise and missing parts, mainly due to thelimited capability to model such deformations axiomatically. Several recentworks showed that invariance to complex shape transformations can be learnedfrom examples. In this paper, we introduce an intrinsic convolutional neuralnetwork architecture based on anisotropic diffusion kernels, which we termAnisotropic Convolutional Neural Network (ACNN). In our construction, wegeneralize convolutions to non-Euclidean domains by constructing a set oforiented anisotropic diffusion kernels, creating in this way a local intrinsicpolar representation of the data (`patch'), which is then correlated with afilter. Several cascades of such filters, linear, and non-linear operators arestacked to form a deep neural network whose parameters are learned byminimizing a task-specific cost. We use ACNNs to effectively learn intrinsicdense correspondences between deformable shapes in very challenging settings,achieving state-of-the-art results on some of the most difficult recentcorrespondence benchmarks."^^schema:Text ;
    schema:author "Davide Boscaini"^^schema:Person,
        "Emanuele Rodolà"^^schema:Person,
        "Jonathan Masci"^^schema:Person,
        "Michael M. Bronstein"^^schema:Person ;
    schema:commentCount "279"^^schema:Integer ;
    schema:dateModified "2016-05-20T17:02:40Z"^^schema:DateTime ;
    schema:datePublished "2016-05-20T17:02:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning shape correspondence with anisotropic convolutional neural  networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06437v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8736265664125680677&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<501> a schema:ScholarlyArticle ;
    schema:abstract "Most tasks in natural language processing can be cast into question answering(QA) problems over language input. We introduce the dynamic memory network(DMN), a neural network architecture which processes input sequences andquestions, forms episodic memories, and generates relevant answers. Questionstrigger an iterative attention process which allows the model to condition itsattention on the inputs and the result of previous iterations. These resultsare then reasoned over in a hierarchical recurrent sequence model to generateanswers. The DMN can be trained end-to-end and obtains state-of-the-art resultson several types of tasks and datasets: question answering (Facebook's bAbIdataset), text classification for sentiment analysis (Stanford SentimentTreebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). Thetraining for these different tasks relies exclusively on trained word vectorrepresentations and input-question-answer triplets."^^schema:Text ;
    schema:author "Ankit Kumar"^^schema:Person,
        "Ishaan Gulrajani"^^schema:Person,
        "James Bradbury"^^schema:Person,
        "Mohit Iyyer"^^schema:Person,
        "Ozan Irsoy"^^schema:Person,
        "Peter Ondruska"^^schema:Person,
        "Richard Socher"^^schema:Person,
        "Romain Paulus"^^schema:Person,
        "Victor Zhong"^^schema:Person ;
    schema:commentCount "867"^^schema:Integer ;
    schema:dateModified "2016-03-05T20:18:55Z"^^schema:DateTime ;
    schema:datePublished "2015-06-24T08:27:02Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"^^schema:Text ;
    schema:publisher "ICML, 1378-1387"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.07285v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7594599060018037557&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<502> a schema:ScholarlyArticle ;
    schema:abstract "The prevalent approach to sequence to sequence learning maps an inputsequence to a variable length output sequence via recurrent neural networks. Weintroduce an architecture based entirely on convolutional neural networks.Compared to recurrent models, computations over all elements can be fullyparallelized during training and optimization is easier since the number ofnon-linearities is fixed and independent of the input length. Our use of gatedlinear units eases gradient propagation and we equip each decoder layer with aseparate attention module. We outperform the accuracy of the deep LSTM setup ofWu et al. (2016) on both WMT'14 English-German and WMT'14 English-Frenchtranslation at an order of magnitude faster speed, both on GPU and CPU."^^schema:Text ;
    schema:author "David Grangier"^^schema:Person,
        "Denis Yarats"^^schema:Person,
        "Jonas Gehring"^^schema:Person,
        "Michael Auli"^^schema:Person,
        "Yann N. Dauphin"^^schema:Person ;
    schema:commentCount "1529"^^schema:Integer ;
    schema:dateModified "2017-07-25T01:40:57Z"^^schema:DateTime ;
    schema:datePublished "2017-05-08T23:25:30Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Convolutional Sequence to Sequence Learning"^^schema:Text ;
    schema:publisher "ICML, 1243-1252"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.03122v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9032432574575787905&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<503> a schema:ScholarlyArticle ;
    schema:abstract "Gatys et al. recently demonstrated that deep networks can generate beautifultextures and stylized images from a single texture example. However, theirmethods requires a slow and memory-consuming optimization process. We proposehere an alternative approach that moves the computational burden to a learningstage. Given a single example of a texture, our approach trains compactfeed-forward convolutional networks to generate multiple samples of the sametexture of arbitrary size and to transfer artistic style from a given image toany other image. The resulting networks are remarkably light-weight and cangenerate textures of quality comparable to Gatys~et~al., but hundreds of timesfaster. More generally, our approach highlights the power and flexibility ofgenerative feed-forward models trained with complex and expressive lossfunctions."^^schema:Text ;
    schema:author "Andrea Vedaldi"^^schema:Person,
        "Dmitry Ulyanov"^^schema:Person,
        "Vadim Lebedev"^^schema:Person,
        "Victor Lempitsky"^^schema:Person ;
    schema:commentCount "488"^^schema:Integer ;
    schema:dateModified "2016-03-10T20:45:40Z"^^schema:DateTime ;
    schema:datePublished "2016-03-10T20:45:40Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Texture Networks: Feed-forward Synthesis of Textures and Stylized Images"^^schema:Text ;
    schema:publisher "ICML, 1349-1357"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.03417v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5452588382099665760&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<504> a schema:ScholarlyArticle ;
    schema:abstract "We introduce Parseval networks, a form of deep neural networks in which theLipschitz constant of linear, convolutional and aggregation layers isconstrained to be smaller than 1. Parseval networks are empirically andtheoretically motivated by an analysis of the robustness of the predictionsmade by deep neural networks when their input is subject to an adversarialperturbation. The most important feature of Parseval networks is to maintainweight matrices of linear and convolutional layers to be (approximately)Parseval tight frames, which are extensions of orthogonal matrices tonon-square matrices. We describe how these constraints can be maintainedefficiently during SGD. We show that Parseval networks match thestate-of-the-art in terms of accuracy on CIFAR-10/100 and Street View HouseNumbers (SVHN) while being more robust than their vanilla counterpart againstadversarial examples. Incidentally, Parseval networks also tend to train fasterand make a better usage of the full capacity of the networks."^^schema:Text ;
    schema:author "Edouard Grave"^^schema:Person,
        "Moustapha Cisse"^^schema:Person,
        "Nicolas Usunier"^^schema:Person,
        "Piotr Bojanowski"^^schema:Person,
        "Yann Dauphin"^^schema:Person ;
    schema:commentCount "329"^^schema:Integer ;
    schema:dateModified "2017-05-02T01:11:21Z"^^schema:DateTime ;
    schema:datePublished "2017-04-28T08:43:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Parseval Networks: Improving Robustness to Adversarial Examples"^^schema:Text ;
    schema:publisher "ICML, 854-863"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.08847v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11979400639430622244&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<505> a schema:ScholarlyArticle ;
    schema:abstract "In value-based reinforcement learning methods such as deep Q-learning,function approximation errors are known to lead to overestimated valueestimates and suboptimal policies. We show that this problem persists in anactor-critic setting and propose novel mechanisms to minimize its effects onboth the actor and the critic. Our algorithm builds on Double Q-learning, bytaking the minimum value between a pair of critics to limit overestimation. Wedraw the connection between target networks and overestimation bias, andsuggest delaying policy updates to reduce per-update error and further improveperformance. We evaluate our method on the suite of OpenAI gym tasks,outperforming the state of the art in every environment tested."^^schema:Text ;
    schema:author "David Meger"^^schema:Person,
        "Herke van Hoof"^^schema:Person,
        "Scott Fujimoto"^^schema:Person ;
    schema:commentCount "389"^^schema:Integer ;
    schema:dateModified "2018-10-22T17:37:07Z"^^schema:DateTime ;
    schema:datePublished "2018-02-26T17:54:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Addressing Function Approximation Error in Actor-Critic Methods"^^schema:Text ;
    schema:publisher "ICML, 1582-1591"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.09477v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2930747733592680111&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<506> a schema:ScholarlyArticle ;
    schema:abstract "Batch Normalization (BatchNorm) is a widely adopted technique that enablesfaster and more stable training of deep neural networks (DNNs). Despite itspervasiveness, the exact reasons for BatchNorm's effectiveness are still poorlyunderstood. The popular belief is that this effectiveness stems fromcontrolling the change of the layers' input distributions during training toreduce the so-called \"internal covariate shift\". In this work, we demonstratethat such distributional stability of layer inputs has little to do with thesuccess of BatchNorm. Instead, we uncover a more fundamental impact ofBatchNorm on the training process: it makes the optimization landscapesignificantly smoother. This smoothness induces a more predictive and stablebehavior of the gradients, allowing for faster training."^^schema:Text ;
    schema:author "Aleksander Madry"^^schema:Person,
        "Andrew Ilyas"^^schema:Person,
        "Dimitris Tsipras"^^schema:Person,
        "Shibani Santurkar"^^schema:Person ;
    schema:commentCount "255"^^schema:Integer ;
    schema:dateModified "2019-04-15T02:34:55Z"^^schema:DateTime ;
    schema:datePublished "2018-05-29T17:42:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "How Does Batch Normalization Help Optimization?"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.11604v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9444562420324395093&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<507> a schema:ScholarlyArticle ;
    schema:abstract "We introduce NoisyNet, a deep reinforcement learning agent with parametricnoise added to its weights, and show that the induced stochasticity of theagent's policy can be used to aid efficient exploration. The parameters of thenoise are learned with gradient descent along with the remaining networkweights. NoisyNet is straightforward to implement and adds little computationaloverhead. We find that replacing the conventional exploration heuristics forA3C, DQN and dueling agents (entropy reward and $\\epsilon$-greedy respectively)with NoisyNet yields substantially higher scores for a wide range of Atarigames, in some cases advancing the agent from sub to super-human performance."^^schema:Text ;
    schema:author "Alex Graves"^^schema:Person,
        "Bilal Piot"^^schema:Person,
        "Charles Blundell"^^schema:Person,
        "Demis Hassabis"^^schema:Person,
        "Ian Osband"^^schema:Person,
        "Jacob Menick"^^schema:Person,
        "Meire Fortunato"^^schema:Person,
        "Mohammad Gheshlaghi Azar"^^schema:Person,
        "Olivier Pietquin"^^schema:Person,
        "Remi Munos"^^schema:Person,
        "Shane Legg"^^schema:Person,
        "Vlad Mnih"^^schema:Person ;
    schema:commentCount "285"^^schema:Integer ;
    schema:dateModified "2019-07-09T09:57:23Z"^^schema:DateTime ;
    schema:datePublished "2017-06-30T17:56:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Noisy Networks for Exploration"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.10295v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13916735202249031707&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<508> a schema:ScholarlyArticle ;
    schema:abstract "Hypernymy, textual entailment, and image captioning can be seen as specialcases of a single visual-semantic hierarchy over words, sentences, and images.In this paper we advocate for explicitly modeling the partial order structureof this hierarchy. Towards this goal, we introduce a general method forlearning ordered representations, and show how it can be applied to a varietyof tasks involving images and language. We show that the resultingrepresentations improve performance over current approaches for hypernymprediction and image-caption retrieval."^^schema:Text ;
    schema:author "Ivan Vendrov"^^schema:Person,
        "Raquel Urtasun"^^schema:Person,
        "Ryan Kiros"^^schema:Person,
        "Sanja Fidler"^^schema:Person ;
    schema:commentCount "332"^^schema:Integer ;
    schema:dateModified "2016-03-01T08:23:50Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T20:56:14Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Order-Embeddings of Images and Language"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06361v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13175166350768143063&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<509> a schema:ScholarlyArticle ;
    schema:abstract "Unlike human learning, machine learning often fails to handle changes betweentraining (source) and test (target) input distributions. Such domain shifts,common in practical scenarios, severely damage the performance of conventionalmachine learning methods. Supervised domain adaptation methods have beenproposed for the case when the target data have labels, including some thatperform very well despite being \"frustratingly easy\" to implement. However, inpractice, the target domain is often unlabeled, requiring unsupervisedadaptation. We propose a simple, effective, and efficient method forunsupervised domain adaptation called CORrelation ALignment (CORAL). CORALminimizes domain shift by aligning the second-order statistics of source andtarget distributions, without requiring any target labels. Even though it isextraordinarily simple--it can be implemented in four lines of Matlabcode--CORAL performs remarkably well in extensive evaluations on standardbenchmark datasets."^^schema:Text ;
    schema:author "Baochen Sun"^^schema:Person,
        "Jiashi Feng"^^schema:Person,
        "Kate Saenko"^^schema:Person ;
    schema:commentCount "574"^^schema:Integer ;
    schema:dateModified "2015-12-09T05:39:43Z"^^schema:DateTime ;
    schema:datePublished "2015-11-17T20:53:26Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Return of Frustratingly Easy Domain Adaptation"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05547v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5209185556385462018&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<51> a schema:ScholarlyArticle ;
    schema:abstract "Neural network models are capable of generating extremely natural soundingconversational interactions. Nevertheless, these models have yet to demonstratethat they can incorporate content in the form of factual information orentity-grounded opinion that would enable them to serve in more task-orientedconversational applications. This paper presents a novel, fully data-driven,and knowledge-grounded neural conversation model aimed at producing morecontentful responses without slot filling. We generalize the widely-usedSeq2Seq approach by conditioning responses on both conversation history andexternal \"facts\", allowing the model to be versatile and applicable in anopen-domain setting. Our approach yields significant improvements over acompetitive Seq2Seq baseline. Human judges found that our outputs aresignificantly more informative."^^schema:Text ;
    schema:author "Bill Dolan"^^schema:Person,
        "Chris Brockett"^^schema:Person,
        "Jianfeng Gao"^^schema:Person,
        "Marjan Ghazvininejad"^^schema:Person,
        "Michel Galley"^^schema:Person,
        "Ming-Wei Chang"^^schema:Person,
        "Wen-tau Yih"^^schema:Person ;
    schema:commentCount "212"^^schema:Integer ;
    schema:dateModified "2018-11-15T19:04:48Z"^^schema:DateTime ;
    schema:datePublished "2017-02-07T09:16:46Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "A Knowledge-Grounded Neural Conversation Model"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.01932v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10303927314409501955&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<510> a schema:ScholarlyArticle ;
    schema:abstract "Probabilistic generative models can be used for compression, denoising,inpainting, texture synthesis, semi-supervised learning, unsupervised featurelearning, and other tasks. Given this wide range of applications, it is notsurprising that a lot of heterogeneity exists in the way these models areformulated, trained, and evaluated. As a consequence, direct comparison betweenmodels is often difficult. This article reviews mostly known but oftenunderappreciated properties relating to the evaluation and interpretation ofgenerative models with a focus on image models. In particular, we show thatthree of the currently most commonly used criteria---average log-likelihood,Parzen window estimates, and visual fidelity of samples---are largelyindependent of each other when the data is high-dimensional. Good performancewith respect to one criterion therefore need not imply good performance withrespect to the other criteria. Our results show that extrapolation from onecriterion to another is not warranted and generative models need to beevaluated directly with respect to the application(s) they were intended for.In addition, we provide examples demonstrating that Parzen window estimatesshould generally be avoided."^^schema:Text ;
    schema:author "Aäron van den Oord"^^schema:Person,
        "Lucas Theis"^^schema:Person,
        "Matthias Bethge"^^schema:Person ;
    schema:commentCount "597"^^schema:Integer ;
    schema:dateModified "2016-04-24T20:03:35Z"^^schema:DateTime ;
    schema:datePublished "2015-11-05T18:22:44Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A note on the evaluation of generative models"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.01844v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11726515919678318873&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<511> a schema:ScholarlyArticle ;
    schema:abstract "This paper investigates recently proposed approaches for defending againstadversarial examples and evaluating adversarial robustness. We motivate'adversarial risk' as an objective for achieving models robust to worst-caseinputs. We then frame commonly used attacks and evaluation metrics as defininga tractable surrogate objective to the true adversarial risk. This suggeststhat models may optimize this surrogate rather than the true adversarial risk.We formalize this notion as 'obscurity to an adversary,' and develop tools andheuristics for identifying obscured models and designing transparent models. Wedemonstrate that this is a significant problem in practice by repurposinggradient-free optimization techniques into adversarial attacks, which we use todecrease the accuracy of several recently proposed defenses to near zero. Ourhope is that our formulations and results will help researchers to develop morepowerful defenses."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Brendan O'Donoghue"^^schema:Person,
        "Jonathan Uesato"^^schema:Person,
        "Pushmeet Kohli"^^schema:Person ;
    schema:commentCount "172"^^schema:Integer ;
    schema:dateModified "2018-06-12T14:20:27Z"^^schema:DateTime ;
    schema:datePublished "2018-02-15T17:13:18Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Risk and the Dangers of Evaluating Against Weak Attacks"^^schema:Text ;
    schema:publisher "ICML, 5032-5041"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.05666v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11987569658631907048&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<512> a schema:ScholarlyArticle ;
    schema:abstract "Computer vision has benefited from initializing multiple deep layers withweights pretrained on large supervised training sets like ImageNet. Naturallanguage processing (NLP) typically sees initialization of only the lowestlayer of deep models with pretrained word vectors. In this paper, we use a deepLSTM encoder from an attentional sequence-to-sequence model trained for machinetranslation (MT) to contextualize word vectors. We show that adding thesecontext vectors (CoVe) improves performance over using only unsupervised wordand character vectors on a wide variety of common NLP tasks: sentiment analysis(SST, IMDb), question classification (TREC), entailment (SNLI), and questionanswering (SQuAD). For fine-grained sentiment analysis and entailment, CoVeimproves performance of our baseline models to the state of the art."^^schema:Text ;
    schema:author "Bryan McCann"^^schema:Person,
        "Caiming Xiong"^^schema:Person,
        "James Bradbury"^^schema:Person,
        "Richard Socher"^^schema:Person ;
    schema:commentCount "494"^^schema:Integer ;
    schema:dateModified "2018-06-20T13:15:06Z"^^schema:DateTime ;
    schema:datePublished "2017-08-01T00:05:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learned in Translation: Contextualized Word Vectors"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.00107v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12356231721397988330&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<513> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a new test of how well language models capture meaning inchildren's books. Unlike standard language modelling benchmarks, itdistinguishes the task of predicting syntactic function words from that ofpredicting lower-frequency words, which carry greater semantic content. Wecompare a range of state-of-the-art models, each with a different way ofencoding what has been previously read. We show that models which storeexplicit representations of long-term contexts outperform state-of-the-artneural language models at predicting semantic content words, although thisadvantage is not observed for syntactic function words. Interestingly, we findthat the amount of text encoded in a single memory representation is highlyinfluential to the performance: there is a sweet-spot, not too big and not toosmall, between single words and full sentences that allows the most meaningfulinformation in a text to be effectively retained and recalled. Further, theattention over such window-based memories can be trained effectively throughself-supervision. We then assess the generality of this principle by applyingit to the CNN QA benchmark, which involves identifying named entities inparaphrased summaries of news articles, and achieve state-of-the-artperformance."^^schema:Text ;
    schema:author "Antoine Bordes"^^schema:Person,
        "Felix Hill"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Sumit Chopra"^^schema:Person ;
    schema:commentCount "408"^^schema:Integer ;
    schema:dateModified "2016-04-01T05:31:33Z"^^schema:DateTime ;
    schema:datePublished "2015-11-07T04:36:20Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "The Goldilocks Principle: Reading Children's Books with Explicit Memory  Representations"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.02301v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14633685640258770614&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<514> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks (CNNs) are usually built by stackingconvolutional operations layer-by-layer. Although CNN has shown strongcapability to extract semantics from raw pixels, its capacity to capturespatial relationships of pixels across rows and columns of an image is notfully explored. These relationships are important to learn semantic objectswith strong shape priors but weak appearance coherences, such as traffic lanes,which are often occluded or not even painted on the road surface as shown inFig. 1 (a). In this paper, we propose Spatial CNN (SCNN), which generalizestraditional deep layer-by-layer convolutions to slice-byslice convolutionswithin feature maps, thus enabling message passings between pixels across rowsand columns in a layer. Such SCNN is particular suitable for long continuousshape structure or large objects, with strong spatial relationship but lessappearance clues, such as traffic lanes, poles, and wall. We apply SCNN on anewly released very challenging traffic lane detection dataset and Cityscapsedataset. The results show that SCNN could learn the spatial relationship forstructure output and significantly improves the performance. We show that SCNNoutperforms the recurrent neural network (RNN) based ReNet and MRF+CNN (MRFNet)in the lane detection dataset by 8.7% and 4.6% respectively. Moreover, our SCNNwon the 1st place on the TuSimple Benchmark Lane Detection Challenge, with anaccuracy of 96.53%."^^schema:Text ;
    schema:author "Jianping Shi"^^schema:Person,
        "Ping Luo"^^schema:Person,
        "Xiaogang Wang"^^schema:Person,
        "Xiaoou Tang"^^schema:Person,
        "Xingang Pan"^^schema:Person ;
    schema:commentCount "129"^^schema:Integer ;
    schema:dateModified "2017-12-17T09:37:52Z"^^schema:DateTime ;
    schema:datePublished "2017-12-17T09:37:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Spatial As Deep: Spatial CNN for Traffic Scene Understanding"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.06080v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7356833526698200169&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<515> a schema:ScholarlyArticle ;
    schema:abstract "Scalable and effective exploration remains a key challenge in reinforcementlearning (RL). While there are methods with optimality guarantees in thesetting of discrete state and action spaces, these methods cannot be applied inhigh-dimensional deep RL scenarios. As such, most contemporary RL relies onsimple heuristics such as epsilon-greedy exploration or adding Gaussian noiseto the controls. This paper introduces Variational Information MaximizingExploration (VIME), an exploration strategy based on maximization ofinformation gain about the agent's belief of environment dynamics. We propose apractical implementation, using variational inference in Bayesian neuralnetworks which efficiently handles continuous state and action spaces. VIMEmodifies the MDP reward function, and can be applied with several differentunderlying RL algorithms. We demonstrate that VIME achieves significantlybetter performance compared to heuristic exploration methods across a varietyof continuous control tasks and algorithms, including tasks with very sparserewards."^^schema:Text ;
    schema:author "Filip De Turck"^^schema:Person,
        "John Schulman"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Rein Houthooft"^^schema:Person,
        "Xi Chen"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "313"^^schema:Integer ;
    schema:dateModified "2017-01-27T09:26:28Z"^^schema:DateTime ;
    schema:datePublished "2016-05-31T15:34:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "VIME: Variational Information Maximizing Exploration"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.09674v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4965361873864842159&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<516> a schema:ScholarlyArticle ;
    schema:abstract "Understanding why a model makes a certain prediction can be as crucial as theprediction's accuracy in many applications. However, the highest accuracy forlarge modern datasets is often achieved by complex models that even expertsstruggle to interpret, such as ensemble or deep learning models, creating atension between accuracy and interpretability. In response, various methodshave recently been proposed to help users interpret the predictions of complexmodels, but it is often unclear how these methods are related and when onemethod is preferable over another. To address this problem, we present aunified framework for interpreting predictions, SHAP (SHapley AdditiveexPlanations). SHAP assigns each feature an importance value for a particularprediction. Its novel components include: (1) the identification of a new classof additive feature importance measures, and (2) theoretical results showingthere is a unique solution in this class with a set of desirable properties.The new class unifies six existing methods, notable because several recentmethods in the class lack the proposed desirable properties. Based on insightsfrom this unification, we present new methods that show improved computationalperformance and/or better consistency with human intuition than previousapproaches."^^schema:Text ;
    schema:author "Scott Lundberg"^^schema:Person,
        "Su-In Lee"^^schema:Person ;
    schema:commentCount "1229"^^schema:Integer ;
    schema:dateModified "2017-11-25T03:53:32Z"^^schema:DateTime ;
    schema:datePublished "2017-05-22T17:38:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Unified Approach to Interpreting Model Predictions"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.07874v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6828961408019591083&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<517> a schema:ScholarlyArticle ;
    schema:abstract "Deep Learning has revolutionized vision via convolutional neural networks(CNNs) and natural language processing via recurrent neural networks (RNNs).However, success stories of Deep Learning with standard feed-forward neuralnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,therefore cannot exploit many levels of abstract representations. We introduceself-normalizing neural networks (SNNs) to enable high-level abstractrepresentations. While batch normalization requires explicit normalization,neuron activations of SNNs automatically converge towards zero mean and unitvariance. The activation function of SNNs are \"scaled exponential linear units\"(SELUs), which induce self-normalizing properties. Using the Banach fixed-pointtheorem, we prove that activations close to zero mean and unit variance thatare propagated through many network layers will converge towards zero mean andunit variance -- even under the presence of noise and perturbations. Thisconvergence property of SNNs allows to (1) train deep networks with manylayers, (2) employ strong regularization, and (3) to make learning highlyrobust. Furthermore, for activations not close to unit variance, we prove anupper and lower bound on the variance, thus, vanishing and exploding gradientsare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learningrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks withstandard FNNs and other machine learning methods such as random forests andsupport vector machines. SNNs significantly outperformed all competing FNNmethods at 121 UCI tasks, outperformed all competing methods at the Tox21dataset, and set a new record at an astronomy data set. The winning SNNarchitectures are often very deep. Implementations are available at:github.com/bioinf-jku/SNNs."^^schema:Text ;
    schema:author "Andreas Mayr"^^schema:Person,
        "Günter Klambauer"^^schema:Person,
        "Sepp Hochreiter"^^schema:Person,
        "Thomas Unterthiner"^^schema:Person ;
    schema:commentCount "963"^^schema:Integer ;
    schema:dateModified "2017-09-07T10:39:00Z"^^schema:DateTime ;
    schema:datePublished "2017-06-08T11:14:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Self-Normalizing Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02515v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3659160383490046744&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<518> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)which views the discriminator as an energy function that attributes lowenergies to the regions near the data manifold and higher energies to otherregions. Similar to the probabilistic GANs, a generator is seen as beingtrained to produce contrastive samples with minimal energies, while thediscriminator is trained to assign high energies to these generated samples.Viewing the discriminator as an energy function allows to use a wide variety ofarchitectures and loss functionals in addition to the usual binary classifierwith logistic output. Among them, we show one instantiation of EBGAN frameworkas using an auto-encoder architecture, with the energy being the reconstructionerror, in place of the discriminator. We show that this form of EBGAN exhibitsmore stable behavior than regular GANs during training. We also show that asingle-scale architecture can be trained to generate high-resolution images."^^schema:Text ;
    schema:author "Junbo Zhao"^^schema:Person,
        "Michael Mathieu"^^schema:Person,
        "Yann LeCun"^^schema:Person ;
    schema:commentCount "770"^^schema:Integer ;
    schema:dateModified "2017-03-06T22:52:53Z"^^schema:DateTime ;
    schema:datePublished "2016-09-11T07:11:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Energy-based Generative Adversarial Network"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.03126v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15426746467469595309&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<519> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel deep neural network architecture for semi-supervisedsemantic segmentation using heterogeneous annotations. Contrary to existingapproaches posing semantic segmentation as a single task of region-basedclassification, our algorithm decouples classification and segmentation, andlearns a separate network for each task. In this architecture, labelsassociated with an image are identified by classification network, and binarysegmentation is subsequently performed for each identified label insegmentation network. The decoupled architecture enables us to learnclassification and segmentation networks separately based on the training datawith image-level and pixel-wise class labels, respectively. It facilitates toreduce search space for segmentation effectively by exploiting class-specificactivation maps obtained from bridging layers. Our algorithm shows outstandingperformance compared to other semi-supervised approaches even with much lesstraining images with strong annotations in PASCAL VOC dataset."^^schema:Text ;
    schema:author "Bohyung Han"^^schema:Person,
        "Hyeonwoo Noh"^^schema:Person,
        "Seunghoon Hong"^^schema:Person ;
    schema:commentCount "254"^^schema:Integer ;
    schema:dateModified "2015-06-17T08:38:32Z"^^schema:DateTime ;
    schema:datePublished "2015-06-16T11:20:04Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.04924v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15385340253531275638&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<52> a schema:ScholarlyArticle ;
    schema:abstract "Recent studies have highlighted the vulnerability of deep neural networks(DNNs) to adversarial examples - a visually indistinguishable adversarial imagecan easily be crafted to cause a well-trained model to misclassify. Existingmethods for crafting adversarial examples are based on $L_2$ and $L_\\infty$distortion metrics. However, despite the fact that $L_1$ distortion accountsfor the total variation and encourages sparsity in the perturbation, little hasbeen developed for crafting $L_1$-based adversarial examples. In this paper, weformulate the process of attacking DNNs via adversarial examples as anelastic-net regularized optimization problem. Our elastic-net attacks to DNNs(EAD) feature $L_1$-oriented adversarial examples and include thestate-of-the-art $L_2$ attack as a special case. Experimental results on MNIST,CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarialexamples with small $L_1$ distortion and attains similar attack performance tothe state-of-the-art methods in different attack scenarios. More importantly,EAD leads to improved attack transferability and complements adversarialtraining for DNNs, suggesting novel insights on leveraging $L_1$ distortion inadversarial machine learning and security implications of DNNs."^^schema:Text ;
    schema:author "Cho-Jui Hsieh"^^schema:Person,
        "Huan Zhang"^^schema:Person,
        "Jinfeng Yi"^^schema:Person,
        "Pin-Yu Chen"^^schema:Person,
        "Yash Sharma"^^schema:Person ;
    schema:commentCount "211"^^schema:Integer ;
    schema:dateModified "2018-02-10T04:49:12Z"^^schema:DateTime ;
    schema:datePublished "2017-09-13T02:40:59Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial  Examples"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.04114v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12822881129295839300&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<520> a schema:ScholarlyArticle ;
    schema:abstract "The success of CNNs in various applications is accompanied by a significantincrease in the computation and parameter storage costs. Recent efforts towardreducing these overheads involve pruning and compressing the weights of variouslayers without hurting original accuracy. However, magnitude-based pruning ofweights reduces a significant number of parameters from the fully connectedlayers and may not adequately reduce the computation costs in the convolutionallayers due to irregular sparsity in the pruned networks. We present anacceleration method for CNNs, where we prune filters from CNNs that areidentified as having a small effect on the output accuracy. By removing wholefilters in the network together with their connecting feature maps, thecomputation costs are reduced significantly. In contrast to pruning weights,this approach does not result in sparse connectivity patterns. Hence, it doesnot need the support of sparse convolution libraries and can work with existingefficient BLAS libraries for dense matrix multiplications. We show that evensimple filter pruning techniques can reduce inference costs for VGG-16 by up to34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to theoriginal accuracy by retraining the networks."^^schema:Text ;
    schema:author "Asim Kadav"^^schema:Person,
        "Hanan Samet"^^schema:Person,
        "Hans Peter Graf"^^schema:Person,
        "Hao Li"^^schema:Person,
        "Igor Durdanovic"^^schema:Person ;
    schema:commentCount "1073"^^schema:Integer ;
    schema:dateModified "2017-03-10T17:57:56Z"^^schema:DateTime ;
    schema:datePublished "2016-08-31T02:29:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Pruning Filters for Efficient ConvNets"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.08710v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10756249335825111134&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<521> a schema:ScholarlyArticle ;
    schema:abstract "Attempts to train a comprehensive artificial intelligence capable of solvingmultiple tasks have been impeded by a chronic problem called catastrophicforgetting. Although simply replaying all previous data alleviates the problem,it requires large memory and even worse, often infeasible in real worldapplications where the access to past data is limited. Inspired by thegenerative nature of hippocampus as a short-term memory system in primatebrain, we propose the Deep Generative Replay, a novel framework with acooperative dual model architecture consisting of a deep generative model(\"generator\") and a task solving model (\"solver\"). With only these two models,training data for previous tasks can easily be sampled and interleaved withthose for a new task. We test our methods in several sequential learningsettings involving image classification tasks."^^schema:Text ;
    schema:author "Hanul Shin"^^schema:Person,
        "Jaehong Kim"^^schema:Person,
        "Jiwon Kim"^^schema:Person,
        "Jung Kwon Lee"^^schema:Person ;
    schema:commentCount "264"^^schema:Integer ;
    schema:dateModified "2017-12-12T02:14:21Z"^^schema:DateTime ;
    schema:datePublished "2017-05-24T10:37:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Continual Learning with Deep Generative Replay"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08690v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5696060555916548471&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<522> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new approach to the problem of neural network expressivity,which seeks to characterize how structural properties of a neural networkfamily affect the functions it is able to compute. Our approach is based on aninterrelated set of measures of expressivity, unified by the novel notion oftrajectory length, which measures how the output of a network changes as theinput sweeps along a one-dimensional path. Our findings can be summarized asfollows:  (1) The complexity of the computed function grows exponentially with depth.  (2) All weights are not equal: trained networks are more sensitive to theirlower (initial) layer weights.  (3) Regularizing on trajectory length (trajectory regularization) is asimpler alternative to batch normalization, with the same performance."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Jon Kleinberg"^^schema:Person,
        "Maithra Raghu"^^schema:Person,
        "Surya Ganguli"^^schema:Person ;
    schema:commentCount "309"^^schema:Integer ;
    schema:dateModified "2017-06-18T13:24:34Z"^^schema:DateTime ;
    schema:datePublished "2016-06-16T19:55:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Expressive Power of Deep Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 2847-2854"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.05336v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12198207364825963041&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<523> a schema:ScholarlyArticle ;
    schema:abstract "The stochastic gradient descent (SGD) method and its variants are algorithmsof choice for many Deep Learning tasks. These methods operate in a small-batchregime wherein a fraction of the training data, say $32$-$512$ data points, issampled to compute an approximation to the gradient. It has been observed inpractice that when using a larger batch there is a degradation in the qualityof the model, as measured by its ability to generalize. We investigate thecause for this generalization drop in the large-batch regime and presentnumerical evidence that supports the view that large-batch methods tend toconverge to sharp minimizers of the training and testing functions - and as iswell known, sharp minima lead to poorer generalization. In contrast,small-batch methods consistently converge to flat minimizers, and ourexperiments support a commonly held view that this is due to the inherent noisein the gradient estimation. We discuss several strategies to attempt to helplarge-batch methods eliminate this generalization gap."^^schema:Text ;
    schema:author "Dheevatsa Mudigere"^^schema:Person,
        "Jorge Nocedal"^^schema:Person,
        "Mikhail Smelyanskiy"^^schema:Person,
        "Nitish Shirish Keskar"^^schema:Person,
        "Ping Tak Peter Tang"^^schema:Person ;
    schema:commentCount "943"^^schema:Integer ;
    schema:dateModified "2017-02-09T20:38:16Z"^^schema:DateTime ;
    schema:datePublished "2016-09-15T20:03:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp  Minima"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.04836v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2526562489715623205&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<524> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the multiresolution recurrent neural network, which extends thesequence-to-sequence framework to model natural language generation as twoparallel discrete stochastic processes: a sequence of high-level coarse tokens,and a sequence of natural language tokens. There are many ways to estimate orlearn the high-level coarse tokens, but we argue that a simple extractionprocedure is sufficient to capture a wealth of high-level discourse semantics.Such procedure allows training the multiresolution recurrent neural network bymaximizing the exact joint log-likelihood over both sequences. In contrast tothe standard log- likelihood objective w.r.t. natural language tokens (wordperplexity), optimizing the joint log-likelihood biases the model towardsmodeling high-level abstractions. We apply the proposed model to the task ofdialogue response generation in two challenging domains: the Ubuntu technicalsupport domain, and Twitter conversations. On Ubuntu, the model outperformscompeting approaches by a substantial margin, achieving state-of-the-artresults according to both automatic evaluation metrics and a human evaluationstudy. On Twitter, the model appears to generate more relevant and on-topicresponses according to automatic evaluation metrics. Finally, our experimentsdemonstrate that the proposed model is more adept at overcoming the sparsity ofnatural language and is better able to capture long-term structure."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Bowen Zhou"^^schema:Person,
        "Gerald Tesauro"^^schema:Person,
        "Iulian Vlad Serban"^^schema:Person,
        "Kartik Talamadupula"^^schema:Person,
        "Tim Klinger"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "147"^^schema:Integer ;
    schema:dateModified "2016-06-14T02:01:16Z"^^schema:DateTime ;
    schema:datePublished "2016-06-02T17:37:31Z"^^schema:DateTime ;
    schema:genre "I.5.1; I.2.7"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multiresolution Recurrent Neural Networks: An Application to Dialogue  Response Generation"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.00776v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4269931547013111900&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<525> a schema:ScholarlyArticle ;
    schema:abstract "Recently, image representation built upon Convolutional Neural Network (CNN)has been shown to provide effective descriptors for image search, outperformingpre-CNN features as short-vector representations. Yet such models are notcompatible with geometry-aware re-ranking methods and still outperformed, onsome particular object retrieval benchmarks, by traditional image searchsystems relying on precise descriptor matching, geometric re-ranking, or queryexpansion. This work revisits both retrieval stages, namely initial search andre-ranking, by employing the same primitive information derived from the CNN.We build compact feature vectors that encode several image regions without theneed to feed multiple inputs to the network. Furthermore, we extend integralimages to handle max-pooling on convolutional layer activations, allowing us toefficiently localize matching objects. The resulting bounding box is finallyused for image re-ranking. As a result, this paper significantly improvesexisting CNN-based recognition pipeline: We report for the first time resultscompeting with traditional methods on the challenging Oxford5k and Paris6kdatasets."^^schema:Text ;
    schema:author "Giorgos Tolias"^^schema:Person,
        "Hervé Jégou"^^schema:Person,
        "Ronan Sicre"^^schema:Person ;
    schema:commentCount "535"^^schema:Integer ;
    schema:dateModified "2016-02-24T15:14:34Z"^^schema:DateTime ;
    schema:datePublished "2015-11-18T17:02:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Particular object retrieval with integral max-pooling of CNN activations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05879v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2928499544278774292&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<526> a schema:ScholarlyArticle ;
    schema:abstract "Learning to navigate in complex environments with dynamic elements is animportant milestone in developing AI agents. In this work we formulate thenavigation question as a reinforcement learning problem and show that dataefficiency and task performance can be dramatically improved by relying onadditional auxiliary tasks leveraging multimodal sensory inputs. In particularwe consider jointly learning the goal-driven reinforcement learning problemwith auxiliary depth prediction and loop closure classification tasks. Thisapproach can learn to navigate from raw sensory input in complicated 3D mazes,approaching human-level performance even under conditions where the goallocation changes frequently. We provide detailed analysis of the agentbehaviour, its ability to localise, and its network activity dynamics, showingthat the agent implicitly learns key navigation abilities."^^schema:Text ;
    schema:author "Andrea Banino"^^schema:Person,
        "Andrew J. Ballard"^^schema:Person,
        "Dharshan Kumaran"^^schema:Person,
        "Fabio Viola"^^schema:Person,
        "Hubert Soyer"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Laurent Sifre"^^schema:Person,
        "Misha Denil"^^schema:Person,
        "Piotr Mirowski"^^schema:Person,
        "Raia Hadsell"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Ross Goroshin"^^schema:Person ;
    schema:commentCount "411"^^schema:Integer ;
    schema:dateModified "2017-01-13T11:15:22Z"^^schema:DateTime ;
    schema:datePublished "2016-11-11T12:14:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Learning to Navigate in Complex Environments"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.03673v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17642659027854201917&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<527> a schema:ScholarlyArticle ;
    schema:abstract "Attention plays a critical role in human visual experience. Furthermore, ithas recently been demonstrated that attention can also play an important rolein the context of applying artificial neural networks to a variety of tasksfrom fields such as computer vision and NLP. In this work we show that, byproperly defining attention for convolutional neural networks, we can actuallyuse this type of information in order to significantly improve the performanceof a student CNN network by forcing it to mimic the attention maps of apowerful teacher network. To that end, we propose several novel methods oftransferring attention, showing consistent improvement across a variety ofdatasets and convolutional neural network architectures. Code and models forour experiments are available athttps://github.com/szagoruyko/attention-transfer"^^schema:Text ;
    schema:author "Nikos Komodakis"^^schema:Person,
        "Sergey Zagoruyko"^^schema:Person ;
    schema:commentCount "380"^^schema:Integer ;
    schema:dateModified "2017-02-12T22:05:47Z"^^schema:DateTime ;
    schema:datePublished "2016-12-12T21:15:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Paying More Attention to Attention: Improving the Performance of  Convolutional Neural Networks via Attention Transfer"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.03928v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8439472615885524081&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<528> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional Neural Networks (ConvNets) are commonly developed at a fixedresource budget, and then scaled up for better accuracy if more resources areavailable. In this paper, we systematically study model scaling and identifythat carefully balancing network depth, width, and resolution can lead tobetter performance. Based on this observation, we propose a new scaling methodthat uniformly scales all dimensions of depth/width/resolution using a simpleyet highly effective compound coefficient. We demonstrate the effectiveness ofthis method on scaling up MobileNets and ResNet.  To go even further, we use neural architecture search to design a newbaseline network and scale it up to obtain a family of models, calledEfficientNets, which achieve much better accuracy and efficiency than previousConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3%top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster oninference than the best existing ConvNet. Our EfficientNets also transfer welland achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%),and 3 other transfer learning datasets, with an order of magnitude fewerparameters. Source code is athttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet."^^schema:Text ;
    schema:author "Mingxing Tan"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "535"^^schema:Integer ;
    schema:dateModified "2020-09-11T05:08:01Z"^^schema:DateTime ;
    schema:datePublished "2019-05-28T17:05:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 6105-6114"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1905.11946v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5472015514843683656&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<529> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we develop a new framework that captures the common landscapeunderlying the common non-convex low-rank matrix problems including matrixsensing, matrix completion and robust PCA. In particular, we show for all aboveproblems (including asymmetric cases): 1) all local minima are also globallyoptimal; 2) no high-order saddle points exists. These results explain whysimple algorithms such as stochastic gradient descent have global converge, andefficiently optimize these non-convex objective functions in practice. Ourframework connects and simplifies the existing analyses on optimizationlandscapes for matrix sensing and symmetric matrix completion. The frameworknaturally leads to new results for asymmetric matrix completion and robust PCA."^^schema:Text ;
    schema:author "Chi Jin"^^schema:Person,
        "Rong Ge"^^schema:Person,
        "Yi Zheng"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2017-04-03T17:49:02Z"^^schema:DateTime ;
    schema:datePublished "2017-04-03T17:49:02Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified  Geometric Analysis"^^schema:Text ;
    schema:publisher "ICML, 1233-1242"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1704.00708v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7908586163390330077&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<53> a schema:ScholarlyArticle ;
    schema:abstract "Training neural networks involves solving large-scale non-convex optimizationproblems. This task has long been believed to be extremely difficult, with fearof local minima and other obstacles motivating a variety of schemes to improveoptimization, such as unsupervised pretraining. However, modern neural networksare able to achieve negligible training error on complex tasks, using onlydirect training with stochastic gradient descent. We introduce a simpleanalysis technique to look for evidence that such networks are overcoming localoptima. We find that, in fact, on a straight path from initialization tosolution, a variety of state of the art neural networks never encounter anysignificant obstacles."^^schema:Text ;
    schema:author "Andrew M. Saxe"^^schema:Person,
        "Ian J. Goodfellow"^^schema:Person,
        "Oriol Vinyals"^^schema:Person ;
    schema:commentCount "261"^^schema:Integer ;
    schema:dateModified "2015-05-21T21:44:31Z"^^schema:DateTime ;
    schema:datePublished "2014-12-19T21:55:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Qualitatively characterizing neural network optimization problems"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6544v6"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11309177599523101036&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<530> a schema:ScholarlyArticle ;
    schema:abstract "We show that there are no spurious local minima in the non-convex factorizedparametrization of low-rank matrix recovery from incoherent linearmeasurements. With noisy measurements we show all local minima are very closeto a global optimum. Together with a curvature bound at saddle points, thisyields a polynomial time global convergence guarantee for stochastic gradientdescent {\\em from random initialization}."^^schema:Text ;
    schema:author "Behnam Neyshabur"^^schema:Person,
        "Nathan Srebro"^^schema:Person,
        "Srinadh Bhojanapalli"^^schema:Person ;
    schema:commentCount "248"^^schema:Integer ;
    schema:dateModified "2016-05-27T00:54:17Z"^^schema:DateTime ;
    schema:datePublished "2016-05-23T22:05:42Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Global Optimality of Local Search for Low Rank Matrix Recovery"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07221v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13377495735395555335&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<531> a schema:ScholarlyArticle ;
    schema:abstract "We combine supervised learning with unsupervised learning in deep neuralnetworks. The proposed model is trained to simultaneously minimize the sum ofsupervised and unsupervised cost functions by backpropagation, avoiding theneed for layer-wise pre-training. Our work builds on the Ladder networkproposed by Valpola (2015), which we extend by combining the model withsupervision. We show that the resulting model reaches state-of-the-artperformance in semi-supervised MNIST and CIFAR-10 classification, in additionto permutation-invariant MNIST classification with all labels."^^schema:Text ;
    schema:author "Antti Rasmus"^^schema:Person,
        "Harri Valpola"^^schema:Person,
        "Mathias Berglund"^^schema:Person,
        "Mikko Honkala"^^schema:Person,
        "Tapani Raiko"^^schema:Person ;
    schema:commentCount "802"^^schema:Integer ;
    schema:dateModified "2015-11-24T09:22:23Z"^^schema:DateTime ;
    schema:datePublished "2015-07-09T19:52:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Semi-Supervised Learning with Ladder Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.02672v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8134619000009445277&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<532> a schema:ScholarlyArticle ;
    schema:abstract "Modeling the distribution of natural images is a landmark problem inunsupervised learning. This task requires an image model that is at onceexpressive, tractable and scalable. We present a deep neural network thatsequentially predicts the pixels in an image along the two spatial dimensions.Our method models the discrete probability of the raw pixel values and encodesthe complete set of dependencies in the image. Architectural novelties includefast two-dimensional recurrent layers and an effective use of residualconnections in deep recurrent networks. We achieve log-likelihood scores onnatural images that are considerably better than the previous state of the art.Our main results also provide benchmarks on the diverse ImageNet dataset.Samples generated from the model appear crisp, varied and globally coherent."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person ;
    schema:commentCount "1098"^^schema:Integer ;
    schema:dateModified "2016-08-19T14:10:16Z"^^schema:DateTime ;
    schema:datePublished "2016-01-25T20:34:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Pixel Recurrent Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 1747-1756"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1601.06759v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13078391055138994928&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<533> a schema:ScholarlyArticle ;
    schema:abstract "Layer-sequential unit-variance (LSUV) initialization - a simple method forweight initialization for deep net learning - is proposed. The method consistsof the two steps. First, pre-initialize weights of each convolution orinner-product layer with orthonormal matrices. Second, proceed from the firstto the final layer, normalizing the variance of the output of each layer to beequal to one.  Experiment with different activation functions (maxout, ReLU-family, tanh)show that the proposed initialization leads to learning of very deep nets that(i) produces networks with test accuracy better or equal to standard methodsand (ii) is at least as fast as the complex schemes proposed specifically forvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastavaet al. (2015)).  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual netsand the state-of-the-art, or very close to it, is achieved on the MNIST,CIFAR-10/100 and ImageNet datasets."^^schema:Text ;
    schema:author "Dmytro Mishkin"^^schema:Person,
        "Jiri Matas"^^schema:Person ;
    schema:commentCount "373"^^schema:Integer ;
    schema:dateModified "2016-02-19T14:37:10Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T22:19:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "All you need is a good init"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06422v7"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6062006264661009371&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<534> a schema:ScholarlyArticle ;
    schema:abstract "We consider learning representations of entities and relations in KBs usingthe neural-embedding approach. We show that most existing models, including NTN(Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalizedunder a unified learning framework, where entities are low-dimensional vectorslearned from a neural network and relations are bilinear and/or linear mappingfunctions. Under this framework, we compare a variety of embedding models onthe link prediction task. We show that a simple bilinear formulation achievesnew state-of-the-art results for the task (achieving a top-10 accuracy of 73.2%vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approachthat utilizes the learned relation embeddings to mine logical rules such as\"BornInCity(a,b) and CityInCountry(b,c) =&gt; Nationality(a,c)\". We find thatembeddings learned from the bilinear objective are particularly good atcapturing relational semantics and that the composition of relations ischaracterized by matrix multiplication. More interestingly, we demonstrate thatour embedding-based rule extraction approach successfully outperforms astate-of-the-art confidence-based rule mining approach in mining Horn rulesthat involve compositional reasoning."^^schema:Text ;
    schema:author "Bishan Yang"^^schema:Person,
        "Jianfeng Gao"^^schema:Person,
        "Li Deng"^^schema:Person,
        "Wen-tau Yih"^^schema:Person,
        "Xiaodong He"^^schema:Person ;
    schema:commentCount "669"^^schema:Integer ;
    schema:dateModified "2015-08-29T15:08:45Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T01:37:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Embedding Entities and Relations for Learning and Inference in Knowledge  Bases"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6575v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14658345583368412090&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<535> a schema:ScholarlyArticle ;
    schema:abstract "The interpretation of deep learning models is a challenge due to their size,complexity, and often opaque internal state. In addition, many systems, such asimage classifiers, operate on low-level features rather than high-levelconcepts. To address these challenges, we introduce Concept Activation Vectors(CAVs), which provide an interpretation of a neural net's internal state interms of human-friendly concepts. The key idea is to view the high-dimensionalinternal state of a neural net as an aid, not an obstacle. We show how to useCAVs as part of a technique, Testing with CAVs (TCAV), that uses directionalderivatives to quantify the degree to which a user-defined concept is importantto a classification result--for example, how sensitive a prediction of \"zebra\"is to the presence of stripes. Using the domain of image classification as atesting ground, we describe how CAVs may be used to explore hypotheses andgenerate insights for a standard image classification network as well as amedical application."^^schema:Text ;
    schema:author "Been Kim"^^schema:Person,
        "Carrie Cai"^^schema:Person,
        "Fernanda Viegas"^^schema:Person,
        "James Wexler"^^schema:Person,
        "Justin Gilmer"^^schema:Person,
        "Martin Wattenberg"^^schema:Person,
        "Rory Sayres"^^schema:Person ;
    schema:commentCount "189"^^schema:Integer ;
    schema:dateModified "2018-06-07T04:33:27Z"^^schema:DateTime ;
    schema:datePublished "2017-11-30T09:26:12Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Interpretability Beyond Feature Attribution: Quantitative Testing with  Concept Activation Vectors (TCAV)"^^schema:Text ;
    schema:publisher "ICML, 2673-2682"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.11279v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9394087570430993813&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<536> a schema:ScholarlyArticle ;
    schema:abstract "Salient object detection increasingly receives attention as an importantcomponent or step in several pattern recognition and image processing tasks.Although a variety of powerful saliency models have been intensively proposed,they usually involve heavy feature (or model) engineering based on priors (orassumptions) about the properties of objects and backgrounds. Inspired by theeffectiveness of recently developed feature learning, we provide a novel DeepImage Saliency Computing (DISC) framework for fine-grained image saliencycomputing. In particular, we model the image saliency from both the coarse- andfine-level observations, and utilize the deep convolutional neural network(CNN) to learn the saliency representation in a progressive manner.Specifically, our saliency model is built upon two stacked CNNs. The first CNNgenerates a coarse-level saliency map by taking the overall image as the input,roughly identifying saliency regions in the global context. Furthermore, weintegrate superpixel-based local context information in the first CNN to refinethe coarse-level saliency map. Guided by the coarse saliency map, the secondCNN focuses on the local context to produce fine-grained and accurate saliencymap while preserving object details. For a testing image, the two CNNscollaboratively conduct the saliency computing in one shot. Our DISC frameworkis capable of uniformly highlighting the objects-of-interest from complexbackground while preserving well object details. Extensive experiments onseveral standard benchmarks suggest that DISC outperforms otherstate-of-the-art methods and it also generalizes well across datasets withoutadditional training. The executable version of DISC is available online:http://vision.sysu.edu.cn/projects/DISC."^^schema:Text ;
    schema:author "Liang Lin"^^schema:Person,
        "Lingbo Liu"^^schema:Person,
        "Tianshui Chen"^^schema:Person,
        "Xiaonan Luo"^^schema:Person,
        "Xuelong Li"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:dateModified "2015-12-10T13:11:23Z"^^schema:DateTime ;
    schema:datePublished "2015-11-13T07:14:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "DISC: Deep Image Saliency Computing via Progressive Representation  Learning"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 27 (6), 1135-1149"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.04192v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9085929998973538234&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<537> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks excel in regimes with large amounts of data, but tend tostruggle when data is scarce or when they need to adapt quickly to changes inthe task. In response, recent work in meta-learning proposes training ameta-learner on a distribution of similar tasks, in the hopes of generalizationto novel but related tasks by learning a high-level strategy that captures theessence of the problem it is asked to solve. However, many recent meta-learningapproaches are extensively hand-designed, either using architecturesspecialized to a particular application, or hard-coding algorithmic componentsthat constrain how the meta-learner solves the task. We propose a class ofsimple and generic meta-learner architectures that use a novel combination oftemporal convolutions and soft attention; the former to aggregate informationfrom past experience and the latter to pinpoint specific pieces of information.In the most extensive set of meta-learning experiments to date, we evaluate theresulting Simple Neural AttentIve Learner (or SNAIL) on severalheavily-benchmarked tasks. On all tasks, in both supervised and reinforcementlearning, SNAIL attains state-of-the-art performance by significant margins."^^schema:Text ;
    schema:author "Mostafa Rohaninejad"^^schema:Person,
        "Nikhil Mishra"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Xi Chen"^^schema:Person ;
    schema:commentCount "345"^^schema:Integer ;
    schema:dateModified "2018-02-25T04:55:20Z"^^schema:DateTime ;
    schema:datePublished "2017-07-11T06:21:31Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Simple Neural Attentive Meta-Learner"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.03141v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13155723657744889520&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<538> a schema:ScholarlyArticle ;
    schema:abstract "The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularitythanks in particular to its ability to nicely handle the structured constraintsappearing in machine learning applications. However, its convergence rate isknown to be slow (sublinear) when the solution lies at the boundary. A simpleless-known fix is to add the possibility to take 'away steps' duringoptimization, an operation that importantly does not require a feasibilityoracle. In this paper, we highlight and clarify several variants of theFrank-Wolfe optimization algorithm that have been successfully applied inpractice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimumnorm point algorithm, and prove for the first time that they all enjoy globallinear convergence, under a weaker condition than strong convexity of theobjective. The constant in the convergence rate has an elegant interpretationas the product of the (classical) condition number of the function with a novelgeometric quantity that plays the role of a 'condition number' of theconstraint set. We provide pointers to where these algorithms have made adifference in practice, in particular with the flow polytope, the marginalpolytope and the base polytope for submodular optimization."^^schema:Text ;
    schema:author "Martin Jaggi"^^schema:Person,
        "Simon Lacoste-Julien"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2015-11-18T20:24:43Z"^^schema:DateTime ;
    schema:datePublished "2015-11-18T20:24:43Z"^^schema:DateTime ;
    schema:genre "90C52, 90C90, 68T05"^^schema:Text,
        "G.1.6; I.2.6"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Global Linear Convergence of Frank-Wolfe Optimization Variants"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05932v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9906218516207641081&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<539> a schema:ScholarlyArticle ;
    schema:abstract "For most deep learning algorithms training is notoriously time consuming.Since most of the computation in training neural networks is typically spent onfloating point multiplications, we investigate an approach to training thateliminates the need for most of these. Our method consists of two parts: Firstwe stochastically binarize weights to convert multiplications involved incomputing hidden states to sign changes. Second, while back-propagating errorderivatives, in addition to binarizing the weights, we quantize therepresentations at each layer to convert the remaining multiplications intobinary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10,SVHN) show that this approach not only does not hurt classification performancebut can result in even better performance than standard stochastic gradientdescent training, paving the way to fast, hardware-friendly training of neuralnetworks."^^schema:Text ;
    schema:author "Matthieu Courbariaux"^^schema:Person,
        "Roland Memisevic"^^schema:Person,
        "Yoshua Bengio"^^schema:Person,
        "Zhouhan Lin"^^schema:Person ;
    schema:commentCount "239"^^schema:Integer ;
    schema:dateModified "2016-02-26T05:24:30Z"^^schema:DateTime ;
    schema:datePublished "2015-10-11T04:32:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural Networks with Few Multiplications"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1510.03009v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6931378573591664631&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<54> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of transferring a sample in one domain to an analogsample in another domain. Given two related domains, S and T, we would like tolearn a generative function G that maps an input sample from S to the domain T,such that the output of a given function f, which accepts inputs in eitherdomains, would remain unchanged. Other than the function f, the training datais unsupervised and consist of a set of samples from each domain. The DomainTransfer Network (DTN) we present employs a compound loss function thatincludes a multiclass GAN loss, an f-constancy component, and a regularizingcomponent that encourages G to map samples from T to themselves. We apply ourmethod to visual domains including digits and face images and demonstrate itsability to generate convincing novel images of previously unseen entities,while preserving their identity."^^schema:Text ;
    schema:author "Adam Polyak"^^schema:Person,
        "Lior Wolf"^^schema:Person,
        "Yaniv Taigman"^^schema:Person ;
    schema:commentCount "554"^^schema:Integer ;
    schema:dateModified "2016-11-07T18:14:57Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T18:14:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Cross-Domain Image Generation"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02200v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1045007962742744076&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<540> a schema:ScholarlyArticle ;
    schema:abstract "This paper introduces Grid Long Short-Term Memory, a network of LSTM cellsarranged in a multidimensional grid that can be applied to vectors, sequencesor higher dimensional data such as images. The network differs from existingdeep LSTM architectures in that the cells are connected between network layersas well as along the spatiotemporal dimensions of the data. The networkprovides a unified way of using LSTM for both deep and sequential computation.We apply the model to algorithmic tasks such as 15-digit integer addition andsequence memorization, where it is able to significantly outperform thestandard LSTM. We then give results for two empirical tasks. We find that 2DGrid LSTM achieves 1.47 bits per character on the Wikipedia characterprediction benchmark, which is state-of-the-art among neural approaches. Inaddition, we use the Grid LSTM to define a novel two-dimensional translationmodel, the Reencoder, and show that it outperforms a phrase-based referencesystem on a Chinese-to-English translation task."^^schema:Text ;
    schema:author "Alex Graves"^^schema:Person,
        "Ivo Danihelka"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person ;
    schema:commentCount "278"^^schema:Integer ;
    schema:dateModified "2016-01-07T18:39:48Z"^^schema:DateTime ;
    schema:datePublished "2015-07-06T16:30:05Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Grid Long Short-Term Memory"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.01526v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14303206616495742373&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<541> a schema:ScholarlyArticle ;
    schema:abstract "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neuralnetwork architecture for image generation. DRAW networks combine a novelspatial attention mechanism that mimics the foveation of the human eye, with asequential variational auto-encoding framework that allows for the iterativeconstruction of complex images. The system substantially improves on the stateof the art for generative models on MNIST, and, when trained on the Street ViewHouse Numbers dataset, it generates images that cannot be distinguished fromreal data with the naked eye."^^schema:Text ;
    schema:author "Alex Graves"^^schema:Person,
        "Daan Wierstra"^^schema:Person,
        "Danilo Jimenez Rezende"^^schema:Person,
        "Ivo Danihelka"^^schema:Person,
        "Karol Gregor"^^schema:Person ;
    schema:commentCount "1363"^^schema:Integer ;
    schema:dateModified "2015-05-20T15:29:42Z"^^schema:DateTime ;
    schema:datePublished "2015-02-16T16:48:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "DRAW: A Recurrent Neural Network For Image Generation"^^schema:Text ;
    schema:publisher "ICML, 1462-1471"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.04623v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8022513888710268841&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<542> a schema:ScholarlyArticle ;
    schema:abstract "The Generative Adversarial Network (GAN) has achieved great success ingenerating realistic (real-valued) synthetic data. However, convergence issuesand difficulties dealing with discrete data hinder the applicability of GAN totext. We propose a framework for generating realistic text via adversarialtraining. We employ a long short-term memory network as generator, and aconvolutional network as discriminator. Instead of using the standard objectiveof GAN, we propose matching the high-dimensional latent feature distributionsof real and synthetic sentences, via a kernelized discrepancy metric. Thiseases adversarial training by alleviating the mode-collapsing problem. Ourexperiments show superior performance in quantitative evaluation, anddemonstrate that our model can generate realistic-looking sentences."^^schema:Text ;
    schema:author "Dinghan Shen"^^schema:Person,
        "Kai Fan"^^schema:Person,
        "Lawrence Carin"^^schema:Person,
        "Ricardo Henao"^^schema:Person,
        "Yizhe Zhang"^^schema:Person,
        "Zhe Gan"^^schema:Person,
        "Zhi Chen"^^schema:Person ;
    schema:commentCount "176"^^schema:Integer ;
    schema:dateModified "2017-11-18T18:40:04Z"^^schema:DateTime ;
    schema:datePublished "2017-06-12T20:55:51Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarial Feature Matching for Text Generation"^^schema:Text ;
    schema:publisher "ICML, 4006-4015"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.03850v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11561684801033759674&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<543> a schema:ScholarlyArticle ;
    schema:abstract "The goal of compressed sensing is to estimate a vector from anunderdetermined system of noisy linear measurements, by making use of priorknowledge on the structure of vectors in the relevant domain. For almost allresults in this literature, the structure is represented by sparsity in awell-chosen basis. We show how to achieve guarantees similar to standardcompressed sensing but without employing sparsity at all. Instead, we supposethat vectors lie near the range of a generative model $G: \\mathbb{R}^k \\to\\mathbb{R}^n$. Our main theorem is that, if $G$ is $L$-Lipschitz, then roughly$O(k \\log L)$ random Gaussian measurements suffice for an $\\ell_2/\\ell_2$recovery guarantee. We demonstrate our results using generative models frompublished variational autoencoder and generative adversarial networks. Ourmethod can use $5$-$10$x fewer measurements than Lasso for the same accuracy."^^schema:Text ;
    schema:author "Ajil Jalal"^^schema:Person,
        "Alexandros G. Dimakis"^^schema:Person,
        "Ashish Bora"^^schema:Person,
        "Eric Price"^^schema:Person ;
    schema:commentCount "248"^^schema:Integer ;
    schema:dateModified "2017-03-09T10:11:03Z"^^schema:DateTime ;
    schema:datePublished "2017-03-09T10:11:03Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Compressed Sensing using Generative Models"^^schema:Text ;
    schema:publisher "ICML, 537-546"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.03208v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14786655061233662443&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<544> a schema:ScholarlyArticle ;
    schema:abstract "We propose the neural programmer-interpreter (NPI): a recurrent andcompositional neural network that learns to represent and execute programs. NPIhas three learnable components: a task-agnostic recurrent core, a persistentkey-value program memory, and domain-specific encoders that enable a single NPIto operate in multiple perceptually diverse environments with distinctaffordances. By learning to compose lower-level programs to expresshigher-level programs, NPI reduces sample complexity and increasesgeneralization ability compared to sequence-to-sequence LSTMs. The programmemory allows efficient learning of additional tasks by building on existingprograms. NPI can also harness the environment (e.g. a scratch pad withread-write pointers) to cache intermediate results of computation, lesseningthe long-term memory burden on recurrent hidden units. In this work we trainthe NPI with fully-supervised execution traces; each program has examplesequences of calls to the immediate subprograms conditioned on the input.Rather than training on a huge number of relatively weak labels, NPI learnsfrom a small number of rich examples. We demonstrate the capability of ourmodel to learn several types of compositional programs: addition, sorting, andcanonicalizing 3D models. Furthermore, a single NPI learns to execute theseprograms and all 21 associated subprograms."^^schema:Text ;
    schema:author "Nando de Freitas"^^schema:Person,
        "Scott Reed"^^schema:Person ;
    schema:commentCount "310"^^schema:Integer ;
    schema:dateModified "2016-02-29T11:12:36Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T17:49:32Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural Programmer-Interpreters"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06279v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14095885171607870380&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<545> a schema:ScholarlyArticle ;
    schema:abstract "While neural machine translation (NMT) is making good progress in the pasttwo years, tens of millions of bilingual sentence pairs are needed for itstraining. However, human labeling is very costly. To tackle this training databottleneck, we develop a dual-learning mechanism, which can enable an NMTsystem to automatically learn from unlabeled data through a dual-learning game.This mechanism is inspired by the following observation: any machinetranslation task has a dual task, e.g., English-to-French translation (primal)versus French-to-English translation (dual); the primal and dual tasks can forma closed loop, and generate informative feedback signals to train thetranslation models, even if without the involvement of a human labeler. In thedual-learning mechanism, we use one agent to represent the model for the primaltask and the other agent to represent the model for the dual task, then askthem to teach each other through a reinforcement learning process. Based on thefeedback signals generated during this process (e.g., the language-modellikelihood of the output of a model, and the reconstruction error of theoriginal sentence after the primal and dual translations), we can iterativelyupdate the two models until convergence (e.g., using the policy gradientmethods). We call the corresponding approach to neural machine translation\\emph{dual-NMT}. Experiments show that dual-NMT works very well onEnglish$\\leftrightarrow$French translation; especially, by learning frommonolingual data (with 10% bilingual data for warm start), it achieves acomparable accuracy to NMT trained from the full bilingual data for theFrench-to-English translation task."^^schema:Text ;
    schema:author "Di He"^^schema:Person,
        "Liwei Wang"^^schema:Person,
        "Nenghai Yu"^^schema:Person,
        "Tao Qin"^^schema:Person,
        "Tie-Yan Liu"^^schema:Person,
        "Wei-Ying Ma"^^schema:Person,
        "Yingce Xia"^^schema:Person ;
    schema:commentCount "355"^^schema:Integer ;
    schema:dateModified "2016-11-01T10:38:29Z"^^schema:DateTime ;
    schema:datePublished "2016-11-01T10:38:29Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Dual Learning for Machine Translation"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.00179v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15841765927830550600&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<546> a schema:ScholarlyArticle ;
    schema:abstract "Bayesian optimization is an effective methodology for the global optimizationof functions with expensive evaluations. It relies on querying a distributionover functions defined by a relatively cheap surrogate model. An accurate modelfor this distribution over functions is critical to the effectiveness of theapproach, and is typically fit using Gaussian processes (GPs). However, sinceGPs scale cubically with the number of observations, it has been challenging tohandle objectives whose optimization requires many evaluations, and as such,massively parallelizing the optimization.  In this work, we explore the use of neural networks as an alternative to GPsto model distributions over functions. We show that performing adaptive basisfunction regression with a neural network as the parametric form performscompetitively with state-of-the-art GP-based approaches, but scales linearlywith the number of data rather than cubically. This allows us to achieve apreviously intractable degree of parallelism, which we apply to large scalehyperparameter optimization, rapidly finding competitive models on benchmarkobject recognition tasks using convolutional networks, and image captiongeneration using neural language models."^^schema:Text ;
    schema:author "Jasper Snoek"^^schema:Person,
        "Kevin Swersky"^^schema:Person,
        "Md. Mostofa Ali Patwary"^^schema:Person,
        "Nadathur Satish"^^schema:Person,
        "Narayanan Sundaram"^^schema:Person,
        "Oren Rippel"^^schema:Person,
        "Prabhat"^^schema:Person,
        "Ryan Kiros"^^schema:Person,
        "Ryan P. Adams"^^schema:Person ;
    schema:commentCount "444"^^schema:Integer ;
    schema:dateModified "2015-07-13T15:47:13Z"^^schema:DateTime ;
    schema:datePublished "2015-02-19T20:51:27Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Scalable Bayesian Optimization Using Deep Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 2171-2180"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.05700v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7151760993960049125&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<547> a schema:ScholarlyArticle ;
    schema:abstract "Linguistic sequence labeling is a general modeling approach that encompassesa variety of problems, such as part-of-speech tagging and named entityrecognition. Recent advances in neural networks (NNs) make it possible to buildreliable models without handcrafted features. However, in many cases, it ishard to obtain sufficient annotations to train these models. In this study, wedevelop a novel neural framework to extract abundant knowledge hidden in rawtexts to empower the sequence labeling task. Besides word-level knowledgecontained in pre-trained word embeddings, character-aware neural languagemodels are incorporated to extract character-level knowledge. Transfer learningtechniques are further adopted to mediate different components and guide thelanguage model towards the key knowledge. Comparing to previous methods, thesetask-specific knowledge allows us to adopt a more concise model and conductmore efficient training. Different from most transfer learning methods, theproposed framework does not rely on any additional supervision. It extractsknowledge from self-contained order information of training sequences.Extensive experiments on benchmark datasets demonstrate the effectiveness ofleveraging character-level knowledge and the efficiency of co-training. Forexample, on the CoNLL03 NER task, model training completes in about 6 hours ona single GPU, reaching F1 score of 91.71$\\pm$0.10 without using any extraannotation."^^schema:Text ;
    schema:author "Frank F. Xu"^^schema:Person,
        "Huan Gui"^^schema:Person,
        "Jian Peng"^^schema:Person,
        "Jiawei Han"^^schema:Person,
        "Jingbo Shang"^^schema:Person,
        "Liyuan Liu"^^schema:Person,
        "Xiang Ren"^^schema:Person ;
    schema:commentCount "163"^^schema:Integer ;
    schema:dateModified "2017-11-23T23:12:40Z"^^schema:DateTime ;
    schema:datePublished "2017-09-13T02:13:25Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Empower Sequence Labeling with Task-Aware Neural Language Model"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.04109v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16154865990911474666&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<548> a schema:ScholarlyArticle ;
    schema:abstract "Graph-structured data appears frequently in domains including chemistry,natural language semantics, social networks, and knowledge bases. In this work,we study feature learning techniques for graph-structured inputs. Our startingpoint is previous work on Graph Neural Networks (Scarselli et al., 2009), whichwe modify to use gated recurrent units and modern optimization techniques andthen extend to output sequences. The result is a flexible and broadly usefulclass of neural network models that has favorable inductive biases relative topurely sequence-based models (e.g., LSTMs) when the problem isgraph-structured. We demonstrate the capabilities on some simple AI (bAbI) andgraph algorithm learning tasks. We then show it achieves state-of-the-artperformance on a problem from program verification, in which subgraphs need tobe matched to abstract data structures."^^schema:Text ;
    schema:author "Daniel Tarlow"^^schema:Person,
        "Marc Brockschmidt"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Yujia Li"^^schema:Person ;
    schema:commentCount "945"^^schema:Integer ;
    schema:dateModified "2017-09-22T21:36:00Z"^^schema:DateTime ;
    schema:datePublished "2015-11-17T18:10:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gated Graph Sequence Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05493v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16266567510296342081&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<549> a schema:ScholarlyArticle ;
    schema:abstract "Most learning approaches treat dimensionality reduction (DR) and clusteringseparately (i.e., sequentially), but recent research has shown that optimizingthe two tasks jointly can substantially improve the performance of both. Thepremise behind the latter genre is that the data samples are obtained vialinear transformation of latent representations that are easy to cluster; butin practice, the transformation from the latent space to the data can be morecomplicated. In this work, we assume that this transformation is an unknown andpossibly nonlinear function. To recover the `clustering-friendly' latentrepresentations and to better cluster the data, we propose a joint DR andK-means clustering approach in which DR is accomplished via learning a deepneural network (DNN). The motivation is to keep the advantages of jointlyoptimizing the two tasks, while exploiting the deep neural network's ability toapproximate any nonlinear function. This way, the proposed approach can workwell for a broad class of generative models. Towards this end, we carefullydesign the DNN structure and the associated joint optimization criterion, andpropose an effective and scalable algorithm to handle the formulatedoptimization problem. Experiments using different real datasets are employed toshowcase the effectiveness of the proposed approach."^^schema:Text ;
    schema:author "Bo Yang"^^schema:Person,
        "Mingyi Hong"^^schema:Person,
        "Nicholas D. Sidiropoulos"^^schema:Person,
        "Xiao Fu"^^schema:Person ;
    schema:commentCount "220"^^schema:Integer ;
    schema:dateModified "2017-06-13T22:40:26Z"^^schema:DateTime ;
    schema:datePublished "2016-10-15T22:51:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Towards K-means-friendly Spaces: Simultaneous Deep Learning and  Clustering"^^schema:Text ;
    schema:publisher "ICML, 3861-3870"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.04794v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6015973098028169119&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<55> a schema:ScholarlyArticle ;
    schema:abstract "Multiple instance learning (MIL) is a variation of supervised learning wherea single class label is assigned to a bag of instances. In this paper, we statethe MIL problem as learning the Bernoulli distribution of the bag label wherethe bag label probability is fully parameterized by neural networks.Furthermore, we propose a neural network-based permutation-invariantaggregation operator that corresponds to the attention mechanism. Notably, anapplication of the proposed attention-based operator provides insight into thecontribution of each instance to the bag label. We show empirically that ourapproach achieves comparable performance to the best MIL methods on benchmarkMIL datasets and it outperforms other methods on a MNIST-based MIL dataset andtwo real-life histopathology datasets without sacrificing interpretability."^^schema:Text ;
    schema:author "Jakub M. Tomczak"^^schema:Person,
        "Max Welling"^^schema:Person,
        "Maximilian Ilse"^^schema:Person ;
    schema:commentCount "175"^^schema:Integer ;
    schema:dateModified "2018-06-28T13:33:03Z"^^schema:DateTime ;
    schema:datePublished "2018-02-13T16:27:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Attention-based Deep Multiple Instance Learning"^^schema:Text ;
    schema:publisher "ICML, 2132-2141"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.04712v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10689360653942822671&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<550> a schema:ScholarlyArticle ;
    schema:abstract "Deep Neural Networks (DNN) have achieved state-of-the-art results in a widerange of tasks, with the best results obtained with large training sets andlarge models. In the past, GPUs enabled these breakthroughs because of theirgreater computational speed. In the future, faster computation at both trainingand test time is likely to be crucial for further progress and for consumerapplications on low-power devices. As a result, there is much interest inresearch and development of dedicated hardware for Deep Learning (DL). Binaryweights, i.e., weights which are constrained to only two possible values (e.g.-1 or 1), would bring great benefits to specialized DL hardware by replacingmany multiply-accumulate operations by simple accumulations, as multipliers arethe most space and power-hungry components of the digital implementation ofneural networks. We introduce BinaryConnect, a method which consists intraining a DNN with binary weights during the forward and backwardpropagations, while retaining precision of the stored weights in whichgradients are accumulated. Like other dropout schemes, we show thatBinaryConnect acts as regularizer and we obtain near state-of-the-art resultswith BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."^^schema:Text ;
    schema:author "Jean-Pierre David"^^schema:Person,
        "Matthieu Courbariaux"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "1466"^^schema:Integer ;
    schema:dateModified "2016-04-18T13:11:45Z"^^schema:DateTime ;
    schema:datePublished "2015-11-02T02:50:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "BinaryConnect: Training Deep Neural Networks with binary weights during  propagations"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.00363v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9513509971843797855&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<551> a schema:ScholarlyArticle ;
    schema:abstract "Many real-world tasks involve multiple agents with partial observability andlimited communication. Learning is challenging in these settings due to localviewpoints of agents, which perceive the world as non-stationary due toconcurrently-exploring teammates. Approaches that learn specialized policiesfor individual tasks face problems when applied to the real world: not only doagents have to learn and store distinct policies for each task, but in practiceidentities of tasks are often non-observable, making these approachesinapplicable. This paper formalizes and addresses the problem of multi-taskmulti-agent reinforcement learning under partial observability. We introduce adecentralized single-task learning approach that is robust to concurrentinteractions of teammates, and present an approach for distilling single-taskpolicies into a unified policy that performs well across multiple relatedtasks, without explicit provision of task identity."^^schema:Text ;
    schema:author "Christopher Amato"^^schema:Person,
        "Jason Pazis"^^schema:Person,
        "John Vian"^^schema:Person,
        "Jonathan P. How"^^schema:Person,
        "Shayegan Omidshafiei"^^schema:Person ;
    schema:commentCount "186"^^schema:Integer ;
    schema:dateModified "2017-07-13T17:34:34Z"^^schema:DateTime ;
    schema:datePublished "2017-03-17T19:32:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under  Partial Observability"^^schema:Text ;
    schema:publisher "ICML, 2681-2690"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.06182v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14362474747446780618&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<552> a schema:ScholarlyArticle ;
    schema:abstract "We propose Efficient Neural Architecture Search (ENAS), a fast andinexpensive approach for automatic model design. In ENAS, a controller learnsto discover neural network architectures by searching for an optimal subgraphwithin a large computational graph. The controller is trained with policygradient to select a subgraph that maximizes the expected reward on thevalidation set. Meanwhile the model corresponding to the selected subgraph istrained to minimize a canonical cross entropy loss. Thanks to parameter sharingbetween child models, ENAS is fast: it delivers strong empirical performancesusing much fewer GPU-hours than all existing automatic model design approaches,and notably, 1000x less expensive than standard Neural Architecture Search. Onthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves atest perplexity of 55.8, establishing a new state-of-the-art among all methodswithout post-training processing. On the CIFAR-10 dataset, ENAS designs novelarchitectures that achieve a test error of 2.89%, which is on par with NASNet(Zoph et al., 2018), whose test error is 2.65%."^^schema:Text ;
    schema:author "Barret Zoph"^^schema:Person,
        "Hieu Pham"^^schema:Person,
        "Jeff Dean"^^schema:Person,
        "Melody Y. Guan"^^schema:Person,
        "Quoc V. Le"^^schema:Person ;
    schema:commentCount "682"^^schema:Integer ;
    schema:dateModified "2018-02-12T03:34:00Z"^^schema:DateTime ;
    schema:datePublished "2018-02-09T14:14:37Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Efficient Neural Architecture Search via Parameter Sharing"^^schema:Text ;
    schema:publisher "ICML, 4092-4101"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.03268v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15692975197474124336&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<553> a schema:ScholarlyArticle ;
    schema:abstract "Representation learning has become an invaluable approach for learning fromsymbolic data such as text and graphs. However, while complex symbolic datasetsoften exhibit a latent hierarchical structure, state-of-the-art methodstypically learn embeddings in Euclidean vector spaces, which do not account forthis property. For this purpose, we introduce a new approach for learninghierarchical representations of symbolic data by embedding them into hyperbolicspace -- or more precisely into an n-dimensional Poincar\\'e ball. Due to theunderlying hyperbolic geometry, this allows us to learn parsimoniousrepresentations of symbolic data by simultaneously capturing hierarchy andsimilarity. We introduce an efficient algorithm to learn the embeddings basedon Riemannian optimization and show experimentally that Poincar\\'e embeddingsoutperform Euclidean embeddings significantly on data with latent hierarchies,both in terms of representation capacity and in terms of generalizationability."^^schema:Text ;
    schema:author "Douwe Kiela"^^schema:Person,
        "Maximilian Nickel"^^schema:Person ;
    schema:commentCount "343"^^schema:Integer ;
    schema:dateModified "2017-05-26T17:40:55Z"^^schema:DateTime ;
    schema:datePublished "2017-05-22T23:14:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Poincaré Embeddings for Learning Hierarchical Representations"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.08039v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6233393442090324202&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<554> a schema:ScholarlyArticle ;
    schema:abstract "We propose a conceptually simple and lightweight framework for deepreinforcement learning that uses asynchronous gradient descent for optimizationof deep neural network controllers. We present asynchronous variants of fourstandard reinforcement learning algorithms and show that parallelactor-learners have a stabilizing effect on training allowing all four methodsto successfully train neural network controllers. The best performing method,an asynchronous variant of actor-critic, surpasses the current state-of-the-arton the Atari domain while training for half the time on a single multi-core CPUinstead of a GPU. Furthermore, we show that asynchronous actor-critic succeedson a wide variety of continuous motor control problems as well as on a new taskof navigating random 3D mazes using a visual input."^^schema:Text ;
    schema:author "Adrià Puigdomènech Badia"^^schema:Person,
        "Alex Graves"^^schema:Person,
        "David Silver"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Mehdi Mirza"^^schema:Person,
        "Tim Harley"^^schema:Person,
        "Timothy P. Lillicrap"^^schema:Person,
        "Volodymyr Mnih"^^schema:Person ;
    schema:commentCount "3403"^^schema:Integer ;
    schema:dateModified "2016-06-16T16:38:45Z"^^schema:DateTime ;
    schema:datePublished "2016-02-04T18:38:41Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Asynchronous Methods for Deep Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 1928-1937"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.01783v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14460380466928185185&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<555> a schema:ScholarlyArticle ;
    schema:abstract "Clustering is central to many data-driven application domains and has beenstudied extensively in terms of distance functions and grouping algorithms.Relatively little work has focused on learning representations for clustering.In this paper, we propose Deep Embedded Clustering (DEC), a method thatsimultaneously learns feature representations and cluster assignments usingdeep neural networks. DEC learns a mapping from the data space to alower-dimensional feature space in which it iteratively optimizes a clusteringobjective. Our experimental evaluations on image and text corpora showsignificant improvement over state-of-the-art methods."^^schema:Text ;
    schema:author "Ali Farhadi"^^schema:Person,
        "Junyuan Xie"^^schema:Person,
        "Ross Girshick"^^schema:Person ;
    schema:commentCount "712"^^schema:Integer ;
    schema:dateModified "2016-05-24T22:27:35Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T20:06:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Deep Embedding for Clustering Analysis"^^schema:Text ;
    schema:publisher "ICML, 478-487"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06335v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18273828742645455219&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<556> a schema:ScholarlyArticle ;
    schema:abstract "In this work we introduce malware detection from raw byte sequences as afruitful research area to the larger machine learning community. Building aneural network for such a problem presents a number of interesting challengesthat have not occurred in tasks such as image processing or NLP. In particular,we note that detection from raw bytes presents a sequence problem with over twomillion time steps and a problem where batch normalization appear to hinder thelearning process. We present our initial work in building a solution to tacklethis problem, which has linear complexity dependence on the sequence length,and allows for interpretable sub-regions of the binary to be identified. Indoing so we will discuss the many challenges in building a neural network toprocess data at this scale, and the methods we used to work around them."^^schema:Text ;
    schema:author "Bryan Catanzaro"^^schema:Person,
        "Charles Nicholas"^^schema:Person,
        "Edward Raff"^^schema:Person,
        "Jared Sylvester"^^schema:Person,
        "Jon Barker"^^schema:Person,
        "Robert Brandon"^^schema:Person ;
    schema:commentCount "132"^^schema:Integer ;
    schema:dateModified "2017-10-25T19:48:54Z"^^schema:DateTime ;
    schema:datePublished "2017-10-25T19:48:54Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Malware Detection by Eating a Whole EXE"^^schema:Text ;
    schema:publisher "AAAI Workshops, 268-276"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.09435v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3220751781952104973&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<557> a schema:ScholarlyArticle ;
    schema:abstract "Dealing with sparse rewards is one of the biggest challenges in ReinforcementLearning (RL). We present a novel technique called Hindsight Experience Replaywhich allows sample-efficient learning from rewards which are sparse and binaryand therefore avoid the need for complicated reward engineering. It can becombined with an arbitrary off-policy RL algorithm and may be seen as a form ofimplicit curriculum.  We demonstrate our approach on the task of manipulating objects with arobotic arm. In particular, we run experiments on three different tasks:pushing, sliding, and pick-and-place, in each case using only binary rewardsindicating whether or not the task is completed. Our ablation studies show thatHindsight Experience Replay is a crucial ingredient which makes trainingpossible in these challenging environments. We show that our policies trainedon a physics simulation can be deployed on a physical robot and successfullycomplete the task."^^schema:Text ;
    schema:author "Alex Ray"^^schema:Person,
        "Bob McGrew"^^schema:Person,
        "Filip Wolski"^^schema:Person,
        "Jonas Schneider"^^schema:Person,
        "Josh Tobin"^^schema:Person,
        "Marcin Andrychowicz"^^schema:Person,
        "Peter Welinder"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Rachel Fong"^^schema:Person,
        "Wojciech Zaremba"^^schema:Person ;
    schema:commentCount "606"^^schema:Integer ;
    schema:dateModified "2018-02-23T10:04:20Z"^^schema:DateTime ;
    schema:datePublished "2017-07-05T17:55:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Hindsight Experience Replay"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.01495v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14733084267697271284&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<558> a schema:ScholarlyArticle ;
    schema:abstract "Neural network training relies on our ability to find \"good\" minimizers ofhighly non-convex loss functions. It is well-known that certain networkarchitecture designs (e.g., skip connections) produce loss functions that traineasier, and well-chosen training parameters (batch size, learning rate,optimizer) produce minimizers that generalize better. However, the reasons forthese differences, and their effects on the underlying loss landscape, are notwell understood. In this paper, we explore the structure of neural lossfunctions, and the effect of loss landscapes on generalization, using a rangeof visualization methods. First, we introduce a simple \"filter normalization\"method that helps us visualize loss function curvature and make meaningfulside-by-side comparisons between loss functions. Then, using a variety ofvisualizations, we explore how network architecture affects the loss landscape,and how training parameters affect the shape of minimizers."^^schema:Text ;
    schema:author "Christoph Studer"^^schema:Person,
        "Gavin Taylor"^^schema:Person,
        "Hao Li"^^schema:Person,
        "Tom Goldstein"^^schema:Person,
        "Zheng Xu"^^schema:Person ;
    schema:commentCount "343"^^schema:Integer ;
    schema:dateModified "2018-11-07T06:25:20Z"^^schema:DateTime ;
    schema:datePublished "2017-12-28T16:15:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Visualizing the Loss Landscape of Neural Nets"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.09913v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11650483902238288010&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<559> a schema:ScholarlyArticle ;
    schema:abstract "While deep learning has led to remarkable advances across diverseapplications, it struggles in domains where the data distribution changes overthe course of learning. In stark contrast, biological neural networkscontinually adapt to changing domains, possibly by leveraging complex molecularmachinery to solve many tasks simultaneously. In this study, we introduceintelligent synapses that bring some of this biological complexity intoartificial neural networks. Each synapse accumulates task relevant informationover time, and exploits this information to rapidly store new memories withoutforgetting old ones. We evaluate our approach on continual learning ofclassification tasks, and show that it dramatically reduces forgetting whilemaintaining computational efficiency."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "Friedemann Zenke"^^schema:Person,
        "Surya Ganguli"^^schema:Person ;
    schema:commentCount "380"^^schema:Integer ;
    schema:dateModified "2017-06-12T19:57:42Z"^^schema:DateTime ;
    schema:datePublished "2017-03-13T00:02:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.NC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continual Learning Through Synaptic Intelligence"^^schema:Text ;
    schema:publisher "ICML, 3987-3995"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.04200v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=13353907805622310554&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<56> a schema:ScholarlyArticle ;
    schema:abstract "Large multilayer neural networks trained with backpropagation have recentlyachieved state-of-the-art results in a wide range of problems. However, usingbackprop for neural net learning still has some disadvantages, e.g., having totune a large number of hyperparameters to the data, lack of calibratedprobabilistic predictions, and a tendency to overfit the training data. Inprinciple, the Bayesian approach to learning neural networks does not havethese problems. However, existing Bayesian techniques lack scalability to largedataset and network sizes. In this work we present a novel scalable method forlearning Bayesian neural networks, called probabilistic backpropagation (PBP).Similar to classical backpropagation, PBP works by computing a forwardpropagation of probabilities through the network and then doing a backwardcomputation of gradients. A series of experiments on ten real-world datasetsshow that PBP is significantly faster than other techniques, while offeringcompetitive predictive abilities. Our experiments also show that PBP providesaccurate estimates of the posterior variance on the network weights."^^schema:Text ;
    schema:author "José Miguel Hernández-Lobato"^^schema:Person,
        "Ryan P. Adams"^^schema:Person ;
    schema:commentCount "426"^^schema:Integer ;
    schema:dateModified "2015-07-15T10:14:49Z"^^schema:DateTime ;
    schema:datePublished "2015-02-18T18:45:17Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Probabilistic Backpropagation for Scalable Learning of Bayesian Neural  Networks"^^schema:Text ;
    schema:publisher "ICML, 1861-1869"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.05336v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7631378507206910182&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<560> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the adversarially learned inference (ALI) model, which jointlylearns a generation network and an inference network using an adversarialprocess. The generation network maps samples from stochastic latent variablesto the data space while the inference network maps training examples in dataspace to the space of latent variables. An adversarial game is cast betweenthese two networks and a discriminative network is trained to distinguishbetween joint latent/data-space samples from the generative network and jointsamples from the inference network. We illustrate the ability of the model tolearn mutually coherent inference and generation networks through theinspections of model samples and reconstructions and confirm the usefulness ofthe learned representations by obtaining a performance competitive withstate-of-the-art on the semi-supervised SVHN and CIFAR10 tasks."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Alex Lamb"^^schema:Person,
        "Ben Poole"^^schema:Person,
        "Ishmael Belghazi"^^schema:Person,
        "Martin Arjovsky"^^schema:Person,
        "Olivier Mastropietro"^^schema:Person,
        "Vincent Dumoulin"^^schema:Person ;
    schema:commentCount "769"^^schema:Integer ;
    schema:dateModified "2017-02-21T18:28:22Z"^^schema:DateTime ;
    schema:datePublished "2016-06-02T14:43:37Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adversarially Learned Inference"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.00704v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10451598130846693107&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<561> a schema:ScholarlyArticle ;
    schema:abstract "We consider approval-based committee voting, i.e. the setting where eachvoter approves a subset of candidates, and these votes are then used to selecta fixed-size set of winners (committee). We propose a natural axiom for thissetting, which we call justified representation (JR). This axiom requires thatif a large enough group of voters exhibits agreement by supporting the samecandidate, then at least one voter in this group has an approved candidate inthe winning committee. We show that for every list of ballots it is possible toselect a committee that provides JR. However, it turns out that severalprominent approval-based voting rules may fail to output such a committee. Inparticular, while Proportional Approval Voting (PAV) always outputs a committeethat provides JR, Reweighted Approval Voting (RAV), a tractable approximationto PAV, does not have this property. We then introduce a stronger version ofthe JR axiom, which we call extended justified representation (EJR), and showthat PAV satisfies EJR, while other rules we consider do not; indeed, EJR canbe used to characterize PAV within the class of weighted PAV rules. We alsoconsider several other questions related to JR and EJR, including therelationship between JR/EJR and core stability, and the complexity of theassociated algorithmic problems."^^schema:Text ;
    schema:author "Edith Elkind"^^schema:Person,
        "Haris Aziz"^^schema:Person,
        "Markus Brill"^^schema:Person,
        "Rupert Freeman"^^schema:Person,
        "Toby Walsh"^^schema:Person,
        "Vincent Conitzer"^^schema:Person ;
    schema:commentCount "159"^^schema:Integer ;
    schema:dateModified "2016-09-12T01:02:43Z"^^schema:DateTime ;
    schema:datePublished "2014-07-31T03:51:34Z"^^schema:DateTime ;
    schema:genre "91A12, 68Q15"^^schema:Text,
        "J.4; I.2.11; F.2"^^schema:Text,
        "cs.GT"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Justified Representation in Approval-Based Committee Voting"^^schema:Text ;
    schema:publisher "Twenty-Ninth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1407.8269v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9171385458786328885&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<562> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we introduce a generative parametric model capable of producinghigh quality samples of natural images. Our approach uses a cascade ofconvolutional networks within a Laplacian pyramid framework to generate imagesin a coarse-to-fine fashion. At each level of the pyramid, a separategenerative convnet model is trained using the Generative Adversarial Nets (GAN)approach (Goodfellow et al.). Samples drawn from our model are of significantlyhigher quality than alternate approaches. In a quantitative assessment by humanevaluators, our CIFAR10 samples were mistaken for real images around 40% of thetime, compared to 10% for samples drawn from a GAN baseline model. We also showsamples from models trained on the higher resolution images of the LSUN scenedataset."^^schema:Text ;
    schema:author "Arthur Szlam"^^schema:Person,
        "Emily Denton"^^schema:Person,
        "Rob Fergus"^^schema:Person,
        "Soumith Chintala"^^schema:Person ;
    schema:commentCount "1517"^^schema:Integer ;
    schema:dateModified "2015-06-18T17:03:54Z"^^schema:DateTime ;
    schema:datePublished "2015-06-18T17:03:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Generative Image Models using a Laplacian Pyramid of Adversarial  Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.05751v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8031319294003741632&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<563> a schema:ScholarlyArticle ;
    schema:abstract "We investigate an experiential learning paradigm for acquiring an internalmodel of intuitive physics. Our model is evaluated on a real-world roboticmanipulation task that requires displacing objects to target locations bypoking. The robot gathered over 400 hours of experience by executing more than100K pokes on different objects. We propose a novel approach based on deepneural networks for modeling the dynamics of robot's interactions directly fromimages, by jointly estimating forward and inverse models of dynamics. Theinverse model objective provides supervision to construct informative visualfeatures, which the forward model can then predict and in turn regularize thefeature space for the inverse model. The interplay between these two objectivescreates useful, accurate models that can then be used for multi-step decisionmaking. This formulation has the additional benefit that it is possible tolearn forward models in an abstract feature space and thus alleviate the needof predicting pixels. Our experiments show that this joint modeling approachoutperforms alternative methods."^^schema:Text ;
    schema:author "Ashvin Nair"^^schema:Person,
        "Jitendra Malik"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Pulkit Agrawal"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "291"^^schema:Integer ;
    schema:dateModified "2017-02-15T22:53:52Z"^^schema:DateTime ;
    schema:datePublished "2016-06-23T19:42:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Learning to Poke by Poking: Experiential Learning of Intuitive Physics"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.07419v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4353677612815002221&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<564> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning agents have achieved state-of-the-art results bydirectly maximising cumulative reward. However, environments contain a muchwider variety of possible training signals. In this paper, we introduce anagent that also maximises many other pseudo-reward functions simultaneously byreinforcement learning. All of these tasks share a common representation that,like unsupervised learning, continues to develop in the absence of extrinsicrewards. We also introduce a novel mechanism for focusing this representationupon extrinsic rewards, so that learning can rapidly adapt to the most relevantaspects of the actual task. Our agent significantly outperforms the previousstate-of-the-art on Atari, averaging 880\\% expert human performance, and achallenging suite of first-person, three-dimensional \\emph{Labyrinth} tasksleading to a mean speedup in learning of 10$\\times$ and averaging 87\\% experthuman performance on Labyrinth."^^schema:Text ;
    schema:author "David Silver"^^schema:Person,
        "Joel Z Leibo"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Max Jaderberg"^^schema:Person,
        "Tom Schaul"^^schema:Person,
        "Volodymyr Mnih"^^schema:Person,
        "Wojciech Marian Czarnecki"^^schema:Person ;
    schema:commentCount "563"^^schema:Integer ;
    schema:dateModified "2016-11-16T18:21:29Z"^^schema:DateTime ;
    schema:datePublished "2016-11-16T18:21:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Reinforcement Learning with Unsupervised Auxiliary Tasks"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.05397v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14888805482854497974&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<565> a schema:ScholarlyArticle ;
    schema:abstract "At present, designing convolutional neural network (CNN) architecturesrequires both human expertise and labor. New architectures are handcrafted bycareful experimentation or modified from a handful of existing networks. Weintroduce MetaQNN, a meta-modeling algorithm based on reinforcement learning toautomatically generate high-performing CNN architectures for a given learningtask. The learning agent is trained to sequentially choose CNN layers using$Q$-learning with an $\\epsilon$-greedy exploration strategy and experiencereplay. The agent explores a large but finite space of possible architecturesand iteratively discovers designs with improved performance on the learningtask. On image classification benchmarks, the agent-designed networks(consisting of only standard convolution, pooling, and fully-connected layers)beat existing networks designed with the same layer types and are competitiveagainst the state-of-the-art methods that use more complex layer types. We alsooutperform existing meta-modeling approaches for network design on imageclassification tasks."^^schema:Text ;
    schema:author "Bowen Baker"^^schema:Person,
        "Nikhil Naik"^^schema:Person,
        "Otkrist Gupta"^^schema:Person,
        "Ramesh Raskar"^^schema:Person ;
    schema:commentCount "562"^^schema:Integer ;
    schema:dateModified "2017-03-22T20:08:30Z"^^schema:DateTime ;
    schema:datePublished "2016-11-07T16:49:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Designing Neural Network Architectures using Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02167v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1457104897417222523&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<566> a schema:ScholarlyArticle ;
    schema:abstract "Representation learning seeks to expose certain aspects of observed data in alearned representation that's amenable to downstream tasks like classification.For instance, a good representation for 2D images might be one that describesonly global structure and discards information about detailed texture. In thispaper, we present a simple but principled method to learn such globalrepresentations by combining Variational Autoencoder (VAE) with neuralautoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAEmodel allows us to have control over what the global latent code can learn and, by designing the architecture accordingly, we can force the global latentcode to discard irrelevant information such as texture in 2D images, and hencethe VAE only \"autoencodes\" data in a lossy fashion. In addition, by leveragingautoregressive models as both prior distribution $p(z)$ and decodingdistribution $p(x|z)$, we can greatly improve generative modeling performanceof VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT andCaltech-101 Silhouettes density estimation tasks."^^schema:Text ;
    schema:author "Diederik P. Kingma"^^schema:Person,
        "Ilya Sutskever"^^schema:Person,
        "John Schulman"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Prafulla Dhariwal"^^schema:Person,
        "Tim Salimans"^^schema:Person,
        "Xi Chen"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "345"^^schema:Integer ;
    schema:dateModified "2017-03-04T06:19:22Z"^^schema:DateTime ;
    schema:datePublished "2016-11-08T21:43:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Lossy Autoencoder"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02731v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11833073722642726902&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<567> a schema:ScholarlyArticle ;
    schema:abstract "An intriguing property of deep neural networks is the existence ofadversarial examples, which can transfer among different architectures. Thesetransferable adversarial examples may severely hinder deep neural network-basedapplications. Previous works mostly study the transferability using small scaledatasets. In this work, we are the first to conduct an extensive study of thetransferability over large models and a large scale dataset, and we are alsothe first to study the transferability of targeted adversarial examples withtheir target labels. We study both non-targeted and targeted adversarialexamples, and show that while transferable non-targeted adversarial examplesare easy to find, targeted adversarial examples generated using existingapproaches almost never transfer with their target labels. Therefore, wepropose novel ensemble-based approaches to generating transferable adversarialexamples. Using such approaches, we observe a large proportion of targetedadversarial examples that are able to transfer with their target labels for thefirst time. We also present some geometric studies to help understanding thetransferable adversarial examples. Finally, we show that the adversarialexamples generated using ensemble-based approaches can successfully attackClarifai.com, which is a black-box image classification system."^^schema:Text ;
    schema:author "Chang Liu"^^schema:Person,
        "Dawn Song"^^schema:Person,
        "Xinyun Chen"^^schema:Person,
        "Yanpei Liu"^^schema:Person ;
    schema:commentCount "603"^^schema:Integer ;
    schema:dateModified "2017-02-07T14:24:44Z"^^schema:DateTime ;
    schema:datePublished "2016-11-08T23:25:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Delving into Transferable Adversarial Examples and Black-box Attacks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.02770v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11918479105697515542&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<568> a schema:ScholarlyArticle ;
    schema:abstract "The goal of graph representation learning is to embed each vertex in a graphinto a low-dimensional vector space. Existing graph representation learningmethods can be classified into two categories: generative models that learn theunderlying connectivity distribution in the graph, and discriminative modelsthat predict the probability of edge existence between a pair of vertices. Inthis paper, we propose GraphGAN, an innovative graph representation learningframework unifying above two classes of methods, in which the generative modeland discriminative model play a game-theoretical minimax game. Specifically,for a given vertex, the generative model tries to fit its underlying trueconnectivity distribution over all other vertices and produces \"fake\" samplesto fool the discriminative model, while the discriminative model tries todetect whether the sampled vertex is from ground truth or generated by thegenerative model. With the competition between these two models, both of themcan alternately and iteratively boost their performance. Moreover, whenconsidering the implementation of generative model, we propose a novel graphsoftmax to overcome the limitations of traditional softmax function, which canbe proven satisfying desirable properties of normalization, graph structureawareness, and computational efficiency. Through extensive experiments onreal-world datasets, we demonstrate that GraphGAN achieves substantial gains ina variety of applications, including link prediction, node classification, andrecommendation, over state-of-the-art baselines."^^schema:Text ;
    schema:author "Fuzheng Zhang"^^schema:Person,
        "Hongwei Wang"^^schema:Person,
        "Jia Wang"^^schema:Person,
        "Jialin Wang"^^schema:Person,
        "Miao Zhao"^^schema:Person,
        "Minyi Guo"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Xing Xie"^^schema:Person ;
    schema:commentCount "180"^^schema:Integer ;
    schema:dateModified "2017-11-22T13:20:17Z"^^schema:DateTime ;
    schema:datePublished "2017-11-22T13:20:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "GraphGAN: Graph Representation Learning with Generative Adversarial Nets"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.08267v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11414835106213661900&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<569> a schema:ScholarlyArticle ;
    schema:abstract "We present an autoencoder that leverages learned representations to bettermeasure similarities in data space. By combining a variational autoencoder witha generative adversarial network we can use learned feature representations inthe GAN discriminator as basis for the VAE reconstruction objective. Thereby,we replace element-wise errors with feature-wise errors to better capture thedata distribution while offering invariance towards e.g. translation. We applyour method to images of faces and show that it outperforms VAEs withelement-wise similarity measures in terms of visual fidelity. Moreover, we showthat the method learns an embedding in which high-level abstract visualfeatures (e.g. wearing glasses) can be modified using simple arithmetic."^^schema:Text ;
    schema:author "Anders Boesen Lindbo Larsen"^^schema:Person,
        "Hugo Larochelle"^^schema:Person,
        "Ole Winther"^^schema:Person,
        "Søren Kaae Sønderby"^^schema:Person ;
    schema:commentCount "965"^^schema:Integer ;
    schema:dateModified "2016-02-10T21:18:27Z"^^schema:DateTime ;
    schema:datePublished "2015-12-31T14:53:39Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Autoencoding beyond pixels using a learned similarity metric"^^schema:Text ;
    schema:publisher "ICML, 1558-1566"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1512.09300v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12417620106993504772&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<57> a schema:ScholarlyArticle ;
    schema:abstract "One long-term goal of machine learning research is to produce methods thatare applicable to reasoning and natural language, in particular building anintelligent dialogue agent. To measure progress towards that goal, we argue forthe usefulness of a set of proxy tasks that evaluate reading comprehension viaquestion answering. Our tasks measure understanding in several ways: whether asystem is able to answer questions via chaining facts, simple induction,deduction and many more. The tasks are designed to be prerequisites for anysystem that aims to be capable of conversing with a human. We believe manyexisting learning systems can currently not solve them, and hence our aim is toclassify these tasks into skill sets, so that researchers can identify (andthen rectify) the failings of their systems. We also extend and improve therecently introduced Memory Networks model, and show it is able to solve some,but not all, of the tasks."^^schema:Text ;
    schema:author "Alexander M. Rush"^^schema:Person,
        "Antoine Bordes"^^schema:Person,
        "Armand Joulin"^^schema:Person,
        "Bart van Merriënboer"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Sumit Chopra"^^schema:Person,
        "Tomas Mikolov"^^schema:Person ;
    schema:commentCount "746"^^schema:Integer ;
    schema:dateModified "2015-12-31T13:08:14Z"^^schema:DateTime ;
    schema:datePublished "2015-02-19T20:46:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.05698v10"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=886478109396958527&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<570> a schema:ScholarlyArticle ;
    schema:abstract "High demand for computation resources severely hinders deployment oflarge-scale Deep Neural Networks (DNN) in resource constrained devices. In thiswork, we propose a Structured Sparsity Learning (SSL) method to regularize thestructures (i.e., filters, channels, filter shapes, and layer depth) of DNNs.SSL can: (1) learn a compact structure from a bigger DNN to reduce computationcost; (2) obtain a hardware-friendly structured sparsity of DNN to efficientlyaccelerate the DNNs evaluation. Experimental results show that SSL achieves onaverage 5.1x and 3.1x speedups of convolutional layer computation of AlexNetagainst CPU and GPU, respectively, with off-the-shelf libraries. These speedupsare about twice speedups of non-structured sparsity; (3) regularize the DNNstructure to improve classification accuracy. The results show that forCIFAR-10, regularization on layer depth can reduce 20 layers of a Deep ResidualNetwork (ResNet) to 18 layers while improve the accuracy from 91.25% to 92.60%,which is still slightly higher than that of original ResNet with 32 layers. ForAlexNet, structure regularization by SSL also reduces the error by around ~1%.Open source code is in https://github.com/wenwei202/caffe/tree/scnn"^^schema:Text ;
    schema:author "Chunpeng Wu"^^schema:Person,
        "Hai Li"^^schema:Person,
        "Wei Wen"^^schema:Person,
        "Yandan Wang"^^schema:Person,
        "Yiran Chen"^^schema:Person ;
    schema:commentCount "977"^^schema:Integer ;
    schema:dateModified "2016-10-18T04:03:41Z"^^schema:DateTime ;
    schema:datePublished "2016-08-12T03:20:43Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.5.1"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Structured Sparsity in Deep Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.03665v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14407046964194758297&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<571> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we study the problem of recovering a low-rank matrix fromlinear measurements. Our algorithm, which we call Procrustes Flow, starts froman initial estimate obtained by a thresholding scheme followed by gradientdescent on a non-convex objective. We show that as long as the measurementsobey a standard restricted isometry property, our algorithm converges to theunknown matrix at a geometric rate. In the case of Gaussian measurements, suchconvergence occurs for a $n_1 \\times n_2$ matrix of rank $r$ when the number ofmeasurements exceeds a constant times $(n_1+n_2)r$."^^schema:Text ;
    schema:author "Benjamin Recht"^^schema:Person,
        "Mahdi Soltanolkotabi"^^schema:Person,
        "Max Simchowitz"^^schema:Person,
        "Ross Boczar"^^schema:Person,
        "Stephen Tu"^^schema:Person ;
    schema:commentCount "246"^^schema:Integer ;
    schema:dateModified "2016-02-05T20:34:55Z"^^schema:DateTime ;
    schema:datePublished "2015-07-13T19:45:28Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text ;
    schema:headline "Low-rank Solutions of Linear Matrix Equations via Procrustes Flow"^^schema:Text ;
    schema:publisher "ICML, 964-973"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.03566v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1139387413638481008&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<572> a schema:ScholarlyArticle ;
    schema:abstract "Efficient exploration in complex environments remains a major challenge forreinforcement learning. We propose bootstrapped DQN, a simple algorithm thatexplores in a computationally and statistically efficient manner through use ofrandomized value functions. Unlike dithering strategies such as epsilon-greedyexploration, bootstrapped DQN carries out temporally-extended (or deep)exploration; this can lead to exponentially faster learning. We demonstratethese benefits in complex stochastic MDPs and in the large-scale ArcadeLearning Environment. Bootstrapped DQN substantially improves learning timesand performance across most Atari games."^^schema:Text ;
    schema:author "Alexander Pritzel"^^schema:Person,
        "Benjamin Van Roy"^^schema:Person,
        "Charles Blundell"^^schema:Person,
        "Ian Osband"^^schema:Person ;
    schema:commentCount "500"^^schema:Integer ;
    schema:dateModified "2016-07-04T17:11:52Z"^^schema:DateTime ;
    schema:datePublished "2016-02-15T10:54:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Exploration via Bootstrapped DQN"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.04621v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1614250880059729675&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<573> a schema:ScholarlyArticle ;
    schema:abstract "Low-dimensional embeddings of nodes in large graphs have proved extremelyuseful in a variety of prediction tasks, from content recommendation toidentifying protein functions. However, most existing approaches require thatall nodes in the graph are present during training of the embeddings; theseprevious approaches are inherently transductive and do not naturally generalizeto unseen nodes. Here we present GraphSAGE, a general, inductive framework thatleverages node feature information (e.g., text attributes) to efficientlygenerate node embeddings for previously unseen data. Instead of trainingindividual embeddings for each node, we learn a function that generatesembeddings by sampling and aggregating features from a node's localneighborhood. Our algorithm outperforms strong baselines on three inductivenode-classification benchmarks: we classify the category of unseen nodes inevolving information graphs based on citation and Reddit post data, and we showthat our algorithm generalizes to completely unseen graphs using a multi-graphdataset of protein-protein interactions."^^schema:Text ;
    schema:author "Jure Leskovec"^^schema:Person,
        "Rex Ying"^^schema:Person,
        "William L. Hamilton"^^schema:Person ;
    schema:commentCount "1617"^^schema:Integer ;
    schema:dateModified "2018-09-10T14:26:58Z"^^schema:DateTime ;
    schema:datePublished "2017-06-07T14:51:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Inductive Representation Learning on Large Graphs"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1706.02216v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10802896480404413344&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<574> a schema:ScholarlyArticle ;
    schema:abstract "Person re-identification (ReID) focuses on identifying people acrossdifferent scenes in video surveillance, which is usually formulated as a binaryclassification task or a ranking task in current person ReID approaches. Inthis paper, we take both tasks into account and propose a multi-task deepnetwork (MTDnet) that makes use of their own advantages and jointly optimizethe two tasks simultaneously for person ReID. To the best of our knowledge, weare the first to integrate both tasks in one network to solve the person ReID.We show that our proposed architecture significantly boosts the performance.Furthermore, deep architecture in general requires a sufficient dataset fortraining, which is usually not met in person ReID. To cope with this situation,we further extend the MTDnet and propose a cross-domain architecture that iscapable of using an auxiliary set to assist training on small target sets. Inthe experiments, our approach outperforms most of existing person ReIDalgorithms on representative datasets including CUHK03, CUHK01, VIPeR, iLIDSand PRID2011, which clearly demonstrates the effectiveness of the proposedapproach."^^schema:Text ;
    schema:author "Jianguo Zhang"^^schema:Person,
        "Kaiqi Huang"^^schema:Person,
        "Weihua Chen"^^schema:Person,
        "Xiaotang Chen"^^schema:Person ;
    schema:commentCount "145"^^schema:Integer ;
    schema:dateModified "2016-11-25T06:22:57Z"^^schema:DateTime ;
    schema:datePublished "2016-07-19T01:59:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "A Multi-task Deep Network for Person Re-identification"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.05369v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8761948355560963456&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<575> a schema:ScholarlyArticle ;
    schema:abstract "One-shot learning is usually tackled by using generative models ordiscriminative embeddings. Discriminative methods based on deep learning, whichare very effective in other learning scenarios, are ill-suited for one-shotlearning as they need large amounts of training data. In this paper, we proposea method to learn the parameters of a deep model in one shot. We construct thelearner as a second deep network, called a learnet, which predicts theparameters of a pupil network from a single exemplar. In this manner we obtainan efficient feed-forward one-shot learner, trained end-to-end by minimizing aone-shot classification objective in a learning to learn formulation. In orderto make the construction feasible, we propose a number of factorizations of theparameters of the pupil network. We demonstrate encouraging results by learningcharacters from single exemplars in Omniglot, and by tracking visual objectsfrom a single initial exemplar in the Visual Object Tracking benchmark."^^schema:Text ;
    schema:author "Andrea Vedaldi"^^schema:Person,
        "Jack Valmadre"^^schema:Person,
        "João F. Henriques"^^schema:Person,
        "Luca Bertinetto"^^schema:Person,
        "Philip H. S. Torr"^^schema:Person ;
    schema:commentCount "229"^^schema:Integer ;
    schema:dateModified "2016-06-16T15:49:26Z"^^schema:DateTime ;
    schema:datePublished "2016-06-16T15:49:26Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Learning feed-forward one-shot learners"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.05233v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8558583381725749208&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<576> a schema:ScholarlyArticle ;
    schema:abstract "Standard methods for generating adversarial examples for neural networks donot consistently fool neural network classifiers in the physical world due to acombination of viewpoint shifts, camera noise, and other naturaltransformations, limiting their relevance to real-world systems. We demonstratethe existence of robust 3D adversarial objects, and we present the firstalgorithm for synthesizing examples that are adversarial over a chosendistribution of transformations. We synthesize two-dimensional adversarialimages that are robust to noise, distortion, and affine transformation. Weapply our algorithm to complex three-dimensional objects, using 3D-printing tomanufacture the first physical adversarial objects. Our results demonstrate theexistence of 3D adversarial objects in the physical world."^^schema:Text ;
    schema:author "Andrew Ilyas"^^schema:Person,
        "Anish Athalye"^^schema:Person,
        "Kevin Kwok"^^schema:Person,
        "Logan Engstrom"^^schema:Person ;
    schema:commentCount "518"^^schema:Integer ;
    schema:dateModified "2018-06-07T16:25:12Z"^^schema:DateTime ;
    schema:datePublished "2017-07-24T04:17:33Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Synthesizing Robust Adversarial Examples"^^schema:Text ;
    schema:publisher "ICML, 284-293"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1707.07397v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10751510407294386830&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<577> a schema:ScholarlyArticle ;
    schema:abstract "Programming language processing (similar to natural language processing) is ahot research topic in the field of software engineering; it has also arousedgrowing interest in the artificial intelligence community. However, differentfrom a natural language sentence, a program contains rich, explicit, andcomplicated structural information. Hence, traditional NLP models may beinappropriate for programs. In this paper, we propose a novel tree-basedconvolutional neural network (TBCNN) for programming language processing, inwhich a convolution kernel is designed over programs' abstract syntax trees tocapture structural information. TBCNN is a generic architecture for programminglanguage processing; our experiments show its effectiveness in two differentprogram analysis tasks: classifying programs according to functionality, anddetecting code snippets of certain patterns. TBCNN outperforms baselinemethods, including several neural models for NLP."^^schema:Text ;
    schema:author "Ge Li"^^schema:Person,
        "Lili Mou"^^schema:Person,
        "Lu Zhang"^^schema:Person,
        "Tao Wang"^^schema:Person,
        "Zhi Jin"^^schema:Person ;
    schema:commentCount "227"^^schema:Integer ;
    schema:dateModified "2015-12-08T12:31:51Z"^^schema:DateTime ;
    schema:datePublished "2014-09-18T06:50:52Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.SE"^^schema:Text ;
    schema:headline "Convolutional Neural Networks over Tree Structures for Programming  Language Processing"^^schema:Text ;
    schema:publisher "Thirtieth AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1409.5718v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12324937124370515795&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<578> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning models are often successfully trained using gradient descent,despite the worst case hardness of the underlying non-convex optimizationproblem. The key question is then under what conditions can one prove thatoptimization will succeed. Here we provide a strong result of this kind. Weconsider a neural net with one hidden layer and a convolutional structure withno overlap and a ReLU activation function. For this architecture we show thatlearning is NP-complete in the general case, but that when the inputdistribution is Gaussian, gradient descent converges to the global optimum inpolynomial time. To the best of our knowledge, this is the first globaloptimality guarantee of gradient descent on a convolutional neural network withReLU activations."^^schema:Text ;
    schema:author "Alon Brutzkus"^^schema:Person,
        "Amir Globerson"^^schema:Person ;
    schema:commentCount "184"^^schema:Integer ;
    schema:dateModified "2017-02-26T01:12:20Z"^^schema:DateTime ;
    schema:datePublished "2017-02-26T01:12:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs"^^schema:Text ;
    schema:publisher "ICML, 605-614"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.07966v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5580029596128142672&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<579> a schema:ScholarlyArticle ;
    schema:abstract "Usually bilingual word vectors are trained \"online\". Mikolov et al. showedthey can also be found \"offline\", whereby two pre-trained embeddings arealigned with a linear transformation, using dictionaries compiled from expertknowledge. In this work, we prove that the linear transformation between twospaces should be orthogonal. This transformation can be obtained using thesingular value decomposition. We introduce a novel \"inverted softmax\" foridentifying translation pairs, with which we improve the precision @1 ofMikolov's original mapping from 34% to 43%, when translating a test setcomposed of both common and rare English words into Italian. Orthogonaltransformations are more robust to noise, enabling us to learn thetransformation without expert bilingual signal by constructing a\"pseudo-dictionary\" from the identical character strings which appear in bothlanguages, achieving 40% precision on the same test set. Finally, we extend ourmethod to retrieve the true translations of English sentences from a corpus of200k Italian sentences with a precision @1 of 68%."^^schema:Text ;
    schema:author "David H. P. Turban"^^schema:Person,
        "Nils Y. Hammerla"^^schema:Person,
        "Samuel L. Smith"^^schema:Person,
        "Steven Hamblin"^^schema:Person ;
    schema:commentCount "301"^^schema:Integer ;
    schema:dateModified "2017-02-13T16:31:06Z"^^schema:DateTime ;
    schema:datePublished "2017-02-13T16:31:06Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Offline bilingual word vectors, orthogonal transformations and the  inverted softmax"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1702.03859v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5636639417293949985&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<58> a schema:ScholarlyArticle ;
    schema:abstract "Kernel classifiers and regressors designed for structured data, such assequences, trees and graphs, have significantly advanced a number ofinterdisciplinary areas such as computational biology and drug design.Typically, kernels are designed beforehand for a data type which either exploitstatistics of the structures or make use of probabilistic generative models,and then a discriminative classifier is learned based on the kernels via convexoptimization. However, such an elegant two-stage approach also limited kernelmethods from scaling up to millions of data points, and exploitingdiscriminative information to learn feature representations.  We propose, structure2vec, an effective and scalable approach for structureddata representation based on the idea of embedding latent variable models intofeature spaces, and learning such feature spaces using discriminativeinformation. Interestingly, structure2vec extracts features by performing asequence of function mappings in a way similar to graphical model inferenceprocedures, such as mean field and belief propagation. In applicationsinvolving millions of data points, we showed that structure2vec runs 2 timesfaster, produces models which are $10,000$ times smaller, while at the sametime achieving the state-of-the-art predictive performance."^^schema:Text ;
    schema:author "Bo Dai"^^schema:Person,
        "Hanjun Dai"^^schema:Person,
        "Le Song"^^schema:Person ;
    schema:commentCount "269"^^schema:Integer ;
    schema:dateModified "2020-01-11T03:00:02Z"^^schema:DateTime ;
    schema:datePublished "2016-03-17T19:29:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Discriminative Embeddings of Latent Variable Models for Structured Data"^^schema:Text ;
    schema:publisher "ICML, 2702-2711"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.05629v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6328035502669651426&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<580> a schema:ScholarlyArticle ;
    schema:abstract "Semantic Role Labeling (SRL) is believed to be a crucial step towards naturallanguage understanding and has been widely studied. Recent years, end-to-endSRL with recurrent neural networks (RNN) has gained increasing attention.However, it remains a major challenge for RNNs to handle structural informationand long range dependencies. In this paper, we present a simple and effectivearchitecture for SRL which aims to address these problems. Our model is basedon self-attention which can directly capture the relationships between twotokens regardless of their distance. Our single model achieves F$_1=83.4$ onthe CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared taskdataset, which outperforms the previous state-of-the-art results by $1.8$ and$1.0$ F$_1$ score respectively. Besides, our model is computationallyefficient, and the parsing speed is 50K tokens per second on a single Titan XGPU."^^schema:Text ;
    schema:author "Jun Xie"^^schema:Person,
        "Mingxuan Wang"^^schema:Person,
        "Xiaodong Shi"^^schema:Person,
        "Yidong Chen"^^schema:Person,
        "Zhixing Tan"^^schema:Person ;
    schema:commentCount "150"^^schema:Integer ;
    schema:dateModified "2017-12-05T11:48:51Z"^^schema:DateTime ;
    schema:datePublished "2017-12-05T11:48:51Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Deep Semantic Role Labeling with Self-Attention"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.01586v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9226285893444450718&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<581> a schema:ScholarlyArticle ;
    schema:abstract "Synthesizing high resolution photorealistic images has been a long-standingchallenge in machine learning. In this paper we introduce new methods for theimproved training of generative adversarial networks (GANs) for imagesynthesis. We construct a variant of GANs employing label conditioning thatresults in 128x128 resolution image samples exhibiting global coherence. Weexpand on previous work for image quality assessment to provide two newanalyses for assessing the discriminability and diversity of samples fromclass-conditional image synthesis models. These analyses demonstrate that highresolution samples provide class information not present in low resolutionsamples. Across 1000 ImageNet classes, 128x128 samples are more than twice asdiscriminable as artificially resized 32x32 samples. In addition, 84.7% of theclasses have samples exhibiting diversity comparable to real ImageNet data."^^schema:Text ;
    schema:author "Augustus Odena"^^schema:Person,
        "Christopher Olah"^^schema:Person,
        "Jonathon Shlens"^^schema:Person ;
    schema:commentCount "1236"^^schema:Integer ;
    schema:dateModified "2017-07-20T20:23:31Z"^^schema:DateTime ;
    schema:datePublished "2016-10-30T00:29:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Conditional Image Synthesis With Auxiliary Classifier GANs"^^schema:Text ;
    schema:publisher "ICML, 2642-2651"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.09585v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12065133258161328182&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<582> a schema:ScholarlyArticle ;
    schema:abstract "Several real-world classification problems are example-dependentcost-sensitive in nature, where the costs due to misclassification vary betweenexamples and not only within classes. However, standard classification methodsdo not take these costs into account, and assume a constant cost ofmisclassification errors. In previous works, some methods that take intoaccount the financial costs into the training of different algorithms have beenproposed, with the example-dependent cost-sensitive decision tree algorithmbeing the one that gives the highest savings. In this paper we propose a newframework of ensembles of example-dependent cost-sensitive decision-trees. Theframework consists in creating different example-dependent cost-sensitivedecision trees on random subsamples of the training set, and then combiningthem using three different combination approaches. Moreover, we propose two newcost-sensitive combination approaches; cost-sensitive weighted voting andcost-sensitive stacking, the latter being based on the cost-sensitive logisticregression method. Finally, using five different databases, from fourreal-world applications: credit card fraud detection, churn modeling, creditscoring and direct marketing, we evaluate the proposed method againststate-of-the-art example-dependent cost-sensitive techniques, namely,cost-proportionate sampling, Bayes minimum risk and cost-sensitive decisiontrees. The results show that the proposed algorithms have better results forall databases, in the sense of higher savings."^^schema:Text ;
    schema:author "Alejandro Correa Bahnsen"^^schema:Person,
        "Bjorn Ottersten"^^schema:Person,
        "Djamila Aouada"^^schema:Person ;
    schema:commentCount "119"^^schema:Integer ;
    schema:dateModified "2015-05-18T13:43:53Z"^^schema:DateTime ;
    schema:datePublished "2015-05-18T13:43:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Ensemble of Example-Dependent Cost-Sensitive Decision Trees"^^schema:Text ;
    schema:publisher "Expert Systems with Applications 42 (19), 6609-6619"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.04637v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17692807637486467277&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<583> a schema:ScholarlyArticle ;
    schema:abstract "A core challenge for an agent learning to interact with the world is topredict how its actions affect objects in its environment. Many existingmethods for learning the dynamics of physical interactions require labeledobject information. However, to scale real-world interaction learning to avariety of scenes and objects, acquiring labeled data becomes increasinglyimpractical. To learn about physical object motion without labels, we developan action-conditioned video prediction model that explicitly models pixelmotion, by predicting a distribution over pixel motion from previous frames.Because our model explicitly predicts motion, it is partially invariant toobject appearance, enabling it to generalize to previously unseen objects. Toexplore video prediction for real-world interactive agents, we also introduce adataset of 59,000 robot interactions involving pushing motions, including atest set with novel objects. In this dataset, accurate prediction of videosconditioned on the robot's future actions amounts to learning a \"visualimagination\" of different futures based on different courses of action. Ourexperiments show that our proposed method produces more accurate videopredictions both quantitatively and qualitatively, when compared to priormethods."^^schema:Text ;
    schema:author "Chelsea Finn"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "560"^^schema:Integer ;
    schema:dateModified "2016-10-17T20:09:56Z"^^schema:DateTime ;
    schema:datePublished "2016-05-23T19:45:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Unsupervised Learning for Physical Interaction through Video Prediction"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07157v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5380767711147691375&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<584> a schema:ScholarlyArticle ;
    schema:abstract "Many sequential processing tasks require complex nonlinear transitionfunctions from one step to the next. However, recurrent neural networks with'deep' transition functions remain difficult to train, even when using LongShort-Term Memory (LSTM) networks. We introduce a novel theoretical analysis ofrecurrent networks based on Gersgorin's circle theorem that illuminates severalmodeling and optimization issues and improves our understanding of the LSTMcell. Based on this analysis we propose Recurrent Highway Networks, whichextend the LSTM architecture to allow step-to-step transition depths largerthan one. Several language modeling experiments demonstrate that the proposedarchitecture results in powerful and efficient models. On the Penn Treebankcorpus, solely increasing the transition depth from 1 to 10 improves word-levelperplexity from 90.6 to 65.4 using the same number of parameters. On the largerWikipedia datasets for character prediction (text8 and enwik8), RHNs outperformall previous results and achieve an entropy of 1.27 bits per character."^^schema:Text ;
    schema:author "Jan Koutník"^^schema:Person,
        "Julian Georg Zilly"^^schema:Person,
        "Jürgen Schmidhuber"^^schema:Person,
        "Rupesh Kumar Srivastava"^^schema:Person ;
    schema:commentCount "326"^^schema:Integer ;
    schema:dateModified "2017-07-04T19:29:23Z"^^schema:DateTime ;
    schema:datePublished "2016-07-12T19:36:50Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Recurrent Highway Networks"^^schema:Text ;
    schema:publisher "ICML, 4189-4198"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.03474v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12472656521661483543&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<585> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have been shown to be very powerful modeling tools formany supervised learning tasks involving complex input patterns. However, theycan also easily overfit to training set biases and label noises. In addition tovarious regularizers, example reweighting algorithms are popular solutions tothese problems, but they require careful tuning of additional hyperparameters,such as example mining schedules and regularization hyperparameters. Incontrast to past reweighting methods, which typically consist of functions ofthe cost value of each example, in this work we propose a novel meta-learningalgorithm that learns to assign weights to training examples based on theirgradient directions. To determine the example weights, our method performs ameta gradient descent step on the current mini-batch example weights (which areinitialized from zero) to minimize the loss on a clean unbiased validation set.Our proposed method can be easily implemented on any type of deep network, doesnot require any additional hyperparameter tuning, and achieves impressiveperformance on class imbalance and corrupted label problems where only a smallamount of clean validation data is available."^^schema:Text ;
    schema:author "Bin Yang"^^schema:Person,
        "Mengye Ren"^^schema:Person,
        "Raquel Urtasun"^^schema:Person,
        "Wenyuan Zeng"^^schema:Person ;
    schema:commentCount "222"^^schema:Integer ;
    schema:dateModified "2019-05-05T15:21:40Z"^^schema:DateTime ;
    schema:datePublished "2018-03-24T03:41:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning to Reweight Examples for Robust Deep Learning"^^schema:Text ;
    schema:publisher "ICML, 4331-4340"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.09050v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17871432661582272860&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<586> a schema:ScholarlyArticle ;
    schema:abstract "We propose prototypical networks for the problem of few-shot classification,where a classifier must generalize to new classes not seen in the training set,given only a small number of examples of each new class. Prototypical networkslearn a metric space in which classification can be performed by computingdistances to prototype representations of each class. Compared to recentapproaches for few-shot learning, they reflect a simpler inductive bias that isbeneficial in this limited-data regime, and achieve excellent results. Weprovide an analysis showing that some simple design decisions can yieldsubstantial improvements over recent approaches involving complicatedarchitectural choices and meta-learning. We further extend prototypicalnetworks to zero-shot learning and achieve state-of-the-art results on theCU-Birds dataset."^^schema:Text ;
    schema:author "Jake Snell"^^schema:Person,
        "Kevin Swersky"^^schema:Person,
        "Richard S. Zemel"^^schema:Person ;
    schema:commentCount "1208"^^schema:Integer ;
    schema:dateModified "2017-06-19T22:48:54Z"^^schema:DateTime ;
    schema:datePublished "2017-03-15T14:31:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Prototypical Networks for Few-shot Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.05175v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8721743270682962846&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<587> a schema:ScholarlyArticle ;
    schema:abstract "We capitalize on large amounts of unlabeled video in order to learn a modelof scene dynamics for both video recognition tasks (e.g. action classification)and video generation tasks (e.g. future prediction). We propose a generativeadversarial network for video with a spatio-temporal convolutional architecturethat untangles the scene's foreground from the background. Experiments suggestthis model can generate tiny videos up to a second at full frame rate betterthan simple baselines, and we show its utility at predicting plausible futuresof static images. Moreover, experiments and visualizations show the modelinternally learns useful features for recognizing actions with minimalsupervision, suggesting scene dynamics are a promising signal forrepresentation learning. We believe generative video models can impact manyapplications in video understanding and simulation."^^schema:Text ;
    schema:author "Antonio Torralba"^^schema:Person,
        "Carl Vondrick"^^schema:Person,
        "Hamed Pirsiavash"^^schema:Person ;
    schema:commentCount "736"^^schema:Integer ;
    schema:dateModified "2016-10-26T13:58:10Z"^^schema:DateTime ;
    schema:datePublished "2016-09-08T22:29:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Generating Videos with Scene Dynamics"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.02612v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12629733064507558057&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<588> a schema:ScholarlyArticle ;
    schema:abstract "We identify a trade-off between robustness and accuracy that serves as aguiding principle in the design of defenses against adversarial examples.Although this problem has been widely studied empirically, much remains unknownconcerning the theory underlying this trade-off. In this work, we decompose theprediction error for adversarial examples (robust error) as the sum of thenatural (classification) error and boundary error, and provide a differentiableupper bound using the theory of classification-calibrated loss, which is shownto be the tightest possible upper bound uniform over all probabilitydistributions and measurable predictors. Inspired by our theoretical analysis,we also design a new defense method, TRADES, to trade adversarial robustnessoff against accuracy. Our proposed algorithm performs well experimentally inreal-world datasets. The methodology is the foundation of our entry to theNeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of~2,000 submissions, surpassing the runner-up approach by $11.41\\%$ in terms ofmean $\\ell_2$ perturbation distance."^^schema:Text ;
    schema:author "Eric P. Xing"^^schema:Person,
        "Hongyang Zhang"^^schema:Person,
        "Jiantao Jiao"^^schema:Person,
        "Laurent El Ghaoui"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Yaodong Yu"^^schema:Person ;
    schema:commentCount "206"^^schema:Integer ;
    schema:dateModified "2019-06-24T07:04:11Z"^^schema:DateTime ;
    schema:datePublished "2019-01-24T18:43:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Theoretically Principled Trade-off between Robustness and Accuracy"^^schema:Text ;
    schema:publisher "ICML, 7472-7482"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1901.08573v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3311622924435738798&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<589> a schema:ScholarlyArticle ;
    schema:abstract "Current end-to-end machine reading and question answering (Q\\&amp;A) models areprimarily based on recurrent neural networks (RNNs) with attention. Despitetheir success, these models are often slow for both training and inference dueto the sequential nature of RNNs. We propose a new Q\\&amp;A architecture calledQANet, which does not require recurrent networks: Its encoder consistsexclusively of convolution and self-attention, where convolution models localinteractions and self-attention models global interactions. On the SQuADdataset, our model is 3x to 13x faster in training and 4x to 9x faster ininference, while achieving equivalent accuracy to recurrent models. Thespeed-up gain allows us to train the model with much more data. We hencecombine our model with data generated by backtranslation from a neural machinetranslation model. On the SQuAD dataset, our single model, trained withaugmented data, achieves 84.6 F1 score on the test set, which is significantlybetter than the best published F1 score of 81.8."^^schema:Text ;
    schema:author "Adams Wei Yu"^^schema:Person,
        "David Dohan"^^schema:Person,
        "Kai Chen"^^schema:Person,
        "Minh-Thang Luong"^^schema:Person,
        "Mohammad Norouzi"^^schema:Person,
        "Quoc V. Le"^^schema:Person,
        "Rui Zhao"^^schema:Person ;
    schema:commentCount "371"^^schema:Integer ;
    schema:dateModified "2018-04-23T11:33:43Z"^^schema:DateTime ;
    schema:datePublished "2018-04-23T11:33:43Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "QANet: Combining Local Convolution with Global Self-Attention for  Reading Comprehension"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1804.09541v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15745561136241294753&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<59> a schema:ScholarlyArticle ;
    schema:abstract "Recent studies reveal that a deep neural network can learn transferablefeatures which generalize well to novel tasks for domain adaptation. However,as deep features eventually transition from general to specific along thenetwork, the feature transferability drops significantly in higher layers withincreasing domain discrepancy. Hence, it is important to formally reduce thedataset bias and enhance the transferability in task-specific layers. In thispaper, we propose a new Deep Adaptation Network (DAN) architecture, whichgeneralizes deep convolutional neural network to the domain adaptationscenario. In DAN, hidden representations of all task-specific layers areembedded in a reproducing kernel Hilbert space where the mean embeddings ofdifferent domain distributions can be explicitly matched. The domaindiscrepancy is further reduced using an optimal multi-kernel selection methodfor mean embedding matching. DAN can learn transferable features withstatistical guarantees, and can scale linearly by unbiased estimate of kernelembedding. Extensive empirical evidence shows that the proposed architectureyields state-of-the-art image classification error rates on standard domainadaptation benchmarks."^^schema:Text ;
    schema:author "Jianmin Wang"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Mingsheng Long"^^schema:Person,
        "Yue Cao"^^schema:Person ;
    schema:commentCount "1545"^^schema:Integer ;
    schema:dateModified "2015-05-27T05:28:35Z"^^schema:DateTime ;
    schema:datePublished "2015-02-10T06:01:30Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Learning Transferable Features with Deep Adaptation Networks"^^schema:Text ;
    schema:publisher "ICML, 97-105"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.02791v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10097353709258117195&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<590> a schema:ScholarlyArticle ;
    schema:abstract "Theoretical and empirical evidence indicates that the depth of neuralnetworks is crucial for their success. However, training becomes more difficultas depth increases, and training of very deep networks remains an open problem.Here we introduce a new architecture designed to overcome this. Our so-calledhighway networks allow unimpeded information flow across many layers oninformation highways. They are inspired by Long Short-Term Memory recurrentnetworks and use adaptive gating units to regulate the information flow. Evenwith hundreds of layers, highway networks can be trained directly throughsimple gradient descent. This enables the study of extremely deep and efficientarchitectures."^^schema:Text ;
    schema:author "Jürgen Schmidhuber"^^schema:Person,
        "Klaus Greff"^^schema:Person,
        "Rupesh Kumar Srivastava"^^schema:Person ;
    schema:commentCount "1066"^^schema:Integer ;
    schema:dateModified "2015-11-23T16:25:30Z"^^schema:DateTime ;
    schema:datePublished "2015-07-22T15:29:14Z"^^schema:DateTime ;
    schema:genre "68T01"^^schema:Text,
        "I.2.6; G.1.6"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Training Very Deep Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1507.06228v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14374917385640982609&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<591> a schema:ScholarlyArticle ;
    schema:abstract "Here we introduce a new model of natural textures based on the feature spacesof convolutional neural networks optimised for object recognition. Samples fromthe model are of high perceptual quality demonstrating the generative power ofneural networks trained in a purely discriminative fashion. Within the model,textures are represented by the correlations between feature maps in severallayers of the network. We show that across layers the texture representationsincreasingly capture the statistical properties of natural images while makingobject information more and more explicit. The model provides a new tool togenerate stimuli for neuroscience and might offer insights into the deeprepresentations learned by convolutional neural networks."^^schema:Text ;
    schema:author "Alexander S. Ecker"^^schema:Person,
        "Leon A. Gatys"^^schema:Person,
        "Matthias Bethge"^^schema:Person ;
    schema:commentCount "659"^^schema:Integer ;
    schema:dateModified "2015-11-06T13:55:09Z"^^schema:DateTime ;
    schema:datePublished "2015-05-27T15:29:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text,
        "q-bio.NC"^^schema:Text ;
    schema:headline "Texture Synthesis Using Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.07376v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16960830956248393695&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<592> a schema:ScholarlyArticle ;
    schema:abstract "Top-performing deep architectures are trained on massive amounts of labeleddata. In the absence of labeled data for a certain task, domain adaptationoften provides an attractive option given that labeled data of similar naturebut from a different domain (e.g. synthetic images) are available. Here, wepropose a new approach to domain adaptation in deep architectures that can betrained on large amount of labeled data from the source domain and large amountof unlabeled data from the target domain (no labeled target-domain data isnecessary).  As the training progresses, the approach promotes the emergence of \"deep\"features that are (i) discriminative for the main learning task on the sourcedomain and (ii) invariant with respect to the shift between the domains. Weshow that this adaptation behaviour can be achieved in almost any feed-forwardmodel by augmenting it with few standard layers and a simple new gradientreversal layer. The resulting augmented architecture can be trained usingstandard backpropagation.  Overall, the approach can be implemented with little effort using any of thedeep-learning packages. The method performs very well in a series of imageclassification experiments, achieving adaptation effect in the presence of bigdomain shifts and outperforming previous state-of-the-art on Office datasets."^^schema:Text ;
    schema:author "Victor Lempitsky"^^schema:Person,
        "Yaroslav Ganin"^^schema:Person ;
    schema:commentCount "1581"^^schema:Integer ;
    schema:dateModified "2015-02-27T14:54:37Z"^^schema:DateTime ;
    schema:datePublished "2014-09-26T08:22:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unsupervised Domain Adaptation by Backpropagation"^^schema:Text ;
    schema:publisher "ICML, 1180-1189"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1409.7495v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1240308825085771392&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<593> a schema:ScholarlyArticle ;
    schema:abstract "We introduce Embed to Control (E2C), a method for model learning and controlof non-linear dynamical systems from raw pixel images. E2C consists of a deepgenerative model, belonging to the family of variational autoencoders, thatlearns to generate image trajectories from a latent space in which the dynamicsis constrained to be locally linear. Our model is derived directly from anoptimal control formulation in latent space, supports long-term prediction ofimage sequences and exhibits strong performance on a variety of complex controlproblems."^^schema:Text ;
    schema:author "Joschka Boedecker"^^schema:Person,
        "Jost Tobias Springenberg"^^schema:Person,
        "Manuel Watter"^^schema:Person,
        "Martin Riedmiller"^^schema:Person ;
    schema:commentCount "374"^^schema:Integer ;
    schema:dateModified "2015-11-20T14:49:18Z"^^schema:DateTime ;
    schema:datePublished "2015-06-24T13:48:51Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Embed to Control: A Locally Linear Latent Dynamics Model for Control  from Raw Images"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.07365v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14464025381144196926&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<594> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widelyused on NLP tasks to capture the long-term and local dependencies,respectively. Attention mechanisms have recently attracted enormous interestdue to their highly parallelizable computation, significantly less trainingtime, and flexibility in modeling dependencies. We propose a novel attentionmechanism in which the attention between elements from input sequence(s) isdirectional and multi-dimensional (i.e., feature-wise). A light-weight neuralnet, \"Directional Self-Attention Network (DiSAN)\", is then proposed to learnsentence embedding, based solely on the proposed attention without any RNN/CNNstructure. DiSAN is only composed of a directional self-attention with temporalorder encoded, followed by a multi-dimensional attention that compresses thesequence into a vector representation. Despite its simple form, DiSANoutperforms complicated RNN models on both prediction quality and timeefficiency. It achieves the best test accuracy among all sentence encodingmethods and improves the most recent best result by 1.02% on the StanfordNatural Language Inference (SNLI) dataset, and shows state-of-the-art testaccuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural languageinference (MultiNLI), Sentences Involving Compositional Knowledge (SICK),Customer Review, MPQA, TREC question-type classification and Subjectivity(SUBJ) datasets."^^schema:Text ;
    schema:author "Chengqi Zhang"^^schema:Person,
        "Guodong Long"^^schema:Person,
        "Jing Jiang"^^schema:Person,
        "Shirui Pan"^^schema:Person,
        "Tao Shen"^^schema:Person,
        "Tianyi Zhou"^^schema:Person ;
    schema:commentCount "294"^^schema:Integer ;
    schema:dateModified "2017-11-20T23:39:11Z"^^schema:DateTime ;
    schema:datePublished "2017-09-14T10:42:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language  Understanding"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.04696v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7314091737208199325&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<595> a schema:ScholarlyArticle ;
    schema:abstract "Sequential querying of differentially private mechanisms degrades the overallprivacy level. In this paper, we answer the fundamental question ofcharacterizing the level of overall privacy degradation as a function of thenumber of queries and the privacy levels maintained by each privatizationmechanism. Our solution is complete: we prove an upper bound on the overallprivacy level and construct a sequence of privatization mechanisms thatachieves this bound. The key innovation is the introduction of an operationalinterpretation of differential privacy (involving hypothesis testing) and theuse of new data processing inequalities. Our result improves over thestate-of-the-art, and has immediate applications in several problems studied inthe literature including differentially private multi-party computation."^^schema:Text ;
    schema:author "Peter Kairouz"^^schema:Person,
        "Pramod Viswanath"^^schema:Person,
        "Sewoong Oh"^^schema:Person ;
    schema:commentCount "200"^^schema:Integer ;
    schema:dateModified "2015-12-06T22:06:01Z"^^schema:DateTime ;
    schema:datePublished "2013-11-04T17:22:00Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.DS"^^schema:Text,
        "cs.IT"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "The Composition Theorem for Differential Privacy"^^schema:Text ;
    schema:publisher "ICML, 1376-1385"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1311.0776v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17631243245787694869&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<596> a schema:ScholarlyArticle ;
    schema:abstract "We consider the fundamental problem of solving quadratic systems of equationsin $n$ variables, where $y_i = |\\langle \\boldsymbol{a}_i, \\boldsymbol{x}\\rangle|^2$, $i = 1, \\ldots, m$ and $\\boldsymbol{x} \\in \\mathbb{R}^n$ isunknown. We propose a novel method, which starting with an initial guesscomputed by means of a spectral method, proceeds by minimizing a nonconvexfunctional as in the Wirtinger flow approach. There are several keydistinguishing features, most notably, a distinct objective functional andnovel update rules, which operate in an adaptive fashion and drop terms bearingtoo much influence on the search direction. These careful selection rulesprovide a tighter initial guess, better descent directions, and thus enhancedpractical performance. On the theoretical side, we prove that for certainunstructured models of quadratic systems, our algorithms return the correctsolution in linear time, i.e. in time proportional to reading the data$\\{\\boldsymbol{a}_i\\}$ and $\\{y_i\\}$ as soon as the ratio $m/n$ between thenumber of equations and unknowns exceeds a fixed numerical constant. We extendthe theory to deal with noisy systems in which we only have $y_i \\approx|\\langle \\boldsymbol{a}_i, \\boldsymbol{x} \\rangle|^2$ and prove that ouralgorithms achieve a statistical accuracy, which is nearly un-improvable. Wecomplement our theoretical study with numerical examples showing that solvingrandom quadratic systems is both computationally and statistically not muchharder than solving linear systems of the same size---hence the title of thispaper. For instance, we demonstrate empirically that the computational cost ofour algorithm is about four times that of solving a least-squares problem ofthe same size."^^schema:Text ;
    schema:author "Emmanuel J. Candes"^^schema:Person,
        "Yuxin Chen"^^schema:Person ;
    schema:commentCount "303"^^schema:Integer ;
    schema:dateModified "2016-03-22T17:05:16Z"^^schema:DateTime ;
    schema:datePublished "2015-05-19T18:37:07Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "math.NA"^^schema:Text,
        "math.ST"^^schema:Text,
        "stat.ML"^^schema:Text,
        "stat.TH"^^schema:Text ;
    schema:headline "Solving Random Quadratic Systems of Equations Is Nearly as Easy as  Solving Linear Systems"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.05114v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11224976403044841324&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<597> a schema:ScholarlyArticle ;
    schema:abstract "Despite recent progress in generative image modeling, successfully generatinghigh-resolution, diverse samples from complex datasets such as ImageNet remainsan elusive goal. To this end, we train Generative Adversarial Networks at thelargest scale yet attempted, and study the instabilities specific to suchscale. We find that applying orthogonal regularization to the generator rendersit amenable to a simple \"truncation trick,\" allowing fine control over thetrade-off between sample fidelity and variety by reducing the variance of theGenerator's input. Our modifications lead to models which set the new state ofthe art in class-conditional image synthesis. When trained on ImageNet at128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previousbest IS of 52.52 and FID of 18.6."^^schema:Text ;
    schema:author "Andrew Brock"^^schema:Person,
        "Jeff Donahue"^^schema:Person,
        "Karen Simonyan"^^schema:Person ;
    schema:commentCount "912"^^schema:Integer ;
    schema:dateModified "2019-02-25T21:32:06Z"^^schema:DateTime ;
    schema:datePublished "2018-09-28T15:38:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Large Scale GAN Training for High Fidelity Natural Image Synthesis"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1809.11096v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9573828555610570748&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<598> a schema:ScholarlyArticle ;
    schema:abstract "Large labeled training sets are the critical building blocks of supervisedlearning methods and are key enablers of deep learning techniques. For someapplications, creating labeled training sets is the most time-consuming andexpensive part of applying machine learning. We therefore propose a paradigmfor the programmatic creation of training sets called data programming in whichusers express weak supervision strategies or domain heuristics as labelingfunctions, which are programs that label subsets of the data, but that arenoisy and may conflict. We show that by explicitly representing this trainingset labeling process as a generative model, we can \"denoise\" the generatedtraining set, and establish theoretically that we can recover the parameters ofthese generative models in a handful of settings. We then show how to modify adiscriminative loss function to make it noise-aware, and demonstrate our methodover a range of discriminative models including logistic regression and LSTMs.Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that dataprogramming would have led to a new winning score, and also show that applyingdata programming to an LSTM model leads to a TAC-KBP score almost 6 F1 pointsover a state-of-the-art LSTM baseline (and into second place in thecompetition). Additionally, in initial user studies we observed that dataprogramming may be an easier way for non-experts to create machine learningmodels when training data is limited or unavailable."^^schema:Text ;
    schema:author "Alexander Ratner"^^schema:Person,
        "Christopher De Sa"^^schema:Person,
        "Christopher Ré"^^schema:Person,
        "Daniel Selsam"^^schema:Person,
        "Sen Wu"^^schema:Person ;
    schema:commentCount "263"^^schema:Integer ;
    schema:dateModified "2017-01-08T19:48:53Z"^^schema:DateTime ;
    schema:datePublished "2016-05-25T04:14:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Data Programming: Creating Large Training Sets, Quickly"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07723v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14359672499909857504&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<599> a schema:ScholarlyArticle ;
    schema:abstract "Designing architectures for deep neural networks requires expert knowledgeand substantial computation time. We propose a technique to acceleratearchitecture selection by learning an auxiliary HyperNet that generates theweights of a main model conditioned on that model's architecture. By comparingthe relative validation performance of networks with HyperNet-generatedweights, we can effectively search over a wide range of architectures at thecost of a single training run. To facilitate this search, we develop a flexiblemechanism based on memory read-writes that allows us to define a wide range ofnetwork connectivity patterns, with ResNet, DenseNet, and FractalNet blocks asspecial cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100,STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance withsimilarly-sized hand-designed networks. Our code is available athttps://github.com/ajbrock/SMASH"^^schema:Text ;
    schema:author "Andrew Brock"^^schema:Person,
        "J. M. Ritchie"^^schema:Person,
        "Nick Weston"^^schema:Person,
        "Theodore Lim"^^schema:Person ;
    schema:commentCount "245"^^schema:Integer ;
    schema:dateModified "2017-08-17T16:03:33Z"^^schema:DateTime ;
    schema:datePublished "2017-08-17T16:03:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "SMASH: One-Shot Model Architecture Search through HyperNetworks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1708.05344v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10456857144668119976&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<6> a schema:ScholarlyArticle ;
    schema:abstract "The recently-developed WaveNet architecture is the current state of the artin realistic speech synthesis, consistently rated as more natural sounding formany different languages than any previous system. However, because WaveNetrelies on sequential generation of one audio sample at a time, it is poorlysuited to today's massively parallel computers, and therefore hard to deploy ina real-time production setting. This paper introduces Probability DensityDistillation, a new method for training a parallel feed-forward network from atrained WaveNet with no significant difference in quality. The resulting systemis capable of generating high-fidelity speech samples at more than 20 timesfaster than real-time, and is deployed online by Google Assistant, includingserving multiple English and Japanese voices."^^schema:Text ;
    schema:author "Aaron van den Oord"^^schema:Person,
        "Alex Graves"^^schema:Person,
        "Dan Belov"^^schema:Person,
        "Demis Hassabis"^^schema:Person,
        "Dominik Grewe"^^schema:Person,
        "Edward Lockhart"^^schema:Person,
        "Erich Elsen"^^schema:Person,
        "Florian Stimberg"^^schema:Person,
        "George van den Driessche"^^schema:Person,
        "Heiga Zen"^^schema:Person,
        "Helen King"^^schema:Person,
        "Igor Babuschkin"^^schema:Person,
        "Karen Simonyan"^^schema:Person,
        "Koray Kavukcuoglu"^^schema:Person,
        "Luis C. Cobo"^^schema:Person,
        "Nal Kalchbrenner"^^schema:Person,
        "Norman Casagrande"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Sander Dieleman"^^schema:Person,
        "Seb Noury"^^schema:Person,
        "Tom Walters"^^schema:Person,
        "Yazhe Li"^^schema:Person ;
    schema:commentCount "293"^^schema:Integer ;
    schema:dateModified "2017-11-28T17:48:11Z"^^schema:DateTime ;
    schema:datePublished "2017-11-28T17:48:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Parallel WaveNet: Fast High-Fidelity Speech Synthesis"^^schema:Text ;
    schema:publisher "ICML, 3915-3923"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.10433v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14024591857649905131&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<60> a schema:ScholarlyArticle ;
    schema:abstract "Graph Convolutional Neural Networks (Graph CNNs) are generalizations ofclassical CNNs to handle graph data such as molecular data, point could andsocial networks. Current filters in graph CNNs are built for fixed and sharedgraph structure. However, for most real data, the graph structures varies inboth size and connectivity. The paper proposes a generalized and flexible graphCNN taking data of arbitrary graph structure as input. In that way atask-driven adaptive graph is learned for each graph data while training. Toefficiently learn the graph, a distance metric learning is proposed. Extensiveexperiments on nine graph-structured datasets have demonstrated the superiorperformance improvement on both convergence speed and predictive accuracy."^^schema:Text ;
    schema:author "Feiyun Zhu"^^schema:Person,
        "Junzhou Huang"^^schema:Person,
        "Ruoyu Li"^^schema:Person,
        "Sheng Wang"^^schema:Person ;
    schema:commentCount "130"^^schema:Integer ;
    schema:dateModified "2018-01-10T03:17:45Z"^^schema:DateTime ;
    schema:datePublished "2018-01-10T03:17:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adaptive Graph Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.03226v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7918065976159007739&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<600> a schema:ScholarlyArticle ;
    schema:abstract "We identify obfuscated gradients, a kind of gradient masking, as a phenomenonthat leads to a false sense of security in defenses against adversarialexamples. While defenses that cause obfuscated gradients appear to defeatiterative optimization-based attacks, we find defenses relying on this effectcan be circumvented. We describe characteristic behaviors of defensesexhibiting the effect, and for each of the three types of obfuscated gradientswe discover, we develop attack techniques to overcome it. In a case study,examining non-certified white-box-secure defenses at ICLR 2018, we findobfuscated gradients are a common occurrence, with 7 of 9 defenses relying onobfuscated gradients. Our new attacks successfully circumvent 6 completely, and1 partially, in the original threat model each paper considers."^^schema:Text ;
    schema:author "Anish Athalye"^^schema:Person,
        "David Wagner"^^schema:Person,
        "Nicholas Carlini"^^schema:Person ;
    schema:commentCount "914"^^schema:Integer ;
    schema:dateModified "2018-07-31T00:09:56Z"^^schema:DateTime ;
    schema:datePublished "2018-02-01T18:20:05Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Obfuscated Gradients Give a False Sense of Security: Circumventing  Defenses to Adversarial Examples"^^schema:Text ;
    schema:publisher "ICML, 274-283"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1802.00420v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16371153415378772336&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<601> a schema:ScholarlyArticle ;
    schema:abstract "We formulate language modeling as a matrix factorization problem, and showthat the expressiveness of Softmax-based models (including the majority ofneural language models) is limited by a Softmax bottleneck. Given that naturallanguage is highly context-dependent, this further implies that in practiceSoftmax with distributed word embeddings does not have enough capacity to modelnatural language. We propose a simple and effective method to address thisissue, and improve the state-of-the-art perplexities on Penn Treebank andWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels onthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 pointsin perplexity."^^schema:Text ;
    schema:author "Ruslan Salakhutdinov"^^schema:Person,
        "William W. Cohen"^^schema:Person,
        "Zhilin Yang"^^schema:Person,
        "Zihang Dai"^^schema:Person ;
    schema:commentCount "204"^^schema:Integer ;
    schema:dateModified "2018-03-02T20:20:52Z"^^schema:DateTime ;
    schema:datePublished "2017-11-10T18:29:00Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.03953v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15538946355362697879&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<602> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) have recently demonstrated thecapability to synthesize compelling real-world images, such as room interiors,album covers, manga, faces, birds, and flowers. While existing models cansynthesize images based on global constraints such as a class label or caption,they do not provide control over pose or object location. We propose a newmodel, the Generative Adversarial What-Where Network (GAWWN), that synthesizesimages given instructions describing what content to draw in which location. Weshow high-quality 128 x 128 image synthesis on the Caltech-UCSD Birds dataset,conditioned on both informal text descriptions and also object location. Oursystem exposes control over both the bounding box around the bird and itsconstituent parts. By modeling the conditional distributions over partlocations, our system also enables conditioning on arbitrary subsets of parts(e.g. only the beak and tail), yielding an efficient interface for picking partlocations. We also show preliminary results on the more challenging domain oftext- and location-controllable synthesis of images of human actions on theMPII Human Pose dataset."^^schema:Text ;
    schema:author "Bernt Schiele"^^schema:Person,
        "Honglak Lee"^^schema:Person,
        "Samuel Tenka"^^schema:Person,
        "Santosh Mohan"^^schema:Person,
        "Scott Reed"^^schema:Person,
        "Zeynep Akata"^^schema:Person ;
    schema:commentCount "327"^^schema:Integer ;
    schema:dateModified "2016-10-08T00:27:57Z"^^schema:DateTime ;
    schema:datePublished "2016-10-08T00:27:57Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Learning What and Where to Draw"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.02454v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2100133886684978488&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<603> a schema:ScholarlyArticle ;
    schema:abstract "This paper focuses on style transfer on the basis of non-parallel text. Thisis an instance of a broad family of problems including machine translation,decipherment, and sentiment modification. The key challenge is to separate thecontent from other aspects such as style. We assume a shared latent contentdistribution across different text corpora, and propose a method that leveragesrefined alignment of latent representations to perform style transfer. Thetransferred sentences from one style should match example sentences from theother style as a population. We demonstrate the effectiveness of thiscross-alignment method on three tasks: sentiment modification, decipherment ofword substitution ciphers, and recovery of word order."^^schema:Text ;
    schema:author "Regina Barzilay"^^schema:Person,
        "Tao Lei"^^schema:Person,
        "Tianxiao Shen"^^schema:Person,
        "Tommi Jaakkola"^^schema:Person ;
    schema:commentCount "295"^^schema:Integer ;
    schema:dateModified "2017-11-06T15:07:03Z"^^schema:DateTime ;
    schema:datePublished "2017-05-26T17:40:12Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Style Transfer from Non-Parallel Text by Cross-Alignment"^^schema:Text ;
    schema:publisher "Proceedings of the 31st International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.09655v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14976647505606347245&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<604> a schema:ScholarlyArticle ;
    schema:abstract "We study the problem of video-to-video synthesis, whose goal is to learn amapping function from an input source video (e.g., a sequence of semanticsegmentation masks) to an output photorealistic video that precisely depictsthe content of the source video. While its image counterpart, theimage-to-image synthesis problem, is a popular topic, the video-to-videosynthesis problem is less explored in the literature. Without understandingtemporal dynamics, directly applying existing image synthesis approaches to aninput video often results in temporally incoherent videos of low visualquality. In this paper, we propose a novel video-to-video synthesis approachunder the generative adversarial learning framework. Through carefully-designedgenerator and discriminator architectures, coupled with a spatio-temporaladversarial objective, we achieve high-resolution, photorealistic, temporallycoherent video results on a diverse set of input formats including segmentationmasks, sketches, and poses. Experiments on multiple benchmarks show theadvantage of our method compared to strong baselines. In particular, our modelis capable of synthesizing 2K resolution videos of street scenes up to 30seconds long, which significantly advances the state-of-the-art of videosynthesis. Finally, we apply our approach to future video prediction,outperforming several state-of-the-art competing systems."^^schema:Text ;
    schema:author "Andrew Tao"^^schema:Person,
        "Bryan Catanzaro"^^schema:Person,
        "Guilin Liu"^^schema:Person,
        "Jan Kautz"^^schema:Person,
        "Jun-Yan Zhu"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Ting-Chun Wang"^^schema:Person ;
    schema:commentCount "295"^^schema:Integer ;
    schema:dateModified "2018-12-03T15:12:44Z"^^schema:DateTime ;
    schema:datePublished "2018-08-20T17:58:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.GR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Video-to-Video Synthesis"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1808.06601v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3120460092236365926&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<605> a schema:ScholarlyArticle ;
    schema:abstract "This paper builds off recent work from Kiperwasser &amp; Goldberg (2016) usingneural attention in a simple graph-based dependency parser. We use a larger butmore thoroughly regularized parser than other recent BiLSTM-based approaches,with biaffine classifiers to predict arcs and labels. Our parser gets state ofthe art or near state of the art performance on standard treebanks for sixdifferent languages, achieving 95.7% UAS and 94.1% LAS on the most popularEnglish PTB dataset. This makes it the highest-performing graph-based parser onthis benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and2.2%---and comparable to the highest performing transition-based parser(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also showwhich hyperparameter choices had a significant effect on parsing accuracy,allowing us to achieve large gains over other graph-based approaches."^^schema:Text ;
    schema:author "Christopher D. Manning"^^schema:Person,
        "Timothy Dozat"^^schema:Person ;
    schema:commentCount "375"^^schema:Integer ;
    schema:dateModified "2017-03-10T04:37:03Z"^^schema:DateTime ;
    schema:datePublished "2016-11-06T07:26:38Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Deep Biaffine Attention for Neural Dependency Parsing"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01734v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2220752205833525649&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<606> a schema:ScholarlyArticle ;
    schema:abstract "The graph convolutional networks (GCN) recently proposed by Kipf and Wellingare an effective graph model for semi-supervised learning. This model, however,was originally designed to be learned with the presence of both training andtest data. Moreover, the recursive neighborhood expansion across layers posestime and memory challenges for training with large, dense graphs. To relax therequirement of simultaneous availability of test data, we interpret graphconvolutions as integral transforms of embedding functions under probabilitymeasures. Such an interpretation allows for the use of Monte Carlo approachesto consistently estimate the integrals, which in turn leads to a batchedtraining scheme as we propose in this work---FastGCN. Enhanced with importancesampling, FastGCN not only is efficient for training but also generalizes wellfor inference. We show a comprehensive set of experiments to demonstrate itseffectiveness compared with GCN and related models. In particular, training isorders of magnitude more efficient while predictions remain comparablyaccurate."^^schema:Text ;
    schema:author "Cao Xiao"^^schema:Person,
        "Jie Chen"^^schema:Person,
        "Tengfei Ma"^^schema:Person ;
    schema:commentCount "244"^^schema:Integer ;
    schema:dateModified "2018-01-30T22:36:16Z"^^schema:DateTime ;
    schema:datePublished "2018-01-30T22:36:16Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "FastGCN: Fast Learning with Graph Convolutional Networks via Importance  Sampling"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.10247v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18054036108684442257&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<607> a schema:ScholarlyArticle ;
    schema:abstract "While neural networks have achieved high accuracy on standard imageclassification benchmarks, their accuracy drops to nearly zero in the presenceof small adversarial perturbations to test inputs. Defenses based onregularization and adversarial training have been proposed, but often followedby new, stronger attacks that defeat these defenses. Can we somehow end thisarms race? In this work, we study this problem for neural networks with onehidden layer. We first propose a method based on a semidefinite relaxation thatoutputs a certificate that for a given network and test input, no attack canforce the error to exceed a certain value. Second, as this certificate isdifferentiable, we jointly optimize it with the network parameters, providingan adaptive regularizer that encourages robustness against all attacks. OnMNIST, our approach produces a network and a certificate that no attack thatperturbs each pixel by at most \\epsilon = 0.1 can cause more than 35% testerror."^^schema:Text ;
    schema:author "Aditi Raghunathan"^^schema:Person,
        "Jacob Steinhardt"^^schema:Person,
        "Percy Liang"^^schema:Person ;
    schema:commentCount "367"^^schema:Integer ;
    schema:dateModified "2020-10-31T23:38:30Z"^^schema:DateTime ;
    schema:datePublished "2018-01-29T02:08:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Certified Defenses against Adversarial Examples"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.09344v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17145877608540180848&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<608> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning can acquire complex behaviors from high-levelspecifications. However, defining a cost function that can be optimizedeffectively and encodes the correct task is challenging in practice. We explorehow inverse optimal control (IOC) can be used to learn behaviors fromdemonstrations, with applications to torque control of high-dimensional roboticsystems. Our method addresses two key challenges in inverse optimal control:first, the need for informative features and effective regularization to imposestructure on the cost, and second, the difficulty of learning the cost functionunder unknown dynamics for high-dimensional continuous systems. To address theformer challenge, we present an algorithm capable of learning arbitrarynonlinear cost functions, such as neural networks, without meticulous featureengineering. To address the latter challenge, we formulate an efficientsample-based approximation for MaxEnt IOC. We evaluate our method on a seriesof simulated tasks and real-world robotic manipulation problems, demonstratingsubstantial improvement over prior methods both in terms of task complexity andsample efficiency."^^schema:Text ;
    schema:author "Chelsea Finn"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "380"^^schema:Integer ;
    schema:dateModified "2016-05-27T16:53:46Z"^^schema:DateTime ;
    schema:datePublished "2016-03-01T20:35:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Guided Cost Learning: Deep Inverse Optimal Control via Policy  Optimization"^^schema:Text ;
    schema:publisher "ICML, 49-58"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1603.00448v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10967669170920763264&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<609> a schema:ScholarlyArticle ;
    schema:abstract "Class imbalance is a common problem in the case of real-world objectdetection and classification tasks. Data of some classes is abundant makingthem an over-represented majority, and data of other classes is scarce, makingthem an under-represented minority. This imbalance makes it challenging for aclassifier to appropriately learn the discriminating boundaries of the majorityand minority classes. In this work, we propose a cost sensitive deep neuralnetwork which can automatically learn robust feature representations for boththe majority and minority classes. During training, our learning procedurejointly optimizes the class dependent costs and the neural network parameters.The proposed approach is applicable to both binary and multi-class problemswithout any modification. Moreover, as opposed to data level approaches, we donot alter the original data distribution which results in a lower computationalcost during the training process. We report the results of our experiments onsix major image classification datasets and show that the proposed approachsignificantly outperforms the baseline algorithms. Comparisons with populardata sampling techniques and cost sensitive classifiers demonstrate thesuperior performance of our proposed method."^^schema:Text ;
    schema:author "Ferdous Sohel"^^schema:Person,
        "Mohammed Bennamoun"^^schema:Person,
        "Munawar Hayat"^^schema:Person,
        "Roberto Togneri"^^schema:Person,
        "Salman H. Khan"^^schema:Person ;
    schema:commentCount "259"^^schema:Integer ;
    schema:dateModified "2017-03-23T10:57:10Z"^^schema:DateTime ;
    schema:datePublished "2015-08-14T05:23:30Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Cost Sensitive Learning of Deep Feature Representations from Imbalanced  Data"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (8), 3573-3587"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1508.03422v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1674347993943612794&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<61> a schema:ScholarlyArticle ;
    schema:abstract "We study characteristics of receptive fields of units in deep convolutionalnetworks. The receptive field size is a crucial issue in many visual tasks, asthe output must respond to large enough areas in the image to captureinformation about large objects. We introduce the notion of an effectivereceptive field, and show that it both has a Gaussian distribution and onlyoccupies a fraction of the full theoretical receptive field. We analyze theeffective receptive field in several architecture designs, and the effect ofnonlinear activations, dropout, sub-sampling and skip connections on it. Thisleads to suggestions for ways to address its tendency to be too small."^^schema:Text ;
    schema:author "Raquel Urtasun"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Wenjie Luo"^^schema:Person,
        "Yujia Li"^^schema:Person ;
    schema:commentCount "407"^^schema:Integer ;
    schema:dateModified "2017-01-25T06:32:29Z"^^schema:DateTime ;
    schema:datePublished "2017-01-15T23:52:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Understanding the Effective Receptive Field in Deep Convolutional Neural  Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1701.04128v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12122802369550112103&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<610> a schema:ScholarlyArticle ;
    schema:abstract "We propose an approach to learn spatio-temporal features in videos fromintermediate visual representations we call \"percepts\" usingGated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on perceptsthat are extracted from all level of a deep convolutional network trained onthe large ImageNet dataset. While high-level percepts contain highlydiscriminative information, they tend to have a low-spatial resolution.Low-level percepts, on the other hand, preserve a higher spatial resolutionfrom which we can model finer motion patterns. Using low-level percepts canleads to high-dimensionality video representations. To mitigate this effect andcontrol the model number of parameters, we introduce a variant of the GRU modelthat leverages the convolution operations to enforce sparse connectivity of themodel units and share parameters across the input spatial locations.  We empirically validate our approach on both Human Action Recognition andVideo Captioning tasks. In particular, we achieve results equivalent tostate-of-art on the YouTube2Text dataset using a simpler text-decoder model andwithout extra 3D CNN features."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Chris Pal"^^schema:Person,
        "Li Yao"^^schema:Person,
        "Nicolas Ballas"^^schema:Person ;
    schema:commentCount "303"^^schema:Integer ;
    schema:dateModified "2016-03-01T18:54:11Z"^^schema:DateTime ;
    schema:datePublished "2015-11-19T22:46:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Delving Deeper into Convolutional Networks for Learning Video  Representations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.06432v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=18128262244324468077&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<611> a schema:ScholarlyArticle ;
    schema:abstract "Generative neural samplers are probabilistic models that implement samplingusing feedforward neural networks: they take a random input vector and producea sample from a probability distribution defined by the network weights. Thesemodels are expressive and allow efficient computation of samples andderivatives, but cannot be used for computing likelihoods or formarginalization. The generative-adversarial training method allows to trainsuch models through the use of an auxiliary discriminative neural network. Weshow that the generative-adversarial approach is a special case of an existingmore general variational divergence estimation approach. We show that anyf-divergence can be used for training generative neural samplers. We discussthe benefits of various choices of divergence functions on training complexityand the quality of the obtained generative models."^^schema:Text ;
    schema:author "Botond Cseke"^^schema:Person,
        "Ryota Tomioka"^^schema:Person,
        "Sebastian Nowozin"^^schema:Person ;
    schema:commentCount "678"^^schema:Integer ;
    schema:dateModified "2016-06-02T14:53:33Z"^^schema:DateTime ;
    schema:datePublished "2016-06-02T14:53:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "f-GAN: Training Generative Neural Samplers using Variational Divergence  Minimization"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1606.00709v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11521929775075838473&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<612> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we prove a conjecture published in 1989 and also partiallyaddress an open problem announced at the Conference on Learning Theory (COLT)2015. With no unrealistic assumption, we first prove the following statementsfor the squared loss function of deep linear neural networks with any depth andany widths: 1) the function is non-convex and non-concave, 2) every localminimum is a global minimum, 3) every critical point that is not a globalminimum is a saddle point, and 4) there exist \"bad\" saddle points (where theHessian has no negative eigenvalue) for the deeper networks (with more thanthree layers), whereas there is no bad saddle point for the shallow networks(with three layers). Moreover, for deep nonlinear neural networks, we prove thesame four statements via a reduction to a deep linear model under theindependence assumption adopted from recent work. As a result, we present aninstance, for which we can answer the following question: how difficult is itto directly train a deep model in theory? It is more difficult than theclassical machine learning models (because of the non-convexity), but not toodifficult (because of the nonexistence of poor local minima). Furthermore, themathematically proven existence of bad saddle points for deeper models wouldsuggest a possible open problem. We note that even though we have advanced thetheoretical foundations of deep learning and non-convex optimization, there isstill a gap between theory and practice."^^schema:Text ;
    schema:author "Kenji Kawaguchi"^^schema:Person ;
    schema:commentCount "512"^^schema:Integer ;
    schema:dateModified "2016-12-27T22:47:50Z"^^schema:DateTime ;
    schema:datePublished "2016-05-23T17:34:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Learning without Poor Local Minima"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.07110v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16088411110075986174&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<613> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a conceptually simple and geometricallyinterpretable objective function, i.e. additive margin Softmax (AM-Softmax),for deep face verification. In general, the face verification task can beviewed as a metric learning problem, so learning large-margin face featureswhose intra-class variation is small and inter-class difference is large is ofgreat importance in order to achieve good performance. Recently, Large-marginSoftmax and Angular Softmax have been proposed to incorporate the angularmargin in a multiplicative manner. In this work, we introduce a novel additiveangular margin for the Softmax loss, which is intuitively appealing and moreinterpretable than the existing works. We also emphasize and discuss theimportance of feature normalization in the paper. Most importantly, ourexperiments on LFW BLUFR and MegaFace show that our additive margin softmaxloss consistently performs better than the current state-of-the-art methodsusing the same network architecture and training dataset. Our code has alsobeen made available at https://github.com/happynear/AMSoftmax"^^schema:Text ;
    schema:author "Feng Wang"^^schema:Person,
        "Haijun Liu"^^schema:Person,
        "Jian Cheng"^^schema:Person,
        "Weiyang Liu"^^schema:Person ;
    schema:commentCount "296"^^schema:Integer ;
    schema:dateModified "2018-05-30T12:35:03Z"^^schema:DateTime ;
    schema:datePublished "2018-01-17T09:13:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Additive Margin Softmax for Face Verification"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1801.05599v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12037509454633593474&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<614> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks have been very successful at predicting sequencesof words in tasks such as language modeling. However, all such models are basedon the conventional classification framework, where the model is trainedagainst one-hot targets, and each word is represented both as an input and asan output in isolation. This causes inefficiencies in learning both in terms ofutilizing all of the information and in terms of the number of parametersneeded to train. We introduce a novel theoretical framework that facilitatesbetter learning in language modeling, and show that our framework leads totying together the input embedding and the output projection matrices, greatlyreducing the number of trainable variables. Our framework leads to state of theart performance on the Penn Treebank with a variety of network models."^^schema:Text ;
    schema:author "Hakan Inan"^^schema:Person,
        "Khashayar Khosravi"^^schema:Person,
        "Richard Socher"^^schema:Person ;
    schema:commentCount "240"^^schema:Integer ;
    schema:dateModified "2017-03-11T19:13:52Z"^^schema:DateTime ;
    schema:datePublished "2016-11-04T17:36:20Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Tying Word Vectors and Word Classifiers: A Loss Framework for Language  Modeling"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01462v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14036439381566283404&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<615> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose the Self-Attention Generative Adversarial Network(SAGAN) which allows attention-driven, long-range dependency modeling for imagegeneration tasks. Traditional convolutional GANs generate high-resolutiondetails as a function of only spatially local points in lower-resolutionfeature maps. In SAGAN, details can be generated using cues from all featurelocations. Moreover, the discriminator can check that highly detailed featuresin distant portions of the image are consistent with each other. Furthermore,recent work has shown that generator conditioning affects GAN performance.Leveraging this insight, we apply spectral normalization to the GAN generatorand find that this improves training dynamics. The proposed SAGAN achieves thestate-of-the-art results, boosting the best published Inception score from 36.8to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on thechallenging ImageNet dataset. Visualization of the attention layers shows thatthe generator leverages neighborhoods that correspond to object shapes ratherthan local regions of fixed shape."^^schema:Text ;
    schema:author "Augustus Odena"^^schema:Person,
        "Dimitris Metaxas"^^schema:Person,
        "Han Zhang"^^schema:Person,
        "Ian Goodfellow"^^schema:Person ;
    schema:commentCount "815"^^schema:Integer ;
    schema:dateModified "2019-06-14T18:20:10Z"^^schema:DateTime ;
    schema:datePublished "2018-05-21T23:10:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Self-Attention Generative Adversarial Networks"^^schema:Text ;
    schema:publisher "ICML, 7354-7363"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1805.08318v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=2966609467730095691&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<616> a schema:ScholarlyArticle ;
    schema:abstract "Probabilistic Boolean Networks (PBNs) were introduced as a computationalmodel for the study of complex dynamical systems, such as Gene RegulatoryNetworks (GRNs). Controllability in this context is the process of makingstrategic interventions to the state of a network in order to drive it towardssome other state that exhibits favourable biological properties. In this paperwe study the ability of a Double Deep Q-Network with Prioritized ExperienceReplay in learning control strategies within a finite number of time steps thatdrive a PBN towards a target state, typically an attractor. The control methodis model-free and does not require knowledge of the network's underlyingdynamics, making it suitable for applications where inference of such dynamicsis intractable. We present extensive experiment results on two synthetic PBNsand the PBN model constructed directly from gene-expression data of a study onmetastatic-melanoma."^^schema:Text ;
    schema:author "Georgios Papagiannis"^^schema:Person,
        "Sotiris Moschoyiannis"^^schema:Person ;
    schema:dateModified "2020-09-07T16:05:20Z"^^schema:DateTime ;
    schema:datePublished "2019-09-07T20:24:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Control of Probabilistic Boolean  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.03331v5"^^schema:URL .

<617> a schema:ScholarlyArticle ;
    schema:abstract "We present an efficient convolution kernel for Convolutional Neural Networks(CNNs) on unstructured grids using parameterized differential operators whilefocusing on spherical signals such as panorama images or planetary signals. Tothis end, we replace conventional convolution kernels with linear combinationsof differential operators that are weighted by learnable parameters.Differential operators can be efficiently estimated on unstructured grids usingone-ring neighbors, and learnable parameters can be optimized through standardback-propagation. As a result, we obtain extremely efficient neural networksthat match or outperform state-of-the-art network architectures in terms ofperformance but with a significantly lower number of network parameters. Weevaluate our algorithm in an extensive series of experiments on a variety ofcomputer vision and climate science tasks, including shape classification,climate pattern segmentation, and omnidirectional image semantic segmentation.Overall, we present (1) a novel CNN approach on unstructured grids usingparameterized differential operators for spherical signals, and (2) we showthat our unique kernel parameterization allows our model to achieve the same orhigher accuracy with significantly fewer network parameters."^^schema:Text ;
    schema:author "Chiyu \"Max\" Jiang"^^schema:Person,
        "Jingwei Huang"^^schema:Person,
        "Karthik Kashinath"^^schema:Person,
        "Matthias Niessner"^^schema:Person,
        "Philip Marcus"^^schema:Person,
        "Prabhat"^^schema:Person ;
    schema:dateModified "2019-01-07T19:56:19Z"^^schema:DateTime ;
    schema:datePublished "2019-01-07T19:56:19Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Spherical CNNs on Unstructured Grids"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.02039v1"^^schema:URL .

<618> a schema:ScholarlyArticle ;
    schema:abstract "Current end-to-end deep Reinforcement Learning (RL) approaches requirejointly learning perception, decision-making and low-level control from verysparse reward signals and high-dimensional inputs, with little capability ofincorporating prior knowledge. This results in prohibitively long trainingtimes for use on real-world robotic tasks. Existing algorithms capable ofextracting task-level representations from high-dimensional inputs, e.g. objectdetection, often produce outputs of varying lengths, restricting their use inRL methods due to the need for neural networks to have fixed length inputs. Inthis work, we propose a framework that combines deep sets encoding, whichallows for variable-length abstract representations, with modular RL thatutilizes these representations, decoupling high-level decision making fromlow-level control. We successfully demonstrate our approach on the robotmanipulation task of object sorting, showing that this method can learneffective policies within mere minutes of highly simplified simulation. Thelearned policies can be directly deployed on a robot without further training,and generalize to variations of the task unseen during training."^^schema:Text ;
    schema:author "Jake Bruce"^^schema:Person,
        "Jürgen Leitner"^^schema:Person,
        "Niko Sünderhauf"^^schema:Person,
        "Robert Lee"^^schema:Person,
        "Serena Mou"^^schema:Person,
        "Vibhavari Dasagi"^^schema:Person ;
    schema:dateModified "2019-10-09T00:21:04Z"^^schema:DateTime ;
    schema:datePublished "2018-09-20T05:09:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Sim-to-Real Transfer of Robot Learning with Variable Length Inputs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.07480v2"^^schema:URL .

<619> a schema:ScholarlyArticle ;
    schema:abstract "Next Point-of-Interest (POI) recommendation is a longstanding problem acrossthe domains of Location-Based Social Networks (LBSN) and transportation. RecentRecurrent Neural Network (RNN) based approaches learn POI-POI relationships ina local view based on independent user visit sequences. This limits the model'sability to directly connect and learn across users in a global view torecommend semantically trained POIs. In this work, we propose aSpatial-Temporal-Preference User Dimensional Graph Attention Network(STP-UDGAT), a novel explore-exploit model that concurrently exploitspersonalized user preferences and explores new POIs in globalspatial-temporal-preference (STP) neighbourhoods, while allowing users toselectively learn from other users. In addition, we propose random walks as amasked self-attention option to leverage the STP graphs' structures and findnew higher-order POI neighbours during exploration. Experimental results on sixreal-world datasets show that our model significantly outperforms baseline andstate-of-the-art methods."^^schema:Text ;
    schema:author "Bryan Hooi"^^schema:Person,
        "Jagannadan Varadarajan"^^schema:Person,
        "Nicholas Lim"^^schema:Person,
        "Renrong Weng"^^schema:Person,
        "See-Kiong Ng"^^schema:Person,
        "Xueou Wang"^^schema:Person,
        "Yong Liang Goh"^^schema:Person ;
    schema:dateModified "2020-10-06T04:03:42Z"^^schema:DateTime ;
    schema:datePublished "2020-10-06T04:03:42Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text ;
    schema:headline "STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention  Network for Next POI Recommendation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.07024v1"^^schema:URL .

<62> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we investigate into the problem of image quality assessment(IQA) and enhancement via machine learning. This issue has long attracted awide range of attention in computational intelligence and image processingcommunities, since, for many practical applications, e.g. object detection andrecognition, raw images are usually needed to be appropriately enhanced toraise the visual quality (e.g. visibility and contrast). In fact, properenhancement can noticeably improve the quality of input images, even betterthan originally captured images which are generally thought to be of the bestquality. In this work, we present two most important contributions. The firstcontribution is to develop a new no-reference (NR) IQA model. Given an image,our quality measure first extracts 17 features through analysis of contrast,sharpness, brightness and more, and then yields a measre of visual qualityusing a regression module, which is learned with big-data training samples thatare much bigger than the size of relevant image datasets. Results ofexperiments on nine datasets validate the superiority and efficiency of ourblind metric compared with typical state-of-the-art full-, reduced- andno-reference IQA methods. The second contribution is that a robust imageenhancement framework is established based on quality optimization. For aninput image, by the guidance of the proposed NR-IQA measure, we conducthistogram modification to successively rectify image brightness and contrast toa proper level. Thorough tests demonstrate that our framework can well enhancenatural images, low-contrast images, low-light images and dehazed images. Thesource code will be released athttps://sites.google.com/site/guke198701/publications."^^schema:Text ;
    schema:author "Dacheng Tao"^^schema:Person,
        "Junfei Qiao"^^schema:Person,
        "Ke Gu"^^schema:Person,
        "Weisi Lin"^^schema:Person ;
    schema:commentCount "150"^^schema:Integer ;
    schema:dateModified "2019-04-18T08:14:24Z"^^schema:DateTime ;
    schema:datePublished "2019-04-18T08:14:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning a No-Reference Quality Assessment Model of Enhanced Images With  Big Data"^^schema:Text ;
    schema:publisher "IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1301-1313"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1904.08632v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9186315539823553743&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<620> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a novel attribute-guided cross-resolution(low-resolution to high-resolution) face recognition framework that leverages acoupled generative adversarial network (GAN) structure with adversarialtraining to find the hidden relationship between the low-resolution andhigh-resolution images in a latent common embedding subspace. The coupled GANframework consists of two sub-networks, one dedicated to the low-resolutiondomain and the other dedicated to the high-resolution domain. Each sub-networkaims to find a projection that maximizes the pair-wise correlation between thetwo feature domains in a common embedding subspace. In addition to projectingthe images into a common subspace, the coupled network also predicts facialattributes to improve the cross-resolution face recognition. Specifically, ourproposed coupled framework exploits facial attributes to further maximize thepair-wise correlation by implicitly matching facial attributes of the low andhigh-resolution images during the training, which leads to a morediscriminative embedding subspace resulting in performance enhancement forcross-resolution face recognition. The efficacy of our approach compared withthe state-of-the-art is demonstrated using the LFWA, Celeb-A, SCFace and UCCSdatasets."^^schema:Text ;
    schema:author "Fariborz Taherkhani"^^schema:Person,
        "Matthew C Valenti"^^schema:Person,
        "Nasser M Nasrabadi"^^schema:Person,
        "Veeru Talreja"^^schema:Person ;
    schema:dateModified "2019-08-05T18:10:55Z"^^schema:DateTime ;
    schema:datePublished "2019-08-05T18:10:55Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Attribute-Guided Coupled GAN for Cross-Resolution Face Recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.01790v1"^^schema:URL .

<621> a schema:ScholarlyArticle ;
    schema:abstract "Federated machine learning which enables resource constrained node devices(e.g., mobile phones and IoT devices) to learn a shared model while keeping thetraining data local, can provide privacy, security and economic benefits bydesigning an effective communication protocol. However, the communicationprotocol amongst different nodes could be exploited by attackers to launch datapoisoning attacks, which has been demonstrated as a big threat to most machinelearning models. In this paper, we attempt to explore the vulnerability offederated machine learning. More specifically, we focus on attacking afederated multi-task learning framework, which is a federated learningframework via adopting a general multi-task learning framework to handlestatistical challenges. We formulate the problem of computing optimal poisoningattacks on federated multi-task learning as a bilevel program that is adaptiveto arbitrary choice of target nodes and source attacking nodes. Then we proposea novel systems-aware optimization method, ATTack on Federated Learning(AT2FL), which is efficiency to derive the implicit gradients for poisoneddata, and further compute optimal attack strategies in the federated machinelearning. Our work is an earlier study that considers issues of data poisoningattack for federated learning. To the end, experimental results on real-worlddatasets show that federated multi-task learning model is very sensitive topoisoning attacks, when the attackers either directly poison the target nodesor indirectly poison the related nodes by exploiting the communicationprotocol."^^schema:Text ;
    schema:author "Gan Sun"^^schema:Person,
        "Ji Liu"^^schema:Person,
        "Jiahua Dong"^^schema:Person,
        "Qiang Wang"^^schema:Person,
        "Yang Cong"^^schema:Person ;
    schema:dateModified "2020-04-19T03:45:05Z"^^schema:DateTime ;
    schema:datePublished "2020-04-19T03:45:05Z"^^schema:DateTime ;
    schema:genre "I.2.11; I.5"^^schema:Text,
        "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Data Poisoning Attacks on Federated Machine Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10020v1"^^schema:URL .

<622> a schema:ScholarlyArticle ;
    schema:abstract "{\\em Hypernetworks} are architectures that produce the weights of atask-specific {\\em primary network}. A notable application of hypernetworks inthe recent literature involves learning to output functional representations.In these scenarios, the hypernetwork learns a representation corresponding tothe weights of a shallow MLP, which typically encodes shape or imageinformation. While such representations have seen considerable success inpractice, they remain lacking in the theoretical guarantees in the wide regimeof the standard architectures. In this work, we study wide over-parameterizedhypernetworks. We show that unlike typical architectures, infinitely widehypernetworks do not guarantee convergence to a global minima under gradientdescent. We further show that convexity can be achieved by increasing thedimensionality of the hypernetwork's output, to represent wide MLPs. In thedually infinite-width regime, we identify the functional priors of thesearchitectures by deriving their corresponding GP and NTK kernels, the latter ofwhich we refer to as the {\\em hyperkernel}. As part of this study, we make amathematical contribution by deriving tight bounds on high order Taylorexpansion terms of standard fully connected ReLU networks."^^schema:Text ;
    schema:author "Etai Littwin"^^schema:Person,
        "Greg Yang"^^schema:Person,
        "Lior Wolf"^^schema:Person,
        "Tomer Galanti"^^schema:Person ;
    schema:dateModified "2020-11-03T08:00:21Z"^^schema:DateTime ;
    schema:datePublished "2020-03-27T00:50:29Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Infinite-Width Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.12193v6"^^schema:URL .

<623> a schema:ScholarlyArticle ;
    schema:abstract "Variational autoencoders~(VAEs) have shown a promise in data-drivenconversation modeling. However, most VAE conversation models match theapproximate posterior distribution over the latent variables to a simple priorsuch as standard normal distribution, thereby restricting the generatedresponses to a relatively simple (e.g., unimodal) scope. In this paper, wepropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) speciallydesigned for dialogue modeling. Unlike VAEs that impose a simple distributionover the latent variables, DialogWAE models the distribution of data bytraining a GAN within the latent variable space. Specifically, our modelsamples from the prior and posterior distributions over the latent variables bytransforming context-dependent random noise using neural networks and minimizesthe Wasserstein distance between the two distributions. We further develop aGaussian mixture prior network to enrich the latent space. Experiments on twopopular datasets show that DialogWAE outperforms the state-of-the-artapproaches in generating more coherent, informative and diverse responses."^^schema:Text ;
    schema:author "Jung-Woo Ha"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Sunghun Kim"^^schema:Person,
        "Xiaodong Gu"^^schema:Person ;
    schema:dateModified "2019-02-26T02:32:44Z"^^schema:DateTime ;
    schema:datePublished "2018-05-31T07:25:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "DialogWAE: Multimodal Response Generation with Conditional Wasserstein  Auto-Encoder"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.12352v2"^^schema:URL .

<624> a schema:ScholarlyArticle ;
    schema:abstract "Recently, real-world recommendation systems need to deal with millions ofcandidates. It is extremely challenging to conduct sophisticated end-to-endalgorithms on the entire corpus due to the tremendous computation costs.Therefore, conventional recommendation systems usually contain two modules. Thematching module focuses on the coverage, which aims to efficiently retrievehundreds of items from large corpora, while the ranking module generatesspecific ranks for these items. Recommendation diversity is an essential factorthat impacts user experience. Most efforts have explored recommendationdiversity in ranking, while the matching module should take more responsibilityfor diversity. In this paper, we propose a novel Heterogeneous graph neuralnetwork framework for diversified recommendation (GraphDR) in matching toimprove both recommendation accuracy and diversity. Specifically, GraphDRbuilds a huge heterogeneous preference network to record different types ofuser preferences, and conduct a field-level heterogeneous graph attentionnetwork for node aggregation. We also innovatively conduct aneighbor-similarity based loss to balance both recommendation accuracy anddiversity for the diversified matching task. In experiments, we conductextensive online and offline evaluations on a real-world recommendation systemwith various accuracy and diversity metrics and achieve significantimprovements. We also conduct model analyses and case study for a betterunderstanding of our model. Moreover, GraphDR has been deployed on a well-knownrecommendation system, which affects millions of users. The source code will bereleased."^^schema:Text ;
    schema:author "Bo Zhang"^^schema:Person,
        "Leyu Lin"^^schema:Person,
        "Peng Cui"^^schema:Person,
        "Qi Liu"^^schema:Person,
        "Ruobing Xie"^^schema:Person,
        "Shukai Liu"^^schema:Person,
        "Ziwei Zhang"^^schema:Person ;
    schema:dateModified "2021-02-07T12:14:18Z"^^schema:DateTime ;
    schema:datePublished "2021-02-07T12:14:18Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text ;
    schema:headline "Improving Accuracy and Diversity in Matching of Recommendation with  Diversified Preference Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.03787v1"^^schema:URL .

<625> a schema:ScholarlyArticle ;
    schema:abstract "Partially observable environments present an important open challenge in thedomain of sequential control learning with delayed rewards. Despite numerousattempts during the two last decades, the majority of reinforcement learningalgorithms and associated approximate models, applied to this context, stillassume Markovian state transitions. In this paper, we explore the use of arecently proposed attention-based model, the Gated End-to-End Memory Network,for sequential control. We call the resulting model the Gated End-to-End MemoryPolicy Network. More precisely, we use a model-free value-based algorithm tolearn policies for partially observed domains using this memory-enhanced neuralnetwork. This model is end-to-end learnable and it features unbounded memory.Indeed, because of its attention mechanism and associated non-parametricmemory, the proposed model allows us to define an attention mechanism over theobservation stream unlike recurrent models. We show encouraging results thatillustrate the capability of our attention-based model in the context of thecontinuous-state non-stationary control problem of stock trading. We alsopresent an OpenAI Gym environment for simulated stock exchange and explain itsrelevance as a benchmark for the field of non-Markovian decision processlearning."^^schema:Text ;
    schema:author "Julien Perez"^^schema:Person,
        "Tomi Silander"^^schema:Person ;
    schema:dateModified "2017-05-31T09:00:44Z"^^schema:DateTime ;
    schema:datePublished "2017-05-31T09:00:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Non-Markovian Control with Gated End-to-End Memory Policy Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1705.10993v1"^^schema:URL .

<626> a schema:ScholarlyArticle ;
    schema:abstract "We propose high-order hypergraph walks as a framework to generalizegraph-based network science techniques to hypergraphs. Edge incidence inhypergraphs is quantitative, yielding hypergraph walks with both length andwidth. Graph methods which then generalize to hypergraphs include connectedcomponent analyses, graph distance-based metrics such as closeness centrality,and motif-based measures such as clustering coefficients. We apply high-orderanalogs of these methods to real world hypernetworks, and show they revealnuanced and interpretable structure that cannot be detected by graph-basedmethods. Lastly, we apply three generative models to the data and find thatbasic hypergraph properties, such as density and degree distributions, do notnecessarily control these new structural measurements. Our work demonstrateshow analyses of hypergraph-structured data are richer when utilizing toolstailored to capture hypergraph-native phenomena, and suggests one possibleavenue towards that end."^^schema:Text ;
    schema:author "Brenda Praggastis"^^schema:Person,
        "Carlos Ortiz Marrero"^^schema:Person,
        "Cliff Joslyn"^^schema:Person,
        "Emilie Purvine"^^schema:Person,
        "Sinan G. Aksoy"^^schema:Person ;
    schema:dateModified "2020-06-08T17:02:26Z"^^schema:DateTime ;
    schema:datePublished "2019-06-26T18:52:33Z"^^schema:DateTime ;
    schema:genre "cs.SI"^^schema:Text,
        "physics.data-an"^^schema:Text,
        "physics.soc-ph"^^schema:Text ;
    schema:headline "Hypernetwork Science via High-Order Hypergraph Walks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.11295v2"^^schema:URL .

<627> a schema:ScholarlyArticle ;
    schema:abstract "A major challenge in computed tomography (CT) is how to minimize patientradiation exposure without compromising image quality and diagnosticperformance. The use of deep convolutional (Conv) neural networks for noisereduction in Low-Dose CT (LDCT) images has recently shown a great potential inthis important application. In this paper, we present a highly efficient andeffective neural network model for LDCT image noise reduction. Specifically, tocapture local anatomical features we integrate Deep Convolutional NeuralNetworks (CNNs) and Skip connection layers for feature extraction. Also, weintroduce parallelized $1\\times 1$ CNN, called Network in Network, to lower thedimensionality of the output from the previous layer, achieving fastercomputational speed at less feature loss. To optimize the performance of thenetwork, we adopt a Wasserstein generative adversarial network (WGAN)framework. Quantitative and qualitative comparisons demonstrate that ourproposed network model can produce images with lower noise and more structuraldetails than state-of-the-art noise-reduction methods."^^schema:Text ;
    schema:author "Chenyu You"^^schema:Person,
        "Ge Wang"^^schema:Person,
        "Linfeng Yang"^^schema:Person,
        "Yi Zhang"^^schema:Person ;
    schema:dateModified "2019-08-03T02:53:26Z"^^schema:DateTime ;
    schema:datePublished "2018-11-26T18:08:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Low-Dose CT via Deep CNN with Skip Connection and Network in Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.10564v2"^^schema:URL .

<628> a schema:ScholarlyArticle ;
    schema:abstract "Concerned with the reliability of neural networks, researchers have developedverification techniques to prove their robustness. Most verifiers work withreal-valued networks. Unfortunately, the exact (complete and sound) verifiersface scalability challenges and provide no correctness guarantees due tofloating point errors. We argue that Binarized Neural Networks (BNNs) providecomparable robustness and allow exact and significantly more efficientverification. We present a new system, EEV, for efficient and exactverification of BNNs. EEV consists of two parts: (i) a novel SAT solver thatspeeds up BNN verification by natively handling the reified cardinalityconstraints arising in BNN encodings; and (ii) strategies to trainsolver-friendly robust BNNs by inducing balanced layer-wise sparsity and lowcardinality bounds, and adaptively cancelling the gradients. We demonstrate theeffectiveness of EEV by presenting the first exact verification results forL-inf-bounded adversarial robustness of nontrivial convolutional BNNs on theMNIST and CIFAR10 datasets. Compared to exact verification of real-valuednetworks of the same architectures on the same tasks, EEV verifies BNNshundreds to thousands of times faster, while delivering comparable verifiableaccuracy in most cases."^^schema:Text ;
    schema:author "Kai Jia"^^schema:Person,
        "Martin Rinard"^^schema:Person ;
    schema:dateModified "2020-10-27T04:00:16Z"^^schema:DateTime ;
    schema:datePublished "2020-05-07T16:34:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.LO"^^schema:Text,
        "cs.SC"^^schema:Text ;
    schema:headline "Efficient Exact Verification of Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.03597v2"^^schema:URL .

<629> a schema:ScholarlyArticle ;
    schema:abstract "Classifying human cognitive states from behavioral and physiological signalsis a challenging problem with important applications in robotics. The problemis challenging due to the data variability among individual users, and sensorartefacts. In this work, we propose an end-to-end framework for real-timecognitive workload classification with mixture Hyper Long Short Term MemoryNetworks, a novel variant of HyperNetworks. Evaluating the proposed approach onan eye-gaze pattern dataset collected from simulated driving scenarios ofdifferent cognitive demands, we show that the proposed framework outperformsprevious baseline methods and achieves 83.9\\% precision and 87.8\\% recallduring test. We also demonstrate the merit of our proposed architecture byshowing improved performance over other LSTM-based methods."^^schema:Text ;
    schema:author "Pierluigi V. Amadori"^^schema:Person,
        "Ruohan Wang"^^schema:Person,
        "Yiannis Demiris"^^schema:Person ;
    schema:dateModified "2018-10-07T13:57:25Z"^^schema:DateTime ;
    schema:datePublished "2018-10-07T13:57:25Z"^^schema:DateTime ;
    schema:genre "cs.HC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Real-Time Workload Classification during Driving using HyperNetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.03145v1"^^schema:URL .

<63> a schema:ScholarlyArticle ;
    schema:abstract "Large, labeled datasets have driven deep learning methods to achieveexpert-level performance on a variety of medical imaging tasks. We presentCheXpert, a large dataset that contains 224,316 chest radiographs of 65,240patients. We design a labeler to automatically detect the presence of 14observations in radiology reports, capturing uncertainties inherent inradiograph interpretation. We investigate different approaches to using theuncertainty labels for training convolutional neural networks that output theprobability of these observations given the available frontal and lateralradiographs. On a validation set of 200 chest radiographic studies which weremanually annotated by 3 board-certified radiologists, we find that differentuncertainty approaches are useful for different pathologies. We then evaluateour best model on a test set composed of 500 chest radiographic studiesannotated by a consensus of 5 board-certified radiologists, and compare theperformance of our model to that of 3 additional radiologists in the detectionof 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, themodel ROC and PR curves lie above all 3 radiologist operating points. Werelease the dataset to the public as a standard benchmark to evaluateperformance of chest radiograph interpretation models.  The dataset is freely available athttps://stanfordmlgroup.github.io/competitions/chexpert ."^^schema:Text ;
    schema:author "Andrew Y. Ng"^^schema:Person,
        "Behzad Haghgoo"^^schema:Person,
        "Bhavik N. Patel"^^schema:Person,
        "Chris Chute"^^schema:Person,
        "Curtis P. Langlotz"^^schema:Person,
        "David A. Mong"^^schema:Person,
        "David B. Larson"^^schema:Person,
        "Henrik Marklund"^^schema:Person,
        "Jayne Seekins"^^schema:Person,
        "Jeremy Irvin"^^schema:Person,
        "Jesse K. Sandberg"^^schema:Person,
        "Katie Shpanskaya"^^schema:Person,
        "Matthew P. Lungren"^^schema:Person,
        "Michael Ko"^^schema:Person,
        "Pranav Rajpurkar"^^schema:Person,
        "Ricky Jones"^^schema:Person,
        "Robyn Ball"^^schema:Person,
        "Safwan S. Halabi"^^schema:Person,
        "Silviana Ciurea-Ilcus"^^schema:Person,
        "Yifan Yu"^^schema:Person ;
    schema:commentCount "163"^^schema:Integer ;
    schema:dateModified "2019-01-21T18:41:59Z"^^schema:DateTime ;
    schema:datePublished "2019-01-21T18:41:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and  Expert Comparison"^^schema:Text ;
    schema:publisher "Proceedings of the AAAI Conference on Artificial Intelligence 33, 590-597"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1901.07031v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6830093712704163164&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<630> a schema:ScholarlyArticle ;
    schema:abstract "Recent work on mode connectivity in the loss landscape of deep neuralnetworks has demonstrated that the locus of (sub-)optimal weight vectors lieson continuous paths. In this work, we train a neural network that serves as ahypernetwork, mapping a latent vector into high-performance (low-loss) weightvectors, generalizing recent findings of mode connectivity to higherdimensional manifolds. We formulate the training objective as a compromisebetween accuracy and diversity, where the diversity takes into account trivialsymmetry transformations of the target network. We demonstrate how to reducethe number of parameters in the hypernetwork by parameter sharing. Oncelearned, the hypernetwork allows for a computationally efficient, ancestralsampling of neural network weights, which we recruit to form large ensembles.The improvement in classification accuracy obtained by this ensemblingindicates that the generated manifold extends in dimensions other thandirections implied by trivial symmetries. For computational efficiency, wedistill an ensemble into a single classifier while retaining generalization."^^schema:Text ;
    schema:author "Erik Nijkamp"^^schema:Person,
        "Lior Deutsch"^^schema:Person,
        "Yu Yang"^^schema:Person ;
    schema:dateModified "2019-05-07T04:28:46Z"^^schema:DateTime ;
    schema:datePublished "2019-05-07T04:28:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Generative Model for Sampling High-Performance and Diverse Weights for  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.02898v1"^^schema:URL .

<631> a schema:ScholarlyArticle ;
    schema:abstract "We show that hypernetworks can be regarded as posets which, in their turn,have a natural interpretation as simplicial complexes and, as such, are endowedwith an intrinsic notion of curvature, namely the Forman Ricci curvature, thatstrongly correlates with the Euler characteristic of the simplicial complex.This approach, inspired by the work of E. Bloch, allows us to canonicallyassociate a simplicial complex structure to a hypernetwork, directed orundirected. In particular, this greatly simplifying the geometric PersistentHomology method we previously proposed."^^schema:Text ;
    schema:author "Emil Saucan"^^schema:Person ;
    schema:dateModified "2021-01-16T10:57:38Z"^^schema:DateTime ;
    schema:datePublished "2021-01-16T10:57:38Z"^^schema:DateTime ;
    schema:genre "53Z50, 57Q70 55N31, 05C82"^^schema:Text,
        "cs.CG"^^schema:Text,
        "cs.SI"^^schema:Text,
        "math.AT"^^schema:Text,
        "math.DG"^^schema:Text ;
    schema:headline "Hypernetworks: From Posets to Geometry"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.06429v1"^^schema:URL .

<632> a schema:ScholarlyArticle ;
    schema:abstract "Lung disease is common throughout the world. These include chronicobstructive pulmonary disease, pneumonia, asthma, tuberculosis, fibrosis, etc.Timely diagnosis of lung disease is essential. Many image processing andmachine learning models have been developed for this purpose. Different formsof existing deep learning techniques including convolutional neural network(CNN), vanilla neural network, visual geometry group based neural network(VGG), and capsule network are applied for lung disease prediction.The basicCNN has poor performance for rotated, tilted, or other abnormal imageorientation. Therefore, we propose a new hybrid deep learning framework bycombining VGG, data augmentation and spatial transformer network (STN) withCNN. This new hybrid method is termed here as VGG Data STN with CNN (VDSNet).As implementation tools, Jupyter Notebook, Tensorflow, and Keras are used. Thenew model is applied to NIH chest X-ray image dataset collected from Kagglerepository. Full and sample versions of the dataset are considered. For bothfull and sample datasets, VDSNet outperforms existing methods in terms of anumber of metrics including precision, recall, F0.5 score and validationaccuracy. For the case of full dataset, VDSNet exhibits a validation accuracyof 73%, while vanilla gray, vanilla RGB, hybrid CNN and VGG, and modifiedcapsule network have accuracy values of 67.8%, 69%, 69.5%, 60.5% and 63.8%,respectively. When sample dataset rather than full dataset is used, VDSNetrequires much lower training time at the expense of a slightly lower validationaccuracy. Hence, the proposed VDSNet framework will simplify the detection oflung disease for experts as well as for doctors."^^schema:Text ;
    schema:author "M. Rubaiyat Hossain Mondal"^^schema:Person,
        "Prajoy Podder"^^schema:Person,
        "Subrato Bharati"^^schema:Person ;
    schema:dateModified "2020-07-01T17:31:27Z"^^schema:DateTime ;
    schema:datePublished "2020-03-02T06:07:30Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Hybrid Deep Learning for Detecting Lung Diseases from X-ray Images"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.00682v3"^^schema:URL .

<633> a schema:ScholarlyArticle ;
    schema:abstract "Combining the Information Bottleneck model with deep learning by replacingmutual information terms with deep neural nets has proved successful in areasranging from generative modelling to interpreting deep neural networks. In thispaper, we revisit the Deep Variational Information Bottleneck and theassumptions needed for its derivation. The two assumed properties of the data$X$, $Y$ and their latent representation $T$ take the form of two Markov chains$T-X-Y$ and $X-T-Y$. Requiring both to hold during the optimisation process canbe limiting for the set of potential joint distributions $P(X,Y,T)$. Wetherefore show how to circumvent this limitation by optimising a lower boundfor $I(T;Y)$ for which only the latter Markov chain has to be satisfied. Theactual mutual information consists of the lower bound which is optimised inDVIB and cognate models in practice and of two terms measuring how much theformer requirement $T-X-Y$ is violated. Finally, we propose to interpret thefamily of information bottleneck models as directed graphical models and showthat in this framework the original and deep information bottlenecks arespecial cases of a fundamental IB model."^^schema:Text ;
    schema:author "Aleksander Wieczorek"^^schema:Person,
        "Volker Roth"^^schema:Person ;
    schema:dateModified "2019-12-31T18:31:42Z"^^schema:DateTime ;
    schema:datePublished "2019-12-31T18:31:42Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Difference Between the Information Bottleneck and the Deep  Information Bottleneck"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.13480v1"^^schema:URL .

<634> a schema:ScholarlyArticle ;
    schema:abstract "Local processing is an essential feature of CNNs and other neural networkarchitectures - it is one of the reasons why they work so well on images whererelevant information is, to a large extent, local. However, perspective effectsstemming from the projection in a conventional camera vary for different globalpositions in the image. We introduce Perspective Crop Layers (PCLs) - a form ofperspective crop of the region of interest based on the camera geometry - andshow that accounting for the perspective consistently improves the accuracy ofstate-of-the-art 3D pose reconstruction methods. PCLs are modular neuralnetwork layers, which, when inserted into existing CNN and MLP architectures,deterministically remove the location-dependent perspective effects whileleaving end-to-end training and the number of parameters of the underlyingneural network unchanged. We demonstrate that PCL leads to improved 3D humanpose reconstruction accuracy for CNN architectures that use croppingoperations, such as spatial transformer networks (STN), and, somewhatsurprisingly, MLPs used for 2D-to-3D keypoint lifting. Our conclusion is thatit is important to utilize camera calibration information when available, forclassical and deep-learning-based computer vision alike. PCL offers an easy wayto improve the accuracy of existing 3D reconstruction networks by making themgeometry-aware."^^schema:Text ;
    schema:author "Frank Yu"^^schema:Person,
        "Helge Rhodin"^^schema:Person,
        "Mathieu Salzmann"^^schema:Person,
        "Pascal Fua"^^schema:Person ;
    schema:dateModified "2020-11-27T08:48:43Z"^^schema:DateTime ;
    schema:datePublished "2020-11-27T08:48:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective  Crop Layers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13607v1"^^schema:URL .

<635> a schema:ScholarlyArticle ;
    schema:abstract "Despite recent advances, the remaining bottlenecks in deep generative modelsare necessity of extensive training and difficulties with generalization fromsmall number of training examples. We develop a new generative model calledGenerative Matching Network which is inspired by the recently proposed matchingnetworks for one-shot learning in discriminative tasks. By conditioning on theadditional input dataset, our model can instantly learn new concepts that werenot available in the training data but conform to a similar generative process.The proposed framework does not explicitly restrict diversity of theconditioning data and also does not require an extensive inference procedurefor training or adaptation. Our experiments on the Omniglot dataset demonstratethat Generative Matching Networks significantly improve predictive performanceon the fly as more additional data is available and outperform existing stateof the art conditional generative models."^^schema:Text ;
    schema:author "Dmitry P. Vetrov"^^schema:Person,
        "Sergey Bartunov"^^schema:Person ;
    schema:dateModified "2017-09-05T07:41:15Z"^^schema:DateTime ;
    schema:datePublished "2016-12-07T10:50:37Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.5"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Fast Adaptation in Generative Models with Generative Matching Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1612.02192v2"^^schema:URL .

<636> a schema:ScholarlyArticle ;
    schema:abstract "Very deep convolutional networks with hundreds of layers have led tosignificant reductions in error on competitive benchmarks. Although theunmatched expressiveness of the many layers can be highly desirable at testtime, training very deep networks comes with its own set of challenges. Thegradients can vanish, the forward flow often diminishes, and the training timecan be painfully slow. To address these problems, we propose stochastic depth,a training procedure that enables the seemingly contradictory setup to trainshort networks and use deep networks at test time. We start with very deepnetworks but during training, for each mini-batch, randomly drop a subset oflayers and bypass them with the identity function. This simple approachcomplements the recent success of residual networks. It reduces training timesubstantially and improves the test error significantly on almost all data setsthat we used for evaluation. With stochastic depth we can increase the depth ofresidual networks even beyond 1200 layers and still yield meaningfulimprovements in test error (4.91% on CIFAR-10)."^^schema:Text ;
    schema:author "Daniel Sedra"^^schema:Person,
        "Gao Huang"^^schema:Person,
        "Kilian Weinberger"^^schema:Person,
        "Yu Sun"^^schema:Person,
        "Zhuang Liu"^^schema:Person ;
    schema:dateModified "2016-07-28T23:24:16Z"^^schema:DateTime ;
    schema:datePublished "2016-03-30T20:58:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Deep Networks with Stochastic Depth"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1603.09382v3"^^schema:URL .

<637> a schema:ScholarlyArticle ;
    schema:abstract "The goal of imitation learning is to mimic expert behavior without access toan explicit reward signal. Expert demonstrations provided by humans, however,often show significant variability due to latent factors that are typically notexplicitly modeled. In this paper, we propose a new algorithm that can inferthe latent structure of expert demonstrations in an unsupervised way. Ourmethod, built on top of Generative Adversarial Imitation Learning, can not onlyimitate complex behaviors, but also learn interpretable and meaningfulrepresentations of complex behavioral data, including visual demonstrations. Inthe driving domain, we show that a model learned from human demonstrations isable to both accurately reproduce a variety of behaviors and accuratelyanticipate human actions using raw visual inputs. Compared with variousbaselines, our method can better capture the latent structure underlying expertdemonstrations, often recovering semantically meaningful factors of variationin the data."^^schema:Text ;
    schema:author "Jiaming Song"^^schema:Person,
        "Stefano Ermon"^^schema:Person,
        "Yunzhu Li"^^schema:Person ;
    schema:dateModified "2017-11-14T21:51:21Z"^^schema:DateTime ;
    schema:datePublished "2017-03-26T16:20:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1703.08840v2"^^schema:URL .

<638> a schema:ScholarlyArticle ;
    schema:abstract "This work presents a novel back-end framework for speaker verification usinggraph attention networks. Segment-wise speaker embeddings extracted frommultiple crops within an utterance are interpreted as node representations of agraph. The proposed framework inputs segment-wise speaker embeddings from anenrollment and a test utterance and directly outputs a similarity score. Wefirst construct a graph using segment-wise speaker embeddings and then inputthese to graph attention networks. After a few graph attention layers withresidual connections, each node is projected into a one-dimensional space usingaffine transform, followed by a readout operation resulting in a scalarsimilarity score. To enable successful adaptation for speaker verification, wepropose techniques such as separating trainable weights for attention mapcalculations between segment-wise speaker embeddings from different utterances.The effectiveness of the proposed framework is validated using three differentspeaker embedding extractors trained with different architectures and objectivefunctions. Experimental results demonstrate consistent improvement over variousbaseline back-end classifiers, with an average equal error rate improvement of20% over the cosine similarity back-end without test time augmentation."^^schema:Text ;
    schema:author "Ha-Jin Yu"^^schema:Person,
        "Hee-Soo Heo"^^schema:Person,
        "Jee-weon Jung"^^schema:Person,
        "Joon Son Chung"^^schema:Person ;
    schema:dateModified "2021-02-08T08:12:17Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T09:08:02Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Graph Attention Networks for Speaker Verification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11543v2"^^schema:URL .

<639> a schema:ScholarlyArticle ;
    schema:abstract "Learning to imitate expert behavior from demonstrations can be challenging,especially in environments with high-dimensional, continuous observations andunknown dynamics. Supervised learning methods based on behavioral cloning (BC)suffer from distribution shift: because the agent greedily imitatesdemonstrated actions, it can drift away from demonstrated states due to erroraccumulation. Recent methods based on reinforcement learning (RL), such asinverse RL and generative adversarial imitation learning (GAIL), overcome thisissue by training an RL agent to match the demonstrations over a long horizon.Since the true reward function for the task is unknown, these methods learn areward function from the demonstrations, often using complex and brittleapproximation techniques that involve adversarial training. We propose a simplealternative that still uses RL, but does not require learning a rewardfunction. The key idea is to provide the agent with an incentive to match thedemonstrations over a long horizon, by encouraging it to return to demonstratedstates upon encountering new, out-of-distribution states. We accomplish this bygiving the agent a constant reward of r=+1 for matching the demonstrated actionin a demonstrated state, and a constant reward of r=0 for all other behavior.Our method, which we call soft Q imitation learning (SQIL), can be implementedwith a handful of minor modifications to any standard Q-learning or off-policyactor-critic algorithm. Theoretically, we show that SQIL can be interpreted asa regularized variant of BC that uses a sparsity prior to encouragelong-horizon imitation. Empirically, we show that SQIL outperforms BC andachieves competitive results compared to GAIL, on a variety of image-based andlow-dimensional tasks in Box2D, Atari, and MuJoCo."^^schema:Text ;
    schema:author "Anca D. Dragan"^^schema:Person,
        "Sergey Levine"^^schema:Person,
        "Siddharth Reddy"^^schema:Person ;
    schema:dateModified "2019-09-25T18:44:47Z"^^schema:DateTime ;
    schema:datePublished "2019-05-27T10:29:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11108v3"^^schema:URL .

<64> a schema:ScholarlyArticle ;
    schema:abstract "Tuning hyperparameters of learning algorithms is hard because gradients areusually unavailable. We compute exact gradients of cross-validation performancewith respect to all hyperparameters by chaining derivatives backwards throughthe entire training procedure. These gradients allow us to optimize thousandsof hyperparameters, including step-size and momentum schedules, weightinitialization distributions, richly parameterized regularization schemes, andneural network architectures. We compute hyperparameter gradients by exactlyreversing the dynamics of stochastic gradient descent with momentum."^^schema:Text ;
    schema:author "David Duvenaud"^^schema:Person,
        "Dougal Maclaurin"^^schema:Person,
        "Ryan P. Adams"^^schema:Person ;
    schema:commentCount "357"^^schema:Integer ;
    schema:dateModified "2015-04-02T17:40:44Z"^^schema:DateTime ;
    schema:datePublished "2015-02-11T23:52:36Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gradient-based Hyperparameter Optimization through Reversible Learning"^^schema:Text ;
    schema:publisher "ICML, 2113-2122"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.03492v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16427522673612533152&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<640> a schema:ScholarlyArticle ;
    schema:abstract "When the training and test data are from different distributions, domainadaptation is needed to reduce dataset bias to improve the model'sgeneralization ability. Since it is difficult to directly match thecross-domain joint distributions, existing methods tend to reduce the marginalor conditional distribution divergence using predefined distances such as MMDand adversarial-based discrepancies. However, it remains challenging todetermine which method is suitable for a given application since they are builtwith certain priors or bias. Thus they may fail to uncover the underlyingrelationship between transferable features and joint distributions. This paperproposes Learning to Match (L2M) to automatically learn the cross-domaindistribution matching without relying on hand-crafted priors on the matchingloss. Instead, L2M reduces the inductive bias by using a meta-network to learnthe distribution matching loss in a data-driven way. L2M is a general frameworkthat unifies task-independent and human-designed matching features. We design anovel optimization algorithm for this challenging objective withself-supervised label propagation. Experiments on public datasets substantiatethe superiority of L2M over SOTA methods. Moreover, we apply L2M to transferfrom pneumonia to COVID-19 chest X-ray images with remarkable performance. L2Mcan also be extended in other distribution matching applications where we showin a trial experiment that L2M generates more realistic and sharper MNISTsamples."^^schema:Text ;
    schema:author "Chang Liu"^^schema:Person,
        "Chaohui Yu"^^schema:Person,
        "Jindong Wang"^^schema:Person,
        "Renjun Xu"^^schema:Person,
        "Tao Qin"^^schema:Person,
        "Tie-Yan Liu"^^schema:Person,
        "Wenjie Feng"^^schema:Person,
        "Yiqiang Chen"^^schema:Person ;
    schema:dateModified "2020-07-27T01:44:38Z"^^schema:DateTime ;
    schema:datePublished "2020-07-17T03:26:13Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning to Match Distributions for Domain Adaptation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.10791v3"^^schema:URL .

<641> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a binarized neural network learning method calledBiDet for efficient object detection. Conventional network binarization methodsdirectly quantize the weights and activations in one-stage or two-stagedetectors with constrained representational capacity, so that the informationredundancy in the networks causes numerous false positives and degrades theperformance significantly. On the contrary, our BiDet fully utilizes therepresentational capacity of the binary neural networks for object detection byredundancy removal, through which the detection precision is enhanced withalleviated false positives. Specifically, we generalize the informationbottleneck (IB) principle to object detection, where the amount of informationin the high-level feature maps is constrained and the mutual informationbetween the feature maps and object detection is maximized. Meanwhile, we learnsparse object priors so that the posteriors are concentrated on informativedetection prediction with false positive elimination. Extensive experiments onthe PASCAL VOC and COCO datasets show that our method outperforms thestate-of-the-art binary neural networks by a sizable margin."^^schema:Text ;
    schema:author "Jie Zhou"^^schema:Person,
        "Jiwen Lu"^^schema:Person,
        "Ziwei Wang"^^schema:Person,
        "Ziyi Wu"^^schema:Person ;
    schema:dateModified "2020-03-09T08:16:16Z"^^schema:DateTime ;
    schema:datePublished "2020-03-09T08:16:16Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "BiDet: An Efficient Binarized Object Detector"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03961v1"^^schema:URL .

<642> a schema:ScholarlyArticle ;
    schema:abstract "This paper demonstrates a method for tensorizing neural networks based uponan efficient way of approximating scale invariant quantum states, theMulti-scale Entanglement Renormalization Ansatz (MERA). We employ MERA as areplacement for the fully connected layers in a convolutional neural networkand test this implementation on the CIFAR-10 and CIFAR-100 datasets. Theproposed method outperforms factorization using tensor trains, providinggreater compression for the same level of accuracy and greater accuracy for thesame level of compression. We demonstrate MERA layers with 14000 times fewerparameters and a reduction in accuracy of less than 1% compared to theequivalent fully connected layers, scaling like O(N)."^^schema:Text ;
    schema:author "Andrew G. Green"^^schema:Person,
        "Andrew Hallam"^^schema:Person,
        "Edward Grant"^^schema:Person,
        "Simone Severini"^^schema:Person,
        "Vid Stojevic"^^schema:Person ;
    schema:dateModified "2018-12-12T23:55:50Z"^^schema:DateTime ;
    schema:datePublished "2017-11-09T12:55:59Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text,
        "quant-ph"^^schema:Text ;
    schema:headline "Compact Neural Networks based on the Multiscale Entanglement  Renormalization Ansatz"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.03357v3"^^schema:URL .

<643> a schema:ScholarlyArticle ;
    schema:abstract "Customer services are critical to all companies, as they may directly connectto the brand reputation. Due to a great number of customers, e-commercecompanies often employ multiple communication channels to answer customers'questions, for example, chatbot and hotline. On one hand, each channel haslimited capacity to respond to customers' requests, on the other hand,customers have different preferences over these channels. The currentproduction systems are mainly built based on business rules, which merelyconsiders tradeoffs between resources and customers' satisfaction. To achievethe optimal tradeoff between resources and customers' satisfaction, we proposea new framework based on deep reinforcement learning, which directly takes bothresources and user model into account. In addition to the framework, we alsopropose a new deep-reinforcement-learning based routing method-double duelingdeep Q-learning with prioritized experience replay (PER-DoDDQN). We evaluateour proposed framework and method using both synthetic and a real customerservice log data from a large financial technology company. We show that ourproposed deep-reinforcement-learning based framework is superior to theexisting production system. Moreover, we also show our proposed PER-DoDDQN isbetter than all other deep Q-learning variants in practice, which provides amore optimal routing plan. These observations suggest that our proposed methodcan seek the trade-off where both channel resources and customers' satisfactionare optimal."^^schema:Text ;
    schema:author "Chong Long"^^schema:Person,
        "Jie Zhang"^^schema:Person,
        "Xiaolu Lu"^^schema:Person,
        "Yafang Wang"^^schema:Person,
        "Zehong Hu"^^schema:Person,
        "Zining Liu"^^schema:Person ;
    schema:dateModified "2019-11-24T12:57:03Z"^^schema:DateTime ;
    schema:datePublished "2019-11-24T12:57:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Which Channel to Ask My Question? Personalized Customer Service Request  Stream Routing using Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.10521v1"^^schema:URL .

<644> a schema:ScholarlyArticle ;
    schema:abstract "The longitudinal analysis of patient response time course following doses oftherapeutics is currently performed using Pharmacokinetic/Pharmacodynamic(PK/PD) methodologies, which requires significant human experience andexpertise in the modeling of dynamical systems. By utilizing recentadvancements in deep learning, we show that the governing differentialequations can be learnt directly from longitudinal patient data. In particular,we propose a novel neural-PK/PD framework that combines key pharmacologicalprinciples with neural ordinary differential equations. We applied it to ananalysis of drug concentration and platelet response from a clinical datasetconsisting of over 600 patients. We show that the neural-PK/PD model improvesupon a state-of-the-art model with respect to metrics for temporal prediction.Furthermore, by incorporating key PK/PD concepts into its architecture, themodel can generalize and enable the simulations of patient responses tountested dosing regimens. These results demonstrate the potential ofneural-PK/PD for automated predictive analytics of patient response timecourse."^^schema:Text ;
    schema:author "Brendan Bender"^^schema:Person,
        "James Lu"^^schema:Person,
        "Jin Y. Jin"^^schema:Person,
        "Yuanfang Guan"^^schema:Person ;
    schema:dateModified "2020-10-22T14:43:22Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T14:43:22Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.QM"^^schema:Text ;
    schema:headline "Deep learning prediction of patient response time course from early data  via neural-pharmacokinetic/pharmacodynamic modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11769v1"^^schema:URL .

<645> a schema:ScholarlyArticle ;
    schema:abstract "We propose a distributed architecture for deep reinforcement learning atscale, that enables agents to learn effectively from orders of magnitude moredata than previously possible. The algorithm decouples acting from learning:the actors interact with their own instances of the environment by selectingactions according to a shared neural network, and accumulate the resultingexperience in a shared experience replay memory; the learner replays samples ofexperience and updates the neural network. The architecture relies onprioritized experience replay to focus only on the most significant datagenerated by the actors. Our architecture substantially improves the state ofthe art on the Arcade Learning Environment, achieving better final performancein a fraction of the wall-clock training time."^^schema:Text ;
    schema:author "Dan Horgan"^^schema:Person,
        "David Budden"^^schema:Person,
        "David Silver"^^schema:Person,
        "Gabriel Barth-Maron"^^schema:Person,
        "Hado van Hasselt"^^schema:Person,
        "John Quan"^^schema:Person,
        "Matteo Hessel"^^schema:Person ;
    schema:dateModified "2018-03-02T16:21:46Z"^^schema:DateTime ;
    schema:datePublished "2018-03-02T16:21:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Distributed Prioritized Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.00933v1"^^schema:URL .

<646> a schema:ScholarlyArticle ;
    schema:abstract "A real time Wall Monitoring System (WMS) is used on the WEST tokamak duringthe C4 experimental campaign. The WMS uses the wall surface temperatures from 6fields of view of the Infrared viewing system. It extracts the raw digital datafrom selected areas, converts it to temperatures using the calibration andwrite it on the shared memory network being used by the Plasma Control System(PCS). The PCS feeds back to actuators, namely the injected power from 5antennae's of the lower hybrid and ion cyclotron resonance radiofrequency (RF)heating systems. WMS activates feed back control 63 times during C4, which is14% of the plasma discharges. It activates mainly as the result of a direct RFloss to the upper divertor pipes. The feedback control maintains the walltemperature within the operation envelope during 97% of the occurrences, whileenabling plasma discharge continuation. The false positive rate establishes at0.2%. WMS significantly facilitated the operation path to high power operationduring C4, by managing the technical risks to critical wall components."^^schema:Text ;
    schema:author "Benjamin Santraine"^^schema:Person,
        "Chakib Belaldil"^^schema:Person,
        "Colette Balorin"^^schema:Person,
        "Raphaël Mitteau"^^schema:Person,
        "Rémy Nouailletas"^^schema:Person,
        "Victor Moncada"^^schema:Person,
        "Xavier Courtois"^^schema:Person ;
    schema:dateModified "2021-01-06T08:14:37Z"^^schema:DateTime ;
    schema:datePublished "2021-01-06T08:14:37Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text,
        "physics.plasm-ph"^^schema:Text ;
    schema:headline "WEST operation with real time feed back control based on wall component  temperature toward machine protection in a steady state tungsten environment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.01914v1"^^schema:URL .

<647> a schema:ScholarlyArticle ;
    schema:abstract "Taking electron microscopy (EM) images in high-resolution is time-consumingand expensive and could be detrimental to the integrity of the samples underobservation. Advances in deep learning enable us to perform super-resolutioncomputationally, so as to obtain high-resolution images from low-resolutionones. When training super-resolution models on pairs of experimentally acquiredEM images, prior models suffer from performance loss while using thepooled-training strategy due to their inability to capture inter-imagedependencies and common features shared among images. Although there existmethods that take advantage of shared features among input instances in imageclassification tasks, they in the current form cannot be applied tosuper-resolution tasks because they fail to preserve an essential property inimage-to-image transformation problems, which is the equivariance property tospatial permutations. To address these limitations, we propose the augmentedequivariant attention networks (AEANets) with better capability to captureinter-image dependencies and shared features, while preserving the equivarianceto spatial permutations. The proposed AEANets captures inter-image dependenciesand common features shared among images via two augmentations on the attentionmechanism; namely, the shared references and the batch-aware attention duringtraining. We theoretically show the equivariance property of the proposedaugmented attention model and experimentally show that AEANets consistentlyoutperforms the baselines in both quantitative and visual results."^^schema:Text ;
    schema:author "Shuiwang Ji"^^schema:Person,
        "Yaochen Xie"^^schema:Person,
        "Yu Ding"^^schema:Person ;
    schema:dateModified "2020-12-10T17:29:29Z"^^schema:DateTime ;
    schema:datePublished "2020-11-06T23:37:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Augmented Equivariant Attention Networks for Electron Microscopy Image  Super-Resolution"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03633v2"^^schema:URL .

<648> a schema:ScholarlyArticle ;
    schema:abstract "Understanding the learning dynamics and inductive bias of neural networks(NNs) is hindered by the opacity of the relationship between NN parameters andthe function represented. We propose reparametrizing ReLU NNs as continuouspiecewise linear splines. Using this spline lens, we study learning dynamics inshallow univariate ReLU NNs, finding unexpected insights and explanations forseveral perplexing phenomena. We develop a surprisingly simple and transparentview of the structure of the loss surface, including its critical and fixedpoints, Hessian, and Hessian spectrum. We also show that standard weightinitializations yield very flat functions, and that this flatness, togetherwith overparametrization and the initial weight scale, is responsible for thestrength and type of implicit regularization, consistent with recent workarXiv:1906.05827. Our implicit regularization results are complementary torecent work arXiv:1906.07842, done independently, which showed thatinitialization scale critically controls implicit regularization via akernel-based argument. Our spline-based approach reproduces their key implicitregularization results but in a far more intuitive and transparent manner.Going forward, our spline-based approach is likely to extend naturally to themultivariate and deep settings, and will play a foundational role in efforts tounderstand neural networks. Videos of learning dynamics using a spline-basedvisualization are available at http://shorturl.at/tFWZ2."^^schema:Text ;
    schema:author "Andy Lu"^^schema:Person,
        "Aneel Damaraju"^^schema:Person,
        "Ankit Patel"^^schema:Person,
        "Josue Ortega Caro"^^schema:Person,
        "Justin Sahs"^^schema:Person,
        "Onur Tavaslioglu"^^schema:Person,
        "Ryan Pyle"^^schema:Person ;
    schema:dateModified "2020-08-04T19:19:49Z"^^schema:DateTime ;
    schema:datePublished "2020-08-04T19:19:49Z"^^schema:DateTime ;
    schema:genre "I.2.0"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Shallow Univariate ReLu Networks as Splines: Initialization, Loss  Surface, Hessian, &amp; Gradient Flow Dynamics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.01772v1"^^schema:URL .

<649> a schema:ScholarlyArticle ;
    schema:abstract "We propose a trust region method for policy optimization that employsQuasi-Newton approximation for the Hessian, called Quasi-Newton Trust RegionPolicy Optimization QNTRPO. Gradient descent is the de facto algorithm forreinforcement learning tasks with continuous controls. The algorithm hasachieved state-of-the-art performance when used in reinforcement learningacross a wide range of tasks. However, the algorithm suffers from a number ofdrawbacks including: lack of stepsize selection criterion, and slowconvergence. We investigate the use of a trust region method using dogleg stepand a Quasi-Newton approximation for the Hessian for policy optimization. Wedemonstrate through numerical experiments over a wide range of challengingcontinuous control tasks that our particular choice is efficient in terms ofnumber of samples and improves performance"^^schema:Text ;
    schema:author "Arvind Raghunathan"^^schema:Person,
        "Devesh Jha"^^schema:Person,
        "Diego Romeres"^^schema:Person ;
    schema:dateModified "2019-12-26T18:29:38Z"^^schema:DateTime ;
    schema:datePublished "2019-12-26T18:29:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Quasi-Newton Trust Region Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.11912v1"^^schema:URL .

<65> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of multiple agents sensing and acting in environmentswith the goal of maximising their shared utility. In these environments, agentsmust learn communication protocols in order to share information that is neededto solve the tasks. By embracing deep neural networks, we are able todemonstrate end-to-end learning of protocols in complex environments inspiredby communication riddles and multi-agent computer vision problems with partialobservability. We propose two approaches for learning in these domains:Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning(DIAL). The former uses deep Q-learning, while the latter exploits the factthat, during learning, agents can backpropagate error derivatives through(noisy) communication channels. Hence, this approach uses centralised learningbut decentralised execution. Our experiments introduce new environments forstudying the learning of communication protocols and present a set ofengineering innovations that are essential for success in these domains."^^schema:Text ;
    schema:author "Jakob N. Foerster"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Shimon Whiteson"^^schema:Person,
        "Yannis M. Assael"^^schema:Person ;
    schema:commentCount "526"^^schema:Integer ;
    schema:dateModified "2016-05-24T18:16:56Z"^^schema:DateTime ;
    schema:datePublished "2016-05-21T17:20:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Learning to Communicate with Deep Multi-Agent Reinforcement Learning"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.06676v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14427321615765348461&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<650> a schema:ScholarlyArticle ;
    schema:abstract "Transition-based parsers implemented with Pointer Networks have become thenew state of the art in dependency parsing, excelling in producing labelledsyntactic trees and outperforming graph-based models in this task. In order tofurther test the capabilities of these powerful neural networks on a harder NLPproblem, we propose a transition system that, thanks to Pointer Networks, canstraightforwardly produce labelled directed acyclic graphs and perform semanticdependency parsing. In addition, we enhance our approach with deepcontextualized word embeddings extracted from BERT. The resulting system notonly outperforms all existing transition-based models, but also matches thebest fully-supervised accuracy to date on the SemEval 2015 Task 18 Englishdatasets among previous state-of-the-art graph-based parsers."^^schema:Text ;
    schema:author "Carlos Gómez-Rodríguez"^^schema:Person,
        "Daniel Fernández-González"^^schema:Person ;
    schema:dateModified "2020-05-28T11:10:31Z"^^schema:DateTime ;
    schema:datePublished "2020-05-27T13:18:27Z"^^schema:DateTime ;
    schema:genre "68T50"^^schema:Text,
        "I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Transition-based Semantic Dependency Parsing with Pointer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.13344v2"^^schema:URL .

<651> a schema:ScholarlyArticle ;
    schema:abstract "Deep learning models for semantic segmentation are able to learn powerfulrepresentations for pixel-wise predictions, but are sensitive to noise at testtime and do not guarantee a plausible topology. Image registration models onthe other hand are able to warp known topologies to target images as a means ofsegmentation, but typically require large amounts of training data, and havenot widely been benchmarked against pixel-wise segmentation models. We proposeAtlas-ISTN, a framework that jointly learns segmentation and registration on 2Dand 3D image data, and constructs a population-derived atlas in the process.Atlas-ISTN learns to segment multiple structures of interest and to registerthe constructed, topologically consistent atlas labelmap to an intermediatepixel-wise segmentation. Additionally, Atlas-ISTN allows for test timerefinement of the model's parameters to optimize the alignment of the atlaslabelmap to an intermediate pixel-wise segmentation. This process bothmitigates for noise in the target image that can result in spurious pixel-wisepredictions, as well as improves upon the one-pass prediction of the model.Benefits of the Atlas-ISTN framework are demonstrated qualitatively andquantitatively on 2D synthetic data and 3D cardiac computed tomography andbrain magnetic resonance image data, out-performing both segmentation andregistration baseline models. Atlas-ISTN also provides inter-subjectcorrespondence of the structures of interest, enabling population-level shapeand motion analysis."^^schema:Text ;
    schema:author "Andreas Schuh"^^schema:Person,
        "Ben Glocker"^^schema:Person,
        "James Batten"^^schema:Person,
        "Karl Hahn"^^schema:Person,
        "Kersten Petersen"^^schema:Person,
        "Matthew Sinclair"^^schema:Person,
        "Michiel Schaap"^^schema:Person,
        "Ying Bai"^^schema:Person ;
    schema:dateModified "2020-12-18T21:53:09Z"^^schema:DateTime ;
    schema:datePublished "2020-12-18T21:53:09Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Atlas-ISTN: Joint Segmentation, Registration and Atlas Construction with  Image-and-Spatial Transformer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.10533v1"^^schema:URL .

<652> a schema:ScholarlyArticle ;
    schema:abstract "Density functional theory (DFT) is used for quantum mechanical simulations ofelectrons in molecules and materials, for applications in chemistry, physics,materials science, and engineering. However, usage of DFT for large numbers ofatoms is hindered by typical scaling of $\\mathcal{O}(N^3)$. Demonstration of asufficiently accurate reduced model with deep neural networks would enablewidespread application of DFT on larger, more complex systems for newscientific discoveries. We show that deep neural networks can be integratedinto, or fully replace, the Kohn-Sham density functional theory scheme formulti-electron systems in simple harmonic oscillator and random externalpotentials. We first show that self-consistent charge densities can be used asinput to an extensive deep neural network to make predictions for correlation,exchange, external, kinetic and total energies simultaneously. Additionally, weshow that one can also make all of the same predictions with the externalpotential rather than the self-consistent charge density, which allows one tocircumvent the Kohn-Sham scheme altogether. We then show that a self-consistentcharge density found from a non-local exchange-correlation functional can beused to make energy predictions for a semi-local exchange-correlationfunctional. Lastly, we use a deep convolutional inverse graphics network topredict the charge density given an external potential and asses the viabilityof the predicted charge densities. This work shows that extensive deep neuralnetworks are generalizable and transferable given the variability of thepotentials and the fact that they can scale to an arbitrary system size with an$\\mathcal{O}(N)$ computational cost."^^schema:Text ;
    schema:author "David Strubbe"^^schema:Person,
        "Isaac Tamblyn"^^schema:Person,
        "Kevin Ryczko"^^schema:Person ;
    schema:dateModified "2018-11-21T20:03:01Z"^^schema:DateTime ;
    schema:datePublished "2018-11-21T20:03:01Z"^^schema:DateTime ;
    schema:genre "cond-mat.mtrl-sci"^^schema:Text,
        "physics.comp-ph"^^schema:Text ;
    schema:headline "Deep Learning and Density Functional Theory"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.08928v1"^^schema:URL .

<653> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a generative moment matching network (GMMN)-basedpost-filter that provides inter-utterance pitch variation for deep neuralnetwork (DNN)-based singing voice synthesis. The natural pitch variation of ahuman singing voice leads to a richer musical experience and is used indouble-tracking, a recording method in which two performances of the samephrase are recorded and mixed to create a richer, layered sound. However,singing voices synthesized using conventional DNN-based methods never varybecause the synthesis process is deterministic and only one waveform issynthesized from one musical score. To address this problem, we use a GMMN tomodel the variation of the modulation spectrum of the pitch contour of naturalsinging voices and add a randomized inter-utterance variation to the pitchcontour generated by conventional DNN-based singing voice synthesis.Experimental evaluations suggest that 1) our approach can provide perceptibleinter-utterance pitch variation while preserving speech quality. We extend ourapproach to double-tracking, and the evaluation demonstrates that 2) GMMN-basedneural double-tracking is perceptually closer to natural double-tracking thanconventional signal processing-based artificial double-tracking is."^^schema:Text ;
    schema:author "Hiroki Tamaru"^^schema:Person,
        "Hiroshi Saruwatari"^^schema:Person,
        "Shinnosuke Takamichi"^^schema:Person,
        "Tomoki Koriyama"^^schema:Person,
        "Yuki Saito"^^schema:Person ;
    schema:dateModified "2019-02-09T07:49:42Z"^^schema:DateTime ;
    schema:datePublished "2019-02-09T07:49:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MM"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Generative Moment Matching Network-based Random Modulation Post-filter  for DNN-based Singing Voice Synthesis and Neural Double-tracking"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.03389v1"^^schema:URL .

<654> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose an alternating directional 3D quasi-recurrentneural network for hyperspectral image (HSI) denoising, which can effectivelyembed the domain knowledge -- structural spatio-spectral correlation and globalcorrelation along spectrum. Specifically, 3D convolution is utilized to extractstructural spatio-spectral correlation in an HSI, while a quasi-recurrentpooling function is employed to capture the global correlation along spectrum.Moreover, alternating directional structure is introduced to eliminate thecausal dependency with no additional computation cost. The proposed model iscapable of modeling spatio-spectral dependency while preserving the flexibilitytowards HSIs with arbitrary number of bands. Extensive experiments on HSIdenoising demonstrate significant improvement over state-of-the-arts undervarious noise settings, in terms of both restoration accuracy and computationtime. Our code is available at https://github.com/Vandermode/QRNN3D."^^schema:Text ;
    schema:author "Hua Huang"^^schema:Person,
        "Kaixuan Wei"^^schema:Person,
        "Ying Fu"^^schema:Person ;
    schema:dateModified "2020-03-10T06:14:53Z"^^schema:DateTime ;
    schema:datePublished "2020-03-10T06:14:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "3D Quasi-Recurrent Neural Network for Hyperspectral Image Denoising"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.04547v1"^^schema:URL .

<655> a schema:ScholarlyArticle ;
    schema:abstract "Like many groups considering the new programming language Julia, we faced thechallenge of accessing the algorithms that we develop in Julia from R.Therefore, we developed the R package JuliaConnectoR, available from the CRANrepository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), inparticular for making advanced deep learning tools available. Formaintainability and stability, we decided to base communication between R andJulia on TCP, using an optimized binary format for exchanging data. Our packagealso specifically contains features that allow for a convenient interactive usein R. This makes it easy to develop R extensions with Julia or to simply callfunctionality from Julia packages in R. With its functionally oriented design,the JuliaConnectoR enables a clean programming style by avoiding state in Juliathat is not visible in the R workspace. We illustrate the further features ofour package with code examples, and also discuss advantages over the twoalternative packages JuliaCall and XRJulia. Finally, we demonstrate the usageof the package with a more extensive example for employing neural ordinarydifferential equations, a recent deep learning technique that has received muchattention. This example also provides more general guidance for integratingdeep learning techniques from Julia into R."^^schema:Text ;
    schema:author "Harald Binder"^^schema:Person,
        "Maren Hackenberg"^^schema:Person,
        "Stefan Lenz"^^schema:Person ;
    schema:dateModified "2020-05-13T14:18:34Z"^^schema:DateTime ;
    schema:datePublished "2020-05-13T14:18:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MS"^^schema:Text,
        "cs.PL"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The JuliaConnectoR: a functionally oriented interface for integrating  Julia in R"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.06334v1"^^schema:URL .

<656> a schema:ScholarlyArticle ;
    schema:abstract "Domain generalization (DG) serves as a promising solution to handle personRe-Identification (Re-ID), which trains the model using labels from the sourcedomain alone, and then directly adopts the trained model to the target domainwithout model updating. However, existing DG approaches are usually disturbedby serious domain variations due to significant dataset variations.Subsequently, DG highly relies on designing domain-invariant features, which ishowever not well exploited, since most existing approaches directly mixmultiple datasets to train DG based models without considering the localdataset similarities, i.e., examples that are very similar but from differentdomains. In this paper, we present a Dual Distribution Alignment Network(DDAN), which handles this challenge by mapping images into a domain-invariantfeature space by selectively aligning distributions of multiple source domains.Such an alignment is conducted by dual-level constraints, i.e., the domain-wiseadversarial feature learning and the identity-wise similarity enhancement. Weevaluate our DDAN on a large-scale Domain Generalization Re-ID (DG Re-ID)benchmark. Quantitative results demonstrate that the proposed DDAN can wellalign the distributions of various source domains, and significantlyoutperforms all existing domain generalization approaches."^^schema:Text ;
    schema:author "Feng Zheng"^^schema:Person,
        "Jianzhuang Liu"^^schema:Person,
        "Peixian Chen"^^schema:Person,
        "Pingyang Dai"^^schema:Person,
        "Qi Tian"^^schema:Person,
        "Rongrong Ji"^^schema:Person ;
    schema:dateModified "2020-07-27T00:08:07Z"^^schema:DateTime ;
    schema:datePublished "2020-07-27T00:08:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Dual Distribution Alignment Network for Generalizable Person  Re-Identification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13249v1"^^schema:URL .

<657> a schema:ScholarlyArticle ;
    schema:abstract "Neural ordinary differential equations (NODEs) treat computation ofintermediate feature vectors as trajectories of ordinary differential equationparameterized by a neural network. In this paper, we propose a novel model,delay differential neural networks (DDNN), inspired by delay differentialequations (DDEs). The proposed model considers the derivative of the hiddenfeature vector as a function of the current feature vector and past featurevectors (history). The function is modelled as a neural network andconsequently, it leads to continuous depth alternatives to many recent ResNetvariants. We propose two different DDNN architectures, depending on the waycurrent and past feature vectors are considered. For training DDNNs, we providea memory-efficient adjoint method for computing gradients and back-propagatethrough the network. DDNN improves the data efficiency of NODE by furtherreducing the number of parameters without affecting the generalizationperformance. Experiments conducted on synthetic and real-world imageclassification datasets such as Cifar10 and Cifar100 show the effectiveness ofthe proposed models."^^schema:Text ;
    schema:author "P. K. Srijith"^^schema:Person,
        "Srinivas Anumasa"^^schema:Person ;
    schema:dateModified "2020-12-12T12:20:54Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T12:20:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Delay Differential Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06800v1"^^schema:URL .

<658> a schema:ScholarlyArticle ;
    schema:abstract "Modeling and prediction of human motion dynamics has long been a challengingproblem in computer vision, and most existing methods rely on the end-to-endsupervised training of various architectures of recurrent neural networks.Inspired by the recent success of deep reinforcement learning methods, in thispaper we propose a new reinforcement learning formulation for the problem ofhuman pose prediction, and develop an imitation learning algorithm forpredicting future poses under this formulation through a combination ofbehavioral cloning and generative adversarial imitation learning. Ourexperiments show that our proposed method outperforms all existingstate-of-the-art baseline models by large margins on the task of human poseprediction in both short-term predictions and long-term predictions, while alsoenjoying huge advantage in training speed."^^schema:Text ;
    schema:author "Borui Wang"^^schema:Person,
        "De-An Huang"^^schema:Person,
        "Ehsan Adeli"^^schema:Person,
        "Hsu-kuang Chiu"^^schema:Person,
        "Juan Carlos Niebles"^^schema:Person ;
    schema:dateModified "2019-09-08T12:39:31Z"^^schema:DateTime ;
    schema:datePublished "2019-09-08T12:39:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Imitation Learning for Human Pose Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.03449v1"^^schema:URL .

<659> a schema:ScholarlyArticle ;
    schema:abstract "Self-supervised learning and data augmentation have significantly reduced theperformance gap between state and image-based reinforcement learning agents incontinuous control tasks. However, it is still unclear whether currenttechniques can face a variety of visual conditions required by real-worldenvironments. We propose a challenging benchmark that tests agents' visualgeneralization by adding graphical variety to existing continuous controldomains. Our empirical analysis shows that current methods struggle togeneralize across a diverse set of visual changes, and we examine the specificfactors of variation that make these tasks difficult. We find that dataaugmentation techniques outperform self-supervised learning approaches and thatmore significant image transformations provide better visual generalization\\footnote{The benchmark and our augmented actor-critic implementation areopen-sourced @ https://github.com/QData/dmc_remastered)"^^schema:Text ;
    schema:author "Jake Grigsby"^^schema:Person,
        "Yanjun Qi"^^schema:Person ;
    schema:dateModified "2020-11-27T20:33:03Z"^^schema:DateTime ;
    schema:datePublished "2020-10-13T23:42:40Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Measuring Visual Generalization in Continuous Control from Pixels"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.06740v2"^^schema:URL .

<66> a schema:ScholarlyArticle ;
    schema:abstract "Human action recognition is an important task in computer vision. Extractingdiscriminative spatial and temporal features to model the spatial and temporalevolutions of different actions plays a key role in accomplishing this task. Inthis work, we propose an end-to-end spatial and temporal attention model forhuman action recognition from skeleton data. We build our model on top of theRecurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), whichlearns to selectively focus on discriminative joints of skeleton within eachframe of the inputs and pays different levels of attention to the outputs ofdifferent frames. Furthermore, to ensure effective training of the network, wepropose a regularized cross-entropy loss to drive the model learning processand develop a joint training strategy accordingly. Experimental resultsdemonstrate the effectiveness of the proposed model,both on the small humanaction recognition data set of SBU and the currently largest NTU dataset."^^schema:Text ;
    schema:author "Cuiling Lan"^^schema:Person,
        "Jiaying Liu"^^schema:Person,
        "Junliang Xing"^^schema:Person,
        "Sijie Song"^^schema:Person,
        "Wenjun Zeng"^^schema:Person ;
    schema:commentCount "354"^^schema:Integer ;
    schema:dateModified "2016-11-18T13:33:28Z"^^schema:DateTime ;
    schema:datePublished "2016-11-18T13:33:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "An End-to-End Spatio-Temporal Attention Model for Human Action  Recognition from Skeleton Data"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.06067v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1164598227028548863&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<660> a schema:ScholarlyArticle ;
    schema:abstract "A power transformer winding is usually subject to mechanical stress andtension because of improper transportation or operation. Radial deformation(RD) is an example of mechanical stress that can impact power transformeroperation through short circuit faults and insulation damages. Frequencyresponse analysis (FRA) is a well-known method to diagnose mechanical defectsin transformers. Despite the precision of FRA, the interpretation of thecalculated frequency response curves is not straightforward and requirescomplex calculations. In this paper, a deep learning algorithm called longshort-term memory (LSTM) is used as a feature extraction technique to locate RDfaults in their early stages. The experimental results verify the effectivenessof the proposed method in the diagnosis and locating of RD defects."^^schema:Text ;
    schema:author "Ali Bidram"^^schema:Person,
        "Arash Moradzadeh"^^schema:Person,
        "Behnam Mohammadi-Ivatloo"^^schema:Person,
        "Kazem Pourhossein"^^schema:Person,
        "Tohid Khalili"^^schema:Person ;
    schema:dateModified "2020-12-13T06:55:05Z"^^schema:DateTime ;
    schema:datePublished "2020-12-13T06:55:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Radial Deformation Emplacement in Power Transformers Using Long  Short-Term Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06982v1"^^schema:URL .

<661> a schema:ScholarlyArticle ;
    schema:abstract "Pose-guided person image generation usually involves using pairedsource-target images to supervise the training, which significantly increasesthe data preparation effort and limits the application of the models. To dealwith this problem, we propose a novel multi-level statistics transfer model,which disentangles and transfers multi-level appearance features from personimages and merges them with pose features to reconstruct the source personimages themselves. So that the source images can be used as supervision forself-driven person image generation. Specifically, our model extractsmulti-level features from the appearance encoder and learns the optimalappearance representation through attention mechanism and attributesstatistics. Then we transfer them to a pose-guided generator for re-fusion ofappearance and pose. Our approach allows for flexible manipulation of personappearance and pose properties to perform pose transfer and clothes styletransfer tasks. Experimental results on the DeepFashion dataset demonstrate ourmethod's superiority compared with state-of-the-art supervised and unsupervisedmethods. In addition, our approach also performs well in the wild."^^schema:Text ;
    schema:author "Bo Peng"^^schema:Person,
        "Jing Dong"^^schema:Person,
        "Tianxiang Ma"^^schema:Person,
        "Wei Wang"^^schema:Person ;
    schema:dateModified "2020-11-23T02:03:31Z"^^schema:DateTime ;
    schema:datePublished "2020-11-18T04:38:48Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "MUST-GAN: Multi-level Statistics Transfer for Self-driven Person Image  Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.09084v2"^^schema:URL .

<662> a schema:ScholarlyArticle ;
    schema:abstract "Spoken language understanding (SLU) systems can be trained on two types oflabelled data: aligned or unaligned. Unaligned data do not require word by wordannotation and is easier to be obtained. In the paper, we focus on spokenlanguage understanding from unaligned data whose annotation is a set ofact-slot-value triples. Previous works usually focus on improve slot-value pairprediction and estimate dialogue act types separately, which ignores thehierarchical structure of the act-slot-value triples. Here, we propose a novelhierarchical decoding model which dynamically parses act, slot and value in astructured way and employs pointer network to handle out-of-vocabulary (OOV)values. Experiments on DSTC2 dataset, a benchmark unaligned dataset, show thatthe proposed model not only outperforms previous state-of-the-art model, butalso can be generalized effectively and efficiently to unseen act-slot typepairs and OOV values."^^schema:Text ;
    schema:author "Kai Yu"^^schema:Person,
        "Su Zhu"^^schema:Person,
        "Zijian Zhao"^^schema:Person ;
    schema:dateModified "2019-04-09T07:26:25Z"^^schema:DateTime ;
    schema:datePublished "2019-04-09T07:26:25Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "A Hierarchical Decoding Model For Spoken Language Understanding From  Unaligned Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.04498v1"^^schema:URL .

<663> a schema:ScholarlyArticle ;
    schema:abstract "A fundamental problem in geostatistical modeling is to infer theheterogeneous geological field based on limited measurements and some priorspatial statistics. Semantic inpainting, a technique for image processing usingdeep generative models, has been recently applied for this purpose,demonstrating its effectiveness in dealing with complex spatial patterns.However, the original semantic inpainting framework incorporates onlyinformation from direct measurements, while in geostatistics indirectmeasurements are often plentiful. To overcome this limitation, here we proposea physics-informed semantic inpainting framework, employing the WassersteinGenerative Adversarial Network with Gradient Penalty (WGAN-GP) and jointlyincorporating the direct and indirect measurements by exploiting the underlyingphysical laws. Our simulation results for a high-dimensional problem with 512dimensions show that in the new method, the physical conservation laws aresatisfied and contribute in enhancing the inpainting performance compared tousing only the direct measurements."^^schema:Text ;
    schema:author "George Em Karniadakis"^^schema:Person,
        "Lingzao Zeng"^^schema:Person,
        "Qiang Zheng"^^schema:Person,
        "Zhendan Cao"^^schema:Person ;
    schema:dateModified "2019-12-23T12:21:44Z"^^schema:DateTime ;
    schema:datePublished "2019-09-19T15:50:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "physics.comp-ph"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Physics-informed semantic inpainting: Application to geostatistical  modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.09459v2"^^schema:URL .

<664> a schema:ScholarlyArticle ;
    schema:abstract "Graph neural networks (GNNs) are typically applied to static graphs that areassumed to be known upfront. This static input structure is often informedpurely by insight of the machine learning practitioner, and might not beoptimal for the actual task the GNN is solving. In absence of reliable domainexpertise, one might resort to inferring the latent graph structure, which isoften difficult due to the vast search space of possible graphs. Here weintroduce Pointer Graph Networks (PGNs) which augment sets or graphs withadditional inferred edges for improved model generalisation ability. PGNs alloweach node to dynamically point to another node, followed by message passingover these pointers. The sparsity of this adaptable graph structure makeslearning tractable while still being sufficiently expressive to simulatecomplex algorithms. Critically, the pointing mechanism is directly supervisedto model long-term sequences of operations on classical data structures,incorporating useful structural inductive biases from theoretical computerscience. Qualitatively, we demonstrate that PGNs can learn parallelisablevariants of pointer-based data structures, namely disjoint set unions andlink/cut trees. PGNs generalise out-of-distribution to 5x larger test inputs ondynamic graph connectivity tasks, outperforming unrestricted GNNs and DeepSets."^^schema:Text ;
    schema:author "Charles Blundell"^^schema:Person,
        "Lars Buesing"^^schema:Person,
        "Matthew C. Overlan"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Petar Veličković"^^schema:Person,
        "Razvan Pascanu"^^schema:Person ;
    schema:dateModified "2020-10-18T20:00:59Z"^^schema:DateTime ;
    schema:datePublished "2020-06-11T12:52:31Z"^^schema:DateTime ;
    schema:genre "cs.DS"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Pointer Graph Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.06380v2"^^schema:URL .

<665> a schema:ScholarlyArticle ;
    schema:abstract "State-of-the-art optimization is steadily shifting towards massively parallelpipelines with extremely large batch sizes. As a consequence, CPU-boundpreprocessing and disk/memory/network operations have emerged as newperformance bottlenecks, as opposed to hardware-accelerated gradientcomputations. In this regime, a recently proposed approach is data echoing(Choi et al., 2019), which takes repeated gradient steps on the same batchwhile waiting for fresh data to arrive from upstream. We provide the firstconvergence analyses of \"data-echoed\" extensions of common optimizationmethods, showing that they exhibit provable improvements over their synchronouscounterparts. Specifically, we show that in convex optimization with stochasticminibatches, data echoing affords speedups on the curvature-dominated part ofthe convergence rate, while maintaining the optimal statistical rate."^^schema:Text ;
    schema:author "Cyril Zhang"^^schema:Person,
        "Kunal Talwar"^^schema:Person,
        "Naman Agarwal"^^schema:Person,
        "Rohan Anil"^^schema:Person,
        "Tomer Koren"^^schema:Person ;
    schema:dateModified "2020-10-26T14:55:31Z"^^schema:DateTime ;
    schema:datePublished "2020-10-26T14:55:31Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stochastic Optimization with Laggard Data Pipelines"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.13639v1"^^schema:URL .

<666> a schema:ScholarlyArticle ;
    schema:abstract "Probabilistic generative models provide a powerful framework for representingdata that avoids the expense of manual annotation typically needed bydiscriminative approaches. Model selection in this generative setting can bechallenging, however, particularly when likelihoods are not easily accessible.To address this issue, we introduce a statistical test of relative similarity,which is used to determine which of two models generates samples that aresignificantly closer to a real-world reference dataset of interest. We use asour test statistic the difference in maximum mean discrepancies (MMDs) betweenthe reference dataset and each model dataset, and derive a powerful,low-variance test based on the joint asymptotic distribution of the MMDsbetween each reference-model pair. In experiments on deep generative models,including the variational auto-encoder and generative moment matching network,the tests provide a meaningful ranking of model performance as a function ofparameter and training settings."^^schema:Text ;
    schema:author "Arthur Gretton"^^schema:Person,
        "Eugene Belilovsky"^^schema:Person,
        "Ioannis Antonoglou"^^schema:Person,
        "Matthew B. Blaschko"^^schema:Person,
        "Wacha Bounliphone"^^schema:Person ;
    schema:dateModified "2016-02-15T15:12:44Z"^^schema:DateTime ;
    schema:datePublished "2015-11-14T17:18:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Test of Relative Similarity For Model Selection in Generative Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1511.04581v4"^^schema:URL .

<667> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning has shown promising results in learning controlpolicies for complex sequential decision-making tasks. However, these neuralnetwork-based policies are known to be vulnerable to adversarial examples. Thisvulnerability poses a potentially serious threat to safety-critical systemssuch as autonomous vehicles. In this paper, we propose a defense mechanism todefend reinforcement learning agents from adversarial attacks by leveraging anaction-conditioned frame prediction module. Our core idea is that theadversarial examples targeting at a neural network-based policy are noteffective for the frame prediction model. By comparing the action distributionproduced by a policy from processing the current observed frame to the actiondistribution produced by the same policy from processing the predicted framefrom the action-conditioned frame prediction module, we can detect the presenceof adversarial examples. Beyond detecting the presence of adversarial examples,our method allows the agent to continue performing the task using the predictedframe when the agent is under attack. We evaluate the performance of ouralgorithm using five games in Atari 2600. Our results demonstrate that theproposed defense mechanism achieves favorable performance against baselinealgorithms in detecting adversarial examples and in earning rewards when theagents are under attack."^^schema:Text ;
    schema:author "Jia-Bin Huang"^^schema:Person,
        "Min Sun"^^schema:Person,
        "Ming-Yu Liu"^^schema:Person,
        "Yen-Chen Lin"^^schema:Person ;
    schema:dateModified "2017-10-02T17:56:26Z"^^schema:DateTime ;
    schema:datePublished "2017-10-02T17:56:26Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Detecting Adversarial Attacks on Neural Network Policies with Visual  Foresight"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.00814v1"^^schema:URL .

<668> a schema:ScholarlyArticle ;
    schema:abstract "We address the task of automatically scoring the competency of candidatesbased on textual features, from the automatic speech recognition (ASR)transcriptions in the asynchronous video job interview (AVI). The key challengeis how to construct the dependency relation between questions and answers, andconduct the semantic level interaction for each question-answer (QA) pair.However, most of the recent studies in AVI focus on how to represent questionsand answers better, but ignore the dependency information and interactionbetween them, which is critical for QA evaluation. In this work, we propose aHierarchical Reasoning Graph Neural Network (HRGNN) for the automaticassessment of question-answer pairs. Specifically, we construct asentence-level relational graph neural network to capture the dependencyinformation of sentences in or between the question and the answer. Based onthese graphs, we employ a semantic-level reasoning graph attention network tomodel the interaction states of the current QA session. Finally, we propose agated recurrent unit encoder to represent the temporal question-answer pairsfor the final prediction. Empirical results conducted on CHNAT (a real-worlddataset) validate that our proposed model significantly outperformstext-matching based benchmark models. Ablation studies and experimental resultswith 10 random seeds also show the effectiveness and stability of our models."^^schema:Text ;
    schema:author "Kai Chen"^^schema:Person,
        "Meng Niu"^^schema:Person,
        "Qingcai Chen"^^schema:Person ;
    schema:dateModified "2020-12-22T12:27:45Z"^^schema:DateTime ;
    schema:datePublished "2020-12-22T12:27:45Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring  of Answer Transcriptions in Video Job Interviews"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11960v1"^^schema:URL .

<669> a schema:ScholarlyArticle ;
    schema:abstract "By interpreting the forward dynamics of the latent representation of neuralnetworks as an ordinary differential equation, Neural Ordinary DifferentialEquation (Neural ODE) emerged as an effective framework for modeling a systemdynamics in the continuous time domain. However, real-world systems ofteninvolves external interventions that cause changes in the system dynamics suchas a moving ball coming in contact with another ball, or such as a patientbeing administered with particular drug. Neural ODE and a number of its recentvariants, however, are not suitable for modeling such interventions as they donot properly model the observations and the interventions separately. In thispaper, we propose a novel neural ODE-based approach (IMODE) that properly modelthe effect of external interventions by employing two ODE functions toseparately handle the observations and the interventions. Using both syntheticand real-world time-series datasets involving interventions, our experimentalresults consistently demonstrate the superiority of IMODE compared to existingapproaches."^^schema:Text ;
    schema:author "Daehoon Gwak"^^schema:Person,
        "Edward Choi"^^schema:Person,
        "Gyuhyeon Sim"^^schema:Person,
        "Jaegul Choo"^^schema:Person,
        "Michael Poli"^^schema:Person,
        "Stefano Massaroli"^^schema:Person ;
    schema:dateModified "2020-10-16T10:55:12Z"^^schema:DateTime ;
    schema:datePublished "2020-10-16T10:55:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Neural Ordinary Differential Equations for Intervention Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.08304v1"^^schema:URL .

<67> a schema:ScholarlyArticle ;
    schema:abstract "As deep nets are increasingly used in applications suited for mobile devices,a fundamental dilemma becomes apparent: the trend in deep learning is to growmodels to absorb ever-increasing data set sizes; however mobile devices aredesigned with very little memory and cannot store such large models. We presenta novel network architecture, HashedNets, that exploits inherent redundancy inneural networks to achieve drastic reductions in model sizes. HashedNets uses alow-cost hash function to randomly group connection weights into hash buckets,and all connections within the same hash bucket share a single parameter value.These parameters are tuned to adjust to the HashedNets weight sharingarchitecture with standard backprop during training. Our hashing procedureintroduces no additional memory overhead, and we demonstrate on severalbenchmark data sets that HashedNets shrink the storage requirements of neuralnetworks substantially while mostly preserving generalization performance."^^schema:Text ;
    schema:author "James T. Wilson"^^schema:Person,
        "Kilian Q. Weinberger"^^schema:Person,
        "Stephen Tyree"^^schema:Person,
        "Wenlin Chen"^^schema:Person,
        "Yixin Chen"^^schema:Person ;
    schema:commentCount "763"^^schema:Integer ;
    schema:dateModified "2015-04-19T04:24:15Z"^^schema:DateTime ;
    schema:datePublished "2015-04-19T04:24:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Compressing Neural Networks with the Hashing Trick"^^schema:Text ;
    schema:publisher "ICML, 2285-2294"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1504.04788v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5053947540904220409&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<670> a schema:ScholarlyArticle ;
    schema:abstract "Emerging reinforcement learning techniques using deep neural networks haveshown great promise in control optimization. They harness non-localregularities of noisy control trajectories and facilitate transfer learningbetween tasks. To leverage these powerful capabilities for quantum controloptimization, we propose a new control framework to simultaneously optimize thespeed and fidelity of quantum computation against both leakage and stochasticcontrol errors. For a broad family of two-qubit unitary gates that areimportant for quantum simulation of many-electron systems, we improve thecontrol robustness by adding control noise into training environments forreinforcement learning agents trained with trusted-region-policy-optimization.The agent control solutions demonstrate a two-order-of-magnitude reduction inaverage-gate-error over baseline stochastic-gradient-descent solutions and upto a one-order-of-magnitude reduction in gate time from optimal gate synthesiscounterparts."^^schema:Text ;
    schema:author "Hartmut Neven"^^schema:Person,
        "Murphy Yuezhen Niu"^^schema:Person,
        "Sergio Boixo"^^schema:Person,
        "Vadim Smelyanskiy"^^schema:Person ;
    schema:dateModified "2018-04-16T17:59:37Z"^^schema:DateTime ;
    schema:datePublished "2018-03-05T19:00:01Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text,
        "quant-ph"^^schema:Text ;
    schema:headline "Universal Quantum Control through Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.01857v2"^^schema:URL .

<671> a schema:ScholarlyArticle ;
    schema:abstract "The state-of-the-art facial image inpainting methods achieved promisingresults but face realism preservation remains a challenge. This is due tolimitations such as; failures in preserving edges and blurry artefacts. Toovercome these limitations, we propose a Symmetric Skip Connection WassersteinGenerative Adversarial Network (S-WGAN) for high-resolution facial imageinpainting. The architecture is an encoder-decoder with convolutional blocks,linked by skip connections. The encoder is a feature extractor that capturesdata abstractions of an input image to learn an end-to-end mapping from aninput (binary masked image) to the ground-truth. The decoder uses learnedabstractions to reconstruct the image. With skip connections, S-WGAN transfersimage details to the decoder. Additionally, we propose a Wasserstein-Perceptualloss function to preserve colour and maintain realism on a reconstructed image.We evaluate our method and the state-of-the-art methods on CelebA-HQ dataset.Our results show S-WGAN produces sharper and more realistic images whenvisually compared with other methods. The quantitative measures show ourproposed S-WGAN achieves the best Structure Similarity Index Measure (SSIM) of0.94."^^schema:Text ;
    schema:author "Connah Kendrick"^^schema:Person,
        "Gee-Sern Hsu"^^schema:Person,
        "Jireh Jam"^^schema:Person,
        "Kevin Walker"^^schema:Person,
        "Moi Hoon Yap"^^schema:Person,
        "Vincent Drouard"^^schema:Person ;
    schema:dateModified "2020-09-12T21:16:39Z"^^schema:DateTime ;
    schema:datePublished "2020-01-11T09:09:23Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Symmetric Skip Connection Wasserstein GAN for High-Resolution Facial  Image Inpainting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.03725v2"^^schema:URL .

<672> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we introduced our joint team SJTU-NICT 's participation in theWMT 2020 machine translation shared task. In this shared task, we participatedin four translation directions of three language pairs: English-Chinese,English-Polish on supervised machine translation track, German-Upper Sorbian onlow-resource and unsupervised machine translation tracks. Based on differentconditions of language pairs, we have experimented with diverse neural machinetranslation (NMT) techniques: document-enhanced NMT, XLM pre-trained languagemodel enhanced NMT, bidirectional translation as a pre-training, referencelanguage based UNMT, data-dependent gaussian prior objective, and BT-BLEUcollaborative filtering self-training. We also used the TF-IDF algorithm tofilter the training set to obtain a domain more similar set with the test setfor finetuning. In our submissions, the primary systems won the first place onEnglish to Chinese, Polish to English, and German to Upper Sorbian translationdirections."^^schema:Text ;
    schema:author "Eiichiro Sumita"^^schema:Person,
        "Hai Zhao"^^schema:Person,
        "Kehai Chen"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Zuchao Li"^^schema:Person ;
    schema:dateModified "2020-10-11T00:40:05Z"^^schema:DateTime ;
    schema:datePublished "2020-10-11T00:40:05Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation  Systems for the WMT20 News Translation Task"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.05122v1"^^schema:URL .

<673> a schema:ScholarlyArticle ;
    schema:abstract "We present a context aware object detection method based on aretrieve-and-transform scene layout model. Given an input image, our approachfirst retrieves a coarse scene layout from a codebook of typical layouttemplates. In order to handle large layout variations, we use a variant of thespatial transformer network to transform and refine the retrieved layout,resulting in a set of interpretable and semantically meaningful feature maps ofobject locations and scales. The above steps are implemented as a LayoutTransfer Network which we integrate into Faster RCNN to allow for jointreasoning of object detection and scene layout estimation. Extensiveexperiments on three public datasets verified that our approach providesconsistent performance improvements to the state-of-the-art object detectionbaselines on a variety of challenging tasks in the traffic surveillance and theautonomous driving domains."^^schema:Text ;
    schema:author "Guobao Xiao"^^schema:Person,
        "Tao Wang"^^schema:Person,
        "Xuming He"^^schema:Person,
        "Yuanzheng Cai"^^schema:Person ;
    schema:dateModified "2019-12-09T06:07:44Z"^^schema:DateTime ;
    schema:datePublished "2019-12-09T06:07:44Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning a Layout Transfer Network for Context Aware Object Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.03865v1"^^schema:URL .

<674> a schema:ScholarlyArticle ;
    schema:abstract "This note compares two recently published machine learning methods forconstructing flexible, but tractable families of variational hidden-variableposteriors. The first method, called \"hierarchical variational models\" enrichesthe inference model with an extra variable, while the other, called \"auxiliarydeep generative models\", enriches the generative model instead. We concludethat the two methods are mathematically equivalent."^^schema:Text ;
    schema:author "Niko Brümmer"^^schema:Person ;
    schema:dateModified "2016-03-09T10:54:36Z"^^schema:DateTime ;
    schema:datePublished "2016-03-08T09:46:30Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "Note on the equivalence of hierarchical variational models and auxiliary  deep generative models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1603.02443v2"^^schema:URL .

<675> a schema:ScholarlyArticle ;
    schema:abstract "The neural ordinary differential equation (Neural ODE) is a novel machinelearning architecture whose weights are smooth functions of the continuousdepth. We apply the Neural ODE to holographic QCD by regarding the weightfunctions as a bulk metric, and train the machine with lattice QCD data ofchiral condensate at finite temperature. The machine finds consistent bulkgeometry at various values of temperature and discovers the emergent black holehorizon in the holographic bulk automatically. The holographic Wilson loopscalculated with the emergent machine-learned bulk spacetime have consistenttemperature dependence of confinement and Debye-screening behavior. In machinelearning models with physically interpretable weights, the Neural ODE frees usfrom discretization artifact leading to difficult ingenuity of hyperparameters,and improves numerical accuracy to make the model more trustworthy."^^schema:Text ;
    schema:author "Hong-Ye Hu"^^schema:Person,
        "Koji Hashimoto"^^schema:Person,
        "Yi-Zhuang You"^^schema:Person ;
    schema:dateModified "2020-06-01T04:41:38Z"^^schema:DateTime ;
    schema:datePublished "2020-06-01T04:41:38Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "gr-qc"^^schema:Text,
        "hep-ph"^^schema:Text,
        "hep-th"^^schema:Text ;
    schema:headline "Neural ODE and Holographic QCD"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.00712v1"^^schema:URL .

<676> a schema:ScholarlyArticle ;
    schema:abstract "Hindsight Experience Replay (HER) is a multi-goal reinforcement learningalgorithm for sparse reward functions. The algorithm treats every failure as asuccess for an alternative (virtual) goal that has been achieved in theepisode. Virtual goals are randomly selected, irrespective of which are mostinstructive for the agent. In this paper, we present two improvements over theexisting HER algorithm. First, we prioritize virtual goals from which the agentwill learn more valuable information. We call this property the instructivenessof the virtual goal and define it by a heuristic measure, which expresses howwell the agent will be able to generalize from that virtual goal to actualgoals. Secondly, we reduce existing bias in HER by the removal of misleadingsamples. To test our algorithms, we built two challenging environments withsparse reward functions. Our empirical results in both environments show vastimprovement in the final success rate and sample efficiency when compared tothe original HER algorithm. A video showing experimental results is availableat https://youtu.be/3cZwfK8Nfps ."^^schema:Text ;
    schema:author "Armin Biess"^^schema:Person,
        "Binyamin Manela"^^schema:Person ;
    schema:dateModified "2020-03-20T14:45:47Z"^^schema:DateTime ;
    schema:datePublished "2019-05-14T10:12:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Bias-Reduced Hindsight Experience Replay with Virtual Goal  Prioritization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.05498v4"^^schema:URL .

<677> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we analyze the performance of general deep reinforcementlearning algorithms for a task-oriented language grounding problem, wherelanguage input contains multiple sub-goals and their order of execution isnon-linear.  We generate a simple instructional language for the GridWorld environment,that is built around three language elements (order connectors) defining theorder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"butbefore\". We apply one of the deep reinforcement learning baselines - Double DQNwith frame stacking and ablate several extensions such as PrioritizedExperience Replay and Gated-Attention architecture.  Our results show that the introduction of non-linear order connectorsimproves the success rate on instructions with a higher number of sub-goals in2-3 times, but it still does not exceed 20%. Also, we observe that the usage ofGated-Attention provides no competitive advantage against concatenation in thissetting. Source code and experiments' results are available athttps://github.com/vkurenkov/language-grounding-multigoal"^^schema:Text ;
    schema:author "Adil Khan"^^schema:Person,
        "Bulat Maksudov"^^schema:Person,
        "Vladislav Kurenkov"^^schema:Person ;
    schema:dateModified "2019-10-27T21:11:42Z"^^schema:DateTime ;
    schema:datePublished "2019-10-27T21:11:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Task-Oriented Language Grounding for Language Input with Multiple  Sub-Goals of Non-Linear Order"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12354v1"^^schema:URL .

<678> a schema:ScholarlyArticle ;
    schema:abstract "The generative adversarial imitation learning (GAIL) has provided anadversarial learning framework for imitating expert policy from demonstrationsin high-dimensional continuous tasks. However, almost all GAIL and itsextensions only design a kind of reward function of logarithmic form in theadversarial training strategy with the Jensen-Shannon (JS) divergence for allcomplex environments. The fixed logarithmic type of reward function may bedifficult to solve all complex tasks, and the vanishing gradients problemcaused by the JS divergence will harm the adversarial learning process. In thispaper, we propose a new algorithm named Wasserstein Distance guided AdversarialImitation Learning (WDAIL) for promoting the performance of imitation learning(IL). There are three improvements in our method: (a) introducing theWasserstein distance to obtain more appropriate measure in the adversarialtraining process, (b) using proximal policy optimization (PPO) in thereinforcement learning stage which is much simpler to implement and makes thealgorithm more efficient, and (c) exploring different reward function shapes tosuit different tasks for improving the performance. The experiment results showthat the learning procedure remains remarkably stable, and achieves significantperformance in the complex continuous control tasks of MuJoCo."^^schema:Text ;
    schema:author "Jun Yang"^^schema:Person,
        "Li Xia"^^schema:Person,
        "Ming Zhang"^^schema:Person,
        "Xiaoteng Ma"^^schema:Person,
        "Xiu Li"^^schema:Person,
        "Yawei Wang"^^schema:Person,
        "Zhiheng Li"^^schema:Person ;
    schema:dateModified "2020-12-08T13:06:20Z"^^schema:DateTime ;
    schema:datePublished "2020-06-05T15:10:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Wasserstein Distance guided Adversarial Imitation Learning with Reward  Shape Exploration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.03503v2"^^schema:URL .

<679> a schema:ScholarlyArticle ;
    schema:abstract "Representation learning over graph structured data has been mostly studied instatic graph settings while efforts for modeling dynamic graphs are stillscant. In this paper, we develop a novel hierarchical variational model thatintroduces additional latent random variables to jointly model the hiddenstates of a graph recurrent neural network (GRNN) to capture both topology andnode attribute changes in dynamic graphs. We argue that the use of high-levellatent random variables in this variational GRNN (VGRNN) can better capturepotential variability observed in dynamic graphs as well as the uncertainty ofnode latent representation. With semi-implicit variational inference developedfor this new VGRNN architecture (SI-VGRNN), we show that flexible non-Gaussianlatent representations can further help dynamic graph analytic tasks. Ourexperiments with multiple real-world dynamic graph datasets demonstrate thatSI-VGRNN and VGRNN consistently outperform the existing baseline andstate-of-the-art methods by a significant margin in dynamic link prediction."^^schema:Text ;
    schema:author "Arman Hasanzadeh"^^schema:Person,
        "Ehsan Hajiramezanali"^^schema:Person,
        "Krishna R Narayanan"^^schema:Person,
        "Mingyuan Zhou"^^schema:Person,
        "Nick Duffield"^^schema:Person,
        "Xiaoning Qian"^^schema:Person ;
    schema:dateModified "2020-04-23T03:03:40Z"^^schema:DateTime ;
    schema:datePublished "2019-08-26T14:44:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Variational Graph Recurrent Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.09710v3"^^schema:URL .

<68> a schema:ScholarlyArticle ;
    schema:abstract "Deep generative models parameterized by neural networks have recentlyachieved state-of-the-art performance in unsupervised and semi-supervisedlearning. We extend deep generative models with auxiliary variables whichimproves the variational approximation. The auxiliary variables leave thegenerative model unchanged but make the variational distribution moreexpressive. Inspired by the structure of the auxiliary variable we also proposea model with two stochastic layers and skip connections. Our findings suggestthat more expressive and properly specified deep generative models convergefaster with better results. We show state-of-the-art performance withinsemi-supervised learning on MNIST, SVHN and NORB datasets."^^schema:Text ;
    schema:author "Casper Kaae Sønderby"^^schema:Person,
        "Lars Maaløe"^^schema:Person,
        "Ole Winther"^^schema:Person,
        "Søren Kaae Sønderby"^^schema:Person ;
    schema:commentCount "294"^^schema:Integer ;
    schema:dateModified "2016-06-16T06:39:08Z"^^schema:DateTime ;
    schema:datePublished "2016-02-17T16:24:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Auxiliary Deep Generative Models"^^schema:Text ;
    schema:publisher "ICML, 1445-1453"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.05473v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9120124950708918697&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<680> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a provably stable variant of neural ordinary differentialequations (neural ODEs) whose trajectories evolve on an energy functionalparametrised by a neural network. Stable neural flows provide an implicitguarantee on asymptotic stability of the depth-flows, leading to robustnessagainst input perturbations and low computational burden for the numericalsolver. The learning procedure is cast as an optimal control problem, and anapproximate solution is proposed based on adjoint sensivity analysis. Wefurther introduce novel regularizers designed to ease the optimization processand speed up convergence. The proposed model class is evaluated on non-linearclassification and function approximation tasks."^^schema:Text ;
    schema:author "Atsushi Yamashita"^^schema:Person,
        "Hajime Asama"^^schema:Person,
        "Jinkyoo Park"^^schema:Person,
        "Michael Poli"^^schema:Person,
        "Michelangelo Bin"^^schema:Person,
        "Stefano Massaroli"^^schema:Person ;
    schema:dateModified "2020-03-18T06:27:21Z"^^schema:DateTime ;
    schema:datePublished "2020-03-18T06:27:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stable Neural Flows"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08063v1"^^schema:URL .

<681> a schema:ScholarlyArticle ;
    schema:abstract "In this work we propose Pathfinder Discovery Networks (PDNs), a method forjointly learning a message passing graph over a multiplex network with adownstream semi-supervised model. PDNs inductively learn an aggregated weightfor each edge, optimized to produce the best outcome for the downstreamlearning task. PDNs are a generalization of attention mechanisms on graphswhich allow flexible construction of similarity functions between nodes, edgeconvolutions, and cheap multiscale mixing layers. We show that PDNs overcomeweaknesses of existing methods for graph attention (e.g. Graph AttentionNetworks), such as the diminishing weight problem. Our experimental resultsdemonstrate competitive predictive performance on academic node classificationtasks. Additional results from a challenging suite of node classificationexperiments show how PDNs can learn a wider class of functions than existingbaselines. We analyze the relative computational complexity of PDNs, and showthat PDN runtime is not considerably higher than static-graph models. Finally,we discuss how PDNs can be used to construct an easily interpretable attentionmechanism that allows users to understand information propagation in the graph."^^schema:Text ;
    schema:author "Amol Kapoor"^^schema:Person,
        "Benedek Rozemberczki"^^schema:Person,
        "Bryan Perozzi"^^schema:Person,
        "Martin Blais"^^schema:Person,
        "Peter Englert"^^schema:Person ;
    schema:dateModified "2020-10-24T11:28:57Z"^^schema:DateTime ;
    schema:datePublished "2020-10-24T11:28:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text ;
    schema:headline "Pathfinder Discovery Networks for Neural Message Passing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.12878v1"^^schema:URL .

<682> a schema:ScholarlyArticle ;
    schema:abstract "Neural Memory Networks (NMNs) have received increased attention in recentyears compared to deep architectures that use a constrained memory. Despitetheir new appeal, the success of NMNs hinges on the ability of thegradient-based optimiser to perform incremental training of the NMNcontrollers, determining how to leverage their high capacity for knowledgeretrieval. This means that while excellent performance can be achieved when thetraining data is consistent and well distributed, rare data samples are hard tolearn from as the controllers fail to incorporate them effectively during modeltraining. Drawing inspiration from the human cognition process, in particularthe utilisation of neuromodulators in the human brain, we propose to decouplethe learning process of the NMN controllers to allow them to achieve flexible,rapid adaptation in the presence of new information. This trait is highlybeneficial for meta-learning tasks where the memory controllers must quicklygrasp abstract concepts in the target domain, and adapt stored knowledge. Thisallows the NMN controllers to quickly determine which memories are to beretained and which are to be erased, and swiftly adapt their strategy to thenew task at hand. Through both quantitative and qualitative evaluations onmultiple public benchmarks, including classification and regression tasks, wedemonstrate the utility of the proposed approach. Our evaluations not onlyhighlight the ability of the proposed NMN architecture to outperform thecurrent state-of-the-art methods, but also provide insights on how the proposedaugmentations help achieve such superior results. In addition, we demonstratethe practical implications of the proposed learning strategy, where thefeedback path can be shared among multiple neural memory networks as amechanism for knowledge sharing."^^schema:Text ;
    schema:author "Clinton Fookes"^^schema:Person,
        "Simon Denman"^^schema:Person,
        "Sridha Sridharan"^^schema:Person,
        "Tharindu Fernando"^^schema:Person ;
    schema:dateModified "2020-11-10T22:44:27Z"^^schema:DateTime ;
    schema:datePublished "2020-11-10T22:44:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Fast &amp; Slow Learning: Incorporating Synthetic Gradients in Neural Memory  Controllers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05438v1"^^schema:URL .

<683> a schema:ScholarlyArticle ;
    schema:abstract "Familia is an open-source toolkit for pragmatic topic modeling in industry.Familia abstracts the utilities of topic modeling in industry as two paradigms:semantic representation and semantic matching. Efficient implementations of thetwo paradigms are made publicly available for the first time. Furthermore, weprovide off-the-shelf topic models trained on large-scale industrial corpora,including Latent Dirichlet Allocation (LDA), SentenceLDA and Topical WordEmbedding (TWE). We further describe typical applications which aresuccessfully powered by topic modeling, in order to ease the confusions anddifficulties of software engineers during topic model selection andutilization."^^schema:Text ;
    schema:author "Chen Li"^^schema:Person,
        "Di Jiang"^^schema:Person,
        "Rongzhong Lian"^^schema:Person,
        "Siqi Bao"^^schema:Person,
        "Zeyu Chen"^^schema:Person ;
    schema:dateModified "2017-07-31T12:48:45Z"^^schema:DateTime ;
    schema:datePublished "2017-07-31T12:48:45Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Familia: An Open-Source Toolkit for Industrial Topic Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.09823v1"^^schema:URL .

<684> a schema:ScholarlyArticle ;
    schema:abstract "It is important to scale out deep neural network (DNN) training for reducingmodel training time. The high communication overhead is one of the majorperformance bottlenecks for distributed DNN training across multiple GPUs. Ourinvestigations have shown that popular open-source DNN systems could onlyachieve 2.5 speedup ratio on 64 GPUs connected by 56 Gbps network. To addressthis problem, we propose a communication backend named GradientFlow fordistributed DNN training, and employ a set of network optimization techniques.First, we integrate ring-based allreduce, mixed-precision training, andcomputation/communication overlap into GradientFlow. Second, we propose lazyallreduce to improve network throughput by fusing multiple communicationoperations into a single one, and design coarse-grained sparse communication toreduce network traffic by only transmitting important gradient chunks. Whentraining ImageNet/AlexNet on 512 GPUs, our approach achieves 410.2 speedupratio and completes 95-epoch training in 1.5 minutes, which outperformsexisting approaches."^^schema:Text ;
    schema:author "Peng Sun"^^schema:Person,
        "Ruobing Han"^^schema:Person,
        "Shengen Yan"^^schema:Person,
        "Wansen Feng"^^schema:Person,
        "Yonggang Wen"^^schema:Person ;
    schema:dateModified "2019-10-22T08:52:08Z"^^schema:DateTime ;
    schema:datePublished "2019-02-19T01:18:56Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text ;
    schema:headline "Optimizing Network Performance for Distributed DNN Training on GPU  Clusters: ImageNet/AlexNet Training in 1.5 Minutes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.06855v3"^^schema:URL .

<685> a schema:ScholarlyArticle ;
    schema:abstract "This study proposes an end-to-end framework for solving multi-objectiveoptimization problems (MOPs) using Deep Reinforcement Learning (DRL), that wecall DRL-MOA. The idea of decomposition is adopted to decompose the MOP into aset of scalar optimization subproblems. Then each subproblem is modelled as aneural network. Model parameters of all the subproblems are optimizedcollaboratively according to a neighborhood-based parameter-transfer strategyand the DRL training algorithm. Pareto optimal solutions can be directlyobtained through the trained neural network models. In specific, themulti-objective travelling salesman problem (MOTSP) is solved in this workusing the DRL-MOA method by modelling the subproblem as a Pointer Network.Extensive experiments have been conducted to study the DRL-MOA and variousbenchmark methods are compared with it. It is found that, once the trainedmodel is available, it can scale to newly encountered problems with no need ofre-training the model. The solutions can be directly obtained by a simpleforward calculation of the neural network; thereby, no iteration is requiredand the MOP can be always solved in a reasonable time. The proposed methodprovides a new way of solving the MOP by means of DRL. It has shown a set ofnew characteristics, e.g., strong generalization ability and fast solving speedin comparison with the existing methods for multi-objective optimizations.Experimental results show the effectiveness and competitiveness of the proposedmethod in terms of model performance and running time."^^schema:Text ;
    schema:author "Kaiwen Li"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Tao Zhang"^^schema:Person ;
    schema:dateModified "2020-04-25T04:03:47Z"^^schema:DateTime ;
    schema:datePublished "2019-06-06T02:24:06Z"^^schema:DateTime ;
    schema:genre "cs.NE"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Multi-objective Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02386v2"^^schema:URL .

<686> a schema:ScholarlyArticle ;
    schema:abstract "Implicitly defined, continuous, differentiable signal representationsparameterized by neural networks have emerged as a powerful paradigm, offeringmany possible benefits over conventional representations. However, currentnetwork architectures for such implicit neural representations are incapable ofmodeling signals with fine detail, and fail to represent a signal's spatial andtemporal derivatives, despite the fact that these are essential to manyphysical signals defined implicitly as the solution to partial differentialequations. We propose to leverage periodic activation functions for implicitneural representations and demonstrate that these networks, dubbed sinusoidalrepresentation networks or Sirens, are ideally suited for representing complexnatural signals and their derivatives. We analyze Siren activation statisticsto propose a principled initialization scheme and demonstrate therepresentation of images, wavefields, video, sound, and their derivatives.Further, we show how Sirens can be leveraged to solve challenging boundaryvalue problems, such as particular Eikonal equations (yielding signed distancefunctions), the Poisson equation, and the Helmholtz and wave equations. Lastly,we combine Sirens with hypernetworks to learn priors over the space of Sirenfunctions."^^schema:Text ;
    schema:author "Alexander W. Bergman"^^schema:Person,
        "David B. Lindell"^^schema:Person,
        "Gordon Wetzstein"^^schema:Person,
        "Julien N. P. Martel"^^schema:Person,
        "Vincent Sitzmann"^^schema:Person ;
    schema:dateModified "2020-06-17T05:13:33Z"^^schema:DateTime ;
    schema:datePublished "2020-06-17T05:13:33Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Implicit Neural Representations with Periodic Activation Functions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.09661v1"^^schema:URL .

<687> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a deep unfolding-based framework for the outputfeedback control of systems with input saturation. Although saturation commonlyarises in several practical control systems, there is still a scarce ofeffective design methodologies that can directly deal with the severenon-linearity of the saturation operator. In this paper, we aim to design ananti-windup controller for enlarging the region of stability of the closed-loopsystem by learning from the numerical simulations of the closed-loop system.The data-driven framework we propose in this paper is based on a deep-learningtechnique called Neural Ordinary Differential Equations. Within our framework,we first obtain a candidate controller by using the deep-learning technique,which is then tested by the existing theoretical results already established inthe literature, thereby avoiding the computational challenge in theconventional design methodologies as well as theoretically guaranteeing theperformance of the system. Our numerical simulation shows that the proposedframework can significantly outperform a conventional design methodology basedon linear matrix inequalities."^^schema:Text ;
    schema:author "Kenji Sugimoto"^^schema:Person,
        "Koki Kobayashi"^^schema:Person,
        "Masaki Ogura"^^schema:Person,
        "Taisuke Kobayashi"^^schema:Person ;
    schema:dateModified "2021-01-27T13:52:49Z"^^schema:DateTime ;
    schema:datePublished "2020-11-20T04:08:41Z"^^schema:DateTime ;
    schema:genre "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Deep unfolding-based output feedback control design for linear systems  with input saturation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.10196v2"^^schema:URL .

<688> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning (RL) is attracting increasing interests in autonomousdriving due to its potential to solve complex classification and controlproblems. However, existing RL algorithms are rarely applied to real vehiclesfor two predominant problems: behaviours are unexplainable, and they cannotguarantee safety under new scenarios. This paper presents a safe RL algorithm,called Parallel Constrained Policy Optimization (PCPO), for two autonomousdriving tasks. PCPO extends today's common actor-critic architecture to athree-component learning framework, in which three neural networks are used toapproximate the policy function, value function and a newly added riskfunction, respectively. Meanwhile, a trust region constraint is added to allowlarge update steps without breaking the monotonic improvement condition. Toensure the feasibility of safety constrained problems, synchronized parallellearners are employed to explore different state spaces, which accelerateslearning and policy-update. The simulations of two scenarios for autonomousvehicles confirm we can ensure safety while achieving fast learning."^^schema:Text ;
    schema:author "Huei Peng"^^schema:Person,
        "Jingliang Duan"^^schema:Person,
        "Lu Wen"^^schema:Person,
        "Shaobing Xu"^^schema:Person,
        "Shengbo Eben Li"^^schema:Person ;
    schema:dateModified "2020-03-03T02:53:30Z"^^schema:DateTime ;
    schema:datePublished "2020-03-03T02:53:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Safe Reinforcement Learning for Autonomous Vehicles through Parallel  Constrained Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.01303v1"^^schema:URL .

<689> a schema:ScholarlyArticle ;
    schema:abstract "Many problems across computer vision and the natural sciences require theanalysis of spherical data, for which representations may be learnedefficiently by encoding equivariance to rotational symmetries. We present ageneralized spherical CNN framework that encompasses various existingapproaches and allows them to be leveraged alongside each other. The onlyexisting non-linear spherical CNN layer that is strictly equivariant hascomplexity $\\mathcal{O}(C^2L^5)$, where $C$ is a measure of representationalcapacity and $L$ the spherical harmonic bandlimit. Such a high computationalcost often prohibits the use of strictly equivariant spherical CNNs. We developtwo new strictly equivariant layers with reduced complexity $\\mathcal{O}(CL^4)$and $\\mathcal{O}(CL^3 \\log L)$, making larger, more expressive modelscomputationally feasible. Moreover, we adopt efficient sampling theory toachieve further computational savings. We show that these developments allowthe construction of more expressive hybrid models that achieve state-of-the-artaccuracy and parameter efficiency on spherical benchmark problems."^^schema:Text ;
    schema:author "Augustin Marignier"^^schema:Person,
        "Augustine N. Mavor-Parker"^^schema:Person,
        "Christopher G. R. Wallis"^^schema:Person,
        "Jason D. McEwen"^^schema:Person,
        "Matthew A. Price"^^schema:Person,
        "Mayeul d'Avezac"^^schema:Person,
        "Oliver J. Cobb"^^schema:Person ;
    schema:dateModified "2020-10-23T15:52:16Z"^^schema:DateTime ;
    schema:datePublished "2020-10-09T18:00:05Z"^^schema:DateTime ;
    schema:genre "astro-ph.IM"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Efficient Generalized Spherical CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11661v2"^^schema:URL .

<69> a schema:ScholarlyArticle ;
    schema:abstract "A key goal of computer vision is to recover the underlying 3D structure from2D observations of the world. In this paper we learn strong deep generativemodels of 3D structures, and recover these structures from 3D and 2D images viaprobabilistic inference. We demonstrate high-quality samples and reportlog-likelihoods on several datasets, including ShapeNet [2], and establish thefirst benchmarks in the literature. We also show how these models and theirinference networks can be trained end-to-end from 2D images. This demonstratesfor the first time the feasibility of learning to infer 3D representations ofthe world in a purely unsupervised manner."^^schema:Text ;
    schema:author "Danilo Jimenez Rezende"^^schema:Person,
        "Max Jaderberg"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Peter Battaglia"^^schema:Person,
        "S. M. Ali Eslami"^^schema:Person,
        "Shakir Mohamed"^^schema:Person ;
    schema:commentCount "232"^^schema:Integer ;
    schema:dateModified "2018-06-19T17:26:53Z"^^schema:DateTime ;
    schema:datePublished "2016-07-03T17:53:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unsupervised Learning of 3D Structure from Images"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1607.00662v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6886635876252957202&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<690> a schema:ScholarlyArticle ;
    schema:abstract "We present Sockeye 2, a modernized and streamlined version of the Sockeyeneural machine translation (NMT) toolkit. New features include a simplifiedcode base through the use of MXNet's Gluon API, a focus on state of the artmodel architectures, distributed mixed precision training, and efficient CPUdecoding with 8-bit quantization. These improvements result in faster trainingand inference, higher automatic metric scores, and a shorter path from researchto production."^^schema:Text ;
    schema:author "David Vilar"^^schema:Person,
        "Felix Hieber"^^schema:Person,
        "Kenneth Heafield"^^schema:Person,
        "Michael Denkowski"^^schema:Person,
        "Tobias Domhan"^^schema:Person,
        "Xing Niu"^^schema:Person ;
    schema:dateModified "2020-08-11T17:42:26Z"^^schema:DateTime ;
    schema:datePublished "2020-08-11T17:42:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.04885v1"^^schema:URL .

<691> a schema:ScholarlyArticle ;
    schema:abstract "Solving goal-oriented tasks is an important but challenging problem inreinforcement learning (RL). For such tasks, the rewards are often sparse,making it difficult to learn a policy effectively. To tackle this difficulty,we propose a new approach called Policy Continuation with Hindsight InverseDynamics (PCHID). This approach learns from Hindsight Inverse Dynamics based onHindsight Experience Replay, enabling the learning process in a self-imitatedmanner and thus can be trained with supervised learning. This work also extendsit to multi-step settings with Policy Continuation. The proposed method isgeneral, which can work in isolation or be combined with other on-policy andoff-policy algorithms. On two multi-goal tasks GridWorld and FetchReach, PCHIDsignificantly improves the sample efficiency as well as the final performance."^^schema:Text ;
    schema:author "Bolei Zhou"^^schema:Person,
        "Dahua Lin"^^schema:Person,
        "Hao Sun"^^schema:Person,
        "Xiaotong Liu"^^schema:Person,
        "Zhizhong Li"^^schema:Person ;
    schema:dateModified "2019-11-01T04:18:43Z"^^schema:DateTime ;
    schema:datePublished "2019-10-30T18:00:21Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Policy Continuation with Hindsight Inverse Dynamics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.14055v2"^^schema:URL .

<692> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks have revolutionized many machine learning tasks in powersystems, ranging from pattern recognition to signal processing. The data inthese tasks is typically represented in Euclidean domains. Nevertheless, thereis an increasing number of applications in power systems, where data arecollected from non-Euclidean domains and represented as the graph-structureddata with high dimensional features and interdependency among nodes. Thecomplexity of graph-structured data has brought significant challenges to theexisting deep neural networks defined in Euclidean domains. Recently, manystudies on extending deep neural networks for graph-structured data in powersystems have emerged. In this paper, a comprehensive overview of graph neuralnetworks (GNNs) in power systems is proposed. Specifically, several classicalparadigms of GNNs structures (e.g., graph convolutional networks, graphrecurrent neural networks, graph attention networks, graph generative networks,spatial-temporal graph convolutional networks, and hybrid forms of GNNs) aresummarized, and key applications in power systems such as fault diagnosis,power prediction, power flow calculation, and data generation are reviewed indetail. Furthermore, main issues and some research trends about theapplications of GNNs in power systems are discussed."^^schema:Text ;
    schema:author "Birgitte Bak-Jensen"^^schema:Person,
        "Jayakrishnan Radhakrishna Pillai"^^schema:Person,
        "Wenlong Liao"^^schema:Person,
        "Yuelong Wang"^^schema:Person,
        "Yusen Wang"^^schema:Person ;
    schema:dateModified "2021-01-25T11:50:45Z"^^schema:DateTime ;
    schema:datePublished "2021-01-25T11:50:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "A Review of Graph Neural Networks and Their Applications in Power  Systems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.10025v1"^^schema:URL .

<693> a schema:ScholarlyArticle ;
    schema:abstract "Variational autoencoders (VAEs) are a standard framework for inducing latentvariable models that have been shown effective in learning text representationsas well as in text generation. The key challenge with using VAEs is the {\\itposterior collapse} problem: learning tends to converge to trivial solutionswhere the generators ignore latent variables. In our Levenstein VAE, we proposeto replace the evidence lower bound (ELBO) with a new objective which is simpleto optimize and prevents posterior collapse. Intuitively, it corresponds togenerating a sequence from the autoencoder and encouraging the model to predictan optimal continuation according to the Levenshtein distance (LD) with thereference sentence at each time step in the generated sequence. We motivate themethod from the probabilistic perspective by showing that it is closely relatedto optimizing a bound on the intractable Kullback-Leibler divergence of anLD-based kernel density estimator from the model distribution. With thisobjective, any generator disregarding latent variables will incur largepenalties and hence posterior collapse does not happen. We relate our approachto policy distillation \\cite{RossGB11} and dynamic oracles \\cite{GoldbergN12}.By considering Yelp and SNLI benchmarks, we show that Levenstein VAE producesmore informative latent representations than alternative approaches topreventing posterior collapse."^^schema:Text ;
    schema:author "Ivan Titov"^^schema:Person,
        "Serhii Havrylov"^^schema:Person ;
    schema:dateModified "2020-04-30T13:27:26Z"^^schema:DateTime ;
    schema:datePublished "2020-04-30T13:27:26Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Preventing Posterior Collapse with Levenshtein Variational Autoencoder"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.14758v1"^^schema:URL .

<694> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning (RL) has been demonstrated to have great potential inmany applications of scientific discovery and design. Recent work includes, forexample, the design of new structures and compositions of molecules fortherapeutic drugs. Much of the existing work related to the application of RLto scientific domains, however, assumes that the available state representationobeys the Markov property. For reasons associated with time, cost, sensoraccuracy, and gaps in scientific knowledge, many scientific design anddiscovery problems do not satisfy the Markov property. Thus, something otherthan a Markov decision process (MDP) should be used to plan / find the optimalpolicy. In this paper, we present a physics-inspired semi-Markov RLenvironment, namely the phase change environment. In addition, we evaluate theperformance of value-based RL algorithms for both MDPs and partially observableMDPs (POMDPs) on the proposed environment. Our results demonstrate deeprecurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), andthat DRQNs benefit from training with hindsight experience replay. Implicationsfor the use of semi-Markovian RL and POMDPs for scientific laboratories arealso discussed."^^schema:Text ;
    schema:author "Colin Bellinger"^^schema:Person,
        "Isaac Tamblyn"^^schema:Person,
        "Mark Crowley"^^schema:Person,
        "Rory Coles"^^schema:Person ;
    schema:dateModified "2020-04-15T20:43:29Z"^^schema:DateTime ;
    schema:datePublished "2020-04-15T20:43:29Z"^^schema:DateTime ;
    schema:genre "I.2; J.2"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Reinforcement Learning in a Physics-Inspired Semi-Markov Environment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.07333v1"^^schema:URL .

<695> a schema:ScholarlyArticle ;
    schema:abstract "In this thesis, we leverage the neural copy mechanism and memory-augmentedneural networks (MANNs) to address existing challenge of neural task-orienteddialogue learning. We show the effectiveness of our strategy by achieving goodperformance in multi-domain dialogue state tracking, retrieval-based dialoguesystems, and generation-based dialogue systems. We first propose a transferabledialogue state generator (TRADE) that leverages its copy mechanism to get ridof dialogue ontology and share knowledge between domains. We also evaluateunseen domain dialogue state tracking and show that TRADE enables zero-shotdialogue state tracking and can adapt to new few-shot domains withoutforgetting the previous domains. Second, we utilize MANNs to improveretrieval-based dialogue learning. They are able to capture dialogue sequentialdependencies and memorize long-term information. We also propose a recordeddelexicalization copy strategy to replace real entity values with orderedentity types. Our models are shown to surpass other retrieval baselines,especially when the conversation has a large number of turns. Lastly, we tacklegeneration-based dialogue learning with two proposed models, thememory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP).Mem2Seq is the first model to combine multi-hop memory attention with the ideaof the copy mechanism. GLMP further introduces the concept of responsesketching and double pointers copying. We show that GLMP achieves thestate-of-the-art performance on human evaluation."^^schema:Text ;
    schema:author "Chien-Sheng Wu"^^schema:Person ;
    schema:dateModified "2019-05-19T04:00:08Z"^^schema:DateTime ;
    schema:datePublished "2019-05-19T04:00:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Learning to Memorize in Neural Task-Oriented Dialogue Systems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.07687v1"^^schema:URL .

<696> a schema:ScholarlyArticle ;
    schema:abstract "Many reinforcement-learning researchers treat the reward function as a partof the environment, meaning that the agent can only know the reward of a stateif it encounters that state in a trial run. However, we argue that this is anunnecessary limitation and instead, the reward function should be provided tothe learning algorithm. The advantage is that the algorithm can then use thereward function to check the reward for states that the agent hasn't evenencountered yet. In addition, the algorithm can simultaneously learn policiesfor multiple reward functions. For each state, the algorithm would calculatethe reward using each of the reward functions and add the rewards to itsexperience replay dataset. The Hindsight Experience Replay algorithm developedby Andrychowicz et al. (2017) does just this, and learns to generalize across adistribution of sparse, goal-based rewards. We extend this algorithm tolinearly-weighted, multi-objective rewards and learn a single policy that cangeneralize across all linear combinations of the multi-objective reward.Whereas other multi-objective algorithms teach the Q-function to generalizeacross the reward weights, our algorithm enables the policy to generalize, andcan thus be used with continuous actions."^^schema:Text ;
    schema:author "Eli Friedman"^^schema:Person,
        "Fred Fontaine"^^schema:Person ;
    schema:dateModified "2018-09-17T17:59:13Z"^^schema:DateTime ;
    schema:datePublished "2018-09-17T17:59:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generalizing Across Multi-Objective Reward Functions in Deep  Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.06364v1"^^schema:URL .

<697> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks (CNNs) constructed natively on the sphere havebeen developed recently and shown to be highly effective for the analysis ofspherical data. While an efficient framework has been formulated, sphericalCNNs are nevertheless highly computationally demanding; typically they cannotscale beyond spherical signals of thousands of pixels. We develop scatteringnetworks constructed natively on the sphere that provide a powerfulrepresentational space for spherical data. Spherical scattering networks arecomputationally scalable and exhibit rotational equivariance, while theirrepresentational space is invariant to isometries and provides efficient andstable signal representations. By integrating scattering networks as anadditional type of layer in the generalized spherical CNN framework, we showhow they can be leveraged to scale spherical CNNs to the high resolution datatypical of many practical applications, with spherical signals of many tens ofmegapixels and beyond."^^schema:Text ;
    schema:author "Augustine N. Mavor-Parker"^^schema:Person,
        "Christopher G. R. Wallis"^^schema:Person,
        "Jason D. McEwen"^^schema:Person ;
    schema:dateModified "2021-02-04T19:00:01Z"^^schema:DateTime ;
    schema:datePublished "2021-02-04T19:00:01Z"^^schema:DateTime ;
    schema:genre "astro-ph.IM"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Scattering Networks on the Sphere for Scalable and Rotationally  Equivariant Spherical CNNs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02828v1"^^schema:URL .

<698> a schema:ScholarlyArticle ;
    schema:abstract "Monotonic policy improvement and off-policy learning are two main desirableproperties for reinforcement learning algorithms. In this paper, by lowerbounding the performance difference of two policies, we show that the monotonicpolicy improvement is guaranteed from on- and off-policy mixture samples. Anoptimization procedure which applies the proposed bound can be regarded as anoff-policy natural policy gradient method. In order to support the theoreticalresult, we provide a trust region policy optimization method using experiencereplay as a naive application of our bound, and evaluate its performance in twoclassical benchmark problems."^^schema:Text ;
    schema:author "Minoru Asada"^^schema:Person,
        "Ryo Iwaki"^^schema:Person ;
    schema:dateModified "2017-11-01T08:37:34Z"^^schema:DateTime ;
    schema:datePublished "2017-10-10T08:18:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On- and Off-Policy Monotonic Policy Improvement"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.03442v2"^^schema:URL .

<699> a schema:ScholarlyArticle ;
    schema:abstract "To model time-varying nonlinear temporal dynamics in sequential data, arecurrent network capable of varying and adjusting the recurrence depth betweeninput intervals is examined. The recurrence depth is extended by severalintermediate hidden state units, and the weight parameters involved indetermining these units are dynamically calculated. The motivation behind thepaper lies on overcoming a deficiency in Recurrent Highway Networks andimproving their performances which are currently at the forefront of RNNs: 1)Determining the appropriate number of recurrent depth in RHN for differenttasks is a huge burden and just setting it to a large number is computationallywasteful with possible repercussion in terms of performance degradation andhigh latency. Expanding on the idea of adaptive computation time (ACT), withthe use of an elastic gate in the form of a rectified exponentially decreasingfunction taking on as arguments as previous hidden state and input, theproposed model is able to evaluate the appropriate recurrent depth for eachinput. The rectified gating function enables the most significant intermediatehidden state updates to come early such that significant performance gain isachieved early. 2) Updating the weights from that of previous intermediatelayer offers a richer representation than the use of shared weights across allintermediate recurrence layers. The weight update procedure is just anexpansion of the idea underlying hypernetworks. To substantiate theeffectiveness of the proposed network, we conducted three experiments:regression on synthetic data, human activity recognition, and language modelingon the Penn Treebank dataset. The proposed networks showed better performancethan other state-of-the-art recurrent networks in all three experiments."^^schema:Text ;
    schema:author "Chang D. Yoo"^^schema:Person,
        "Hyunsin Park"^^schema:Person ;
    schema:dateModified "2017-08-14T13:39:28Z"^^schema:DateTime ;
    schema:datePublished "2017-08-14T13:39:28Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Early Improving Recurrent Elastic Highway Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.04116v1"^^schema:URL .

<7> a schema:ScholarlyArticle ;
    schema:abstract "We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for buildinga generative model of the data distribution. WAE minimizes a penalized form ofthe Wasserstein distance between the model distribution and the targetdistribution, which leads to a different regularizer than the one used by theVariational Auto-Encoder (VAE). This regularizer encourages the encodedtraining distribution to match the prior. We compare our algorithm with severalother techniques and show that it is a generalization of adversarialauto-encoders (AAE). Our experiments show that WAE shares many of theproperties of VAEs (stable training, encoder-decoder architecture, nice latentmanifold structure) while generating samples of better quality, as measured bythe FID score."^^schema:Text ;
    schema:author "Bernhard Schoelkopf"^^schema:Person,
        "Ilya Tolstikhin"^^schema:Person,
        "Olivier Bousquet"^^schema:Person,
        "Sylvain Gelly"^^schema:Person ;
    schema:commentCount "371"^^schema:Integer ;
    schema:dateModified "2019-12-05T10:27:44Z"^^schema:DateTime ;
    schema:datePublished "2017-11-05T10:18:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Wasserstein Auto-Encoders"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.01558v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1669877132293977025&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<70> a schema:ScholarlyArticle ;
    schema:abstract "Generic generation and manipulation of text is challenging and has limitedsuccess compared to recent deep generative modeling in visual domain. Thispaper aims at generating plausible natural language sentences, whose attributesare dynamically controlled by learning disentangled latent representations withdesignated semantics. We propose a new neural generative model which combinesvariational auto-encoders and holistic attribute discriminators for effectiveimposition of semantic structures. With differentiable approximation todiscrete text samples, explicit constraints on independent attribute controls,and efficient collaborative learning of generator and discriminators, our modellearns highly interpretable representations from even only word annotations,and produces realistic sentences with desired attributes. Quantitativeevaluation validates the accuracy of sentence and attribute generation."^^schema:Text ;
    schema:author "Eric P. Xing"^^schema:Person,
        "Ruslan Salakhutdinov"^^schema:Person,
        "Xiaodan Liang"^^schema:Person,
        "Zhiting Hu"^^schema:Person,
        "Zichao Yang"^^schema:Person ;
    schema:commentCount "401"^^schema:Integer ;
    schema:dateModified "2018-09-13T02:16:40Z"^^schema:DateTime ;
    schema:datePublished "2017-03-02T21:23:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Toward Controlled Generation of Text"^^schema:Text ;
    schema:publisher "ICML, 1587-1596"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.00955v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14533919283203963154&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<700> a schema:ScholarlyArticle ;
    schema:abstract "We propose a transition-based approach that, by training a single model, canefficiently parse any input sentence with both constituent and dependencytrees, supporting both continuous/projective and discontinuous/non-projectivesyntactic structures. To that end, we develop a Pointer Network architecturewith two separate task-specific decoders and a common encoder, and follow amultitask learning strategy to jointly train them. The resulting quadraticsystem, not only becomes the first parser that can jointly produce bothunrestricted constituent and dependency trees from a single model, but alsoproves that both syntactic formalisms can benefit from each other duringtraining, achieving state-of-the-art accuracies in several widely-usedbenchmarks such as the continuous English and Chinese Penn Treebanks, as wellas the discontinuous German NEGRA and TIGER datasets."^^schema:Text ;
    schema:author "Carlos Gómez-Rodríguez"^^schema:Person,
        "Daniel Fernández-González"^^schema:Person ;
    schema:dateModified "2020-09-21T10:04:07Z"^^schema:DateTime ;
    schema:datePublished "2020-09-21T10:04:07Z"^^schema:DateTime ;
    schema:genre "68T50"^^schema:Text,
        "I.2.7"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Multitask Pointer Network for Multi-Representational Parsing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.09730v1"^^schema:URL .

<701> a schema:ScholarlyArticle ;
    schema:abstract "Machine reading using differentiable reasoning models has recently shownremarkable progress. In this context, End-to-End trainable Memory Networks,MemN2N, have demonstrated promising performance on simple natural languagebased reasoning tasks such as factual reasoning and basic deduction. However,other tasks, namely multi-fact question-answering, positional reasoning ordialog related tasks, remain challenging particularly due to the necessity ofmore complex interactions between the memory and controller modules composingthis family of models. In this paper, we introduce a novel end-to-end memoryaccess regulation mechanism inspired by the current progress on the connectionshort-cutting principle in the field of computer vision. Concretely, we developa Gated End-to-End trainable Memory Network architecture, GMemN2N. From themachine learning perspective, this new capability is learned in an end-to-endfashion without the use of any additional supervision signal which is, as faras our knowledge goes, the first of its kind. Our experiments show significantimprovements on the most challenging tasks in the 20 bAbI dataset, without theuse of any domain knowledge. Then, we show improvements on the dialog bAbItasks including the real human-bot conversion-based Dialog State TrackingChallenge (DSTC-2) dataset. On these two datasets, our model sets the new stateof the art."^^schema:Text ;
    schema:author "Fei Liu"^^schema:Person,
        "Julien Perez"^^schema:Person ;
    schema:dateModified "2016-11-17T15:09:29Z"^^schema:DateTime ;
    schema:datePublished "2016-10-13T19:38:03Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Gated End-to-End Memory Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1610.04211v2"^^schema:URL .

<702> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement Learning (RL) algorithms typically require millions ofenvironment interactions to learn successful policies in sparse rewardsettings. Hindsight Experience Replay (HER) was introduced as a technique toincrease sample efficiency by reimagining unsuccessful trajectories assuccessful ones by altering the originally intended goals. However, it cannotbe directly applied to visual environments where goal states are oftencharacterized by the presence of distinct visual features. In this work, weshow how visual trajectories can be hallucinated to appear successful byaltering agent observations using a generative model trained on relatively fewsnapshots of the goal. We then use this model in combination with HER to trainRL agents in visual settings. We validate our approach on 3D navigation tasksand a simulated robotics application and show marked improvement over baselinesderived from previous work."^^schema:Text ;
    schema:author "Himanshu Sahni"^^schema:Person,
        "Ilya Kuzovkin"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Toby Buckley"^^schema:Person ;
    schema:dateModified "2019-10-30T02:23:49Z"^^schema:DateTime ;
    schema:datePublished "2019-01-31T18:50:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory  GANs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.11529v2"^^schema:URL .

<703> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks (NNs) have been widely applied in speech processing tasks,and, in particular, those employing microphone arrays. Nevertheless, most ofthe existing NN architectures can only deal with fixed and position-specificmicrophone arrays. In this paper, we present an NN architecture that can copewith microphone arrays on which no prior knowledge is presumed, and demonstrateits applicability on the speech dereverberation problem. To this end, ourapproach harnesses recent advances in the Deep Sets framework to design anarchitecture that enhances the reverberant log-spectrum. We provide a setup fortraining and testing such a network. Our experiments, using REVERB challengedatasets, show that the proposed position-agnostic setup performs comparablywith the position-aware framework and sometimes slightly better, even withfewer microphones. In addition, it substantially improves performance over asingle microphone architecture."^^schema:Text ;
    schema:author "Ethan Fetaya"^^schema:Person,
        "Haggai Maron"^^schema:Person,
        "Sharon Gannot"^^schema:Person,
        "Yochai Yemini"^^schema:Person ;
    schema:dateModified "2020-10-22T17:13:12Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T17:13:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Position-Agnostic Multi-Microphone Speech Dereverberation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11875v1"^^schema:URL .

<704> a schema:ScholarlyArticle ;
    schema:abstract "Autopilot systems are typically composed of an \"inner loop\" providingstability and control, while an \"outer loop\" is responsible for mission-levelobjectives, e.g. way-point navigation. Autopilot systems for UAVs arepredominately implemented using Proportional, Integral Derivative (PID) controlsystems, which have demonstrated exceptional performance in stableenvironments. However more sophisticated control is required to operate inunpredictable, and harsh environments. Intelligent flight control systems is anactive area of research addressing limitations of PID control most recentlythrough the use of reinforcement learning (RL) which has had success in otherapplications such as robotics. However previous work has focused primarily onusing RL at the mission-level controller. In this work, we investigate theperformance and accuracy of the inner control loop providing attitude controlwhen using intelligent flight control systems trained with the state-of-the-artRL algorithms, Deep Deterministic Gradient Policy (DDGP), Trust Region PolicyOptimization (TRPO) and Proximal Policy Optimization (PPO). To investigatethese unknowns we first developed an open-source high-fidelity simulationenvironment to train a flight controller attitude control of a quadrotorthrough RL. We then use our environment to compare their performance to that ofa PID controller to identify if using RL is appropriate in high-precision,time-critical flight control."^^schema:Text ;
    schema:author "Azer Bestavros"^^schema:Person,
        "Renato Mancuso"^^schema:Person,
        "Richard West"^^schema:Person,
        "William Koch"^^schema:Person ;
    schema:dateModified "2018-04-11T18:16:50Z"^^schema:DateTime ;
    schema:datePublished "2018-04-11T18:16:50Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Reinforcement Learning for UAV Attitude Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.04154v1"^^schema:URL .

<705> a schema:ScholarlyArticle ;
    schema:abstract "We explore Deep Reinforcement Learning in a parameterized action space.Specifically, we investigate how to achieve sample-efficient end-to-endtraining in these tasks. We propose a new compact architecture for the taskswhere the parameter policy is conditioned on the output of the discrete actionpolicy. We also propose two new methods based on the state-of-the-artalgorithms Trust Region Policy Optimization (TRPO) and Stochastic ValueGradient (SVG) to train such an architecture. We demonstrate that these methodsoutperform the state of the art method, Parameterized Action DDPG, on testdomains."^^schema:Text ;
    schema:author "Drew Wicke"^^schema:Person,
        "Ermo Wei"^^schema:Person,
        "Sean Luke"^^schema:Person ;
    schema:dateModified "2018-10-23T04:52:53Z"^^schema:DateTime ;
    schema:datePublished "2018-10-23T04:52:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Approaches for Reinforcement Learning in Parameterized  Action Space"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.09656v1"^^schema:URL .

<706> a schema:ScholarlyArticle ;
    schema:abstract "With the tremendous growth of videos over the Internet, video thumbnails,providing video content previews, are becoming increasingly crucial toinfluencing users' online searching experiences. Conventional video thumbnailsare generated once purely based on the visual characteristics of videos, andthen displayed as requested. Hence, such video thumbnails, without consideringthe users' searching intentions, cannot provide a meaningful snapshot of thevideo contents that users concern. In this paper, we define a distinctively newtask, namely sentence specified dynamic video thumbnail generation, where thegenerated thumbnails not only provide a concise preview of the original videocontents but also dynamically relate to the users' searching intentions withsemantic correspondences to the users' query sentences. To tackle such achallenging task, we propose a novel graph convolved video thumbnail pointer(GTP). Specifically, GTP leverages a sentence specified video graphconvolutional network to model both the sentence-video semantic interaction andthe internal video relationships incorporated with the sentence information,based on which a temporal conditioned pointer network is then introduced tosequentially generate the sentence specified video thumbnails. Moreover, weannotate a new dataset based on ActivityNet Captions for the proposed new task,which consists of 10,000+ video-sentence pairs with each accompanied by anannotated sentence specified video thumbnail. We demonstrate that our proposedGTP outperforms several baseline methods on the created dataset, and thusbelieve that our initial results along with the release of the new dataset willinspire further research on sentence specified dynamic video thumbnailgeneration. Dataset and code are available at https://github.com/yytzsy/GTP."^^schema:Text ;
    schema:author "Lin Ma"^^schema:Person,
        "Wenwu Zhu"^^schema:Person,
        "Yitian Yuan"^^schema:Person ;
    schema:dateModified "2019-10-16T09:47:43Z"^^schema:DateTime ;
    schema:datePublished "2019-08-12T08:35:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Sentence Specified Dynamic Video Thumbnail Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.04052v2"^^schema:URL .

<707> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Imitation Learning (GAIL) is a powerful and practicalapproach for learning sequential decision-making policies. Different fromReinforcement Learning (RL), GAIL takes advantage of demonstration data byexperts (e.g., human), and learns both the policy and reward function of theunknown environment. Despite the significant empirical progresses, the theorybehind GAIL is still largely unknown. The major difficulty comes from theunderlying temporal dependency of the demonstration data and the minimaxcomputational formulation of GAIL without convex-concave structure. To bridgesuch a gap between theory and practice, this paper investigates the theoreticalproperties of GAIL. Specifically, we show: (1) For GAIL with general rewardparameterization, the generalization can be guaranteed as long as the class ofthe reward functions is properly controlled; (2) For GAIL, where the reward isparameterized as a reproducing kernel function, GAIL can be efficiently solvedby stochastic first order optimization algorithms, which attain sublinearconvergence to a stationary solution. To the best of our knowledge, these arethe first results on statistical and computational guarantees of imitationlearning with reward/policy function approximation. Numerical experiments areprovided to support our analysis."^^schema:Text ;
    schema:author "Minshuo Chen"^^schema:Person,
        "Tianyi Liu"^^schema:Person,
        "Tuo Zhao"^^schema:Person,
        "Xingguo Li"^^schema:Person,
        "Yizhou Wang"^^schema:Person,
        "Zhaoran Wang"^^schema:Person,
        "Zhuoran Yang"^^schema:Person ;
    schema:dateModified "2020-01-12T03:31:31Z"^^schema:DateTime ;
    schema:datePublished "2020-01-09T00:40:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Computation and Generalization of Generative Adversarial Imitation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.02792v2"^^schema:URL .

<708> a schema:ScholarlyArticle ;
    schema:abstract "Taking greedy decoding algorithm as it should be, this work focuses onfurther strengthening the model itself for Chinese word segmentation (CWS),which results in an even more fast and more accurate CWS model. Our modelconsists of an attention only stacked encoder and a light enough decoder forthe greedy segmentation plus two highway connections for smoother training, inwhich the encoder is composed of a newly proposed Transformer variant,Gaussian-masked Directional (GD) Transformer, and a biaffine attention scorer.With the effective encoder design, our model only needs to take unigramfeatures for scoring. Our model is evaluated on SIGHAN Bakeoff benchmarkdatasets. The experimental results show that with the highest segmentationspeed, the proposed model achieves new state-of-the-art or comparableperformance against strong baselines in terms of strict closed test setting."^^schema:Text ;
    schema:author "Hai Zhao"^^schema:Person,
        "Sufeng Duan"^^schema:Person ;
    schema:dateModified "2020-10-06T06:38:42Z"^^schema:DateTime ;
    schema:datePublished "2019-10-31T15:32:19Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Attention Is All You Need for Chinese Word Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.14537v3"^^schema:URL .

<709> a schema:ScholarlyArticle ;
    schema:abstract "A critical part of multi-person multi-camera tracking is personre-identification (re-ID) algorithm, which recognizes and retains identities ofall detected unknown people throughout the video stream. Many re-ID algorithmstoday exemplify state of the art results, but not much work has been done toexplore the deployment of such algorithms for computation and power constrainedreal-time scenarios. In this paper, we study the effect of using a light-weightmodel, MobileNet-v2 for re-ID and investigate the impact of single (FP32)precision versus half (FP16) precision for training on the server and inferenceon the edge nodes. We further compare the results with the baseline model whichuses ResNet-50 on state of the art benchmarks including CUHK03, Market-1501,and Duke-MTMC. The MobileNet-V2 mixed precision training method can improveboth inference throughput on the edge node, and training time on server$3.25\\times$ reaching to 27.77fps and $1.75\\times$, respectively and decreasespower consumption on the edge node by $1.45\\times$, while it deterioratesaccuracy only 5.6\\% in respect to ResNet-50 single precision on the average forthree different datasets. The code and pre-trained networks are publiclyavailable at https://github.com/TeCSAR-UNCC/person-reid."^^schema:Text ;
    schema:author "Hamed Tabkhi"^^schema:Person,
        "Mohammadreza Baharani"^^schema:Person,
        "Shrey Mohan"^^schema:Person ;
    schema:dateModified "2019-08-19T23:38:53Z"^^schema:DateTime ;
    schema:datePublished "2019-08-19T23:38:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Real-time Person Re-identification at the Edge: A Mixed Precision  Approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.07842v1"^^schema:URL .

<71> a schema:ScholarlyArticle ;
    schema:abstract "We propose to study the problem of few-shot learning with the prism ofinference on a partially observed graphical model, constructed from acollection of input images whose label can be either observed or not. Byassimilating generic message-passing inference algorithms with theirneural-network counterparts, we define a graph neural network architecture thatgeneralizes several of the recently proposed few-shot learning models. Besidesproviding improved numerical performance, our framework is easily extended tovariants of few-shot learning, such as semi-supervised or active learning,demonstrating the ability of graph-based models to operate well on 'relational'tasks."^^schema:Text ;
    schema:author "Joan Bruna"^^schema:Person,
        "Victor Garcia"^^schema:Person ;
    schema:commentCount "259"^^schema:Integer ;
    schema:dateModified "2018-02-20T16:52:36Z"^^schema:DateTime ;
    schema:datePublished "2017-11-10T23:32:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Few-Shot Learning with Graph Neural Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.04043v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15420545241088720867&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<710> a schema:ScholarlyArticle ;
    schema:abstract "We present a visually grounded model of speech perception which projectsspoken utterances and images to a joint semantic space. We use a multi-layerrecurrent highway network to model the temporal nature of spoken speech, andshow that it learns to extract both form and meaning-based linguistic knowledgefrom the input signal. We carry out an in-depth analysis of the representationsused by different components of the trained model and show that encoding ofsemantic aspects tends to become richer as we go up the hierarchy of layers,whereas encoding of form-related aspects of the language input tends toinitially increase and then plateau or decrease."^^schema:Text ;
    schema:author "Afra Alishahi"^^schema:Person,
        "Grzegorz Chrupała"^^schema:Person,
        "Lieke Gelderloos"^^schema:Person ;
    schema:dateModified "2017-06-30T07:34:55Z"^^schema:DateTime ;
    schema:datePublished "2017-02-07T13:02:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Representations of language in a model of visually grounded speech  signal"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1702.01991v3"^^schema:URL .

<711> a schema:ScholarlyArticle ;
    schema:abstract "Exploring the idea of phase retrieval has been intriguing researchers fordecades, due to its appearance in a wide range of applications. The task of aphase retrieval algorithm is typically to recover a signal from linearphaseless measurements. In this paper, we approach the problem by proposing ahybrid model-based data-driven deep architecture, referred to as Unfolded PhaseRetrieval (UPR), that exhibits significant potential in improving theperformance of state-of-the art data-driven and model-based phase retrievalalgorithms. The proposed method benefits from versatility and interpretabilityof well-established model-based algorithms, while simultaneously benefitingfrom the expressive power of deep neural networks. In particular, our proposedmodel-based deep architecture is applied to the conventional phase retrievalproblem (via the incremental reshaped Wirtinger flow algorithm) and the sparsephase retrieval problem (via the sparse truncated amplitude flow algorithm),showing immense promise in both cases. Furthermore, we consider a joint designof the sensing matrix and the signal processing algorithm and utilize the deepunfolding technique in the process. Our numerical results illustrate theeffectiveness of such hybrid model-based and data-driven frameworks andshowcase the untapped potential of data-aided methodologies to enhance theexisting phase retrieval algorithms."^^schema:Text ;
    schema:author "Mojtaba Soltanalian"^^schema:Person,
        "Naveed Naimipour"^^schema:Person,
        "Shahin Khobahi"^^schema:Person ;
    schema:dateModified "2020-12-21T03:46:17Z"^^schema:DateTime ;
    schema:datePublished "2020-12-21T03:46:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Unfolded Algorithms for Deep Phase Retrieval"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11102v1"^^schema:URL .

<712> a schema:ScholarlyArticle ;
    schema:abstract "The outbreak of the coronavirus disease 2019 (COVID-19) has now spreadthroughout the globe infecting over 100 million people and causing the death ofover 2.2 million people. Thus, there is an urgent need to study the dynamics ofepidemiological models to gain a better understanding of how such diseasesspread. While epidemiological models can be computationally expensive, recentadvances in machine learning techniques have given rise to neural networks withthe ability to learn and predict complex dynamics at reduced computationalcosts. Here we introduce two digital twins of a SEIRS model applied to anidealised town. The SEIRS model has been modified to take account of spatialvariation and, where possible, the model parameters are based on official virusspreading data from the UK. We compare predictions from a data-correctedBidirectional Long Short-Term Memory network and a predictive GenerativeAdversarial Network. The predictions given by these two frameworks are accuratewhen compared to the original SEIRS model data. Additionally, these frameworksare data-agnostic and could be applied to towns, idealised or real, in the UKor in other countries. Also, more compartments could be included in the SEIRSmodel, in order to study more realistic epidemiological behaviour."^^schema:Text ;
    schema:author "Christopher C. Pain"^^schema:Person,
        "Claire E. Heaney"^^schema:Person,
        "César Quilodrán-Casas"^^schema:Person,
        "Rossella Arcucci"^^schema:Person,
        "Vinicius Santos Silva"^^schema:Person,
        "Yike Guo"^^schema:Person ;
    schema:dateModified "2021-02-03T11:54:24Z"^^schema:DateTime ;
    schema:datePublished "2021-02-03T11:54:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "physics.soc-ph"^^schema:Text ;
    schema:headline "Digital twins based on bidirectional LSTM and GAN for modelling COVID-19"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02664v1"^^schema:URL .

<713> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel solution to challenging sparse-reward, continuous controlproblems that require hierarchical planning at multiple levels of abstraction.Our solution, dubbed AlphaNPI-X, involves three separate stages of learning.First, we use off-policy reinforcement learning algorithms with experiencereplay to learn a set of atomic goal-conditioned policies, which can be easilyrepurposed for many tasks. Second, we learn self-models describing the effectof the atomic policies on the environment. Third, the self-models are harnessedto learn recursive compositional programs with multiple levels of abstraction.The key insight is that the self-models enable planning by imagination,obviating the need for interaction with the world when learning higher-levelcompositional programs. To accomplish the third stage of learning, we extendthe AlphaNPI algorithm, which applies AlphaZero to learn recursive neuralprogrammer-interpreters. We empirically show that AlphaNPI-X can effectivelylearn to tackle challenging sparse manipulation tasks, such as stackingmultiple blocks, where powerful model-free baselines fail."^^schema:Text ;
    schema:author "Alexandre Laterre"^^schema:Person,
        "Feryal Behbahani"^^schema:Person,
        "Karim Beguir"^^schema:Person,
        "Nando de Freitas"^^schema:Person,
        "Nicolas Perrin"^^schema:Person,
        "Olivier Sigaud"^^schema:Person,
        "Thomas Pierrot"^^schema:Person ;
    schema:dateModified "2020-07-27T08:27:14Z"^^schema:DateTime ;
    schema:datePublished "2020-07-27T08:27:14Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Learning Compositional Neural Programs for Continuous Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.13363v1"^^schema:URL .

<714> a schema:ScholarlyArticle ;
    schema:abstract "Residual neural networks (ResNets) are a promising class of deep neuralnetworks that have shown excellent performance for a number of learning tasks,e.g., image classification and recognition. Mathematically, ResNetarchitectures can be interpreted as forward Euler discretizations of anonlinear initial value problem whose time-dependent control variablesrepresent the weights of the neural network. Hence, training a ResNet can becast as an optimal control problem of the associated dynamical system. Forsimilar time-dependent optimal control problems arising in engineeringapplications, parallel-in-time methods have shown notable improvements inscalability. This paper demonstrates the use of those techniques for efficientand effective training of ResNets. The proposed algorithms replace theclassical (sequential) forward and backward propagation through the networklayers by a parallel nonlinear multigrid iteration applied to the layer domain.This adds a new dimension of parallelism across layers that is attractive whentraining very deep networks. From this basic idea, we derive multiplelayer-parallel methods. The most efficient version employs a simultaneousoptimization approach where updates to the network parameters are based oninexact gradient information in order to speed up the training process. Usingnumerical examples from supervised classification, we demonstrate that the newapproach achieves similar training performance to traditional methods, butenables layer-parallelism and thus provides speedup over layer-serial methodsthrough greater concurrency."^^schema:Text ;
    schema:author "E. C. Cyr"^^schema:Person,
        "J. B. Schroder"^^schema:Person,
        "L. Ruthotto"^^schema:Person,
        "N. R. Gauger"^^schema:Person,
        "S. Günther"^^schema:Person ;
    schema:dateModified "2019-07-25T05:58:00Z"^^schema:DateTime ;
    schema:datePublished "2018-12-11T12:26:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Layer-Parallel Training of Deep Residual Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.04352v3"^^schema:URL .

<715> a schema:ScholarlyArticle ;
    schema:abstract "Expert Iteration (ExIt) is an effective framework for learning game-playingpolicies from self-play. ExIt involves training a policy to mimic the searchbehaviour of a tree search algorithm - such as Monte-Carlo tree search - andusing the trained policy to guide it. The policy and the tree search can theniteratively improve each other, through experience gathered in self-playbetween instances of the guided tree search algorithm. This paper outlinesthree different approaches for manipulating the distribution of data collectedfrom self-play, and the procedure that samples batches for learning updatesfrom the collected data. Firstly, samples in batches are weighted based on thedurations of the episodes in which they were originally experienced. Secondly,Prioritized Experience Replay is applied within the ExIt framework, toprioritise sampling experience from which we expect to obtain valuable trainingsignals. Thirdly, a trained exploratory policy is used to diversify thetrajectories experienced in self-play. This paper summarises the effects ofthese manipulations on training performance evaluated in fourteen differentboard games. We find major improvements in early training performance in somegames, and minor improvements averaged over fourteen games."^^schema:Text ;
    schema:author "Cameron Browne"^^schema:Person,
        "Dennis J. N. J. Soemers"^^schema:Person,
        "Matthew Stephenson"^^schema:Person,
        "Éric Piette"^^schema:Person ;
    schema:dateModified "2020-05-30T14:32:46Z"^^schema:DateTime ;
    schema:datePublished "2020-05-30T14:32:46Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Manipulating the Distributions of Experience used for Self-Play Learning  in Expert Iteration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.00283v1"^^schema:URL .

<716> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes an extremely lightweight phone-based transducer modelwith a tiny decoding graph on edge devices. First, a phone synchronous decoding(PSD) algorithm based on blank label skipping is first used to speed up thetransducer decoding process. Then, to decrease the deletion errors introducedby the high blank score, a blank label deweighting approach is proposed. Toreduce parameters and computation, deep feedforward sequential memory network(DFSMN) layers are used in the transducer encoder, and a CNN-based statelesspredictor is adopted. SVD technology compresses the model further. WFST-baseddecoding graph takes the context-independent (CI) phone posteriors as input andallows us to flexibly bias user-specific information. Finally, with only 0.9Mparameters after SVD, our system could give a relative 9.1% - 20.5% improvementcompared with a bigger conventional hybrid system on edge devices."^^schema:Text ;
    schema:author "Long Ma"^^schema:Person,
        "Sining Sun"^^schema:Person,
        "Yuekai Zhang"^^schema:Person ;
    schema:dateModified "2021-02-07T06:11:04Z"^^schema:DateTime ;
    schema:datePublished "2021-01-18T03:07:57Z"^^schema:DateTime ;
    schema:genre "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Tiny Transducer: A Highly-efficient Speech Recognition Model on Edge  Devices"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.06856v2"^^schema:URL .

<717> a schema:ScholarlyArticle ;
    schema:abstract "In this thesis, I propose a family of fully decentralized deep multi-agentreinforcement learning (MARL) algorithms to achieve high, real-time performancein network-level traffic signal control. In this approach, each intersection ismodeled as an agent that plays a Markovian Game against the other intersectionnodes in a traffic signal network modeled as an undirected graph, to approachthe optimal reduction in delay. Following Partially Observable Markov DecisionProcesses (POMDPs), there are 3 levels of communication schemes betweenadjacent learning agents: independent deep Q-leaning (IDQL), shared statesreinforcement learning (S2RL) and a shared states &amp; rewards version ofS2RL--S2R2L. In these 3 variants of decentralized MARL schemes, individualagent trains its local deep Q network (DQN) separately, enhanced byconvergence-guaranteed techniques like double DQN, prioritized experiencereplay, multi-step bootstrapping, etc. To test the performance of the proposedthree MARL algorithms, a SUMO-based simulation platform is developed to mimicthe traffic evolution of the real world. Fed with random traffic demand betweenpermitted OD pairs, a 4x4 Manhattan-style grid network is set up as thetestbed, two different vehicle arrival rates are generated for model trainingand testing. The experiment results show that S2R2L has a quicker convergencerate and better convergent performance than IDQL and S2RL in the trainingprocess. Moreover, three MARL schemes all reveal exceptional generalizationabilities. Their testing results surpass the benchmark Max Pressure (MP)algorithm, under the criteria of average vehicle delay, network-level queuelength and fuel consumption rate. Notably, S2R2L has the best testingperformance of reducing 34.55% traffic delay and dissipating 10.91% queuelength compared with MP."^^schema:Text ;
    schema:author "Jin Guo"^^schema:Person ;
    schema:dateModified "2020-07-17T23:15:45Z"^^schema:DateTime ;
    schema:datePublished "2020-07-02T06:58:27Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Decentralized Deep Reinforcement Learning for Network Level Traffic  Signal Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.03433v2"^^schema:URL .

<718> a schema:ScholarlyArticle ;
    schema:abstract "This paper studies the practicality of the current state-of-the-artunsupervised methods in neural machine translation (NMT). In ten translationtasks with various data settings, we analyze the conditions under which theunsupervised methods fail to produce reasonable translations. We show thattheir performance is severely affected by linguistic dissimilarity and domainmismatch between source and target monolingual data. Such conditions are commonfor low-resource language pairs, where unsupervised learning works poorly. Inall of our experiments, supervised and semi-supervised baselines with50k-sentence bilingual data outperform the best unsupervised results. Ouranalyses pinpoint the limits of the current unsupervised NMT and also suggestimmediate research directions."^^schema:Text ;
    schema:author "Hermann Ney"^^schema:Person,
        "Miguel Graça"^^schema:Person,
        "Yunsu Kim"^^schema:Person ;
    schema:dateModified "2020-04-22T14:00:55Z"^^schema:DateTime ;
    schema:datePublished "2020-04-22T14:00:55Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "When and Why is Unsupervised Neural Machine Translation Useless?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10581v1"^^schema:URL .

<719> a schema:ScholarlyArticle ;
    schema:abstract "In this paper we consider the problem of combining multiple probabilisticcausal models, provided by different experts, under the requirement that theaggregated model satisfy the criterion of counterfactual fairness. We buildupon the work on causal models and fairness in machine learning, and we expressthe problem of combining multiple models within the framework of opinionpooling. We propose two simple algorithms, grounded in the theory ofcounterfactual fairness and causal judgment aggregation, that are guaranteed togenerate aggregated probabilistic causal models respecting the criterion offairness, and we compare their behaviors on a toy case study."^^schema:Text ;
    schema:author "Fabio Massimo Zennaro"^^schema:Person,
        "Magdalena Ivanovska"^^schema:Person ;
    schema:dateModified "2018-10-01T12:56:06Z"^^schema:DateTime ;
    schema:datePublished "2018-05-24T19:39:20Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text ;
    schema:headline "Pooling of Causal Models under Counterfactual Fairness via Causal  Judgement Aggregation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.09866v2"^^schema:URL .

<72> a schema:ScholarlyArticle ;
    schema:abstract "Over the last years, deep convolutional neural networks (ConvNets) havetransformed the field of computer vision thanks to their unparalleled capacityto learn high level semantic image features. However, in order to successfullylearn those features, they usually require massive amounts of manually labeleddata, which is both expensive and impractical to scale. Therefore, unsupervisedsemantic feature learning, i.e., learning without requiring manual annotationeffort, is of crucial importance in order to successfully harvest the vastamount of visual data that are available today. In our work we propose to learnimage features by training ConvNets to recognize the 2d rotation that isapplied to the image that it gets as input. We demonstrate both qualitativelyand quantitatively that this apparently simple task actually provides a verypowerful supervisory signal for semantic feature learning. We exhaustivelyevaluate our method in various unsupervised feature learning benchmarks and weexhibit in all of them state-of-the-art performance. Specifically, our resultson those benchmarks demonstrate dramatic improvements w.r.t. priorstate-of-the-art approaches in unsupervised representation learning and thussignificantly close the gap with supervised feature learning. For instance, inPASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet modelachieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that isonly 2.4 points lower from the supervised case. We get similarly strikingresults when we transfer our unsupervised learned features on various othertasks, such as ImageNet classification, PASCAL classification, PASCALsegmentation, and CIFAR-10 classification. The code and models of our paperwill be published on: https://github.com/gidariss/FeatureLearningRotNet ."^^schema:Text ;
    schema:author "Nikos Komodakis"^^schema:Person,
        "Praveer Singh"^^schema:Person,
        "Spyros Gidaris"^^schema:Person ;
    schema:commentCount "333"^^schema:Integer ;
    schema:dateModified "2018-03-21T03:21:14Z"^^schema:DateTime ;
    schema:datePublished "2018-03-21T03:21:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Representation Learning by Predicting Image Rotations"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1803.07728v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12748509220929577948&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<720> a schema:ScholarlyArticle ;
    schema:abstract "We characterize the growth of the Sibson mutual information, of any orderthat is at least unity, between a random variable and an increasing set ofnoisy, conditionally independent observations of the random variable. TheSibson mutual information increases to an order-dependent limit exponentiallyfast, with an exponent that is order-independent. The result is contrasted withcomposition theorems in differential privacy."^^schema:Text ;
    schema:author "Aaron B. Wagner"^^schema:Person,
        "Benjamin Wu"^^schema:Person,
        "G. Edward Suh"^^schema:Person,
        "Ibrahim Issa"^^schema:Person ;
    schema:dateModified "2020-05-12T20:08:30Z"^^schema:DateTime ;
    schema:datePublished "2020-05-12T20:08:30Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "Strong Asymptotic Composition Theorems for Sibson Mutual Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.06033v1"^^schema:URL .

<721> a schema:ScholarlyArticle ;
    schema:abstract "Bandwidth forecasting in Mobile Broadband (MBB) networks is a challengingtask, particularly when coupled with a degree of mobility. In this work, weintroduce HINDSIGHT++, an open-source R-based framework for bandwidthforecasting experimentation in MBB networks with Long Short Term Memory (LSTM)networks. We instrument HINDSIGHT++ following an Automated Machine Learning(AutoML) paradigm to first, alleviate the burden of data preprocessing, andsecond, enhance performance related aspects. We primarily focus on bandwidthforecasting for Fifth Generation (5G) networks. In particular, we leverage5Gophers, the first open-source attempt to measure network performance onoperational 5G networks in the US. We further explore the LSTM performanceboundaries on Fourth Generation (4G) commercial settings using NYU-METS, anopen-source dataset comprising of hundreds of bandwidth traces spanningdifferent mobility scenarios. Our study aims to investigate the impact ofhyperparameter optimization on achieving state-of-the-art performance andbeyond. Results highlight its significance under 5G scenarios showing anaverage Mean Absolute Error (MAE) decrease of near 30% when compared to priorstate-of-the-art values. Due to its universal design, we argue that HINDSIGHT++can serve as a handy software tool for a multitude of applications in otherscientific fields."^^schema:Text ;
    schema:author "Antonios Argyriou"^^schema:Person,
        "Apostolos Pappas"^^schema:Person,
        "Konstantinos Kousias"^^schema:Person,
        "Michael Riegler"^^schema:Person,
        "Ozgu Alay"^^schema:Person ;
    schema:dateModified "2020-11-20T18:59:27Z"^^schema:DateTime ;
    schema:datePublished "2020-11-20T18:59:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text ;
    schema:headline "Long Short Term Memory Networks for Bandwidth Forecasting in Mobile  Broadband Networks under Mobility"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.10563v1"^^schema:URL .

<722> a schema:ScholarlyArticle ;
    schema:abstract "This paper explores convolutional generative networks as an alternative toiterative reconstruction algorithms in medical image reconstruction. The taskof medical image reconstruction involves mapping of projection main datacollected from the detector to the image domain. This mapping is done typicallythrough iterative reconstruction algorithms which are time consuming andcomputationally expensive. Trained deep learning networks provide fasteroutputs as proven in various tasks across computer vision. In this work wepropose a direct reconstruction framework exclusively with deep learningarchitectures. The proposed framework consists of three segments, namelydenoising, reconstruction and super resolution. The denoising and the superresolution segments act as processing steps. The reconstruction segmentconsists of a novel double U-Net generator (DUG) which learns thesinogram-to-image transformation. This entire network was trained on positronemission tomography (PET) and computed tomography (CT) images. Thereconstruction framework approximates two-dimensional (2-D) mapping fromprojection domain to image domain. The architecture proposed in thisproof-of-concept work is a novel approach to direct image reconstruction;further improvement is required to implement it in a clinical setting."^^schema:Text ;
    schema:author "Alexandre Bousse"^^schema:Person,
        "Didier Benoit"^^schema:Person,
        "Dimitris Visvikis"^^schema:Person,
        "V. S. S. Kandarpa"^^schema:Person ;
    schema:dateModified "2020-12-03T15:28:27Z"^^schema:DateTime ;
    schema:datePublished "2020-12-03T15:28:27Z"^^schema:DateTime ;
    schema:genre "physics.med-ph"^^schema:Text ;
    schema:headline "DUG-RECON: A Framework for Direct Image Reconstruction using  Convolutional Generative Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.02000v1"^^schema:URL .

<723> a schema:ScholarlyArticle ;
    schema:abstract "The heavy traffic congestion problem has always been a concern for moderncities. To alleviate traffic congestion, researchers use reinforcement learning(RL) to develop better traffic signal control (TSC) algorithms in recent years.However, most RL models are trained and tested in the same traffic flowenvironment, which results in a serious overfitting problem. Since the trafficflow environment in the real world keeps varying, these models can hardly beapplied due to the lack of generalization ability. Besides, the limited numberof accessible traffic flow data brings extra difficulty in testing thegeneralization ability of the models. In this paper, we design a novel trafficflow generator based on Wasserstein generative adversarial network to generatesufficient diverse and quality traffic flows and use them to build propertraining and testing environments. Then we propose a meta-RL TSC frameworkGeneraLight to improve the generalization ability of TSC models. GeneraLightboosts the generalization performance by combining the idea of flow clusteringand model-agnostic meta-learning. We conduct extensive experiments on multiplereal-world datasets to show the superior performance of GeneraLight ongeneralizing to different traffic flows."^^schema:Text ;
    schema:author "Chang Liu"^^schema:Person,
        "Guanjie Zheng"^^schema:Person,
        "Huichu Zhang"^^schema:Person,
        "Weinan Zhang"^^schema:Person,
        "Yong Yu"^^schema:Person ;
    schema:dateModified "2020-09-17T04:14:28Z"^^schema:DateTime ;
    schema:datePublished "2020-09-17T04:14:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "GeneraLight: Improving Environment Generalization of Traffic Signal  Control via Meta Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.08052v1"^^schema:URL .

<724> a schema:ScholarlyArticle ;
    schema:abstract "Question Answering systems are generally modelled as a pipeline consisting ofa sequence of steps. In such a pipeline, Entity Linking (EL) is often the firststep. Several EL models first perform span detection and then entitydisambiguation. In such models errors from the span detection phase cascade tolater steps and result in a drop of overall accuracy. Moreover, lack of goldentity spans in training data is a limiting factor for span detector training.Hence the movement towards end-to-end EL models began where no separate spandetection step is involved. In this work we present a novel approach toend-to-end EL by applying the popular Pointer Network model, which achievescompetitive performance. We demonstrate this in our evaluation over threedatasets on the Wikidata Knowledge Graph."^^schema:Text ;
    schema:author "Debanjan Chaudhuri"^^schema:Person,
        "Debayan Banerjee"^^schema:Person,
        "Jens Lehmann"^^schema:Person,
        "Mohnish Dubey"^^schema:Person ;
    schema:dateModified "2020-08-31T21:15:28Z"^^schema:DateTime ;
    schema:datePublished "2020-08-31T21:15:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "PNEL: Pointer Network based End-To-End Entity Linking over Knowledge  Graphs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.00106v1"^^schema:URL .

<725> a schema:ScholarlyArticle ;
    schema:abstract "We study the ability of neural networks to steer or control trajectories ofdynamical systems on graphs, which we represent with neural ordinarydifferential equations (neural ODEs). To do so, we introduce a neural-ODEcontrol (NODEC) framework and find that it can learn control signals that drivegraph dynamical systems into desired target states. While we use loss functionsthat do not constrain the control energy, our results show that NODEC producescontrol signals that are highly correlated with optimal (or minimum energy)control signals. Finally, we empirically showcase the high performance andversatility of NODEC for various (non-)linear dynamics and loss functions ondifferent graphs."^^schema:Text ;
    schema:author "Lucas Böttcher"^^schema:Person,
        "Nino Antulov-Fantulin"^^schema:Person,
        "Thomas Asikis"^^schema:Person ;
    schema:dateModified "2021-01-04T19:05:02Z"^^schema:DateTime ;
    schema:datePublished "2020-06-17T10:47:03Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Ordinary Differential Equation Control of Dynamics on Graphs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.09773v3"^^schema:URL .

<726> a schema:ScholarlyArticle ;
    schema:abstract "Advances in machine learning have revolutionized capabilities in applicationsranging from natural language processing to marketing to health care. Here, wedemonstrate the efficacy of machine learning in predicting chaotic behavior incomplex nonlinear mechanical systems. Specifically, we use quasi-recurrentneural networks to predict extremely chaotic time series data obtained frommultistable origami systems. Additionally, while machine learning is oftenviewed as a \"black box\", in this study we conduct hidden layer analysis tounderstand how the neural network can process not only periodic, but alsochaotic data in an accurate manner. Also, our approach shows its effectivenessin characterizing and predicting chaotic dynamics in a noisy environment ofvibrations without relying on a mathematical model of origami systems.Therefore, our method is fully data-driven and has the potential to be used forcomplex scenarios, such as the nonlinear dynamics of thin-walled structures andbiological membrane systems."^^schema:Text ;
    schema:author "Hiromi Yasuda"^^schema:Person,
        "Jinkyu Yang"^^schema:Person,
        "Jordan R. Raney"^^schema:Person,
        "Koshiro Yamaguchi"^^schema:Person,
        "Richard Wiebe"^^schema:Person,
        "Yasuhiro Miyazawa"^^schema:Person ;
    schema:dateModified "2020-02-26T17:30:38Z"^^schema:DateTime ;
    schema:datePublished "2020-02-26T17:30:38Z"^^schema:DateTime ;
    schema:genre "cond-mat.dis-nn"^^schema:Text,
        "cond-mat.soft"^^schema:Text,
        "physics.class-ph"^^schema:Text ;
    schema:headline "Data-driven prediction and analysis of chaotic origami dynamics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.12176v1"^^schema:URL .

<727> a schema:ScholarlyArticle ;
    schema:abstract "Recent studies on neural architecture search have shown that automaticallydesigned neural networks perform as good as expert-crafted architectures. Whilemost existing works aim at finding architectures that optimize the predictionaccuracy, these architectures may have complexity and is therefore not suitablebeing deployed on certain computing environment (e.g., with limited powerbudgets). We propose MONAS, a framework for Multi-Objective NeuralArchitectural Search that employs reward functions considering both predictionaccuracy and other important objectives (e.g., power consumption) whensearching for neural network architectures. Experimental results showed that,compared to the state-ofthe-arts, models found by MONAS achieve comparable orbetter classification accuracy on computer vision applications, whilesatisfying the additional objectives such as peak power."^^schema:Text ;
    schema:author "Chi-Hung Hsu"^^schema:Person,
        "Chun-Hao Liu"^^schema:Person,
        "Da-Cheng Juan"^^schema:Person,
        "Hsin-Ping Chou"^^schema:Person,
        "Jhao-Hong Liang"^^schema:Person,
        "Jia-Yu Pan"^^schema:Person,
        "Shih-Chieh Chang"^^schema:Person,
        "Shu-Huan Chang"^^schema:Person,
        "Wei Wei"^^schema:Person,
        "Yu-Ting Chen"^^schema:Person ;
    schema:dateModified "2018-12-03T06:54:48Z"^^schema:DateTime ;
    schema:datePublished "2018-06-27T08:12:01Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "MONAS: Multi-Objective Neural Architecture Search using Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.10332v2"^^schema:URL .

<728> a schema:ScholarlyArticle ;
    schema:abstract "Hypernetworks were recently shown to improve the performance of messagepassing algorithms for decoding error correcting codes. In this work, wedemonstrate how hypernetworks can be applied to decode polar codes by employinga new formalization of the polar belief propagation decoding scheme. Wedemonstrate that our method improves the previous results of neural polardecoders and achieves, for large SNRs, the same bit-error-rate performances asthe successive list cancellation method, which is known to be better than anybelief propagation decoders and very close to the maximum likelihood decoder."^^schema:Text ;
    schema:author "Eliya Nachmani"^^schema:Person,
        "Lior Wolf"^^schema:Person ;
    schema:dateModified "2020-02-10T11:08:54Z"^^schema:DateTime ;
    schema:datePublished "2019-11-08T12:58:43Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text ;
    schema:headline "A Gated Hypernet Decoder for Polar Codes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.03229v2"^^schema:URL .

<729> a schema:ScholarlyArticle ;
    schema:abstract "Time series classification problems exist in many fields and have beenexplored for a couple of decades. However, they still remain challenging, andtheir solutions need to be further improved for real-world applications interms of both accuracy and efficiency. In this paper, we propose a hybridneural architecture, called Self-Attentive Recurrent Convolutional Networks(SARCoN), to learn multi-faceted representations for univariate time series.SARCoN is the synthesis of long short-term memory networks with self-attentivemechanisms and Fully Convolutional Networks, which work in parallel to learnthe representations of univariate time series from different perspectives. Thecomponent modules of the proposed architecture are trained jointly in anend-to-end manner and they classify the input time series in a cooperative way.Due to its domain-agnostic nature, SARCoN is able to generalize a diversity ofdomain tasks. Our experimental results show that, compared to thestate-of-the-art approaches for time series classification, the proposedarchitecture can achieve remarkable improvements for a set of univariate timeseries benchmarks from the UCR repository. Moreover, the self-attention and theglobal average pooling in the proposed architecture enable visibleinterpretability by facilitating the identification of the contribution regionsof the original time series. An overall analysis confirms that multi-facetedrepresentations of time series aid in capturing deep temporal correctionswithin complex time series, which is essential for the improvement of timeseries classification performance. Our work provides a novel angle that deepensthe understanding of time series classification, qualifying our proposed modelas an ideal choice for real-world applications."^^schema:Text ;
    schema:author "Jian Cheng"^^schema:Person,
        "Zhenyu Liu"^^schema:Person ;
    schema:dateModified "2020-12-21T16:42:07Z"^^schema:DateTime ;
    schema:datePublished "2020-12-21T16:42:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Multi-Faceted Representation Learning with Hybrid Architecture for Time  Series Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11472v1"^^schema:URL .

<73> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we present a simple and efficient method for training deepneural networks in a semi-supervised setting where only a small portion oftraining data is labeled. We introduce self-ensembling, where we form aconsensus prediction of the unknown labels using the outputs of thenetwork-in-training on different epochs, and most importantly, under differentregularization and input augmentation conditions. This ensemble prediction canbe expected to be a better predictor for the unknown labels than the output ofthe network at the most recent training epoch, and can thus be used as a targetfor training. Using our method, we set new records for two standardsemi-supervised learning benchmarks, reducing the (non-augmented)classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16%by enabling the standard augmentations. We additionally obtain a clearimprovement in CIFAR-100 classification accuracy by using random images fromthe Tiny Images dataset as unlabeled extra inputs during training. Finally, wedemonstrate good tolerance to incorrect labels."^^schema:Text ;
    schema:author "Samuli Laine"^^schema:Person,
        "Timo Aila"^^schema:Person ;
    schema:commentCount "492"^^schema:Integer ;
    schema:dateModified "2017-03-15T14:22:41Z"^^schema:DateTime ;
    schema:datePublished "2016-10-07T12:15:42Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Temporal Ensembling for Semi-Supervised Learning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1610.02242v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=12742815032693937464&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<730> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks are ubiquitous in Machine Learning applicationsfor solving a variety of problems. They however can not be used in their nativeform when the domain of the data is commonly encountered manifolds such as thesphere, the special orthogonal group, the Grassmanian, the manifold ofsymmetric positive definite matrices and others. Most recently, generalizationof CNNs to data domains such as the 2-sphere has been reported by some researchgroups, which is referred to as the spherical CNNs (SCNNs). The key property ofSCNNs distinct from CNNs is that they exhibit the rotational equivarianceproperty that allows for sharing learned weights within a layer. In this paper,we theoretically generalize the CNNs to Riemannian homogeneous manifolds, thatinclude but are not limited to the aforementioned example manifolds. Our keycontributions in this work are: (i) A theorem stating that linear groupequivariance systems are fully characterized by correlation of functions on thedomain manifold and vice-versa. This is fundamental to the characterization ofall linear group equivariant systems and parallels the widely used result inlinear system theory for vector spaces. (ii) As a corrolary, we prove theequivariance of the correlation operation to group actions admitted by theinput domains which are Riemannian homogeneous manifolds. (iii) We present thefirst end-to-end deep network architecture for classification of diffusionmagnetic resonance image (dMRI) scans acquired from a cohort of 44 ParkinsonDisease patients and 50 control/normal subjects. (iv) A proof of conceptexperiment involving synthetic data generated on the manifold of symmetricpositive definite matrices is presented to demonstrate the applicability of ournetwork to other types of domains."^^schema:Text ;
    schema:author "Baba C. Vemuri"^^schema:Person,
        "Monami Banerjee"^^schema:Person,
        "Rudrasis Chakraborty"^^schema:Person ;
    schema:dateModified "2018-08-06T20:46:42Z"^^schema:DateTime ;
    schema:datePublished "2018-05-14T22:56:46Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "A CNN for homogneous Riemannian manifolds with applications to  Neuroimaging"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.05487v3"^^schema:URL .

<731> a schema:ScholarlyArticle ;
    schema:abstract "Predictive models with a focus on different spatial-temporal scales benefitgovernments and healthcare systems to combat the COVID-19 pandemic. Here wepresent the conditional Long Short-Term Memory networks with Quantile output(condLSTM-Q), a well-performing model for making quantile predictions onCOVID-19 death tolls at the county level with a two-week forecast window. Thisfine geographical scale is a rare but useful feature in publicly availablepredictive models, which would especially benefit state-level officials tocoordinate resources within the state. The quantile predictions from condLSTM-Qinform people about the distribution of the predicted death tolls, allowingbetter evaluation of possible trajectories of the severity. Given thescalability and generalizability of neural network models, this model couldincorporate additional data sources with ease, and could be further developedto generate other useful predictions such as new cases or hospitalizationsintuitively."^^schema:Text ;
    schema:author "HyeongChan Jo"^^schema:Person,
        "Juhyun Kim"^^schema:Person,
        "Tzu-Chen Huang"^^schema:Person,
        "Yu-Li Ni"^^schema:Person ;
    schema:dateModified "2020-11-23T16:14:48Z"^^schema:DateTime ;
    schema:datePublished "2020-11-23T16:14:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "condLSTM-Q: A novel deep learning model for predicting Covid-19  mortality in fine geographical Scale"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11507v1"^^schema:URL .

<732> a schema:ScholarlyArticle ;
    schema:abstract "The Lipschitz constant of a network plays an important role in manyapplications of deep learning, such as robustness certification and WassersteinGenerative Adversarial Network. We introduce a semidefinite programminghierarchy to estimate the global and local Lipschitz constant of a multiplelayer deep neural network. The novelty is to combine a polynomial lifting forReLU functions derivatives with a weak generalization of Putinar's positivitycertificate. This idea could also apply to other, nearly sparse, polynomialoptimization problems in machine learning. We empirically demonstrate that ourmethod provides a trade-off with respect to state of the art linear programmingapproach, and in some cases we obtain better bounds in less time."^^schema:Text ;
    schema:author "Edouard Pauwels"^^schema:Person,
        "Jean-Bernard Lasserre"^^schema:Person,
        "Tong Chen"^^schema:Person,
        "Victor Magron"^^schema:Person ;
    schema:dateModified "2020-10-28T09:19:39Z"^^schema:DateTime ;
    schema:datePublished "2020-02-10T11:09:37Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text ;
    schema:headline "Semialgebraic Optimization for Lipschitz Constants of ReLU Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.03657v4"^^schema:URL .

<733> a schema:ScholarlyArticle ;
    schema:abstract "Swarm systems constitute a challenging problem for reinforcement learning(RL) as the algorithm needs to learn decentralized control policies that cancope with limited local sensing and communication abilities of the agents.While it is often difficult to directly define the behavior of the agents,simple communication protocols can be defined more easily using prior knowledgeabout the given task. In this paper, we propose a number of simplecommunication protocols that can be exploited by deep reinforcement learning tofind decentralized control policies in a multi-robot swarm environment. Theprotocols are based on histograms that encode the local neighborhood relationsof the agents and can also transmit task-specific information, such as theshortest distance and direction to a desired target. In our framework, we usean adaptation of Trust Region Policy Optimization to learn complexcollaborative tasks, such as formation building and building a communicationlink. We evaluate our findings in a simulated 2D-physics environment, andcompare the implications of different communication protocols."^^schema:Text ;
    schema:author "Adrian Šošić"^^schema:Person,
        "Gerhard Neumann"^^schema:Person,
        "Maximilian Hüttenrauch"^^schema:Person ;
    schema:dateModified "2018-07-18T08:39:08Z"^^schema:DateTime ;
    schema:datePublished "2017-09-21T09:18:09Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "cs.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Local Communication Protocols for Learning Complex Swarm Behaviors with  Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.07224v2"^^schema:URL .

<734> a schema:ScholarlyArticle ;
    schema:abstract "As demand drives systems to generalize to various domains and problems, thestudy of multitask, transfer and lifelong learning has become an increasinglyimportant pursuit. In discrete domains, performance on the Atari game suite hasemerged as the de facto benchmark for assessing multitask learning. However, incontinuous domains there is a lack of agreement on standard multitaskevaluation environments which makes it difficult to compare differentapproaches fairly. In this work, we describe a benchmark set of tasks that wehave developed in an extendable framework based on OpenAI Gym. We run a simplebaseline using Trust Region Policy Optimization and release the frameworkpublicly to be expanded and used for the systematic comparison of multitask,transfer, and lifelong learning in continuous domains."^^schema:Text ;
    schema:author "David Meger"^^schema:Person,
        "Florian Shkurti"^^schema:Person,
        "Gregory Dudek"^^schema:Person,
        "Johanna Hansen"^^schema:Person,
        "Peter Henderson"^^schema:Person,
        "Wei-Di Chang"^^schema:Person ;
    schema:dateModified "2017-08-14T22:55:03Z"^^schema:DateTime ;
    schema:datePublished "2017-08-14T22:55:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Benchmark Environments for Multitask Learning in Continuous Domains"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.04352v1"^^schema:URL .

<735> a schema:ScholarlyArticle ;
    schema:abstract "Policy distillation in deep reinforcement learning provides an effective wayto transfer control policies from a larger network to a smaller untrainednetwork without a significant degradation in performance. However, policydistillation is underexplored in deep reinforcement learning, and existingapproaches are computationally inefficient, resulting in a long distillationtime. In addition, the effectiveness of the distillation process is stilllimited to the model capacity. We propose a new distillation mechanism, calledreal-time policy distillation, in which training the teacher model anddistilling the policy to the student model occur simultaneously. Accordingly,the teacher's latest policy is transferred to the student model in real time.This reduces the distillation time to half the original time or even less andalso makes it possible for extremely small student models to learn skills atthe expert level. We evaluated the proposed algorithm in the Atari 2600 domain.The results show that our approach can achieve full distillation in most games,even with compression ratios up to 1.7%."^^schema:Text ;
    schema:author "Pooyan Fazli"^^schema:Person,
        "Yuxiang Sun"^^schema:Person ;
    schema:dateModified "2019-12-29T11:10:37Z"^^schema:DateTime ;
    schema:datePublished "2019-12-29T11:10:37Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Real-time Policy Distillation in Deep Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.12630v1"^^schema:URL .

<736> a schema:ScholarlyArticle ;
    schema:abstract "We generalise Spatial Transformer Networks (STN) by replacing the parametrictransformation of a fixed, regular sampling grid with a deformable, statisticalshape model which is itself learnt. We call this a Statistical TransformerNetwork (StaTN). By training a network containing a StaTN end-to-end for aparticular task, the network learns the optimal nonrigid alignment of the inputdata for the task. Moreover, the statistical shape model is learnt with nodirect supervision (such as landmarks) and can be reused for other tasks.Besides training for a specific task, we also show that a StaTN can learn ashape model using generic loss functions. This includes a loss inspired by theminimum description length principle in which an appearance model is alsolearnt from scratch. In this configuration, our model learns an activeappearance model and a means to fit the model from scratch with no supervisionat all, even identity labels."^^schema:Text ;
    schema:author "Anil Bas"^^schema:Person,
        "William A. P. Smith"^^schema:Person ;
    schema:dateModified "2018-04-07T10:18:15Z"^^schema:DateTime ;
    schema:datePublished "2018-04-07T10:18:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Statistical transformer networks: learning shape and appearance models  via self supervision"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.02541v1"^^schema:URL .

<737> a schema:ScholarlyArticle ;
    schema:abstract "Siamese network based trackers formulate the visual tracking task as asimilarity matching problem. Almost all popular Siamese trackers realize thesimilarity learning via convolutional feature cross-correlation between atarget branch and a search branch. However, since the size of target featureregion needs to be pre-fixed, these cross-correlation base methods suffer fromeither reserving much adverse background information or missing a great deal offoreground information. Moreover, the global matching between the target andsearch region also largely neglects the target structure and part-levelinformation.  In this paper, to solve the above issues, we propose a simple target-awareSiamese graph attention network for general object tracking. We propose toestablish part-to-part correspondence between the target and the search regionwith a complete bipartite graph, and apply the graph attention mechanism topropagate target information from the template feature to the search feature.Further, instead of using the pre-fixed region cropping fortemplate-feature-area selection, we investigate a target-aware area selectionmechanism to fit the size and aspect ratio variations of different objects.Experiments on challenging benchmarks including GOT-10k, UAV123, OTB-100 andLaSOT demonstrate that the proposed SiamGAT outperforms many state-of-the-arttrackers and achieves leading performance. Code is available at:https://git.io/SiamGAT"^^schema:Text ;
    schema:author "Chunhua Shen"^^schema:Person,
        "Dongyan Guo"^^schema:Person,
        "Liyan Zhang"^^schema:Person,
        "Yanyan Shao"^^schema:Person,
        "Ying Cui"^^schema:Person,
        "Zhenhua Wang"^^schema:Person ;
    schema:dateModified "2020-11-23T04:26:45Z"^^schema:DateTime ;
    schema:datePublished "2020-11-23T04:26:45Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Graph Attention Tracking"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11204v1"^^schema:URL .

<738> a schema:ScholarlyArticle ;
    schema:abstract "With rapid progress across platforms for quantum systems, the problem ofmany-body quantum state reconstruction for noisy quantum states becomes animportant challenge. Recent works found promise in recasting the problem ofquantum state reconstruction to learning the probability distribution ofquantum state measurement vectors using generative neural network models. Herewe propose the \"Attention-based Quantum Tomography\" (AQT), a quantum statereconstruction using an attention mechanism-based generative network thatlearns the mixed state density matrix of a noisy quantum state. The AQT isbased on the model proposed in \"Attention is all you need\" by Vishwani et al(2017) that is designed to learn long-range correlations in natural languagesentences and thereby outperform previous natural language processing models.We demonstrate not only that AQT outperforms earlier neural-network-basedquantum state reconstruction on identical tasks but that AQT can accuratelyreconstruct the density matrix associated with a noisy quantum stateexperimentally realized in an IBMQ quantum computer. We speculate the successof the AQT stems from its ability to model quantum entanglement across theentire quantum system much as the attention model for natural languageprocessing captures the correlations among words in a sentence."^^schema:Text ;
    schema:author "Eun-Ah Kim"^^schema:Person,
        "Felix Wu"^^schema:Person,
        "Juan Carrasquilla"^^schema:Person,
        "Paul Ginsparg"^^schema:Person,
        "Peter Cha"^^schema:Person,
        "Peter L. McMahon"^^schema:Person ;
    schema:dateModified "2020-06-22T17:50:12Z"^^schema:DateTime ;
    schema:datePublished "2020-06-22T17:50:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "quant-ph"^^schema:Text ;
    schema:headline "Attention-based Quantum Tomography"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.12469v1"^^schema:URL .

<739> a schema:ScholarlyArticle ;
    schema:abstract "Over 800 languages are spoken across West Africa. Despite the obviousdiversity among people who speak these languages, one language significantlyunifies them all - West African Pidgin English. There are at least 80 millionspeakers of West African Pidgin English. However, there is no known naturallanguage processing (NLP) work on this language. In this work, we perform thefirst NLP work on the most popular variant of the language, providing threemajor contributions. First, the provision of a Pidgin corpus of over 56000sentences, which is the largest we know of. Secondly, the training of the firstever cross-lingual embedding between Pidgin and English. This aligned embeddingwill be helpful in the performance of various downstream tasks between Englishand Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translationmodel between Pidgin and English which achieves BLEU scores of 7.93 from Pidginto English, and 5.18 from English to Pidgin. In all, this work greatly reducesthe barrier of entry for future NLP works on West African Pidgin English."^^schema:Text ;
    schema:author "Kelechi Ogueji"^^schema:Person,
        "Orevaoghene Ahia"^^schema:Person ;
    schema:dateModified "2019-12-07T05:30:09Z"^^schema:DateTime ;
    schema:datePublished "2019-12-07T05:30:09Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "PidginUNMT: Unsupervised Neural Machine Translation from West African  Pidgin to English"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.03444v1"^^schema:URL .

<74> a schema:ScholarlyArticle ;
    schema:abstract "Saliency methods have emerged as a popular tool to highlight features in aninput deemed relevant for the prediction of a learned model. Several saliencymethods have been proposed, often guided by visual appeal on image data. Inthis work, we propose an actionable methodology to evaluate what kinds ofexplanations a given method can and cannot provide. We find that reliance,solely, on visual assessment can be misleading. Through extensive experimentswe show that some existing saliency methods are independent both of the modeland of the data generating process. Consequently, methods that fail theproposed tests are inadequate for tasks that are sensitive to either data ormodel, such as, finding outliers in the data, explaining the relationshipbetween inputs and outputs that the model learned, and debugging the model. Weinterpret our findings through an analogy with edge detection in images, atechnique that requires neither training data nor model. Theory in the case ofa linear model and a single-layer convolutional neural network supports ourexperimental findings."^^schema:Text ;
    schema:author "Been Kim"^^schema:Person,
        "Ian Goodfellow"^^schema:Person,
        "Julius Adebayo"^^schema:Person,
        "Justin Gilmer"^^schema:Person,
        "Michael Muelly"^^schema:Person,
        "Moritz Hardt"^^schema:Person ;
    schema:commentCount "220"^^schema:Integer ;
    schema:dateModified "2020-11-06T13:40:14Z"^^schema:DateTime ;
    schema:datePublished "2018-10-08T07:27:11Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Sanity Checks for Saliency Maps"^^schema:Text ;
    schema:publisher "Proceedings of the 32nd International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1810.03292v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8767887416569707674&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<740> a schema:ScholarlyArticle ;
    schema:abstract "Although group convolutional networks are able to learn powerfulrepresentations based on symmetry patterns, they lack explicit means to learnmeaningful relationships among them (e.g., relative positions and poses). Inthis paper, we present attentive group equivariant convolutions, ageneralization of the group convolution, in which attention is applied duringthe course of convolution to accentuate meaningful symmetry combinations andsuppress non-plausible, misleading ones. We indicate that prior work on visualattention can be described as special cases of our proposed framework and showempirically that our attentive group equivariant convolutional networksconsistently outperform conventional group convolutional networks on benchmarkimage datasets. Simultaneously, we provide interpretability to the learnedconcepts through the visualization of equivariant attention maps."^^schema:Text ;
    schema:author "David W. Romero"^^schema:Person,
        "Erik J. Bekkers"^^schema:Person,
        "Jakub M. Tomczak"^^schema:Person,
        "Mark Hoogendoorn"^^schema:Person ;
    schema:dateModified "2020-06-30T07:41:35Z"^^schema:DateTime ;
    schema:datePublished "2020-02-07T14:06:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Attentive Group Equivariant Convolutional Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.03830v3"^^schema:URL .

<741> a schema:ScholarlyArticle ;
    schema:abstract "Recognizing precise geometrical configurations of groups of objects is a keycapability of human spatial cognition, yet little studied in the deep learningliterature so far. In particular, a fundamental problem is how a machine canlearn and compare classes of geometric spatial configurations that areinvariant to the point of view of an external observer. In this paper we maketwo key contributions. First, we propose SpatialSim (Spatial Similarity), anovel geometrical reasoning benchmark, and argue that progress on thisbenchmark would pave the way towards a general solution to address thischallenge in the real world. This benchmark is composed of two tasks:Identification and Comparison, each one instantiated in increasing levels ofdifficulty. Secondly, we study how relational inductive biases exhibited byfully-connected message-passing Graph Neural Networks (MPGNNs) are useful tosolve those tasks, and show their advantages over less relational baselinessuch as Deep Sets and unstructured models such as Multi-Layer Perceptrons.Finally, we highlight the current limits of GNNs in these tasks."^^schema:Text ;
    schema:author "Katja Hofmann"^^schema:Person,
        "Laetitia Teodorescu"^^schema:Person,
        "Pierre-Yves Oudeyer"^^schema:Person ;
    schema:dateModified "2020-07-16T18:16:31Z"^^schema:DateTime ;
    schema:datePublished "2020-04-09T14:13:20Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "SpatialSim: Recognizing Spatial Configurations of Objects with Graph  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.04546v2"^^schema:URL .

<742> a schema:ScholarlyArticle ;
    schema:abstract "Graph convolutional networks (GCN) have recently demonstrated their potentialin analyzing non-grid structure data that can be represented as graphs. Thecore idea is to encode the local topology of a graph, via convolutions, intothe feature of a center node. In this paper, we propose a novel GCN model,which we term as Shortest Path Graph Attention Network (SPAGAN). Unlikeconventional GCN models that carry out node-based attentions within each layer,the proposed SPAGAN conducts path-based attention that explicitly accounts forthe influence of a sequence of nodes yielding the minimum cost, or shortestpath, between the center node and its higher-order neighbors. SPAGAN thereforeallows for a more informative and intact exploration of the graph structure andfurther {a} more effective aggregation of information from distant neighborsinto the center node, as compared to node-based GCN methods. We test SPAGAN onthe downstream classification task on several standard datasets, and achieveperformances superior to the state of the art. Code is publicly available athttps://github.com/ihollywhy/SPAGAN."^^schema:Text ;
    schema:author "Dacheng Tao"^^schema:Person,
        "Junsong Yuan"^^schema:Person,
        "Mingli Song"^^schema:Person,
        "Xinchao Wang"^^schema:Person,
        "Yiding Yang"^^schema:Person ;
    schema:dateModified "2021-01-10T03:18:34Z"^^schema:DateTime ;
    schema:datePublished "2021-01-10T03:18:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "SPAGAN: Shortest Path Graph Attention Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.03464v1"^^schema:URL .

<743> a schema:ScholarlyArticle ;
    schema:abstract "Unlike traditional time series, the action sequences of human decision makingusually involve many cognitive processes such as beliefs, desires, intentionsand theory of mind, i.e. what others are thinking. This makes predicting humandecision making challenging to be treated agnostically to the underlyingpsychological mechanisms. We propose to use a recurrent neural networkarchitecture based on long short-term memory networks (LSTM) to predict thetime series of the actions taken by the human subjects at each step of theirdecision making, the first application of such methods in this research domain.We trained our prediction networks on the behavioral data from severalpublished psychological experiments of human decision making, and demonstrateda clear advantage over the state-of-the-art methods in predicting humandecision making trajectories in both single-agent scenarios such as IowaGambling Task and multi-agent scenarios such as Iterated Prisoner's Dilemma."^^schema:Text ;
    schema:author "Baihan Lin"^^schema:Person,
        "Djallel Bouneffouf"^^schema:Person,
        "Guillermo Cecchi"^^schema:Person ;
    schema:dateModified "2020-10-22T03:36:03Z"^^schema:DateTime ;
    schema:datePublished "2020-10-22T03:36:03Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "q-bio.NC"^^schema:Text ;
    schema:headline "Predicting Human Decision Making in Psychological Tasks with Recurrent  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11413v1"^^schema:URL .

<744> a schema:ScholarlyArticle ;
    schema:abstract "Automatic definition extraction from texts is an important task that hasnumerous applications in several natural language processing fields such assummarization, analysis of scientific texts, automatic taxonomy generation,ontology generation, concept identification, and question answering. Fordefinitions that are contained within a single sentence, this problem can beviewed as a binary classification of sentences into definitions andnon-definitions. In this paper, we focus on automatic detection of one-sentencedefinitions in mathematical texts, which are difficult to separate fromsurrounding text. We experiment with several data representations, whichinclude sentence syntactic structure and word embeddings, and apply deeplearning methods such as the Convolutional Neural Network (CNN) and the LongShort-Term Memory network (LSTM), in order to identify mathematicaldefinitions. Our experiments demonstrate the superiority of CNN and itscombination with LSTM, when applied on the syntactically-enriched inputrepresentation. We also present a new dataset for definition extraction frommathematical texts. We demonstrate that this dataset is beneficial for trainingsupervised models aimed at extraction of mathematical definitions. Ourexperiments with different domains demonstrate that mathematical definitionsrequire special treatment, and that using cross-domain learning is inefficientfor that task."^^schema:Text ;
    schema:author "Lior Reznik"^^schema:Person,
        "Marina Litvak"^^schema:Person,
        "Natalia Vanetik"^^schema:Person,
        "Sergey Shevchuk"^^schema:Person ;
    schema:dateModified "2020-11-09T15:57:53Z"^^schema:DateTime ;
    schema:datePublished "2020-11-09T15:57:53Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "Automated Discovery of Mathematical Definitions in Text with Deep Neural  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.04521v1"^^schema:URL .

<745> a schema:ScholarlyArticle ;
    schema:abstract "Score matching provides an effective approach to learning flexibleunnormalized models, but its scalability is limited by the need to evaluate asecond-order derivative. In this paper, we present a scalable approximation toa general family of learning objectives including score matching, by observinga new connection between these objectives and Wasserstein gradient flows. Wepresent applications with promise in learning neural density estimators onmanifolds, and training implicit variational and Wasserstein auto-encoders witha manifold-valued prior."^^schema:Text ;
    schema:author "Bo Zhang"^^schema:Person,
        "Jun Zhu"^^schema:Person,
        "Shuyu Cheng"^^schema:Person,
        "Yueru Li"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:dateModified "2020-02-18T11:40:26Z"^^schema:DateTime ;
    schema:datePublished "2020-02-18T11:40:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.07501v1"^^schema:URL .

<746> a schema:ScholarlyArticle ;
    schema:abstract "We explore a collaborative and cooperative multi-agent reinforcement learningsetting where a team of reinforcement learning agents attempt to solve a singlecooperative task in a multi-scenario setting. We propose a novel multi-agentreinforcement learning algorithm inspired by universal value functionapproximators that not only generalizes over state space but also over a set ofdifferent scenarios. Additionally, to prove our claim, we are introducing achallenging 2D multi-agent urban security environment where the learning agentsare trying to protect a person from nearby bystanders in a variety ofscenarios. Our study shows that state-of-the-art multi-agent reinforcementlearning algorithms fail to generalize a single task over multiple scenarioswhile our proposed solution works equally well as scenario-dependent policies."^^schema:Text ;
    schema:author "Hassam Ullah Sheikh"^^schema:Person,
        "Ladislau Bölöni"^^schema:Person ;
    schema:dateModified "2019-08-24T18:36:17Z"^^schema:DateTime ;
    schema:datePublished "2019-08-24T18:36:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text ;
    schema:headline "Universal Policies to Learn Them All"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.09184v1"^^schema:URL .

<747> a schema:ScholarlyArticle ;
    schema:abstract "Model-based reinforcement learning (MBRL) approaches rely on discrete-timestate transition models whereas physical systems and the vast majority ofcontrol tasks operate in continuous-time. To avoid time-discretizationapproximation of the underlying process, we propose a continuous-time MBRLframework based on a novel actor-critic method. Our approach also infers theunknown state evolution differentials with Bayesian neural ordinarydifferential equations (ODE) to account for epistemic uncertainty. We implementand test our method on a new ODE-RL suite that explicitly solvescontinuous-time control systems. Our experiments illustrate that the model isrobust against irregular and noisy data, is sample-efficient, and can solvecontrol problems which pose challenges to discrete-time MBRL methods."^^schema:Text ;
    schema:author "Harri Lähdesmäki"^^schema:Person,
        "Markus Heinonen"^^schema:Person,
        "Çağatay Yıldız"^^schema:Person ;
    schema:dateModified "2021-02-09T11:30:19Z"^^schema:DateTime ;
    schema:datePublished "2021-02-09T11:30:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continuous-Time Model-Based Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.04764v1"^^schema:URL .

<748> a schema:ScholarlyArticle ;
    schema:abstract "Automated vehicles' neural networks suffer from overfit, poorgeneralizability, and untrained edge cases due to limited data availability.Researchers synthesize randomized edge-case scenarios to assist in the trainingprocess, though simulation introduces potential for overfit to latent rules andfeatures. Automating worst-case scenario generation could yield informativedata for improving self driving. To this end, we introduce a \"PhysicallyAdversarial Intelligent Network\" (PAIN), wherein self-driving vehicles interactaggressively in the CARLA simulation environment. We train two agents, aprotagonist and an adversary, using dueling double deep Q networks (DDDQNs)with prioritized experience replay. The coupled networks alternatelyseek-to-collide and to avoid collisions such that the \"defensive\" avoidancealgorithm increases the mean-time-to-failure and distance traveled undernon-hostile operating conditions. The trained protagonist becomes moreresilient to environmental uncertainty and less prone to corner case failuresresulting in collisions than the agent trained without an adversary."^^schema:Text ;
    schema:author "Demetris Coleman"^^schema:Person,
        "Joshua E. Siegel"^^schema:Person,
        "Piyush Gupta"^^schema:Person ;
    schema:dateModified "2020-03-24T05:04:13Z"^^schema:DateTime ;
    schema:datePublished "2020-03-24T05:04:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards Safer Self-Driving Through Great PAIN (Physically Adversarial  Intelligent Networks)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.10662v1"^^schema:URL .

<749> a schema:ScholarlyArticle ;
    schema:abstract "Binarized Neural Networks, a recently discovered class of neural networkswith minimal memory requirements and no reliance on multiplication, are afantastic opportunity for the realization of compact and energy efficientinference hardware. However, such neural networks are generally not entirelybinarized: their first layer remains with fixed point input. In this work, wepropose a stochastic computing version of Binarized Neural Networks, where theinput is also binarized. Simulations on the example of the Fashion-MNIST andCIFAR-10 datasets show that such networks can approach the performance ofconventional Binarized Neural Networks. We evidence that the training procedureshould be adapted for use with stochastic computing. Finally, the ASICimplementation of our scheme is investigated, in a system that closelyassociates logic and memory, implemented by Spin Torque Magnetoresistive RandomAccess Memory. This analysis shows that the stochastic computing approach canallow considerable savings with regards to conventional Binarized Neuralnetworks in terms of area (62% area reduction on the Fashion-MNIST task). Itcan also allow important savings in terms of energy consumption, if we acceptreasonable reduction of accuracy: for example a factor 2.1 can be saved, withthe cost of 1.4% in Fashion-MNIST test accuracy. These results highlight thehigh potential of Binarized Neural Networks for hardware implementation, andthat adapting them to hardware constrains can provide important benefits."^^schema:Text ;
    schema:author "Bogdan Penkovsky"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Jacques-Olivier Klein"^^schema:Person,
        "Jean-Michel Portal"^^schema:Person,
        "Marc Bocquet"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2019-06-03T16:34:48Z"^^schema:DateTime ;
    schema:datePublished "2019-06-03T16:34:48Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "Stochastic Computing for Hardware Implementation of Binarized Neural  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.00915v1"^^schema:URL .

<75> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks coupled with fast simulation and improved computationhave led to recent successes in the field of reinforcement learning (RL).However, most current RL-based approaches fail to generalize since: (a) the gapbetween simulation and real world is so large that policy-learning approachesfail to transfer; (b) even if policy learning is done in real world, the datascarcity leads to failed generalization from training to test scenarios (e.g.,due to different friction or object masses). Inspired from H-infinity controlmethods, we note that both modeling errors and differences in training and testscenarios can be viewed as extra forces/disturbances in the system. This paperproposes the idea of robust adversarial reinforcement learning (RARL), where wetrain an agent to operate in the presence of a destabilizing adversary thatapplies disturbance forces to the system. The jointly trained adversary isreinforced -- that is, it learns an optimal destabilization policy. Weformulate the policy learning as a zero-sum, minimax objective function.Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah,Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)improves training stability; (b) is robust to differences in training/testconditions; and c) outperform the baseline even in the absence of theadversary."^^schema:Text ;
    schema:author "Abhinav Gupta"^^schema:Person,
        "James Davidson"^^schema:Person,
        "Lerrel Pinto"^^schema:Person,
        "Rahul Sukthankar"^^schema:Person ;
    schema:commentCount "191"^^schema:Integer ;
    schema:dateModified "2017-03-08T04:58:51Z"^^schema:DateTime ;
    schema:datePublished "2017-03-08T04:58:51Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Robust Adversarial Reinforcement Learning"^^schema:Text ;
    schema:publisher "ICML, 2817-2826"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1703.02702v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=10521359398547093876&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<750> a schema:ScholarlyArticle ;
    schema:abstract "While deep neural networks have surpassed human performance in multiplesituations, they are prone to catastrophic forgetting: upon training a newtask, they rapidly forget previously learned ones. Neuroscience studies, basedon idealized tasks, suggest that in the brain, synapses overcome this issue byadjusting their plasticity depending on their past history. However, such\"metaplastic\" behaviour has never been leveraged to mitigate catastrophicforgetting in deep neural networks. In this work, we highlight a connectionbetween metaplasticity models and the training process of binarized neuralnetworks, a low-precision version of deep neural networks. Building on thisidea, we propose and demonstrate experimentally, in situations of multitask andstream learning, a training technique that prevents catastrophic forgettingwithout needing previously presented data, nor formal boundaries betweendatasets. We support our approach with a theoretical analysis on a tractabletask. This work bridges computational neuroscience and deep learning, andpresents significant assets for future embedded and neuromorphic systems."^^schema:Text ;
    schema:author "Axel Laborieux"^^schema:Person,
        "Damien Querlioz"^^schema:Person,
        "Maxence Ernoult"^^schema:Person,
        "Tifenn Hirtzlin"^^schema:Person ;
    schema:dateModified "2020-03-07T08:09:34Z"^^schema:DateTime ;
    schema:datePublished "2020-03-07T08:09:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Synaptic Metaplasticity in Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03533v1"^^schema:URL .

<751> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning has shown growing success in recent years. However, currentmachine learning systems are highly specialized, trained for particularproblems or domains, and typically on a single narrow dataset. Human learning,on the other hand, is highly general and adaptable. Never-ending learning is amachine learning paradigm that aims to bridge this gap, with the goal ofencouraging researchers to design machine learning systems that can learn toperform a wider variety of inter-related tasks in more complex environments. Todate, there is no environment or testbed to facilitate the development andevaluation of never-ending learning systems. To this end, we propose the JellyBean World testbed. The Jelly Bean World allows experimentation overtwo-dimensional grid worlds which are filled with items and in which agents cannavigate. This testbed provides environments that are sufficiently complex andwhere more generally intelligent algorithms ought to perform better thancurrent state-of-the-art reinforcement learning approaches. It does so byproducing non-stationary environments and facilitating experimentation withmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hopethat this new freely-available software will prompt new research and interestin the development and evaluation of never-ending learning systems and morebroadly, general intelligence systems."^^schema:Text ;
    schema:author "Abulhair Saparov"^^schema:Person,
        "Emmanouil Antonios Platanios"^^schema:Person,
        "Tom Mitchell"^^schema:Person ;
    schema:dateModified "2020-02-15T02:43:16Z"^^schema:DateTime ;
    schema:datePublished "2020-02-15T02:43:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.MA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Jelly Bean World: A Testbed for Never-Ending Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.06306v1"^^schema:URL .

<752> a schema:ScholarlyArticle ;
    schema:abstract "With the rapid development of online education system, knowledge tracingwhich aims at predicting students' knowledge state is becoming a critical andfundamental task in personalized education. Traditionally, existing methods aredomain-specified. However, there are a larger number of domains (e.g.,subjects, schools) in the real world and the lacking of data in some domains,how to utilize the knowledge and information in other domains to help train aknowledge tracing model for target domains is increasingly important. We referto this problem as domain adaptation for knowledge tracing (DAKT) whichcontains two aspects: (1) how to achieve great knowledge tracing performance ineach domain. (2) how to transfer good performed knowledge tracing model betweendomains. To this end, in this paper, we propose a novel adaptable framework,namely adaptable knowledge tracing (AKT) to address the DAKT problem.Specifically, for the first aspect, we incorporate the educationalcharacteristics (e.g., slip, guess, question texts) based on the deep knowledgetracing (DKT) to obtain a good performed knowledge tracing model. For thesecond aspect, we propose and adopt three domain adaptation processes. First,we pre-train an auto-encoder to select useful source instances for target modeltraining. Second, we minimize the domain-specific knowledge state distributiondiscrepancy under maximum mean discrepancy (MMD) measurement to achieve domainadaptation. Third, we adopt fine-tuning to deal with the problem that theoutput dimension of source and target domain are different to make the modelsuitable for target domains. Extensive experimental results on two privatedatasets and seven public datasets clearly prove the effectiveness of AKT forgreat knowledge tracing performance and its superior transferable ability."^^schema:Text ;
    schema:author "Enhong Chen"^^schema:Person,
        "Qi Liu"^^schema:Person,
        "Song Cheng"^^schema:Person ;
    schema:dateModified "2020-01-14T15:04:48Z"^^schema:DateTime ;
    schema:datePublished "2020-01-14T15:04:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Domain Adaption for Knowledge Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.04841v1"^^schema:URL .

<753> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks (RNNs) stand at the forefront of many recentdevelopments in deep learning. Yet a major difficulty with these models istheir tendency to overfit, with dropout shown to fail when applied to recurrentlayers. Recent results at the intersection of Bayesian modelling and deeplearning offer a Bayesian interpretation of common deep learning techniquessuch as dropout. This grounding of dropout in approximate Bayesian inferencesuggests an extension of the theoretical results, offering insights into theuse of dropout with RNN models. We apply this new variational inference baseddropout technique in LSTM and GRU models, assessing it on language modellingand sentiment analysis tasks. The new approach outperforms existing techniques,and to the best of our knowledge improves on the single model state-of-the-artin language modelling with the Penn Treebank (73.4 test perplexity). Thisextends our arsenal of variational tools in deep learning."^^schema:Text ;
    schema:author "Yarin Gal"^^schema:Person,
        "Zoubin Ghahramani"^^schema:Person ;
    schema:dateModified "2016-10-05T15:09:30Z"^^schema:DateTime ;
    schema:datePublished "2015-12-16T19:18:43Z"^^schema:DateTime ;
    schema:genre "stat.ML"^^schema:Text ;
    schema:headline "A Theoretically Grounded Application of Dropout in Recurrent Neural  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1512.05287v5"^^schema:URL .

<754> a schema:ScholarlyArticle ;
    schema:abstract "Regularized Auto-Encoders (RAEs) form a rich class of neural generativemodels. They effectively model the joint-distribution between the data and thelatent space using an Encoder-Decoder combination, with regularization imposedin terms of a prior over the latent space. Despite their advantages, such asstability in training, the performance of AE based models has not reached thesuperior standards as that of the other generative models such as GenerativeAdversarial Networks (GANs). Motivated by this, we examine the effect of thelatent prior on the generation quality of deterministic AE models in thispaper. Specifically, we consider the class of RAEs with deterministicEncoder-Decoder pairs, Wasserstein Auto-Encoders (WAE), and show that having afixed prior distribution, \\textit{a priori}, oblivious to the dimensionality ofthe `true' latent space, will lead to the infeasibility of the optimizationproblem considered. Further, we show that, in the finite data regime, despiteknowing the correct latent dimensionality, there exists a bias-variancetrade-off with any arbitrary prior imposition. As a remedy to both the issuesmentioned above, we introduce an additional state space in the form of flexiblylearnable latent priors, in the optimization objective of the WAEs. Weimplicitly learn the distribution of the latent prior jointly with the AEtraining, which not only makes the learning objective feasible but alsofacilitates operation on different points of the bias-variance curve. We showthe efficacy of our model, called FlexAE, through several experiments onmultiple datasets, and demonstrate that it is the new state-of-the-art for theAE based generative models."^^schema:Text ;
    schema:author "Arnab Kumar Mondal"^^schema:Person,
        "Himanshu Asnani"^^schema:Person,
        "Parag Singla"^^schema:Person,
        "Prathosh AP"^^schema:Person ;
    schema:dateModified "2020-09-19T10:56:48Z"^^schema:DateTime ;
    schema:datePublished "2020-06-10T14:00:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "To Regularize or Not To Regularize? The Bias Variance Trade-off in  Regularized AEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.05838v2"^^schema:URL .

<755> a schema:ScholarlyArticle ;
    schema:abstract "Importance weighted variational inference (Burda et al., 2015) uses multiplei.i.d. samples to have a tighter variational lower bound. We believe a jointproposal has the potential of reducing the number of redundant samples, andintroduce a hierarchical structure to induce correlation. The hope is that theproposals would coordinate to make up for the error made by one another toreduce the variance of the importance estimator. Theoretically, we analyze thecondition under which convergence of the estimator variance can be connected toconvergence of the lower bound. Empirically, we confirm that maximization ofthe lower bound does implicitly minimize variance. Further analysis shows thatthis is a result of negative correlation induced by the proposed hierarchicalmeta sampling scheme, and performance of inference also improves when thenumber of samples increases."^^schema:Text ;
    schema:author "Aaron Courville"^^schema:Person,
        "Alexandre Lacoste"^^schema:Person,
        "Chin-Wei Huang"^^schema:Person,
        "Eeshan Dhekane"^^schema:Person,
        "Kris Sankaran"^^schema:Person ;
    schema:dateModified "2019-05-13T05:27:05Z"^^schema:DateTime ;
    schema:datePublished "2019-05-13T05:27:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Importance Weighted Autoencoders"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.04866v1"^^schema:URL .

<756> a schema:ScholarlyArticle ;
    schema:abstract "We present Revel, a partially neural reinforcement learning (RL) frameworkfor provably safe exploration in continuous state and action spaces. A keychallenge for provably safe deep RL is that repeatedly verifying neuralnetworks within a learning loop is computationally infeasible. We address thischallenge using two policy classes: a general, neurosymbolic class withapproximate gradients and a more restricted class of symbolic policies thatallows efficient verification. Our learning algorithm is a mirror descent overpolicies: in each iteration, it safely lifts a symbolic policy into theneurosymbolic space, performs safe gradient updates to the resulting policy,and projects the updated policy into the safe symbolic subset, all withoutrequiring explicit verification of neural networks. Our empirical results showthat Revel enforces safe exploration in many scenarios in which ConstrainedPolicy Optimization does not, and that it can discover policies that outperformthose learned through prior approaches to verified exploration."^^schema:Text ;
    schema:author "Abhinav Verma"^^schema:Person,
        "Greg Anderson"^^schema:Person,
        "Isil Dillig"^^schema:Person,
        "Swarat Chaudhuri"^^schema:Person ;
    schema:dateModified "2020-10-26T14:02:51Z"^^schema:DateTime ;
    schema:datePublished "2020-09-26T14:51:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neurosymbolic Reinforcement Learning with Formally Verified Exploration"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.12612v2"^^schema:URL .

<757> a schema:ScholarlyArticle ;
    schema:abstract "Estimating student proficiency is an important task for computer basedlearning systems. We compare a family of IRT-based proficiency estimationmethods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neuralnetwork model with promising initial results. We evaluate how well each modelpredicts a student's future response given previous responses using twopublicly available and one proprietary data set. We find that IRT-based methodsconsistently matched or outperformed DKT across all data sets at the finestlevel of content granularity that was tractable for them to be trained on. Ahierarchical extension of IRT that captured item grouping structure performedbest overall. When data sets included non-trivial autocorrelations in studentresponse patterns, a temporal extension of IRT improved performance overstandard IRT while the RNN-based method did not. We conclude that IRT-basedmodels provide a simpler, better-performing alternative to existing RNN-basedmodels of student interaction data while also affording more interpretabilityand guarantees due to their formulation as Bayesian probabilistic models."^^schema:Text ;
    schema:author "Bojian Han"^^schema:Person,
        "Chaitanya Ekanadham"^^schema:Person,
        "Kevin H. Wilson"^^schema:Person,
        "Yan Karklin"^^schema:Person ;
    schema:dateModified "2016-05-21T18:26:21Z"^^schema:DateTime ;
    schema:datePublished "2016-04-08T12:54:18Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Back to the Basics: Bayesian extensions of IRT outperform neural  networks for proficiency estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1604.02336v2"^^schema:URL .

<758> a schema:ScholarlyArticle ;
    schema:abstract "Dual-energy computed tomography has great potential in materialcharacterization and identification, whereas the reconstructedmaterial-specific images always suffer from magnified noise and beam hardeningartifacts. In this study, a data-driven approach using dual interactiveWasserstein generative adversarial networks is proposed to improve the materialdecomposition accuracy. Specifically, two interactive generators are used tosynthesize the corresponding material images and different loss functions fortraining the decomposition model are incorporated to preserve texture and edgesin the generated images. Besides, a selector is employed to ensure themodelling ability of two generators. The results from both the simulationphantoms and real data demonstrate the advantages of this method in suppressingthe noise and beam hardening artifacts."^^schema:Text ;
    schema:author "Huilong Li"^^schema:Person,
        "Ming Cheng"^^schema:Person,
        "Qingjie Cao"^^schema:Person,
        "Zaifeng Shi"^^schema:Person,
        "Zhongqi Wang"^^schema:Person ;
    schema:dateModified "2020-07-22T08:03:24Z"^^schema:DateTime ;
    schema:datePublished "2020-07-22T08:03:24Z"^^schema:DateTime ;
    schema:genre "eess.IV"^^schema:Text,
        "physics.med-ph"^^schema:Text ;
    schema:headline "A material decomposition method for dual-energy CT via dual interactive  Wasserstein generative adversarial networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.11247v1"^^schema:URL .

<759> a schema:ScholarlyArticle ;
    schema:abstract "Slimmable neural networks provide a flexible trade-off front betweenprediction error and computational cost (such as the number of floating-pointoperations or FLOPs) with the same storage cost as a single model. They havebeen proposed recently for resource-constrained settings such as mobiledevices. However, current slimmable neural networks use a singlewidth-multiplier for all the layers to arrive at sub-networks with differentperformance profiles, which neglects that different layers affect the network'sprediction accuracy differently and have different FLOP requirements. Hence,developing a principled approach for deciding width-multipliers acrossdifferent layers could potentially improve the performance of slimmablenetworks. To allow for heterogeneous width-multipliers across different layers,we formulate the problem of optimizing slimmable networks from amulti-objective optimization lens, which leads to a novel algorithm foroptimizing both the shared weights and the width-multipliers for thesub-networks. We perform extensive empirical analysis with 14 network anddataset combinations and find that less over-parameterized networks benefitmore from a joint channel and weight optimization than extremelyover-parameterized networks. Quantitatively, improvements up to 1.7% and 1% intop-1 accuracy on the ImageNet dataset can be attained for MobileNetV2 andMobileNetV3, respectively. Our results highlight the potential of optimizingthe channel counts for different layers jointly with the weights for slimmablenetworks."^^schema:Text ;
    schema:author "Ari S. Morcos"^^schema:Person,
        "Diana Marculescu"^^schema:Person,
        "Ting-Wu Chin"^^schema:Person ;
    schema:dateModified "2020-10-05T01:33:08Z"^^schema:DateTime ;
    schema:datePublished "2020-07-23T02:05:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.11752v2"^^schema:URL .

<76> a schema:ScholarlyArticle ;
    schema:abstract "Deep neural networks (DNNs) have demonstrated state-of-the-art results onmany pattern recognition tasks, especially vision classification problems.Understanding the inner workings of such computational brains is bothfascinating basic science that is interesting in its own right - similar to whywe study the human brain - and will enable researchers to further improve DNNs.One path to understanding how a neural network functions internally is to studywhat each of its neurons has learned to detect. One such method is calledactivation maximization (AM), which synthesizes an input (e.g. an image) thathighly activates a neuron. Here we dramatically improve the qualitative stateof the art of activation maximization by harnessing a powerful, learned prior:a deep generator network (DGN). The algorithm (1) generates qualitativelystate-of-the-art synthetic images that look almost real, (2) reveals thefeatures learned by each neuron in an interpretable way, (3) generalizes wellto new datasets and somewhat well to different network architectures withoutrequiring the prior to be relearned, and (4) can be considered as ahigh-quality generative method (in this case, by generating novel, creative,interesting, recognizable images)."^^schema:Text ;
    schema:author "Alexey Dosovitskiy"^^schema:Person,
        "Anh Nguyen"^^schema:Person,
        "Jason Yosinski"^^schema:Person,
        "Jeff Clune"^^schema:Person,
        "Thomas Brox"^^schema:Person ;
    schema:commentCount "305"^^schema:Integer ;
    schema:dateModified "2016-11-23T18:41:12Z"^^schema:DateTime ;
    schema:datePublished "2016-05-30T16:22:54Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Synthesizing the preferred inputs for neurons in neural networks via  deep generator networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1605.09304v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5242797434107730911&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<760> a schema:ScholarlyArticle ;
    schema:abstract "As a key component in a dialogue system, dialogue state tracking plays animportant role. It is very important for dialogue state tracking to deal withthe problem of unknown slot values. As far as we known, almost all existingapproaches depend on pointer network to solve the unknown slot value problem.These pointer network-based methods usually have a hidden assumption that thereis at most one out-of-vocabulary word in an unknown slot value because of thecharacter of a pointer network. However, often, there are multipleout-of-vocabulary words in an unknown slot value, and it makes the existingmethods perform bad. To tackle the problem, in this paper, we propose a novelContext-Sensitive Generation network (CSG) which can facilitate therepresentation of out-of-vocabulary words when generating the unknown slotvalue. Extensive experiments show that our proposed method performs better thanthe state-of-the-art baselines."^^schema:Text ;
    schema:author "Heyan Huang"^^schema:Person,
        "Puhai Yang"^^schema:Person,
        "Xian-Ling Mao"^^schema:Person ;
    schema:dateModified "2020-10-16T09:31:38Z"^^schema:DateTime ;
    schema:datePublished "2020-05-08T09:22:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Context-Sensitive Generation Network for Handing Unknown Slot Values in  Dialogue State Tracking"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.03923v3"^^schema:URL .

<761> a schema:ScholarlyArticle ;
    schema:abstract "With the recent trend of applying machine learning in every aspect of humanlife, it is important to incorporate fairness into the core of the predictivealgorithms. We address the problem of predicting the quality of public speecheswhile being fair with respect to sensitive attributes of the speakers, e.g.gender and race. We use the TED talks as an input repository of public speechesbecause it consists of speakers from a diverse community and has a wideoutreach. Utilizing the theories of Causal Models, Counterfactual Fairness andstate-of-the-art neural language models, we propose a mathematical frameworkfor fair prediction of the public speaking quality. We employ groundedassumptions to construct a causal model capturing how different attributesaffect public speaking quality. This causal model contributes in generatingcounterfactual data to train a fair predictive model. Our framework is generalenough to utilize any assumption within the causal model. Experimental resultsshow that while prediction accuracy is comparable to recent work on thisdataset, our predictions are counterfactually fair with respect to a novelmetric when compared to true data labels. The FairyTED setup not only allowsorganizers to make informed and diverse selection of speakers from theunobserved counterfactual possibilities but it also ensures that viewers andnew users are not influenced by unfair and unbalanced ratings from arbitraryvisitors to the www.ted.com website when deciding to view a talk."^^schema:Text ;
    schema:author "Ankani Chattoraj"^^schema:Person,
        "Md. Iftekhar Tanveer"^^schema:Person,
        "Rupam Acharyya"^^schema:Person,
        "Shouman Das"^^schema:Person ;
    schema:dateModified "2019-11-25T09:55:52Z"^^schema:DateTime ;
    schema:datePublished "2019-11-25T09:55:52Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "FairyTED: A Fair Rating Predictor for TED Talk Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.11558v1"^^schema:URL .

<762> a schema:ScholarlyArticle ;
    schema:abstract "We propose a context-adaptive entropy model for use in end-to-end optimizedimage compression. Our model exploits two types of contexts, bit-consumingcontexts and bit-free contexts, distinguished based upon whether additional bitallocation is required. Based on these contexts, we allow the model to moreaccurately estimate the distribution of each latent representation with a moregeneralized form of the approximation models, which accordingly leads to anenhanced compression performance. Based on the experimental results, theproposed method outperforms the traditional image codecs, such as BPG andJPEG2000, as well as other previous artificial-neural-network (ANN) basedapproaches, in terms of the peak signal-to-noise ratio (PSNR) and multi-scalestructural similarity (MS-SSIM) index."^^schema:Text ;
    schema:author "Jooyoung Lee"^^schema:Person,
        "Seung-Kwon Beack"^^schema:Person,
        "Seunghyun Cho"^^schema:Person ;
    schema:dateModified "2019-05-06T05:18:37Z"^^schema:DateTime ;
    schema:datePublished "2018-09-27T10:59:47Z"^^schema:DateTime ;
    schema:genre "eess.IV"^^schema:Text ;
    schema:headline "Context-adaptive Entropy Model for End-to-end Optimized Image  Compression"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.10452v4"^^schema:URL .

<763> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation(NMT) is associated with noise anderrors in synthetic data when executing vanilla back-translations. Here, weexplicitly exploits language model(LM) to drive construction of an unsupervisedNMT system. This features two steps. First, we initialize NMT models usingsynthetic data generated via temporary statistical machine translation(SMT).Second, unlike vanilla back-translation, we formulate a weight function, thatscores synthetic data at each step of subsequent iterative training; thisallows unsupervised training to an improved outcome. We present the detailedmathematical construction of our method. Experimental WMT2014 English-French,and WMT2016 English-German and English-Russian translation tasks revealed thatour method outperforms the best prior systems by more than 3 BLEU points."^^schema:Text ;
    schema:author "Ruoran Ren"^^schema:Person,
        "Wei Zhang"^^schema:Person,
        "Xiaodong Wang"^^schema:Person,
        "Youyuan Lin"^^schema:Person,
        "Zhen Huang"^^schema:Person,
        "Zhenshuang Liang"^^schema:Person ;
    schema:dateModified "2019-11-10T14:04:59Z"^^schema:DateTime ;
    schema:datePublished "2019-11-10T14:04:59Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Language Model-Driven Unsupervised Neural Machine Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.03937v1"^^schema:URL .

<764> a schema:ScholarlyArticle ;
    schema:abstract "Pre-trained text-to-text transformers achieve impressive performance across awide range of NLP tasks, and they naturally support zero-shot learning (ZSL) byusing the task description as prompt in the input. However, this approach haspotential limitations, as it learns from input-output pairs at instance level,instead of learning to solve tasks at task level. Alternatively, applyingexisting ZSL methods to text-to-text transformers is non-trivial due to theirtext generation objective and huge size. To address these issues, we introduceHypter, a framework that improves zero-shot transferability by training ahypernetwork to generate task-specific adapters from task descriptions. Thisformulation enables learning at task level, and greatly reduces the number ofparameters by using light-weight adapters. Experiments on two datasetsdemonstrate Hypter improves upon fine-tuning baselines."^^schema:Text ;
    schema:author "Qinyuan Ye"^^schema:Person,
        "Xiang Ren"^^schema:Person ;
    schema:dateModified "2021-01-02T10:50:23Z"^^schema:DateTime ;
    schema:datePublished "2021-01-02T10:50:23Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Zero-shot Learning by Generating Task-specific Adapters"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.00420v1"^^schema:URL .

<765> a schema:ScholarlyArticle ;
    schema:abstract "As data structures and mathematical objects used for complex systemsmodeling, hypergraphs sit nicely poised between on the one hand the world ofnetwork models, and on the other that of higher-order mathematical abstractionsfrom algebra, lattice theory, and topology. They are able to represent complexsystems interactions more faithfully than graphs and networks, while also beingsome of the simplest classes of systems representing topological structures ascollections of multidimensional objects connected in a particular pattern. Inthis paper we discuss the role of (undirected) hypergraphs in the science ofcomplex networks, and provide a mathematical overview of the core conceptsneeded for hypernetwork modeling, including duality and the relationship tobicolored graphs, quantitative adjacency and incidence, the nature of walks inhypergraphs, and available topological relationships and properties. We closewith a brief discussion of two example applications: biomedical databases fordisease analysis, and domain-name system (DNS) analysis of cyber data."^^schema:Text ;
    schema:author "Brenda Praggastis"^^schema:Person,
        "Brett Jefferson"^^schema:Person,
        "Cliff A. Joslyn"^^schema:Person,
        "Emilie A. H. Purvine"^^schema:Person,
        "Ignacio J. Tripodi"^^schema:Person,
        "Lawrence E. Hunter"^^schema:Person,
        "Sinan Aksoy"^^schema:Person,
        "Tiffany J. Callahan"^^schema:Person ;
    schema:dateModified "2020-03-26T07:52:04Z"^^schema:DateTime ;
    schema:datePublished "2020-03-26T07:52:04Z"^^schema:DateTime ;
    schema:genre "05C65,"^^schema:Text,
        "G.2.2"^^schema:Text,
        "cs.DM"^^schema:Text ;
    schema:headline "Hypernetwork Science: From Multidimensional Networks to Computational  Topology"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.11782v1"^^schema:URL .

<766> a schema:ScholarlyArticle ;
    schema:abstract "Research has shown that deep neural networks contain significant redundancy,and thus that high classification accuracy can be achieved even when weightsand activations are quantized down to binary values. Network binarization onFPGAs greatly increases area efficiency by replacing resource-hungrymultipliers with lightweight XNOR gates. However, an FPGA's fundamentalbuilding block, the K-LUT, is capable of implementing far more than an XNOR: itcan perform any K-input Boolean operation. Inspired by this observation, wepropose LUTNet, an end-to-end hardware-software framework for the constructionof area-efficient FPGA-based neural network accelerators using the native LUTsas inference operators. We describe the realization of both unrolled and tiledLUTNet architectures, with the latter facilitating smaller, less power-hungrydeployment over the former while sacrificing area and energy efficiency alongwith throughput. For both varieties, we demonstrate that the exploitation ofLUT flexibility allows for far heavier pruning than possible in prior works,resulting in significant area savings while achieving comparable accuracy.Against the state-of-the-art binarized neural network implementation, weachieve up to twice the area efficiency for several standard network modelswhen inferencing popular datasets. We also demonstrate that even greater energyefficiency improvements are obtainable."^^schema:Text ;
    schema:author "Erwei Wang"^^schema:Person,
        "George A. Constantinides"^^schema:Person,
        "James J. Davis"^^schema:Person,
        "Peter Y. K. Cheung"^^schema:Person ;
    schema:dateModified "2020-03-02T23:26:43Z"^^schema:DateTime ;
    schema:datePublished "2019-10-24T00:04:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "LUTNet: Learning FPGA Configurations for Highly Efficient Neural Network  Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12625v2"^^schema:URL .

<767> a schema:ScholarlyArticle ;
    schema:abstract "The problem of fair classification can be mollified if we develop a method toremove the embedded sensitive information from the classification features.This line of separating the sensitive information is developed through thecausal inference, and the causal inference enables the counterfactualgenerations to contrast the what-if case of the opposite sensitive attribute.Along with this separation with the causality, a frequent assumption in thedeep latent causal model defines a single latent variable to absorb the entireexogenous uncertainty of the causal graph. However, we claim that suchstructure cannot distinguish the 1) information caused by the intervention(i.e., sensitive variable) and 2) information correlated with the interventionfrom the data. Therefore, this paper proposes Disentangled Causal EffectVariational Autoencoder (DCEVAE) to resolve this limitation by disentanglingthe exogenous uncertainty into two latent variables: either 1) independent tointerventions or 2) correlated to interventions without causality.Particularly, our disentangling approach preserves the latent variablecorrelated to interventions in generating counterfactual examples. We show thatour method estimates the total effect and the counterfactual effect without acomplete causal graph. By adding a fairness regularization, DCEVAE generates acounterfactual fair dataset while losing less original information. Also,DCEVAE generates natural counterfactual images by only flipping sensitiveinformation. Additionally, we theoretically show the differences in thecovariance structures of DCEVAE and prior works from the perspective of thelatent disentanglement."^^schema:Text ;
    schema:author "Hyemi Kim"^^schema:Person,
        "Il-Chul Moon"^^schema:Person,
        "JoonHo Jang"^^schema:Person,
        "Kyungwoo Song"^^schema:Person,
        "Seungjae Shin"^^schema:Person,
        "Wanmo Kang"^^schema:Person,
        "Weonyoung Joo"^^schema:Person ;
    schema:dateModified "2020-12-09T09:46:14Z"^^schema:DateTime ;
    schema:datePublished "2020-11-24T03:43:59Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Counterfactual Fairness with Disentangled Causal Effect Variational  Autoencoder"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11878v2"^^schema:URL .

<768> a schema:ScholarlyArticle ;
    schema:abstract "Dynamic routing in software-defined networking (SDN) can be viewed as acentralized decision-making problem. Most of the existing deep reinforcementlearning (DRL) agents can address it, thanks to the deep neural network(DNN)incorporated. However, fully-connected feed-forward neural network (FFNN)is usually adopted, where spatial correlation and temporal variation of trafficflows are ignored. This drawback usually leads to significantly highcomputational complexity due to large number of training parameters. Toovercome this problem, we propose a novel model-free framework for dynamicrouting in SDN, which is referred to as spatio-temporal deterministic policygradient (STDPG) agent. Both the actor and critic networks are based onidentical DNN structure, where a combination of convolutional neural network(CNN) and long short-term memory network (LSTM) with temporal attentionmechanism, CNN-LSTM-TAM, is devised. By efficiently exploiting spatial andtemporal features, CNNLSTM-TAM helps the STDPG agent learn better from theexperience transitions. Furthermore, we employ the prioritized experiencereplay (PER) method to accelerate the convergence of model training. Theexperimental results show that STDPG can automatically adapt for currentnetwork environment and achieve robust convergence. Compared with a numberstate-ofthe-art DRL agents, STDPG achieves better routing solutions in terms ofthe average end-to-end delay."^^schema:Text ;
    schema:author "Huanlai Xing"^^schema:Person,
        "Juan Chen"^^schema:Person,
        "Muhammad Azhar Iqbal"^^schema:Person,
        "Penglin Dai"^^schema:Person,
        "Shouxi Luo"^^schema:Person,
        "Zhiwen Xiao"^^schema:Person ;
    schema:dateModified "2020-04-21T07:19:07Z"^^schema:DateTime ;
    schema:datePublished "2020-04-21T07:19:07Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "STDPG: A Spatio-Temporal Deterministic Policy Gradient Agent for Dynamic  Routing in SDN"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.09783v1"^^schema:URL .

<769> a schema:ScholarlyArticle ;
    schema:abstract "Recent studies show that the state-of-the-art deep neural networks (DNNs) arevulnerable to adversarial examples, resulting from small-magnitudeperturbations added to the input. Given that that emerging physical systems areusing DNNs in safety-critical situations, adversarial examples could misleadthese systems and cause dangerous situations.Therefore, understandingadversarial examples in the physical world is an important step towardsdeveloping resilient learning algorithms. We propose a general attackalgorithm,Robust Physical Perturbations (RP2), to generate robust visualadversarial perturbations under different physical conditions. Using thereal-world case of road sign classification, we show that adversarial examplesgenerated using RP2 achieve high targeted misclassification rates againststandard-architecture road sign classifiers in the physical world under variousenvironmental conditions, including viewpoints. Due to the current lack of astandardized testing method, we propose a two-stage evaluation methodology forrobust physical adversarial examples consisting of lab and field tests. Usingthis methodology, we evaluate the efficacy of physical adversarialmanipulations on real objects. Witha perturbation in the form of only black andwhite stickers,we attack a real stop sign, causing targeted misclassificationin 100% of the images obtained in lab settings, and in 84.8%of the capturedvideo frames obtained on a moving vehicle(field test) for the targetclassifier."^^schema:Text ;
    schema:author "Amir Rahmati"^^schema:Person,
        "Atul Prakash"^^schema:Person,
        "Bo Li"^^schema:Person,
        "Chaowei Xiao"^^schema:Person,
        "Dawn Song"^^schema:Person,
        "Earlence Fernandes"^^schema:Person,
        "Ivan Evtimov"^^schema:Person,
        "Kevin Eykholt"^^schema:Person,
        "Tadayoshi Kohno"^^schema:Person ;
    schema:dateModified "2018-04-10T16:22:47Z"^^schema:DateTime ;
    schema:datePublished "2017-07-27T17:37:22Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Robust Physical-World Attacks on Deep Learning Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.08945v5"^^schema:URL .

<77> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent Neural Networks can be trained to produce sequences of tokens givensome input, as exemplified by recent results in machine translation and imagecaptioning. The current approach to training them consists of maximizing thelikelihood of each token in the sequence given the current (recurrent) stateand the previous token. At inference, the unknown previous token is thenreplaced by a token generated by the model itself. This discrepancy betweentraining and inference can yield errors that can accumulate quickly along thegenerated sequence. We propose a curriculum learning strategy to gently changethe training process from a fully guided scheme using the true previous token,towards a less guided scheme which mostly uses the generated token instead.Experiments on several sequence prediction tasks show that this approach yieldssignificant improvements. Moreover, it was used successfully in our winningentry to the MSCOCO image captioning challenge, 2015."^^schema:Text ;
    schema:author "Navdeep Jaitly"^^schema:Person,
        "Noam Shazeer"^^schema:Person,
        "Oriol Vinyals"^^schema:Person,
        "Samy Bengio"^^schema:Person ;
    schema:commentCount "897"^^schema:Integer ;
    schema:dateModified "2015-09-23T16:35:42Z"^^schema:DateTime ;
    schema:datePublished "2015-06-09T20:33:47Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Scheduled Sampling for Sequence Prediction with Recurrent Neural  Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.03099v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4523710212567339415&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<770> a schema:ScholarlyArticle ;
    schema:abstract "With the rapid development of Artificial Intelligence (AI), the problem of AIsecurity has gradually emerged. Most existing machine learning algorithms maybe attacked by adversarial examples. An adversarial example is a slightlymodified input sample that can lead to a false result of machine learningalgorithms. The adversarial examples pose a potential security threat for manyAI application areas, especially in the domain of robot path planning. In thisfield, the adversarial examples obstruct the algorithm by adding obstacles tothe normal maps, resulting in multiple effects on the predicted path. However,there is no suitable approach to automatically identify them. To our knowledge,all previous work uses manual observation method to estimate the attack resultsof adversarial maps, which is time-consuming. Aiming at the existing problem,this paper explores a method to automatically identify the adversarial examplesin Value Iteration Networks (VIN), which has a strong generalization ability.We analyze the possible scenarios caused by the adversarial maps. We propose atraining-based identification approach to VIN adversarial examples by combingthe path feature comparison and path image classification. We evaluate ourmethod using the adversarial maps dataset, show that our method can achieve ahigh-accuracy and faster identification than manual observation method."^^schema:Text ;
    schema:author "Gang Li"^^schema:Person,
        "Jingjing Liu"^^schema:Person,
        "Jiqiang Liu"^^schema:Person,
        "Tong Chen"^^schema:Person,
        "Wenjia Niu"^^schema:Person,
        "Yingdi Wang"^^schema:Person,
        "Yingxiao Xiang"^^schema:Person ;
    schema:dateModified "2018-10-18T14:17:12Z"^^schema:DateTime ;
    schema:datePublished "2018-10-18T14:17:12Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text ;
    schema:headline "A Training-based Identification Approach to VIN Adversarial Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.08070v1"^^schema:URL .

<771> a schema:ScholarlyArticle ;
    schema:abstract "Recently, it has been shown that many functions on sets can be represented bysum decompositions. These decompositons easily lend themselves to neuralapproximations, extending the applicability of neural nets to set-valuedinputs---Deep Set learning. This work investigates a core component of Deep Setarchitecture: aggregation functions. We suggest and examine alternatives tocommonly used aggregation functions, including learnable recurrent aggregationfunctions. Empirically, we show that the Deep Set networks are highly sensitiveto the choice of aggregation functions: beyond improved performance, we findthat learnable aggregations lower hyper-parameter sensitivity and generalizebetter to out-of-distribution input size."^^schema:Text ;
    schema:author "Adnan Akhundov"^^schema:Person,
        "Justin Bayer"^^schema:Person,
        "Maximilian Soelch"^^schema:Person,
        "Patrick van der Smagt"^^schema:Person ;
    schema:dateModified "2020-04-08T14:56:07Z"^^schema:DateTime ;
    schema:datePublished "2019-03-18T10:24:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On Deep Set Learning and the Choice of Aggregations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.07348v2"^^schema:URL .

<772> a schema:ScholarlyArticle ;
    schema:abstract "We present a method for efficient learning of control policies for multiplerelated robotic motor skills. Our approach consists of two stages, jointtraining and specialization training. During the joint training stage, a neuralnetwork policy is trained with minimal information to disambiguate the motorskills. This forces the policy to learn a common representation of thedifferent tasks. Then, during the specialization training stage we selectivelysplit the weights of the policy based on a per-weight metric that measures thedisagreement among the multiple tasks. By splitting part of the control policy,it can be further trained to specialize to each task. To update the controlpolicy during learning, we use Trust Region Policy Optimization withGeneralized Advantage Function (TRPOGAE). We propose a modification to thegradient update stage of TRPO to better accommodate multi-task learningscenarios. We evaluate our approach on three continuous motor skill learningproblems in simulation: 1) a locomotion task where three single legged robotswith considerable difference in shape and size are trained to hop forward, 2) amanipulation task where three robot manipulators with different sizes and jointtypes are trained to reach different locations in 3D space, and 3) locomotionof a two-legged robot, whose range of motion of one leg is constrained indifferent ways. We compare our training method to three baselines. The firstbaseline uses only joint training for the policy, the second trains independentpolicies for each task, and the last randomly selects weights to split. We showthat our approach learns more efficiently than each of the baseline methods."^^schema:Text ;
    schema:author "C. Karen Liu"^^schema:Person,
        "Greg Turk"^^schema:Person,
        "Wenhao Yu"^^schema:Person ;
    schema:dateModified "2018-03-02T22:23:00Z"^^schema:DateTime ;
    schema:datePublished "2017-09-23T00:54:18Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Multi-task Learning with Gradient Guided Policy Specialization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.07979v3"^^schema:URL .

<773> a schema:ScholarlyArticle ;
    schema:abstract "Interactive Educational Systems (IES) enabled researchers to trace studentknowledge in different skills and provide recommendations for a better learningpath. To estimate the student knowledge and further predict their futureperformance, the interest in utilizing the student interaction data captured byIES to develop learner performance models is increasing rapidly. Moreover, withthe advances in computing systems, the amount of data captured by these IESsystems is also increasing that enables deep learning models to compete withtraditional logistic models and Markov processes. However, it is still notempirically evident if these deep models outperform traditional models on thecurrent scale of datasets with millions of student interactions. In this work,we adopt EdNet, the largest student interaction dataset publicly available inthe education domain, to understand how accurately both deep and traditionalmodels predict future student performances. Our work observes that logisticregression models with carefully engineered features outperformed deep modelsfrom extensive experimentation. We follow this analysis with interpretationstudies based on Locally Interpretable Model-agnostic Explanation (LIME) tounderstand the impact of various features on best performing modelpre-dictions."^^schema:Text ;
    schema:author "Jiaqi Gong"^^schema:Person,
        "Lujie Chen"^^schema:Person,
        "Varun Mandalapu"^^schema:Person ;
    schema:dateModified "2021-01-20T22:40:38Z"^^schema:DateTime ;
    schema:datePublished "2021-01-20T22:40:38Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Do we need to go Deep? Knowledge Tracing with Big Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.08349v1"^^schema:URL .

<774> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a new class of time-continuous recurrent neural network models.Instead of declaring a learning system's dynamics by implicit nonlinearities,we construct networks of linear first-order dynamical systems modulated vianonlinear interlinked gates. The resulting models represent dynamical systemswith varying (i.e., liquid) time-constants coupled to their hidden state, withoutputs being computed by numerical differential equation solvers. These neuralnetworks exhibit stable and bounded behavior, yield superior expressivitywithin the family of neural ordinary differential equations, and give rise toimproved performance on time-series prediction tasks. To demonstrate theseproperties, we first take a theoretical approach to find bounds over theirdynamics and compute their expressive power by the trajectory length measure inlatent trajectory space. We then conduct a series of time-series predictionexperiments to manifest the approximation capability of Liquid Time-ConstantNetworks (LTCs) compared to classical and modern RNNs. Code and data areavailable at https://github.com/raminmh/liquid_time_constant_networks"^^schema:Text ;
    schema:author "Alexander Amini"^^schema:Person,
        "Daniela Rus"^^schema:Person,
        "Mathias Lechner"^^schema:Person,
        "Radu Grosu"^^schema:Person,
        "Ramin Hasani"^^schema:Person ;
    schema:dateModified "2020-12-14T22:23:52Z"^^schema:DateTime ;
    schema:datePublished "2020-06-08T09:53:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Liquid Time-constant Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.04439v4"^^schema:URL .

<775> a schema:ScholarlyArticle ;
    schema:abstract "Huge amounts of textual conversations occur online every day, where multipleconversations take place concurrently. Interleaved conversations lead todifficulties in not only following the ongoing discussions but also extractingrelevant information from simultaneous messages. Conversation disentanglementaims to separate intermingled messages into detached conversations. However,existing disentanglement methods rely mostly on handcrafted features that aredataset specific, which hinders generalization and adaptability. In this work,we propose an end-to-end online framework for conversation disentanglement thatavoids time-consuming domain-specific feature engineering. We design a novelway to embed the whole utterance that comprises timestamp, speaker, and messagetext, and proposes a custom attention mechanism that models disentanglement asa pointing problem while effectively capturing inter-utterance interactions inan end-to-end fashion. We also introduce a joint-learning objective to bettercapture contextual information. Our experiments on the Ubuntu IRC dataset showthat our method achieves state-of-the-art performance in both link andconversation prediction tasks."^^schema:Text ;
    schema:author "Shafiq Joty"^^schema:Person,
        "Tao Yu"^^schema:Person ;
    schema:dateModified "2020-10-21T15:43:07Z"^^schema:DateTime ;
    schema:datePublished "2020-10-21T15:43:07Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Online Conversation Disentanglement with Pointer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.11080v1"^^schema:URL .

<776> a schema:ScholarlyArticle ;
    schema:abstract "Multiagent reinforcement learning algorithms (MARL) have been demonstrated oncomplex tasks that require the coordination of a team of multiple agents tocomplete. Existing works have focused on sharing information between agents viacentralized critics to stabilize learning or through communication to increaseperformance, but do not generally look at how information can be shared betweenagents to address the curse of dimensionality in MARL. We posit that amultiagent problem can be decomposed into a multi-task problem where each agentexplores a subset of the state space instead of exploring the entire statespace. This paper introduces a multiagent actor-critic algorithm and method forcombining knowledge from homogeneous agents through distillation andvalue-matching that outperforms policy distillation alone and allows furtherlearning in both discrete and continuous action spaces."^^schema:Text ;
    schema:author "Dong-Ki Kim"^^schema:Person,
        "Jonathan P. How"^^schema:Person,
        "Samir Wadhwania"^^schema:Person,
        "Shayegan Omidshafiei"^^schema:Person ;
    schema:dateModified "2019-03-15T15:13:02Z"^^schema:DateTime ;
    schema:datePublished "2019-03-15T15:13:02Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Policy Distillation and Value Matching in Multiagent Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.06592v1"^^schema:URL .

<777> a schema:ScholarlyArticle ;
    schema:abstract "Attributed networks nowadays are ubiquitous in a myriad of high-impactapplications, such as social network analysis, financial fraud detection, anddrug discovery. As a central analytical task on attributed networks, nodeclassification has received much attention in the research community. Inreal-world attributed networks, a large portion of node classes only containlimited labeled instances, rendering a long-tail node class distribution.Existing node classification algorithms are unequipped to handle the\\textit{few-shot} node classes. As a remedy, few-shot learning has attracted asurge of attention in the research community. Yet, few-shot node classificationremains a challenging problem as we need to address the following questions:(i) How to extract meta-knowledge from an attributed network for few-shot nodeclassification? (ii) How to identify the informativeness of each labeledinstance for building a robust and effective model? To answer these questions,in this paper, we propose a graph meta-learning framework -- Graph PrototypicalNetworks (GPN). By constructing a pool of semi-supervised node classificationtasks to mimic the real test environment, GPN is able to perform\\textit{meta-learning} on an attributed network and derive a highlygeneralizable model for handling the target classification task. Extensiveexperiments demonstrate the superior capability of GPN in few-shot nodeclassification."^^schema:Text ;
    schema:author "Chenghao Liu"^^schema:Person,
        "Huan Liu"^^schema:Person,
        "Jianling Wang"^^schema:Person,
        "Jundong Li"^^schema:Person,
        "Kai Shu"^^schema:Person,
        "Kaize Ding"^^schema:Person ;
    schema:dateModified "2020-11-27T05:15:11Z"^^schema:DateTime ;
    schema:datePublished "2020-06-23T04:13:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Graph Prototypical Networks for Few-shot Learning on Attributed Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.12739v3"^^schema:URL .

<778> a schema:ScholarlyArticle ;
    schema:abstract "In open-ended environments, autonomous learning agents must set their owngoals and build their own curriculum through an intrinsically motivatedexploration. They may consider a large diversity of goals, aiming to discoverwhat is controllable in their environments, and what is not. Because some goalsmight prove easy and some impossible, agents must actively select which goal topractice at any moment, to maximize their overall mastery on the set oflearnable goals. This paper proposes CURIOUS, an algorithm that leverages 1) amodular Universal Value Function Approximator with hindsight learning toachieve a diversity of goals of different kinds within a unique policy and 2)an automated curriculum learning mechanism that biases the attention of theagent towards goals maximizing the absolute learning progress. Agents focussequentially on goals of increasing complexity, and focus back on goals thatare being forgotten. Experiments conducted in a new modular-goal roboticenvironment show the resulting developmental self-organization of a learningcurriculum, and demonstrate properties of robustness to distracting goals,forgetting and changes in body properties."^^schema:Text ;
    schema:author "Cédric Colas"^^schema:Person,
        "Mohamed Chetouani"^^schema:Person,
        "Olivier Sigaud"^^schema:Person,
        "Pierre Fournier"^^schema:Person,
        "Pierre-Yves Oudeyer"^^schema:Person ;
    schema:dateModified "2019-05-29T11:52:20Z"^^schema:DateTime ;
    schema:datePublished "2018-10-15T11:40:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.06284v4"^^schema:URL .

<779> a schema:ScholarlyArticle ;
    schema:abstract "The past decade has seen a rapid penetration of electric vehicles (EV) in themarket, more and more logistics and transportation companies start to deployEVs for service provision. In order to model the operations of a commercial EVfleet, we utilize the EV routing problem with time windows (EVRPTW). In thisresearch, we propose an end-to-end deep reinforcement learning framework tosolve the EVRPTW. In particular, we develop an attention model incorporatingthe pointer network and a graph embedding technique to parameterize astochastic policy for solving the EVRPTW. The model is then trained usingpolicy gradient with rollout baseline. Our numerical studies show that theproposed model is able to efficiently solve EVRPTW instances of large sizesthat are not solvable with any existing approaches."^^schema:Text ;
    schema:author "Bissan Ghaddar"^^schema:Person,
        "Bo Lin"^^schema:Person,
        "Jatin Nathwani"^^schema:Person ;
    schema:dateModified "2020-11-14T01:14:31Z"^^schema:DateTime ;
    schema:datePublished "2020-10-05T15:06:02Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Electric Vehicle Routing Problem with  Time Windows"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.02068v2"^^schema:URL .

<78> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) modelfor generating novel image captions. It directly models the probabilitydistribution of generating a word given previous words and an image. Imagecaptions are generated by sampling from this distribution. The model consistsof two sub-networks: a deep recurrent neural network for sentences and a deepconvolutional network for images. These two sub-networks interact with eachother in a multimodal layer to form the whole m-RNN model. The effectiveness ofour model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K,Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. Inaddition, we apply the m-RNN model to retrieval tasks for retrieving images orsentences, and achieves significant performance improvement over thestate-of-the-art methods which directly optimize the ranking objective functionfor retrieval. The project page of this work is:www.stat.ucla.edu/~junhua.mao/m-RNN.html ."^^schema:Text ;
    schema:author "Alan Yuille"^^schema:Person,
        "Jiang Wang"^^schema:Person,
        "Junhua Mao"^^schema:Person,
        "Wei Xu"^^schema:Person,
        "Yi Yang"^^schema:Person,
        "Zhiheng Huang"^^schema:Person ;
    schema:commentCount "843"^^schema:Integer ;
    schema:dateModified "2015-06-11T15:26:58Z"^^schema:DateTime ;
    schema:datePublished "2014-12-20T08:10:04Z"^^schema:DateTime ;
    schema:genre "I.2.6; I.2.7; I.2.10"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)"^^schema:Text ;
    schema:publisher "ICLR"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.6632v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16666958166938946394&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<780> a schema:ScholarlyArticle ;
    schema:abstract "We are considering the problem of controlling a team of robotic bodyguardsprotecting a VIP from physical assault in the presence of neutral and/oradversarial bystanders. This task is part of a much larger class of problemsinvolving coordinated robot behavior in the presence of humans. This problem ischallenging due to the large number of active entities with different agendas,the need of cooperation between the robots as well as the requirement to takeinto consideration criteria such as social norms and unobtrusiveness inaddition to the main goal of VIP safety. Furthermore, different settings suchas street, public space or red carpet require very different behavior from therobot. We describe how a multi-agent reinforcement learning approach can evolvebehavior policies for teams of robot bodyguards that compare well withhand-engineered approaches. Furthermore, we show that an algorithm inspired byuniversal value function approximators can learn policies that exhibitappropriate, distinct behavior in environments with different requirements."^^schema:Text ;
    schema:author "Hassam Ullah Sheikh"^^schema:Person,
        "Ladislau Boloni"^^schema:Person ;
    schema:dateModified "2020-03-25T19:30:21Z"^^schema:DateTime ;
    schema:datePublished "2018-09-12T14:55:19Z"^^schema:DateTime ;
    schema:genre "cs.MA"^^schema:Text ;
    schema:headline "Emergence of Scenario-Appropriate Collaborative Behaviors for Teams of  Robotic Bodyguards"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.04500v3"^^schema:URL .

<781> a schema:ScholarlyArticle ;
    schema:abstract "A key appeal of the recently proposed Neural Ordinary DifferentialEquation(ODE) framework is that it seems to provide a continuous-time extensionof discrete residual neural networks. As we show herein, though, trained NeuralODE models actually depend on the specific numerical method used duringtraining. If the trained model is supposed to be a flow generated from an ODE,it should be possible to choose another numerical solver with equal or smallernumerical error without loss of performance. We observe that if training relieson a solver with overly coarse discretization, then testing with another solverof equal or smaller numerical error results in a sharp drop in accuracy. Insuch cases, the combination of vector field and numerical method cannot beinterpreted as a flow generated from an ODE, which arguably poses a fatalbreakdown of the Neural ODE concept. We observe, however, that there exists acritical step size beyond which the training yields a valid ODE vector field.We propose a method that monitors the behavior of the ODE solver duringtraining to adapt its step size, aiming to ensure a valid ODE withoutunnecessarily increasing computational cost. We verify this adaption algorithmon two common bench mark datasets as well as a synthetic dataset. Furthermore,we introduce a novel synthetic dataset in which the underlying ODE directlygenerates a classification task."^^schema:Text ;
    schema:author "Katharina Ott"^^schema:Person,
        "Michael Tiemann"^^schema:Person,
        "Philipp Hennig"^^schema:Person,
        "Prateek Katiyar"^^schema:Person ;
    schema:dateModified "2020-07-30T11:24:05Z"^^schema:DateTime ;
    schema:datePublished "2020-07-30T11:24:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "When are Neural ODE Solutions Proper ODEs?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.15386v1"^^schema:URL .

<782> a schema:ScholarlyArticle ;
    schema:abstract "Self-attention (SA) mechanisms can capture effectively global dependencies indeep neural networks, and have been applied to natural language processing andimage processing successfully. However, SA modules for image reconstructionhave high time and space complexity, which restrict their applications tohigher-resolution images. In this paper, we refine the SA module inself-attention generative adversarial networks (SAGAN) via adapting a non-localoperation, revising the connectivity among the units in SA module andre-implementing its computational pattern, such that its time and spacecomplexity is reduced from $\\text{O}(n^2)$ to $\\text{O}(n)$, but it is stillequivalent to the original SA module. Further, we explore the principles behindthe module and discover that our module is a special kind of channel attentionmechanisms. Experimental results based on two benchmark datasets of imagereconstruction, verify that under the same computational environment, twomodels can achieve comparable effectiveness for image reconstruction, but theproposed one runs faster and takes up less memory space."^^schema:Text ;
    schema:author "Ge Song"^^schema:Person,
        "Jianwu Li"^^schema:Person,
        "Tieling Li"^^schema:Person,
        "Zheng Wang"^^schema:Person ;
    schema:dateModified "2019-05-20T11:43:37Z"^^schema:DateTime ;
    schema:datePublished "2019-05-20T11:43:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Less Memory, Faster Speed: Refining Self-Attention Module for Image  Reconstruction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.08008v1"^^schema:URL .

<783> a schema:ScholarlyArticle ;
    schema:abstract "In Reinforcement Learning (RL), an agent explores the environment andcollects trajectories into the memory buffer for later learning. However, thecollected trajectories can easily be imbalanced with respect to the achievedgoal states. The problem of learning from imbalanced data is a well-knownproblem in supervised learning, but has not yet been thoroughly researched inRL. To address this problem, we propose a novel Curiosity-Driven Prioritization(CDP) framework to encourage the agent to over-sample those trajectories thathave rare achieved goal states. The CDP framework mimics the human learningprocess and focuses more on relatively uncommon events. We evaluate our methodsusing the robotic environment provided by OpenAI Gym. The environment containssix robot manipulation tasks. In our experiments, we combined CDP with DeepDeterministic Policy Gradient (DDPG) with or without Hindsight ExperienceReplay (HER). The experimental results show that CDP improves both performanceand sample-efficiency of reinforcement learning agents, compared tostate-of-the-art methods."^^schema:Text ;
    schema:author "Rui Zhao"^^schema:Person,
        "Volker Tresp"^^schema:Person ;
    schema:dateModified "2020-05-24T08:15:29Z"^^schema:DateTime ;
    schema:datePublished "2019-02-20T12:31:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Curiosity-Driven Experience Prioritization via Density Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.08039v3"^^schema:URL .

<784> a schema:ScholarlyArticle ;
    schema:abstract "Pose-guided person image generation is to transform a source person image toa target pose. This task requires spatial manipulations of source data.However, Convolutional Neural Networks are limited by the lack of ability tospatially transform the inputs. In this paper, we propose a differentiableglobal-flow local-attention framework to reassemble the inputs at the featurelevel. Specifically, our model first calculates the global correlations betweensources and targets to predict flow fields. Then, the flowed local patch pairsare extracted from the feature maps to calculate the local attentioncoefficients. Finally, we warp the source features using a content-awaresampling method with the obtained local attention coefficients. The results ofboth subjective and objective experiments demonstrate the superiority of ourmodel. Besides, additional results in video animation and view synthesis showthat our model is applicable to other tasks requiring spatial transformation.Our source code is available athttps://github.com/RenYurui/Global-Flow-Local-Attention."^^schema:Text ;
    schema:author "Ge Li"^^schema:Person,
        "Junming Chen"^^schema:Person,
        "Thomas H. Li"^^schema:Person,
        "Xiaoming Yu"^^schema:Person,
        "Yurui Ren"^^schema:Person ;
    schema:dateModified "2020-03-18T09:42:02Z"^^schema:DateTime ;
    schema:datePublished "2020-03-02T07:31:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Deep Image Spatial Transformation for Person Image Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.00696v2"^^schema:URL .

<785> a schema:ScholarlyArticle ;
    schema:abstract "Keyphrase extraction from documents is useful to a variety of applicationssuch as information retrieval and document summarization. This paper presentsan end-to-end method called DivGraphPointer for extracting a set of diversifiedkeyphrases from a document. DivGraphPointer combines the advantages oftraditional graph-based ranking methods and recent neural network-basedapproaches. Specifically, given a document, a word graph is constructed fromthe document based on word proximity and is encoded with graph convolutionalnetworks, which effectively capture document-level word salience by modelinglong-range dependency between words in the document and aggregating multipleappearances of identical words into one node. Furthermore, we propose adiversified point network to generate a set of diverse keyphrases out of theword graph in the decoding process. Experimental results on five benchmark datasets show that our proposed method significantly outperforms the existingstate-of-the-art approaches."^^schema:Text ;
    schema:author "Jian Tang"^^schema:Person,
        "Jian-Yun Nie"^^schema:Person,
        "Pan Du"^^schema:Person,
        "Zhi-Hong Deng"^^schema:Person,
        "Zhiqing Sun"^^schema:Person ;
    schema:dateModified "2019-05-19T05:17:12Z"^^schema:DateTime ;
    schema:datePublished "2019-05-19T05:17:12Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text ;
    schema:headline "DivGraphPointer: A Graph Pointer Network for Extracting Diverse  Keyphrases"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.07689v1"^^schema:URL .

<786> a schema:ScholarlyArticle ;
    schema:abstract "We present \"Cross-Camera Convolutional Color Constancy\" (C5), alearning-based method, trained on images from multiple cameras, that accuratelyestimates a scene's illuminant color from raw images captured by a new camerapreviously unseen during training. C5 is a hypernetwork-like extension of theconvolutional color constancy (CCC) approach: C5 learns to generate the weightsof a CCC model that is then evaluated on the input image, with the CCC weightsdynamically adapted to different input content. Unlike prior cross-camera colorconstancy models, which are usually designed to be agnostic to the spectralproperties of test-set images from unobserved cameras, C5 approaches thisproblem through the lens of transductive inference: additional unlabeled imagesare provided as input to the model at test time, which allows the model tocalibrate itself to the spectral properties of the test-set camera duringinference. C5 achieves state-of-the-art accuracy for cross-camera colorconstancy on several datasets, is fast to evaluate (~7 and ~90 ms per image ona GPU or CPU, respectively), and requires little memory (~2 MB), and, thus, isa practical solution to the problem of calibration-free automatic white balancefor mobile photography."^^schema:Text ;
    schema:author "Chloe LeGendre"^^schema:Person,
        "Francois Bleibel"^^schema:Person,
        "Jonathan T. Barron"^^schema:Person,
        "Mahmoud Afifi"^^schema:Person,
        "Yun-Ta Tsai"^^schema:Person ;
    schema:dateModified "2020-11-24T04:37:22Z"^^schema:DateTime ;
    schema:datePublished "2020-11-24T04:37:22Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Cross-Camera Convolutional Color Constancy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11890v1"^^schema:URL .

<787> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial networks (GANs) are recently highly successful ingenerative applications involving images and start being applied to time seriesdata. Here we describe EEG-GAN as a framework to generateelectroencephalographic (EEG) brain signals. We introduce a modification to theimproved training of Wasserstein GANs to stabilize training and investigate arange of architectural choices critical for time series generation (mostnotably up- and down-sampling). For evaluation we consider and comparedifferent metrics such as Inception score, Frechet inception distance andsliced Wasserstein distance, together showing that our EEG-GAN frameworkgenerated naturalistic EEG examples. It thus opens up a range of new generativeapplication scenarios in the neuroscientific and neurological context, such asdata augmentation in brain-computer interfacing tasks, EEG super-sampling, orrestoration of corrupted data segments. The possibility to generate signals ofa certain class and/or with specific properties may also open a new avenue forresearch into the underlying structure of brain signals."^^schema:Text ;
    schema:author "Kay Gregor Hartmann"^^schema:Person,
        "Robin Tibor Schirrmeister"^^schema:Person,
        "Tonio Ball"^^schema:Person ;
    schema:dateModified "2018-06-05T18:10:11Z"^^schema:DateTime ;
    schema:datePublished "2018-06-05T18:10:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "q-bio.NC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "EEG-GAN: Generative adversarial networks for electroencephalograhic  (EEG) brain signals"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.01875v1"^^schema:URL .

<788> a schema:ScholarlyArticle ;
    schema:abstract "In spite of much recent research in the area, it is still unclear whethersubject-area question-answering data is useful for machine readingcomprehension (MRC) tasks. In this paper, we investigate this question. Wecollect a large-scale multi-subject multiple-choice question-answering dataset,ExamQA, and use incomplete and noisy snippets returned by a web search engineas the relevant context for each question-answering instance to convert it intoa weakly-labeled MRC instance. We then propose a self-teaching paradigm tobetter use the generated weakly-labeled MRC instances to improve a target MRCtask. Experimental results show that we can obtain an improvement of 5.1% inaccuracy on a multiple-choice MRC dataset, C^3, demonstrating the effectivenessof our framework and the usefulness of large-scale subject-areaquestion-answering data for machine reading comprehension."^^schema:Text ;
    schema:author "Claire Cardie"^^schema:Person,
        "Dian Yu"^^schema:Person,
        "Dong Yu"^^schema:Person,
        "Kai Sun"^^schema:Person ;
    schema:dateModified "2021-02-01T23:18:58Z"^^schema:DateTime ;
    schema:datePublished "2021-02-01T23:18:58Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Self-Teaching Machines to Read and Comprehend with Large-Scale  Multi-Subject Question Answering Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.01226v1"^^schema:URL .

<789> a schema:ScholarlyArticle ;
    schema:abstract "Trust region policy optimization (TRPO) is a popular and empiricallysuccessful policy search algorithm in Reinforcement Learning (RL) in which asurrogate problem, that restricts consecutive policies to be 'close' to oneanother, is iteratively solved. Nevertheless, TRPO has been considered aheuristic algorithm inspired by Conservative Policy Iteration (CPI). We showthat the adaptive scaling mechanism used in TRPO is in fact the natural \"RLversion\" of traditional trust-region methods from convex analysis. We firstanalyze TRPO in the planning setting, in which we have access to the model andthe entire state space. Then, we consider sample-based TRPO and establish$\\tilde O(1/\\sqrt{N})$ convergence rate to the global optimum. Importantly, theadaptive scaling mechanism allows us to analyze TRPO in regularized MDPs forwhich we prove fast rates of $\\tilde O(1/N)$, much like results in convexoptimization. This is the first result in RL of better rates when regularizingthe instantaneous cost or reward."^^schema:Text ;
    schema:author "Lior Shani"^^schema:Person,
        "Shie Mannor"^^schema:Person,
        "Yonathan Efroni"^^schema:Person ;
    schema:dateModified "2019-12-12T17:07:53Z"^^schema:DateTime ;
    schema:datePublished "2019-09-06T08:43:38Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Adaptive Trust Region Policy Optimization: Global Convergence and Faster  Rates for Regularized MDPs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.02769v2"^^schema:URL .

<79> a schema:ScholarlyArticle ;
    schema:abstract "There is a lot of research interest in encoding variable length sentencesinto fixed length vectors, in a way that preserves the sentence meanings. Twocommon methods include representations based on averaging word vectors, andrepresentations based on the hidden states of recurrent neural networks such asLSTMs. The sentence vectors are used as features for subsequent machinelearning tasks or for pre-training in the context of deep learning. However,not much is known about the properties that are encoded in these sentencerepresentations and about the language information they capture. We propose aframework that facilitates better understanding of the encoded representations.We define prediction tasks around isolated aspects of sentence structure(namely sentence length, word content, and word order), and scorerepresentations by the ability to train a classifier to solve each predictiontask when using the representation as input. We demonstrate the potentialcontribution of the approach by analyzing different sentence representationmechanisms. The analysis sheds light on the relative strengths of differentsentence embedding methods with respect to these low level prediction tasks,and on the effect of the encoded vector's dimensionality on the resultingrepresentations."^^schema:Text ;
    schema:author "Einat Kermany"^^schema:Person,
        "Ofer Lavi"^^schema:Person,
        "Yoav Goldberg"^^schema:Person,
        "Yonatan Belinkov"^^schema:Person,
        "Yossi Adi"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2017-02-09T06:58:50Z"^^schema:DateTime ;
    schema:datePublished "2016-08-15T08:51:38Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction  Tasks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1608.04207v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6309693306335821652&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<790> a schema:ScholarlyArticle ;
    schema:abstract "High-capacity models require vast amounts of data, and data augmentation is acommon remedy when this resource is limited. Standard augmentation techniquesapply small hand-tuned transformations to existing data, which is a brittleprocess that realistically only allows for simple transformations. We propose aBayesian interpretation of data augmentation where the transformations aremodelled as latent variables to be marginalized, and show how these can beinferred variationally in an end-to-end fashion. This allows for significantlymore complex transformations than manual tuning, and the marginalizationimplies a form of test-time data augmentation. The resulting model can beinterpreted as a probabilistic extension of spatial transformer networks.Experimentally, we demonstrate improvements in accuracy and uncertaintyquantification in image and time series classification tasks."^^schema:Text ;
    schema:author "Frederik Warburg"^^schema:Person,
        "Kristoffer H. Madsen"^^schema:Person,
        "Martin Jørgensen"^^schema:Person,
        "Pola Schwöbel"^^schema:Person,
        "Søren Hauberg"^^schema:Person ;
    schema:dateModified "2020-04-07T18:22:02Z"^^schema:DateTime ;
    schema:datePublished "2020-04-07T18:22:02Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Probabilistic Spatial Transformers for Bayesian Data Augmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.03637v1"^^schema:URL .

<791> a schema:ScholarlyArticle ;
    schema:abstract "We propose a voting ensemble of models trained by using block-wisetransformed images with secret keys for an adversarially robust defense.Key-based adversarial defenses were demonstrated to outperform state-of-the-artdefenses against gradient-based (white-box) attacks. However, the key-baseddefenses are not effective enough against gradient-free (black-box) attackswithout requiring any secret keys. Accordingly, we aim to enhance robustnessagainst black-box attacks by using a voting ensemble of models. In the proposedensemble, a number of models are trained by using images transformed withdifferent keys and block sizes, and then a voting ensemble is applied to themodels. In image classification experiments, the proposed defense isdemonstrated to defend state-of-the-art attacks. The proposed defense achievesa clean accuracy of 95.56 % and an attack success rate of less than 9 % underattacks with a noise distance of 8/255 on the CIFAR-10 dataset."^^schema:Text ;
    schema:author "Hitoshi Kiya"^^schema:Person,
        "MaungMaung AprilPyone"^^schema:Person ;
    schema:dateModified "2020-11-16T02:48:37Z"^^schema:DateTime ;
    schema:datePublished "2020-11-16T02:48:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Ensemble of Models Trained by Key-based Transformed Images for  Adversarially Robust Defense Against Black-box Attacks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.07697v1"^^schema:URL .

<792> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement Learning(RL) with sparse rewards is a major challenge. Wepropose \\emph{Hindsight Trust Region Policy Optimization}(HTRPO), a new RLalgorithm that extends the highly successful TRPO algorithm with\\emph{hindsight} to tackle the challenge of sparse rewards. Hindsight refers tothe algorithm's ability to learn from information across goals, including onesnot intended for the current task. HTRPO leverages two main ideas. Itintroduces QKL, a quadratic approximation to the KL divergence constraint onthe trust region, leading to reduced variance in KL divergence estimation andimproved stability in policy update. It also presents Hindsight GoalFiltering(HGF) to select conductive hindsight goals. In experiments, weevaluate HTRPO in various sparse reward tasks, including simple benchmarks,image-based Atari games, and simulated robot control. Ablation studies indicatethat QKL and HGF contribute greatly to learning stability and high performance.Comparison results show that in all tasks, HTRPO consistently outperforms bothTRPO and HPG, a state-of-the-art algorithm for RL with sparse rewards."^^schema:Text ;
    schema:author "David Hsu"^^schema:Person,
        "Hanbo Zhang"^^schema:Person,
        "Nanning Zheng"^^schema:Person,
        "Site Bai"^^schema:Person,
        "Xuguang Lan"^^schema:Person ;
    schema:dateModified "2020-02-11T02:00:15Z"^^schema:DateTime ;
    schema:datePublished "2019-07-29T13:59:42Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hindsight Trust Region Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.12439v3"^^schema:URL .

<793> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in policy gradient methods and deep learning havedemonstrated their applicability for complex reinforcement learning problems.However, the variance of the performance gradient estimates obtained from thesimulation is often excessive, leading to poor sample efficiency. In thispaper, we apply the stochastic variance reduced gradient descent (SVRG) tomodel-free policy gradient to significantly improve the sample-efficiency. TheSVRG estimation is incorporated into a trust-region Newton conjugate gradientframework for the policy optimization. On several Mujoco tasks, our methodachieves significantly better performance compared to the state-of-the-artmodel-free policy gradient methods in robotic continuous control such as trustregion policy optimization (TRPO)"^^schema:Text ;
    schema:author "Jian Peng"^^schema:Person,
        "Qiang Liu"^^schema:Person,
        "Tianbing Xu"^^schema:Person ;
    schema:dateModified "2018-03-29T17:51:14Z"^^schema:DateTime ;
    schema:datePublished "2017-10-17T00:05:06Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stochastic Variance Reduction for Policy Gradient Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.06034v4"^^schema:URL .

<794> a schema:ScholarlyArticle ;
    schema:abstract "Neural processor development is reducing our reliance on remote server accessto process deep learning operations in an increasingly edge-driven world. Byemploying in-memory processing, parallelization techniques, andalgorithm-hardware co-design, memristor crossbar arrays are known toefficiently compute large scale matrix-vector multiplications. However,state-of-the-art implementations of negative weights require duplicative columnwires, and high precision weights using single-bit memristors furtherdistributes computations. These constraints dramatically increase chip area andresistive losses, which lead to increased power consumption and reducedaccuracy. In this paper, we develop an adaptive precision method by varying thenumber of memristors at each crosspoint. We also present a weight mappingalgorithm designed for implementation on our crossbar array. This novelalgorithm-hardware solution is described as the radix-X Convolutional NeuralNetwork Crossbar Array, and demonstrate how to efficiently represent negativeweights using a single column line, rather than double the number of additionalcolumns. Using both simulation and experimental results, we verify that ourradix-5 CNN array achieves a validation accuracy of 90.5% on the CIFAR-10dataset, a 4.5% improvement over binarized neural networks whilstsimultaneously reducing crossbar area by 46% over conventional arrays byremoving the need for duplicate columns to represent signed weights."^^schema:Text ;
    schema:author "Jaeheum Lee"^^schema:Person,
        "Jason K. Eshraghian"^^schema:Person,
        "Kamran Eshraghian"^^schema:Person,
        "Kyoungrok Cho"^^schema:Person ;
    schema:dateModified "2019-06-22T06:14:24Z"^^schema:DateTime ;
    schema:datePublished "2019-06-22T06:14:24Z"^^schema:DateTime ;
    schema:genre "cs.AR"^^schema:Text,
        "eess.IV"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Adaptive Precision CNN Accelerator Using Radix-X Parallel Connected  Memristor Crossbars"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.09395v1"^^schema:URL .

<795> a schema:ScholarlyArticle ;
    schema:abstract "Discrete spatial patterns and their continuous transformations are twoimportant regularities contained in natural signals. Lie groups andrepresentation theory are mathematical tools that have been used in previousworks to model continuous image transformations. On the other hand, sparsecoding is an important tool for learning dictionaries of patterns in naturalsignals. In this paper, we combine these ideas in a Bayesian generative modelthat learns to disentangle spatial patterns and their continuoustransformations in a completely unsupervised manner. Images are modeled as asparse superposition of shape components followed by a transformation that isparameterized by n continuous variables. The shape components andtransformations are not predefined, but are instead adapted to learn thesymmetries in the data, with the constraint that the transformations form arepresentation of an n-dimensional torus. Training the model on a datasetconsisting of controlled geometric transformations of specific MNIST digitsshows that it can recover these transformations along with the digits. Trainingon the full MNIST dataset shows that it can learn both the basic digit shapesand the natural transformations such as shearing and stretching that arecontained in this data."^^schema:Text ;
    schema:author "Bruno Olshausen"^^schema:Person,
        "Frank Qiu"^^schema:Person,
        "Ho Yin Chau"^^schema:Person,
        "Yubei Chen"^^schema:Person ;
    schema:dateModified "2020-12-11T19:11:32Z"^^schema:DateTime ;
    schema:datePublished "2020-12-11T19:11:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Disentangling images with Lie group transformations and sparse coding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.12071v1"^^schema:URL .

<796> a schema:ScholarlyArticle ;
    schema:abstract "In reinforcement learning (RL), temporal abstraction still remains as animportant and unsolved problem. The options framework provided clues totemporal abstraction in the RL, and the option-critic architecture elegantlysolved the two problems of finding options and learning RL agents in anend-to-end manner. However, it is necessary to examine whether the optionslearned through this method play a mutually exclusive role. In this paper, wepropose a Hellinger distance regularizer, a method for disentangling options.In addition, we will shed light on various indicators from the statisticalpoint of view to compare with the options learned through the existingoption-critic architecture."^^schema:Text ;
    schema:author "Junyoung Choi"^^schema:Person,
        "Minsung Hyun"^^schema:Person,
        "Nojun Kwak"^^schema:Person ;
    schema:dateModified "2019-04-15T07:43:17Z"^^schema:DateTime ;
    schema:datePublished "2019-04-15T07:43:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Disentangling Options with Hellinger Distance Regularizer"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.06887v1"^^schema:URL .

<797> a schema:ScholarlyArticle ;
    schema:abstract "We consider learning representations (features) in the setting in which wehave access to multiple unlabeled views of the data for learning while only oneview is available for downstream tasks. Previous work on this problem hasproposed several techniques based on deep neural networks, typically involvingeither autoencoder-like networks with a reconstruction objective or pairedfeedforward networks with a batch-style correlation-based objective. We analyzeseveral techniques based on prior work, as well as new variants, and comparethem empirically on image, speech, and text tasks. We find an advantage forcorrelation-based representation learning, while the best results on most tasksare obtained with our new variant, deep canonically correlated autoencoders(DCCAE). We also explore a stochastic optimization procedure for minibatchcorrelation-based objectives and discuss the time/performance trade-offs forkernel-based and neural network-based implementations."^^schema:Text ;
    schema:author "Jeff Bilmes"^^schema:Person,
        "Karen Livescu"^^schema:Person,
        "Raman Arora"^^schema:Person,
        "Weiran Wang"^^schema:Person ;
    schema:dateModified "2016-02-02T17:51:43Z"^^schema:DateTime ;
    schema:datePublished "2016-02-02T17:51:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "On Deep Multi-View Representation Learning: Objectives and Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1602.01024v1"^^schema:URL .

<798> a schema:ScholarlyArticle ;
    schema:abstract "As the most successful variant and improvement for Trust Region PolicyOptimization (TRPO), proximal policy optimization (PPO) has been widely appliedacross various domains with several advantages: efficient data utilization,easy implementation, and good parallelism. In this paper, a first-ordergradient reinforcement learning algorithm called Policy Optimization withPenalized Point Probability Distance (POP3D), which is a lower bound to thesquare of total variance divergence is proposed as another powerful variant.Firstly, we talk about the shortcomings of several commonly used algorithms, bywhich our method is partly motivated. Secondly, we address to overcome theseshortcomings by applying POP3D. Thirdly, we dive into its mechanism from theperspective of solution manifold. Finally, we make quantitative comparisonsamong several state-of-the-art algorithms based on common benchmarks.Simulation results show that POP3D is highly competitive compared with PPO.Besides, our code is released in https://github.com/paperwithcode/pop3d."^^schema:Text ;
    schema:author "Xiangxiang Chu"^^schema:Person ;
    schema:dateModified "2019-02-14T08:51:28Z"^^schema:DateTime ;
    schema:datePublished "2018-07-02T02:49:36Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Policy Optimization With Penalized Point Probability Distance: An  Alternative To Proximal Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.00442v4"^^schema:URL .

<799> a schema:ScholarlyArticle ;
    schema:abstract "A recent trend of fair machine learning is to define fairness ascausality-based notions which concern the causal connection between protectedattributes and decisions. However, one common challenge of all causality-basedfairness notions is identifiability, i.e., whether they can be uniquelymeasured from observational data, which is a critical barrier to applying thesenotions to real-world situations. In this paper, we develop a framework formeasuring different causality-based fairness. We propose a unified definitionthat covers most of previous causality-based fairness notions, namely thepath-specific counterfactual fairness (PC fairness). Based on that, we proposea general method in the form of a constrained optimization problem for boundingthe path-specific counterfactual fairness under all unidentifiable situations.Experiments on synthetic and real-world datasets show the correctness andeffectiveness of our method."^^schema:Text ;
    schema:author "Hanghang Tong"^^schema:Person,
        "Lu Zhang"^^schema:Person,
        "Xintao Wu"^^schema:Person,
        "Yongkai Wu"^^schema:Person ;
    schema:dateModified "2019-10-20T23:00:53Z"^^schema:DateTime ;
    schema:datePublished "2019-10-20T23:00:53Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "PC-Fairness: A Unified Framework for Measuring Causality-based Fairness"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12586v1"^^schema:URL .

<8> a schema:ScholarlyArticle ;
    schema:abstract "In spite of the recent success of neural machine translation (NMT) instandard benchmarks, the lack of large parallel corpora poses a major practicalproblem for many language pairs. There have been several proposals to alleviatethis issue with, for instance, triangulation and semi-supervised learningtechniques, but they still require a strong cross-lingual signal. In this work,we completely remove the need of parallel data and propose a novel method totrain an NMT system in a completely unsupervised manner, relying on nothing butmonolingual corpora. Our model builds upon the recent work on unsupervisedembedding mappings, and consists of a slightly modified attentionalencoder-decoder model that can be trained on monolingual corpora alone using acombination of denoising and backtranslation. Despite the simplicity of theapproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014French-to-English and German-to-English translation. The model can also profitfrom small parallel corpora, and attains 21.81 and 15.24 points when combinedwith 100,000 parallel sentences, respectively. Our implementation is releasedas an open source project."^^schema:Text ;
    schema:author "Eneko Agirre"^^schema:Person,
        "Gorka Labaka"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Mikel Artetxe"^^schema:Person ;
    schema:commentCount "359"^^schema:Integer ;
    schema:dateModified "2018-02-26T16:54:14Z"^^schema:DateTime ;
    schema:datePublished "2017-10-30T16:17:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Unsupervised Neural Machine Translation"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1710.11041v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6109181985493123662&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<80> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent sequence generators conditioned on input data through an attentionmechanism have recently shown very good performance on a range of tasks in-cluding machine translation, handwriting synthesis and image caption gen-eration. We extend the attention-mechanism with features needed for speechrecognition. We show that while an adaptation of the model used for machinetranslation in reaches a competitive 18.7% phoneme error rate (PER) on theTIMIT phoneme recognition task, it can only be applied to utterances which areroughly as long as the ones it was trained on. We offer a qualitativeexplanation of this failure and propose a novel and generic method of addinglocation-awareness to the attention mechanism to alleviate this issue. The newmethod yields a model that is robust to long inputs and achieves 18% PER insingle utterances and 20% in 10-times longer (repeated) utterances. Finally, wepropose a change to the at- tention mechanism that prevents it fromconcentrating too much on single frames, which further reduces PER to 17.6%level."^^schema:Text ;
    schema:author "Dmitriy Serdyuk"^^schema:Person,
        "Dzmitry Bahdanau"^^schema:Person,
        "Jan Chorowski"^^schema:Person,
        "Kyunghyun Cho"^^schema:Person,
        "Yoshua Bengio"^^schema:Person ;
    schema:commentCount "1268"^^schema:Integer ;
    schema:dateModified "2015-06-24T19:10:33Z"^^schema:DateTime ;
    schema:datePublished "2015-06-24T19:10:33Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Attention-Based Models for Speech Recognition"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.07503v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16516573035858419027&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<800> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a novel meta learning approach for automaticchannel pruning of very deep neural networks. We first train a PruningNet, akind of meta network, which is able to generate weight parameters for anypruned structure given the target network. We use a simple stochastic structuresampling method for training the PruningNet. Then, we apply an evolutionaryprocedure to search for good-performing pruned networks. The search is highlyefficient because the weights are directly generated by the trained PruningNetand we do not need any finetuning at search time. With a single PruningNettrained for the target network, we can search for various Pruned Networks underdifferent constraints with little human participation. Compared to thestate-of-the-art pruning methods, we have demonstrated superior performances onMobileNet V1/V2 and ResNet. Codes are available onhttps://github.com/liuzechun/MetaPruning."^^schema:Text ;
    schema:author "Haoyuan Mu"^^schema:Person,
        "Jian Sun"^^schema:Person,
        "Tim Kwang-Ting Cheng"^^schema:Person,
        "Xiangyu Zhang"^^schema:Person,
        "Xin Yang"^^schema:Person,
        "Zechun Liu"^^schema:Person,
        "Zichao Guo"^^schema:Person ;
    schema:dateModified "2019-08-14T03:41:11Z"^^schema:DateTime ;
    schema:datePublished "2019-03-25T12:05:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.10258v3"^^schema:URL .

<801> a schema:ScholarlyArticle ;
    schema:abstract "Quantifying how far the output of a learning algorithm is from its target isan essential task in machine learning. However, in quantum settings, the losslandscapes of commonly used distance metrics often produce undesirable outcomessuch as poor local minima and exponentially decaying gradients. As a newapproach, we consider here the quantum earth mover's (EM) or Wasserstein-1distance, recently proposed in [De Palma et al., arXiv:2009.04469] as a quantumanalog to the classical EM distance. We show that the quantum EM distancepossesses unique properties, not found in other commonly used quantum distancemetrics, that make quantum learning more stable and efficient. We propose aquantum Wasserstein generative adversarial network (qWGAN) which takesadvantage of the quantum EM distance and provides an efficient means ofperforming learning on quantum data. Our qWGAN requires resources polynomial inthe number of qubits, and our numerical experiments demonstrate that it iscapable of learning a diverse set of quantum data."^^schema:Text ;
    schema:author "Bobak Toussi Kiani"^^schema:Person,
        "Giacomo De Palma"^^schema:Person,
        "Milad Marvian"^^schema:Person,
        "Seth Lloyd"^^schema:Person,
        "Zi-Wen Liu"^^schema:Person ;
    schema:dateModified "2021-01-08T14:33:19Z"^^schema:DateTime ;
    schema:datePublished "2021-01-08T14:33:19Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "quant-ph"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Quantum Earth Mover's Distance: A New Approach to Learning Quantum Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.03037v1"^^schema:URL .

<802> a schema:ScholarlyArticle ;
    schema:abstract "Existing inefficient traffic light control causes numerous problems, such aslong delay and waste of energy. To improve efficiency, taking real-time trafficinformation as an input and dynamically adjusting the traffic light durationaccordingly is a must. In terms of how to dynamically adjust traffic signals'duration, existing works either split the traffic signal into equal duration orextract limited traffic information from the real data. In this paper, we studyhow to decide the traffic signals' duration based on the collected data fromdifferent sensors and vehicular networks. We propose a deep reinforcementlearning model to control the traffic light. In the model, we quantify thecomplex traffic scenario as states by collecting data and dividing the wholeintersection into small grids. The timing changes of a traffic light are theactions, which are modeled as a high-dimension Markov decision process. Thereward is the cumulative waiting time difference between two cycles. To solvethe model, a convolutional neural network is employed to map the states torewards. The proposed model is composed of several components to improve theperformance, such as dueling network, target network, double Q-learningnetwork, and prioritized experience replay. We evaluate our model viasimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,and the simulation results show the efficiency of our model in controllingtraffic lights."^^schema:Text ;
    schema:author "Guiling Wang"^^schema:Person,
        "Xiaoyuan Liang"^^schema:Person,
        "Xunsheng Du"^^schema:Person,
        "Zhu Han"^^schema:Person ;
    schema:dateModified "2018-03-29T15:24:28Z"^^schema:DateTime ;
    schema:datePublished "2018-03-29T15:24:28Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning for Traffic Light Control in Vehicular  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1803.11115v1"^^schema:URL .

<803> a schema:ScholarlyArticle ;
    schema:abstract "Molecular optimization aims to discover novel molecules with desirableproperties. Two fundamental challenges are: (i) it is not trivial to generatevalid molecules in a controllable way due to hard chemical constraints such asthe valency conditions, and (ii) it is often costly to evaluate a property of anovel molecule, and therefore, the number of property evaluations is limited.These challenges are to some extent alleviated by a combination of avariational autoencoder (VAE) and Bayesian optimization (BO). VAE converts amolecule into/from its latent continuous vector, and BO optimizes a latentcontinuous vector (and its corresponding molecule) within a limited number ofproperty evaluations. While the most recent work, for the first time, achieved100% validity, its architecture is rather complex due to auxiliary neuralnetworks other than VAE, making it difficult to train. This paper presents amolecular hypergraph grammar variational autoencoder (MHG-VAE), which uses asingle VAE to achieve 100% validity. Our idea is to develop a graph grammarencoding the hard chemical constraints, called molecular hypergraph grammar(MHG), which guides VAE to always generate valid molecules. We also present analgorithm to construct MHG from a set of molecules."^^schema:Text ;
    schema:author "Hiroshi Kajino"^^schema:Person ;
    schema:dateModified "2019-04-23T04:52:44Z"^^schema:DateTime ;
    schema:datePublished "2018-09-08T02:25:52Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Molecular Hypergraph Grammar with its Application to Molecular  Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.02745v2"^^schema:URL .

<804> a schema:ScholarlyArticle ;
    schema:abstract "When researchers develop new econometric methods it is common practice tocompare the performance of the new methods to those of existing methods inMonte Carlo studies. The credibility of such Monte Carlo studies is oftenlimited because of the freedom the researcher has in choosing the design. Inrecent years a new class of generative models emerged in the machine learningliterature, termed Generative Adversarial Networks (GANs) that can be used tosystematically generate artificial data that closely mimics real economicdatasets, while limiting the degrees of freedom for the researcher andoptionally satisfying privacy guarantees with respect to their training data.In addition if an applied researcher is concerned with the performance of aparticular statistical method on a specific data set (beyond its theoreticalproperties in large samples), she may wish to assess the performance, e.g., thecoverage rate of confidence intervals or the bias of the estimator, usingsimulated data which resembles her setting. Tol illustrate these methods weapply Wasserstein GANs (WGANs) to compare a number of different estimators foraverage treatment effects under unconfoundedness in three distinct settings(corresponding to three real data sets) and present a methodology for assessingthe robustness of the results. In this example, we find that (i) there is notone estimator that outperforms the others in all three settings, so researchersshould tailor their analytic approach to a given setting, and (ii) systematicsimulation studies can be helpful for selecting among competing methods in thissituation."^^schema:Text ;
    schema:author "Evan Munro"^^schema:Person,
        "Guido Imbens"^^schema:Person,
        "Jonas Metzger"^^schema:Person,
        "Susan Athey"^^schema:Person ;
    schema:dateModified "2020-07-22T03:47:55Z"^^schema:DateTime ;
    schema:datePublished "2019-09-05T05:01:38Z"^^schema:DateTime ;
    schema:genre "econ.EM"^^schema:Text,
        "stat.ME"^^schema:Text ;
    schema:headline "Using Wasserstein Generative Adversarial Networks for the Design of  Monte Carlo Simulations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.02210v3"^^schema:URL .

<805> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we study a few challenging theoretical and numerical issues onthe well known trust region policy optimization for deep reinforcementlearning. The goal is to find a policy that maximizes the total expected rewardwhen the agent acts according to the policy. The trust region subproblem isconstructed with a surrogate function coherent to the total expected reward anda general distance constraint around the latest policy. We solve the subproblemusing a preconditioned stochastic gradient method with a line search scheme toensure that each step promotes the model function and stays in the trustregion. To overcome the bias caused by sampling to the function estimationsunder the random settings, we add the empirical standard deviation of the totalexpected reward to the predicted increase in a ratio in order to update thetrust region radius and decide whether the trial point is accepted. Moreover,for a Gaussian policy which is commonly used for continuous action space, themaximization with respect to the mean and covariance is performed separately tocontrol the entropy loss. Our theoretical analysis shows that the deterministicversion of the proposed algorithm tends to generate a monotonic improvement ofthe total expected reward and the global convergence is guaranteed undermoderate assumptions. Comparisons with the state-of-the-art methods demonstratethe effectiveness and robustness of our method over robotic controls and gameplayings from OpenAI Gym."^^schema:Text ;
    schema:author "Mingming Zhao"^^schema:Person,
        "Yongfeng Li"^^schema:Person,
        "Zaiwen Wen"^^schema:Person ;
    schema:dateModified "2019-11-26T15:27:13Z"^^schema:DateTime ;
    schema:datePublished "2019-11-26T15:27:13Z"^^schema:DateTime ;
    schema:genre "math.OC"^^schema:Text ;
    schema:headline "A Stochastic Trust-Region Framework for Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.11640v1"^^schema:URL .

<806> a schema:ScholarlyArticle ;
    schema:abstract "Various neural-based methods have been proposed so far for joint mentiondetection and coreference resolution. However, existing works on coreferenceresolution are mainly dependent on filtered mention representation, while otherspans are largely neglected. In this paper, we aim at increasing theutilization rate of data and investigating whether those eliminated spans aretotally useless, or to what extent they can improve the performance ofcoreference resolution. To achieve this, we propose a mention representationrefining strategy where spans highly related to mentions are well leveragedusing a pointer network for representation enhancing. Notably, we utilize anadditional loss term in this work to encourage the diversity between entityclusters. Experimental results on the document-level CoNLL-2012 Shared TaskEnglish dataset show that eliminated spans are indeed much effective and ourapproach can achieve competitive results when compared with previousstate-of-the-art in coreference resolution."^^schema:Text ;
    schema:author "Guodong Zhou"^^schema:Person,
        "Longyin Zhang"^^schema:Person,
        "Xin Tan"^^schema:Person ;
    schema:dateModified "2021-01-04T02:02:49Z"^^schema:DateTime ;
    schema:datePublished "2021-01-04T02:02:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Are Eliminated Spans Useless for Coreference Resolution? Not at all"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.00737v1"^^schema:URL .

<807> a schema:ScholarlyArticle ;
    schema:abstract "We propose to learn a curriculum or a syllabus for supervised learning anddeep reinforcement learning with deep neural networks by an attachable deepneural network, called ScreenerNet. Specifically, we learn a weight for eachsample by jointly training the ScreenerNet and the main network in anend-to-end self-paced fashion. The ScreenerNet neither has sampling bias norrequires to remember the past learning history. We show the networks augmentedwith the ScreenerNet achieve early convergence with better accuracy than thestate-of-the-art curricular learning methods in extensive experiments usingthree popular vision datasets such as MNIST, CIFAR10 and Pascal VOC2012, and aCart-pole task using Deep Q-learning. Moreover, the ScreenerNet can extendother curriculum learning methods such as Prioritized Experience Replay (PER)for further accuracy improvement."^^schema:Text ;
    schema:author "Jonghyun Choi"^^schema:Person,
        "Tae-Hoon Kim"^^schema:Person ;
    schema:dateModified "2018-06-06T06:46:02Z"^^schema:DateTime ;
    schema:datePublished "2018-01-03T05:49:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "ScreenerNet: Learning Self-Paced Curriculum for Deep Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1801.00904v4"^^schema:URL .

<808> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel approach (DyNODE) that captures the underlying dynamics ofa system by incorporating control in a neural ordinary differential equationframework. We conduct a systematic evaluation and comparison of our method andstandard neural network architectures for dynamics modeling. Our resultsindicate that a simple DyNODE architecture when combined with an actor-criticreinforcement learning (RL) algorithm that uses model predictions to improvethe critic's target values, outperforms canonical neural networks, both insample efficiency and predictive performance across a diverse range ofcontinuous tasks that are frequently used to benchmark RL algorithms. Thisapproach provides a new avenue for the development of models that are moresuited to learn the evolution of dynamical systems, particularly useful in thecontext of model-based reinforcement learning. To assist related work, we havemade code available at https://github.com/vmartinezalvarez/DyNODE ."^^schema:Text ;
    schema:author "Cristian G. Fălcuţescu"^^schema:Person,
        "Rareş Roşca"^^schema:Person,
        "Victor M. Martinez Alvarez"^^schema:Person ;
    schema:dateModified "2020-09-09T12:56:58Z"^^schema:DateTime ;
    schema:datePublished "2020-09-09T12:56:58Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DyNODE: Neural Ordinary Differential Equations for Dynamics Modeling in  Continuous Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.04278v1"^^schema:URL .

<809> a schema:ScholarlyArticle ;
    schema:abstract "Performing fact verification based on structured data is important for manyreal-life applications and is a challenging research problem, particularly whenit involves both symbolic operations and informal inference based on languageunderstanding. In this paper, we present a Program-enhanced Verbalization andGraph Attention Network (ProgVGAT) to integrate programs and execution intotextual inference models. Specifically, a verbalization with program executionmodel is proposed to accumulate evidences that are embedded in operations overthe tables. Built on that, we construct the graph attention verificationnetworks, which are designed to fuse different sources of evidences fromverbalized program execution, program structures, and the original statementsand tables, to make the final verification decision. To support the aboveframework, we propose a program selection module optimized with a new trainingstrategy based on margin loss, to produce more accurate programs, which isshown to be effective in enhancing the final verification results. Experimentalresults show that the proposed framework achieves the new state-of-the-artperformance, a 74.4% accuracy, on the benchmark dataset TABFACT."^^schema:Text ;
    schema:author "Feng Nie"^^schema:Person,
        "Quan Liu"^^schema:Person,
        "Xiaodan Zhu"^^schema:Person,
        "Xiaoyu Yang"^^schema:Person,
        "Yufei Feng"^^schema:Person,
        "Zhigang Chen"^^schema:Person ;
    schema:dateModified "2020-11-26T20:27:59Z"^^schema:DateTime ;
    schema:datePublished "2020-10-06T23:29:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Program Enhanced Fact Verification with Verbalization and Graph  Attention Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.03084v5"^^schema:URL .

<81> a schema:ScholarlyArticle ;
    schema:abstract "We present StarSpace, a general-purpose neural embedding model that can solvea wide variety of problems: labeling tasks such as text classification, rankingtasks such as information retrieval/web search, collaborative filtering-basedor content-based recommendation, embedding of multi-relational graphs, andlearning word, sentence or document level embeddings. In each case the modelworks by embedding those entities comprised of discrete features and comparingthem against each other -- learning similarities dependent on the task.Empirical results on a number of tasks show that StarSpace is highlycompetitive with existing methods, whilst also being generally applicable tonew cases where those methods are not."^^schema:Text ;
    schema:author "Adam Fisch"^^schema:Person,
        "Antoine Bordes"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Keith Adams"^^schema:Person,
        "Ledell Wu"^^schema:Person,
        "Sumit Chopra"^^schema:Person ;
    schema:commentCount "135"^^schema:Integer ;
    schema:dateModified "2017-11-21T02:59:57Z"^^schema:DateTime ;
    schema:datePublished "2017-09-12T14:16:56Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "StarSpace: Embed All The Things!"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.03856v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1391286903653880286&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<810> a schema:ScholarlyArticle ;
    schema:abstract "Transportation systems often rely on understanding the flow of vehicles orpedestrian. From traffic monitoring at the city scale, to commuters in trainterminals, recent progress in sensing technology make it possible to usecameras to better understand the demand, i.e., better track moving agents(e.g., vehicles and pedestrians). Whether the cameras are mounted on drones,vehicles, or fixed in the built environments, they inevitably remain scatter.We need to develop the technology to re-identify the same agents across imagescaptured from non-overlapping field-of-views, referred to as the visualre-identification task. State-of-the-art methods learn a neural network basedrepresentation trained with the cross-entropy loss function. We argue that suchloss function is not suited for the visual re-identification task hence proposeto model confidence in the representation learning framework. We show theimpact of our confidence-based learning framework with three methods: labelsmoothing, confidence penalty, and deep variational information bottleneck.They all show a boost in performance validating our claim. Our contribution isgeneric to any agent of interest, i.e., vehicles or pedestrians, and outperformhighly specialized state-of-the-art methods across 5 datasets. The source codeand models are shared towards an open science mission."^^schema:Text ;
    schema:author "Alexandre Alahi"^^schema:Person,
        "George Adaimi"^^schema:Person,
        "Sven Kreiss"^^schema:Person ;
    schema:dateModified "2020-09-10T08:53:43Z"^^schema:DateTime ;
    schema:datePublished "2019-06-11T16:49:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Deep Visual Re-Identification with Confidence"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.04692v2"^^schema:URL .

<811> a schema:ScholarlyArticle ;
    schema:abstract "Most existing knowledge graphs suffer from incompleteness. Embeddingknowledge graphs into continuous vector spaces has recently attractedincreasing interest in knowledge base completion. However, in most existingembedding methods, only fact triplets are utilized, and logical rules have notbeen thoroughly studied for the knowledge base completion task. To overcome theproblem, we propose an association rules enhanced knowledge graph attentionnetwork (AR-KGAT). The AR-KGAT captures both entity and relation features forhigh-order neighborhoods of any given entity in an end-to-end manner under thegraph attention network framework. The major component of AR-KGAT is an encoderof an effective neighborhood aggregator, which addresses the problems byaggregating neighbors with both association-rules-based and graph-basedattention weights. Additionally, the proposed model also encapsulates therepresentations from multi-hop neighbors of nodes to refine their embeddings.The decoder enables AR-KGAT to be translational between entities and relationswhile keeping the superior link prediction performance. A logic-like inferencepattern is utilized as constraints for knowledge graph embedding. Then, theglobal loss is minimized over both atomic and complex formulas to achieve theembedding task. In this manner, we learn embeddings compatible with tripletsand rules, which are certainly more predictive for knowledge acquisition andinference. We conduct extensive experiments on two benchmark datasets: WN18RRand FB15k-237, for two knowledge graph completion tasks: the link predictionand triplet classification to evaluate the proposed AR-KGAT model. The resultsshow that the proposed AR-KGAT model achieves significant and consistentimprovements over state-of-the-art methods."^^schema:Text ;
    schema:author "Jianbin Huang"^^schema:Person,
        "Qinglin Tan"^^schema:Person,
        "Zhenghao Zhang"^^schema:Person ;
    schema:dateModified "2020-11-14T13:18:55Z"^^schema:DateTime ;
    schema:datePublished "2020-11-14T13:18:55Z"^^schema:DateTime ;
    schema:genre "cs.IR"^^schema:Text ;
    schema:headline "Association Rules Enhanced Knowledge Graph Attention Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.08431v1"^^schema:URL .

<812> a schema:ScholarlyArticle ;
    schema:abstract "Goal-oriented reinforcement learning has recently been a practical frameworkfor robotic manipulation tasks, in which an agent is required to reach acertain goal defined by a function on the state space. However, the sparsity ofsuch reward definition makes traditional reinforcement learning algorithms veryinefficient. Hindsight Experience Replay (HER), a recent advance, has greatlyimproved sample efficiency and practical applicability for such problems. Itexploits previous replays by constructing imaginary goals in a simple heuristicway, acting like an implicit curriculum to alleviate the challenge of sparsereward signal. In this paper, we introduce Hindsight Goal Generation (HGG), anovel algorithmic framework that generates valuable hindsight goals which areeasy for an agent to achieve in the short term and are also potential forguiding the agent to reach the actual goal in the long term. We haveextensively evaluated our goal generation algorithm on a number of roboticmanipulation tasks and demonstrated substantially improvement over the originalHER in terms of sample efficiency."^^schema:Text ;
    schema:author "Jian Peng"^^schema:Person,
        "Kefan Dong"^^schema:Person,
        "Qiang Liu"^^schema:Person,
        "Yuan Zhou"^^schema:Person,
        "Zhizhou Ren"^^schema:Person ;
    schema:dateModified "2019-12-18T04:31:39Z"^^schema:DateTime ;
    schema:datePublished "2019-06-10T21:21:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Exploration via Hindsight Goal Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.04279v3"^^schema:URL .

<813> a schema:ScholarlyArticle ;
    schema:abstract "We provide a method to solve optimization problem when objective function isa complex stochastic simulator of an urban transportation system. To reach thisgoal, a Bayesian optimization framework is introduced. We show how the choiceof prior and inference algorithm effect the outcome of our optimizationprocedure. We develop dimensionality reduction techniques that allow for ouroptimization techniques to be applicable for real-life problems. We develop adistributed, Gaussian Process Bayesian regression and active learning modelsthat allow parallel execution of our algorithms and enable usage of highperformance computing. We present a fully Bayesian approach that is more sampleefficient and reduces computational budget. Our framework is supported bytheoretical analysis and an empirical study. We demonstrate our framework onthe problem of calibrating a multi-modal transportation network of city ofBloomington, Illinois. Finally, we discuss directions for further research."^^schema:Text ;
    schema:author "Laura Schultz"^^schema:Person,
        "Vadim Sokolov"^^schema:Person ;
    schema:dateModified "2019-01-14T06:29:12Z"^^schema:DateTime ;
    schema:datePublished "2018-10-08T20:31:22Z"^^schema:DateTime ;
    schema:genre "stat.CO"^^schema:Text ;
    schema:headline "Practical Bayesian Optimization for Transportation Simulators"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1810.03688v2"^^schema:URL .

<814> a schema:ScholarlyArticle ;
    schema:abstract "Learning over massive data stored in different locations is essential in manyreal-world applications. However, sharing data is full of challenges due to theincreasing demands of privacy and security with the growing use of smart mobiledevices and IoT devices. Federated learning provides a potential solution toprivacy-preserving and secure machine learning, by means of jointly training aglobal model without uploading data distributed on multiple devices to acentral server. However, most existing work on federated learning adoptsmachine learning models with full-precision weights, and almost all thesemodels contain a large number of redundant parameters that do not need to betransmitted to the server, consuming an excessive amount of communicationcosts. To address this issue, we propose a federated trained ternaryquantization (FTTQ) algorithm, which optimizes the quantized networks on theclients through a self-learning quantization factor. A convergence proof of thequantization factor and the unbiasedness of FTTQ is given. In addition, wepropose a ternary federated averaging protocol (T-FedAvg) to reduce theupstream and downstream communication of federated learning systems. Empiricalexperiments are conducted to train widely used deep learning models on publiclyavailable datasets, and our results demonstrate the effectiveness of FTTQ andT-FedAvg compared with the canonical federated learning algorithms in reducingcommunication costs and maintaining the learning performance."^^schema:Text ;
    schema:author "Jinjin Xu"^^schema:Person,
        "Ran Cheng"^^schema:Person,
        "Wangli He"^^schema:Person,
        "Wenli Du"^^schema:Person,
        "Yaochu Jin"^^schema:Person ;
    schema:dateModified "2020-03-07T11:55:34Z"^^schema:DateTime ;
    schema:datePublished "2020-03-07T11:55:34Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Ternary Compression for Communication-Efficient Federated Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.03564v1"^^schema:URL .

<815> a schema:ScholarlyArticle ;
    schema:abstract "Reduced-precision arithmetic improves the size, cost, power and performanceof neural networks in digital logic. In convolutional neural networks, the useof 1b weights can achieve state-of-the-art error rates while eliminatingmultiplication, reducing storage and improving power efficiency. TheBinaryConnect binary-weighted system, for example, achieves 9.9% error usingfloating-point activations on the CIFAR-10 dataset. In this paper, we introduceTinBiNN, a lightweight vector processor overlay for accelerating inferencecomputations with 1b weights and 8b activations. The overlay is very small --it uses about 5,000 4-input LUTs and fits into a low cost iCE40 UltraPlus FPGAfrom Lattice Semiconductor. To show this can be useful, we build two embedded'person detector' systems by shrinking the original BinaryConnect network. Thefirst is a 10-category classifier with a 89% smaller network that runs in1,315ms and achieves 13.6% error. The other is a 1-category classifier that iseven smaller, runs in 195ms, and has only 0.4% error. In both classifiers, theerror can be attributed entirely to training and not reduced precision."^^schema:Text ;
    schema:author "Aaron Severance"^^schema:Person,
        "Abdullah Raouf"^^schema:Person,
        "Guy G. F. Lemieux"^^schema:Person,
        "Hussein Osman"^^schema:Person,
        "Joe Edwards"^^schema:Person,
        "Joel Vandergriendt"^^schema:Person,
        "Ryan De Iaco"^^schema:Person,
        "Satwant Singh"^^schema:Person,
        "Tom Watzka"^^schema:Person ;
    schema:dateModified "2019-03-05T14:51:36Z"^^schema:DateTime ;
    schema:datePublished "2019-03-05T14:51:36Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.OH"^^schema:Text ;
    schema:headline "TinBiNN: Tiny Binarized Neural Network Overlay in about 5,000 4-LUTs and  5mW"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.06630v1"^^schema:URL .

<816> a schema:ScholarlyArticle ;
    schema:abstract "We consider the problem of Human-Object Interaction (HOI) Detection, whichaims to locate and recognize HOI instances in the form of &lt;human, action,object&gt; in images. Most existing works treat HOIs as individual interactioncategories, thus can not handle the problem of long-tail distribution andpolysemy of action labels. We argue that multi-level consistencies amongobjects, actions and interactions are strong cues for generating semanticrepresentations of rare or previously unseen HOIs. Leveraging the compositionaland relational peculiarities of HOI labels, we propose ConsNet, aknowledge-aware framework that explicitly encodes the relations among objects,actions and interactions into an undirected graph called consistency graph, andexploits Graph Attention Networks (GATs) to propagate knowledge among HOIcategories as well as their constituents. Our model takes visual features ofcandidate human-object pairs and word embeddings of HOI labels as inputs, mapsthem into visual-semantic joint embedding space and obtains detection resultsby measuring their similarities. We extensively evaluate our model on thechallenging V-COCO and HICO-DET datasets, and results validate that ourapproach outperforms state-of-the-arts under both fully-supervised andzero-shot settings."^^schema:Text ;
    schema:author "Chang Wen Chen"^^schema:Person,
        "Junsong Yuan"^^schema:Person,
        "Ye Liu"^^schema:Person ;
    schema:dateModified "2020-09-15T05:35:03Z"^^schema:DateTime ;
    schema:datePublished "2020-08-14T09:11:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "ConsNet: Learning Consistency Graph for Zero-Shot Human-Object  Interaction Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.06254v2"^^schema:URL .

<817> a schema:ScholarlyArticle ;
    schema:abstract "Learning from demonstrations is a popular tool for accelerating and reducingthe exploration requirements of reinforcement learning. When providing expertdemonstrations to human students, we know that the demonstrations must fallwithin a particular range of difficulties called the \"Zone of ProximalDevelopment (ZPD)\". If they are too easy the student learns nothing, but ifthey are too difficult the student is unable to follow along. This raises thequestion: Given a set of potential demonstrators, which among them is bestsuited for teaching any particular learner? Prior work, such as the popularDeep Q-learning from Demonstrations (DQfD) algorithm has generally focused onsingle demonstrators. In this work we consider the problem of choosing amongmultiple demonstrators of varying skill levels. Our results align withintuition from human learners: it is not always the best policy to drawdemonstrations from the best performing demonstrator (in terms of reward). Weshow that careful selection of teaching strategies can result in sampleefficiency gains in the learner's environment across nine Atari games"^^schema:Text ;
    schema:author "Chen Tang"^^schema:Person,
        "Daniel Seita"^^schema:Person,
        "David Chan"^^schema:Person,
        "John Canny"^^schema:Person,
        "Mandi Zhao"^^schema:Person,
        "Roshan Rao"^^schema:Person ;
    schema:dateModified "2019-10-26T23:05:43Z"^^schema:DateTime ;
    schema:datePublished "2019-10-26T23:05:43Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "ZPD Teaching Strategies for Deep Reinforcement Learning from  Demonstrations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.12154v1"^^schema:URL .

<818> a schema:ScholarlyArticle ;
    schema:abstract "Designing hierarchical reinforcement learning algorithms that induce a notionof safety is not only vital for safety-critical applications, but also, bringsbetter understanding of an artificially intelligent agent's decisions. Whilelearning end-to-end options automatically has been fully realized recently, wepropose a solution to learning safe options. We introduce the idea ofcontrollability of states based on the temporal difference errors in theoption-critic framework. We then derive the policy-gradient theorem withcontrollability and propose a novel framework called safe option-critic. Wedemonstrate the effectiveness of our approach in the four-rooms grid-world,cartpole, and three games in the Arcade Learning Environment (ALE): MsPacman,Amidar and Q*Bert. Learning of end-to-end options with the proposed notion ofsafety achieves reduction in the variance of return and boosts the performancein environments with intrinsic variability in the reward structure. Moreimportantly, the proposed algorithm outperforms the vanilla options in all theenvironments and primitive actions in two out of three ALE games."^^schema:Text ;
    schema:author "Arushi Jain"^^schema:Person,
        "Doina Precup"^^schema:Person,
        "Khimya Khetarpal"^^schema:Person ;
    schema:dateModified "2018-07-21T00:39:23Z"^^schema:DateTime ;
    schema:datePublished "2018-07-21T00:39:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text ;
    schema:headline "Safe Option-Critic: Learning Safety in the Option-Critic Architecture"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.08060v1"^^schema:URL .

<819> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we propose a novel method for generating 3D point clouds thatleverage properties of hyper networks. Contrary to the existing methods thatlearn only the representation of a 3D object, our approach simultaneously findsa representation of the object and its 3D surface. The main idea of ourHyperCloud method is to build a hyper network that returns weights of aparticular neural network (target network) trained to map points from a uniformunit ball distribution into a 3D shape. As a consequence, a particular 3D shapecan be generated using point-by-point sampling from the assumed priordistribution and transforming sampled points with the target network. Since thehyper network is based on an auto-encoder architecture trained to reconstructrealistic 3D shapes, the target network weights can be considered aparametrization of the surface of a 3D shape, and not a standard representationof point cloud usually returned by competitive approaches. The proposedarchitecture allows finding mesh-based representation of 3D objects in agenerative manner while providing point clouds en pair in quality with thestate-of-the-art methods."^^schema:Text ;
    schema:author "Jacek Tabor"^^schema:Person,
        "Maciej Zamorski"^^schema:Person,
        "Maciej Zięba"^^schema:Person,
        "Przemysław Spurek"^^schema:Person,
        "Sebastian Winczowski"^^schema:Person,
        "Tomasz Trzciński"^^schema:Person ;
    schema:dateModified "2020-10-13T19:18:59Z"^^schema:DateTime ;
    schema:datePublished "2020-02-10T11:09:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Hypernetwork approach to generating point clouds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.00802v2"^^schema:URL .

<82> a schema:ScholarlyArticle ;
    schema:abstract "In practice, there are often explicit constraints on what representations ordecisions are acceptable in an application of machine learning. For example itmay be a legal requirement that a decision must not favour a particular group.Alternatively it can be that that representation of data must not haveidentifying information. We address these two related issues by learningflexible representations that minimize the capability of an adversarial critic.This adversary is trying to predict the relevant sensitive variable from therepresentation, and so minimizing the performance of the adversary ensuresthere is little or no information in the representation about the sensitivevariable. We demonstrate this adversarial approach on two problems: makingdecisions free from discrimination and removing private information fromimages. We formulate the adversarial model as a minimax problem, and optimizethat minimax objective using a stochastic gradient alternate min-max optimizer.We demonstrate the ability to provide discriminant free representations forstandard test problems, and compare with previous state of the art methods forfairness, showing statistically significant improvement across most cases. Theflexibility of this method is shown via a novel problem: removing annotationsfrom images, from unaligned training examples of annotated and unannotatedimages, and with no a priori knowledge of the form of annotation provided tothe model."^^schema:Text ;
    schema:author "Amos Storkey"^^schema:Person,
        "Harrison Edwards"^^schema:Person ;
    schema:commentCount "204"^^schema:Integer ;
    schema:dateModified "2016-03-04T11:01:34Z"^^schema:DateTime ;
    schema:datePublished "2015-11-18T18:06:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Censoring Representations with an Adversary"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1511.05897v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=14450653116005073046&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<820> a schema:ScholarlyArticle ;
    schema:abstract "Recent research has made impressive progress in single-turn dialoguemodelling. In the multi-turn setting, however, current models are still farfrom satisfactory. One major challenge is the frequently occurred coreferenceand information omission in our daily conversation, making it hard for machinesto understand the real intention. In this paper, we propose rewriting the humanutterance as a pre-process to help multi-turn dialgoue modelling. Eachutterance is first rewritten to recover all coreferred and omitted information.The next processing steps are then performed based on the rewritten utterance.To properly train the utterance rewriter, we collect a new dataset with humanannotations and introduce a Transformer-based utterance rewriting architectureusing the pointer network. We show the proposed architecture achievesremarkably good performance on the utterance rewriting task. The trainedutterance rewriter can be easily integrated into online chatbots and bringsgeneral improvement over different domains."^^schema:Text ;
    schema:author "Cheng Niu"^^schema:Person,
        "Fei Sun"^^schema:Person,
        "Hui Su"^^schema:Person,
        "Jie Zhou"^^schema:Person,
        "Pengwei Hu"^^schema:Person,
        "Rongzhi Zhang"^^schema:Person,
        "Xiaoyu Shen"^^schema:Person ;
    schema:dateModified "2019-06-14T06:45:08Z"^^schema:DateTime ;
    schema:datePublished "2019-06-14T06:45:08Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Improving Multi-turn Dialogue Modelling with Utterance ReWriter"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.07004v1"^^schema:URL .

<821> a schema:ScholarlyArticle ;
    schema:abstract "Place recognition is an essential component of Simultaneous Localization AndMapping (SLAM). Under severe appearance change, reliable place recognition is adifficult perception task since the same place is perceptually very differentin the morning, at night, or over different seasons. This work addresses placerecognition as a domain translation task. Using a pair of coupled GenerativeAdversarial Networks (GANs), we show that it is possible to generate theappearance of one domain (such as summer) from another (such as winter) withoutrequiring image-to-image correspondences across the domains. Mapping betweendomains is learned from sets of images in each domain without knowing theinstance-to-instance correspondence by enforcing a cyclic consistencyconstraint. In the process, meaningful feature spaces are learned for eachdomain, the distances in which can be used for the task of place recognition.Experiments show that learned features correspond to visual similarity and canbe effectively used for place recognition across seasons."^^schema:Text ;
    schema:author "Ian Reid"^^schema:Person,
        "Michael Milford"^^schema:Person,
        "Ravi Garg"^^schema:Person,
        "Yasir Latif"^^schema:Person ;
    schema:dateModified "2018-02-27T03:39:05Z"^^schema:DateTime ;
    schema:datePublished "2017-09-26T04:14:52Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Addressing Challenging Place Recognition Tasks using Generative  Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1709.08810v2"^^schema:URL .

<822> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we address unsupervised pose-guided person image generation,which is known challenging due to non-rigid deformation. Unlike previousmethods learning a rock-hard direct mapping between human bodies, we propose anew pathway to decompose the hard mapping into two more accessible subtasks,namely, semantic parsing transformation and appearance generation. Firstly, asemantic generative network is proposed to transform between semantic parsingmaps, in order to simplify the non-rigid deformation learning. Secondly, anappearance generative network learns to synthesize semantic-aware textures.Thirdly, we demonstrate that training our framework in an end-to-end mannerfurther refines the semantic maps and final results accordingly. Our method isgeneralizable to other semantic-aware person image generation tasks, eg,clothing texture transfer and controlled image manipulation. Experimentalresults demonstrate the superiority of our method on DeepFashion andMarket-1501 datasets, especially in keeping the clothing attributes and betterbody shapes."^^schema:Text ;
    schema:author "Jiaying Liu"^^schema:Person,
        "Sijie Song"^^schema:Person,
        "Tao Mei"^^schema:Person,
        "Wei Zhang"^^schema:Person ;
    schema:dateModified "2019-04-18T13:12:53Z"^^schema:DateTime ;
    schema:datePublished "2019-04-06T07:19:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Person Image Generation with Semantic Parsing  Transformation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.03379v2"^^schema:URL .

<823> a schema:ScholarlyArticle ;
    schema:abstract "While \"attention is all you need\" may be proving true, we do not yet knowwhy: attention-based models such as BERT are superior but how theycontextualize information even for simple grammatical rules such assubject-verb number agreement (SVA) is uncertain. We introduce multi-partitepatterns, abstractions of sets of paths through a neural network model.Patterns quantify and localize the effect of an input concept (e.g., asubject's number) on an output concept (e.g. corresponding verb's number) topaths passing through a sequence of model components, thus surfacing how BERTcontextualizes information. We describe guided pattern refinement, an efficientsearch procedure for finding patterns representative of concept-critical paths.We discover that patterns generate succinct and meaningful explanations forBERT, highlighted by \"copy\" and \"transfer\" operations implemented by skipconnections and attention heads, respectively. We also show how patternvisualizations help us understand how BERT contextualizes various grammaticalconcepts, such as SVA across clauses, and why it makes errors in some caseswhile succeeding in others."^^schema:Text ;
    schema:author "Anupam Datta"^^schema:Person,
        "Kaiji Lu"^^schema:Person,
        "Piotr Mardziel"^^schema:Person,
        "Zifan Wang"^^schema:Person ;
    schema:dateModified "2020-11-02T04:28:16Z"^^schema:DateTime ;
    schema:datePublished "2020-11-02T04:28:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Abstracting Influence Paths for Explaining (Contextualization of) BERT  Models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00740v1"^^schema:URL .

<824> a schema:ScholarlyArticle ;
    schema:abstract "In population synthesis applications, when considering populations with manyattributes, a fundamental problem is the estimation of rare combinations offeature attributes. Unsurprisingly, it is notably more difficult to reliablyrepresentthe sparser regions of such multivariate distributions and inparticular combinations of attributes which are absent from the originalsample. In the literature this is commonly known as sampling zeros for which nosystematic solution has been proposed so far. In this paper, two machinelearning algorithms, from the family of deep generative models,are proposed forthe problem of population synthesis and with particular attention to theproblem of sampling zeros. Specifically, we introduce the WassersteinGenerative Adversarial Network (WGAN) and the Variational Autoencoder(VAE), andadapt these algorithms for a large-scale population synthesis application. Themodels are implemented on a Danish travel survey with a feature-space of morethan 60 variables. The models are validated in a cross-validation scheme and aset of new metrics for the evaluation of the sampling-zero problem is proposed.Results show how these models are able to recover sampling zeros while keepingthe estimation of truly impossible combinations, the structural zeros, at acomparatively low level. Particularly, for a low dimensional experiment, theVAE, the marginal sampler and the fully random sampler generate 5%, 21% and26%, respectively, more structural zeros per sampling zero generated by theWGAN, while for a high dimensional case, these figures escalate to 44%, 2217%and 170440%, respectively. This research directly supports the development ofagent-based systems and in particular cases where detailed socio-economic orgeographical representations are required."^^schema:Text ;
    schema:author "Francisco C. Pereira"^^schema:Person,
        "Jeppe Rich"^^schema:Person,
        "Sergio Garrido"^^schema:Person,
        "Stanislav S. Borysov"^^schema:Person ;
    schema:dateModified "2019-09-17T09:58:45Z"^^schema:DateTime ;
    schema:datePublished "2019-09-17T09:58:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.AP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Prediction of rare feature combinations in population synthesis:  Application of deep generative modelling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.07689v1"^^schema:URL .

<825> a schema:ScholarlyArticle ;
    schema:abstract "Despite foreseeing tremendous speedups over conventional deep neuralnetworks, the performance advantage of binarized neural networks (BNNs) hasmerely been showcased on general-purpose processors such as CPUs and GPUs. Infact, due to being unable to leverage bit-level-parallelism with a word-basedarchitecture, GPUs have been criticized for extremely low utilization (1%) whenexecuting BNNs. Consequently, the latest tensorcores in NVIDIA Turing GPUsstart to experimentally support bit computation. In this work, we look intothis brand new bit computation capability and characterize its unique features.We show that the stride of memory access can significantly affect performancedelivery and a data-format co-design is highly desired to support thetensorcores for achieving superior performance than existing software solutionswithout tensorcores. We realize the tensorcore-accelerated BNN design,particularly the major functions for fully-connect and convolution layers --bit matrix multiplication and bit convolution. Evaluations on two NVIDIA TuringGPUs show that, with ResNet-18, our BTC-BNN design can process ImageNet at arate of 5.6K images per second, 77% faster than state-of-the-art. Our BNNapproach is released on https://github.com/pnnl/TCBNN."^^schema:Text ;
    schema:author "Ang Li"^^schema:Person,
        "Simon Su"^^schema:Person ;
    schema:dateModified "2020-12-15T00:13:59Z"^^schema:DateTime ;
    schema:datePublished "2020-06-30T07:32:02Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Accelerating Binarized Neural Networks via Bit-Tensor-Cores in Turing  GPUs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16578v2"^^schema:URL .

<826> a schema:ScholarlyArticle ;
    schema:abstract "The goal of this paper is to deal with a data scarcity scenario where deeplearning techniques use to fail. We compare the use of two well establishedtechniques, Restricted Boltzmann Machines and Variational Auto-encoders, asgenerative models in order to increase the training set in a classificationframework. Essentially, we rely on Markov Chain Monte Carlo (MCMC) algorithmsfor generating new samples. We show that generalization can be improvedcomparing this methodology to other state-of-the-art techniques, e.g.semi-supervised learning with ladder networks. Furthermore, we show that RBM isbetter than VAE generating new samples for training a classifier with goodgeneralization capabilities."^^schema:Text ;
    schema:author "Daniel Ramos"^^schema:Person,
        "Juan Maroñas"^^schema:Person,
        "Roberto Paredes"^^schema:Person ;
    schema:dateModified "2019-03-21T14:38:45Z"^^schema:DateTime ;
    schema:datePublished "2019-03-21T14:38:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Generative Models For Deep Learning with Very Scarce Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.09030v1"^^schema:URL .

<827> a schema:ScholarlyArticle ;
    schema:abstract "The ability of a reinforcement learning (RL) agent to learn about many rewardfunctions at the same time has many potential benefits, such as thedecomposition of complex tasks into simpler ones, the exchange of informationbetween tasks, and the reuse of skills. We focus on one aspect in particular,namely the ability to generalise to unseen tasks. Parametric generalisationrelies on the interpolation power of a function approximator that is given thetask description as input; one of its most common form are universal valuefunction approximators (UVFAs). Another way to generalise to new tasks is toexploit structure in the RL problem itself. Generalised policy improvement(GPI) combines solutions of previous tasks into a policy for the unseen task;this relies on instantaneous policy evaluation of old policies under the newreward function, which is made possible through successor features (SFs). Ourproposed universal successor features approximators (USFAs) combine theadvantages of all of these, namely the scalability of UVFAs, the instantinference of SFs, and the strong generalisation of GPI. We discuss thechallenges involved in training a USFA, its generalisation properties anddemonstrate its practical benefits and transfer abilities on a large-scaledomain in which the agent has to navigate in a first-person perspectivethree-dimensional environment."^^schema:Text ;
    schema:author "André Barreto"^^schema:Person,
        "Daniel Mankowitz"^^schema:Person,
        "David Silver"^^schema:Person,
        "Diana Borsa"^^schema:Person,
        "Hado van Hasselt"^^schema:Person,
        "John Quan"^^schema:Person,
        "Rémi Munos"^^schema:Person,
        "Tom Schaul"^^schema:Person ;
    schema:dateModified "2018-12-18T20:01:41Z"^^schema:DateTime ;
    schema:datePublished "2018-12-18T20:01:41Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Universal Successor Features Approximators"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.07626v1"^^schema:URL .

<828> a schema:ScholarlyArticle ;
    schema:abstract "Neural networks (NNs) are known for their high predictive accuracy in complexlearning problems. Beside practical advantages, NNs also indicate favourabletheoretical properties such as universal approximation (UA) theorems. BinarizedNeural Networks (BNNs) significantly reduce time and memory demands byrestricting the weight and activation domains to two values. Despite thepractical advantages, theoretical guarantees based on UA theorems of BNNs arerather sparse in the literature. We close this gap by providing UA theorems forfully connected BNNs under the following scenarios: (1) for binarized inputs,UA can be constructively achieved under one hidden layer; (2) for inputs withreal numbers, UA can not be achieved under one hidden layer but can beconstructively achieved under two hidden layers for Lipschitz-continuousfunctions. Our results indicate that fully connected BNNs can approximatefunctions universally, under certain conditions."^^schema:Text ;
    schema:author "Burim Ramosaj"^^schema:Person,
        "Jian-Jia Chen"^^schema:Person,
        "Mario Günzel"^^schema:Person,
        "Mikail Yayla"^^schema:Person ;
    schema:dateModified "2021-02-04T14:30:24Z"^^schema:DateTime ;
    schema:datePublished "2021-02-04T14:30:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Universal Approximation Theorems of Fully Connected Binarized Neural  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02631v1"^^schema:URL .

<829> a schema:ScholarlyArticle ;
    schema:abstract "The study of quantum generative models is well-motivated, not only because ofits importance in quantum machine learning and quantum chemistry but alsobecause of the perspective of its implementation on near-term quantum machines.Inspired by previous studies on the adversarial training of classical andquantum generative models, we propose the first design of quantum WassersteinGenerative Adversarial Networks (WGANs), which has been shown to improve therobustness and the scalability of the adversarial training of quantumgenerative models even on noisy quantum hardware. Specifically, we propose adefinition of the Wasserstein semimetric between quantum data, which inherits afew key theoretical merits of its classical counterpart. We also demonstratehow to turn the quantum Wasserstein semimetric into a concrete design ofquantum WGANs that can be efficiently implemented on quantum machines. Ournumerical study, via classical simulation of quantum systems, shows the morerobust and scalable numerical performance of our quantum WGANs over otherquantum GAN proposals. As a surprising application, our quantum WGAN has beenused to generate a 3-qubit quantum circuit of ~50 gates that well approximatesa 3-qubit 1-d Hamiltonian simulation circuit that requires over 10k gates usingstandard techniques."^^schema:Text ;
    schema:author "Shouvanik Chakrabarti"^^schema:Person,
        "Soheil Feizi"^^schema:Person,
        "Tongyang Li"^^schema:Person,
        "Xiaodi Wu"^^schema:Person,
        "Yiming Huang"^^schema:Person ;
    schema:dateModified "2019-10-31T21:11:57Z"^^schema:DateTime ;
    schema:datePublished "2019-10-31T21:11:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "quant-ph"^^schema:Text ;
    schema:headline "Quantum Wasserstein Generative Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.00111v1"^^schema:URL .

<83> a schema:ScholarlyArticle ;
    schema:abstract "Multiple instance learning (MIL) can reduce the need for costly annotation intasks such as semantic segmentation by weakening the required degree ofsupervision. We propose a novel MIL formulation of multi-class semanticsegmentation learning by a fully convolutional network. In this setting, weseek to learn a semantic segmentation model from just weak image-level labels.The model is trained end-to-end to jointly optimize the representation whiledisambiguating the pixel-image label assignment. Fully convolutional trainingaccepts inputs of any size, does not need object proposal pre-processing, andoffers a pixelwise loss map for selecting latent instances. Our multi-class MILloss exploits the further supervision given by images with multiple labels. Weevaluate this approach through preliminary experiments on the PASCAL VOCsegmentation challenge."^^schema:Text ;
    schema:author "Deepak Pathak"^^schema:Person,
        "Evan Shelhamer"^^schema:Person,
        "Jonathan Long"^^schema:Person,
        "Trevor Darrell"^^schema:Person ;
    schema:commentCount "230"^^schema:Integer ;
    schema:dateModified "2015-04-15T05:31:10Z"^^schema:DateTime ;
    schema:datePublished "2014-12-22T20:49:54Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Fully Convolutional Multi-Class Multiple Instance Learning"^^schema:Text ;
    schema:publisher "ICLR (Workshop)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1412.7144v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6242051221514792488&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<830> a schema:ScholarlyArticle ;
    schema:abstract "Identifying accurate dynamic models is required for the simulation andcontrol of various technical systems. In many important real-worldapplications, however, the two main modeling approaches often fail to meetrequirements: first principles methods suffer from high bias, whereasdata-driven modeling tends to have high variance. Additionally, purelydata-based models often require large amounts of data and are often difficultto interpret. In this paper, we present physics-informed neural ordinarydifferential equations (PINODE), a hybrid model that combines the two modelingtechniques to overcome the aforementioned problems. This new approach directlyincorporates the equations of motion originating from the Lagrange Mechanicsinto a deep neural network structure. Thus, we can integrate prior physicsknowledge where it is available and use function approximation--e. g., neuralnetworks--where it is not. The method is tested with a forward model of areal-world physical system with large uncertainties. The resulting model isaccurate and data-efficient while ensuring physical plausibility. With this, wedemonstrate a method that beneficially merges physical insight with real data.Our findings are of interest for model-based control and system identificationof mechanical systems."^^schema:Text ;
    schema:author "Manuel A. Roehrl"^^schema:Person,
        "Michel Tokic"^^schema:Person,
        "Stefan Obermayer"^^schema:Person,
        "Thomas A. Runkler"^^schema:Person,
        "Veronika Brandtstetter"^^schema:Person ;
    schema:dateModified "2020-05-29T15:10:43Z"^^schema:DateTime ;
    schema:datePublished "2020-05-29T15:10:43Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Modeling System Dynamics with Physics-Informed Neural Networks Based on  Lagrangian Mechanics"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2005.14617v1"^^schema:URL .

<831> a schema:ScholarlyArticle ;
    schema:abstract "Recurrent neural networks have shown remarkable success in modelingsequences. However low resource situations still adversely affect thegeneralizability of these models. We introduce a new family of models, calledLattice Recurrent Units (LRU), to address the challenge of learning deepmulti-layer recurrent models with limited resources. LRU models achieve thisgoal by creating distinct (but coupled) flow of information inside the units: afirst flow along time dimension and a second flow along depth dimension. Italso offers a symmetry in how information can flow horizontally and vertically.We analyze the effects of decoupling three different components of our LRUmodel: Reset Gate, Update Gate and Projected State. We evaluate this family onnew LRU models on computational convergence rates and statistical efficiency.Our experiments are performed on four publicly-available datasets, comparingwith Grid-LSTM and Recurrent Highway networks. Our results show that LRU hasbetter empirical computational convergence rates and statistical efficiencyvalues, along with learning more accurate language models."^^schema:Text ;
    schema:author "Chaitanya Ahuja"^^schema:Person,
        "Louis-Philippe Morency"^^schema:Person ;
    schema:dateModified "2017-11-22T05:11:17Z"^^schema:DateTime ;
    schema:datePublished "2017-10-06T01:52:14Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency  for Sequence Modeling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1710.02254v2"^^schema:URL .

<832> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a saliency-based distortion layer for convolutional neuralnetworks that helps to improve the spatial sampling of input data for a giventask. Our differentiable layer can be added as a preprocessing block toexisting task networks and trained altogether in an end-to-end fashion. Theeffect of the layer is to efficiently estimate how to sample from the originaldata in order to boost task performance. For example, for an imageclassification task in which the original data might range in size up toseveral megapixels, but where the desired input images to the task network aremuch smaller, our layer learns how best to sample from the underlying highresolution data in a manner which preserves task-relevant information betterthan uniform downsampling. This has the effect of creating distorted,caricature-like intermediate images, in which idiosyncratic elements of theimage that improve task performance are zoomed and exaggerated. Unlikealternative approaches such as spatial transformer networks, our proposed layeris inspired by image saliency, computed efficiently from uniformly downsampleddata, and degrades gracefully to a uniform sampling strategy under uncertainty.We apply our layer to improve existing networks for the tasks of human gazeestimation and fine-grained object classification. Code for our method isavailable in: http://github.com/recasens/Saliency-Sampler"^^schema:Text ;
    schema:author "Adrià Recasens"^^schema:Person,
        "Antonio Torralba"^^schema:Person,
        "Petr Kellnhofer"^^schema:Person,
        "Simon Stent"^^schema:Person,
        "Wojciech Matusik"^^schema:Person ;
    schema:dateModified "2018-09-10T14:36:15Z"^^schema:DateTime ;
    schema:datePublished "2018-09-10T14:36:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning to Zoom: a Saliency-Based Sampling Layer for Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.03355v1"^^schema:URL .

<833> a schema:ScholarlyArticle ;
    schema:abstract "The manual design of analog circuits is a tedious task of parameter tuningthat requires hours of work by human experts. In this work, we make asignificant step towards a fully automatic design method that is based on deeplearning. The method selects the components and their configuration, as well astheir numerical parameters. By contrast, the current literature methods arelimited to the parameter fitting part only. A two-stage network is used, whichfirst generates a chain of circuit components and then predicts theirparameters. A hypernetwork scheme is used in which a weight generating network,which is conditioned on the circuit's power spectrum, produces the parametersof a primal RNN network that places the components. A differential simulator isused for refining the numerical values of the components. We show that ourmodel provides an efficient design solution, and is superior to alternativesolutions."^^schema:Text ;
    schema:author "Lior Wolf"^^schema:Person,
        "Michael Rotman"^^schema:Person ;
    schema:dateModified "2020-02-10T13:36:09Z"^^schema:DateTime ;
    schema:datePublished "2019-11-08T05:13:05Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Electric Analog Circuit Design with Hypernetworks and a Differential  Simulator"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.03053v2"^^schema:URL .

<834> a schema:ScholarlyArticle ;
    schema:abstract "The objective of this paper is to provide a temporal dynamic model forresting state functional Magnetic Resonance Imaging (fMRI) trajectory topredict future brain images based on the given sequence. To this end, we cameup with the model that takes advantage of representation learning and NeuralOrdinary Differential Equation (Neural ODE) to compress the fMRI image datainto latent representation and learn to predict the trajectory followingdifferential equation. Latent space was analyzed by Gaussian Mixture Model. Thelearned fMRI trajectory embedding can be used to explain the variance of thetrajectory and predict human traits for each subject. This method achievesaverage 0.5 spatial correlation for the whole predicted trajectory, and providetrained ODE parameter for further analysis."^^schema:Text ;
    schema:author "Zheyu Wen"^^schema:Person ;
    schema:dateModified "2020-11-16T18:16:19Z"^^schema:DateTime ;
    schema:datePublished "2020-11-16T18:16:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Temporal Dynamic Model for Resting State fMRI Data: A Neural Ordinary  Differential Equation approach"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.08146v1"^^schema:URL .

<835> a schema:ScholarlyArticle ;
    schema:abstract "Variational Inference is a powerful tool in the Bayesian modeling toolkit,however, its effectiveness is determined by the expressivity of the utilizedvariational distributions in terms of their ability to match the true posteriordistribution. In turn, the expressivity of the variational family is largelylimited by the requirement of having a tractable density function. To overcomethis roadblock, we introduce a new family of variational upper bounds on amarginal log density in the case of hierarchical models (also known as latentvariable models). We then give an upper bound on the Kullback-Leiblerdivergence and derive a family of increasingly tighter variational lower boundson the otherwise intractable standard evidence lower bound for hierarchicalvariational distributions, enabling the use of more expressive approximateposteriors. We show that previously known methods, such as HierarchicalVariational Models, Semi-Implicit Variational Inference and DoublySemi-Implicit Variational Inference can be seen as special cases of theproposed approach, and empirically demonstrate superior performance of theproposed method in a set of experiments."^^schema:Text ;
    schema:author "Artem Sobolev"^^schema:Person,
        "Dmitry Vetrov"^^schema:Person ;
    schema:dateModified "2019-05-08T18:38:51Z"^^schema:DateTime ;
    schema:datePublished "2019-05-08T18:38:51Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Importance Weighted Hierarchical Variational Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.03290v1"^^schema:URL .

<836> a schema:ScholarlyArticle ;
    schema:abstract "Recently, neural networks purely based on attention were shown to addressimage understanding tasks such as image classification. However, these visualtransformers are pre-trained with hundreds of millions of images using anexpensive infrastructure, thereby limiting their adoption.  In this work, we produce a competitive convolution-free transformer bytraining on Imagenet only. We train them on a single computer in less than 3days. Our reference vision transformer (86M parameters) achieves top-1 accuracyof 83.1% (single-crop evaluation) on ImageNet with no external data.  More importantly, we introduce a teacher-student strategy specific totransformers. It relies on a distillation token ensuring that the studentlearns from the teacher through attention. We show the interest of thistoken-based distillation, especially when using a convnet as a teacher. Thisleads us to report results competitive with convnets for both Imagenet (wherewe obtain up to 85.2% accuracy) and when transferring to other tasks. We shareour code and models."^^schema:Text ;
    schema:author "Alexandre Sablayrolles"^^schema:Person,
        "Francisco Massa"^^schema:Person,
        "Hervé Jégou"^^schema:Person,
        "Hugo Touvron"^^schema:Person,
        "Matthieu Cord"^^schema:Person,
        "Matthijs Douze"^^schema:Person ;
    schema:dateModified "2021-01-15T15:52:50Z"^^schema:DateTime ;
    schema:datePublished "2020-12-23T18:42:10Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Training data-efficient image transformers &amp; distillation through  attention"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.12877v2"^^schema:URL .

<837> a schema:ScholarlyArticle ;
    schema:abstract "Causal approaches to fairness have seen substantial recent interest, bothfrom the machine learning community and from wider parties interested inethical prediction algorithms. In no small part, this has been due to the factthat causal models allow one to simultaneously leverage data and expertknowledge to remove discriminatory effects from predictions. However, one ofthe primary assumptions in causal modeling is that you know the causal graph.This introduces a new opportunity for bias, caused by misspecifying the causalmodel. One common way for misspecification to occur is via unmeasuredconfounding: the true causal effect between variables is partially described byunobserved quantities. In this work we design tools to assess the sensitivityof fairness measures to this confounding for the popular class of non-linearadditive noise models (ANMs). Specifically, we give a procedure for computingthe maximum difference between two counterfactually fair predictors, where onehas become biased due to confounding. For the case of bivariate confounding ourtechnique can be swiftly computed via a sequence of closed-form updates. Formultivariate confounding we give an algorithm that can be efficiently solvedvia automatic differentiation. We demonstrate our new sensitivity analysistools in real-world fairness scenarios to assess the bias arising fromconfounding."^^schema:Text ;
    schema:author "Adrian Weller"^^schema:Person,
        "Matt J. Kusner"^^schema:Person,
        "Niki Kilbertus"^^schema:Person,
        "Philip J. Ball"^^schema:Person,
        "Ricardo Silva"^^schema:Person ;
    schema:dateModified "2019-07-01T19:47:40Z"^^schema:DateTime ;
    schema:datePublished "2019-07-01T19:47:40Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "The Sensitivity of Counterfactual Fairness to Unmeasured Confounding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.01040v1"^^schema:URL .

<838> a schema:ScholarlyArticle ;
    schema:abstract "Hand-object pose estimation (HOPE) aims to jointly detect the poses of both ahand and of a held object. In this paper, we propose a lightweight model calledHOPE-Net which jointly estimates hand and object pose in 2D and 3D inreal-time. Our network uses a cascade of two adaptive graph convolutionalneural networks, one to estimate 2D coordinates of the hand joints and objectcorners, followed by another to convert 2D coordinates to 3D. Our experimentsshow that through end-to-end training of the full network, we achieve betteraccuracy for both the 2D and 3D coordinate estimation problems. The proposed 2Dto 3D graph convolution-based model could be applied to other 3D landmarkdetection problems, where it is possible to first predict the 2D keypoints andthen transform them to 3D."^^schema:Text ;
    schema:author "Bardia Doosti"^^schema:Person,
        "David Crandall"^^schema:Person,
        "Majid Mirbagheri"^^schema:Person,
        "Shujon Naha"^^schema:Person ;
    schema:dateModified "2020-03-31T19:01:42Z"^^schema:DateTime ;
    schema:datePublished "2020-03-31T19:01:42Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "HOPE-Net: A Graph-based Model for Hand-Object Pose Estimation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.00060v1"^^schema:URL .

<839> a schema:ScholarlyArticle ;
    schema:abstract "Face parsing is an important computer vision task that requires accuratepixel segmentation of facial parts (such as eyes, nose, mouth, etc.), providinga basis for further face analysis, modification, and other applications.Interlinked Convolutional Neural Networks (iCNN) was proved to be an effectivetwo-stage model for face parsing. However, the original iCNN was trainedseparately in two stages, limiting its performance. To solve this problem, weintroduce a simple, end-to-end face parsing framework: STN-aidediCNN(STN-iCNN), which extends the iCNN by adding a Spatial Transformer Network(STN) between the two isolated stages. The STN-iCNN uses the STN to provide atrainable connection to the original two-stage iCNN pipeline, making end-to-endjoint training possible. Moreover, as a by-product, STN also provides moreprecise cropped parts than the original cropper. Due to these two advantages,our approach significantly improves the accuracy of the original model. Ourmodel achieved competitive performance on the Helen Dataset, the standard faceparsing dataset. It also achieved superior performance on CelebAMask-HQdataset, proving its good generalization. Our code has been released athttps://github.com/aod321/STN-iCNN."^^schema:Text ;
    schema:author "Liang Tang"^^schema:Person,
        "Valentin Yiu"^^schema:Person,
        "Xiaolin Hu"^^schema:Person,
        "Zi Yin"^^schema:Person ;
    schema:dateModified "2020-06-23T19:27:52Z"^^schema:DateTime ;
    schema:datePublished "2020-02-12T08:03:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "End-to-End Face Parsing via Interlinked Convolutional Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.04831v2"^^schema:URL .

<84> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing---where a machine models the knowledge of a student as theyinteract with coursework---is a well established problem in computer supportededucation. Though effectively modeling student knowledge would have higheducational impact, the task has many inherent challenges. In this paper weexplore the utility of using Recurrent Neural Networks (RNNs) to model studentlearning. The RNN family of models have important advantages over previousmethods in that they do not require the explicit encoding of human domainknowledge, and can capture more complex representations of student knowledge.Using neural networks results in substantial improvements in predictionperformance on a range of knowledge tracing datasets. Moreover the learnedmodel can be used for intelligent curriculum design and allows straightforwardinterpretation and discovery of structure in student tasks. These resultssuggest a promising new line of research for knowledge tracing and an exemplaryapplication task for RNNs."^^schema:Text ;
    schema:author "Chris Piech"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Jonathan Huang"^^schema:Person,
        "Jonathan Spencer"^^schema:Person,
        "Leonidas Guibas"^^schema:Person,
        "Mehran Sahami"^^schema:Person,
        "Surya Ganguli"^^schema:Person ;
    schema:commentCount "318"^^schema:Integer ;
    schema:dateModified "2015-06-19T08:29:00Z"^^schema:DateTime ;
    schema:datePublished "2015-06-19T08:29:00Z"^^schema:DateTime ;
    schema:genre "K.3.1"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Deep Knowledge Tracing"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1506.05908v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7245594791529377875&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<840> a schema:ScholarlyArticle ;
    schema:abstract "A relation tuple consists of two entities and the relation between them, andoften such tuples are found in unstructured text. There may be multiplerelation tuples present in a text and they may share one or both entities amongthem. Extracting such relation tuples from a sentence is a difficult task andsharing of entities or overlapping entities among the tuples makes it morechallenging. Most prior work adopted a pipeline approach where entities wereidentified first followed by finding the relations among them, thus missing theinteraction among the relation tuples in a sentence. In this paper, we proposetwo approaches to use encoder-decoder architecture for jointly extractingentities and relations. In the first approach, we propose a representationscheme for relation tuples which enables the decoder to generate one word at atime like machine translation models and still finds all the tuples present ina sentence with full entity names of different length and with overlappingentities. Next, we propose a pointer network-based decoding approach where anentire tuple is generated at every time step. Experiments on the publiclyavailable New York Times corpus show that our proposed approaches outperformprevious work and achieve significantly higher F1 scores."^^schema:Text ;
    schema:author "Hwee Tou Ng"^^schema:Person,
        "Tapas Nayak"^^schema:Person ;
    schema:dateModified "2019-11-22T06:52:21Z"^^schema:DateTime ;
    schema:datePublished "2019-11-22T06:52:21Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Effective Modeling of Encoder-Decoder Architecture for Joint Entity and  Relation Extraction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.09886v1"^^schema:URL .

<841> a schema:ScholarlyArticle ;
    schema:abstract "MLPerf, an emerging machine learning benchmark suite strives to cover a broadrange of applications of machine learning. We present a study on itscharacteristics and how the MLPerf benchmarks differ from some of the previousdeep learning benchmarks like DAWNBench and DeepBench. We find that applicationbenchmarks such as MLPerf (although rich in kernels) exhibit different featurescompared to kernel benchmarks such as DeepBench. MLPerf benchmark suitecontains a diverse set of models which allows unveiling various bottlenecks inthe system. Based on our findings, dedicated low latency interconnect betweenGPUs in multi-GPU systems is required for optimal distributed deep learningtraining. We also observe variation in scaling efficiency across the MLPerfmodels. The variation exhibited by the different models highlight theimportance of smart scheduling strategies for multi-GPU training. Anotherobservation is that CPU utilization increases with increase in number of GPUsused for training. Corroborating prior work we also observe and quantifyimprovements possible by compiler optimizations, mixed-precision training anduse of Tensor Cores."^^schema:Text ;
    schema:author "Bagus Hanindhito"^^schema:Person,
        "Eugene B. John"^^schema:Person,
        "Gunjan Jha"^^schema:Person,
        "Lizy K. John"^^schema:Person,
        "Qinzhe Wu"^^schema:Person,
        "Ramesh Radhakrishnan"^^schema:Person,
        "Snehil Verma"^^schema:Person ;
    schema:dateModified "2019-08-24T20:55:10Z"^^schema:DateTime ;
    schema:datePublished "2019-08-24T20:55:10Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Demystifying the MLPerf Benchmark Suite"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.09207v1"^^schema:URL .

<842> a schema:ScholarlyArticle ;
    schema:abstract "Over past years, the easy accessibility to the large scale datasets hassignificantly shifted the paradigm for developing highly accurate predictionmodels that are driven from Neural Network (NN). These models can bepotentially impacted by the radiation-induced transient faults that might leadto the gradual downgrade of the long-running expected NN inference accelerator.The crucial observation from our rigorous vulnerability assessment on the NNinference accelerator demonstrates that the weights and activation functionsare unevenly susceptible to both single-event upset (SEU) and multi-bit upset(MBU), especially in the first five layers of our selected convolution neuralnetwork. In this paper, we present the relatively-accurate statistical modelsto delineate the impact of both undertaken SEU and MBU across layers and pereach layer of the selected NN. These models can be used for evaluating theerror-resiliency magnitude of NN topology before adopting them in thesafety-critical applications."^^schema:Text ;
    schema:author "Arman Roohi"^^schema:Person,
        "Connor Broyles"^^schema:Person,
        "Navid Khoshavi"^^schema:Person,
        "Saman Sargolzaei"^^schema:Person,
        "Yu Bi"^^schema:Person ;
    schema:dateModified "2020-04-21T14:01:53Z"^^schema:DateTime ;
    schema:datePublished "2020-04-10T16:10:24Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Entropy-Based Modeling for Estimating Soft Errors Impact on Binarized  Neural Network Inference"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.05089v2"^^schema:URL .

<843> a schema:ScholarlyArticle ;
    schema:abstract "Accurately predicting the binding affinity between drugs and proteins is anessential step for computational drug discovery. Since graph neural networks(GNNs) have demonstrated remarkable success in various graph-related tasks,GNNs have been considered as a promising tool to improve the binding affinityprediction in recent years. However, most of the existing GNN architectures canonly encode the topological graph structure of drugs and proteins withoutconsidering the relative spatial information among their atoms. Whereas,different from other graph datasets such as social networks and commonsenseknowledge graphs, the relative spatial position and chemical bonds among atomshave significant impacts on the binding affinity. To this end, in this paper,we propose a diStance-aware Molecule graph Attention Network (S-MAN) tailoredto drug-target binding affinity prediction. As a dedicated solution, we firstpropose a position encoding mechanism to integrate the topological structureand spatial position information into the constructed pocket-ligand graph.Moreover, we propose a novel edge-node hierarchical attentive aggregationstructure which has edge-level aggregation and node-level aggregation. Thehierarchical attentive aggregation can capture spatial dependencies amongatoms, as well as fuse the position-enhanced information with the capability ofdiscriminating multiple spatial relations among atoms. Finally, we conductextensive experiments on two standard datasets to demonstrate the effectivenessof S-MAN."^^schema:Text ;
    schema:author "Dejing Dou"^^schema:Person,
        "Fan Wang"^^schema:Person,
        "Haoyi Xiong"^^schema:Person,
        "Hui Xiong"^^schema:Person,
        "Jingbo Zhou"^^schema:Person,
        "Liang Huang"^^schema:Person,
        "Shuangli Li"^^schema:Person,
        "Tong Xu"^^schema:Person ;
    schema:dateModified "2020-12-17T17:44:01Z"^^schema:DateTime ;
    schema:datePublished "2020-12-17T17:44:01Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.QM"^^schema:Text ;
    schema:headline "Distance-aware Molecule Graph Attention Network for Drug-Target Binding  Affinity Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.09624v1"^^schema:URL .

<844> a schema:ScholarlyArticle ;
    schema:abstract "Generative adversarial networks (GANs) have emerged as a powerfulunsupervised method to model the statistical patterns of real-world data sets,such as natural images. These networks are trained to map random inputs intheir latent space to new samples representative of the learned data. However,the structure of the latent space is hard to intuit due to its highdimensionality and the non-linearity of the generator, which limits theusefulness of the models. Understanding the latent space requires a way toidentify input codes for existing real-world images (inversion), and a way toidentify directions with known image transformations (interpretability). Here,we use a geometric framework to address both issues simultaneously. We developan architecture-agnostic method to compute the Riemannian metric of the imagemanifold created by GANs. The eigen-decomposition of the metric isolates axesthat account for different levels of image variability. An empirical analysisof several pretrained GANs shows that image variation around each position isconcentrated along surprisingly few major axes (the space is highlyanisotropic) and the directions that create this large variation are similar atdifferent positions in the space (the space is homogeneous). We show that manyof the top eigenvectors correspond to interpretable transforms in the imagespace, with a substantial part of eigenspace corresponding to minor transformswhich could be compressed out. This geometric understanding unifies keyprevious results related to GAN interpretability. We show that the use of thismetric allows for more efficient optimization in the latent space (e.g. GANinversion) and facilitates unsupervised discovery of interpretable axes. Ourresults illustrate that defining the geometry of the GAN image manifold canserve as a general framework for understanding GANs."^^schema:Text ;
    schema:author "Binxu Wang"^^schema:Person,
        "Carlos R. Ponce"^^schema:Person ;
    schema:dateModified "2021-01-15T07:57:33Z"^^schema:DateTime ;
    schema:datePublished "2021-01-15T07:57:33Z"^^schema:DateTime ;
    schema:genre "I.2.10; I.3.3; I.3.5; G.1.4"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NA"^^schema:Text,
        "cs.NE"^^schema:Text,
        "math.NA"^^schema:Text ;
    schema:headline "The Geometry of Deep Generative Image Models and its Applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.06006v1"^^schema:URL .

<845> a schema:ScholarlyArticle ;
    schema:abstract "Stable feature extraction is the key for the Loop closure detection (LCD)task in the simultaneously localization and mapping (SLAM) framework. In ourpaper, the feature extraction is operated by using a generative adversarialnetworks (GANs) based unsupervised learning. GANs are powerful generativemodels, however, GANs based adversarial learning suffers from traininginstability. We find that the data-code joint distribution in the adversariallearning is a more complex manifold than in the original GANs. And the lossfunction that drive the attractive force between synthesis and targetdistributions is unable for efficient latent code learning for LCD task. Torelieve this problem, we combines the original adversarial learning with aninner cycle restriction module and a side updating module. To our bestknowledge, we are the first to extract the adversarial features from the lightdetection and ranging (LiDAR) based inputs, which is invariant to the changescaused by illumination and appearance as in the visual inputs. We use the KITTIodometry datasets to investigate the performance of our method. The extensiveexperiments results shows that, with the same LiDAR projection maps, theproposed features are more stable in training, and could significantly improvethe robustness on viewpoints differences than other state-of-art methods."^^schema:Text ;
    schema:author "Haibo Luo"^^schema:Person,
        "Jianda Han"^^schema:Person,
        "Lingyun Xu"^^schema:Person,
        "Peng Yin"^^schema:Person,
        "Yunhui Liu"^^schema:Person ;
    schema:dateModified "2017-11-21T07:33:30Z"^^schema:DateTime ;
    schema:datePublished "2017-11-21T07:33:30Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Towards Stable Adversarial Feature Learning for LiDAR based Loop Closure  Detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.07659v1"^^schema:URL .

<846> a schema:ScholarlyArticle ;
    schema:abstract "We introduce Larq Compute Engine, the world's fastest Binarized NeuralNetwork (BNN) inference engine, and use this framework to investigate severalimportant questions about the efficiency of BNNs and to design a newstate-of-the-art BNN architecture. LCE provides highly optimizedimplementations of binary operations and accelerates binary convolutions by 8.5- 18.5x compared to their full-precision counterparts on Pixel 1 phones. LCE'sintegration with Larq and a sophisticated MLIR-based converter allow users tomove smoothly from training to deployment. By extending TensorFlow andTensorFlow Lite, LCE supports models which combine binary and full-precisionlayers, and can be easily integrated into existing applications. Using LCE, weanalyze the performance of existing BNN computer vision architectures anddevelop QuickNet, a simple, easy-to-reproduce BNN that outperforms existingbinary networks in terms of latency and accuracy on ImageNet. Furthermore, weinvestigate the impact of full-precision shortcuts and the relationship betweennumber of MACs and model latency. We are convinced that empirical performanceshould drive BNN architecture design and hope this work will facilitate othersto design, benchmark and deploy binary models."^^schema:Text ;
    schema:author "Adam Hillier"^^schema:Person,
        "Jelmer Neeven"^^schema:Person,
        "Koen Helwegen"^^schema:Person,
        "Leon Overweel"^^schema:Person,
        "Lukas Geiger"^^schema:Person,
        "Tim de Bruin"^^schema:Person,
        "Tom Bannink"^^schema:Person ;
    schema:dateModified "2020-11-18T16:56:14Z"^^schema:DateTime ;
    schema:datePublished "2020-11-18T16:56:14Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Larq Compute Engine: Design, Benchmark, and Deploy State-of-the-Art  Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.09398v1"^^schema:URL .

<847> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (DRL) is a promising approach for developinglegged locomotion skills. However, the iterative design process that isinevitable in practice is poorly supported by the default methodology. It isdifficult to predict the outcomes of changes made to the reward functions,policy architectures, and the set of tasks being trained on. In this paper, wepropose a practical method that allows the reward function to be fullyredefined on each successive design iteration while limiting the deviation fromthe previous iteration. We characterize policies via sets of DeterministicAction Stochastic State (DASS) tuples, which represent the deterministic policystate-action pairs as sampled from the states visited by the trained stochasticpolicy. New policies are trained using a policy gradient algorithm which thenmixes RL-based policy gradients with gradient updates defined by the DASStuples. The tuples also allow for robust policy distillation to new networkarchitectures. We demonstrate the effectiveness of this iterative-designapproach on the bipedal robot Cassie, achieving stable walking with differentgait styles at various speeds. We demonstrate the successful transfer ofpolicies learned in simulation to the physical robot without any dynamicsrandomization, and that variable-speed walking policies for the physical robotcan be represented by a small dataset of 5-10k tuples."^^schema:Text ;
    schema:author "Jeremy Dao"^^schema:Person,
        "Jonathan Hurst"^^schema:Person,
        "Michiel van de Panne"^^schema:Person,
        "Patrick Clary"^^schema:Person,
        "Pedro Morais"^^schema:Person,
        "Zhaoming Xie"^^schema:Person ;
    schema:dateModified "2019-03-22T14:48:40Z"^^schema:DateTime ;
    schema:datePublished "2019-03-22T14:48:40Z"^^schema:DateTime ;
    schema:genre "cs.RO"^^schema:Text ;
    schema:headline "Iterative Reinforcement Learning Based Design of Dynamic Locomotion  Skills for Cassie"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.09537v1"^^schema:URL .

<848> a schema:ScholarlyArticle ;
    schema:abstract "Stochastic control-flow models (SCFMs) are a class of generative models thatinvolve branching on choices from discrete random variables. Amortizedgradient-based learning of SCFMs is challenging as most approaches targetingdiscrete variables rely on their continuous relaxations---which can beintractable in SCFMs, as branching on relaxations requires evaluating all(exponentially many) branching paths. Tractable alternatives mainly combineREINFORCE with complex control-variate schemes to improve the variance of naiveestimators. Here, we revisit the reweighted wake-sleep (RWS) (Bornschein andBengio, 2015) algorithm, and through extensive evaluations, show that itoutperforms current state-of-the-art methods in learning SCFMs. Further, incontrast to the importance weighted autoencoder, we observe that RWS learnsbetter models and inference networks with increasing numbers of particles. Ourresults suggest that RWS is a competitive, often preferable, alternative forlearning SCFMs."^^schema:Text ;
    schema:author "Adam R. Kosiorek"^^schema:Person,
        "Frank Wood"^^schema:Person,
        "N. Siddharth"^^schema:Person,
        "Tuan Anh Le"^^schema:Person,
        "Yee Whye Teh"^^schema:Person ;
    schema:dateModified "2019-09-16T13:04:45Z"^^schema:DateTime ;
    schema:datePublished "2018-05-26T12:16:46Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Revisiting Reweighted Wake-Sleep for Models with Stochastic Control Flow"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.10469v2"^^schema:URL .

<849> a schema:ScholarlyArticle ;
    schema:abstract "The distributional perspective on reinforcement learning (RL) has given riseto a series of successful Q-learning algorithms, resulting in state-of-the-artperformance in arcade game environments. However, it has not yet been analyzedhow these findings from a discrete setting translate to complex practicalapplications characterized by noisy, high dimensional and continuousstate-action spaces. In this work, we propose Quantile QT-Opt (Q2-Opt), adistributional variant of the recently introduced distributed Q-learningalgorithm for continuous domains, and examine its behaviour in a series ofsimulated and real vision-based robotic grasping tasks. The absence of an actorin Q2-Opt allows us to directly draw a parallel to the previous discreteexperiments in the literature without the additional complexities induced by anactor-critic architecture. We demonstrate that Q2-Opt achieves a superiorvision-based object grasping success rate, while also being more sampleefficient. The distributional formulation also allows us to experiment withvarious risk distortion metrics that give us an indication of how robots canconcretely manage risk in practice using a Deep RL control policy. As anadditional contribution, we perform batch RL experiments in our virtualenvironment and compare them with the latest findings from discrete settings.Surprisingly, we find that the previous batch RL findings from the literatureobtained on arcade game environments do not generalise to our setup."^^schema:Text ;
    schema:author "Adrian Li"^^schema:Person,
        "Cristian Bodnar"^^schema:Person,
        "Karol Hausman"^^schema:Person,
        "Mrinal Kalakrishnan"^^schema:Person,
        "Peter Pastor"^^schema:Person ;
    schema:dateModified "2020-06-04T12:56:16Z"^^schema:DateTime ;
    schema:datePublished "2019-10-01T22:12:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Quantile QT-Opt for Risk-Aware Vision-Based Robotic Grasping"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.02787v3"^^schema:URL .

<85> a schema:ScholarlyArticle ;
    schema:abstract "We present a scalable approach for semi-supervised learning ongraph-structured data that is based on an efficient variant of convolutionalneural networks which operate directly on graphs. We motivate the choice of ourconvolutional architecture via a localized first-order approximation ofspectral graph convolutions. Our model scales linearly in the number of graphedges and learns hidden layer representations that encode both local graphstructure and features of nodes. In a number of experiments on citationnetworks and on a knowledge graph dataset we demonstrate that our approachoutperforms related methods by a significant margin."^^schema:Text ;
    schema:author "Max Welling"^^schema:Person,
        "Thomas N. Kipf"^^schema:Person ;
    schema:commentCount "4036"^^schema:Integer ;
    schema:dateModified "2017-02-22T09:55:36Z"^^schema:DateTime ;
    schema:datePublished "2016-09-09T19:48:41Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Semi-Supervised Classification with Graph Convolutional Networks"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1609.02907v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=9692529718922546949&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<850> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning and data mining techniques have been used extensively inorder to detect credit card frauds. However, most studies consider credit cardtransactions as isolated events and not as a sequence of transactions. In thisframework, we model a sequence of credit card transactions from three differentperspectives, namely (i) The sequence contains or doesn't contain a fraud (ii)The sequence is obtained by fixing the card-holder or the payment terminal(iii) It is a sequence of spent amount or of elapsed time between the currentand previous transactions. Combinations of the three binary perspectives giveeight sets of sequences from the (training) set of transactions. Each one ofthese sequences is modelled with a Hidden Markov Model (HMM). Each HMMassociates a likelihood to a transaction given its sequence of previoustransactions. These likelihoods are used as additional features in a RandomForest classifier for fraud detection. Our multiple perspectives HMM-basedapproach offers automated feature engineering to model temporal correlations soas to improve the effectiveness of the classification task and allows for anincrease in the detection of fraudulent transactions when combined with thestate of the art expert based feature engineering strategy for credit cardfraud detection. In extension to previous works, we show that this approachgoes beyond ecommerce transactions and provides a robust feature engineeringover different datasets, hyperparameters and classifiers. Moreover, we comparestrategies to deal with structural missing values."^^schema:Text ;
    schema:author "Liyun He-Guelton"^^schema:Person,
        "Léa Laporte"^^schema:Person,
        "Michael Granitzer"^^schema:Person,
        "Olivier Caelen"^^schema:Person,
        "Pierre-Edouard Portier"^^schema:Person,
        "Sylvie Calabretto"^^schema:Person,
        "Yvan Lucas"^^schema:Person ;
    schema:dateModified "2019-09-03T13:53:35Z"^^schema:DateTime ;
    schema:datePublished "2019-09-03T13:53:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards automated feature engineering for credit card fraud detection  using multi-perspective HMMs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.01185v1"^^schema:URL .

<851> a schema:ScholarlyArticle ;
    schema:abstract "Learning-based methods are promising to plan robot motion without performingextensive search, which is needed by many non-learning approaches. Recently,Value Iteration Networks (VINs) received much interest since---in contrast tostandard CNN-based architectures---they learn goal-directed behaviors whichgeneralize well to unseen domains. However, VINs are restricted to small andlow-dimensional domains, limiting their applicability to real-world planningproblems.  To address this issue, we propose to extend VINs to representations withmultiple levels of abstraction. While the vicinity of the robot is representedin sufficient detail, the representation gets spatially coarser with increasingdistance from the robot. The information loss caused by the decreasingresolution is compensated by increasing the number of features representing acell. We show that our approach is capable of solving significantly larger 2Dgrid world planning tasks than the original VIN implementation. In contrast toa multiresolution coarse-to-fine VIN implementation which does not employadditional descriptive features, our approach is capable of solving challengingenvironments, which demonstrates that the proposed method learns to encodeuseful information in the additional features. As an application for solvingreal-world planning tasks, we successfully employ our method to planomnidirectional driving for a search-and-rescue robot in cluttered terrain."^^schema:Text ;
    schema:author "Daniel Schleich"^^schema:Person,
        "Sven Behnke"^^schema:Person,
        "Tobias Klamt"^^schema:Person ;
    schema:dateModified "2019-07-01T09:11:43Z"^^schema:DateTime ;
    schema:datePublished "2019-05-27T09:17:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Value Iteration Networks on Multiple Levels of Abstraction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11068v2"^^schema:URL .

<852> a schema:ScholarlyArticle ;
    schema:abstract "Stars and cycles are basic structures in network construction. The former hasbeen well studied in network analysis, while the latter attracted rareattention. A node together with its neighbors constitute a neighborhoodstar-structure where the basic assumption is two nodes interact through theirdirect connection. A cycle is a closed loop with many nodes who can influenceeach other even without direct connection. Here we show their difference andrelationship in understanding network structure and function. We define twocycle-based node characteristics, namely cycle number and cycle ratio, whichcan be used to measure a node's importance. Numerical analyses on six disparatereal networks suggest that the nodes with higher cycle ratio are more importantto network connectivity, while cycle number can better quantify a nodeinfluence of cycle-based spreading than the common star-based nodecentralities. We also find that an ordinary network can be converted into ahypernetwork by considering its basic cycles as hyperedges, meanwhile, a newmatrix called the cycle number matrix is captured. We hope that this paper canopen a new direction of understanding both local and global structures ofnetwork and its function."^^schema:Text ;
    schema:author "Dinghua Shi"^^schema:Person,
        "Linyuan Lü"^^schema:Person,
        "Tianlong Fan"^^schema:Person ;
    schema:dateModified "2019-03-12T02:05:23Z"^^schema:DateTime ;
    schema:datePublished "2019-03-04T17:47:24Z"^^schema:DateTime ;
    schema:genre "physics.data-an"^^schema:Text,
        "physics.soc-ph"^^schema:Text ;
    schema:headline "Towards the cycle structures in complex network: A new perspective"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.01397v3"^^schema:URL .

<853> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning and data mining techniques have been used extensively inorder to detect credit card frauds. However, most studies consider credit cardtransactions as isolated events and not as a sequence of transactions.  In this article, we model a sequence of credit card transactions from threedifferent perspectives, namely (i) does the sequence contain a Fraud? (ii) Isthe sequence obtained by fixing the card-holder or the payment terminal? (iii)Is it a sequence of spent amount or of elapsed time between the current andprevious transactions? Combinations of the three binary perspectives give eightsets of sequences from the (training) set of transactions. Each one of thesesets is modelled with a Hidden Markov Model (HMM). Each HMM associates alikelihood to a transaction given its sequence of previous transactions. Theselikelihoods are used as additional features in a Random Forest classifier forfraud detection. This multiple perspectives HMM-based approach enables anautomatic feature engineering in order to model the sequential properties ofthe dataset with respect to the classification task. This strategy allows for a15% increase in the precision-recall AUC compared to the state of the artfeature engineering strategy for credit card fraud detection."^^schema:Text ;
    schema:author "Liyun He-Guelton"^^schema:Person,
        "Léa Laporte"^^schema:Person,
        "Michael Granitzer"^^schema:Person,
        "Olivier Caelen"^^schema:Person,
        "Pierre-Edouard Portier"^^schema:Person,
        "Sylvie Calabretto"^^schema:Person,
        "Yvan Lucas"^^schema:Person ;
    schema:dateModified "2019-05-15T15:29:49Z"^^schema:DateTime ;
    schema:datePublished "2019-05-15T15:29:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multiple perspectives HMM-based feature engineering for credit card  fraud detection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.06247v1"^^schema:URL .

<854> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we propose a novel goal-oriented dialog task, automatic symptomdetection. We build a system that can interact with patients through dialog todetect and collect clinical symptoms automatically, which can save a doctor'stime interviewing the patient. Given a set of explicit symptoms provided by thepatient to initiate a dialog for diagnosing, the system is trained to collectimplicit symptoms by asking questions, in order to collect more information formaking an accurate diagnosis. After getting the reply from the patient for eachquestion, the system also decides whether current information is enough for ahuman doctor to make a diagnosis. To achieve this goal, we propose two neuralmodels and a training pipeline for the multi-step reasoning task. We also builda knowledge graph as additional inputs to further improve model performance.Experiments show that our model significantly outperforms the baseline by 4%,discovering 67% of implicit symptoms on average with a limited number ofquestions."^^schema:Text ;
    schema:author "Hongyin Luo"^^schema:Person,
        "James Glass"^^schema:Person,
        "Shang-Wen Li"^^schema:Person ;
    schema:dateModified "2021-01-24T18:50:16Z"^^schema:DateTime ;
    schema:datePublished "2021-01-24T18:50:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Knowledge Grounded Conversational Symptom Detection with Graph Memory  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.09773v1"^^schema:URL .

<855> a schema:ScholarlyArticle ;
    schema:abstract "The transfer of knowledge from one policy to another is an important tool inDeep Reinforcement Learning. This process, referred to as distillation, hasbeen used to great success, for example, by enhancing the optimisation ofagents, leading to stronger performance faster, on harder domains [26, 32, 5,8]. Despite the widespread use and conceptual simplicity of distillation, manydifferent formulations are used in practice, and the subtle variations betweenthem can often drastically change the performance and the resulting objectivethat is being optimised. In this work, we rigorously explore the entirelandscape of policy distillation, comparing the motivations and strengths ofeach variant through theoretical and empirical analysis. Our results point tothree distillation techniques, that are preferred depending on specifics of thetask. Specifically a newly proposed expected entropy regularised distillationallows for quicker learning in a wide range of situations, while stillguaranteeing convergence."^^schema:Text ;
    schema:author "Grzegorz Swirszcz"^^schema:Person,
        "Max Jaderberg"^^schema:Person,
        "Razvan Pascanu"^^schema:Person,
        "Siddhant M. Jayakumar"^^schema:Person,
        "Simon Osindero"^^schema:Person,
        "Wojciech Marian Czarnecki"^^schema:Person ;
    schema:dateModified "2019-02-06T14:01:34Z"^^schema:DateTime ;
    schema:datePublished "2019-02-06T14:01:34Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Distilling Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.02186v1"^^schema:URL .

<856> a schema:ScholarlyArticle ;
    schema:abstract "Graph Neural Networks (GNNs) have been popularly used for analyzingnon-Euclidean data such as social network data and biological data. Despitetheir success, the design of graph neural networks requires a lot of manualwork and domain knowledge. In this paper, we propose a Graph NeuralArchitecture Search method (GraphNAS for short) that enables automatic searchof the best graph neural architecture based on reinforcement learning.Specifically, GraphNAS first uses a recurrent network to generatevariable-length strings that describe the architectures of graph neuralnetworks, and then trains the recurrent network with reinforcement learning tomaximize the expected accuracy of the generated architectures on a validationdata set. Extensive experimental results on node classification tasks in bothtransductive and inductive learning settings demonstrate that GraphNAS canachieve consistently better performance on the Cora, Citeseer, Pubmed citationnetwork, and protein-protein interaction network. On node classification tasks,GraphNAS can design a novel network architecture that rivals the besthuman-invented architecture in terms of test set accuracy."^^schema:Text ;
    schema:author "Chuan Zhou"^^schema:Person,
        "Hong Yang"^^schema:Person,
        "Peng Zhang"^^schema:Person,
        "Yang Gao"^^schema:Person,
        "Yue Hu"^^schema:Person ;
    schema:dateModified "2019-08-20T03:00:40Z"^^schema:DateTime ;
    schema:datePublished "2019-04-22T07:13:10Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "GraphNAS: Graph Neural Architecture Search with Reinforcement Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.09981v2"^^schema:URL .

<857> a schema:ScholarlyArticle ;
    schema:abstract "Reduced order models play an important role in the design, optimization andcontrol of dynamical systems. In recent years, there has been an increasinginterest in the application of data-driven techniques for model reduction thatcan decrease the computational burden of numerical solutions, while preservingthe most important features of complex physical problems. In this paper, we usethe proper orthogonal decomposition to reduce the dimensionality of the modeland introduce a novel generative neural ODE (NODE) architecture to forecast thebehavior of the temporal coefficients. With this methodology, we replace theclassical Galerkin projection with an architecture characterized by the use ofa continuous latent space. We exemplify the methodology on the dynamics of theVon Karman vortex street of the flow past a cylinder generated by a Large-eddySimulation (LES)-based code. We compare the NODE methodology with an LSTMbaseline to assess the extrapolation capabilities of the generative model andpresent some qualitative evaluations of the flow reconstructions."^^schema:Text ;
    schema:author "Andreas Dengel"^^schema:Person,
        "Carlos J. G. Rojas"^^schema:Person,
        "Mateus Dias Ribeiro"^^schema:Person ;
    schema:dateModified "2021-02-03T19:33:51Z"^^schema:DateTime ;
    schema:datePublished "2021-02-03T19:33:51Z"^^schema:DateTime ;
    schema:genre "physics.comp-ph"^^schema:Text,
        "physics.flu-dyn"^^schema:Text ;
    schema:headline "Reduced-order Model for Fluid Flows via Neural Ordinary Differential  Equations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.02248v1"^^schema:URL .

<858> a schema:ScholarlyArticle ;
    schema:abstract "Binarized Neural Networks (BNNs) can significantly reduce the inferencelatency and energy consumption in resource-constrained devices due to theirpure-logical computation and fewer memory accesses. However, training BNNs isdifficult since the activation flow encounters degeneration, saturation, andgradient mismatch problems. Prior work alleviates these issues by increasingactivation bits and adding floating-point scaling factors, thereby sacrificingBNN's energy efficiency. In this paper, we propose to use distribution loss toexplicitly regularize the activation flow, and develop a framework tosystematically formulate the loss. Our experiments show that the distributionloss can consistently improve the accuracy of BNNs without losing their energybenefits. Moreover, equipped with the proposed regularization, BNN training isshown to be robust to the selection of hyper-parameters including optimizer andlearning rate."^^schema:Text ;
    schema:author "Diana Marculescu"^^schema:Person,
        "Ruizhou Ding"^^schema:Person,
        "Ting-Wu Chin"^^schema:Person,
        "Zeye Liu"^^schema:Person ;
    schema:dateModified "2019-04-04T23:20:09Z"^^schema:DateTime ;
    schema:datePublished "2019-04-04T23:20:09Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Regularizing Activation Distribution for Training Binarized Deep  Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.02823v1"^^schema:URL .

<859> a schema:ScholarlyArticle ;
    schema:abstract "Many applications, such as autonomous driving, heavily rely on multi-modaldata where spatial alignment between the modalities is required. Mostmulti-modal registration methods struggle computing the spatial correspondencebetween the images using prevalent cross-modality similarity measures. In thiswork, we bypass the difficulties of developing cross-modality similaritymeasures, by training an image-to-image translation network on the two inputmodalities. This learned translation allows training the registration networkusing simple and reliable mono-modality metrics. We perform multi-modalregistration using two networks - a spatial transformation network and atranslation network. We show that by encouraging our translation network to begeometry preserving, we manage to train an accurate spatial transformationnetwork. Compared to state-of-the-art multi-modal methods our presented methodis unsupervised, requiring no pairs of aligned modalities for training, and canbe adapted to any pair of modalities. We evaluate our method quantitatively andqualitatively on commercial datasets, showing that it performs well on severalmodalities and achieves accurate alignment."^^schema:Text ;
    schema:author "Amit Bermano"^^schema:Person,
        "Daniel Cohen-Or"^^schema:Person,
        "Dov Danon"^^schema:Person,
        "Ilya Leizerson"^^schema:Person,
        "Moab Arar"^^schema:Person,
        "Yiftach Ginger"^^schema:Person ;
    schema:dateModified "2020-03-18T07:21:09Z"^^schema:DateTime ;
    schema:datePublished "2020-03-18T07:21:09Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Unsupervised Multi-Modal Image Registration via Geometry Preserving  Image-to-Image Translation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08073v1"^^schema:URL .

<86> a schema:ScholarlyArticle ;
    schema:abstract "We describe an iterative procedure for optimizing policies, with guaranteedmonotonic improvement. By making several approximations to thetheoretically-justified procedure, we develop a practical algorithm, calledTrust Region Policy Optimization (TRPO). This algorithm is similar to naturalpolicy gradient methods and is effective for optimizing large nonlinearpolicies such as neural networks. Our experiments demonstrate its robustperformance on a wide variety of tasks: learning simulated robotic swimming,hopping, and walking gaits; and playing Atari games using images of the screenas input. Despite its approximations that deviate from the theory, TRPO tendsto give monotonic improvement, with little tuning of hyperparameters."^^schema:Text ;
    schema:author "John Schulman"^^schema:Person,
        "Michael I. Jordan"^^schema:Person,
        "Philipp Moritz"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Sergey Levine"^^schema:Person ;
    schema:commentCount "2405"^^schema:Integer ;
    schema:dateModified "2017-04-20T18:04:12Z"^^schema:DateTime ;
    schema:datePublished "2015-02-19T06:44:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Trust Region Policy Optimization"^^schema:Text ;
    schema:publisher "ICML, 1889-1897"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1502.05477v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4215501129336400677&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<860> a schema:ScholarlyArticle ;
    schema:abstract "Reduced precision computation for deep neural networks is one of the keyareas addressing the widening compute gap driven by an exponential growth inmodel size. In recent years, deep learning training has largely migrated to16-bit precision, with significant gains in performance and energy efficiency.However, attempts to train DNNs at 8-bit precision have met with significantchallenges because of the higher precision and dynamic range requirements ofback-propagation. In this paper, we propose a method to train deep neuralnetworks using 8-bit floating point representation for weights, activations,errors, and gradients. In addition to reducing compute precision, we alsoreduced the precision requirements for the master copy of weights from 32-bitto 16-bit. We demonstrate state-of-the-art accuracy across multiple data sets(imagenet-1K, WMT16) and a broader set of workloads (Resnet-18/34/50, GNMT,Transformer) than previously reported. We propose an enhanced loss scalingmethod to augment the reduced subnormal range of 8-bit floating point forimproved error propagation. We also examine the impact of quantization noise ongeneralization and propose a stochastic rounding technique to address gradientnoise. As a result of applying all these techniques, we report slightly highervalidation accuracy compared to full precision baseline."^^schema:Text ;
    schema:author "Bharat Kaul"^^schema:Person,
        "Dipankar Das"^^schema:Person,
        "Naveen Mellempudi"^^schema:Person,
        "Sudarshan Srinivasan"^^schema:Person ;
    schema:dateModified "2019-05-29T11:25:09Z"^^schema:DateTime ;
    schema:datePublished "2019-05-29T11:25:09Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Mixed Precision Training With 8-bit Floating Point"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.12334v1"^^schema:URL .

<861> a schema:ScholarlyArticle ;
    schema:abstract "Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification isa critical and highly competitive area of research in bioinformatics because ofits potential for expediting drug develop-ment and research. Predicting anunknown compound's therapeutic and chemical characteristics ac-cording to howthese characteristics affect multiple organs/systems makes automatic ATCclassifica-tion a challenging multi-label problem. Results: In this work, wepropose combining multiple multi-label classifiers trained on distinct sets offeatures, including sets extracted from a Bidirectional Long Short-Term MemoryNetwork (BiLSTM). Experiments demonstrate the power of this approach, which isshown to outperform the best methods reported in the literature, including thestate-of-the-art developed by the fast.ai research group. Availability: Allsource code developed for this study is available athttps://github.com/LorisNanni. Contact: loris.nanni@unipd.it"^^schema:Text ;
    schema:author "Alessandra Lumini"^^schema:Person,
        "Loris Nanni"^^schema:Person,
        "Sheryl Brahnam"^^schema:Person ;
    schema:dateModified "2021-01-22T19:49:47Z"^^schema:DateTime ;
    schema:datePublished "2021-01-22T19:49:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "q-bio.QM"^^schema:Text ;
    schema:headline "Neural networks for Anatomical Therapeutic Chemical (ATC)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.11713v1"^^schema:URL .

<862> a schema:ScholarlyArticle ;
    schema:abstract "Atomistic modeling of energetic disorder in organic semiconductors (OSCs) andits effects on the optoelectronic properties of OSCs requires a large number ofexcited-state electronic-structure calculations, a computationally dauntingtask for many OSC applications. In this work, we advocate the use of deeplearning to address this challenge and demonstrate that state-of-the-art deepneural networks (DNNs) are capable of predicting the electronic properties ofOSCs at an accuracy comparable with the quantum chemistry methods used forgenerating training data. We extensively investigate the performances of fourrecent DNNs (deep tensor neural network, SchNet, message passing neuralnetwork, and multilevel graph convolutional neural network) in predictingvarious electronic properties of an important class of OSCs, i.e.,oligothiophenes (OTs), including their HOMO and LUMO energies, excited-stateenergies and associated transition dipole moments. We find that SchNet showsthe best performance for OTs of different sizes (from bithiophene tosexithiophene), achieving average prediction errors in the range of 20-80meVcompared to the results from (time-dependent) density functional theory. Weshow that SchNet also consistently outperforms shallow feed-forward neuralnetworks, especially in difficult cases with large molecules or limitedtraining data. We further show that SchNet could predict the transition dipolemoment accurately, a task previously known to be difficult for feed-forwardneural networks, and we ascribe the relatively large errors in transitiondipole prediction seen for some OT configurations to the charge-transfercharacter of their excited states. Finally, we demonstrate the effectiveness ofSchNet by modeling the UV-Vis absorption spectra of OTs in dichloromethane anda good agreement is observed between the calculated and experimental spectra."^^schema:Text ;
    schema:author "Chang-Yu Hsieh"^^schema:Person,
        "Chee-Kong Lee"^^schema:Person,
        "Chengqiang Lu"^^schema:Person,
        "Liang Shi"^^schema:Person,
        "Qi Liu"^^schema:Person,
        "Qiming Sun"^^schema:Person,
        "Shengyu Zhang"^^schema:Person ;
    schema:dateModified "2019-10-29T21:42:02Z"^^schema:DateTime ;
    schema:datePublished "2019-10-29T21:42:02Z"^^schema:DateTime ;
    schema:genre "cond-mat.mtrl-sci"^^schema:Text,
        "physics.chem-ph"^^schema:Text,
        "physics.comp-ph"^^schema:Text ;
    schema:headline "Deep Learning for Optoelectronic Properties of Organic Semiconductors"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.13551v1"^^schema:URL .

<863> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel pathology-sensitive deep learning model (PS-DeVCEM) forframe-level anomaly detection and multi-label classification of different colondiseases in video capsule endoscopy (VCE) data. Our proposed model is capableof coping with the key challenge of colon apparent heterogeneity caused byseveral types of diseases. Our model is driven by attention-based deep multipleinstance learning and is trained end-to-end on weakly labeled data using videolabels instead of detailed frame-by-frame annotation. The spatial and temporalfeatures are obtained through ResNet50 and residual Long short-term memory(residual LSTM) blocks, respectively. Additionally, the learned temporalattention module provides the importance of each frame to the final labelprediction. Moreover, we developed a self-supervision method to maximize thedistance between classes of pathologies. We demonstrate through qualitative andquantitative experiments that our proposed weakly supervised learning modelgives superior precision and F1-score reaching, 61.6% and 55.1%, as compared tothree state-of-the-art video analysis methods respectively. We also show ourmodel's ability to temporally localize frames with pathologies, without frameannotation information during training. Furthermore, we collected and annotatedthe first and largest VCE dataset with only video labels. The dataset contains455 short video segments with 28,304 frames and 14 classes of colorectaldiseases and artifacts. Dataset and code supporting this publication will bemade available on our home page."^^schema:Text ;
    schema:author "A. Mohammed"^^schema:Person,
        "I. Farup"^^schema:Person,
        "M. Pedersen"^^schema:Person,
        "S. Yildirim"^^schema:Person,
        "Ø Hovde"^^schema:Person ;
    schema:dateModified "2020-11-22T15:33:37Z"^^schema:DateTime ;
    schema:datePublished "2020-11-22T15:33:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "PS-DeVCEM: Pathology-sensitive deep learning model for video capsule  endoscopy based on weakly labeled data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.12957v1"^^schema:URL .

<864> a schema:ScholarlyArticle ;
    schema:abstract "One-shot weight sharing methods have recently drawn great attention in neuralarchitecture search due to high efficiency and competitive performance.However, weight sharing across models has an inherent deficiency, i.e.,insufficient training of subnetworks in hypernetworks. To alleviate thisproblem, we present a simple yet effective architecture distillation method.The central idea is that subnetworks can learn collaboratively and teach eachother throughout the training process, aiming to boost the convergence ofindividual models. We introduce the concept of prioritized path, which refersto the architecture candidates exhibiting superior performance during training.Distilling knowledge from the prioritized paths is able to boost the trainingof subnetworks. Since the prioritized paths are changed on the fly depending ontheir performance and complexity, the final obtained paths are the cream of thecrop. We directly select the most promising one from the prioritized paths asthe final architecture, without using other complex search methods, such asreinforcement learning or evolution algorithms. The experiments on ImageNetverify such path distillation method can improve the convergence ratio andperformance of the hypernetwork, as well as boosting the training ofsubnetworks. The discovered architectures achieve superior performance comparedto the recent MobileNetV3 and EfficientNet families under aligned settings.Moreover, the experiments on object detection and more challenging search spaceshow the generality and robustness of the proposed method. Code and models areavailable at https://github.com/microsoft/cream.git."^^schema:Text ;
    schema:author "Hao Du"^^schema:Person,
        "Hongyuan Yu"^^schema:Person,
        "Houwen Peng"^^schema:Person,
        "Jianlong Fu"^^schema:Person,
        "Jing Liao"^^schema:Person,
        "Qi Li"^^schema:Person ;
    schema:dateModified "2020-11-24T15:37:37Z"^^schema:DateTime ;
    schema:datePublished "2020-10-29T17:55:05Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural  Architecture Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.15821v2"^^schema:URL .

<865> a schema:ScholarlyArticle ;
    schema:abstract "Deep Neural Networks have now achieved state-of-the-art results in a widerange of tasks including image classification, object detection and so on.However, they are both computation consuming and memory intensive, making themdifficult to deploy on low-power devices. Network binarization is one of theexisting effective techniques for model compression and acceleration, but thereis no computing kernel yet to support it on PyTorch. In this paper we developeda computing kernel supporting 1-bit xnor and bitcount computation on PyTorch.Experimental results show that our kernel could accelerate the inference of thebinarized neural network by 3 times in GPU and by 4.5 times in CPU comparedwith the control group."^^schema:Text ;
    schema:author "Marco Pedersoli"^^schema:Person,
        "Xianda Xu"^^schema:Person ;
    schema:dateModified "2019-11-11T05:26:04Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T05:26:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "A Computing Kernel for Network Binarization on PyTorch"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04477v1"^^schema:URL .

<866> a schema:ScholarlyArticle ;
    schema:abstract "Spherical data is found in many applications. By modeling the discretizedsphere as a graph, we can accommodate non-uniformly distributed, partial, andchanging samplings. Moreover, graph convolutions are computationally moreefficient than spherical convolutions. As equivariance is desired to exploitrotational symmetries, we discuss how to approach rotation equivariance usingthe graph neural network introduced in Defferrard et al. (2016). Experimentsshow good performance on rotation-invariant learning problems. Code andexamples are available at https://github.com/SwissDataScienceCenter/DeepSphere"^^schema:Text ;
    schema:author "Michaël Defferrard"^^schema:Person,
        "Nathanaël Perraudin"^^schema:Person,
        "Raphael Sgier"^^schema:Person,
        "Tomasz Kacprzak"^^schema:Person ;
    schema:dateModified "2019-04-08T18:01:04Z"^^schema:DateTime ;
    schema:datePublished "2019-04-08T18:01:04Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DeepSphere: towards an equivariant graph-based spherical CNN"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.05146v1"^^schema:URL .

<867> a schema:ScholarlyArticle ;
    schema:abstract "Time series prediction has been studied in a variety of domains. However, itis still challenging to predict future series given historical observations andpast exogenous data. Existing methods either fail to consider the interactionsamong different components of exogenous variables which may affect theprediction accuracy, or cannot model the correlations between exogenous dataand target data. Besides, the inherent temporal dynamics of exogenous data arealso related to the target series prediction, and thus should be considered aswell. To address these issues, we propose an end-to-end deep learning model,i.e., Hierarchical attention-based Recurrent Highway Network (HRHN), whichincorporates spatio-temporal feature extraction of exogenous variables andtemporal dynamics modeling of target variables into a single framework.Moreover, by introducing the hierarchical attention mechanism, HRHN canadaptively select the relevant exogenous features in different semantic levels.We carry out comprehensive empirical evaluations with various methods overseveral datasets, and show that HRHN outperforms the state of the arts in timeseries prediction, especially in capturing sudden changes and suddenoscillations of time series."^^schema:Text ;
    schema:author "Jian Liu"^^schema:Person,
        "Lin Ma"^^schema:Person,
        "Qiang Du"^^schema:Person,
        "Wei Liu"^^schema:Person,
        "Weizhong Zhang"^^schema:Person,
        "Yunzhe Tao"^^schema:Person ;
    schema:dateModified "2018-06-02T18:46:50Z"^^schema:DateTime ;
    schema:datePublished "2018-06-02T18:46:50Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Attention-Based Recurrent Highway Networks for Time Series  Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.00685v1"^^schema:URL .

<868> a schema:ScholarlyArticle ;
    schema:abstract "Recent advances in sensing technologies require the design and development ofpattern recognition models capable of processing spatiotemporal dataefficiently. In this study, we propose a spatially and temporally awaretensor-based neural network for human pose classification usingthree-dimensional skeleton data. Our model employs three novel components.First, an input layer capable of constructing highly discriminativespatiotemporal features. Second, a tensor fusion operation that producescompact yet rich representations of the data, and third, a tensor-based neuralnetwork that processes data representations in their original tensor form. Ourmodel is end-to-end trainable and characterized by a small number of trainableparameters making it suitable for problems where the annotated data is limited.Experimental evaluation of the proposed model indicates that it can achievestate-of-the-art performance."^^schema:Text ;
    schema:author "Anastasios Doulamis"^^schema:Person,
        "Athanasios Voulodimos"^^schema:Person,
        "Konstantinos Makantasis"^^schema:Person,
        "Nikolaos Bakalos"^^schema:Person,
        "Nikolaos Doulamis"^^schema:Person ;
    schema:dateModified "2020-10-18T17:52:46Z"^^schema:DateTime ;
    schema:datePublished "2020-04-17T10:20:56Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Space-Time Domain Tensor Neural Networks: An Application on Human Pose  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.08153v2"^^schema:URL .

<869> a schema:ScholarlyArticle ;
    schema:abstract "Pancreatic ductal adenocarcinoma (PDAC) is one of the most lethal cancerswith an overall five-year survival rate of 8%. Due to subtle texture changes ofPDAC, pancreatic dual-phase imaging is recommended for better diagnosis ofpancreatic disease. In this study, we aim at enhancing PDAC automaticsegmentation by integrating multi-phase information (i.e., arterial phase andvenous phase). To this end, we present Hyper-Pairing Network (HPN), a 3D fullyconvolution neural network which effectively integrates information fromdifferent phases. The proposed approach consists of a dual path network wherethe two parallel streams are interconnected with hyper-connections forintensive information exchange. Additionally, a pairing loss is added toencourage the commonality between high-level feature representations ofdifferent phases. Compared to prior arts which use single phase data, HPNreports a significant improvement up to 7.73% (from 56.21% to 63.94%) in termsof DSC."^^schema:Text ;
    schema:author "Alan Yuille"^^schema:Person,
        "Angtian Wang"^^schema:Person,
        "Elliot Fishman"^^schema:Person,
        "Seyoun Park"^^schema:Person,
        "Yan Wang"^^schema:Person,
        "Yingwei Li"^^schema:Person,
        "Yuyin Zhou"^^schema:Person,
        "Zhishuai Zhang"^^schema:Person ;
    schema:dateModified "2019-09-03T00:55:37Z"^^schema:DateTime ;
    schema:datePublished "2019-09-03T00:55:37Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Hyper-Pairing Network for Multi-Phase Pancreatic Ductal Adenocarcinoma  Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.00906v1"^^schema:URL .

<87> a schema:ScholarlyArticle ;
    schema:abstract "Learning goal-directed behavior in environments with sparse feedback is amajor challenge for reinforcement learning algorithms. The primary difficultyarises due to insufficient exploration, resulting in an agent being unable tolearn robust value functions. Intrinsically motivated agents can explore newbehavior for its own sake rather than to directly solve problems. Suchintrinsic behaviors could eventually help the agent solve tasks posed by theenvironment. We present hierarchical-DQN (h-DQN), a framework to integratehierarchical value functions, operating at different temporal scales, withintrinsically motivated deep reinforcement learning. A top-level value functionlearns a policy over intrinsic goals, and a lower-level function learns apolicy over atomic actions to satisfy the given goals. h-DQN allows forflexible goal specifications, such as functions over entities and relations.This provides an efficient space for exploration in complicated environments.We demonstrate the strength of our approach on two problems with very sparse,delayed feedback: (1) a complex discrete stochastic decision process, and (2)the classic ATARI game `Montezuma's Revenge'."^^schema:Text ;
    schema:author "Ardavan Saeedi"^^schema:Person,
        "Joshua B. Tenenbaum"^^schema:Person,
        "Karthik R. Narasimhan"^^schema:Person,
        "Tejas D. Kulkarni"^^schema:Person ;
    schema:commentCount "546"^^schema:Integer ;
    schema:dateModified "2016-05-31T14:45:58Z"^^schema:DateTime ;
    schema:datePublished "2016-04-20T18:47:48Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Hierarchical Deep Reinforcement Learning: Integrating Temporal  Abstraction and Intrinsic Motivation"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1604.06057v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=17312997916185144890&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<870> a schema:ScholarlyArticle ;
    schema:abstract "Extrapolating fine-grained pixel-level correspondences in a fullyunsupervised manner from a large set of misaligned images can benefit severalcomputer vision and graphics problems, e.g. co-segmentation, super-resolution,image edit propagation, structure-from-motion, and 3D reconstruction. Severaljoint image alignment and congealing techniques have been proposed to tacklethis problem, but robustness to initialisation, ability to scale to largedatasets, and alignment accuracy seem to hamper their wide applicability. Toovercome these limitations, we propose an unsupervised joint alignment methodleveraging a densely fused spatial transformer network to estimate the warpingparameters for each image and a low-capacity auto-encoder whose reconstructionerror is used as an auxiliary measure of joint alignment. Experimental resultson digits from multiple versions of MNIST (i.e., original, perturbed, affNISTand infiMNIST) and faces from LFW, show that our approach is capable ofaligning millions of images with high accuracy and robustness to differentlevels and types of perturbation. Moreover, qualitative and quantitativeresults suggest that the proposed method outperforms state-of-the-artapproaches both in terms of alignment quality and robustness to initialisation."^^schema:Text ;
    schema:author "Christos Sagonas"^^schema:Person,
        "Jacques Cali"^^schema:Person,
        "Roberto Annunziata"^^schema:Person ;
    schema:dateModified "2019-10-14T10:24:31Z"^^schema:DateTime ;
    schema:datePublished "2019-08-12T12:55:31Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Jointly Aligning Millions of Images with Deep Penalised Reconstruction  Congealing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.04130v2"^^schema:URL .

<871> a schema:ScholarlyArticle ;
    schema:abstract "We analyze approximation rates by deep ReLU networks of a class ofmulti-variate solutions of Kolmogorov equations which arise in option pricing.Key technical devices are deep ReLU architectures capable of efficientlyapproximating tensor products. Combining this with results concerning theapproximation of well behaved (i.e. fulfilling some smoothness properties)univariate functions, this provides insights into rates of deep ReLUapproximation of multi-variate functions with tensor structures. We apply thisin particular to the model problem given by the price of a European maximumoption on a basket of $d$ assets within the Black-Scholes model for Europeanmaximum option pricing. We prove that the solution to the $d$-variate optionpricing problem can be approximated up to an $\\varepsilon$-error by a deep ReLUnetwork with depth $\\mathcal{O}\\big(\\ln(d)\\ln(\\varepsilon^{-1})+\\ln(d)^2\\big)$and $\\mathcal{O}\\big(d^{2+\\frac{1}{n}}\\varepsilon^{-\\frac{1}{n}}\\big)$ non-zeroweights, where $n\\in \\mathbb{N}$ is arbitrary (with the constant implied in$\\mathcal{O}(\\cdot)$ depending on $n$). The techniques developed in theconstructive proof are of independent interest in the analysis of theexpressive power of deep neural networks for solution manifolds of PDEs in highdimension."^^schema:Text ;
    schema:author "Arnulf Jentzen"^^schema:Person,
        "Christoph Schwab"^^schema:Person,
        "Dennis Elbrächter"^^schema:Person,
        "Philipp Grohs"^^schema:Person ;
    schema:dateModified "2020-11-03T14:24:52Z"^^schema:DateTime ;
    schema:datePublished "2018-09-20T15:17:27Z"^^schema:DateTime ;
    schema:genre "41Axx, 35Kxx, 65-XX, 65D30"^^schema:Text,
        "math.FA"^^schema:Text ;
    schema:headline "DNN Expression Rate Analysis of High-dimensional PDEs: Application to  Option Pricing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.07669v3"^^schema:URL .

<872> a schema:ScholarlyArticle ;
    schema:abstract "Achieving state-of-the-art performance on natural language understandingtasks typically relies on fine-tuning a fresh model for every task.Consequently, this approach leads to a higher overall parameter cost, alongwith higher technical maintenance for serving multiple models. Learning asingle multi-task model that is able to do well for all the tasks has been achallenging and yet attractive proposition. In this paper, we propose\\textsc{HyperGrid}, a new approach for highly effective multi-task learning.The proposed approach is based on a decomposable hypernetwork that learnsgrid-wise projections that help to specialize regions in weight matrices fordifferent tasks. In order to construct the proposed hypernetwork, our methodlearns the interactions and composition between a global (task-agnostic) stateand a local task-specific state. We apply our proposed \\textsc{HyperGrid} onthe current state-of-the-art T5 model, demonstrating strong performance acrossthe GLUE and SuperGLUE benchmarks when using only a single multi-task model.Our method helps bridge the gap between fine-tuning and multi-task learningapproaches."^^schema:Text ;
    schema:author "Da-Cheng Juan"^^schema:Person,
        "Dara Bahri"^^schema:Person,
        "Donald Metzler"^^schema:Person,
        "Yi Tay"^^schema:Person,
        "Zhe Zhao"^^schema:Person ;
    schema:dateModified "2020-07-12T02:49:16Z"^^schema:DateTime ;
    schema:datePublished "2020-07-12T02:49:16Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.IR"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "HyperGrid: Efficient Multi-Task Transformers with Grid-wise Decomposable  Hyper Projections"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.05891v1"^^schema:URL .

<873> a schema:ScholarlyArticle ;
    schema:abstract "The traditional mode of recording faults in heavy factory equipment has beenvia hand marked inspection sheets, wherein a machine engineer manually marksthe faulty machine regions on a paper outline of the machine. Over the years,millions of such inspection sheets have been recorded and the data within thesesheets has remained inaccessible. However, with industries going digital andwaking up to the potential value of fault data for machine health monitoring,there is an increased impetus towards digitization of these hand markedinspection records. To target this digitization, we propose a novel visualpipeline combining state of the art deep learning models, with domain knowledgeand low level vision techniques, followed by inference of visual relationships.Our framework is robust to the presence of both static and non-staticbackground in the document, variability in the machine template diagrams,unstructured shape of graphical objects to be identified and variability in thestrokes of handwritten text. The proposed pipeline incorporates a capsule andspatial transformer network based classifier for accurate text reading, and acustomized CTPN network for text detection in addition to hybrid techniques forarrow detection and dialogue cloud removal. We have tested our approach on areal world dataset of 50 inspection sheets for large containers and boilers.The results are visually appealing and the pipeline achieved an accuracy of87.1% for text detection and 94.6% for text reading."^^schema:Text ;
    schema:author "Animesh"^^schema:Person,
        "Arindam Chowdhury"^^schema:Person,
        "Lovekesh Vig"^^schema:Person,
        "Rohit Rahul"^^schema:Person,
        "Samarth Mittal"^^schema:Person ;
    schema:dateModified "2018-12-11T13:10:14Z"^^schema:DateTime ;
    schema:datePublished "2018-12-11T13:10:14Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Reading Industrial Inspection Sheets by Inferring Visual Relations"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.07104v1"^^schema:URL .

<874> a schema:ScholarlyArticle ;
    schema:abstract "Generative Adversarial Networks (GANs) have been used to model the underlyingprobability distribution of sample based datasets. GANs are notoriuos fortraining difficulties and their dependence on arbitrary hyperparameters. Onerecent improvement in GAN literature is to use the Wasserstein distance as lossfunction leading to Wasserstein Generative Adversarial Networks (WGANs). Usingthis as a basis, we show various ways in which the Wasserstein distance isestimated for the task of generative modelling. Additionally, the secrets intraining such models are shown and summarized at the end of this work. Whereapplicable, we extend current works to different algorithms, different costfunctions, and different regularization schemes to improve generative models."^^schema:Text ;
    schema:author "Daniel Soukup"^^schema:Person,
        "Thomas Pinetz"^^schema:Person,
        "Thomas Pock"^^schema:Person ;
    schema:dateModified "2019-10-02T11:49:00Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T11:49:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the estimation of the Wasserstein distance in generative models"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00888v1"^^schema:URL .

<875> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we explore the task of generating photo-realistic face imagesfrom lines. Previous methods based on conditional generative adversarialnetworks (cGANs) have shown their power to generate visually plausible imageswhen a conditional image and an output image share well-aligned structures.However, these models fail to synthesize face images with a whole set ofwell-defined structures, e.g. eyes, noses, mouths, etc., especially when theconditional line map lacks one or several parts. To address this problem, wepropose a conditional self-attention generative adversarial network (CSAGAN).We introduce a conditional self-attention mechanism to cGANs to capturelong-range dependencies between different regions in faces. We also build amulti-scale discriminator. The large-scale discriminator enforces thecompleteness of global structures and the small-scale discriminator encouragesfine details, thereby enhancing the realism of generated face images. Weevaluate the proposed model on the CelebA-HD dataset by two perceptual userstudies and three quantitative metrics. The experiment results demonstrate thatour method generates high-quality facial images while preserving facialstructures. Our results outperform state-of-the-art methods both quantitativelyand qualitatively."^^schema:Text ;
    schema:author "Feng Wu"^^schema:Person,
        "Xuejin Chen"^^schema:Person,
        "Yuhang Li"^^schema:Person,
        "Zheng-Jun Zha"^^schema:Person ;
    schema:dateModified "2019-10-20T07:05:24Z"^^schema:DateTime ;
    schema:datePublished "2019-10-20T07:05:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "LinesToFacePhoto: Face Photo Generation from Lines with Conditional  Self-Attention Generative Adversarial Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.08914v1"^^schema:URL .

<876> a schema:ScholarlyArticle ;
    schema:abstract "While propagation-based approaches have achieved state-of-the-art performancefor video object segmentation, the literature lacks a fair comparison ofdifferent methods using the same settings. In this paper, we carry out anempirical study for propagation-based methods. We view these approaches from aunified perspective and conduct detailed ablation study for core methods, inputcues, multi-object combination and training strategies. With careful designs,our improved end-to-end memory networks achieve a global mean of 76.1 on DAVIS2017 val set."^^schema:Text ;
    schema:author "Guanjun Guo"^^schema:Person,
        "Hengkai Guo"^^schema:Person,
        "Huaxia Li"^^schema:Person,
        "Jiachen Liu"^^schema:Person,
        "Qian He"^^schema:Person,
        "Wenji Wang"^^schema:Person,
        "Xuefeng Xiao"^^schema:Person ;
    schema:dateModified "2019-07-30T08:00:47Z"^^schema:DateTime ;
    schema:datePublished "2019-07-30T08:00:47Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "An Empirical Study of Propagation-based Methods for Video Object  Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.12769v1"^^schema:URL .

<877> a schema:ScholarlyArticle ;
    schema:abstract "We propose a tensor neural network ($t$-NN) framework that offers an excitingnew paradigm for designing neural networks with multidimensional (tensor) data.Our network architecture is based on the $t$-product (Kilmer and Martin, 2011),an algebraic formulation to multiply tensors via circulant convolution. In this$t$-product algebra, we interpret tensors as $t$-linear operators analogous tomatrices as linear operators, and hence our framework inherits mimetic matrixproperties. To exemplify the elegant, matrix-mimetic algebraic structure of our$t$-NNs, we expand on recent work (Haber and Ruthotto, 2017) which interpretsdeep neural networks as discretizations of non-linear differential equationsand introduces stable neural networks which promote superior generalization.Motivated by this dynamic framework, we introduce a stable $t$-NN whichfacilitates more rapid learning because of its reduced, more powerfulparameterization. Through our high-dimensional design, we create a more compactparameter space and extract multidimensional correlations otherwise latent intraditional algorithms. We further generalize our $t$-NN framework to a familyof tensor-tensor products (Kernfeld, Kilmer, and Aeron, 2015) which stillinduce a matrix-mimetic algebraic structure. Through numerical experiments onthe MNIST and CIFAR-10 datasets, we demonstrate the more powerfulparameterizations and improved generalizability of stable $t$-NNs."^^schema:Text ;
    schema:author "Elizabeth Newman"^^schema:Person,
        "Haim Avron"^^schema:Person,
        "Lior Horesh"^^schema:Person,
        "Misha Kilmer"^^schema:Person ;
    schema:dateModified "2018-11-15T19:37:24Z"^^schema:DateTime ;
    schema:datePublished "2018-11-15T19:37:24Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NA"^^schema:Text,
        "math.NA"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Stable Tensor Neural Networks for Rapid Deep Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.06569v1"^^schema:URL .

<878> a schema:ScholarlyArticle ;
    schema:abstract "Image to image transformation has gained popularity from different researchcommunities due to its enormous impact on different applications, includingmedical. In this work, we have introduced a generalized scheme for consistencyfor GAN architectures with two new concepts of Transformation Learning (TL) andRelative Learning (ReL) for enhanced learning image transformations.Consistency for GAN architectures suffered from inadequate constraints andfailed to learn multiple and multi-modal transformations, which is inevitablefor many medical applications. The main drawback is that it focused on creatingan intermediate and workable hybrid, which is not permissible for the medicalapplications which focus on minute details. Another drawback is the weakinterrelation between the two learning phases and TL and ReL have introducedimproved coordination among them. We have demonstrated the capability of thenovel network framework on public datasets. We emphasized that our novelarchitecture produced an improved neural image transformation version for theimage, which is more acceptable to the medical community. Experiments andresults demonstrated the effectiveness of our framework with enhancementcompared to the previous works."^^schema:Text ;
    schema:author "Chiranjib Sur"^^schema:Person ;
    schema:dateModified "2020-06-14T06:03:30Z"^^schema:DateTime ;
    schema:datePublished "2020-06-14T06:03:30Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "ReLGAN: Generalization of Consistency for GAN with Disjoint Constraints  and Relative Learning of Generative Processes for Multiple Transformation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.07809v1"^^schema:URL .

<879> a schema:ScholarlyArticle ;
    schema:abstract "Text-based games are suitable test-beds for designing agents that can learnby interaction with the environment in the form of natural language text. Veryrecently, deep reinforcement learning based agents have been successfullyapplied for playing text-based games. In this paper, we explore the possibilityof designing a single agent to play several text-based games and of expandingthe agent's vocabulary using the vocabulary of agents trained for multiplegames. To this extent, we explore the application of recently proposed policydistillation method for video games to the text-based game setting. We also usetext-based games as a test-bed to analyze and hence understand policydistillation approach in detail."^^schema:Text ;
    schema:author "Balaraman Ravindran"^^schema:Person,
        "Ghulam Ahmed Ansari"^^schema:Person,
        "Sagar J P"^^schema:Person,
        "Sarath Chandar"^^schema:Person ;
    schema:dateModified "2018-05-17T10:43:04Z"^^schema:DateTime ;
    schema:datePublished "2018-05-17T10:43:04Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Language Expansion In Text-Based Games"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.07274v1"^^schema:URL .

<88> a schema:ScholarlyArticle ;
    schema:abstract "In recent years, significant progress has been made in solving challengingproblems across various domains using deep reinforcement learning (RL).Reproducing existing work and accurately judging the improvements offered bynovel methods is vital to sustaining this progress. Unfortunately, reproducingresults for state-of-the-art deep RL methods is seldom straightforward. Inparticular, non-determinism in standard benchmark environments, combined withvariance intrinsic to the methods, can make reported results tough tointerpret. Without significance metrics and tighter standardization ofexperimental reporting, it is difficult to determine whether improvements overthe prior state-of-the-art are meaningful. In this paper, we investigatechallenges posed by reproducibility, proper experimental techniques, andreporting procedures. We illustrate the variability in reported metrics andresults when comparing against common baselines and suggest guidelines to makefuture results in deep RL more reproducible. We aim to spur discussion abouthow to ensure continued progress in the field by minimizing wasted effortstemming from results that are non-reproducible and easily misinterpreted."^^schema:Text ;
    schema:author "David Meger"^^schema:Person,
        "Doina Precup"^^schema:Person,
        "Joelle Pineau"^^schema:Person,
        "Peter Henderson"^^schema:Person,
        "Philip Bachman"^^schema:Person,
        "Riashat Islam"^^schema:Person ;
    schema:commentCount "567"^^schema:Integer ;
    schema:dateModified "2019-01-30T04:21:41Z"^^schema:DateTime ;
    schema:datePublished "2017-09-19T06:09:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Reinforcement Learning that Matters"^^schema:Text ;
    schema:publisher "Thirty-Second AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1709.06560v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4728083518318824086&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<880> a schema:ScholarlyArticle ;
    schema:abstract "Artificial neural networks have become ubiquitous in modern life, which hastriggered the emergence of a new class of application specific integratedcircuits for their acceleration. ReRAM-based accelerators have gainedsignificant traction due to their ability to leverage in-memory computations.In a crossbar structure, they can perform multiply-and-accumulate operationsmore efficiently than standard CMOS logic. By virtue of being resistiveswitches, ReRAM switches can only reliably store one of two states. This is asevere limitation on the range of values in a computational kernel. This paperpresents a novel scheme in alleviating the single-bit-per-device restriction byexploiting frequency dependence of v-i plane hysteresis, and assigning kernelinformation not only to the device conductance but also partially distributingit to the frequency of a time-varying input. We show this approach reducesaverage power consumption for a single crossbar convolution by up to a factorof x16 for an unsigned 8-bit input image, where each convolutional processconsumes a worst-case of 1.1mW, and reduces area by a factor of x8, withoutreducing accuracy to the level of binarized neural networks. This presents amassive saving in computing cost when there are many simultaneous in-situmultiply-and-accumulate processes occurring across different crossbars."^^schema:Text ;
    schema:author "Garrick Orchard"^^schema:Person,
        "Herbert Ho-Ching Iu"^^schema:Person,
        "Jason K. Eshraghian"^^schema:Person,
        "Seungbum Baek"^^schema:Person,
        "Sung-Mo Kang"^^schema:Person,
        "Wen Lei"^^schema:Person ;
    schema:dateModified "2019-04-26T18:25:16Z"^^schema:DateTime ;
    schema:datePublished "2019-04-26T18:25:16Z"^^schema:DateTime ;
    schema:genre "eess.IV"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Analog Weights in ReRAM DNN Accelerators"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.12008v1"^^schema:URL .

<881> a schema:ScholarlyArticle ;
    schema:abstract "Interpretability and explainability of deep neural networks are challengingdue to their scale, complexity, and the agreeable notions on which theexplaining process rests. Previous work, in particular, has focused onrepresenting internal components of neural networks through human-friendlyvisuals and concepts. On the other hand, in real life, when making a decision,human tends to rely on similar situations and/or associations in the past.Hence arguably, a promising approach to make the model transparent is to designit in a way such that the model explicitly connects the current sample with theseen ones, and bases its decision on these samples. Grounded on that principle,we propose in this paper an explainable, evidence-based memory networkarchitecture, which learns to summarize the dataset and extract supportingevidences to make its decision. Our model achieves state-of-the-art performanceon two popular question answering datasets (i.e. TrecQA and WikiQA). Viafurther analysis, we show that this model can reliably trace the errors it hasmade in the validation step to the training instances that might have causedthese errors. We believe that this error-tracing capability providessignificant benefit in improving dataset quality in many applications."^^schema:Text ;
    schema:author "Dinh Phung"^^schema:Person,
        "Franck Dernoncourt"^^schema:Person,
        "Nham Le"^^schema:Person,
        "Nhan Dam"^^schema:Person,
        "Quan Tran"^^schema:Person,
        "Trung Le"^^schema:Person,
        "Tuan Lai"^^schema:Person ;
    schema:dateModified "2020-11-05T21:18:21Z"^^schema:DateTime ;
    schema:datePublished "2020-11-05T21:18:21Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Explain by Evidence: An Explainable Memory-based Neural Network for  Question Answering"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.03096v1"^^schema:URL .

<882> a schema:ScholarlyArticle ;
    schema:abstract "We revisit and extend the experiments of Goodfellow et al. (2014), who showedthat - for then state-of-the-art networks - \"the objective function has asimple, approximately convex shape\" along the linear path betweeninitialization and the trained weights. We do not find this to be the case formodern networks on CIFAR-10 and ImageNet. Instead, although loss is roughlymonotonically non-increasing along this path, it remains high until close tothe optimum. In addition, training quickly becomes linearly separated from theoptimum by loss barriers. We conclude that, although Goodfellow et al.'sfindings describe the \"relatively easy to optimize\" MNIST setting, behavior isqualitatively different in modern settings."^^schema:Text ;
    schema:author "Jonathan Frankle"^^schema:Person ;
    schema:dateModified "2020-12-12T20:01:33Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T20:01:33Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Revisiting \"Qualitatively Characterizing Neural Network Optimization  Problems\""^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06898v1"^^schema:URL .

<883> a schema:ScholarlyArticle ;
    schema:abstract "Low precision networks in the reinforcement learning (RL) setting arerelatively unexplored because of the limitations of binary activations forfunction approximation. Here, in the discrete action ATARI domain, wedemonstrate, for the first time, that low precision policy distillation from ahigh precision network provides a principled, practical way to train an RLagent. As an application, on 10 different ATARI games, we demonstrate real-timeend-to-end game playing on low-power neuromorphic hardware by converting asequence of game frames into discrete actions."^^schema:Text ;
    schema:author "Davis R. Barch"^^schema:Person,
        "Deepika Bablani"^^schema:Person,
        "Dharmendra S. Modha"^^schema:Person,
        "Jeffrey A. Kusnitz"^^schema:Person,
        "Jeffrey L Mckinstry"^^schema:Person,
        "John V. Arthur"^^schema:Person,
        "Michael V. Debole"^^schema:Person,
        "Steven K. Esser"^^schema:Person ;
    schema:dateModified "2018-09-25T00:03:33Z"^^schema:DateTime ;
    schema:datePublished "2018-09-25T00:03:33Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Low Precision Policy Distillation with Application to Low-Power,  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.09260v1"^^schema:URL .

<884> a schema:ScholarlyArticle ;
    schema:abstract "We propose an efficient neural framework for sentence-level discourseanalysis in accordance with Rhetorical Structure Theory (RST). Our frameworkcomprises a discourse segmenter to identify the elementary discourse units(EDU) in a text, and a discourse parser that constructs a discourse tree in atop-down fashion. Both the segmenter and the parser are based on PointerNetworks and operate in linear time. Our segmenter yields an $F_1$ score of95.4, and our parser achieves an $F_1$ score of 81.7 on the aggregated labeled(relation) metric, surpassing previous approaches by a good margin andapproaching human agreement on both tasks (98.3 and 83.0 $F_1$)."^^schema:Text ;
    schema:author "M Saiful Bari"^^schema:Person,
        "Prathyusha Jwalapuram"^^schema:Person,
        "Shafiq Joty"^^schema:Person,
        "Xiang Lin"^^schema:Person ;
    schema:dateModified "2019-06-12T05:05:06Z"^^schema:DateTime ;
    schema:datePublished "2019-05-14T15:54:57Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "A Unified Linear-Time Framework for Sentence-Level Discourse Parsing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.05682v2"^^schema:URL .

<885> a schema:ScholarlyArticle ;
    schema:abstract "Examining field-programmable gate array (FPGA) bitstream is found to helpdetect known function blocks, which offers assistance and insight to analyzethe circuit's system function. Our goal is to detect one or more than onefunction block in FPGA design from a complete bitstream by utilizing the latestdeep learning techniques, which do not require manually designing features. Tothis end, in this paper, we propose a deep learning-based FPGA function blockdetection method by transforming the bitstream into a three-channel colorimage. In specific, we first analyze the format of the bitstream to find themapping relationship between the configuration bits and configurable logicblocks. Next, an image-coded representation of bitstream is proposed suitablefor deep learning processing. This bitstream-to-image transformation takes intoaccount of the adjacency nature of the programmable logic as well as highdegree of redundancy of configuration information. With the color imagestransformed from bitstreams as the training dataset, a deep learning-basedobject detection algorithm is applied for generating the function blockdetection results. The effects of EDA tools, input size of the deep neuralnetwork, and the data arrangement of representation on the detection accuracyare explored. The Xilinx Zynq-7000 SoCs and Xilinx Zynq UltraScale+ MPSoCs areadopted to verify the proposed method, and the results show that the meanAverage Precision (IoU=0.5) for 10 function blocks is as high as 97.72% forYOLOv3 detector."^^schema:Text ;
    schema:author "Minzhen Chen"^^schema:Person,
        "Peng Liu"^^schema:Person ;
    schema:dateModified "2020-07-20T07:45:05Z"^^schema:DateTime ;
    schema:datePublished "2020-07-20T07:45:05Z"^^schema:DateTime ;
    schema:genre "cs.OH"^^schema:Text,
        "eess.IV"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Deep Learning-Based FPGA Function Block Detection Method using an  Image-Coded Representation of Bitstream"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.11434v1"^^schema:URL .

<886> a schema:ScholarlyArticle ;
    schema:abstract "This paper proposes a method for OOD detection. Questioning the premise ofprevious studies that ID and OOD samples are separated distinctly, we considersamples lying in the intermediate of the two and use them for training anetwork. We generate such samples using multiple image transformations thatcorrupt inputs in various ways and with different severity levels. We estimatewhere the generated samples by a single image transformation lie between ID andOOD using a network trained on clean ID samples. To be specific, we make thenetwork classify the generated samples and calculate their mean classificationaccuracy, using which we create a soft target label for them. We train the samenetwork from scratch using the original ID samples and the generated sampleswith the soft labels created for them. We detect OOD samples by thresholdingthe entropy of the predicted softmax probability. The experimental results showthat our method outperforms the previous state-of-the-art in the standardbenchmark tests. We also analyze the effect of the number and particularcombinations of image corrupting transformations on the performance."^^schema:Text ;
    schema:author "Anh-Chuong Dang"^^schema:Person,
        "Engkarat Techapanurak"^^schema:Person,
        "Takayuki Okatani"^^schema:Person ;
    schema:dateModified "2021-01-07T11:34:18Z"^^schema:DateTime ;
    schema:datePublished "2021-01-07T11:34:18Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Bridging In- and Out-of-distribution Samples for Their Better  Discriminability"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.02500v1"^^schema:URL .

<887> a schema:ScholarlyArticle ;
    schema:abstract "Generative moment matching networks (GMMNs) are introduced as dependencemodels for the joint innovation distribution of multivariate time series (MTS).Following the popular copula-GARCH approach for modeling dependent MTS data, aframework based on a GMMN-GARCH approach is presented. First, ARMA-GARCH modelsare utilized to capture the serial dependence within each univariate marginaltime series. Second, if the number of marginal time series is large, principalcomponent analysis (PCA) is used as a dimension-reduction step. Last, theremaining cross-sectional dependence is modeled via a GMMN, the maincontribution of this work. GMMNs are highly flexible and easy to simulate from,which is a major advantage over the copula--GARCH approach. Applicationsinvolving yield curve modeling and the analysis of foreign exchange ratereturns demonstrate the utility of the GMMN-GARCH approach, especially in termsof producing better empirical predictive distributions and making betterprobabilistic forecasts. All results are reproducible with the demoGMMN_MTS_paper of the R package gnn."^^schema:Text ;
    schema:author "Avinash Prasad"^^schema:Person,
        "Marius Hofert"^^schema:Person,
        "Mu Zhu"^^schema:Person ;
    schema:dateModified "2020-10-02T14:54:36Z"^^schema:DateTime ;
    schema:datePublished "2020-02-25T03:26:52Z"^^schema:DateTime ;
    schema:genre "62H99, 65C60, 60E05, 00A72, 65C10, 62M10"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ME"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multivariate time-series modeling with generative neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.10645v2"^^schema:URL .

<888> a schema:ScholarlyArticle ;
    schema:abstract "A family of super deep networks, referred to as residual networks or ResNet,achieved record-beating performance in various visual tasks such as imagerecognition, object detection, and semantic segmentation. The ability to trainvery deep networks naturally pushed the researchers to use enormous resourcesto achieve the best performance. Consequently, in many applications super deepresidual networks were employed for just a marginal improvement in performance.In this paper, we propose epsilon-ResNet that allows us to automaticallydiscard redundant layers, which produces responses that are smaller than athreshold epsilon, with a marginal or no loss in performance. Theepsilon-ResNet architecture can be achieved using a few additional rectifiedlinear units in the original ResNet. Our method does not use any additionalvariables nor numerous trials like other hyper-parameter optimizationtechniques. The layer selection is achieved using a single training process andthe evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNetdatasets. In some instances, we achieve about 80% reduction in the number ofparameters."^^schema:Text ;
    schema:author "Srikumar Ramalingam"^^schema:Person,
        "Xin Yu"^^schema:Person,
        "Zhiding Yu"^^schema:Person ;
    schema:dateModified "2019-06-16T00:03:19Z"^^schema:DateTime ;
    schema:datePublished "2018-04-05T03:19:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning Strict Identity Mappings in Deep Residual Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.01661v5"^^schema:URL .

<889> a schema:ScholarlyArticle ;
    schema:abstract "Huge overhead of beam training poses a significant challenge to mmWavecommunications. To address this issue, beam tracking has been widelyinvestigated whereas existing methods are hard to handle serious multipathinterference and non-stationary scenarios. Inspired by the spatial similaritybetween low-frequency and mmWave channels in non-standalone architectures, thispaper proposes to utilize prior low-frequency information to predict theoptimal mmWave beam, where deep learning is adopted to enhance the predictionaccuracy. Specifically, periodically estimated low-frequency channel stateinformation (CSI) is applied to track the movement of user equipment, andtiming offset indicator is proposed to indicate the instant of mmWave beamtraining relative to low-frequency CSI estimation. Meanwhile, long-short termmemory networks based dedicated models are designed to implement theprediction. Simulation results show that our proposed scheme can achieve higherbeamforming gain than the conventional methods while requiring little overheadof mmWave beam training."^^schema:Text ;
    schema:author "Dongxuan He"^^schema:Person,
        "Hancun Sun"^^schema:Person,
        "Ke Ma"^^schema:Person,
        "Zhaocheng Wang"^^schema:Person ;
    schema:dateModified "2021-02-08T08:53:58Z"^^schema:DateTime ;
    schema:datePublished "2020-10-30T08:59:58Z"^^schema:DateTime ;
    schema:genre "eess.SP"^^schema:Text ;
    schema:headline "Deep Learning Assisted mmWave Beam Prediction with Prior Low-frequency  Information"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.02332v2"^^schema:URL .

<89> a schema:ScholarlyArticle ;
    schema:abstract "We show how to turn any classifier that classifies well under Gaussian noiseinto a new classifier that is certifiably robust to adversarial perturbationsunder the $\\ell_2$ norm. This \"randomized smoothing\" technique has beenproposed recently in the literature, but existing guarantees are loose. Weprove a tight robustness guarantee in $\\ell_2$ norm for smoothing with Gaussiannoise. We use randomized smoothing to obtain an ImageNet classifier with e.g. acertified top-1 accuracy of 49% under adversarial perturbations with $\\ell_2$norm less than 0.5 (=127/255). No certified defense has been shown feasible onImageNet except for smoothing. On smaller-scale datasets where competingapproaches to certified $\\ell_2$ robustness are viable, smoothing delivershigher certified accuracies. Our strong empirical results suggest thatrandomized smoothing is a promising direction for future research intoadversarially robust classification. Code and models are available athttp://github.com/locuslab/smoothing."^^schema:Text ;
    schema:author "Elan Rosenfeld"^^schema:Person,
        "J. Zico Kolter"^^schema:Person,
        "Jeremy M Cohen"^^schema:Person ;
    schema:commentCount "202"^^schema:Integer ;
    schema:dateModified "2019-06-15T07:40:33Z"^^schema:DateTime ;
    schema:datePublished "2019-02-08T02:08:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Certified Adversarial Robustness via Randomized Smoothing"^^schema:Text ;
    schema:publisher "ICML, 1310-1320"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1902.02918v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=7039519782328477041&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<890> a schema:ScholarlyArticle ;
    schema:abstract "Federated Learning (FL) is currently the most widely adopted framework forcollaborative training of (deep) machine learning models under privacyconstraints. Albeit it's popularity, it has been observed that FederatedLearning yields suboptimal results if the local clients' data distributionsdiverge. To address this issue, we present Clustered Federated Learning (CFL),a novel Federated Multi-Task Learning (FMTL) framework, which exploitsgeometric properties of the FL loss surface, to group the client populationinto clusters with jointly trainable data distributions. In contrast toexisting FMTL approaches, CFL does not require any modifications to the FLcommunication protocol to be made, is applicable to general non-convexobjectives (in particular deep neural networks) and comes with strongmathematical guarantees on the clustering quality. CFL is flexible enough tohandle client populations that vary over time and can be implemented in aprivacy preserving way. As clustering is only performed after FederatedLearning has converged to a stationary point, CFL can be viewed as apost-processing method that will always achieve greater or equal performancethan conventional FL by allowing clients to arrive at more specialized models.We verify our theoretical analysis in experiments with deep convolutional andrecurrent neural networks on commonly used Federated Learning datasets."^^schema:Text ;
    schema:author "Felix Sattler"^^schema:Person,
        "Klaus-Robert Müller"^^schema:Person,
        "Wojciech Samek"^^schema:Person ;
    schema:dateModified "2019-10-04T15:31:09Z"^^schema:DateTime ;
    schema:datePublished "2019-10-04T15:31:09Z"^^schema:DateTime ;
    schema:genre "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Clustered Federated Learning: Model-Agnostic Distributed Multi-Task  Optimization under Privacy Constraints"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.01991v1"^^schema:URL .

<891> a schema:ScholarlyArticle ;
    schema:abstract "Value iteration networks (VINs) have been demonstrated to have a goodgeneralization ability for reinforcement learning tasks across similar domains.However, based on our experiments, a policy learned by VINs still fail togeneralize well on the domain whose action space and feature space are notidentical to those in the domain where it is trained. In this paper, we proposea transfer learning approach on top of VINs, termed Transfer VINs (TVINs), suchthat a learned policy from a source domain can be generalized to a targetdomain with only limited training data, even if the source domain and thetarget domain have domain-specific actions and features. We empirically verifythat our proposed TVINs outperform VINs when the source and the target domainshave similar but not identical action and feature spaces. Furthermore, we showthat the performance improvement is consistent across different environments,maze sizes, dataset sizes as well as different values of hyperparameters suchas number of iteration and kernel size."^^schema:Text ;
    schema:author "Bin Zhong"^^schema:Person,
        "Hankz Hankui Zhuo"^^schema:Person,
        "Jin Xu"^^schema:Person,
        "Junyi Shen"^^schema:Person,
        "Sinno Jialin Pan"^^schema:Person ;
    schema:dateModified "2019-11-27T01:55:19Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T08:07:49Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Transfer Value Iteration Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.05701v2"^^schema:URL .

<892> a schema:ScholarlyArticle ;
    schema:abstract "We address one-shot imitation learning, where the goal is to execute apreviously unseen task based on a single demonstration. While there has beenexciting progress in this direction, most of the approaches still require a fewhundred tasks for meta-training, which limits the scalability of theapproaches. Our main contribution is to formulate one-shot imitation learningas a symbolic planning problem along with the symbol grounding problem. Thisformulation disentangles the policy execution from the inter-taskgeneralization and leads to better data efficiency. The key technical challengeis that the symbol grounding is prone to error with limited training data andleads to subsequent symbolic planning failures. We address this challenge byproposing a continuous relaxation of the discrete symbolic planner thatdirectly plans on the probabilistic outputs of the symbol grounding model. Ourcontinuous relaxation of the planner can still leverage the informationcontained in the probabilistic symbol grounding and significantly improve overthe baseline planner for the one-shot imitation learning tasks without usinglarge training data."^^schema:Text ;
    schema:author "Animesh Garg"^^schema:Person,
        "Danfei Xu"^^schema:Person,
        "De-An Huang"^^schema:Person,
        "Juan Carlos Niebles"^^schema:Person,
        "Li Fei-Fei"^^schema:Person,
        "Silvio Savarese"^^schema:Person,
        "Yuke Zhu"^^schema:Person ;
    schema:dateModified "2019-11-05T02:58:19Z"^^schema:DateTime ;
    schema:datePublished "2019-08-16T16:28:12Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Continuous Relaxation of Symbolic Planner for One-Shot Imitation  Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.06769v2"^^schema:URL .

<893> a schema:ScholarlyArticle ;
    schema:abstract "Convolutional neural networks (CNNs) are fragile to small perturbations inthe input images. These networks are thus prone to malicious attacks thatperturb the inputs to force a misclassification. Such slightly manipulatedimages aimed at deceiving the classifier are known as adversarial images. Inthis work, we investigate statistical differences between natural images andadversarial ones. More precisely, we show that employing a proper imagetransformation and for a class of adversarial attacks, the distribution of theleading digit of the pixels in adversarial images deviates from Benford's law.The stronger the attack, the more distant the resulting distribution is fromBenford's law. Our analysis provides a detailed investigation of this newapproach that can serve as a basis for alternative adversarial exampledetection methods that do not need to modify the original CNN classifierneither work on the raw high-dimensional pixels as features to defend againstattacks."^^schema:Text ;
    schema:author "Eric A. Antonelo"^^schema:Person,
        "Fabio L. Baldissera"^^schema:Person,
        "João G. Zago"^^schema:Person,
        "Rodrigo T. Saad"^^schema:Person ;
    schema:dateModified "2021-02-09T02:50:29Z"^^schema:DateTime ;
    schema:datePublished "2021-02-09T02:50:29Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Benford's law: what does it say on adversarial images?"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.04615v1"^^schema:URL .

<894> a schema:ScholarlyArticle ;
    schema:abstract "Using tools from category theory, we provide a framework where artificialneural networks, and their architectures, can be formally described. We firstdefine the notion of machine in a general categorical context, and show howsimple machines can be combined into more complex ones. We explore finite- andinfinite-depth machines, which generalize neural networks and neural ordinarydifferential equations. Borrowing ideas from functional analysis and kernelmethods, we build complete, normed, infinite-dimensional spaces of machines,and discuss how to find optimal architectures and parameters -- within thosespaces -- to solve a given computational problem. In our numerical experiments,these kernel-inspired networks can outperform classical neural networks whenthe training dataset is small."^^schema:Text ;
    schema:author "Mattia G. Bergomi"^^schema:Person,
        "Patrizio Frosini"^^schema:Person,
        "Pietro Vertechi"^^schema:Person ;
    schema:dateModified "2020-07-08T16:24:55Z"^^schema:DateTime ;
    schema:datePublished "2020-07-06T14:27:06Z"^^schema:DateTime ;
    schema:genre "18A20, 47L05"^^schema:Text,
        "I.2.6"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Parametric machines: a fresh approach to architecture search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02777v2"^^schema:URL .

<895> a schema:ScholarlyArticle ;
    schema:abstract "The use of $\\ell_p$ $(p=1,2)$ norms has largely dominated the measurement ofloss in neural networks due to their simplicity and analytical properties.However, when used to assess the loss of visual information, these simple normsare not very consistent with human perception. Here, we describe a different\"proximal\" approach to optimize image analysis networks against quantitativeperceptual models. Specifically, we construct a proxy network, broadly termedProxIQA, which mimics the perceptual model while serving as a loss layer of thenetwork. We experimentally demonstrate how this optimization framework can beapplied to train an end-to-end optimized image compression network. By buildingon top of an existing deep image compression model, we are able to demonstratea bitrate reduction of as much as $31\\%$ over MSE optimization, given aspecified perceptual quality (VMAF) level."^^schema:Text ;
    schema:author "Alan C. Bovik"^^schema:Person,
        "Andrey Norkin"^^schema:Person,
        "Christos G. Bampis"^^schema:Person,
        "Li-Heng Chen"^^schema:Person,
        "Zhi Li"^^schema:Person ;
    schema:dateModified "2020-10-29T15:48:02Z"^^schema:DateTime ;
    schema:datePublished "2019-10-19T21:07:33Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image  Compression"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.08845v2"^^schema:URL .

<896> a schema:ScholarlyArticle ;
    schema:abstract "Optimization of Binarized Neural Networks (BNNs) currently relies onreal-valued latent weights to accumulate small update steps. In this paper, weargue that these latent weights cannot be treated analogously to weights inreal-valued networks. Instead their main role is to provide inertia duringtraining. We interpret current methods in terms of inertia and provide novelinsights into the optimization of BNNs. We subsequently introduce the firstoptimizer specifically designed for BNNs, Binary Optimizer (Bop), anddemonstrate its performance on CIFAR-10 and ImageNet. Together, theredefinition of latent weights as inertia and the introduction of Bop enable abetter understanding of BNN optimization and open up the way for furtherimprovements in training methodologies for BNNs. Code is available at:https://github.com/plumerai/rethinking-bnn-optimization"^^schema:Text ;
    schema:author "James Widdicombe"^^schema:Person,
        "Koen Helwegen"^^schema:Person,
        "Kwang-Ting Cheng"^^schema:Person,
        "Lukas Geiger"^^schema:Person,
        "Roeland Nusselder"^^schema:Person,
        "Zechun Liu"^^schema:Person ;
    schema:dateModified "2019-11-06T16:40:41Z"^^schema:DateTime ;
    schema:datePublished "2019-06-05T16:32:39Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Latent Weights Do Not Exist: Rethinking Binarized Neural Network  Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02107v2"^^schema:URL .

<897> a schema:ScholarlyArticle ;
    schema:abstract "To reduce the resource demand of neural network (NN) inference systems, ithas been proposed to use approximate memory, in which the supply voltage andthe timing parameters are tuned trading accuracy with energy consumption andperformance. Tuning these parameters aggressively leads to bit errors, whichcan be tolerated by NNs when bit flips are injected during training. However,bit flip training, which is the state of the art for achieving bit errortolerance, does not scale well; it leads to massive overheads and cannot beapplied for high bit error rates (BERs). Alternative methods to achieve biterror tolerance in NNs are needed, but the underlying principles behind the biterror tolerance of NNs have not been reported yet. With this lack ofunderstanding, further progress in the research on NN bit error tolerance willbe restrained.  In this study, our objective is to investigate the internal changes in theNNs that bit flip training causes, with a focus on binarized NNs (BNNs). Tothis end, we quantify the properties of bit error tolerant BNNs with twometrics. First, we propose a neuron-level bit error tolerance metric, whichcalculates the margin between the pre-activation values and batch normalizationthresholds. Secondly, to capture the effects of bit error tolerance on theinterplay of neurons, we propose an inter-neuron bit error tolerance metric,which measures the importance of each neuron and computes the variance over allimportance values. Our experimental results support that these two metrics arestrongly related to bit error tolerance."^^schema:Text ;
    schema:author "Jian-Jia Chen"^^schema:Person,
        "Katharina Morik"^^schema:Person,
        "Kuan-Hsun Chen"^^schema:Person,
        "Lukas Pfahler"^^schema:Person,
        "Mario Günzel"^^schema:Person,
        "Mikail Yayla"^^schema:Person,
        "Rodion Novkin"^^schema:Person,
        "Sebastian Buschjäger"^^schema:Person ;
    schema:dateModified "2021-02-02T06:44:55Z"^^schema:DateTime ;
    schema:datePublished "2021-02-02T06:44:55Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Bit Error Tolerance Metrics for Binarized Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.01344v1"^^schema:URL .

<898> a schema:ScholarlyArticle ;
    schema:abstract "We propose a continuous neural network architecture, termed ExplainableTensorized Neural Ordinary Differential Equations (ETN-ODE), for multi-steptime series prediction at arbitrary time points. Unlike the existingapproaches, which mainly handle univariate time series for multi-stepprediction or multivariate time series for single-step prediction, ETN-ODEcould model multivariate time series for arbitrary-step prediction. Inaddition, it enjoys a tandem attention, w.r.t. temporal attention and variableattention, being able to provide explainable insights into the data.Specifically, ETN-ODE combines an explainable Tensorized Gated Recurrent Unit(Tensorized GRU or TGRU) with Ordinary Differential Equations (ODE). Thederivative of the latent states is parameterized with a neural network. Thiscontinuous-time ODE network enables a multi-step prediction at arbitrary timepoints. We quantitatively and qualitatively demonstrate the effectiveness andthe interpretability of ETN-ODE on five different multi-step prediction tasksand one arbitrary-step prediction task. Extensive experiments show that ETN-ODEcan lead to accurate predictions at arbitrary time points while attaining bestperformance against the baseline methods in standard multi-step time seriesprediction."^^schema:Text ;
    schema:author "Kaizhu Huang"^^schema:Person,
        "Penglei Gao"^^schema:Person,
        "Rui Zhang"^^schema:Person,
        "Xi Yang"^^schema:Person ;
    schema:dateModified "2020-11-26T08:29:50Z"^^schema:DateTime ;
    schema:datePublished "2020-11-26T08:29:50Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Explainable Tensorized Neural Ordinary Differential Equations  forArbitrary-step Time Series Prediction"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.13174v1"^^schema:URL .

<899> a schema:ScholarlyArticle ;
    schema:abstract "Currently, many applications in Machine Learning are based on define newmodels to extract more information about data, In this case Deep ReinforcementLearning with the most common application in video games like Atari, Mario, andothers causes an impact in how to computers can learning by himself with onlyinformation called rewards obtained from any action. There is a lot ofalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposedby DeepMind used in AlphaZero and Go. In this document, We proposed DeepRecurrent Double Q-Learning that is an implementation of Deep ReinforcementLearning using Double Q-Learning algorithms and Recurrent Networks like LSTMand DRQN."^^schema:Text ;
    schema:author "Felipe Moreno-Vera"^^schema:Person ;
    schema:dateModified "2019-10-17T21:45:01Z"^^schema:DateTime ;
    schema:datePublished "2019-08-16T15:56:16Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Performing Deep Recurrent Double Q-Learning for Atari Games"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1908.06040v2"^^schema:URL .

<9> a schema:ScholarlyArticle ;
    schema:abstract "It has long been known that a single-layer fully-connected neural networkwith an i.i.d. prior over its parameters is equivalent to a Gaussian process(GP), in the limit of infinite network width. This correspondence enables exactBayesian inference for infinite width neural networks on regression tasks bymeans of evaluating the corresponding GP. Recently, kernel functions whichmimic multi-layer random neural networks have been developed, but only outsideof a Bayesian framework. As such, previous work has not identified that thesekernels can be used as covariance functions for GPs and allow fully Bayesianprediction with a deep neural network.  In this work, we derive the exact equivalence between infinitely wide deepnetworks and GPs. We further develop a computationally efficient pipeline tocompute the covariance function for these GPs. We then use the resulting GPs toperform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10.We observe that trained neural network accuracy approaches that of thecorresponding GP with increasing layer width, and that the GP uncertainty isstrongly correlated with trained network prediction error. We further find thattest performance increases as finite-width trained networks are made wider andmore similar to a GP, and thus that GP predictions typically outperform thoseof finite-width networks. Finally we connect the performance of these GPs tothe recent theory of signal propagation in random neural networks."^^schema:Text ;
    schema:author "Jaehoon Lee"^^schema:Person,
        "Jascha Sohl-Dickstein"^^schema:Person,
        "Jeffrey Pennington"^^schema:Person,
        "Roman Novak"^^schema:Person,
        "Samuel S. Schoenholz"^^schema:Person,
        "Yasaman Bahri"^^schema:Person ;
    schema:commentCount "251"^^schema:Integer ;
    schema:dateModified "2018-03-03T00:45:00Z"^^schema:DateTime ;
    schema:datePublished "2017-11-01T02:13:25Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Deep Neural Networks as Gaussian Processes"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1711.00165v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=6709509064500094656&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<90> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents an end-to-end trainable fast scene text detector, namedTextBoxes, which detects scene text with both high accuracy and efficiency in asingle network forward pass, involving no post-process except for a standardnon-maximum suppression. TextBoxes outperforms competing methods in terms oftext localization accuracy and is much faster, taking only 0.09s per image in afast implementation. Furthermore, combined with a text recognizer, TextBoxessignificantly outperforms state-of-the-art approaches on word spotting andend-to-end text recognition tasks."^^schema:Text ;
    schema:author "Baoguang Shi"^^schema:Person,
        "Minghui Liao"^^schema:Person,
        "Wenyu Liu"^^schema:Person,
        "Xiang Bai"^^schema:Person,
        "Xinggang Wang"^^schema:Person ;
    schema:commentCount "347"^^schema:Integer ;
    schema:dateModified "2016-11-21T13:35:15Z"^^schema:DateTime ;
    schema:datePublished "2016-11-21T13:35:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "TextBoxes: A Fast Text Detector with a Single Deep Neural Network"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.06779v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=1599895949788746925&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<900> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel neural network architecture, termed Decomposer-Composer,for semantic structure-aware 3D shape modeling. Our method utilizes anauto-encoder-based pipeline, and produces a novel factorized shape embeddingspace, where the semantic structure of the shape collection translates into adata-dependent sub-space factorization, and where shape composition anddecomposition become simple linear operations on the embedding coordinates. Wefurther propose to model shape assembly using an explicit learned partdeformation module, which utilizes a 3D spatial transformer network to performan in-network volumetric grid deformation, and which allows us to train thewhole system end-to-end. The resulting network allows us to perform part-levelshape manipulation, unattainable by existing approaches. Our extensive ablationstudy, comparison to baseline methods and qualitative analysis demonstrate theimproved performance of the proposed method."^^schema:Text ;
    schema:author "Anastasia Dubrovina"^^schema:Person,
        "Fei Xia"^^schema:Person,
        "Leonidas Guibas"^^schema:Person,
        "Mira Shalah"^^schema:Person,
        "Panos Achlioptas"^^schema:Person,
        "Raphael Groscot"^^schema:Person ;
    schema:dateModified "2019-10-30T13:53:56Z"^^schema:DateTime ;
    schema:datePublished "2019-01-09T23:25:38Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Composite Shape Modeling via Latent Space Factorization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.02968v2"^^schema:URL .

<901> a schema:ScholarlyArticle ;
    schema:abstract "Machine Learning (ML) has recently been demonstrated to rival expert-levelhuman accuracy in prediction and detection tasks in a variety of domains,including medicine. Despite these impressive findings, however, a key barrierto the full realization of ML's potential in medical prognoses is technologyacceptance. Recent efforts to produce explainable AI (XAI) have made progressin improving the interpretability of some ML models, but these efforts sufferfrom limitations intrinsic to their design: they work best at identifying why asystem fails, but do poorly at explaining when and why a model's prediction iscorrect. We posit that the acceptability of ML predictions in expert domains islimited by two key factors: the machine's horizon of prediction that extendsbeyond human capability, and the inability for machine predictions toincorporate human intuition into their models. We propose the use of a novel MLarchitecture, Neural Ordinary Differential Equations (NODEs) to enhance humanunderstanding and encourage acceptability. Our approach prioritizes humancognitive intuition at the center of the algorithm design, and offers adistribution of predictions rather than single outputs. We explain how thisapproach may significantly improve human-machine collaboration in predictiontasks in expert domains such as medical prognoses. We propose a model anddemonstrate, by expanding a concrete example from the literature, how our modeladvances the vision of future hybrid Human-AI systems."^^schema:Text ;
    schema:author "D. Fompeyrine"^^schema:Person,
        "E. S. Vorm"^^schema:Person,
        "F. Rose"^^schema:Person,
        "G. Pellegrin"^^schema:Person,
        "N. Ricka"^^schema:Person ;
    schema:dateModified "2021-02-08T10:52:23Z"^^schema:DateTime ;
    schema:datePublished "2021-02-08T10:52:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Enhancing Human-Machine Teaming for Medical Prognosis Through Neural  Ordinary Differential Equations (NODEs)"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.04121v1"^^schema:URL .

<902> a schema:ScholarlyArticle ;
    schema:abstract "The common pipeline in autonomous driving systems is highly modular andincludes a perception component which extracts lists of surrounding objects andpasses these lists to a high-level decision component. In this case, leveragingthe benefits of deep reinforcement learning for high-level decision makingrequires special architectures to deal with multiple variable-length sequencesof different object types, such as vehicles, lanes or traffic signs. At thesame time, the architecture has to be able to cover interactions betweentraffic participants in order to find the optimal action to be taken. In thiswork, we propose the novel Deep Scenes architecture, that can learn complexinteraction-aware scene representations based on extensions of either 1) DeepSets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Qoff-policy reinforcement learning algorithms, both outperformingstate-of-the-art methods in evaluations with the publicly available trafficsimulator SUMO."^^schema:Text ;
    schema:author "Gabriel Kalweit"^^schema:Person,
        "Joschka Boedecker"^^schema:Person,
        "Maria Huegle"^^schema:Person,
        "Moritz Werling"^^schema:Person ;
    schema:dateModified "2019-09-30T10:59:11Z"^^schema:DateTime ;
    schema:datePublished "2019-09-30T10:59:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning  in Autonomous Driving"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.13582v1"^^schema:URL .

<903> a schema:ScholarlyArticle ;
    schema:abstract "Despite its popularity, several recent works question the effectiveness ofMAML when test tasks are different from training tasks, thus suggesting varioustask-conditioned methodology to improve the initialization. Instead ofsearching for better task-aware initialization, we focus on a complementaryfactor in MAML framework, inner-loop optimization (or fast adaptation).Consequently, we propose a new weight update rule that greatly enhances thefast adaptation process. Specifically, we introduce a small meta-network thatcan adaptively generate per-step hyperparameters: learning rate and weightdecay coefficients. The experimental results validate that the AdaptiveLearning of hyperparameters for Fast Adaptation (ALFA) is the equally importantingredient that was often neglected in the recent few-shot learning approaches.Surprisingly, fast adaptation from random initialization with ALFA can alreadyoutperform MAML."^^schema:Text ;
    schema:author "Heewon Kim"^^schema:Person,
        "Janghoon Choi"^^schema:Person,
        "Kyoung Mu Lee"^^schema:Person,
        "Myungsub Choi"^^schema:Person,
        "Sungyong Baik"^^schema:Person ;
    schema:dateModified "2020-12-08T06:53:01Z"^^schema:DateTime ;
    schema:datePublished "2020-10-31T08:05:34Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Meta-Learning with Adaptive Hyperparameters"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.00209v2"^^schema:URL .

<904> a schema:ScholarlyArticle ;
    schema:abstract "In this article, we evaluate computational models of natural language withrespect to the universal statistical behaviors of natural language. Statisticalmechanical analyses have revealed that natural language text is characterizedby scaling properties, which quantify the global structure in the vocabularypopulation and the long memory of a text. We study whether five scalingproperties (given by Zipf's law, Heaps' law, Ebeling's method, Taylor's law,and long-range correlation analysis) can serve for evaluation of computationalmodels. Specifically, we test $n$-gram language models, a probabilisticcontext-free grammar (PCFG), language models based on Simon/Pitman-Yorprocesses, neural language models, and generative adversarial networks (GANs)for text generation. Our analysis reveals that language models based onrecurrent neural networks (RNNs) with a gating mechanism (i.e., long short-termmemory, LSTM; a gated recurrent unit, GRU; and quasi-recurrent neural networks,QRNNs) are the only computational models that can reproduce the long memorybehavior of natural language. Furthermore, through comparison with recentlyproposed model-based evaluation methods, we find that the exponent of Taylor'slaw is a good indicator of model quality."^^schema:Text ;
    schema:author "Kumiko Tanaka-Ishii"^^schema:Person,
        "Shuntaro Takahashi"^^schema:Person ;
    schema:dateModified "2019-06-22T03:24:32Z"^^schema:DateTime ;
    schema:datePublished "2019-06-22T03:24:32Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Evaluating Computational Language Models with Scaling Properties of  Natural Language"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.09379v1"^^schema:URL .

<905> a schema:ScholarlyArticle ;
    schema:abstract "Normalizing flows are a powerful technique for obtaining reparameterizablesamples from complex multimodal distributions. Unfortunately current approachesfall short when the underlying space has a non trivial topology, and are onlyavailable for the most basic geometries. Recently normalizing flows inEuclidean space based on Neural ODEs show great promise, yet suffer the samelimitations. Using ideas from differential geometry and geometric controltheory, we describe how neural ODEs can be extended to smooth manifolds. Weshow how vector fields provide a general framework for parameterizing aflexible class of invertible mapping on these spaces and we illustrate howgradient based learning can be performed. As a result we define a generalmethodology for building normalizing flows on manifolds."^^schema:Text ;
    schema:author "Luca Falorsi"^^schema:Person,
        "Patrick Forré"^^schema:Person ;
    schema:dateModified "2020-06-11T17:56:34Z"^^schema:DateTime ;
    schema:datePublished "2020-06-11T17:56:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Neural Ordinary Differential Equations on Manifolds"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.06663v1"^^schema:URL .

<906> a schema:ScholarlyArticle ;
    schema:abstract "How to discover and evaluate the true strength of models quickly andaccurately is one of the key challenges in Neural Architecture Search (NAS). Tocope with this problem, we propose an Architecture-Driven Weight Prediction(ADWP) approach for neural architecture search (NAS). In our approach, we firstdesign an architecture-intensive search space and then train a HyperNetwork byinputting stochastic encoding architecture parameters. In the trainedHyperNetwork, weights of convolution kernels can be well predicted for neuralarchitectures in the search space. Consequently, the target architectures canbe evaluated efficiently without any finetuning, thus enabling us to searchfortheoptimalarchitectureinthespaceofgeneralnetworks (macro-search). Throughreal experiments, we evaluate the performance of the models discovered by theproposed AD-WPNAS and results show that one search procedure can be completedin 4.0 GPU hours on CIFAR-10. Moreover, the discovered model obtains a testerror of 2.41% with only 1.52M parameters which is superior to the bestexisting models."^^schema:Text ;
    schema:author "BoGu"^^schema:Person,
        "ChenjunZhou"^^schema:Person,
        "XuZhang"^^schema:Person ;
    schema:dateModified "2020-03-03T05:06:20Z"^^schema:DateTime ;
    schema:datePublished "2020-03-03T05:06:20Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "ADWPNAS: Architecture-Driven Weight Prediction for Neural Architecture  Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.01335v1"^^schema:URL .

<907> a schema:ScholarlyArticle ;
    schema:abstract "We propose a new method for event extraction (EE) task based on an imitationlearning framework, specifically, inverse reinforcement learning (IRL) viagenerative adversarial network (GAN). The GAN estimates proper rewardsaccording to the difference between the actions committed by the expert (orground truth) and the agent among complicated states in the environment. EEtask benefits from these dynamic rewards because instances and labels yield tovarious extents of difficulty and the gains are expected to be diverse -- e.g.,an ambiguous but correctly detected trigger or argument should receive highgains -- while the traditional RL models usually neglect such differences andpay equal attention on all instances. Moreover, our experiments alsodemonstrate that the proposed framework outperforms state-of-the-art methods,without explicit feature engineering."^^schema:Text ;
    schema:author "Heng Ji"^^schema:Person,
        "Tongtao Zhang"^^schema:Person ;
    schema:dateModified "2018-04-21T02:43:00Z"^^schema:DateTime ;
    schema:datePublished "2018-04-21T02:43:00Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Event Extraction with Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1804.07881v1"^^schema:URL .

<908> a schema:ScholarlyArticle ;
    schema:abstract "Big neural networks trained on large datasets have advanced thestate-of-the-art for a large variety of challenging problems, improvingperformance by a large margin. However, under low memory and limitedcomputational power constraints, the accuracy on the same problems dropsconsiderable. In this paper, we propose a series of techniques thatsignificantly improve the accuracy of binarized neural networks (i.e networkswhere both the features and the weights are binary). We evaluate the proposedimprovements on two diverse tasks: fine-grained recognition (human poseestimation) and large-scale image recognition (ImageNet classification).Specifically, we introduce a series of novel methodological changes including:(a) more appropriate activation functions, (b) reverse-order initialization,(c) progressive quantization, and (d) network stacking and show that theseadditions improve existing state-of-the-art network binarization techniques,significantly. Additionally, for the first time, we also investigate the extentto which network binarization and knowledge distillation can be combined. Whentested on the challenging MPII dataset, our method shows a performanceimprovement of more than 4% in absolute terms. Finally, we further validate ourfindings by applying the proposed techniques for large-scale object recognitionon the Imagenet dataset, on which we report a reduction of error rate by 4%."^^schema:Text ;
    schema:author "Adrian Bulat"^^schema:Person,
        "Georgios Tzimiropoulos"^^schema:Person,
        "Jean Kossaifi"^^schema:Person,
        "Maja Pantic"^^schema:Person ;
    schema:dateModified "2019-04-11T17:55:06Z"^^schema:DateTime ;
    schema:datePublished "2019-04-11T17:55:06Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Improved training of binary networks for human pose estimation and image  recognition"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.05868v1"^^schema:URL .

<909> a schema:ScholarlyArticle ;
    schema:abstract "One of the most promising ways to observe the Universe is by detecting the21cm emission from cosmic neutral hydrogen (HI) through radio-telescopes. Thoseobservations can shed light on fundamental astrophysical questions only ifaccurate theoretical predictions are available. In order to maximize thescientific return of these surveys, those predictions need to include differentobservables and be precise on non-linear scales. Currently, one of the bestways to achieve this is via cosmological hydrodynamic simulations; however, thecomputational cost of these simulations is high -- tens of millions of CPUhours. In this work, we use Wasserstein Generative Adversarial Networks (WGANs)to generate new high-resolution ($35~h^{-1}{\\rm kpc}$) 3D realizations ofcosmic HI at $z=5$. We do so by sampling from a 100-dimension manifold, learnedby the generator, that characterizes the fully non-linear abundance andclustering of cosmic HI from the state-of-the-art simulation IllustrisTNG. Weshow that different statistical properties of the produced samples -- 1D PDF,power spectrum, bispectrum, and void size function -- match very well those ofIllustrisTNG, and outperform state-of-the-art models such as Halo OccupationDistributions (HODs). Our WGAN samples reproduce the abundance of HI across 9orders of magnitude, from the Ly$\\alpha$ forest to Damped Lyman Absorbers. WGANcan produce new samples orders of magnitude faster than hydrodynamicsimulations."^^schema:Text ;
    schema:author "Asena Derin Cengiz"^^schema:Person,
        "Atakan Okan"^^schema:Person,
        "Francisco Villaescusa-Navarro"^^schema:Person,
        "Juan Zamudio-Fernandez"^^schema:Person,
        "Laurence Perreault Levasseur"^^schema:Person,
        "Seda Bilaloglu"^^schema:Person,
        "Shirley Ho"^^schema:Person,
        "Siyu He"^^schema:Person ;
    schema:dateModified "2019-04-29T17:56:01Z"^^schema:DateTime ;
    schema:datePublished "2019-04-29T17:56:01Z"^^schema:DateTime ;
    schema:genre "astro-ph.CO"^^schema:Text,
        "astro-ph.IM"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "HIGAN: Cosmic Neutral Hydrogen with Generative Adversarial Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.12846v1"^^schema:URL .

<91> a schema:ScholarlyArticle ;
    schema:abstract "We propose a practical method for $L_0$ norm regularization for neuralnetworks: pruning the network during training by encouraging weights to becomeexactly zero. Such regularization is interesting since (1) it can greatly speedup training and inference, and (2) it can improve generalization. AIC and BIC,well-known model selection criteria, are special cases of $L_0$ regularization.However, since the $L_0$ norm of weights is non-differentiable, we cannotincorporate it directly as a regularization term in the objective function. Wepropose a solution through the inclusion of a collection of non-negativestochastic gates, which collectively determine which weights to set to zero. Weshow that, somewhat surprisingly, for certain distributions over the gates, theexpected $L_0$ norm of the resulting gated weights is differentiable withrespect to the distribution parameters. We further propose the \\emph{hardconcrete} distribution for the gates, which is obtained by \"stretching\" abinary concrete distribution and then transforming its samples with ahard-sigmoid. The parameters of the distribution over the gates can then bejointly optimized with the original network parameters. As a result our methodallows for straightforward and efficient learning of model structures withstochastic gradient descent and allows for conditional computation in aprincipled way. We perform various experiments to demonstrate the effectivenessof the resulting approach and regularizer."^^schema:Text ;
    schema:author "Christos Louizos"^^schema:Person,
        "Diederik P. Kingma"^^schema:Person,
        "Max Welling"^^schema:Person ;
    schema:commentCount "237"^^schema:Integer ;
    schema:dateModified "2018-06-22T14:54:59Z"^^schema:DateTime ;
    schema:datePublished "2017-12-04T19:20:27Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Sparse Neural Networks through $L_0$ Regularization"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1712.01312v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=16875065764676968506&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<910> a schema:ScholarlyArticle ;
    schema:abstract "We propose a deep network that can be trained to tackle image reconstructionand classification problems that involve detection of multiple objectinstances, without any supervision regarding their whereabouts. The networklearns to extract the most significant top-K patches, and feeds these patchesto a task-specific network -- e.g., auto-encoder or classifier -- to solve adomain specific problem. The challenge in training such a network is thenon-differentiable top-K selection process. To address this issue, we lift thetraining optimization problem by treating the result of top-K selection as aslack variable, resulting in a simple, yet effective, multi-stage training. Ourmethod is able to learn to detect recurrent structures in the training datasetby learning to reconstruct images. It can also learn to localize structureswhen only knowledge on the occurrence of the object is provided, and in doingso it outperforms the state-of-the-art."^^schema:Text ;
    schema:author "Andrea Tagliasacchi"^^schema:Person,
        "Baptiste Angles"^^schema:Person,
        "Kwang Moo Yi"^^schema:Person,
        "Simon Kornblith"^^schema:Person,
        "Yuhe Jin"^^schema:Person ;
    schema:dateModified "2020-12-04T19:19:05Z"^^schema:DateTime ;
    schema:datePublished "2018-11-26T22:49:20Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "MIST: Multiple Instance Spatial Transformer Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.10725v5"^^schema:URL .

<911> a schema:ScholarlyArticle ;
    schema:abstract "Many measurements or observations in computer vision and machine learningmanifest as non-Euclidean data. While recent proposals (like spherical CNN)have extended a number of deep neural network architectures to manifold-valueddata, and this has often provided strong improvements in performance, theliterature on generative models for manifold data is quite sparse. Partly dueto this gap, there are also no modality transfer/translation models formanifold-valued data whereas numerous such methods based on generative modelsare available for natural images. This paper addresses this gap, motivated by aneed in brain imaging -- in doing so, we expand the operating range of certaingenerative models (as well as generative models for modality transfer) fromnatural images to images with manifold-valued measurements. Our main result isthe design of a two-stream version of GLOW (flow-based invertible generativemodels) that can synthesize information of a field of one type ofmanifold-valued measurements given another. On the theoretical side, weintroduce three kinds of invertible layers for manifold-valued data, which arenot only analogous to their functionality in flow-based generative models(e.g., GLOW) but also preserve the key benefits (determinants of the Jacobianare easy to calculate). For experiments, on a large dataset from the HumanConnectome Project (HCP), we show promising results where we can reliably andaccurately reconstruct brain images of a field of orientation distributionfunctions (ODF) from diffusion tensor images (DTI), where the latter has a$5\\times$ faster acquisition time but at the expense of worse angularresolution."^^schema:Text ;
    schema:author "Liu Yang"^^schema:Person,
        "Rudrasis Chakraborty"^^schema:Person,
        "Vikas Singh"^^schema:Person,
        "Xingjian Zhen"^^schema:Person ;
    schema:dateModified "2020-12-18T02:19:18Z"^^schema:DateTime ;
    schema:datePublished "2020-12-18T02:19:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Flow-based Generative Models for Learning Manifold to Manifold Mappings"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.10013v1"^^schema:URL .

<912> a schema:ScholarlyArticle ;
    schema:abstract "This study proposes a novel framework for spectral unmixing by using 1Dconvolution kernels and spectral uncertainty. High-level representations arecomputed from data, and they are further modeled with the Multinomial MixtureModel to estimate fractions under severe spectral uncertainty. Furthermore, anew trainable uncertainty term based on a nonlinear neural network model isintroduced in the reconstruction step. All uncertainty models are optimized byWasserstein Generative Adversarial Network (WGAN) to improve stability andcapture uncertainty. Experiments are performed on both real and syntheticdatasets. The results validate that the proposed method obtainsstate-of-the-art performance, especially for the real datasets compared to thebaselines. Project page at: https://github.com/savasozkan/dscn."^^schema:Text ;
    schema:author "Gozde Bozdagi Akar"^^schema:Person,
        "Savas Ozkan"^^schema:Person ;
    schema:dateModified "2020-12-12T16:49:01Z"^^schema:DateTime ;
    schema:datePublished "2020-12-12T16:49:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Spectral Unmixing With Multinomial Mixture Kernel and Wasserstein  Generative Adversarial Loss"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.06859v1"^^schema:URL .

<913> a schema:ScholarlyArticle ;
    schema:abstract "Image clustering is an important but challenging task in machine learning. Asin most image processing areas, the latest improvements came from models basedon the deep learning approach. However, classical deep learning methods haveproblems to deal with spatial image transformations like scale and rotation. Inthis paper, we propose the use of visual attention techniques to reduce thisproblem in image clustering methods. We evaluate the combination of a deepimage clustering model called Deep Adaptive Clustering (DAC) with the SpatialTransformer Networks (STN). The proposed model is evaluated in the datasetsMNIST and FashionMNIST and outperformed the baseline model."^^schema:Text ;
    schema:author "Cleber Zanchettin"^^schema:Person,
        "Thiago V. M. Souza"^^schema:Person ;
    schema:dateModified "2019-10-24T13:43:23Z"^^schema:DateTime ;
    schema:datePublished "2019-02-09T01:56:24Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Improving Deep Image Clustering With Spatial Transformer Layers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1902.05401v2"^^schema:URL .

<914> a schema:ScholarlyArticle ;
    schema:abstract "We introduce a new large-scale NLI benchmark dataset, collected via aniterative, adversarial human-and-model-in-the-loop procedure. We show thattraining models on this new dataset leads to state-of-the-art performance on avariety of popular NLI benchmarks, while posing a more difficult challenge withits new test set. Our analysis sheds light on the shortcomings of currentstate-of-the-art models, and shows that non-expert annotators are successful atfinding their weaknesses. The data collection method can be applied in anever-ending learning scenario, becoming a moving target for NLU, rather than astatic benchmark that will quickly saturate."^^schema:Text ;
    schema:author "Adina Williams"^^schema:Person,
        "Douwe Kiela"^^schema:Person,
        "Emily Dinan"^^schema:Person,
        "Jason Weston"^^schema:Person,
        "Mohit Bansal"^^schema:Person,
        "Yixin Nie"^^schema:Person ;
    schema:dateModified "2020-05-06T17:01:56Z"^^schema:DateTime ;
    schema:datePublished "2019-10-31T16:50:43Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Adversarial NLI: A New Benchmark for Natural Language Understanding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.14599v2"^^schema:URL .

<915> a schema:ScholarlyArticle ;
    schema:abstract "The effectiveness of a language model is influenced by its tokenrepresentations, which must encode contextual information and handle the sameword form having a plurality of meanings (polysemy). Currently, none of thecommon language modelling architectures explicitly model polysemy. We propose alanguage model which not only predicts the next word, but also its sense incontext. We argue that this higher prediction granularity may be useful for endtasks such as assistive writing, and allow for more a precise linking oflanguage models with knowledge bases. We find that multi-sense languagemodelling requires architectures that go beyond standard language models, andhere propose a structured prediction framework that decomposes the task into aword followed by a sense prediction task. For sense prediction, we utilise aGraph Attention Network, which encodes definitions and example uses of wordsenses. Overall, we find that multi-sense language modelling is a highlychallenging task, and suggest that future work focus on the creation of moreannotated training datasets."^^schema:Text ;
    schema:author "Andrea Lekkas"^^schema:Person,
        "Isabelle Augenstein"^^schema:Person,
        "Peter Schneider-Kamp"^^schema:Person ;
    schema:dateModified "2020-12-10T16:06:05Z"^^schema:DateTime ;
    schema:datePublished "2020-12-10T16:06:05Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Multi-Sense Language Modelling"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.05776v1"^^schema:URL .

<916> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel framework for Deep Reinforcement Learning (DRL) in modularrobotics to train a robot directly from joint states, using traditional robotictools. We use an state-of-the-art implementation of the Proximal PolicyOptimization, Trust Region Policy Optimization and Actor-CriticKronecker-Factored Trust Region algorithms to learn policies in four differentModular Articulated Robotic Arm (MARA) environments. We support this processusing a framework that communicates with typical tools used in robotics, suchas Gazebo and Robot Operating System 2 (ROS 2). We evaluate several algorithmsin modular robots with an empirical study in simulation."^^schema:Text ;
    schema:author "Alejandro Solano Rueda"^^schema:Person,
        "Elias Barba Moral"^^schema:Person,
        "Lander Usategui San Juan"^^schema:Person,
        "Nestor Gonzalez Lopez"^^schema:Person,
        "Risto Kojcev"^^schema:Person,
        "Víctor Mayoral Vilches"^^schema:Person,
        "Yue Leire Erro Nuin"^^schema:Person ;
    schema:dateModified "2019-03-18T05:27:29Z"^^schema:DateTime ;
    schema:datePublished "2019-03-14T22:13:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "ROS2Learn: a reinforcement learning framework for ROS 2"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1903.06282v2"^^schema:URL .

<917> a schema:ScholarlyArticle ;
    schema:abstract "Recent years have witnessed a tremendous improvement of deep reinforcementlearning. However, a challenging problem is that an agent may suffer frominefficient exploration, particularly for on-policy methods. Previousexploration methods either rely on complex structure to estimate the novelty ofstates, or incur sensitive hyper-parameters causing instability. We propose anefficient exploration method, Multi-Path Policy Optimization (MPPO), which doesnot incur high computation cost and ensures stability. MPPO maintains anefficient mechanism that effectively utilizes a population of diverse policiesto enable better exploration, especially in sparse environments. We also give atheoretical guarantee of the stable performance. We build our scheme upon twowidely-adopted on-policy methods, the Trust-Region Policy Optimizationalgorithm and Proximal Policy Optimization algorithm. We conduct extensiveexperiments on several MuJoCo tasks and their sparsified variants to fairlyevaluate the proposed method. Results show that MPPO significantly outperformsstate-of-the-art exploration methods in terms of both sample efficiency andfinal performance."^^schema:Text ;
    schema:author "Ling Pan"^^schema:Person,
        "Longbo Huang"^^schema:Person,
        "Qingpeng Cai"^^schema:Person ;
    schema:dateModified "2020-02-14T15:17:23Z"^^schema:DateTime ;
    schema:datePublished "2019-11-11T12:19:23Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multi-Path Policy Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1911.04207v3"^^schema:URL .

<918> a schema:ScholarlyArticle ;
    schema:abstract "In this draft, which reports on work in progress, we 1) adapt the informationbottleneck functional by replacing the compression term by class-conditionalcompression, 2) relax this functional using a variational bound related toclass-conditional disentanglement, 3) consider this functional as a trainingobjective for stochastic neural networks, and 4) show that the latentrepresentations are learned such that they can be used in a naive Bayesclassifier. We continue by suggesting a series of experiments along the linesof Nonlinear In-formation Bottleneck [Kolchinsky et al., 2018], DeepVariational Information Bottleneck [Alemi et al., 2017], and InformationDropout [Achille and Soatto, 2018]. We furthermore suggest a neural networkwhere the decoder architecture is a parameterized naive Bayes decoder."^^schema:Text ;
    schema:author "Bernhard C. Geiger"^^schema:Person,
        "Rana Ali Amjad"^^schema:Person ;
    schema:dateModified "2019-06-06T13:32:54Z"^^schema:DateTime ;
    schema:datePublished "2019-06-06T13:32:54Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Class-Conditional Compression and Disentanglement: Bridging the Gap  between Neural Networks and Naive Bayes Classifiers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.02576v1"^^schema:URL .

<919> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge tracing is the task of modeling each student's mastery of knowledgeconcepts (KCs) as (s)he engages with a sequence of learning activities. Eachstudent's knowledge is modeled by estimating the performance of the student onthe learning activities. It is an important research area for providing apersonalized learning platform to students. In recent years, methods based onRecurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) andDynamic Key-Value Memory Network (DKVMN) outperformed all the traditionalmethods because of their ability to capture complex representation of humanlearning. However, these methods face the issue of not generalizing well whiledealing with sparse data which is the case with real-world data as studentsinteract with few KCs. In order to address this issue, we develop an approachthat identifies the KCs from the student's past activities that are\\textit{relevant} to the given KC and predicts his/her mastery based on therelatively few KCs that it picked. Since predictions are made based onrelatively few past activities, it handles the data sparsity problem betterthan the methods based on RNN. For identifying the relevance between the KCs,we propose a self-attention based approach, Self Attentive Knowledge Tracing(SAKT). Extensive experimentation on a variety of real-world dataset shows thatour model outperforms the state-of-the-art models for knowledge tracing,improving AUC by 4.43% on average."^^schema:Text ;
    schema:author "George Karypis"^^schema:Person,
        "Shalini Pandey"^^schema:Person ;
    schema:dateModified "2019-07-16T04:47:35Z"^^schema:DateTime ;
    schema:datePublished "2019-07-16T04:47:35Z"^^schema:DateTime ;
    schema:genre "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A Self-Attentive model for Knowledge Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1907.06837v1"^^schema:URL .

<92> a schema:ScholarlyArticle ;
    schema:abstract "We present a machine learning-based approach to lossy image compression whichoutperforms all existing codecs, while running in real-time.  Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets ofgeneric images across all quality levels. At the same time, our codec isdesigned to be lightweight and deployable: for example, it can encode or decodethe Kodak dataset in around 10ms per image on GPU.  Our architecture is an autoencoder featuring pyramidal analysis, an adaptivecoding module, and regularization of the expected codelength. We alsosupplement our approach with adversarial training specialized towards use in acompression setting: this enables us to produce visually pleasingreconstructions for very low bitrates."^^schema:Text ;
    schema:author "Lubomir Bourdev"^^schema:Person,
        "Oren Rippel"^^schema:Person ;
    schema:commentCount "217"^^schema:Integer ;
    schema:dateModified "2017-05-16T17:51:07Z"^^schema:DateTime ;
    schema:datePublished "2017-05-16T17:51:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Real-Time Adaptive Image Compression"^^schema:Text ;
    schema:publisher "ICML, 2922-2930"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1705.05823v1"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5970681635183362212&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<920> a schema:ScholarlyArticle ;
    schema:abstract "Natural policy gradient (NPG) methods are among the most widely used policyoptimization algorithms in contemporary reinforcement learning. This class ofmethods is often applied in conjunction with entropy regularization -- analgorithmic scheme that encourages exploration -- and is closely related tosoft policy iteration and trust region policy optimization. Despite theempirical success, the theoretical underpinnings for NPG methods remain limitedeven for the tabular setting. This paper develops $\\textit{non-asymptotic}$convergence guarantees for entropy-regularized NPG methods under softmaxparameterization, focusing on discounted Markov decision processes (MDPs).Assuming access to exact policy evaluation, we demonstrate that the algorithmconverges linearly -- or even quadratically once it enters a local regionaround the optimal policy -- when computing optimal value functions of theregularized MDP. Moreover, the algorithm is provably stable vis-\\`a-visinexactness of policy evaluation. Our convergence results accommodate a widerange of learning rates, and shed light upon the role of entropy regularizationin enabling fast convergence."^^schema:Text ;
    schema:author "Chen Cheng"^^schema:Person,
        "Shicong Cen"^^schema:Person,
        "Yuejie Chi"^^schema:Person,
        "Yuting Wei"^^schema:Person,
        "Yuxin Chen"^^schema:Person ;
    schema:dateModified "2020-09-24T19:16:41Z"^^schema:DateTime ;
    schema:datePublished "2020-07-13T17:58:41Z"^^schema:DateTime ;
    schema:genre "cs.IT"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.IT"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Fast Global Convergence of Natural Policy Gradient Methods with Entropy  Regularization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.06558v4"^^schema:URL .

<921> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel image transformation scheme using generative adversarialnetworks (GANs) for privacy-preserving deep neural networks (DNNs). Theproposed scheme enables us not only to apply images without visual informationto DNNs, but also to enhance robustness against ciphertext-only attacks (COAs)including DNN-based attacks. In this paper, the proposed transformation schemeis demonstrated to be able to protect visual information on plain images, andthe visually-protected images are directly applied to DNNs forprivacy-preserving image classification. Since the proposed scheme utilizesGANs, there is no need to manage encryption keys. In an image classificationexperiment, we evaluate the effectiveness of the proposed scheme in terms ofclassification accuracy and robustness against COAs."^^schema:Text ;
    schema:author "Hitoshi Kiya"^^schema:Person,
        "Warit Sirichotedumrong"^^schema:Person ;
    schema:dateModified "2020-06-02T01:57:21Z"^^schema:DateTime ;
    schema:datePublished "2020-06-02T01:57:21Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "A GAN-Based Image Transformation Scheme for Privacy-Preserving Deep  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.01342v1"^^schema:URL .

<922> a schema:ScholarlyArticle ;
    schema:abstract "Modern Convolutional Neural Networks (CNN) are extremely powerful on a rangeof computer vision tasks. However, their performance may degrade when the datais characterised by large intra-class variability caused by spatialtransformations. The Spatial Transformer Network (STN) is currently the methodof choice for providing CNNs the ability to remove those transformations andimprove performance in an end-to-end learning framework. In this paper, wepropose Densely Fused Spatial Transformer Network (DeSTNet), which, to our bestknowledge, is the first dense fusion pattern for combining multiple STNs.Specifically, we show how changing the connectivity pattern of multiple STNsfrom sequential to dense leads to more powerful alignment modules. Extensiveexperiments on three benchmarks namely, MNIST, GTSRB, and IDocDB show that theproposed technique outperforms related state-of-the-art methods (i.e., STNs andCSTNs) both in terms of accuracy and robustness."^^schema:Text ;
    schema:author "Christos Sagonas"^^schema:Person,
        "Jacques Calì"^^schema:Person,
        "Roberto Annunziata"^^schema:Person ;
    schema:dateModified "2018-07-16T10:27:31Z"^^schema:DateTime ;
    schema:datePublished "2018-07-11T10:06:32Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "DeSTNet: Densely Fused Spatial Transformer Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1807.04050v2"^^schema:URL .

<923> a schema:ScholarlyArticle ;
    schema:abstract "Auto-encoders are among the most popular neural network architecture fordimension reduction. They are composed of two parts: the encoder which maps themodel distribution to a latent manifold and the decoder which maps the latentmanifold to a reconstructed distribution. However, auto-encoders are known toprovoke chaotically scattered data distribution in the latent manifoldresulting in an incomplete reconstructed distribution. Current distancemeasures fail to detect this problem because they are not able to acknowledgethe shape of the data manifolds, i.e. their topological features, and the scaleat which the manifolds should be analyzed. We propose Persistent Homology forWasserstein Auto-Encoders, called PHom-WAE, a new methodology to assess andmeasure the data distribution of a generative model. PHom-WAE minimizes theWasserstein distance between the true distribution and the reconstructeddistribution and uses persistent homology, the study of the topologicalfeatures of a space at different spatial resolutions, to compare the nature ofthe latent manifold and the reconstructed distribution. Our experimentsunderline the potential of persistent homology for Wasserstein Auto-Encoders incomparison to Variational Auto-Encoders, another type of generative model. Theexperiments are conducted on a real-world data set particularly challenging fortraditional distance measures and auto-encoders. PHom-WAE is the firstmethodology to propose a topological distance measure, the bottleneck distance,for Wasserstein Auto-Encoders used to compare decoded samples of high qualityin the context of credit card transactions."^^schema:Text ;
    schema:author "Francois Petit"^^schema:Person,
        "Gaston Ormazabal"^^schema:Person,
        "Jean Hilger"^^schema:Person,
        "Jeremy Charlier"^^schema:Person,
        "Radu State"^^schema:Person ;
    schema:dateModified "2019-08-12T06:16:58Z"^^schema:DateTime ;
    schema:datePublished "2019-05-24T06:48:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Visualization of AE's Training on Credit Card Transactions with  Persistent Homology"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.13020v2"^^schema:URL .

<924> a schema:ScholarlyArticle ;
    schema:abstract "Differential equations are frequently used in engineering domains, such asmodeling and control of industrial systems, where safety and performanceguarantees are of paramount importance. Traditional physics-based modelingapproaches require domain expertise and are often difficult to tune or adapt tonew systems. In this paper, we show how to model discrete ordinary differentialequations (ODE) with algebraic nonlinearities as deep neural networks withvarying degrees of prior knowledge. We derive the stability guarantees of thenetwork layers based on the implicit constraints imposed on the weight'seigenvalues. Moreover, we show how to use barrier methods to generically handleadditional inequality constraints. We demonstrate the prediction accuracy oflearned neural ODEs evaluated on open-loop simulations compared to ground truthdynamics with bi-linear terms."^^schema:Text ;
    schema:author "Aaron Tuor"^^schema:Person,
        "Draguna Vrabie"^^schema:Person,
        "Jan Drgona"^^schema:Person ;
    schema:dateModified "2020-04-22T22:07:57Z"^^schema:DateTime ;
    schema:datePublished "2020-04-22T22:07:57Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Constrained Neural Ordinary Differential Equations with Stability  Guarantees"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.10883v1"^^schema:URL .

<925> a schema:ScholarlyArticle ;
    schema:abstract "To improve the performance of classical generative adversarial network (GAN),Wasserstein generative adversarial networks (W-GAN) was developed as aKantorovich dual formulation of the optimal transport (OT) problem usingWasserstein-1 distance. However, it was not clear how cycleGAN-type generativemodels can be derived from the optimal transport theory. Here we show that anovel cycleGAN architecture can be derived as a Kantorovich dual OT formulationif a penalized least square (PLS) cost with deep learning-based inverse pathpenalty is used as a transportation cost. One of the most important advantagesof this formulation is that depending on the knowledge of the forward problem,distinct variations of cycleGAN architecture can be derived: for example, onewith two pairs of generators and discriminators, and the other with only asingle pair of generator and discriminator. Even for the two generator cases,we show that the structural knowledge of the forward operator can lead to asimpler generator architecture which significantly simplifies the neuralnetwork training. The new cycleGAN formulation, what we call the OT-cycleGAN,have been applied for various biomedical imaging problems, such as acceleratedmagnetic resonance imaging (MRI), super-resolution microscopy, and low-dosex-ray computed tomography (CT). Experimental results confirm the efficacy andflexibility of the theory."^^schema:Text ;
    schema:author "Byeongsu Sim"^^schema:Person,
        "Chanyong Jung"^^schema:Person,
        "Gyutaek Oh"^^schema:Person,
        "Jeongsol Kim"^^schema:Person,
        "Jong Chul Ye"^^schema:Person ;
    schema:dateModified "2020-08-30T12:14:48Z"^^schema:DateTime ;
    schema:datePublished "2019-09-25T11:28:49Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Optimal Transport driven CycleGAN for Unsupervised Learning in Inverse  Problems"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1909.12116v4"^^schema:URL .

<926> a schema:ScholarlyArticle ;
    schema:abstract "Neural Architecture Search (NAS) has been quite successful in constructingstate-of-the-art models on a variety of tasks. Unfortunately, the computationalcost can make it difficult to scale. In this paper, we make the first attemptto study Meta Architecture Search which aims at learning a task-agnosticrepresentation that can be used to speed up the process of architecture searchon a large number of tasks. We propose the Bayesian Meta Architecture SEarch(BASE) framework which takes advantage of a Bayesian formulation of thearchitecture search problem to learn over an entire set of taskssimultaneously. We show that on Imagenet classification, we can find a modelthat achieves 25.7% top-1 error and 8.1% top-5 error by adapting thearchitecture in less than an hour from an 8 GPU days pretrained meta-network.By learning a good prior for NAS, our method dramatically decreases therequired computation cost while achieving comparable performance to currentstate-of-the-art methods - even finding competitive models for unseen datasetswith very quick adaptation. We believe our framework will open up newpossibilities for efficient and massively scalable architecture search researchacross multiple tasks."^^schema:Text ;
    schema:author "Albert Shaw"^^schema:Person,
        "Bo Dai"^^schema:Person,
        "Le Song"^^schema:Person,
        "Wei Wei"^^schema:Person,
        "Weiyang Liu"^^schema:Person ;
    schema:dateModified "2019-11-15T16:06:14Z"^^schema:DateTime ;
    schema:datePublished "2018-12-22T19:25:08Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Meta Architecture Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1812.09584v2"^^schema:URL .

<927> a schema:ScholarlyArticle ;
    schema:abstract "The quantization of weights to binary states in Deep Neural Networks (DNNs)can replace resource-hungry multiply accumulate operations with simpleaccumulations. Such Binarized Neural Networks (BNNs) exhibit greatly reducedresource and power requirements. In addition, memristors have been shown aspromising synaptic weight elements in DNNs. In this paper, we propose andsimulate novel Binarized Memristive Convolutional Neural Network (BMCNN)architectures employing hybrid weight and parameter representations. We trainthe proposed architectures offline and then map the trained parameters to ourbinarized memristive devices for inference. To take into account the variationsin memristive devices, and to study their effect on the performance, weintroduce variations in $R_{ON}$ and $R_{OFF}$. Moreover, we introduce means tomitigate the adverse effect of memristive variations in our proposed networks.Finally, we benchmark our BMCNNs and variation-aware BMCNNs using the MNISTdataset."^^schema:Text ;
    schema:author "Alex James"^^schema:Person,
        "Corey Lammie"^^schema:Person,
        "Mostafa Rahimi Azghadi"^^schema:Person,
        "Olga Krestinskaya"^^schema:Person ;
    schema:dateModified "2019-10-14T05:46:12Z"^^schema:DateTime ;
    schema:datePublished "2019-10-14T05:46:12Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text,
        "cs.NE"^^schema:Text,
        "eess.SP"^^schema:Text ;
    schema:headline "Variation-aware Binarized Memristive Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.05920v1"^^schema:URL .

<928> a schema:ScholarlyArticle ;
    schema:abstract "Mean squared error (MSE) and $\\ell_p$ norms have largely dominated themeasurement of loss in neural networks due to their simplicity and analyticalproperties. However, when used to assess visual information loss, these simplenorms are not highly consistent with human perception. Here, we propose adifferent proxy approach to optimize image analysis networks againstquantitative perceptual models. Specifically, we construct a proxy network,which mimics the perceptual model while serving as a loss layer of thenetwork.We experimentally demonstrate how this optimization framework can beapplied to train an end-to-end optimized image compression network. By buildingon top of a modern deep image compression models, we are able to demonstrate anaveraged bitrate reduction of $28.7\\%$ over MSE optimization, given a specifiedperceptual quality (VMAF) level."^^schema:Text ;
    schema:author "Alan C. Bovik"^^schema:Person,
        "Andrey Norkin"^^schema:Person,
        "Christos G. Bampis"^^schema:Person,
        "Li-Heng Chen"^^schema:Person,
        "Zhi Li"^^schema:Person ;
    schema:dateModified "2020-07-09T15:04:06Z"^^schema:DateTime ;
    schema:datePublished "2020-07-03T14:33:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "Perceptually Optimizing Deep Image Compression"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2007.02711v2"^^schema:URL .

<929> a schema:ScholarlyArticle ;
    schema:abstract "We propose learning flexible but interpretable functions that aggregate avariable-length set of permutation-invariant feature vectors to predict alabel. We use a deep lattice network model so we can architect the modelstructure to enhance interpretability, and add monotonicity constraints betweeninputs-and-outputs. We then use the proposed set function to automate theengineering of dense, interpretable features from sparse categorical features,which we call semantic feature engine. Experiments on real-world data show theachieved accuracy is similar to deep sets or deep neural networks, and iseasier to debug and understand."^^schema:Text ;
    schema:author "Andrew Cotter"^^schema:Person,
        "Heinrich Jiang"^^schema:Person,
        "James Muller"^^schema:Person,
        "Maya Gupta"^^schema:Person,
        "Serena Wang"^^schema:Person,
        "Taman Narayan"^^schema:Person,
        "Tao Zhu"^^schema:Person ;
    schema:dateModified "2018-05-31T18:53:15Z"^^schema:DateTime ;
    schema:datePublished "2018-05-31T18:53:15Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Interpretable Set Functions"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.00050v1"^^schema:URL .

<93> a schema:ScholarlyArticle ;
    schema:abstract "Categorical variables are a natural choice for representing discretestructure in the world. However, stochastic neural networks rarely usecategorical latent variables due to the inability to backpropagate throughsamples. In this work, we present an efficient gradient estimator that replacesthe non-differentiable sample from a categorical distribution with adifferentiable sample from a novel Gumbel-Softmax distribution. Thisdistribution has the essential property that it can be smoothly annealed into acategorical distribution. We show that our Gumbel-Softmax estimator outperformsstate-of-the-art gradient estimators on structured output prediction andunsupervised generative modeling tasks with categorical latent variables, andenables large speedups on semi-supervised classification."^^schema:Text ;
    schema:author "Ben Poole"^^schema:Person,
        "Eric Jang"^^schema:Person,
        "Shixiang Gu"^^schema:Person ;
    schema:commentCount "1224"^^schema:Integer ;
    schema:dateModified "2017-08-05T22:45:19Z"^^schema:DateTime ;
    schema:datePublished "2016-11-03T19:48:08Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Categorical Reparameterization with Gumbel-Softmax"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1611.01144v5"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=8563509432417332168&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<930> a schema:ScholarlyArticle ;
    schema:abstract "Knowledge Tracing (KT) is a task of tracing evolving knowledge state ofstudents with respect to one or more concepts as they engage in a sequence oflearning activities. One important purpose of KT is to personalize the practicesequence to help students learn knowledge concepts efficiently. However,existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracingeither model knowledge state for each predefined concept separately or fail topinpoint exactly which concepts a student is good at or unfamiliar with. Tosolve these problems, this work introduces a new model called Dynamic Key-ValueMemory Networks (DKVMN) that can exploit the relationships between underlyingconcepts and directly output a student's mastery level of each concept. Unlikestandard memory-augmented neural networks that facilitate a single memorymatrix or two static memory matrices, our model has one static matrix calledkey, which stores the knowledge concepts and the other dynamic matrix calledvalue, which stores and updates the mastery levels of corresponding concepts.Experiments show that our model consistently outperforms the state-of-the-artmodel in a range of KT datasets. Moreover, the DKVMN model can automaticallydiscover underlying concepts of exercises typically performed by humanannotations and depict the changing knowledge state of a student."^^schema:Text ;
    schema:author "Dit-Yan Yeung"^^schema:Person,
        "Irwin King"^^schema:Person,
        "Jiani Zhang"^^schema:Person,
        "Xingjian Shi"^^schema:Person ;
    schema:dateModified "2017-02-17T06:09:27Z"^^schema:DateTime ;
    schema:datePublished "2016-11-24T09:12:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Dynamic Key-Value Memory Networks for Knowledge Tracing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1611.08108v2"^^schema:URL .

<931> a schema:ScholarlyArticle ;
    schema:abstract "West African Pidgin English is a language that is significantly spoken inWest Africa, consisting of at least 75 million speakers. Nevertheless, propermachine translation systems and relevant NLP datasets for pidgin English arevirtually absent. In this work, we develop techniques targeted at bridging thegap between Pidgin English and English in the context of natural languagegeneration. %As a proof of concept, we explore the proposed techniques in thearea of data-to-text generation. By building upon the previously releasedmonolingual Pidgin English text and parallel English data-to-text corpus, wehope to build a system that can automatically generate Pidgin Englishdescriptions from structured data. We first train a data-to-English textgeneration system, before employing techniques in unsupervised neural machinetranslation and self-training to establish the Pidgin-to-English cross-lingualalignment. The human evaluation performed on the generated Pidgin texts showsthat, though still far from being practically usable, the pivoting +self-training technique improves both Pidgin text fluency and relevance."^^schema:Text ;
    schema:author "David Ifeoluwa Adelani"^^schema:Person,
        "Ernie Chang"^^schema:Person,
        "Vera Demberg"^^schema:Person,
        "Xiaoyu Shen"^^schema:Person ;
    schema:dateModified "2020-03-18T15:27:35Z"^^schema:DateTime ;
    schema:datePublished "2020-03-18T15:27:35Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Unsupervised Pidgin Text Generation By Pivoting English Data and  Self-Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08272v1"^^schema:URL .

<932> a schema:ScholarlyArticle ;
    schema:abstract "We present the first sentence simplification model that learns explicit editoperations (ADD, DELETE, and KEEP) via a neural programmer-interpreterapproach. Most current neural sentence simplification systems are variants ofsequence-to-sequence models adopted from machine translation. These methodslearn to simplify sentences as a byproduct of the fact that they are trained oncomplex-simple sentence pairs. By contrast, our neural programmer-interpreteris directly trained to predict explicit edit operations on targeted parts ofthe input sentence, resembling the way that humans might perform simplificationand revision. Our model outperforms previous state-of-the-art neural sentencesimplification models (without external knowledge) by large margins on threebenchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89WikiSmall, +1.41 Newsela), and is judged by humans to produce overall betterand simpler output sentences."^^schema:Text ;
    schema:author "Jackie Chi Kit Cheung"^^schema:Person,
        "Mehdi Rezagholizadeh"^^schema:Person,
        "Yue Dong"^^schema:Person,
        "Zichao Li"^^schema:Person ;
    schema:dateModified "2019-06-19T14:00:15Z"^^schema:DateTime ;
    schema:datePublished "2019-06-19T14:00:15Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "EditNTS: An Neural Programmer-Interpreter Model for Sentence  Simplification through Explicit Editing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.08104v1"^^schema:URL .

<933> a schema:ScholarlyArticle ;
    schema:abstract "Singing voice conversion aims to convert singer's voice from source to targetwithout changing singing content. Parallel training data is typically requiredfor the training of singing voice conversion system, that is however notpractical in real-life applications. Recent encoder-decoder structures, such asvariational autoencoding Wasserstein generative adversarial network (VAW-GAN),provide an effective way to learn a mapping through non-parallel training data.In this paper, we propose a singing voice conversion framework that is based onVAW-GAN. We train an encoder to disentangle singer identity and singing prosody(F0 contour) from phonetic content. By conditioning on singer identity and F0,the decoder generates output spectral features with unseen target singeridentity, and improves the F0 rendering. Experimental results show that theproposed framework achieves better performance than the baseline frameworks."^^schema:Text ;
    schema:author "Berrak Sisman"^^schema:Person,
        "Haizhou Li"^^schema:Person,
        "Junchen Lu"^^schema:Person,
        "Kun Zhou"^^schema:Person ;
    schema:dateModified "2020-11-03T10:58:10Z"^^schema:DateTime ;
    schema:datePublished "2020-08-10T09:44:10Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "VAW-GAN for Singing Voice Conversion with Non-parallel Training Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.03992v3"^^schema:URL .

<934> a schema:ScholarlyArticle ;
    schema:abstract "Machine learning plays an increasingly significant role in many aspects ofour lives (including medicine, transportation, security, justice and otherdomains), making the potential consequences of false predictions increasinglydevastating. These consequences may be mitigated if we can automatically flagsuch false predictions and potentially assign them to alternative, morereliable mechanisms, that are possibly more costly and involve human attention.This suggests the task of detecting errors, which we tackle in this paper forthe case of visual classification. To this end, we propose a novel approach forclassification confidence estimation. We apply a set of semantics-preservingimage transformations to the input image, and show how the resulting image setscan be used to estimate confidence in the classifier's prediction. Wedemonstrate the potential of our approach by extensively evaluating it on awide variety of classifier architectures and datasets, includingResNext/ImageNet, achieving state of the art performance. This paperconstitutes a significant revision of our earlier work in this direction (Bahat&amp; Shakhnarovich, 2018)."^^schema:Text ;
    schema:author "Gregory Shakhnarovich"^^schema:Person,
        "Yuval Bahat"^^schema:Person ;
    schema:dateModified "2020-06-30T11:59:53Z"^^schema:DateTime ;
    schema:datePublished "2020-06-30T11:59:53Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Classification Confidence Estimation with Test-Time Data-Augmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.16705v1"^^schema:URL .

<935> a schema:ScholarlyArticle ;
    schema:abstract "We present a self-attention based bilingual adversarial text generator(B-GAN) which can learn to generate text from the encoder representation of anunsupervised neural machine translation system. B-GAN is able to generate adistributed latent space representation which can be paired with an attentionbased decoder to generate fluent sentences. When trained on an encoder sharedbetween two languages and paired with the appropriate decoder, it can generatesentences in either language. B-GAN is trained using a combination ofreconstruction loss for auto-encoder, a cross domain loss for translation and aGAN based adversarial loss for text generation. We demonstrate that B-GAN,trained on monolingual corpora only using multiple losses, generates morefluent sentences compared to monolingual baselines while effectively using halfthe number of parameters."^^schema:Text ;
    schema:author "Ahmad Rashid"^^schema:Person,
        "Alan Do-Omri"^^schema:Person,
        "Md. Akmal Haidar"^^schema:Person,
        "Mehdi Rezagholizadeh"^^schema:Person,
        "Qun Liu"^^schema:Person ;
    schema:dateModified "2020-11-10T23:03:50Z"^^schema:DateTime ;
    schema:datePublished "2020-11-10T23:03:50Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "From Unsupervised Machine Translation To Adversarial Text Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.05449v1"^^schema:URL .

<936> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (DRL) is a booming area of artificialintelligence. Many practical applications of DRL naturally involve more thanone collaborative learners, making it important to study DRL in a multi-agentcontext. Previous research showed that effective learning in complexmulti-agent systems demands for highly coordinated environment explorationamong all the participating agents. Many researchers attempted to cope withthis challenge through learning centralized value functions. However, thecommon strategy for every agent to learn their local policies directly oftenfail to nurture strong inter-agent collaboration and can be sample inefficientwhenever agents alter their communication channels. To address these issues, wepropose a new framework known as centralized training and exploration withdecentralized execution via policy distillation. Guided by this framework andthe maximum-entropy learning technique, we will first train agents' policieswith shared global component to foster coordinated and effective learning.Locally executable policies will be derived subsequently from the trainedglobal policies via policy distillation. Experiments show that our newframework and algorithm can achieve significantly better performance and highersample efficiency than a cutting-edge baseline on several multi-agent DRLbenchmarks."^^schema:Text ;
    schema:author "Gang Chen"^^schema:Person ;
    schema:dateModified "2019-10-21T05:07:42Z"^^schema:DateTime ;
    schema:datePublished "2019-10-21T05:07:42Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "A New Framework for Multi-Agent Reinforcement Learning -- Centralized  Training and Exploration with Decentralized Execution via Policy Distillation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.09152v1"^^schema:URL .

<937> a schema:ScholarlyArticle ;
    schema:abstract "We propose a novel image sampling method for differentiable imagetransformation in deep neural networks. The sampling schemes currently used indeep learning, such as Spatial Transformer Networks, rely on bilinearinterpolation, which performs poorly under severe scale changes, and moreimportantly, results in poor gradient propagation. This is due to their strictreliance on direct neighbors. Instead, we propose to generate random auxiliarysamples in the vicinity of each pixel in the sampled image, and create a linearapproximation with their intensity values. We then use this approximation as adifferentiable formula for the transformed image. We demonstrate that ourapproach produces more representative gradients with a wider basin ofconvergence for image alignment, which leads to considerable performanceimprovements when training networks for classification tasks. This is not onlytrue under large downsampling, but also when there are no scale changes. Wecompare our approach with multi-scale sampling and show that we outperform it.We then demonstrate that our improvements to the sampler are compatible withother tangential improvements to Spatial Transformer Networks and that itfurther improves their performance."^^schema:Text ;
    schema:author "Andrea Tagliasacchi"^^schema:Person,
        "Eduard Trulls"^^schema:Person,
        "Kwang Moo Yi"^^schema:Person,
        "Wei Jiang"^^schema:Person,
        "Weiwei Sun"^^schema:Person ;
    schema:dateModified "2019-09-10T17:17:32Z"^^schema:DateTime ;
    schema:datePublished "2019-01-22T00:07:12Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Linearized Multi-Sampling for Differentiable Image Transformation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.07124v3"^^schema:URL .

<938> a schema:ScholarlyArticle ;
    schema:abstract "Most deep learning approaches for text-to-SQL generation are limited to theWikiSQL dataset, which only supports very simple queries. Recently,template-based and sequence-to-sequence approaches were proposed to supportcomplex queries, which contain join queries, nested queries, and other types.However, Finegan-Dollak et al. (2018) demonstrated that both the approacheslack the ability to generate SQL of unseen templates. In this paper, we proposea template-based one-shot learning model for the text-to-SQL generation so thatthe model can generate SQL of an untrained template based on a single example.First, we classify the SQL template using the Matching Network that isaugmented by our novel architecture Candidate Search Network. Then, we fill thevariable slots in the predicted template using the Pointer Network. We showthat our model outperforms state-of-the-art approaches for various text-to-SQLdatasets in two aspects: 1) the SQL generation accuracy for the trainedtemplates, and 2) the adaptability to the unseen SQL templates based on asingle example without any additional training."^^schema:Text ;
    schema:author "Dongjun Lee"^^schema:Person,
        "Jaesik Yoon"^^schema:Person,
        "Jongyun Song"^^schema:Person,
        "Sanggil Lee"^^schema:Person,
        "Sungroh Yoon"^^schema:Person ;
    schema:dateModified "2019-04-26T06:29:29Z"^^schema:DateTime ;
    schema:datePublished "2019-04-26T06:29:29Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.DB"^^schema:Text ;
    schema:headline "One-Shot Learning for Text-to-SQL Generation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.11499v1"^^schema:URL .

<939> a schema:ScholarlyArticle ;
    schema:abstract "Q-learning with value function approximation may have the poor performancebecause of overestimation bias and imprecise estimate. Specifically,overestimation bias is from the maximum operator over noise estimate, which isexaggerated using the estimate of a subsequent state. Inspired by the recentadvance of deep reinforcement learning and Double Q-learning, we introduce thedecorrelated double Q-learning (D2Q). Specifically, we introduce thedecorrelated regularization item to reduce the correlation between valuefunction approximators, which can lead to less biased estimation and lowvariance. The experimental results on a suite of MuJoCo continuous controltasks demonstrate that our decorrelated double Q-learning can effectivelyimprove the performance."^^schema:Text ;
    schema:author "Gang Chen"^^schema:Person ;
    schema:dateModified "2020-06-12T05:59:05Z"^^schema:DateTime ;
    schema:datePublished "2020-06-12T05:59:05Z"^^schema:DateTime ;
    schema:genre "68T01"^^schema:Text,
        "I.2.9"^^schema:Text,
        "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Decorrelated Double Q-learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.06956v1"^^schema:URL .

<94> a schema:ScholarlyArticle ;
    schema:abstract "We propose a lifelong learning system that has the ability to reuse andtransfer knowledge from one task to another while efficiently retaining thepreviously learned knowledge-base. Knowledge is transferred by learningreusable skills to solve tasks in Minecraft, a popular video game which is anunsolved and high-dimensional lifelong learning problem. These reusable skills,which we refer to as Deep Skill Networks, are then incorporated into our novelHierarchical Deep Reinforcement Learning Network (H-DRLN) architecture usingtwo techniques: (1) a deep skill array and (2) skill distillation, our novelvariation of policy distillation (Rusu et. al. 2015) for learning skills. Skilldistillation enables the HDRLN to efficiently retain knowledge and thereforescale in lifelong learning, by accumulating knowledge and encapsulatingmultiple reusable skills into a single distilled network. The H-DRLN exhibitssuperior performance and lower learning sample complexity compared to theregular Deep Q Network (Mnih et. al. 2015) in sub-domains of Minecraft."^^schema:Text ;
    schema:author "Chen Tessler"^^schema:Person,
        "Daniel J. Mankowitz"^^schema:Person,
        "Shahar Givony"^^schema:Person,
        "Shie Mannor"^^schema:Person,
        "Tom Zahavy"^^schema:Person ;
    schema:commentCount "194"^^schema:Integer ;
    schema:dateModified "2016-11-30T17:35:27Z"^^schema:DateTime ;
    schema:datePublished "2016-04-25T13:45:50Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "A Deep Hierarchical Approach to Lifelong Learning in Minecraft"^^schema:Text ;
    schema:publisher "Thirty-First AAAI Conference on Artificial Intelligence"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1604.07255v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=15352455767272452459&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<940> a schema:ScholarlyArticle ;
    schema:abstract "We study the global convergence of generative adversarial imitation learningfor linear quadratic regulators, which is posed as minimax optimization. Toaddress the challenges arising from non-convex-concave geometry, we analyze thealternating gradient algorithm and establish its Q-linear rate of convergenceto a unique saddle point, which simultaneously recovers the globally optimalpolicy and reward function. We hope our results may serve as a small steptowards understanding and taming the instability in imitation learning as wellas in more general non-convex-concave alternating minimax optimization thatarises from reinforcement learning and generative adversarial learning."^^schema:Text ;
    schema:author "Mingyi Hong"^^schema:Person,
        "Qi Cai"^^schema:Person,
        "Yongxin Chen"^^schema:Person,
        "Zhaoran Wang"^^schema:Person ;
    schema:dateModified "2019-01-11T17:54:47Z"^^schema:DateTime ;
    schema:datePublished "2019-01-11T17:54:47Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "On the Global Convergence of Imitation Learning: A Case for Linear  Quadratic Regulator"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1901.03674v1"^^schema:URL .

<941> a schema:ScholarlyArticle ;
    schema:abstract "Structure-preserved denoising of 3D magnetic resonance imaging (MRI) imagesis a critical step in medical image analysis. Over the past few years, manyalgorithms with impressive performances have been proposed. In this paper,inspired by the idea of deep learning, we introduce an MRI denoising methodbased on the residual encoder-decoder Wasserstein generative adversarialnetwork (RED-WGAN). Specifically, to explore the structure similarity betweenneighboring slices, a 3D configuration is utilized as the basic processingunit. Residual autoencoders combined with deconvolution operations areintroduced into the generator network. Furthermore, to alleviate theoversmoothing shortcoming of the traditional mean squared error (MSE) lossfunction, the perceptual similarity, which is implemented by calculating thedistances in the feature space extracted by a pretrained VGG-19 network, isincorporated with the MSE and adversarial losses to form the new loss function.Extensive experiments are implemented to assess the performance of the proposedmethod. The experimental results show that the proposed RED-WGAN achievesperformance superior to several state-of-the-art methods in both simulated andreal clinical data. In particular, our method demonstrates powerful abilitiesin both noise suppression and structure preservation."^^schema:Text ;
    schema:author "Hu Chen"^^schema:Person,
        "Huaiqiang Sun"^^schema:Person,
        "Jiliu Zhou"^^schema:Person,
        "Jinrong Hu"^^schema:Person,
        "Maosong Ran"^^schema:Person,
        "Yang Chen"^^schema:Person,
        "Yi Zhang"^^schema:Person ;
    schema:dateModified "2019-05-05T03:42:19Z"^^schema:DateTime ;
    schema:datePublished "2018-08-12T13:30:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "physics.med-ph"^^schema:Text ;
    schema:headline "Denoising of 3-D Magnetic Resonance Images Using a Residual  Encoder-Decoder Wasserstein Generative Adversarial Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.03941v2"^^schema:URL .

<942> a schema:ScholarlyArticle ;
    schema:abstract "We present a generalization bound for feedforward neural networks in terms ofthe product of the spectral norm of the layers and the Frobenius norm of theweights. The generalization bound is derived using a PAC-Bayes analysis."^^schema:Text ;
    schema:author "Behnam Neyshabur"^^schema:Person,
        "Nathan Srebro"^^schema:Person,
        "Srinadh Bhojanapalli"^^schema:Person ;
    schema:dateModified "2018-02-23T22:30:45Z"^^schema:DateTime ;
    schema:datePublished "2017-07-29T22:36:35Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.09564v2"^^schema:URL .

<943> a schema:ScholarlyArticle ;
    schema:abstract "In mobile crowdsourcing (MCS), the platform selects participants to completelocation-aware tasks from the recruiters aiming to achieve multiple goals(e.g., profit maximization, energy efficiency, and fairness). However,different MCS systems have different goals and there are possibly conflictinggoals even in one MCS system. Therefore, it is crucial to design a participantselection algorithm that applies to different MCS systems to achieve multiplegoals. To deal with this issue, we formulate the participant selection problemas a reinforcement learning problem and propose to solve it with a novelmethod, which we call auxiliary-task based deep reinforcement learning (ADRL).We use transformers to extract representations from the context of the MCSsystem and a pointer network to deal with the combinatorial optimizationproblem. To improve the sample efficiency, we adopt an auxiliary-task trainingprocess that trains the network to predict the imminent tasks from therecruiters, which facilitates the embedding learning of the deep learningmodel. Additionally, we release a simulated environment on a specific MCS task,the ride-sharing task, and conduct extensive performance evaluations in thisenvironment. The experimental results demonstrate that ADRL outperforms andimproves sample efficiency over other well-recognized baselines in varioussettings."^^schema:Text ;
    schema:author "Chuheng Zhang"^^schema:Person,
        "Qiang Ni"^^schema:Person,
        "Wanchun Dou"^^schema:Person,
        "Wei Shen"^^schema:Person,
        "Xiaonan He"^^schema:Person,
        "Yan Wang"^^schema:Person ;
    schema:dateModified "2020-08-26T00:55:05Z"^^schema:DateTime ;
    schema:datePublished "2020-08-25T15:02:54Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Auxiliary-task Based Deep Reinforcement Learning for Participant  Selection Problem in Mobile Crowdsourcing"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.11087v2"^^schema:URL .

<944> a schema:ScholarlyArticle ;
    schema:abstract "Video-to-video synthesis is a challenging problem aiming at learning atranslation function between a sequence of semantic maps and a photo-realisticvideo depicting the characteristics of a driving video. We propose ahead-to-head system of our own implementation capable of fully transferring thehuman head 3D pose, facial expressions and eye gaze from a source to a targetactor, while preserving the identity of the target actor. Our system produceshigh-fidelity, temporally-smooth and photo-realistic synthetic videosfaithfully transferring the human time-varying head attributes from the sourceto the target actor. Our proposed implementation: 1) works in real time ($\\sim20$ fps), 2) runs on a commodity laptop with a webcam as the only input, 3) isinteractive, allowing the participant to drive a target person, e.g. acelebrity, politician, etc, instantly by varying their expressions, head pose,and eye gaze, and visualising the synthesised video concurrently."^^schema:Text ;
    schema:author "Anastasios Roussos"^^schema:Person,
        "Michail Christos Doukas"^^schema:Person,
        "Mohammad Rami Koujan"^^schema:Person,
        "Stefanos Zafeiriou"^^schema:Person ;
    schema:dateModified "2020-05-22T00:51:38Z"^^schema:DateTime ;
    schema:datePublished "2020-05-22T00:51:38Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "ReenactNet: Real-time Full Head Reenactment"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.10500v1"^^schema:URL .

<945> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we evaluate training of deep recurrent neural networks withhalf-precision floats. We implement a distributed, data-parallel, synchronoustraining algorithm by integrating TensorFlow and CUDA-aware MPI to enableexecution across multiple GPU nodes and making use of high-speed interconnects.We introduce a learning rate schedule facilitating neural network convergenceat up to $O(100)$ workers.  Strong scaling tests performed on clusters of NVIDIA Pascal P100 GPUs showlinear runtime and logarithmic communication time scaling for both single andmixed precision training modes. Performance is evaluated on a scientificdataset taken from the Joint European Torus (JET) tokamak, containingmulti-modal time series of sensory measurements leading up to deleteriousevents called plasma disruptions, and the benchmark Large Movie ReviewDataset~\\cite{imdb}. Half-precision significantly reduces memory and networkbandwidth, allowing training of state-of-the-art models with over 70 milliontrainable parameters while achieving a comparable test set performance assingle precision."^^schema:Text ;
    schema:author "Alexey Svyatkovskiy"^^schema:Person,
        "Julian Kates-Harbeck"^^schema:Person,
        "William Tang"^^schema:Person ;
    schema:dateModified "2019-11-30T23:57:48Z"^^schema:DateTime ;
    schema:datePublished "2019-11-30T23:57:48Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Training Distributed Deep Recurrent Neural Networks with Mixed Precision  on GPU Clusters"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.00286v1"^^schema:URL .

<946> a schema:ScholarlyArticle ;
    schema:abstract "Response evaluation criteria in solid tumors (RECIST) is the standardmeasurement for tumor extent to evaluate treatment responses in cancerpatients. As such, RECIST annotations must be accurate. However, RECISTannotations manually labeled by radiologists require professional knowledge andare time-consuming, subjective, and prone to inconsistency among differentobservers. To alleviate these problems, we propose a cascaded convolutionalneural network based method to semi-automatically label RECIST annotations anddrastically reduce annotation time. The proposed method consists of two stages:lesion region normalization and RECIST estimation. We employ the spatialtransformer network (STN) for lesion region normalization, where a localizationnetwork is designed to predict the lesion region and the transformationparameters with a multi-task learning strategy. For RECIST estimation, we adaptthe stacked hourglass network (SHN), introducing a relationship constraint lossto improve the estimation precision. STN and SHN can both be learned in anend-to-end fashion. We train our system on the DeepLesion dataset, obtaining aconsensus model trained on RECIST annotations performed by multipleradiologists over a multi-year period. Importantly, when judged against theinter-reader variability of two additional radiologist raters, our systemperforms more stably and with less variability, suggesting that RECISTannotations can be reliably obtained with reduced labor and time."^^schema:Text ;
    schema:author "Adam P. Harrison"^^schema:Person,
        "Jing Xiao"^^schema:Person,
        "Mohammadhadi Bagheri"^^schema:Person,
        "Ronald M. Summers"^^schema:Person,
        "Youbao Tang"^^schema:Person ;
    schema:dateModified "2018-06-25T14:52:07Z"^^schema:DateTime ;
    schema:datePublished "2018-06-25T14:52:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Semi-Automatic RECIST Labeling on CT Scans with Cascaded Convolutional  Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1806.09507v1"^^schema:URL .

<947> a schema:ScholarlyArticle ;
    schema:abstract "Policy gradient methods in reinforcement learning have become increasinglyprevalent for state-of-the-art performance in continuous control tasks. Novelmethods typically benchmark against a few key algorithms such as deepdeterministic policy gradients and trust region policy optimization. As such,it is important to present and use consistent baselines experiments. However,this can be difficult due to general variance in the algorithms,hyper-parameter tuning, and environment stochasticity. We investigate anddiscuss: the significance of hyper-parameters in policy gradients forcontinuous control, general variance in the algorithms, and reproducibility ofreported results. We provide guidelines on reporting novel results ascomparisons against baseline methods such that future researchers can makeinformed decisions when investigating novel methods."^^schema:Text ;
    schema:author "Doina Precup"^^schema:Person,
        "Maziar Gomrokchi"^^schema:Person,
        "Peter Henderson"^^schema:Person,
        "Riashat Islam"^^schema:Person ;
    schema:dateModified "2017-08-10T19:20:15Z"^^schema:DateTime ;
    schema:datePublished "2017-08-10T19:20:15Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for  Continuous Control"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.04133v1"^^schema:URL .

<948> a schema:ScholarlyArticle ;
    schema:abstract "Anomaly detection on multivariate time-series is of great importance in bothdata mining research and industrial applications. Recent approaches haveachieved significant progress in this topic, but there is remaininglimitations. One major limitation is that they do not capture the relationshipsbetween different time-series explicitly, resulting in inevitable false alarms.In this paper, we propose a novel self-supervised framework for multivariatetime-series anomaly detection to address this issue. Our framework considerseach univariate time-series as an individual feature and includes two graphattention layers in parallel to learn the complex dependencies of multivariatetime-series in both temporal and feature dimensions. In addition, our approachjointly optimizes a forecasting-based model and are construction-based model,obtaining better time-series representations through a combination ofsingle-timestamp prediction and reconstruction of the entire time-series. Wedemonstrate the efficacy of our model through extensive experiments. Theproposed method outperforms other state-of-the-art models on three real-worlddatasets. Further analysis shows that our method has good interpretability andis useful for anomaly diagnosis."^^schema:Text ;
    schema:author "Bixiong Xu"^^schema:Person,
        "Congrui Huang"^^schema:Person,
        "Defu Cao"^^schema:Person,
        "Hang Zhao"^^schema:Person,
        "Jie Tong"^^schema:Person,
        "Jing Bai"^^schema:Person,
        "Juanyong Duan"^^schema:Person,
        "Qi Zhang"^^schema:Person,
        "Yujing Wang"^^schema:Person,
        "Yunhai Tong"^^schema:Person ;
    schema:dateModified "2020-09-04T07:46:19Z"^^schema:DateTime ;
    schema:datePublished "2020-09-04T07:46:19Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Multivariate Time-series Anomaly Detection via Graph Attention Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2009.02040v1"^^schema:URL .

<949> a schema:ScholarlyArticle ;
    schema:abstract "Over the last few years, convolutional neural networks (CNNs) have proved toreach super-human performance in visual recognition tasks. However, CNNs caneasily be fooled by adversarial examples, i.e., maliciously-crafted images thatforce the networks to predict an incorrect output while being extremely similarto those for which a correct output is predicted. Regular adversarial examplesare not robust to input image transformations, which can then be used to detectwhether an adversarial example is presented to the network. Nevertheless, it isstill possible to generate adversarial examples that are robust to suchtransformations.  This paper extensively explores the detection of adversarial examples viaimage transformations and proposes a novel methodology, called \\textit{defenseperturbation}, to detect robust adversarial examples with the same inputtransformations the adversarial examples are robust to. Such a \\textit{defenseperturbation} is shown to be an effective counter-measure to robust adversarialexamples.  Furthermore, multi-network adversarial examples are introduced. This kind ofadversarial examples can be used to simultaneously fool multiple networks,which is critical in systems that use network redundancy, such as those basedon architectures with majority voting over multiple CNNs. An extensive set ofexperiments based on state-of-the-art CNNs trained on the Imagenet dataset isfinally reported."^^schema:Text ;
    schema:author "Alessandro Biondi"^^schema:Person,
        "Federico Nesti"^^schema:Person,
        "Giorgio Buttazzo"^^schema:Person ;
    schema:dateModified "2021-01-27T14:50:41Z"^^schema:DateTime ;
    schema:datePublished "2021-01-27T14:50:41Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Detecting Adversarial Examples by Input Transformations, Defense  Perturbations, and Voting"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.11466v1"^^schema:URL .

<95> a schema:ScholarlyArticle ;
    schema:abstract "We present weight normalization: a reparameterization of the weight vectorsin a neural network that decouples the length of those weight vectors fromtheir direction. By reparameterizing the weights in this way we improve theconditioning of the optimization problem and we speed up convergence ofstochastic gradient descent. Our reparameterization is inspired by batchnormalization but does not introduce any dependencies between the examples in aminibatch. This means that our method can also be applied successfully torecurrent models such as LSTMs and to noise-sensitive applications such as deepreinforcement learning or generative models, for which batch normalization isless well suited. Although our method is much simpler, it still provides muchof the speed-up of full batch normalization. In addition, the computationaloverhead of our method is lower, permitting more optimization steps to be takenin the same amount of time. We demonstrate the usefulness of our method onapplications in supervised image recognition, generative modelling, and deepreinforcement learning."^^schema:Text ;
    schema:author "Diederik P. Kingma"^^schema:Person,
        "Tim Salimans"^^schema:Person ;
    schema:commentCount "792"^^schema:Integer ;
    schema:dateModified "2016-06-04T01:21:52Z"^^schema:DateTime ;
    schema:datePublished "2016-02-25T10:13:45Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Weight Normalization: A Simple Reparameterization to Accelerate Training  of Deep Neural Networks"^^schema:Text ;
    schema:publisher "Proceedings of the 30th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1602.07868v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=5176697277672103356&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<950> a schema:ScholarlyArticle ;
    schema:abstract "Tensor decomposition is an effective approach to compress over-parameterizedneural networks and to enable their deployment on resource-constrained hardwareplatforms. However, directly applying tensor compression in the trainingprocess is a challenging task due to the difficulty of choosing a proper tensorrank. In order to achieve this goal, this paper proposes a Bayesian tensorizedneural network. Our Bayesian method performs automatic model compression via anadaptive tensor rank determination. We also present approaches for posteriordensity calculation and maximum a posteriori (MAP) estimation for theend-to-end training of our tensorized neural network. We provide experimentalvalidation on a fully connected neural network, a CNN and a residual neuralnetwork where our work produces $7.4\\times$ to $137\\times$ more compact neuralnetworks directly from the training."^^schema:Text ;
    schema:author "Cole Hawkins"^^schema:Person,
        "Zheng Zhang"^^schema:Person ;
    schema:dateModified "2019-05-24T23:18:17Z"^^schema:DateTime ;
    schema:datePublished "2019-05-24T23:18:17Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Bayesian Tensorized Neural Networks with Automatic Rank Selection"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.10478v1"^^schema:URL .

<951> a schema:ScholarlyArticle ;
    schema:abstract "Experience replay is widely used in deep reinforcement learning algorithmsand allows agents to remember and learn from experiences from the past. In aneffort to learn more efficiently, researchers proposed prioritized experiencereplay (PER) which samples important transitions more frequently. In thispaper, we propose Prioritized Sequence Experience Replay (PSER) a framework forprioritizing sequences of experience in an attempt to both learn moreefficiently and to obtain better performance. We compare the performance of PERand PSER sampling techniques in a tabular Q-learning environment and in DQN onthe Atari 2600 benchmark. We prove theoretically that PSER is guaranteed toconverge faster than PER and empirically show PSER substantially improves uponPER."^^schema:Text ;
    schema:author "Josh Bertram"^^schema:Person,
        "Marc Brittain"^^schema:Person,
        "Peng Wei"^^schema:Person,
        "Xuxi Yang"^^schema:Person ;
    schema:dateModified "2020-02-19T16:04:29Z"^^schema:DateTime ;
    schema:datePublished "2019-05-25T15:38:00Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Prioritized Sequence Experience Replay"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.12726v2"^^schema:URL .

<952> a schema:ScholarlyArticle ;
    schema:abstract "Exploiting the great expressive power of Deep Neural Network architectures,relies on the ability to train them. While current theoretical work provides,mostly, results showing the hardness of this task, empirical evidence usuallydiffers from this line, with success stories in abundance. A strong positionamong empirically successful architectures is captured by networks whereextensive weight sharing is used, either by Convolutional or Recurrent layers.Additionally, characterizing specific aspects of different tasks, making them\"harder\" or \"easier\", is an interesting direction explored both theoreticallyand empirically. We consider a family of ConvNet architectures, and prove thatweight sharing can be crucial, from an optimization point of view. We exploredifferent notions of the frequency, of the target function, proving necessityof the target function having some low frequency components. This necessity isnot sufficient - only with weight sharing can it be exploited, thustheoretically separating architectures using it, from others which do not. Ourtheoretical results are aligned with empirical experiments in an even moregeneral setting, suggesting viability of examination of the role played byinterleaving those aspects in broader families of tasks."^^schema:Text ;
    schema:author "Ohad Shamir"^^schema:Person,
        "Shai Shalev-Shwartz"^^schema:Person,
        "Shaked Shammah"^^schema:Person ;
    schema:dateModified "2017-06-02T13:56:59Z"^^schema:DateTime ;
    schema:datePublished "2017-06-02T13:56:59Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Weight Sharing is Crucial to Succesful Optimization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1706.00687v1"^^schema:URL .

<953> a schema:ScholarlyArticle ;
    schema:abstract "We present a novel, real-time, semantic segmentation network in which theencoder both encodes and generates the parameters (weights) of the decoder.Furthermore, to allow maximal adaptivity, the weights at each decoder blockvary spatially. For this purpose, we design a new type of hypernetwork,composed of a nested U-Net for drawing higher level context features, amulti-headed weight generating module which generates the weights of each blockin the decoder immediately before they are consumed, for efficient memoryutilization, and a primary network that is composed of novel dynamic patch-wiseconvolutions. Despite the usage of less-conventional blocks, our architectureobtains real-time performance. In terms of the runtime vs. accuracy trade-off,we surpass state of the art (SotA) results on popular semantic segmentationbenchmarks: PASCAL VOC 2012 (val. set) and real-time semantic segmentation onCityscapes, and CamVid."^^schema:Text ;
    schema:author "Lior Wolf"^^schema:Person,
        "Tal Hassner"^^schema:Person,
        "Yuval Nirkin"^^schema:Person ;
    schema:dateModified "2020-12-21T18:58:18Z"^^schema:DateTime ;
    schema:datePublished "2020-12-21T18:58:18Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.11582v1"^^schema:URL .

<954> a schema:ScholarlyArticle ;
    schema:abstract "We propose Information Theoretic-Learning (ITL) divergence measures forvariational regularization of neural networks. We also explore ITL-regularizedautoencoders as an alternative to variational autoencoding bayes, adversarialautoencoders and generative adversarial networks for randomly generating sampledata without explicitly defining a partition function. This paper alsoformalizes, generative moment matching networks under the ITL framework."^^schema:Text ;
    schema:author "Eder Santana"^^schema:Person,
        "Jose C Principe"^^schema:Person,
        "Matthew Emigh"^^schema:Person ;
    schema:dateModified "2016-03-22T01:05:47Z"^^schema:DateTime ;
    schema:datePublished "2016-03-22T01:05:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Information Theoretic-Learning Auto-Encoder"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1603.06653v1"^^schema:URL .

<955> a schema:ScholarlyArticle ;
    schema:abstract "Visuomotor control (VMC) is an effective means of achieving basicmanipulation tasks such as pushing or pick-and-place from raw images.Conditioning VMC on desired goal states is a promising way of achievingversatile skill primitives. However, common conditioning schemes either rely ontask-specific fine tuning - e.g. using one-shot imitation learning (IL) - or onsampling approaches using a forward model of scene dynamics i.e.model-predictive control (MPC), leaving deployability and planning horizonseverely limited. In this paper we propose a conditioning scheme which avoidsthese pitfalls by learning the controller and its conditioning in an end-to-endmanner. Our model predicts complex action sequences based directly on a dynamicimage representation of the robot motion and the distance to a given targetobservation. In contrast to related works, this enables our approach toefficiently perform complex manipulation tasks from raw image observationswithout predefined control primitives or test time demonstrations. We reportsignificant improvements in task success over representative MPC and ILbaselines. We also demonstrate our model's generalisation capabilities inchallenging, unseen tasks featuring visual noise, cluttered scenes and unseenobject geometries."^^schema:Text ;
    schema:author "Andrea Vedaldi"^^schema:Person,
        "Chia-Man Hung"^^schema:Person,
        "Ingmar Posner"^^schema:Person,
        "Oliver Groth"^^schema:Person ;
    schema:dateModified "2020-11-08T17:58:17Z"^^schema:DateTime ;
    schema:datePublished "2020-03-19T15:04:37Z"^^schema:DateTime ;
    schema:genre "I.2.9; I.2.10"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Goal-Conditioned End-to-End Visuomotor Control for Versatile Skill  Primitives"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08854v2"^^schema:URL .

<956> a schema:ScholarlyArticle ;
    schema:abstract "We introduce the Convolutional Conditional Neural Process (ConvCNP), a newmember of the Neural Process family that models translation equivariance in thedata. Translation equivariance is an important inductive bias for many learningproblems including time series modelling, spatial data, and images. The modelembeds data sets into an infinite-dimensional function space as opposed to afinite-dimensional vector space. To formalize this notion, we extend the theoryof neural representations of sets to include functional representations, anddemonstrate that any translation-equivariant embedding can be represented usinga convolutional deep set. We evaluate ConvCNPs in several settings,demonstrating that they achieve state-of-the-art performance compared toexisting NPs. We demonstrate that building in translation equivariance enableszero-shot generalization to challenging, out-of-domain tasks."^^schema:Text ;
    schema:author "Andrew Y. K. Foong"^^schema:Person,
        "James Requeima"^^schema:Person,
        "Jonathan Gordon"^^schema:Person,
        "Richard E. Turner"^^schema:Person,
        "Wessel P. Bruinsma"^^schema:Person,
        "Yann Dubois"^^schema:Person ;
    schema:dateModified "2020-06-25T13:20:06Z"^^schema:DateTime ;
    schema:datePublished "2019-10-29T21:56:00Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Convolutional Conditional Neural Processes"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.13556v5"^^schema:URL .

<957> a schema:ScholarlyArticle ;
    schema:abstract "When the navigational environment is known, it can be represented as a graphwhere landmarks are nodes, the robot behaviors that move from node to node areedges, and the route is a set of behavioral instructions. The route path fromsource to destination can be viewed as a class of combinatorial optimizationproblems where the path is a sequential subset from a set of discrete items.The pointer network is an attention-based recurrent network that is suitablefor such a task. In this paper, we utilize a modified R-NET with gatedattention and self-matching attention translating natural language instructionsto a high-level plan for behavioral robot navigation by developing anunderstanding of the behavioral navigational graph to enable the pointernetwork to produce a sequence of behaviors representing the path. Tests on thenavigation graph dataset show that our model outperforms the state-of-the-artapproach for both known and unknown environments."^^schema:Text ;
    schema:author "Amar Shrestha"^^schema:Person,
        "Haowen Fang"^^schema:Person,
        "Krittaphat Pugdeethosapol"^^schema:Person,
        "Qinru Qiu"^^schema:Person ;
    schema:dateModified "2020-01-08T01:14:11Z"^^schema:DateTime ;
    schema:datePublished "2020-01-08T01:14:11Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "High-Level Plan for Behavioral Robot Navigation with Natural Language  Directions and R-NET"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.02330v1"^^schema:URL .

<958> a schema:ScholarlyArticle ;
    schema:abstract "Memristive crossbars can efficiently implement Binarized Neural Networks(BNNs) wherein the weights are stored in high-resistance states (HRS) andlow-resistance states (LRS) of the synapses. We propose SwitchX mapping ofweights onto crossbars such that the power consumed by the crossbars and theimpact of crossbar non-idealities, that lead to degradation in computationalaccuracy, are minimized. Essentially, SwitchX maps the binary weights in suchmanner that the crossbar comprises of more HRS than LRS synapses. Increased HRSin a crossbar will decrease the overall output dot-product current and thuslead to power savings. Interestingly, BNNs mapped onto crossbars with SwitchXalso exhibit better robustness against adversarial attacks than thecorresponding software BNN baseline as well as the standard crossbar mappedBNNs. Finally, we combine SwitchX with state-aware training (that furtherincreases the feasibility of HRS states during weight mapping) to boost therobustness and energy-efficiency of BNN on hardware. We find that this approachyields stronger defense against adversarial attacks than Adversarial training,a state-of-the-art software defense. We perform experiments using benchmarkdatasets (CIFAR-100 &amp; CIFAR-10) and show that SwitchX combined with state-awaretraining can yield upto ~35% improvements in clean accuracy and ~6-16% inadversarial accuracies against conventional BNNs on a 32x32 crossbar, whilegaining ~22% savings in overall crossbar power consumption."^^schema:Text ;
    schema:author "Abhiroop Bhattacharjee"^^schema:Person,
        "Priyadarshini Panda"^^schema:Person ;
    schema:dateModified "2020-11-30T01:48:06Z"^^schema:DateTime ;
    schema:datePublished "2020-11-30T01:48:06Z"^^schema:DateTime ;
    schema:genre "cs.ET"^^schema:Text ;
    schema:headline "SwitchX- Gmin-Gmax Switching for Energy-Efficient and Robust  Implementation of Binary Neural Networks on Memristive Xbars"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.14498v1"^^schema:URL .

<959> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a novel framework for automatic learning of complexstrategies in human decision making. The task that we are interested in is tobetter facilitate long term planning for complex, multi-step events. We observetemporal relationships at the subtask level of expert demonstrations, anddetermine the different strategies employed in order to successfully complete atask. To capture the relationship between the subtasks and the overall goal, weutilise two external memory modules, one for capturing dependencies within asingle expert demonstration, such as the sequential relationship amongdifferent sub tasks, and a global memory module for modelling task levelcharacteristics such as best practice employed by different humans based ontheir domain expertise. Furthermore, we demonstrate how the hidden staterepresentation of the memory can be used as a reward signal to smooth the statetransitions, eradicating subtle changes. We evaluate the effectiveness of theproposed model for an autonomous highway driving application, where wedemonstrate its capability to learn different expert policies and outperformstate-of-the-art methods. The scope in industrial applications extends to anyrobotics and automation application which requires learning from complexdemonstrations containing series of subtasks."^^schema:Text ;
    schema:author "Clinton Fookes"^^schema:Person,
        "Simon Denman"^^schema:Person,
        "Sridha Sridharan"^^schema:Person,
        "Tharindu Fernando"^^schema:Person ;
    schema:dateModified "2018-05-13T22:56:58Z"^^schema:DateTime ;
    schema:datePublished "2018-05-13T22:56:58Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Learning Temporal Strategic Relationships using Generative Adversarial  Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.04969v1"^^schema:URL .

<96> a schema:ScholarlyArticle ;
    schema:abstract "Network pruning is widely used for reducing the heavy inference cost of deepmodels in low-resource settings. A typical pruning algorithm is a three-stagepipeline, i.e., training (a large model), pruning and fine-tuning. Duringpruning, according to a certain criterion, redundant weights are pruned andimportant weights are kept to best preserve the accuracy. In this work, we makeseveral surprising observations which contradict common beliefs. For allstate-of-the-art structured pruning algorithms we examined, fine-tuning apruned model only gives comparable or worse performance than training thatmodel with randomly initialized weights. For pruning algorithms which assume apredefined target network architecture, one can get rid of the full pipelineand directly train the target network from scratch. Our observations areconsistent for multiple network architectures, datasets, and tasks, which implythat: 1) training a large, over-parameterized model is often not necessary toobtain an efficient final model, 2) learned \"important\" weights of the largemodel are typically not useful for the small pruned model, 3) the prunedarchitecture itself, rather than a set of inherited \"important\" weights, ismore crucial to the efficiency in the final model, which suggests that in somecases pruning can be useful as an architecture search paradigm. Our resultssuggest the need for more careful baseline evaluations in future research onstructured pruning methods. We also compare with the \"Lottery TicketHypothesis\" (Frankle &amp; Carbin 2019), and find that with optimal learning rate,the \"winning ticket\" initialization as used in Frankle &amp; Carbin (2019) does notbring improvement over random initialization."^^schema:Text ;
    schema:author "Gao Huang"^^schema:Person,
        "Mingjie Sun"^^schema:Person,
        "Tinghui Zhou"^^schema:Person,
        "Trevor Darrell"^^schema:Person,
        "Zhuang Liu"^^schema:Person ;
    schema:commentCount "214"^^schema:Integer ;
    schema:dateModified "2019-03-05T05:58:11Z"^^schema:DateTime ;
    schema:datePublished "2018-10-11T22:15:28Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Rethinking the Value of Network Pruning"^^schema:Text ;
    schema:publisher "ICLR (Poster)"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1810.05270v2"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=3601827758437367761&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<960> a schema:ScholarlyArticle ;
    schema:abstract "Minimum expected distance estimation (MEDE) algorithms have been widely usedfor probabilistic models with intractable likelihood functions and they havebecome increasingly popular due to their use in implicit generative modeling(e.g. Wasserstein generative adversarial networks, Wasserstein autoencoders).Emerging from computational optimal transport, the Sliced-Wasserstein (SW)distance has become a popular choice in MEDE thanks to its simplicity andcomputational benefits. While several studies have reported empirical successon generative modeling with SW, the theoretical properties of such estimatorshave not yet been established. In this study, we investigate the asymptoticproperties of estimators that are obtained by minimizing SW. We first show thatconvergence in SW implies weak convergence of probability measures in generalWasserstein spaces. Then we show that estimators obtained by minimizing SW (andalso an approximate version of SW) are asymptotically consistent. We finallyprove a central limit theorem, which characterizes the asymptotic distributionof the estimators and establish a convergence rate of $\\sqrt{n}$, where $n$denotes the number of observed data points. We illustrate the validity of ourtheory on both synthetic data and neural networks."^^schema:Text ;
    schema:author "Alain Durmus"^^schema:Person,
        "Kimia Nadjahi"^^schema:Person,
        "Roland Badeau"^^schema:Person,
        "Umut Şimşekli"^^schema:Person ;
    schema:dateModified "2020-03-24T13:56:43Z"^^schema:DateTime ;
    schema:datePublished "2019-06-11T12:13:12Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Asymptotic Guarantees for Learning Generative Models with the  Sliced-Wasserstein Distance"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1906.04516v2"^^schema:URL .

<961> a schema:ScholarlyArticle ;
    schema:abstract "This tutorial material on Convolutional Neural Networks (CNN) and itsapplications in digital media research is based on the concept of SymbolicTensor Neural Networks. The set of STNN expressions is specified in Backus-NaurForm (BNF) which is annotated by constraints typical for labeled acyclicdirected graphs (DAG). The BNF induction begins from a collection of neuralunit symbols with extra (up to five) decoration fields (including tensor depthand sharing fields). The inductive rules provide not only the general graphstructure but also the specific shortcuts for residual blocks of units. Asyntactic mechanism for network fragments modularization is introduced via userdefined units and their instances. Moreover, the dual BNF rules are specifiedin order to generate the Dual Symbolic Tensor Neural Network (DSTNN). Thejoined interpretation of STNN and DSTNN provides the correct flow of gradienttensors, back propagated at the training stage. The proposed symbolicrepresentation of CNNs is illustrated for six generic digital mediaapplications (CREAMS): Compression, Recognition, Embedding, Annotation, 3DModeling for human-computer interfacing, and data Security based on digitalmedia objects. In order to make the CNN description and its gradient flowcomplete, for all presented applications, the symbolic representations ofmathematically defined loss/gain functions and gradient flow equations for allused core units, are given. The tutorial is to convince the reader that STNN isnot only a convenient symbolic notation for public presentations of CNN basedsolutions for CREAMS problems but also that it is a design blueprint with apotential for automatic generation of application source code."^^schema:Text ;
    schema:author "Wladyslaw Skarbek"^^schema:Person ;
    schema:dateModified "2018-12-12T09:16:30Z"^^schema:DateTime ;
    schema:datePublished "2018-09-18T08:25:01Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.MM"^^schema:Text ;
    schema:headline "Symbolic Tensor Neural Networks for Digital Media - from Tensor  Processing via BNF Graph Rules to CREAMS Applications"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.06582v2"^^schema:URL .

<962> a schema:ScholarlyArticle ;
    schema:abstract "Building machine learning models that are fair with respect to anunprivileged group is a topical problem. Modern fairness-aware algorithms oftenignore causal effects and enforce fairness through modifications applicable toonly a subset of machine learning models. In this work, we propose a newdefinition of fairness that incorporates causality through the ControlledDirect Effect (CDE). We develop regularizations to tackle classical fairnessmeasures and present a causal regularization that satisfies our new fairnessdefinition by removing the impact of unprivileged group variables on the modeloutcomes as measured by the CDE. These regularizations are applicable to anymodel trained using by iteratively minimizing a loss through differentiation.We demonstrate our approaches using both gradient boosting and logisticregression on: a synthetic dataset, the UCI Adult (Census) Dataset, and areal-world credit-risk dataset. Our results were found to mitigate unfairnessfrom the predictions with small reductions in model performance."^^schema:Text ;
    schema:author "James M. Hickey"^^schema:Person,
        "Pietro G. Di Stefano"^^schema:Person,
        "Vlasios Vasileiou"^^schema:Person ;
    schema:dateModified "2020-02-26T11:28:34Z"^^schema:DateTime ;
    schema:datePublished "2020-02-25T10:13:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Counterfactual fairness: removing direct effects through regularization"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.10774v2"^^schema:URL .

<963> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we aim to do code completion based on implementing a NeuralNetwork from Li et. al.. Our contribution is that we use an encoding that isin-between character and word encoding called Byte Pair Encoding (BPE). We usethis on the source code files treating them as natural text without first goingthrough the abstract syntax tree (AST). We have implemented two models: anattention-enhanced LSTM and a pointer network, where the pointer network wasoriginally introduced to solve out of vocabulary problems. We are interested tosee if BPE can replace the need for the pointer network for code completion."^^schema:Text ;
    schema:author "Bastijn Kostense"^^schema:Person,
        "Nikhil Saldanha"^^schema:Person,
        "Youri Arkesteijn"^^schema:Person ;
    schema:dateModified "2020-04-14T08:00:40Z"^^schema:DateTime ;
    schema:datePublished "2020-04-14T08:00:40Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SE"^^schema:Text ;
    schema:headline "Code Completion using Neural Attention and Byte Pair Encoding"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.06343v1"^^schema:URL .

<964> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (UNMT) has recently attracted greatinterest in the machine translation community. The main advantage of the UNMTlies in its easy collection of required large training text sentences whilewith only a slightly worse performance than supervised neural machinetranslation which requires expensive annotated translation pairs on sometranslation tasks. In most studies, the UMNT is trained with clean data withoutconsidering its robustness to the noisy data. However, in real-world scenarios,there usually exists noise in the collected input sentences which degrades theperformance of the translation system since the UNMT is sensitive to the smallperturbations of the input sentences. In this paper, we first time explicitlytake the noisy data into consideration to improve the robustness of the UNMTbased systems. First of all, we clearly defined two types of noises in trainingsentences, i.e., word noise and word order noise, and empirically investigateits effect in the UNMT, then we propose adversarial training methods withdenoising process in the UNMT. Experimental results on several language pairsshow that our proposed methods substantially improved the robustness of theconventional UNMT systems in noisy scenarios."^^schema:Text ;
    schema:author "Eiichiro Sumita"^^schema:Person,
        "Haipeng Sun"^^schema:Person,
        "Kehai Chen"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Tiejun Zhao"^^schema:Person,
        "Xugang Lu"^^schema:Person ;
    schema:dateModified "2020-12-03T03:19:36Z"^^schema:DateTime ;
    schema:datePublished "2020-02-28T05:17:55Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Robust Unsupervised Neural Machine Translation with Adversarial  Denoising Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.12549v2"^^schema:URL .

<965> a schema:ScholarlyArticle ;
    schema:abstract "For a data holder, such as a hospital or a government entity, who has aprivately held collection of personal data, in which the revealing and/orprocessing of the personal identifiable data is restricted and prohibited bylaw. Then, \"how can we ensure the data holder does conceal the identity of eachindividual in the imagery of personal data while still preserving certainuseful aspects of the data after de-identification?\" becomes a challenge issue.In this work, we propose an approach towards high-resolution facial imagede-identification, called k-Same-Siamese-GAN, which leverages thek-Same-Anonymity mechanism, the Generative Adversarial Network, and thehyperparameter tuning methods. Moreover, to speed up model training and reducememory consumption, the mixed precision training technique is also applied tomake kSS-GAN provide guarantees regarding privacy protection on close-formidentities and be trained much more efficiently as well. Finally, to validateits applicability, the proposed work has been applied to actual datasets - RafDand CelebA for performance testing. Besides protecting privacy ofhigh-resolution facial images, the proposed system is also justified for itsability in automating parameter tuning and breaking through the limitation ofthe number of adjustable parameters."^^schema:Text ;
    schema:author "Ja-Ling Wu"^^schema:Person,
        "Jyh-Shing Jang"^^schema:Person,
        "Kuo-Teng Ding"^^schema:Person,
        "Min-Jhih Huang"^^schema:Person,
        "Yi-Lun Pan"^^schema:Person ;
    schema:dateModified "2019-09-17T05:24:19Z"^^schema:DateTime ;
    schema:datePublished "2019-03-27T14:27:07Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "k-Same-Siamese-GAN: k-Same Algorithm with Generative Adversarial Network  for Facial Image De-identification with Hyperparameter Tuning and Mixed  Precision Training"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1904.00816v2"^^schema:URL .

<966> a schema:ScholarlyArticle ;
    schema:abstract "Graphs play an important role in many applications. Recently, Graph NeuralNetworks (GNNs) have achieved promising results in graph analysis tasks. Somestate-of-the-art GNN models have been proposed, e.g., Graph ConvolutionalNetworks (GCNs), Graph Attention Networks (GATs), etc. Despite these successes,most of the GNNs only have shallow structure. This causes the low expressivepower of the GNNs. To fully utilize the power of the deep neural network, somedeep GNNs have been proposed recently. However, the design of deep GNNsrequires significant architecture engineering. In this work, we propose amethod to automate the deep GNNs design. In our proposed method, we add a newtype of skip connection to the GNNs search space to encourage feature reuse andalleviate the vanishing gradient problem. We also allow our evolutionaryalgorithm to increase the layers of GNNs during the evolution to generatedeeper networks. We evaluate our method in the graph node classification task.The experiments show that the GNNs generated by our method can obtainstate-of-the-art results in Cora, Citeseer, Pubmed and PPI datasets."^^schema:Text ;
    schema:author "Irwin King"^^schema:Person,
        "Yaoman Li"^^schema:Person ;
    schema:dateModified "2020-11-23T09:04:17Z"^^schema:DateTime ;
    schema:datePublished "2020-11-23T09:04:17Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.SI"^^schema:Text ;
    schema:headline "AutoGraph: Automated Graph Neural Network"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2011.11288v1"^^schema:URL .

<967> a schema:ScholarlyArticle ;
    schema:abstract "Spatial transformer networks (STNs) were designed to enable CNNs to learninvariance to image transformations. STNs were originally proposed to transformCNN feature maps as well as input images. This enables the use of more complexfeatures when predicting transformation parameters. However, since STNs performa purely spatial transformation, they do not, in the general case, have theability to align the feature maps of a transformed image and its original. Wepresent a theoretical argument for this and investigate the practicalimplications, showing that this inability is coupled with decreasedclassification accuracy. We advocate taking advantage of more complex featuresin deeper layers by instead sharing parameters between the classification andthe localisation network."^^schema:Text ;
    schema:author "Lukas Finnveden"^^schema:Person,
        "Tony Lindeberg"^^schema:Person,
        "Ylva Jansson"^^schema:Person ;
    schema:dateModified "2020-01-14T12:59:56Z"^^schema:DateTime ;
    schema:datePublished "2020-01-14T12:59:56Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "The problems with using STNs to align CNN feature maps"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2001.05858v1"^^schema:URL .

<968> a schema:ScholarlyArticle ;
    schema:abstract "It is becoming increasingly clear that many machine learning classifiers arevulnerable to adversarial examples. In attempting to explain the origin ofadversarial examples, previous studies have typically focused on the fact thatneural networks operate on high dimensional data, they overfit, or they are toolinear. Here we argue that the origin of adversarial examples is primarily dueto an inherent uncertainty that neural networks have about their predictions.We show that the functional form of this uncertainty is independent ofarchitecture, dataset, and training protocol; and depends only on thestatistics of the logit differences of the network, which do not changesignificantly during training. This leads to adversarial error having auniversal scaling, as a power-law, with respect to the size of the adversarialperturbation. We show that this universality holds for a broad range ofdatasets (MNIST, CIFAR10, ImageNet, and random data), models (includingstate-of-the-art deep networks, linear models, adversarially trained networks,and networks trained on randomly shuffled labels), and attacks (FGSM, stepl.l., PGD). Motivated by these results, we study the effects of reducingprediction entropy on adversarial robustness. Finally, we study the effect ofnetwork architectures on adversarial sensitivity. To do this, we use neuralarchitecture search with reinforcement learning to find adversarially robustarchitectures on CIFAR10. Our resulting architecture is more robust to white\\emph{and} black box attacks compared to previous attempts."^^schema:Text ;
    schema:author "Barret Zoph"^^schema:Person,
        "Ekin D. Cubuk"^^schema:Person,
        "Quoc V. Le"^^schema:Person,
        "Samuel S. Schoenholz"^^schema:Person ;
    schema:dateModified "2017-11-08T06:54:49Z"^^schema:DateTime ;
    schema:datePublished "2017-11-08T06:54:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Intriguing Properties of Adversarial Examples"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1711.02846v1"^^schema:URL .

<969> a schema:ScholarlyArticle ;
    schema:abstract "Attention-based sequence-to-sequence (seq2seq) speech synthesis has achievedextraordinary performance. But a studio-quality corpus with manualtranscription is necessary to train such seq2seq systems. In this paper, wepropose an approach to build high-quality and stable seq2seq based speechsynthesis system using challenging found data, where training speech containsnoisy interferences (acoustic noise) and texts are imperfect speech recognitiontranscripts (textual noise). To deal with text-side noise, we propose a VQVAEbased heuristic method to compensate erroneous linguistic feature with phoneticinformation learned directly from speech. As for the speech-side noise, wepropose to learn a noise-independent feature in the auto-regressive decoderthrough adversarial training and data augmentation, which does not need anextra speech enhancement model. Experiments show the effectiveness of theproposed approach in dealing with text-side and speech-side noise. Surpassingthe denoising approach based on a state-of-the-art speech enhancement model,our system built on noisy found data can synthesize clean and high-qualityspeech with MOS close to the system built on the clean counterpart."^^schema:Text ;
    schema:author "Lei Xie"^^schema:Person,
        "Shan Yang"^^schema:Person,
        "Yuxuan Wang"^^schema:Person ;
    schema:dateModified "2020-04-28T15:32:45Z"^^schema:DateTime ;
    schema:datePublished "2020-04-28T15:32:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.SD"^^schema:Text,
        "eess.AS"^^schema:Text ;
    schema:headline "Adversarial Feature Learning and Unsupervised Clustering based Speech  Synthesis for Found Data with Acoustic and Textual Noise"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.13595v1"^^schema:URL .

<97> a schema:ScholarlyArticle ;
    schema:abstract "Cross-entropy loss together with softmax is arguably one of the most commonused supervision components in convolutional neural networks (CNNs). Despiteits simplicity, popularity and excellent performance, the component does notexplicitly encourage discriminative learning of features. In this paper, wepropose a generalized large-margin softmax (L-Softmax) loss which explicitlyencourages intra-class compactness and inter-class separability between learnedfeatures. Moreover, L-Softmax not only can adjust the desired margin but alsocan avoid overfitting. We also show that the L-Softmax loss can be optimized bytypical stochastic gradient descent. Extensive experiments on four benchmarkdatasets demonstrate that the deeply-learned features with L-softmax lossbecome more discriminative, hence significantly boosting the performance on avariety of visual classification and verification tasks."^^schema:Text ;
    schema:author "Meng Yang"^^schema:Person,
        "Weiyang Liu"^^schema:Person,
        "Yandong Wen"^^schema:Person,
        "Zhiding Yu"^^schema:Person ;
    schema:commentCount "511"^^schema:Integer ;
    schema:dateModified "2017-11-17T23:23:09Z"^^schema:DateTime ;
    schema:datePublished "2016-12-07T15:36:11Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Large-Margin Softmax Loss for Convolutional Neural Networks"^^schema:Text ;
    schema:publisher "ICML, 507-516"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1612.02295v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=132136711413140598&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<970> a schema:ScholarlyArticle ;
    schema:abstract "In this work, we present HyperFlow - a novel generative model that leverageshypernetworks to create continuous 3D object representations in a form oflightweight surfaces (meshes), directly out of point clouds. Efficient objectrepresentations are essential for many computer vision applications, includingrobotic manipulation and autonomous driving. However, creating thoserepresentations is often cumbersome, because it requires processing unorderedsets of point clouds. Therefore, it is either computationally expensive, due toadditional optimization constraints such as permutation invariance, or leads toquantization losses introduced by binning point clouds into discrete voxels.Inspired by mesh-based representations of objects used in computer graphics, wepostulate a fundamentally different approach and represent 3D objects as afamily of surfaces. To that end, we devise a generative model that uses ahypernetwork to return the weights of a Continuous Normalizing Flows (CNF)target network. The goal of this target network is to map points from aprobability distribution into a 3D mesh. To avoid numerical instability of theCNF on compact support distributions, we propose a new Spherical Log-Normalfunction which models density of 3D points around object surfaces mimickingnoise introduced by 3D capturing devices. As a result, we obtain continuousmesh-based object representations that yield better qualitative results thancompeting approaches, while reducing training time by over an order ofmagnitude."^^schema:Text ;
    schema:author "Jacek Tabor"^^schema:Person,
        "Maciej Zięba"^^schema:Person,
        "Przemysław Spurek"^^schema:Person,
        "Tomasz Trzciński"^^schema:Person ;
    schema:dateModified "2020-06-15T19:18:02Z"^^schema:DateTime ;
    schema:datePublished "2020-06-15T19:18:02Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "eess.IV"^^schema:Text ;
    schema:headline "HyperFlow: Representing 3D Objects as Surfaces"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.08710v1"^^schema:URL .

<971> a schema:ScholarlyArticle ;
    schema:abstract "While deep reinforcement learning has achieved tremendous successes invarious applications, most existing works only focus on maximizing the expectedvalue of total return and thus ignore its inherent stochasticity. Suchstochasticity is also known as the aleatoric uncertainty and is closely relatedto the notion of risk. In this work, we make the first attempt to studyrisk-sensitive deep reinforcement learning under the average reward settingwith the variance risk criteria. In particular, we focus on avariance-constrained policy optimization problem where the goal is to find apolicy that maximizes the expected value of the long-run average reward,subject to a constraint that the long-run variance of the average reward isupper bounded by a threshold. Utilizing Lagrangian and Fenchel dualities, wetransform the original problem into an unconstrained saddle-point policyoptimization problem, and propose an actor-critic algorithm that iterativelyand efficiently updates the policy, the Lagrange multiplier, and the Fencheldual variable. When both the value and policy functions are represented bymulti-layer overparameterized neural networks, we prove that our actor-criticalgorithm generates a sequence of policies that finds a globally optimal policyat a sublinear rate."^^schema:Text ;
    schema:author "Ethan X. Fang"^^schema:Person,
        "Han Zhong"^^schema:Person,
        "Zhaoran Wang"^^schema:Person,
        "Zhuoran Yang"^^schema:Person ;
    schema:dateModified "2020-12-28T05:02:26Z"^^schema:DateTime ;
    schema:datePublished "2020-12-28T05:02:26Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.OC"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds  Globally Optimal Policy"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.14098v1"^^schema:URL .

<972> a schema:ScholarlyArticle ;
    schema:abstract "Inverse reinforcement learning (IRL) is used to infer the reward functionfrom the actions of an expert running a Markov Decision Process (MDP). A novelapproach using variational inference for learning the reward function isproposed in this research. Using this technique, the intractable posteriordistribution of the continuous latent variable (the reward function in thiscase) is analytically approximated to appear to be as close to the prior beliefwhile trying to reconstruct the future state conditioned on the current stateand action. The reward function is derived using a well-known deep generativemodel known as Conditional Variational Auto-encoder (CVAE) with Wassersteinloss function, thus referred to as Conditional Wasserstein Auto-encoder-IRL(CWAE-IRL), which can be analyzed as a combination of the backward and forwardinference. This can then form an efficient alternative to the previousapproaches to IRL while having no knowledge of the system dynamics of theagent. Experimental results on standard benchmarks such as objectworld andpendulum show that the proposed algorithm can effectively learn the latentreward function in complex, high-dimensional environments."^^schema:Text ;
    schema:author "Arpan Kusari"^^schema:Person ;
    schema:dateModified "2019-10-02T14:06:23Z"^^schema:DateTime ;
    schema:datePublished "2019-10-02T14:06:23Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement  Learning problem"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.00584v1"^^schema:URL .

<973> a schema:ScholarlyArticle ;
    schema:abstract "Graph neural networks are currently leading the performance charts inlearning-based molecule property prediction and classification. Computationalchemistry has, therefore, become the a prominent testbed for generic graphneural networks, as well as for specialized message passing methods. In thiswork, we demonstrate that the replacement of the underlying networks withhypernetworks leads to a boost in performance, obtaining state of the artresults in various benchmarks. A major difficulty in the application ofhypernetworks is their lack of stability. We tackle this by combining thecurrent message and the first message. A recent work has tackled the traininginstability of hypernetworks in the context of error correcting codes, byreplacing the activation function of the message passing network with alow-order Taylor approximation of it. We demonstrate that our generic solutioncan replace this domain-specific solution."^^schema:Text ;
    schema:author "Eliya Nachmani"^^schema:Person,
        "Lior Wolf"^^schema:Person ;
    schema:dateModified "2020-02-01T16:44:34Z"^^schema:DateTime ;
    schema:datePublished "2020-02-01T16:44:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Molecule Property Prediction and Classification with Graph Hypernetworks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.00240v1"^^schema:URL .

<974> a schema:ScholarlyArticle ;
    schema:abstract "Deriving event storylines is an effective summarization method to succinctlyorganize extensive information, which can significantly alleviate the pain ofinformation overload. The critical challenge is the lack of widely recognizeddefinition of storyline metric. Prior studies have developed various approachesbased on different assumptions about users' interests. These works can extractinteresting patterns, but their assumptions do not guarantee that the derivedpatterns will match users' preference. On the other hand, their exclusivenessof single modality source misses cross-modality information. This paperproposes a method, multimodal imitation learning via generative adversarialnetworks(MIL-GAN), to directly model users' interests as reflected by variousdata. In particular, the proposed model addresses the critical challenge byimitating users' demonstrated storylines. Our proposed model is designed tolearn the reward patterns given user-provided storylines and then applies thelearned policy to unseen data. The proposed approach is demonstrated to becapable of acquiring the user's implicit intent and outperforming competingmethods by a substantial margin with a user study."^^schema:Text ;
    schema:author "Arnold P. Boedihardjo"^^schema:Person,
        "Chang-Tien Lu"^^schema:Person,
        "Jing Dai"^^schema:Person,
        "Xuchao Zhang"^^schema:Person,
        "Zhiqian Chen"^^schema:Person ;
    schema:dateModified "2017-12-05T02:51:35Z"^^schema:DateTime ;
    schema:datePublished "2017-12-05T02:51:35Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Multimodal Storytelling via Generative Adversarial Imitation Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1712.01455v1"^^schema:URL .

<975> a schema:ScholarlyArticle ;
    schema:abstract "Capsule Networks (CapsNets) are brand-new architectures that have shownground-breaking results in certain areas of Computer Vision (CV). In 2017,Hinton and his team introduced CapsNets with routing-by-agreement in \"Sabour etal\" and in a more recent paper \"Matrix Capsules with EM Routing\" they proposeda more complete architecture with Expectation-Maximization (EM) algorithm.Unlike the traditional convolutional neural networks (CNNs), this architectureis able to preserve the pose of the objects in the picture. Due to thischaracteristic, it has been able to beat the previous state-of-theart resultson the smallNORB dataset, which includes samples with various view points.Also, this architecture is more robust to white box adversarial attacks.However, CapsNets have two major drawbacks. They can't perform as well as CNNson complex datasets and, they need a huge amount of time for training. We tryto mitigate these shortcomings by finding optimum settings of EM routingiterations for training CapsNets. Unlike the past studies, we use un-equalnumbers of EM routing iterations for different stages of the CapsNet. For ourresearch, we use three datasets: Yale face dataset, Belgium Traffic Signdataset, and Fashion-MNIST dataset."^^schema:Text ;
    schema:author "Amin Nasim Saravi"^^schema:Person,
        "Hassan Khotanlou"^^schema:Person,
        "Moein Hasani"^^schema:Person ;
    schema:dateModified "2020-07-31T13:10:16Z"^^schema:DateTime ;
    schema:datePublished "2019-12-11T14:13:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "An Efficient Approach for Using Expectation Maximization Algorithm in  Capsule Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1912.05333v3"^^schema:URL .

<976> a schema:ScholarlyArticle ;
    schema:abstract "Policy optimization methods are one of the most widely used classes ofReinforcement Learning (RL) algorithms. Yet, so far, such methods have beenmostly analyzed from an optimization perspective, without addressing theproblem of exploration, or by making strong assumptions on the interaction withthe environment. In this paper we consider model-based RL in the tabularfinite-horizon MDP setting with unknown transitions and bandit feedback. Forthis setting, we propose an optimistic trust region policy optimization (TRPO)algorithm for which we establish $\\tilde O(\\sqrt{S^2 A H^4 K})$ regret forstochastic rewards. Furthermore, we prove $\\tilde O( \\sqrt{ S^2 A H^4 } K^{2/3}) $ regret for adversarial rewards. Interestingly, this result matches previousbounds derived for the bandit feedback case, yet with known transitions. To thebest of our knowledge, the two results are the first sub-linear regret boundsobtained for policy optimization algorithms with unknown transitions and banditfeedback."^^schema:Text ;
    schema:author "Aviv Rosenberg"^^schema:Person,
        "Lior Shani"^^schema:Person,
        "Shie Mannor"^^schema:Person,
        "Yonathan Efroni"^^schema:Person ;
    schema:dateModified "2020-06-18T17:13:53Z"^^schema:DateTime ;
    schema:datePublished "2020-02-19T15:41:18Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Optimistic Policy Optimization with Bandit Feedback"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.08243v2"^^schema:URL .

<977> a schema:ScholarlyArticle ;
    schema:abstract "Traditional Convolutional Neural Networks (CNNs) typically use the sameactivation function (usually ReLU) for all neurons with non-linear mappingoperations. For example, the deep convolutional architecture Inception-v4 usesReLU. To improve the classification performance of traditional CNNs, a new\"Multi-function Convolutional Neural Network\" (MCNN) is created by usingdifferent activation functions for different neurons. For $n$ neurons and $m$different activation functions, there are a total of $m^n-m$ MCNNs and only $m$traditional CNNs. Therefore, the best model is very likely to be chosen fromMCNNs because there are $m^n-2m$ more MCNNs than traditional CNNs. Forperformance analysis, two different datasets for two applications (classifyinghandwritten digits from the MNIST database and classifying brain MRI imagesinto one of the four stages of Alzheimer's disease (AD)) are used. For bothapplications, an activation function is randomly selected for each layer of aMCNN. For the AD diagnosis application, MCNNs using a newly createdmulti-function Inception-v4 architecture are constructed. Overall, simulationsshow that MCNNs can outperform traditional CNNs in terms of multi-classclassification accuracy for both applications. An important future researchwork will be to efficiently select the best MCNN from $m^n-m$ candidate MCNNs.Current CNN software only provides users with partial functionality of MCNNssince different layers can use different activation functions but notindividual neurons in the same layer. Thus, modifying current CNN softwaresystems such as ResNets, DenseNets, and Dual Path Networks by using multipleactivation functions and developing more effective and faster MCNN softwaresystems and tools would be very useful to solve difficult practical imageclassification problems."^^schema:Text ;
    schema:author "Luna M. Zhang"^^schema:Person ;
    schema:dateModified "2018-05-30T03:14:03Z"^^schema:DateTime ;
    schema:datePublished "2018-05-30T03:14:03Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Multi-function Convolutional Neural Networks for Improving Image  Classification Performance"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1805.11788v1"^^schema:URL .

<978> a schema:ScholarlyArticle ;
    schema:abstract "The wide-spread availability of rich data has fueled the growth of machinelearning applications in numerous domains. However, growth in domains withhighly-sensitive data (e.g., medical) is largely hindered as the private natureof data prohibits it from being shared. To this end, we proposeGradient-sanitized Wasserstein Generative Adversarial Networks (GS-WGAN), whichallows releasing a sanitized form of the sensitive data with rigorous privacyguarantees. In contrast to prior work, our approach is able to distort gradientinformation more precisely, and thereby enabling training deeper models whichgenerate more informative samples. Moreover, our formulation naturally allowsfor training GANs in both centralized and federated (i.e., decentralized) datascenarios. Through extensive experiments, we find our approach consistentlyoutperforms state-of-the-art approaches across multiple metrics (e.g., samplequality) and datasets."^^schema:Text ;
    schema:author "Dingfan Chen"^^schema:Person,
        "Mario Fritz"^^schema:Person,
        "Tribhuvanesh Orekondy"^^schema:Person ;
    schema:dateModified "2020-06-15T10:01:01Z"^^schema:DateTime ;
    schema:datePublished "2020-06-15T10:01:01Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially  Private Generators"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2006.08265v1"^^schema:URL .

<979> a schema:ScholarlyArticle ;
    schema:abstract "Unsupervised neural machine translation (UNMT) that relies solely on massivemonolingual corpora has achieved remarkable results in several translationtasks. However, in real-world scenarios, massive monolingual corpora do notexist for some extremely low-resource languages such as Estonian, and UNMTsystems usually perform poorly when there is not an adequate training corpusfor one language. In this paper, we first define and analyze the unbalancedtraining data scenario for UNMT. Based on this scenario, we propose UNMTself-training mechanisms to train a robust UNMT system and improve itsperformance in this case. Experimental results on several language pairs showthat the proposed methods substantially outperform conventional UNMT systems."^^schema:Text ;
    schema:author "Eiichiro Sumita"^^schema:Person,
        "Haipeng Sun"^^schema:Person,
        "Kehai Chen"^^schema:Person,
        "Masao Utiyama"^^schema:Person,
        "Rui Wang"^^schema:Person,
        "Tiejun Zhao"^^schema:Person ;
    schema:dateModified "2020-04-09T12:07:17Z"^^schema:DateTime ;
    schema:datePublished "2020-04-09T12:07:17Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Self-Training for Unsupervised Neural Machine Translation in Unbalanced  Training Data Scenarios"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2004.04507v1"^^schema:URL .

<98> a schema:ScholarlyArticle ;
    schema:abstract "This work aims to address the problem of image-based question-answering (QA)with new models and datasets. In our work, we propose to use neural networksand visual semantic embeddings, without intermediate stages such as objectdetection and image segmentation, to predict answers to simple questions aboutimages. Our model performs 1.8 times better than the only published results onan existing image QA dataset. We also present a question generation algorithmthat converts image descriptions, which are widely available, into QA form. Weused this algorithm to produce an order-of-magnitude larger dataset, with moreevenly distributed answers. A suite of baseline results on this new dataset arealso presented."^^schema:Text ;
    schema:author "Mengye Ren"^^schema:Person,
        "Richard Zemel"^^schema:Person,
        "Ryan Kiros"^^schema:Person ;
    schema:commentCount "470"^^schema:Integer ;
    schema:dateModified "2015-11-29T22:45:12Z"^^schema:DateTime ;
    schema:datePublished "2015-05-08T15:59:44Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text,
        "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Exploring Models and Data for Image Question Answering"^^schema:Text ;
    schema:publisher "Proceedings of the 28th International Conference on Neural Information …"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1505.02074v4"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=11183301518990088958&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<980> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose an actor ensemble algorithm, named ACE, forcontinuous control with a deterministic policy in reinforcement learning. InACE, we use actor ensemble (i.e., multiple actors) to search the global maximaof the critic. Besides the ensemble perspective, we also formulate ACE in theoption framework by extending the option-critic architecture with deterministicintra-option policies, revealing a relationship between ensemble and options.Furthermore, we perform a look-ahead tree search with those actors and alearned value prediction model, resulting in a refined value estimation. Wedemonstrate a significant performance boost of ACE over DDPG and its variantsin challenging physical robot simulators."^^schema:Text ;
    schema:author "Hao Chen"^^schema:Person,
        "Hengshuai Yao"^^schema:Person,
        "Shangtong Zhang"^^schema:Person ;
    schema:dateModified "2018-11-06T22:32:55Z"^^schema:DateTime ;
    schema:datePublished "2018-11-06T22:32:55Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1811.02696v1"^^schema:URL .

<981> a schema:ScholarlyArticle ;
    schema:abstract "In recent work, it was shown that combining multi-kernel based support vectormachines (SVMs) can lead to near state-of-the-art performance on an actionrecognition dataset (HMDB-51 dataset). This was 0.4\\% lower than frameworksthat used hand-crafted features in addition to the deep convolutional featureextractors. In the present work, we show that combining distributed GaussianProcesses with multi-stream deep convolutional neural networks (CNN) alleviatethe need to augment a neural network with hand-crafted features. In contrast toprior work, we treat each deep neural convolutional network as an expertwherein the individual predictions (and their respective uncertainties) arecombined into a Product of Experts (PoE) framework."^^schema:Text ;
    schema:author "Biswa Sengupta"^^schema:Person,
        "Yu Qian"^^schema:Person ;
    schema:dateModified "2017-08-18T07:51:43Z"^^schema:DateTime ;
    schema:datePublished "2017-08-18T07:51:43Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.NE"^^schema:Text,
        "stat.CO"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Pillar Networks++: Distributed non-parametric deep and wide networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1708.06250v1"^^schema:URL .

<982> a schema:ScholarlyArticle ;
    schema:abstract "5G cellular networks are being deployed all over the world and thisarchitecture supports ultra-dense network (UDN) deployment. Small cells have avery important role in providing 5G connectivity to the end users. Exponentialincreases in devices, data and network demands make it mandatory for theservice providers to manage handovers better, to cater to the services that auser desire. In contrast to any traditional handover improvement scheme, wedevelop a 'Deep-Mobility' model by implementing a deep learning neural network(DLNN) to manage network mobility, utilizing in-network deep learning andprediction. We use network key performance indicators (KPIs) to train our modelto analyze network traffic and handover requirements. In this method, RF signalconditions are continuously observed and tracked using deep learning neuralnetworks such as the Recurrent neural network (RNN) or Long Short-Term Memorynetwork (LSTM) and system level inputs are also considered in conjunction, totake a collective decision for a handover. We can study multiple parameters andinteractions between system events along with the user mobility, which wouldthen trigger a handoff in any given scenario. Here, we show the fundamentalmodeling approach and demonstrate usefulness of our model while investigatingimpacts and sensitivities of certain KPIs from the user equipment (UE) andnetwork side."^^schema:Text ;
    schema:author "Anurag Thantharate"^^schema:Person,
        "Cory Beard"^^schema:Person,
        "Rahul Arun Paropkari"^^schema:Person ;
    schema:dateModified "2021-01-19T01:19:11Z"^^schema:DateTime ;
    schema:datePublished "2021-01-17T00:31:37Z"^^schema:DateTime ;
    schema:genre "C.2; H.2; I.4; J.6"^^schema:Text,
        "cs.DC"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NE"^^schema:Text ;
    schema:headline "Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G  Handover"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.06558v2"^^schema:URL .

<983> a schema:ScholarlyArticle ;
    schema:abstract "Self Normalizing Neural Networks(SNN) proposed on Feed Forward NeuralNetworks(FNN) outperform regular FNN architectures in various machine learningtasks. Particularly in the domain of Computer Vision, the activation functionScaled Exponential Linear Units (SELU) proposed for SNNs, perform better thanother non linear activations such as ReLU. The goal of SNN is to produce anormalized output for a normalized input. Established neural networkarchitectures like feed forward networks and Convolutional Neural Networks(CNN)lack the intrinsic nature of normalizing outputs. Hence, requiring additionallayers such as Batch Normalization. Despite the success of SNNs, theircharacteristic features on other network architectures like CNN haven't beenexplored, especially in the domain of Natural Language Processing. In thispaper we aim to show the effectiveness of proposed, Self NormalizingConvolutional Neural Networks(SCNN) on text classification. We analyze theirperformance with the standard CNN architecture used on several textclassification datasets. Our experiments demonstrate that SCNN achievescomparable results to standard CNN model with significantly fewer parameters.Furthermore it also outperforms CNN with equal number of parameters."^^schema:Text ;
    schema:author "Avinash Madasu"^^schema:Person,
        "Vijjini Anvesh Rao"^^schema:Person ;
    schema:dateModified "2019-05-03T18:38:39Z"^^schema:DateTime ;
    schema:datePublished "2019-05-03T18:38:39Z"^^schema:DateTime ;
    schema:genre "cs.CL"^^schema:Text ;
    schema:headline "Effectiveness of Self Normalizing Neural Networks for Text  Classification"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.01338v1"^^schema:URL .

<984> a schema:ScholarlyArticle ;
    schema:abstract "This article was withdrawn because (1) it was uploaded without theco-authors' knowledge or consent, and (2) there are allegations of plagiarism."^^schema:Text ;
    schema:author "Jun Qi"^^schema:Person ;
    schema:dateModified "2017-08-03T14:32:30Z"^^schema:DateTime ;
    schema:datePublished "2017-07-18T16:04:08Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "Submodular Mini-Batch Training in Generative Moment Matching Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.05721v3"^^schema:URL .

<985> a schema:ScholarlyArticle ;
    schema:abstract "Rapid progress in deep reinforcement learning has made it increasinglyfeasible to train controllers for high-dimensional humanoid bodies. However,methods that use pure reinforcement learning with simple reward functions tendto produce non-humanlike and overly stereotyped movement behaviors. In thiswork, we extend generative adversarial imitation learning to enable training ofgeneric neural network policies to produce humanlike movement patterns fromlimited demonstrations consisting only of partially observed state features,without access to actions, even when the demonstrations come from a body withdifferent and unknown physical parameters. We leverage this approach to buildsub-skill policies from motion capture data and show that they can be reused tosolve tasks when controlled by a higher level controller."^^schema:Text ;
    schema:author "Dhruva TB"^^schema:Person,
        "Greg Wayne"^^schema:Person,
        "Jay Lemmon"^^schema:Person,
        "Josh Merel"^^schema:Person,
        "Nicolas Heess"^^schema:Person,
        "Sriram Srinivasan"^^schema:Person,
        "Yuval Tassa"^^schema:Person,
        "Ziyu Wang"^^schema:Person ;
    schema:dateModified "2017-07-10T14:02:39Z"^^schema:DateTime ;
    schema:datePublished "2017-07-07T14:46:45Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text ;
    schema:headline "Learning human behaviors from motion capture by adversarial imitation"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.02201v2"^^schema:URL .

<986> a schema:ScholarlyArticle ;
    schema:abstract "Reinforcement learning methods have been used for learning dialogue policies.However, learning an effective dialogue policy frequently requiresprohibitively many conversations. This is partly because of the sparse rewardsin dialogues, and the very few successful dialogues in early learning phase.Hindsight experience replay (HER) enables learning from failures, but thevanilla HER is inapplicable to dialogue learning due to the implicit goals. Inthis work, we develop two complex HER methods providing different trade-offsbetween complexity and performance, and, for the first time, enabled HER-baseddialogue policy learning. Experiments using a realistic user simulator showthat our HER methods perform better than existing experience replay methods (asapplied to deep Q-networks) in learning rate."^^schema:Text ;
    schema:author "Keting Lu"^^schema:Person,
        "Shiqi Zhang"^^schema:Person,
        "Xiaoping Chen"^^schema:Person ;
    schema:dateModified "2018-11-22T13:51:34Z"^^schema:DateTime ;
    schema:datePublished "2018-08-20T15:04:30Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CL"^^schema:Text ;
    schema:headline "Goal-oriented Dialogue Policy Learning from Failures"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1808.06497v2"^^schema:URL .

<987> a schema:ScholarlyArticle ;
    schema:abstract "Designing a convolution for a spherical neural network requires a delicatetradeoff between efficiency and rotation equivariance. DeepSphere, a methodbased on a graph representation of the sampled sphere, strikes a controllablebalance between these two desiderata. This contribution is twofold. First, westudy both theoretically and empirically how equivariance is affected by theunderlying graph with respect to the number of vertices and neighbors. Second,we evaluate DeepSphere on relevant problems. Experiments show state-of-the-artperformance and demonstrates the efficiency and flexibility of thisformulation. Perhaps surprisingly, comparison with previous work suggests thatanisotropic filters might be an unnecessary price to pay. Our code is availableat https://github.com/deepsphere"^^schema:Text ;
    schema:author "Frédérick Gusset"^^schema:Person,
        "Martino Milani"^^schema:Person,
        "Michaël Defferrard"^^schema:Person,
        "Nathanaël Perraudin"^^schema:Person ;
    schema:dateModified "2020-12-30T01:35:27Z"^^schema:DateTime ;
    schema:datePublished "2020-12-30T01:35:27Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "DeepSphere: a graph-based spherical CNN"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2012.15000v1"^^schema:URL .

<988> a schema:ScholarlyArticle ;
    schema:abstract "Artificial neural networks have exceeded human-level performance inaccomplishing several individual tasks (e.g. voice recognition, objectrecognition, and video games). However, such success remains modest compared tohuman intelligence that can learn and perform an unlimited number of tasks.Humans' ability of learning and accumulating knowledge over their lifetime isan essential aspect of their intelligence. Continual machine learning aims at ahigher level of machine intelligence through providing the artificial agentswith the ability to learn online from a non-stationary and never-ending streamof data. A key component of such a never-ending learning process is to overcomethe catastrophic forgetting of previously seen data, a problem that neuralnetworks are well known to suffer from. The work described in this thesis hasbeen dedicated to the investigation of continual learning and solutions tomitigate the forgetting phenomena in neural networks. To approach the continuallearning problem, we first assume a task incremental setting where tasks arereceived one at a time and data from previous tasks are not stored. Since thetask incremental setting can't be assumed in all continual learning scenarios,we also study the more general online continual setting. We consider aninfinite stream of data drawn from a non-stationary distribution with asupervisory or self-supervisory training signal. The proposed methods in thisthesis have tackled important aspects of continual learning. They wereevaluated on different benchmarks and over various learning sequences. Advancesin the state of the art of continual learning have been shown and challengesfor bringing continual learning into application were critically identified."^^schema:Text ;
    schema:author "Rahaf Aljundi"^^schema:Person ;
    schema:dateModified "2019-10-18T09:48:14Z"^^schema:DateTime ;
    schema:datePublished "2019-10-07T10:52:14Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text,
        "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Continual Learning in Neural Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1910.02718v2"^^schema:URL .

<989> a schema:ScholarlyArticle ;
    schema:abstract "Learning nonlinear dynamics from aggregate datais a challenging problembecause the full trajectory of each individual is not available, namely, theindividual observed at one time may not beobserved at the next time point, orthe identity ofindividual is unavailable. This is in sharp contrastto learningdynamics with full trajectory data, on which the majority of existing methodsare based. We propose a novel method using the weak form of Fokker PlanckEquation(FPE) -- a partial differential equation -- to describe the densityevolution of data in a sampled form, which is then combined with Wassersteingenerative adversarial network (WGAN) in the training process. Insuch a samplebased framework we are able to learn the nonlinear dynamics from aggregate datawithout explicitly solving FPE. More importantly, our model can also readilyhandle high dimensional cases by leveraging deep neural networks. Wedemonstrate our approach in the context of aseries of synthetic and real-worlddata sets."^^schema:Text ;
    schema:author "Haomin Zhou"^^schema:Person,
        "Hongyuan Zha"^^schema:Person,
        "Shaojun Ma"^^schema:Person,
        "Shu Liu"^^schema:Person ;
    schema:dateModified "2021-02-08T03:32:07Z"^^schema:DateTime ;
    schema:datePublished "2020-02-10T03:20:13Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "math.AP"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Learning Stochastic Behaviour from Aggregate Data"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.03513v4"^^schema:URL .

<99> a schema:ScholarlyArticle ;
    schema:abstract "Recently, researchers have made significant progress combining the advancesin deep learning for learning feature representations with reinforcementlearning. Some notable examples include training agents to play Atari gamesbased on raw pixel data and to acquire advanced manipulation skills using rawsensory inputs. However, it has been difficult to quantify progress in thedomain of continuous control due to the lack of a commonly adopted benchmark.In this work, we present a benchmark suite of continuous control tasks,including classic tasks like cart-pole swing-up, tasks with very high state andaction dimensionality such as 3D humanoid locomotion, tasks with partialobservations, and tasks with hierarchical structure. We report novel findingsbased on the systematic evaluation of a range of implemented reinforcementlearning algorithms. Both the benchmark and reference implementations arereleased at https://github.com/rllab/rllab in order to facilitate experimentalreproducibility and to encourage adoption by other researchers."^^schema:Text ;
    schema:author "John Schulman"^^schema:Person,
        "Pieter Abbeel"^^schema:Person,
        "Rein Houthooft"^^schema:Person,
        "Xi Chen"^^schema:Person,
        "Yan Duan"^^schema:Person ;
    schema:commentCount "850"^^schema:Integer ;
    schema:dateModified "2016-05-27T19:25:59Z"^^schema:DateTime ;
    schema:datePublished "2016-04-22T18:57:24Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text ;
    schema:headline "Benchmarking Deep Reinforcement Learning for Continuous Control"^^schema:Text ;
    schema:publisher "ICML, 1329-1338"^^schema:Periodical ;
    schema:url "http://arxiv.org/abs/1604.06778v3"^^schema:URL,
        "http://scholar.google.com/scholar?oi=bibs&cluster=4776639135351919780&btnI=1&nossl=1&hl=en&oe=ASCII"^^schema:URL .

<990> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning has recently gained a focus on problems wherepolicy or value functions are independent of goals. Evidence exists that thesampling of goals has a strong effect on the learning performance, but there isa lack of general mechanisms that focus on optimizing the goal samplingprocess. In this work, we present a simple and general goal masking method thatalso allows us to estimate a goal's difficulty level and thus realize acurriculum learning approach for deep RL. Our results indicate that focusing ongoals with a medium difficulty level is appropriate for deep deterministicpolicy gradient (DDPG) methods, while an \"aim for the stars and reach themoon-strategy\", where hard goals are sampled much more often than simple goals,leads to the best learning performance in cases where DDPG is combined with forhindsight experience replay (HER). We demonstrate that the approachsignificantly outperforms standard goal sampling for different robotic objectmanipulation problems."^^schema:Text ;
    schema:author "Manfred Eppe"^^schema:Person,
        "Stefan Wermter"^^schema:Person,
        "Sven Magg"^^schema:Person ;
    schema:dateModified "2019-02-13T12:02:59Z"^^schema:DateTime ;
    schema:datePublished "2018-09-17T12:01:02Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Curriculum goal masking for continuous deep reinforcement learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1809.06146v2"^^schema:URL .

<991> a schema:ScholarlyArticle ;
    schema:abstract "This paper presents a study of automatic design of neural networkarchitectures for skeleton-based action recognition. Specifically, we encode askeleton-based action instance into a tensor and carefully define a set ofoperations to build two types of network cells: normal cells and reductioncells. The recently developed DARTS (Differentiable Architecture Search) isadopted to search for an effective network architecture that is built upon thetwo types of cells. All operations are 2D based in order to reduce the overallcomputation and search space. Experiments on the challenging NTU RGB+D andKinectics datasets have verified that most of the networks developed to datefor skeleton-based action recognition are likely not compact and efficient. Theproposed method provides an approach to search for such a compact network thatis able to achieve comparative or even better performance than thestate-of-the-art methods."^^schema:Text ;
    schema:author "Haoyuan Zhang"^^schema:Person,
        "Pichao Wang"^^schema:Person,
        "Wanqing Li"^^schema:Person,
        "Yonghong Hou"^^schema:Person,
        "Zihui Guo"^^schema:Person ;
    schema:dateModified "2020-10-29T03:24:15Z"^^schema:DateTime ;
    schema:datePublished "2020-10-29T03:24:15Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "SAR-NAS: Skeleton-based Action Recognition via Neural Architecture  Searching"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.15336v1"^^schema:URL .

<992> a schema:ScholarlyArticle ;
    schema:abstract "Deep reinforcement learning (RL) uses model-free techniques to optimizetask-specific control policies. Despite having emerged as a promising approachfor complex problems, RL is still hard to use reliably for real-worldapplications. Apart from challenges such as precise reward function tuning,inaccurate sensing and actuation, and non-deterministic response, existing RLmethods do not guarantee behavior within required safety constraints that arecrucial for real robot scenarios. In this regard, we introduce guidedconstrained policy optimization (GCPO), an RL framework based upon ourimplementation of constrained proximal policy optimization (CPPO) for trackingbase velocity commands while following the defined constraints. We alsointroduce schemes which encourage state recovery into constrained regions incase of constraint violations. We present experimental results of our trainingmethod and test it on the real ANYmal quadruped robot. We compare our approachagainst the unconstrained RL method and show that guided constrained RL offersfaster convergence close to the desired optimum resulting in an optimal, yetphysically feasible, robotic control behavior without the need for precisereward function tuning."^^schema:Text ;
    schema:author "Alexander Mitchell"^^schema:Person,
        "Ioannis Havoutis"^^schema:Person,
        "Siddhant Gangapurwala"^^schema:Person ;
    schema:dateModified "2020-02-22T10:15:53Z"^^schema:DateTime ;
    schema:datePublished "2020-02-22T10:15:53Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "cs.RO"^^schema:Text,
        "cs.SY"^^schema:Text,
        "eess.SY"^^schema:Text ;
    schema:headline "Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot  Locomotion"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2002.09676v1"^^schema:URL .

<993> a schema:ScholarlyArticle ;
    schema:abstract "This article is concerned with the approximation and expressive powers ofdeep neural networks. This is an active research area currently producing manyinteresting papers. The results most commonly found in the literature provethat neural networks approximate functions with classical smoothness to thesame accuracy as classical linear methods of approximation, e.g. approximationby polynomials or by piecewise polynomials on prescribed partitions. However,approximation by neural networks depending on n parameters is a form ofnonlinear approximation and as such should be compared with other nonlinearmethods such as variable knot splines or n-term approximation fromdictionaries. The performance of neural networks in targeted applications suchas machine learning indicate that they actually possess even greaterapproximation power than these traditional methods of nonlinear approximation.The main results of this article prove that this is indeed the case. This isdone by exhibiting large classes of functions which can be efficiently capturedby neural networks where classical nonlinear methods fall short of the task.The present article purposefully limits itself to studying the approximation ofunivariate functions by ReLU networks. Many generalizations to functions ofseveral variables and other activation functions can be envisioned. However,even in this simplest of settings considered here, a theory that completelyquantifies the approximation power of neural networks is still lacking."^^schema:Text ;
    schema:author "B. Hanin"^^schema:Person,
        "G. Petrova"^^schema:Person,
        "I. Daubechies"^^schema:Person,
        "R. DeVore"^^schema:Person,
        "S. Foucart"^^schema:Person ;
    schema:dateModified "2019-05-05T12:54:35Z"^^schema:DateTime ;
    schema:datePublished "2019-05-05T12:54:35Z"^^schema:DateTime ;
    schema:genre "41A25, 41A30, 41A46, 68T99, 82C32, 92B20,"^^schema:Text,
        "cs.LG"^^schema:Text ;
    schema:headline "Nonlinear Approximation and (Deep) ReLU Networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1905.02199v1"^^schema:URL .

<994> a schema:ScholarlyArticle ;
    schema:abstract "In this paper, we propose a novel defensive transformation that enables us tomaintain a high classification accuracy under the use of both clean images andadversarial examples for adversarially robust defense. The proposedtransformation is a block-wise preprocessing technique with a secret key toinput images. We developed three algorithms to realize the proposedtransformation: Pixel Shuffling, Bit Flipping, and FFX Encryption. Experimentswere carried out on the CIFAR-10 and ImageNet datasets by using both black-boxand white-box attacks with various metrics including adaptive ones. The resultsshow that the proposed defense achieves high accuracy close to that of usingclean images even under adaptive attacks for the first time. In the best-casescenario, a model trained by using images transformed by FFX Encryption (blocksize of 4) yielded an accuracy of 92.30% on clean images and 91.48% under PGDattack with a noise distance of 8/255, which is close to the non-robustaccuracy (95.45%) for the CIFAR-10 dataset, and it yielded an accuracy of72.18% on clean images and 71.43% under the same attack, which is also close tothe standard accuracy (73.70%) for the ImageNet dataset. Overall, all threeproposed algorithms are demonstrated to outperform state-of-the-art defensesincluding adversarial training whether or not a model is under attack."^^schema:Text ;
    schema:author "Hitoshi Kiya"^^schema:Person,
        "MaungMaung AprilPyone"^^schema:Person ;
    schema:dateModified "2020-10-02T06:07:12Z"^^schema:DateTime ;
    schema:datePublished "2020-10-02T06:07:12Z"^^schema:DateTime ;
    schema:genre "cs.CR"^^schema:Text,
        "cs.CV"^^schema:Text ;
    schema:headline "Block-wise Image Transformation with Secret Key for Adversarially Robust  Defense"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2010.00801v1"^^schema:URL .

<995> a schema:ScholarlyArticle ;
    schema:abstract "The need for robust, secure and private machine learning is an important goalfor realizing the full potential of the Internet of Things (IoT). Federatedlearning has proven to help protect against privacy violations and informationleakage. However, it introduces new risk vectors which make machine learningmodels more difficult to defend against adversarial samples. In this study, weexamine the role of differential privacy and self-normalization in mitigatingthe risk of adversarial samples specifically in a federated learningenvironment. We introduce DiPSeN, a Differentially Private Self-normalizingNeural Network which combines elements of differential privacy noise withself-normalizing techniques. Our empirical results on three publicly availabledatasets show that DiPSeN successfully improves the adversarial robustness of adeep learning classifier in a federated learning environment based on severalevaluation metrics."^^schema:Text ;
    schema:author "Ashraf Matrawy"^^schema:Person,
        "M. Omair Shafiq"^^schema:Person,
        "Olakunle Ibitoye"^^schema:Person ;
    schema:dateModified "2021-01-08T20:49:56Z"^^schema:DateTime ;
    schema:datePublished "2021-01-08T20:49:56Z"^^schema:DateTime ;
    schema:genre "cs.AI"^^schema:Text,
        "cs.CY"^^schema:Text,
        "cs.LG"^^schema:Text,
        "cs.NI"^^schema:Text ;
    schema:headline "DiPSeN: Differentially Private Self-normalizing Neural Networks For  Adversarial Robustness in Federated Learning"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2101.03218v1"^^schema:URL .

<996> a schema:ScholarlyArticle ;
    schema:abstract "Accurate detection of lane and road markings is a task of great importancefor intelligent vehicles. In existing approaches, the detection accuracy oftendegrades with the increasing distance. This is due to the fact that distantlane and road markings occupy a small number of pixels in the image, and scalesof lane and road markings are inconsistent at various distances andperspectives. The Inverse Perspective Mapping (IPM) can be used to eliminatethe perspective distortion, but the inherent interpolation can lead toartifacts especially around distant lane and road markings and thus has anegative impact on the accuracy of lane marking detection and segmentation. Tosolve this problem, we adopt the Encoder-Decoder architecture in FullyConvolutional Networks and leverage the idea of Spatial Transformer Networks tointroduce a novel semantic segmentation neural network. This approachdecomposes the IPM process into multiple consecutive differentiable homographictransform layers, which are called \"Perspective Transformer Layers\".Furthermore, the interpolated feature map is refined by subsequentconvolutional layers thus reducing the artifacts and improving the accuracy.The effectiveness of the proposed method in lane marking detection is validatedon two public datasets: TuSimple and ApolloScape"^^schema:Text ;
    schema:author "Junqiao Zhao"^^schema:Person,
        "Wei Tian"^^schema:Person,
        "Xiaozhou Ren"^^schema:Person,
        "Yuyao Huang"^^schema:Person,
        "Zhuoping Yu"^^schema:Person ;
    schema:dateModified "2020-10-25T06:38:46Z"^^schema:DateTime ;
    schema:datePublished "2020-03-19T03:22:52Z"^^schema:DateTime ;
    schema:genre "cs.CV"^^schema:Text ;
    schema:headline "Detecting Lane and Road Markings at A Distance with Perspective  Transformer Layers"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2003.08550v2"^^schema:URL .

<997> a schema:ScholarlyArticle ;
    schema:abstract "Motivated by the general robustness properties of the 01 loss we propose asingle hidden layer 01 loss neural network trained with stochastic coordinatedescent as a defense against adversarial attacks in machine learning. Onemeasure of a model's robustness is the minimum distortion required to make theinput adversarial. This can be approximated with the Boundary Attack (Brendelet. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare theminimum distortion of the 01 loss network to the binarized neural network andthe standard sigmoid activation network with cross-entropy loss all trainedwith and without Gaussian noise on the CIFAR10 benchmark binary classificationbetween classes 0 and 1. Both with and without noise training we find our 01loss network to have the largest adversarial distortion of the three models bynon-trivial margins. To further validate these results we subject all models tosubstitute model black box attacks under different distortion thresholds andfind that the 01 loss network is the hardest to attack across all distortions.At a distortion of 0.125 both sigmoid activated cross-entropy loss andbinarized networks have almost 0% accuracy on adversarial examples whereas the01 loss network is at 40%. Even though both 01 loss and the binarized networkuse sign activations their training algorithms are different which in turn givedifferent solutions for robustness. Finally we compare our network to simpleconvolutional models under substitute model black box attacks and find theiraccuracies to be comparable. Our work shows that the 01 loss network has thepotential to defend against black box adversarial attacks better than convexloss and binarized networks."^^schema:Text ;
    schema:author "Meiyan Xie"^^schema:Person,
        "Usman Roshan"^^schema:Person,
        "Yunzhe Xue"^^schema:Person ;
    schema:dateModified "2020-08-20T18:18:49Z"^^schema:DateTime ;
    schema:datePublished "2020-08-20T18:18:49Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Towards adversarial robustness with 01 loss neural networks"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2008.09148v1"^^schema:URL .

<998> a schema:ScholarlyArticle ;
    schema:abstract "Embeddings of knowledge graphs have received significant attention due totheir excellent performance for tasks like link prediction and entityresolution. In this short paper, we are providing a comparison of twostate-of-the-art knowledge graph embeddings for which their equivalence hasrecently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio,2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we brieflyreview both models and discuss how their scoring functions are equivalent. Wethen analyze the discrepancy of results reported in the original articles, andshow experimentally that they are likely due to the use of different lossfunctions. In further experiments, we evaluate the ability of both models toembed symmetric and antisymmetric patterns. Finally, we discuss advantages anddisadvantages of both models and under which conditions one would be preferableto the other."^^schema:Text ;
    schema:author "Maximilian Nickel"^^schema:Person,
        "Théo Trouillon"^^schema:Person ;
    schema:dateModified "2017-07-23T04:30:21Z"^^schema:DateTime ;
    schema:datePublished "2017-07-05T17:17:34Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text,
        "stat.ML"^^schema:Text ;
    schema:headline "Complex and Holographic Embeddings of Knowledge Graphs: A Comparison"^^schema:Text ;
    schema:url "http://arxiv.org/abs/1707.01475v2"^^schema:URL .

<999> a schema:ScholarlyArticle ;
    schema:abstract "Neural ordinary differential equations (Neural ODEs) are a new family ofdeep-learning models with continuous depth. However, the numerical estimationof the gradient in the continuous case is not well solved: existingimplementations of the adjoint method suffer from inaccuracy in reverse-timetrajectory, while the naive method and the adaptive checkpoint adjoint method(ACA) have a memory cost that grows with integration time. In this project,based on the asynchronous leapfrog (ALF) solver, we propose theMemory-efficient ALF Integrator (MALI), which has a constant memory cost\\textit{w.r.t} number of solver steps in integration similar to the adjointmethod, and guarantees accuracy in reverse-time trajectory (hence accuracy ingradient estimation). We validate MALI in various tasks: on image recognitiontasks, to our knowledge, MALI is the first to enable feasible training of aNeural ODE on ImageNet and outperform a well-tuned ResNet, while existingmethods fail due to either heavy memory burden or inaccuracy; for time seriesmodeling, MALI significantly outperforms the adjoint method; and for continuousgenerative models, MALI achieves new state-of-the-art performance."^^schema:Text ;
    schema:author "James S. Duncan"^^schema:Person,
        "Juntang Zhuang"^^schema:Person,
        "Nicha C. Dvornek"^^schema:Person,
        "Sekhar Tatikonda"^^schema:Person ;
    schema:dateModified "2021-02-09T06:33:47Z"^^schema:DateTime ;
    schema:datePublished "2021-02-09T06:33:47Z"^^schema:DateTime ;
    schema:genre "cs.LG"^^schema:Text ;
    schema:headline "MALI: A memory efficient and reverse accurate integrator for Neural ODEs"^^schema:Text ;
    schema:url "http://arxiv.org/abs/2102.04668v1"^^schema:URL .

