{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rltk\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-source",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'ai'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-landscape",
   "metadata": {},
   "source": [
    "**Arxiv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_arxiv.shape pre  deduplucation: (1780, 7)\n",
      "df_arxiv.shape post deduplucation: (1780, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1409.0473v7</td>\n",
       "      <td>2016-05-19T21:53:22Z</td>\n",
       "      <td>2014-09-01T16:33:02Z</td>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>Neural machine translation is a recently pro...</td>\n",
       "      <td>[Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]</td>\n",
       "      <td>[cs.CL, cs.LG, cs.NE, stat.ML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/1511.06434v2</td>\n",
       "      <td>2016-01-07T23:09:39Z</td>\n",
       "      <td>2015-11-19T22:50:32Z</td>\n",
       "      <td>Unsupervised Representation Learning with Deep...</td>\n",
       "      <td>In recent years, supervised learning with co...</td>\n",
       "      <td>[Alec Radford, Luke Metz, Soumith Chintala]</td>\n",
       "      <td>[cs.LG, cs.CV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1412.6572v3</td>\n",
       "      <td>2015-03-20T20:19:16Z</td>\n",
       "      <td>2014-12-20T01:17:12Z</td>\n",
       "      <td>Explaining and Harnessing Adversarial Examples</td>\n",
       "      <td>Several machine learning models, including n...</td>\n",
       "      <td>[Ian J. Goodfellow, Jonathon Shlens, Christian...</td>\n",
       "      <td>[stat.ML, cs.LG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/1609.02907v4</td>\n",
       "      <td>2017-02-22T09:55:36Z</td>\n",
       "      <td>2016-09-09T19:48:41Z</td>\n",
       "      <td>Semi-Supervised Classification with Graph Conv...</td>\n",
       "      <td>We present a scalable approach for semi-supe...</td>\n",
       "      <td>[Thomas N. Kipf, Max Welling]</td>\n",
       "      <td>[cs.LG, stat.ML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1509.02971v6</td>\n",
       "      <td>2019-07-05T10:47:27Z</td>\n",
       "      <td>2015-09-09T23:01:36Z</td>\n",
       "      <td>Continuous control with deep reinforcement lea...</td>\n",
       "      <td>We adapt the ideas underlying the success of...</td>\n",
       "      <td>[Timothy P. Lillicrap, Jonathan J. Hunt, Alexa...</td>\n",
       "      <td>[cs.LG, stat.ML]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 url               updated  \\\n",
       "0   http://arxiv.org/abs/1409.0473v7  2016-05-19T21:53:22Z   \n",
       "1  http://arxiv.org/abs/1511.06434v2  2016-01-07T23:09:39Z   \n",
       "2   http://arxiv.org/abs/1412.6572v3  2015-03-20T20:19:16Z   \n",
       "3  http://arxiv.org/abs/1609.02907v4  2017-02-22T09:55:36Z   \n",
       "4  http://arxiv.org/abs/1509.02971v6  2019-07-05T10:47:27Z   \n",
       "\n",
       "              published                                              title  \\\n",
       "0  2014-09-01T16:33:02Z  Neural Machine Translation by Jointly Learning...   \n",
       "1  2015-11-19T22:50:32Z  Unsupervised Representation Learning with Deep...   \n",
       "2  2014-12-20T01:17:12Z     Explaining and Harnessing Adversarial Examples   \n",
       "3  2016-09-09T19:48:41Z  Semi-Supervised Classification with Graph Conv...   \n",
       "4  2015-09-09T23:01:36Z  Continuous control with deep reinforcement lea...   \n",
       "\n",
       "                                             summary  \\\n",
       "0    Neural machine translation is a recently pro...   \n",
       "1    In recent years, supervised learning with co...   \n",
       "2    Several machine learning models, including n...   \n",
       "3    We present a scalable approach for semi-supe...   \n",
       "4    We adapt the ideas underlying the success of...   \n",
       "\n",
       "                                             authors  \\\n",
       "0   [Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]   \n",
       "1        [Alec Radford, Luke Metz, Soumith Chintala]   \n",
       "2  [Ian J. Goodfellow, Jonathon Shlens, Christian...   \n",
       "3                      [Thomas N. Kipf, Max Welling]   \n",
       "4  [Timothy P. Lillicrap, Jonathan J. Hunt, Alexa...   \n",
       "\n",
       "                       categories  \n",
       "0  [cs.CL, cs.LG, cs.NE, stat.ML]  \n",
       "1                  [cs.LG, cs.CV]  \n",
       "2                [stat.ML, cs.LG]  \n",
       "3                [cs.LG, stat.ML]  \n",
       "4                [cs.LG, stat.ML]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arxiv = pd.read_json(f'crawler558/arxiv_crawler_{TOPIC}.jl', lines=True)\n",
    "print(f'df_arxiv.shape pre  deduplucation: {df_arxiv.shape}')\n",
    "df_arxiv = df_arxiv.drop_duplicates(subset='title')\n",
    "print(f'df_arxiv.shape post deduplucation: {df_arxiv.shape}')\n",
    "df_arxiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "determined-quarter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1780 entries, 0 to 1779\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          1780 non-null   object\n",
      " 1   url         1780 non-null   object\n",
      " 2   updated     1780 non-null   object\n",
      " 3   published   1780 non-null   object\n",
      " 4   title       1780 non-null   object\n",
      " 5   summary     1780 non-null   object\n",
      " 6   authors     1780 non-null   object\n",
      " 7   categories  1780 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 111.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Generate an id column for RLTK to use\n",
    "df_arxiv.reset_index(inplace=True)\n",
    "df_arxiv['index'] = df_arxiv['index'].astype('str')\n",
    "df_arxiv.rename(columns={'index':'ID'}, inplace=True)\n",
    "df_arxiv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-soundtrack",
   "metadata": {},
   "source": [
    "**Google Scholar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerous-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_gscholar.shape pre  deduplication: (1020, 6)\n",
      "df_gscholar.shape post deduplication: (1016, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[D Bahdanau, K Cho, Y Bengio]</td>\n",
       "      <td>ICLR</td>\n",
       "      <td>13000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unsupervised Representation Learning with Deep...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[A Radford, L Metz, S Chintala]</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>6544</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explaining and Harnessing Adversarial Examples.</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[IJ Goodfellow, J Shlens, C Szegedy]</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>4827</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semi-Supervised Classification with Graph Conv...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[TN Kipf, M Welling]</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>4036</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Continuous control with deep reinforcement lea...</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>[TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T ...</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>3683</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Neural Machine Translation by Jointly Learning...   \n",
       "1  Unsupervised Representation Learning with Deep...   \n",
       "2    Explaining and Harnessing Adversarial Examples.   \n",
       "3  Semi-Supervised Classification with Graph Conv...   \n",
       "4  Continuous control with deep reinforcement lea...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "3  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "4  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                             authors        journal  \\\n",
       "0                      [D Bahdanau, K Cho, Y Bengio]           ICLR   \n",
       "1                    [A Radford, L Metz, S Chintala]  ICLR (Poster)   \n",
       "2               [IJ Goodfellow, J Shlens, C Szegedy]  ICLR (Poster)   \n",
       "3                               [TN Kipf, M Welling]  ICLR (Poster)   \n",
       "4  [TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T ...  ICLR (Poster)   \n",
       "\n",
       "   citations  year  \n",
       "0      13000  2015  \n",
       "1       6544  2016  \n",
       "2       4827  2015  \n",
       "3       4036  2017  \n",
       "4       3683  2016  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gscholar = pd.read_json(f'Google_Scholar/articles_{TOPIC}.json')\n",
    "print(f'df_gscholar.shape pre  deduplication: {df_gscholar.shape}')\n",
    "df_gscholar = df_gscholar.drop_duplicates(subset='title')\n",
    "print(f'df_gscholar.shape post deduplication: {df_gscholar.shape}')\n",
    "\n",
    "# Fix the wrong URLs\n",
    "df_gscholar['url'] = df_gscholar['url'].apply(lambda x: x[27:])\n",
    "\n",
    "df_gscholar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "third-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1016 entries, 0 to 1015\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         1016 non-null   object\n",
      " 1   title      1016 non-null   object\n",
      " 2   url        1016 non-null   object\n",
      " 3   authors    1016 non-null   object\n",
      " 4   journal    1016 non-null   object\n",
      " 5   citations  1016 non-null   object\n",
      " 6   year       1016 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 55.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Generate an id column for RLTK to use\n",
    "df_gscholar.reset_index(inplace=True)\n",
    "df_gscholar['index'] = df_gscholar['index'].astype('str')\n",
    "df_gscholar.rename(columns={'index':'ID'}, inplace=True)\n",
    "\n",
    "# Also set all columns to string type\n",
    "df_gscholar['citations'] = df_gscholar['citations'].astype('str')\n",
    "df_gscholar['year'] = df_gscholar['year'].astype('str')\n",
    "df_gscholar.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-reporter",
   "metadata": {},
   "source": [
    "### Naïve Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposite-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# How many matches can be found with a naÏve identical string approach?\n",
    "arxiv_titles = df_arxiv['title']\n",
    "gscholar_titles = df_gscholar['title']\n",
    "print(len([1 for w in arxiv_titles.values if w in gscholar_titles.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protective-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged.shape: (2747, 14)\n",
      "Number of match found with pd.merge: 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>url_x</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors_x</th>\n",
       "      <th>categories</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>url_y</th>\n",
       "      <th>authors_y</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/abs/1409.0473v7</td>\n",
       "      <td>2016-05-19T21:53:22Z</td>\n",
       "      <td>2014-09-01T16:33:02Z</td>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>Neural machine translation is a recently pro...</td>\n",
       "      <td>[Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]</td>\n",
       "      <td>[cs.CL, cs.LG, cs.NE, stat.ML]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/abs/1511.06434v2</td>\n",
       "      <td>2016-01-07T23:09:39Z</td>\n",
       "      <td>2015-11-19T22:50:32Z</td>\n",
       "      <td>Unsupervised Representation Learning with Deep...</td>\n",
       "      <td>In recent years, supervised learning with co...</td>\n",
       "      <td>[Alec Radford, Luke Metz, Soumith Chintala]</td>\n",
       "      <td>[cs.LG, cs.CV]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/abs/1412.6572v3</td>\n",
       "      <td>2015-03-20T20:19:16Z</td>\n",
       "      <td>2014-12-20T01:17:12Z</td>\n",
       "      <td>Explaining and Harnessing Adversarial Examples</td>\n",
       "      <td>Several machine learning models, including n...</td>\n",
       "      <td>[Ian J. Goodfellow, Jonathon Shlens, Christian...</td>\n",
       "      <td>[stat.ML, cs.LG]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_x                              url_x               updated  \\\n",
       "0    0   http://arxiv.org/abs/1409.0473v7  2016-05-19T21:53:22Z   \n",
       "1    1  http://arxiv.org/abs/1511.06434v2  2016-01-07T23:09:39Z   \n",
       "2    2   http://arxiv.org/abs/1412.6572v3  2015-03-20T20:19:16Z   \n",
       "\n",
       "              published                                              title  \\\n",
       "0  2014-09-01T16:33:02Z  Neural Machine Translation by Jointly Learning...   \n",
       "1  2015-11-19T22:50:32Z  Unsupervised Representation Learning with Deep...   \n",
       "2  2014-12-20T01:17:12Z     Explaining and Harnessing Adversarial Examples   \n",
       "\n",
       "                                             summary  \\\n",
       "0    Neural machine translation is a recently pro...   \n",
       "1    In recent years, supervised learning with co...   \n",
       "2    Several machine learning models, including n...   \n",
       "\n",
       "                                           authors_x  \\\n",
       "0   [Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]   \n",
       "1        [Alec Radford, Luke Metz, Soumith Chintala]   \n",
       "2  [Ian J. Goodfellow, Jonathon Shlens, Christian...   \n",
       "\n",
       "                       categories ID_y url_y authors_y journal citations year  \n",
       "0  [cs.CL, cs.LG, cs.NE, stat.ML]  NaN   NaN       NaN     NaN       NaN  NaN  \n",
       "1                  [cs.LG, cs.CV]  NaN   NaN       NaN     NaN       NaN  NaN  \n",
       "2                [stat.ML, cs.LG]  NaN   NaN       NaN     NaN       NaN  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both datasets by \"SQL\" join\n",
    "df_merged = df_arxiv.merge(df_gscholar, on='title', how='outer')\n",
    "print(f'df_merged.shape: {df_merged.shape}')\n",
    "\n",
    "# Number of match found with pd.merge:\n",
    "print(f'Number of match found with pd.merge: {df_arxiv.shape[0] + df_gscholar.shape[0] - df_merged.shape[0]}')\n",
    "\n",
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-count",
   "metadata": {},
   "source": [
    "## RLTK Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divine-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLTK Tokenizer\n",
    "tokenizer = rltk.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-lighting",
   "metadata": {},
   "source": [
    "**Arxiv Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = 'ArxivRecord'\n",
    "        \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def authors_string(self):\n",
    "        return self.raw_object['authors']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['title']\n",
    "        \n",
    "    @rltk.cached_property\n",
    "    def summary_string(self):\n",
    "        return self.raw_object['summary']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def categories_string(self):\n",
    "        return self.raw_object['categories']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def published_string(self):\n",
    "        return self.raw_object['published']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def updated_string(self):\n",
    "        return self.raw_object['updated']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def blocking_tokens(self):\n",
    "        tokens = ' '.join([self.title_string])\n",
    "        tokens = re.sub(r'\\bThe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bthe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bof\\b', '', tokens)\n",
    "        tokens = re.sub(r\"\\b's\\b\", '', tokens)\n",
    "        tokens = re.sub(r'\\band\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bI\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bA\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bin\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bfor\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bon\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bwith\\b', '', tokens)\n",
    "        return set(tokenizer.tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marked-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors_string</th>\n",
       "      <th>title_string</th>\n",
       "      <th>summary_string</th>\n",
       "      <th>categories_string</th>\n",
       "      <th>published_string</th>\n",
       "      <th>updated_string</th>\n",
       "      <th>url_string</th>\n",
       "      <th>blocking_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]</td>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>Neural machine translation is a recently pro...</td>\n",
       "      <td>[cs.CL, cs.LG, cs.NE, stat.ML]</td>\n",
       "      <td>2014-09-01T16:33:02Z</td>\n",
       "      <td>2016-05-19T21:53:22Z</td>\n",
       "      <td>http://arxiv.org/abs/1409.0473v7</td>\n",
       "      <td>{Translation, by, Neural, Machine, Align, Join...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Alec Radford, Luke Metz, Soumith Chintala]</td>\n",
       "      <td>Unsupervised Representation Learning with Deep...</td>\n",
       "      <td>In recent years, supervised learning with co...</td>\n",
       "      <td>[cs.LG, cs.CV]</td>\n",
       "      <td>2015-11-19T22:50:32Z</td>\n",
       "      <td>2016-01-07T23:09:39Z</td>\n",
       "      <td>http://arxiv.org/abs/1511.06434v2</td>\n",
       "      <td>{Representation, Unsupervised, Deep, Learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Ian J. Goodfellow, Jonathon Shlens, Christian...</td>\n",
       "      <td>Explaining and Harnessing Adversarial Examples</td>\n",
       "      <td>Several machine learning models, including n...</td>\n",
       "      <td>[stat.ML, cs.LG]</td>\n",
       "      <td>2014-12-20T01:17:12Z</td>\n",
       "      <td>2015-03-20T20:19:16Z</td>\n",
       "      <td>http://arxiv.org/abs/1412.6572v3</td>\n",
       "      <td>{Explaining, Examples, Adversarial, Harnessing}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                     authors_string  \\\n",
       "0  0   [Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio]   \n",
       "1  1        [Alec Radford, Luke Metz, Soumith Chintala]   \n",
       "2  2  [Ian J. Goodfellow, Jonathon Shlens, Christian...   \n",
       "\n",
       "                                        title_string  \\\n",
       "0  Neural Machine Translation by Jointly Learning...   \n",
       "1  Unsupervised Representation Learning with Deep...   \n",
       "2     Explaining and Harnessing Adversarial Examples   \n",
       "\n",
       "                                      summary_string  \\\n",
       "0    Neural machine translation is a recently pro...   \n",
       "1    In recent years, supervised learning with co...   \n",
       "2    Several machine learning models, including n...   \n",
       "\n",
       "                categories_string      published_string        updated_string  \\\n",
       "0  [cs.CL, cs.LG, cs.NE, stat.ML]  2014-09-01T16:33:02Z  2016-05-19T21:53:22Z   \n",
       "1                  [cs.LG, cs.CV]  2015-11-19T22:50:32Z  2016-01-07T23:09:39Z   \n",
       "2                [stat.ML, cs.LG]  2014-12-20T01:17:12Z  2015-03-20T20:19:16Z   \n",
       "\n",
       "                          url_string  \\\n",
       "0   http://arxiv.org/abs/1409.0473v7   \n",
       "1  http://arxiv.org/abs/1511.06434v2   \n",
       "2   http://arxiv.org/abs/1412.6572v3   \n",
       "\n",
       "                                     blocking_tokens  \n",
       "0  {Translation, by, Neural, Machine, Align, Join...  \n",
       "1  {Representation, Unsupervised, Deep, Learning,...  \n",
       "2    {Explaining, Examples, Adversarial, Harnessing}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_arxiv = rltk.Dataset(reader=rltk.DataFrameReader(df_arxiv), record_class=ArxivRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "print(type(ds_arxiv))\n",
    "ds_arxiv.generate_dataframe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-steps",
   "metadata": {},
   "source": [
    "**Google Scholar Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "august-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GScholarRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = 'GScholarRecord'\n",
    "        \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def authors_string(self):\n",
    "        return self.raw_object['authors']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['title']\n",
    "        \n",
    "    @rltk.cached_property\n",
    "    def journal_string(self):\n",
    "        return self.raw_object['journal']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def citations_string(self):\n",
    "        return self.raw_object['citations']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def year_string(self):\n",
    "        return self.raw_object['year']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def blocking_tokens(self):\n",
    "        tokens = ' '.join([self.title_string])\n",
    "        tokens = re.sub(r'\\bThe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bthe\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bof\\b', '', tokens)\n",
    "        tokens = re.sub(r\"\\b's\\b\", '', tokens)\n",
    "        tokens = re.sub(r'\\band\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bI\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bA\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bin\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bfor\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bon\\b', '', tokens)\n",
    "        tokens = re.sub(r'\\bwith\\b', '', tokens)\n",
    "        return set(tokenizer.tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "embedded-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors_string</th>\n",
       "      <th>title_string</th>\n",
       "      <th>journal_string</th>\n",
       "      <th>citations_string</th>\n",
       "      <th>year_string</th>\n",
       "      <th>url_string</th>\n",
       "      <th>blocking_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[D Bahdanau, K Cho, Y Bengio]</td>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>ICLR</td>\n",
       "      <td>13000</td>\n",
       "      <td>2015</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{., Translation, by, Neural, Machine, Align, J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[A Radford, L Metz, S Chintala]</td>\n",
       "      <td>Unsupervised Representation Learning with Deep...</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>6544</td>\n",
       "      <td>2016</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{., Representation, Unsupervised, Deep, Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[IJ Goodfellow, J Shlens, C Szegedy]</td>\n",
       "      <td>Explaining and Harnessing Adversarial Examples.</td>\n",
       "      <td>ICLR (Poster)</td>\n",
       "      <td>4827</td>\n",
       "      <td>2015</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>{Examples, ., Harnessing, Explaining, Adversar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                        authors_string  \\\n",
       "0  0         [D Bahdanau, K Cho, Y Bengio]   \n",
       "1  1       [A Radford, L Metz, S Chintala]   \n",
       "2  2  [IJ Goodfellow, J Shlens, C Szegedy]   \n",
       "\n",
       "                                        title_string journal_string  \\\n",
       "0  Neural Machine Translation by Jointly Learning...           ICLR   \n",
       "1  Unsupervised Representation Learning with Deep...  ICLR (Poster)   \n",
       "2    Explaining and Harnessing Adversarial Examples.  ICLR (Poster)   \n",
       "\n",
       "  citations_string year_string  \\\n",
       "0            13000        2015   \n",
       "1             6544        2016   \n",
       "2             4827        2015   \n",
       "\n",
       "                                          url_string  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                     blocking_tokens  \n",
       "0  {., Translation, by, Neural, Machine, Align, J...  \n",
       "1  {., Representation, Unsupervised, Deep, Learni...  \n",
       "2  {Examples, ., Harnessing, Explaining, Adversar...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gscholar = rltk.Dataset(reader=rltk.DataFrameReader(df_gscholar), record_class=GScholarRecord, adapter=rltk.MemoryKeyValueAdapter())\n",
    "print(type(ds_gscholar))\n",
    "ds_gscholar.generate_dataframe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-fraud",
   "metadata": {},
   "source": [
    "### Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dramatic-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rltk.blocking.block.Block'>\n"
     ]
    }
   ],
   "source": [
    "# Generate blocks from tokens\n",
    "token_blocker = rltk.TokenBlockGenerator()\n",
    "blocks = token_blocker.generate(\n",
    "    token_blocker.block(ds_arxiv, property_='blocking_tokens'),\n",
    "    token_blocker.block(ds_gscholar, property_='blocking_tokens'))\n",
    "print(type(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifth-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction Ratio: 0.60755\n"
     ]
    }
   ],
   "source": [
    "# Extract all record pairs from the block\n",
    "record_pairs = rltk.get_record_pairs(ds_arxiv, ds_gscholar, block=blocks)\n",
    "\n",
    "# Get the total number of record pairs generated\n",
    "compared_pairs = len(list(record_pairs))\n",
    "\n",
    "# Get the number of elements in each rltk.Dataset\n",
    "tally_imdb = ds_arxiv.generate_dataframe().shape[0]\n",
    "tally_tmd = ds_gscholar.generate_dataframe().shape[0]\n",
    "\n",
    "# Calculate the total number of pairs if both datasets were to be compared without any blocking (eg: a double for loop)\n",
    "tally_unblocked = tally_imdb * tally_tmd\n",
    "\n",
    "# Calculate how much smaller the blocked pairings are\n",
    "reduction_ratio = compared_pairs / tally_unblocked\n",
    "\n",
    "# Calculate the reduction ratio (the inverse of the )\n",
    "reduction_ratio = 1 - reduction_ratio\n",
    "print(f'Reduction Ratio: {reduction_ratio:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-public",
   "metadata": {},
   "source": [
    "### Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "automated-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_title = arxiv_tuple.title_string.strip().lower()\n",
    "    gscholar_title = gscholar_tuple.title_string.strip().lower()\n",
    "    similarity = SequenceMatcher(None, arxiv_title, gscholar_title).ratio()\n",
    "\n",
    "    penalties = sum([len(arxiv_title)<=6,\n",
    "                     len(gscholar_title)<=6])\n",
    "\n",
    "    return similarity * (0.9**penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "together-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_author = ' '.join(arxiv_tuple.authors_string).strip().lower()\n",
    "    gscholar_author = ' '.join(gscholar_tuple.authors_string).strip().lower()\n",
    "    similarity = SequenceMatcher(None, arxiv_author, gscholar_author).ratio() \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wooden-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_similarity(arxiv_tuple, gscholar_tuple):\n",
    "    arxiv_year = int(float(arxiv_tuple.updated_string[0:4]))\n",
    "    gscholar_year = int(float(gscholar_tuple.year_string))\n",
    "    similarity = 1 /(1 + abs(arxiv_year-gscholar_year))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wireless-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_similarity(arxiv_tuple, gscholar_tuple, match_threshold=0.75):\n",
    "    sim_title = title_similarity(arxiv_tuple, gscholar_tuple)\n",
    "    sim_author = author_similarity(arxiv_tuple, gscholar_tuple)\n",
    "    sim_year = year_similarity(arxiv_tuple, gscholar_tuple)\n",
    "\n",
    "    element_similarity = (0.70 * sim_title) + (0.15 * sim_author) + (0.15 * sim_year)\n",
    "\n",
    "    return element_similarity > match_threshold, element_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "straight-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv samples: 1780\n",
      "GScholar samples: 1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 21/21 [2:48:52<00:00, 482.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Set_A Size</th>\n",
       "      <th>Set_B Size</th>\n",
       "      <th>Duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>572870.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>572870.0</td>\n",
       "      <td>1142947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>572870.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>572870.0</td>\n",
       "      <td>1142947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>572694.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>572694.0</td>\n",
       "      <td>1142595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>565465.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>565465.0</td>\n",
       "      <td>1128137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>522940.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>522940.0</td>\n",
       "      <td>1043087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>410293.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>410293.0</td>\n",
       "      <td>817794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>247252.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>247252.0</td>\n",
       "      <td>491712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>119245.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>119245.0</td>\n",
       "      <td>235707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>49201.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>49201.0</td>\n",
       "      <td>95735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>17674.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>17674.0</td>\n",
       "      <td>33009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>5794.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>5794.0</td>\n",
       "      <td>9701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>2164.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>2790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>774.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>679.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>632.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>616.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>603.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>439.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>360.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Matches  Set_A Size  Set_B Size  Duplicates\n",
       "0.00  572870.0      1778.0    572870.0   1142947.0\n",
       "0.05  572870.0      1778.0    572870.0   1142947.0\n",
       "0.10  572694.0      1778.0    572694.0   1142595.0\n",
       "0.15  565465.0      1778.0    565465.0   1128137.0\n",
       "0.20  522940.0      1778.0    522940.0   1043087.0\n",
       "0.25  410293.0      1777.0    410293.0    817794.0\n",
       "0.30  247252.0      1777.0    247252.0    491712.0\n",
       "0.35  119245.0      1769.0    119245.0    235707.0\n",
       "0.40   49201.0      1661.0     49201.0     95735.0\n",
       "0.45   17674.0      1399.0     17674.0     33009.0\n",
       "0.50    5794.0      1095.0      5794.0      9701.0\n",
       "0.55    2164.0       861.0      2164.0      2790.0\n",
       "0.60    1088.0       739.0      1088.0       806.0\n",
       "0.65     774.0       672.0       774.0       251.0\n",
       "0.70     679.0       637.0       679.0       102.0\n",
       "0.75     632.0       619.0       632.0        29.0\n",
       "0.80     616.0       614.0       616.0         4.0\n",
       "0.85     603.0       601.0       603.0         2.0\n",
       "0.90     439.0       438.0       439.0         1.0\n",
       "0.95     360.0       359.0       360.0         1.0\n",
       "1.00       0.0         0.0         0.0         0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict matches for all pairs in the blocked data \n",
    "print(f'Arxiv samples: {df_arxiv.shape[0]}')\n",
    "print(f'GScholar samples: {df_gscholar.shape[0]}')\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "THRESHOLDS = [T/100 for T in range(0, 101, 5)]\n",
    "\n",
    "# Iterate through various thresholds to find the most matches without any duplicates\n",
    "for T in tqdm(THRESHOLDS):\n",
    "\n",
    "    # Set to store pairs of IDs matched\n",
    "    ids_matched = set()\n",
    "    \n",
    "    # Iterate through candidates on the block\n",
    "    for block_id, arxiv_id, gscholar_id in blocks.pairwise(ds_arxiv, ds_gscholar):\n",
    "        \n",
    "        # Find similarity at a given threshold\n",
    "        match , similarity = elementwise_similarity(ds_arxiv.get_record(arxiv_id),\n",
    "                                                    ds_gscholar.get_record(gscholar_id),\n",
    "                                                    match_threshold=T)\n",
    "        # If a match is found, add to the set of matches\n",
    "        if match:\n",
    "            ids_matched.add((arxiv_id, gscholar_id))\n",
    "    \n",
    "    # Count the number of unique elements derived from each source\n",
    "    set_a = set()\n",
    "    set_b = set()\n",
    "    for tp in ids_matched:\n",
    "        set_a.add(tp[0])\n",
    "        set_b.add(tp[1])\n",
    "    \n",
    "    summary_df.at[T, 'Matches'] = int(len(ids_matched))\n",
    "    summary_df.at[T, 'Set_A Size'] = int(len(set_a))\n",
    "    summary_df.at[T, 'Set_B Size'] = int(len(ids_matched))\n",
    "    summary_df.at[T, 'Duplicates'] = int((len(ids_matched)-len(set_a)) + (len(ids_matched)-len(set_b)))\n",
    "    \n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afraid-anaheim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the lowest threshold which gives no duplicates\n",
    "optimal_threshold = summary_df[summary_df['Duplicates']==0].index[0]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "polar-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set threshold to 0.80 to trade 616 extra True Positives for 4 extra False Positives\n",
    "optimal_threshold = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recovered-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv samples: 1780\n",
      "GScholar samples: 1016\n",
      "\n",
      "Matches: 616\n",
      "Non-Matches Arxiv: 1164\n",
      "Non-Matches GScholar: 401\n"
     ]
    }
   ],
   "source": [
    "# Generate matches based on the optimal (no-duplicate) threshold\n",
    "print(f'Arxiv samples: {df_arxiv.shape[0]}')\n",
    "print(f'GScholar samples: {df_gscholar.shape[0]}')\n",
    "\n",
    "# Store tuples of matches IDs, as well as singletons witouth a match\n",
    "ids_matched = set()\n",
    "singles_arxiv = set()\n",
    "singles_gscholar = set()\n",
    "\n",
    "# Write matches (and non-matches) to a CSV\n",
    "with open(f'Matches_{TOPIC}.csv', 'w') as predictions_full:\n",
    "    for block_id, arxiv_id, gscholar_id in blocks.pairwise(ds_arxiv, ds_gscholar):\n",
    "\n",
    "        match , similarity = elementwise_similarity(ds_arxiv.get_record(arxiv_id),\n",
    "                                                    ds_gscholar.get_record(gscholar_id),\n",
    "                                                    match_threshold=optimal_threshold)\n",
    "\n",
    "        if match:\n",
    "            ids_matched.add((arxiv_id, gscholar_id))\n",
    "        else:\n",
    "            singles_arxiv.add(arxiv_id)\n",
    "            singles_gscholar.add(gscholar_id)\n",
    "    \n",
    "    # After finding all matches, write them to a csv\n",
    "    for match_pair in ids_matched:\n",
    "        predictions_full.write(f'{match_pair[0]},{match_pair[1]},1\\n')\n",
    "        # And ensure that no item in the matches is counted as a single\n",
    "        try:\n",
    "            singles_arxiv.remove(match_pair[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            singles_gscholar.remove(match_pair[1])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Then write all the singles which didn't find a match\n",
    "    NULL = None\n",
    "    for arxiv_id in singles_arxiv:\n",
    "        predictions_full.write(f'{arxiv_id},{NULL},0\\n')\n",
    "    for gscholar_id in singles_gscholar:\n",
    "        predictions_full.write(f'{NULL},{gscholar_id},0\\n')        \n",
    "        \n",
    "print()\n",
    "print(f'Matches: {len(ids_matched)}')\n",
    "print(f'Non-Matches Arxiv: {len(singles_arxiv)}')\n",
    "print(f'Non-Matches GScholar: {len(singles_gscholar)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-clause",
   "metadata": {},
   "source": [
    "### Create Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "basic-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "MYNS = Namespace('http://inf558.org/myfakenamespace#')\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "\n",
    "# Initliaze the graph\n",
    "g = rdflib.Graph()\n",
    "\n",
    "# Bind namespace and prefixes\n",
    "g.bind('my_ns', MYNS)\n",
    "g.bind('schema', SCHEMA)\n",
    "g.bind('rdf', RDF)\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('xsd', XSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "assumed-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_df.shape: (2181, 3)\n",
      "predicted matches: 616  [28.24 %]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXIV_ID</th>\n",
       "      <th>GSCHOLAR_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1052</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1438</td>\n",
       "      <td>475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1766</td>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1180</td>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ARXIV_ID GSCHOLAR_ID  LABEL\n",
       "0      570         204      1\n",
       "1     1052         297      1\n",
       "2     1438         475      1\n",
       "3     1766         919      1\n",
       "4     1180         354      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predictions to be used in populating the RDF\n",
    "predictions_df = pd.read_csv(f'Matches_{TOPIC}.csv', header=None, names=['ARXIV_ID', 'GSCHOLAR_ID', 'LABEL'])\n",
    "print(f'predictions_df.shape: {predictions_df.shape}')\n",
    "predicted_matches = predictions_df['LABEL'].sum()\n",
    "print(f'predicted matches: {predicted_matches}  [{100*predicted_matches/predictions_df.shape[0]:.2f} %]')\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "funded-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2181/2181 [00:22<00:00, 95.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the merged datasets\n",
    "df_merged = pd.DataFrame(columns = ['ID', 'title', 'authors', 'published', 'updated', \n",
    "                                    'abstract', 'categories', 'citations', 'arxiv_url', 'gscholar_url'],\n",
    "                         dtype='object')\n",
    "json_merged = {}\n",
    "\n",
    "NEW_ID = 0\n",
    "\n",
    "# Populate the RDF with predictions with a positive (1) label\n",
    "for idx, row in tqdm(predictions_df.iterrows(), total=predictions_df.shape[0]):\n",
    "    \n",
    "    # Populate the json object\n",
    "    json_merged[NEW_ID] = {}\n",
    "    \n",
    "    ### URI ###\n",
    "    node_uri = URIRef(str(NEW_ID))\n",
    "    g.add((node_uri, RDF.type, SCHEMA.ScholarlyArticle))\n",
    "    df_merged.at[NEW_ID, 'ID'] = NEW_ID\n",
    "    json_merged[NEW_ID]['ID'] = NEW_ID\n",
    "\n",
    "    \n",
    "    ### Title ###\n",
    "    try:\n",
    "        title_arxiv = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['title'].values[0])\n",
    "    except:\n",
    "        title_arxiv = '<___>'\n",
    "    try:\n",
    "        title_gscholar = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['title'].values[0])\n",
    "    except:\n",
    "        title_gscholar = '<___>'\n",
    "    title = title_arxiv if title_arxiv != '<___>' else title_gscholar if title_gscholar != '<___>' else None\n",
    "    g.add((node_uri, SCHEMA.headline, Literal(title, datatype=SCHEMA.Text)))\n",
    "    df_merged.at[NEW_ID, 'title'] = title\n",
    "    json_merged[NEW_ID]['title'] = title\n",
    "\n",
    "    \n",
    "    ### Author(s) ###\n",
    "    try:\n",
    "        author_arxiv = df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['authors'].values[0]\n",
    "        author_arxiv = [name.strip() for name in author_arxiv if name != '<___>']\n",
    "    except:\n",
    "        author_arxiv = '<___>'\n",
    "    try:\n",
    "        author_gscholar = df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['authors'].values[0]\n",
    "        author_gscholar = [name.strip() for name in author_gscholar if name != '<___>']\n",
    "    except:\n",
    "        author_gscholar = '<___>'\n",
    "    if author_arxiv != '<___>':\n",
    "        authors = list(set(author_arxiv))\n",
    "    else:\n",
    "        authors = list(set(author_gscholar))           \n",
    "    [g.add((node_uri, SCHEMA.author, Literal(author, datatype=SCHEMA.Person))) for author in authors]\n",
    "    df_merged.at[NEW_ID, 'authors'] = authors\n",
    "    json_merged[NEW_ID]['authors'] = authors\n",
    "                       \n",
    "    ### Published ###\n",
    "    try:\n",
    "        published = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['published'].values[0])\n",
    "        g.add((node_uri, SCHEMA.datePublished, Literal(published, datatype=SCHEMA.DateTime)))\n",
    "        df_merged.at[NEW_ID, 'published'] = published\n",
    "        json_merged[NEW_ID]['published'] = published\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "                       \n",
    "    ### Updated ###\n",
    "    try:\n",
    "        updated = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['updated'].values[0])\n",
    "        g.add((node_uri, SCHEMA.dateModified, Literal(updated, datatype=SCHEMA.DateTime)))\n",
    "        df_merged.at[NEW_ID, 'updated'] = updated\n",
    "        json_merged[NEW_ID]['updated'] = updated\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "                       \n",
    "    ### Abstract ###\n",
    "    try:\n",
    "        abstract = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['summary'].values[0]).strip()\n",
    "        g.add((node_uri, SCHEMA.abstract, Literal(abstract, datatype=SCHEMA.Text)))\n",
    "        df_merged.at[NEW_ID, 'abstract'] = abstract\n",
    "        json_merged[NEW_ID]['abstract'] = abstract\n",
    "    except:\n",
    "        pass\n",
    "       \n",
    "                       \n",
    "    ### Categories ###\n",
    "    try:\n",
    "        categories = df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['categories'].values[0]\n",
    "        categories = [name.strip() for name in categories if name != '<___>']\n",
    "        [g.add((node_uri, SCHEMA.genre, Literal(category, datatype=SCHEMA.Text))) for category in categories]\n",
    "        df_merged.at[NEW_ID, 'categories'] = categories\n",
    "        json_merged[NEW_ID]['categories'] = categories\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "                       \n",
    "    ### Journal ###\n",
    "    try:\n",
    "        journal = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['journal'].values[0])\n",
    "        g.add((node_uri, SCHEMA.publisher, Literal(journal, datatype=SCHEMA.Periodical))) #datatype=SCHEMA.Organisation\n",
    "        df_merged.at[NEW_ID, 'journal'] = journal\n",
    "        json_merged[NEW_ID]['journal'] = journal\n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "                       \n",
    "    ### Citations ###\n",
    "    try:\n",
    "        citations = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['citations'].values[0])\n",
    "        g.add((node_uri, SCHEMA.commentCount, Literal(citations, datatype=SCHEMA.Integer)))\n",
    "        df_merged.at[NEW_ID, 'citations'] = citations\n",
    "        json_merged[NEW_ID]['citations'] = citations\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "                       \n",
    "    ### Arxiv URL ###\n",
    "    try:\n",
    "        arxiv_url = str(df_arxiv[df_arxiv['ID'] == str(row['ARXIV_ID'])]['url'].values[0])\n",
    "        g.add((node_uri, SCHEMA.url, Literal(arxiv_url, datatype=SCHEMA.URL)))\n",
    "        df_merged.at[NEW_ID, 'arxiv_url'] = arxiv_url    \n",
    "        json_merged[NEW_ID]['arxiv_url'] = arxiv_url\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "                       \n",
    "    ### Google Scholar URL ###\n",
    "    try:\n",
    "        gscholar_url = str(df_gscholar[df_gscholar['ID'] == str(row['GSCHOLAR_ID'])]['url'].values[0])\n",
    "        g.add((node_uri, SCHEMA.url, Literal(gscholar_url, datatype=SCHEMA.URL)))\n",
    "        df_merged.at[NEW_ID, 'gscholar_url'] = gscholar_url   \n",
    "        json_merged[NEW_ID]['gscholar_url'] = gscholar_url\n",
    "    except:\n",
    "        pass\n",
    "             \n",
    "                       \n",
    "    NEW_ID += 1\n",
    "    \n",
    "# Save to disk using turtle format\n",
    "g.serialize(f'Triples_{TOPIC}.ttl.', format=\"turtle\")\n",
    "\n",
    "# And save the merged DataFrame as CSV\n",
    "df_merged.to_csv(f'Merged_{TOPIC}.csv', index=False)\n",
    "\n",
    "# Also save as Json, just because\n",
    "with open(f'Json_{TOPIC}.json', 'w') as fout:\n",
    "    json.dump(json_merged, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "active-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>citations</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>gscholar_url</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Improved Training of Wasserstein GANs</td>\n",
       "      <td>[Aaron Courville, Martin Arjovsky, Faruk Ahmed...</td>\n",
       "      <td>2017-03-31T19:25:00Z</td>\n",
       "      <td>2017-12-25T23:03:49Z</td>\n",
       "      <td>Generative Adversarial Networks (GANs) are pow...</td>\n",
       "      <td>[cs.LG, stat.ML]</td>\n",
       "      <td>3041</td>\n",
       "      <td>http://arxiv.org/abs/1704.00028v3</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>Proceedings of the 31st International Conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RETAIN: An Interpretable Predictive Model for ...</td>\n",
       "      <td>[Walter F. Stewart, Edward Choi, Mohammad Taha...</td>\n",
       "      <td>2016-08-19T21:54:46Z</td>\n",
       "      <td>2017-02-26T15:13:31Z</td>\n",
       "      <td>Accuracy and interpretability are two dominant...</td>\n",
       "      <td>[cs.LG, cs.AI, cs.NE]</td>\n",
       "      <td>385</td>\n",
       "      <td>http://arxiv.org/abs/1608.05745v4</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>Proceedings of the 30th International Conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Markov Chain Monte Carlo and Variational Infer...</td>\n",
       "      <td>[Diederik P. Kingma, Max Welling, Tim Salimans]</td>\n",
       "      <td>2014-10-23T19:23:53Z</td>\n",
       "      <td>2015-05-19T13:53:13Z</td>\n",
       "      <td>Recent advances in stochastic gradient variati...</td>\n",
       "      <td>[stat.CO, stat.ML]</td>\n",
       "      <td>331</td>\n",
       "      <td>http://arxiv.org/abs/1410.6460v4</td>\n",
       "      <td>http://scholar.google.com/scholar?oi=bibs&amp;clus...</td>\n",
       "      <td>ICML, 1218-1226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID                                              title  \\\n",
       "0  0              Improved Training of Wasserstein GANs   \n",
       "1  1  RETAIN: An Interpretable Predictive Model for ...   \n",
       "2  2  Markov Chain Monte Carlo and Variational Infer...   \n",
       "\n",
       "                                             authors             published  \\\n",
       "0  [Aaron Courville, Martin Arjovsky, Faruk Ahmed...  2017-03-31T19:25:00Z   \n",
       "1  [Walter F. Stewart, Edward Choi, Mohammad Taha...  2016-08-19T21:54:46Z   \n",
       "2    [Diederik P. Kingma, Max Welling, Tim Salimans]  2014-10-23T19:23:53Z   \n",
       "\n",
       "                updated                                           abstract  \\\n",
       "0  2017-12-25T23:03:49Z  Generative Adversarial Networks (GANs) are pow...   \n",
       "1  2017-02-26T15:13:31Z  Accuracy and interpretability are two dominant...   \n",
       "2  2015-05-19T13:53:13Z  Recent advances in stochastic gradient variati...   \n",
       "\n",
       "              categories citations                          arxiv_url  \\\n",
       "0       [cs.LG, stat.ML]      3041  http://arxiv.org/abs/1704.00028v3   \n",
       "1  [cs.LG, cs.AI, cs.NE]       385  http://arxiv.org/abs/1608.05745v4   \n",
       "2     [stat.CO, stat.ML]       331   http://arxiv.org/abs/1410.6460v4   \n",
       "\n",
       "                                        gscholar_url  \\\n",
       "0  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "1  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "2  http://scholar.google.com/scholar?oi=bibs&clus...   \n",
       "\n",
       "                                             journal  \n",
       "0  Proceedings of the 31st International Conferen...  \n",
       "1  Proceedings of the 30th International Conferen...  \n",
       "2                                    ICML, 1218-1226  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "expensive-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2181 entries, 0 to 2180\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            2181 non-null   object\n",
      " 1   title         2181 non-null   object\n",
      " 2   authors       2181 non-null   object\n",
      " 3   published     1780 non-null   object\n",
      " 4   updated       1780 non-null   object\n",
      " 5   abstract      1780 non-null   object\n",
      " 6   categories    1780 non-null   object\n",
      " 7   citations     1017 non-null   object\n",
      " 8   arxiv_url     1780 non-null   object\n",
      " 9   gscholar_url  1017 non-null   object\n",
      " 10  journal       1017 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 269.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "welsh-company",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'ID': 0,\n",
       "  'title': 'Improved Training of Wasserstein GANs',\n",
       "  'authors': ['Aaron Courville',\n",
       "   'Martin Arjovsky',\n",
       "   'Faruk Ahmed',\n",
       "   'Vincent Dumoulin',\n",
       "   'Ishaan Gulrajani'],\n",
       "  'published': '2017-03-31T19:25:00Z',\n",
       "  'updated': '2017-12-25T23:03:49Z',\n",
       "  'abstract': 'Generative Adversarial Networks (GANs) are powerful generative models, butsuffer from training instability. The recently proposed Wasserstein GAN (WGAN)makes progress toward stable training of GANs, but sometimes can still generateonly low-quality samples or fail to converge. We find that these problems areoften due to the use of weight clipping in WGAN to enforce a Lipschitzconstraint on the critic, which can lead to undesired behavior. We propose analternative to clipping weights: penalize the norm of gradient of the criticwith respect to its input. Our proposed method performs better than standardWGAN and enables stable training of a wide variety of GAN architectures withalmost no hyperparameter tuning, including 101-layer ResNets and languagemodels over discrete data. We also achieve high quality generations on CIFAR-10and LSUN bedrooms.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '3041',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.00028v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3068694056154618633&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 1: {'ID': 1,\n",
       "  'title': 'RETAIN: An Interpretable Predictive Model for Healthcare using Reverse  Time Attention Mechanism',\n",
       "  'authors': ['Walter F. Stewart',\n",
       "   'Edward Choi',\n",
       "   'Mohammad Taha Bahadori',\n",
       "   'Andy Schuetz',\n",
       "   'Jimeng Sun',\n",
       "   'Joshua A. Kulas'],\n",
       "  'published': '2016-08-19T21:54:46Z',\n",
       "  'updated': '2017-02-26T15:13:31Z',\n",
       "  'abstract': 'Accuracy and interpretability are two dominant features of successfulpredictive models. Typically, a choice must be made in favor of complex blackbox models such as recurrent neural networks (RNN) for accuracy versus lessaccurate but more interpretable traditional models such as logistic regression.This tradeoff poses challenges in medicine where both accuracy andinterpretability are important. We addressed this challenge by developing theREverse Time AttentIoN model (RETAIN) for application to Electronic HealthRecords (EHR) data. RETAIN achieves high accuracy while remaining clinicallyinterpretable and is based on a two-level neural attention model that detectsinfluential past visits and significant clinical variables within those visits(e.g. key diagnoses). RETAIN mimics physician practice by attending the EHRdata in a reverse time order so that recent clinical visits are likely toreceive higher attention. RETAIN was tested on a large health system EHRdataset with 14 million visits completed by 263K patients over an 8 year periodand demonstrated predictive accuracy and computational scalability comparableto state-of-the-art methods such as RNN, and ease of interpretabilitycomparable to traditional models.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '385',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.05745v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12067026852472885249&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 2: {'ID': 2,\n",
       "  'title': 'Markov Chain Monte Carlo and Variational Inference: Bridging the Gap',\n",
       "  'authors': ['Diederik P. Kingma', 'Max Welling', 'Tim Salimans'],\n",
       "  'published': '2014-10-23T19:23:53Z',\n",
       "  'updated': '2015-05-19T13:53:13Z',\n",
       "  'abstract': 'Recent advances in stochastic gradient variational inference have made itpossible to perform variational Bayesian inference with posteriorapproximations containing auxiliary random variables. This enables us toexplore a new synthesis of variational inference and Monte Carlo methods wherewe incorporate one or more steps of MCMC into our variational approximation. Bydoing so we obtain a rich class of inference algorithms bridging the gapbetween variational methods and MCMC, and offering the best of both worlds:fast posterior approximation through the maximization of an explicit objective,with the option of trading off additional computation for additional accuracy.We describe the theoretical foundations that make this possible and show somepromising first results.',\n",
       "  'categories': ['stat.CO', 'stat.ML'],\n",
       "  'journal': 'ICML, 1218-1226',\n",
       "  'citations': '331',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1410.6460v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1527223141103092286&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 3: {'ID': 3,\n",
       "  'title': 'Adversarial Examples: Attacks and Defenses for Deep Learning',\n",
       "  'authors': ['Qile Zhu', 'Pan He', 'Xiaoyong Yuan', 'Xiaolin Li'],\n",
       "  'published': '2017-12-19T18:44:07Z',\n",
       "  'updated': '2018-07-07T02:32:57Z',\n",
       "  'abstract': 'With rapid progress and significant successes in a wide spectrum ofapplications, deep learning is being applied in many safety-criticalenvironments. However, deep neural networks have been recently found vulnerableto well-designed input samples, called adversarial examples. Adversarialexamples are imperceptible to human but can easily fool deep neural networks inthe testing/deploying stage. The vulnerability to adversarial examples becomesone of the major risks for applying deep neural networks in safety-criticalenvironments. Therefore, attacks and defenses on adversarial examples drawgreat attention. In this paper, we review recent findings on adversarialexamples for deep neural networks, summarize the methods for generatingadversarial examples, and propose a taxonomy of these methods. Under thetaxonomy, applications for adversarial examples are investigated. We furtherelaborate on countermeasures for adversarial examples and explore thechallenges and the potential solutions.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 30 (9), 2805-2824',\n",
       "  'citations': '400',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.07107v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4187134806050974749&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 4: {'ID': 4,\n",
       "  'title': 'Federated Multi-Task Learning',\n",
       "  'authors': ['Virginia Smith',\n",
       "   'Maziar Sanjabi',\n",
       "   'Chao-Kai Chiang',\n",
       "   'Ameet Talwalkar'],\n",
       "  'published': '2017-05-30T06:20:31Z',\n",
       "  'updated': '2018-02-27T07:29:26Z',\n",
       "  'abstract': 'Federated learning poses new statistical and systems challenges in trainingmachine learning models over distributed networks of devices. In this work, weshow that multi-task learning is naturally suited to handle the statisticalchallenges of this setting, and propose a novel systems-aware optimizationmethod, MOCHA, that is robust to practical systems issues. Our method andtheory for the first time consider issues of high communication cost,stragglers, and fault tolerance for distributed multi-task learning. Theresulting method achieves significant speedups compared to alternatives in thefederated setting, as we demonstrate through simulations on real-worldfederated datasets.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '261',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10467v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2729989706953112243&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 5: {'ID': 5,\n",
       "  'title': 'Fixing a Broken ELBO',\n",
       "  'authors': ['Ben Poole',\n",
       "   'Kevin Murphy',\n",
       "   'Rif A. Saurous',\n",
       "   'Ian Fischer',\n",
       "   'Joshua V. Dillon',\n",
       "   'Alexander A. Alemi'],\n",
       "  'published': '2017-11-01T17:58:43Z',\n",
       "  'updated': '2018-02-13T20:54:38Z',\n",
       "  'abstract': 'Recent work in unsupervised representation learning has focused on learningdeep directed latent-variable models. Fitting these models by maximizing themarginal likelihood or evidence is typically intractable, thus a commonapproximation is to maximize the evidence lower bound (ELBO) instead. However,maximum likelihood training (whether exact or approximate) does not necessarilyresult in a good latent representation, as we demonstrate both theoreticallyand empirically. In particular, we derive variational lower and upper bounds onthe mutual information between the input and the latent variable, and use thesebounds to derive a rate-distortion curve that characterizes the tradeoffbetween compression and reconstruction accuracy. Using this framework, wedemonstrate that there is a family of models with identical ELBO, but differentquantitative and qualitative characteristics. Our framework also suggests asimple new method to ensure that latent variable models with powerfulstochastic decoders do not ignore their latent code.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 159-168',\n",
       "  'citations': '173',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00464v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=841461541918895515&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 6: {'ID': 6,\n",
       "  'title': 'Parallel WaveNet: Fast High-Fidelity Speech Synthesis',\n",
       "  'authors': ['Nal Kalchbrenner',\n",
       "   'Edward Lockhart',\n",
       "   'Dominik Grewe',\n",
       "   'Yazhe Li',\n",
       "   'Karen Simonyan',\n",
       "   'Tom Walters',\n",
       "   'Seb Noury',\n",
       "   'Demis Hassabis',\n",
       "   'Aaron van den Oord',\n",
       "   'Oriol Vinyals',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Helen King',\n",
       "   'Dan Belov',\n",
       "   'Florian Stimberg',\n",
       "   'Sander Dieleman',\n",
       "   'Alex Graves',\n",
       "   'Norman Casagrande',\n",
       "   'Igor Babuschkin',\n",
       "   'Heiga Zen',\n",
       "   'Luis C. Cobo',\n",
       "   'Erich Elsen',\n",
       "   'George van den Driessche'],\n",
       "  'published': '2017-11-28T17:48:11Z',\n",
       "  'updated': '2017-11-28T17:48:11Z',\n",
       "  'abstract': \"The recently-developed WaveNet architecture is the current state of the artin realistic speech synthesis, consistently rated as more natural sounding formany different languages than any previous system. However, because WaveNetrelies on sequential generation of one audio sample at a time, it is poorlysuited to today's massively parallel computers, and therefore hard to deploy ina real-time production setting. This paper introduces Probability DensityDistillation, a new method for training a parallel feed-forward network from atrained WaveNet with no significant difference in quality. The resulting systemis capable of generating high-fidelity speech samples at more than 20 timesfaster than real-time, and is deployed online by Google Assistant, includingserving multiple English and Japanese voices.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 3915-3923',\n",
       "  'citations': '293',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.10433v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14024591857649905131&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 7: {'ID': 7,\n",
       "  'title': 'Wasserstein Auto-Encoders',\n",
       "  'authors': ['Sylvain Gelly',\n",
       "   'Bernhard Schoelkopf',\n",
       "   'Ilya Tolstikhin',\n",
       "   'Olivier Bousquet'],\n",
       "  'published': '2017-11-05T10:18:27Z',\n",
       "  'updated': '2019-12-05T10:27:44Z',\n",
       "  'abstract': 'We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for buildinga generative model of the data distribution. WAE minimizes a penalized form ofthe Wasserstein distance between the model distribution and the targetdistribution, which leads to a different regularizer than the one used by theVariational Auto-Encoder (VAE). This regularizer encourages the encodedtraining distribution to match the prior. We compare our algorithm with severalother techniques and show that it is a generalization of adversarialauto-encoders (AAE). Our experiments show that WAE shares many of theproperties of VAEs (stable training, encoder-decoder architecture, nice latentmanifold structure) while generating samples of better quality, as measured bythe FID score.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '371',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.01558v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1669877132293977025&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 8: {'ID': 8,\n",
       "  'title': 'Unsupervised Neural Machine Translation',\n",
       "  'authors': ['Kyunghyun Cho',\n",
       "   'Gorka Labaka',\n",
       "   'Eneko Agirre',\n",
       "   'Mikel Artetxe'],\n",
       "  'published': '2017-10-30T16:17:34Z',\n",
       "  'updated': '2018-02-26T16:54:14Z',\n",
       "  'abstract': 'In spite of the recent success of neural machine translation (NMT) instandard benchmarks, the lack of large parallel corpora poses a major practicalproblem for many language pairs. There have been several proposals to alleviatethis issue with, for instance, triangulation and semi-supervised learningtechniques, but they still require a strong cross-lingual signal. In this work,we completely remove the need of parallel data and propose a novel method totrain an NMT system in a completely unsupervised manner, relying on nothing butmonolingual corpora. Our model builds upon the recent work on unsupervisedembedding mappings, and consists of a slightly modified attentionalencoder-decoder model that can be trained on monolingual corpora alone using acombination of denoising and backtranslation. Despite the simplicity of theapproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014French-to-English and German-to-English translation. The model can also profitfrom small parallel corpora, and attains 21.81 and 15.24 points when combinedwith 100,000 parallel sentences, respectively. Our implementation is releasedas an open source project.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '359',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.11041v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6109181985493123662&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 9: {'ID': 9,\n",
       "  'title': 'Deep Neural Networks as Gaussian Processes',\n",
       "  'authors': ['Jeffrey Pennington',\n",
       "   'Roman Novak',\n",
       "   'Jaehoon Lee',\n",
       "   'Samuel S. Schoenholz',\n",
       "   'Jascha Sohl-Dickstein',\n",
       "   'Yasaman Bahri'],\n",
       "  'published': '2017-11-01T02:13:25Z',\n",
       "  'updated': '2018-03-03T00:45:00Z',\n",
       "  'abstract': 'It has long been known that a single-layer fully-connected neural networkwith an i.i.d. prior over its parameters is equivalent to a Gaussian process(GP), in the limit of infinite network width. This correspondence enables exactBayesian inference for infinite width neural networks on regression tasks bymeans of evaluating the corresponding GP. Recently, kernel functions whichmimic multi-layer random neural networks have been developed, but only outsideof a Bayesian framework. As such, previous work has not identified that thesekernels can be used as covariance functions for GPs and allow fully Bayesianprediction with a deep neural network.  In this work, we derive the exact equivalence between infinitely wide deepnetworks and GPs. We further develop a computationally efficient pipeline tocompute the covariance function for these GPs. We then use the resulting GPs toperform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10.We observe that trained neural network accuracy approaches that of thecorresponding GP with increasing layer width, and that the GP uncertainty isstrongly correlated with trained network prediction error. We further find thattest performance increases as finite-width trained networks are made wider andmore similar to a GP, and thus that GP predictions typically outperform thoseof finite-width networks. Finally we connect the performance of these GPs tothe recent theory of signal propagation in random neural networks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '251',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00165v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6709509064500094656&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 10: {'ID': 10,\n",
       "  'title': 'Matching Networks for One Shot Learning',\n",
       "  'authors': ['Charles Blundell',\n",
       "   'Oriol Vinyals',\n",
       "   'Timothy Lillicrap',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Daan Wierstra'],\n",
       "  'published': '2016-06-13T19:34:22Z',\n",
       "  'updated': '2017-12-29T17:45:19Z',\n",
       "  'abstract': 'Learning from a few examples remains a key challenge in machine learning.Despite recent advances in important domains such as vision and language, thestandard supervised deep learning paradigm does not offer a satisfactorysolution for learning new concepts rapidly from little data. In this work, weemploy ideas from metric learning based on deep neural features and from recentadvances that augment neural networks with external memories. Our frameworklearns a network that maps a small labelled support set and an unlabelledexample to its label, obviating the need for fine-tuning to adapt to new classtypes. We then define one-shot learning problems on vision (using Omniglot,ImageNet) and language tasks. Our algorithm improves one-shot accuracy onImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared tocompeting approaches. We also demonstrate the usefulness of the same model onlanguage modeling by introducing a one-shot task on the Penn Treebank.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1564',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.04080v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16507194575687684095&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 11: {'ID': 11,\n",
       "  'title': 'Co-occurrence Feature Learning for Skeleton based Action Recognition  using Regularized Deep LSTM Networks',\n",
       "  'authors': ['Li Shen',\n",
       "   'Junliang Xing',\n",
       "   'Yanghao Li',\n",
       "   'Wenjun Zeng',\n",
       "   'Wentao Zhu',\n",
       "   'Xiaohui Xie',\n",
       "   'Cuiling Lan'],\n",
       "  'published': '2016-03-24T22:43:55Z',\n",
       "  'updated': '2016-03-24T22:43:55Z',\n",
       "  'abstract': 'Skeleton based action recognition distinguishes human actions using thetrajectories of skeleton joints, which provide a very good representation fordescribing actions. Considering that recurrent neural networks (RNNs) with LongShort-Term Memory (LSTM) can learn feature representations and model long-termtemporal dependencies automatically, we propose an end-to-end fully connecteddeep LSTM network for skeleton based action recognition. Inspired by theobservation that the co-occurrences of the joints intrinsically characterizehuman actions, we take the skeleton as the input at each time slot andintroduce a novel regularization scheme to learn the co-occurrence features ofskeleton joints. To train the deep LSTM network effectively, we propose a newdropout algorithm which simultaneously operates on the gates, cells, and outputresponses of the LSTM neurons. Experimental results on three human actionrecognition datasets consistently demonstrate the effectiveness of the proposedmodel.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '441',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.07772v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1557422179662919133&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 12: {'ID': 12,\n",
       "  'title': 'Decoupled Neural Interfaces using Synthetic Gradients',\n",
       "  'authors': ['Wojciech Marian Czarnecki',\n",
       "   'Alex Graves',\n",
       "   'Simon Osindero',\n",
       "   'Max Jaderberg',\n",
       "   'Oriol Vinyals',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'David Silver'],\n",
       "  'published': '2016-08-18T17:29:09Z',\n",
       "  'updated': '2017-07-03T10:52:04Z',\n",
       "  'abstract': \"Training directed neural networks typically requires forward-propagating datathrough a computation graph, followed by backpropagating error signal, toproduce weight updates. All layers, or more generally, modules, of the networkare therefore locked, in the sense that they must wait for the remainder of thenetwork to execute forwards and propagate error backwards before they can beupdated. In this work we break this constraint by decoupling modules byintroducing a model of the future computation of the network graph. Thesemodels predict what the result of the modelled subgraph will produce using onlylocal information. In particular we focus on modelling error gradients: byusing the modelled synthetic gradient in place of true backpropagated errorgradients we decouple subgraphs, and can update them independently andasynchronously i.e. we realise decoupled neural interfaces. We show results forfeed-forward models, where every layer is trained asynchronously, recurrentneural networks (RNNs) where predicting one's future gradient extends the timeover which the RNN can effectively model, and also a hierarchical RNN systemwith ticking at different timescales. Finally, we demonstrate that in additionto predicting gradients, the same framework can be used to predict inputs,resulting in models which are decoupled in both the forward and backwards pass-- amounting to independent networks which co-learn such that they can becomposed into a single functioning corporation.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1627-1635',\n",
       "  'citations': '173',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.05343v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3896090481314997713&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 13: {'ID': 13,\n",
       "  'title': 'PixelDefend: Leveraging Generative Models to Understand and Defend  against Adversarial Examples',\n",
       "  'authors': ['Stefano Ermon',\n",
       "   'Yang Song',\n",
       "   'Nate Kushman',\n",
       "   'Sebastian Nowozin',\n",
       "   'Taesup Kim'],\n",
       "  'published': '2017-10-30T04:21:23Z',\n",
       "  'updated': '2018-05-21T05:26:01Z',\n",
       "  'abstract': 'Adversarial perturbations of normal images are usually imperceptible tohumans, but they can seriously confuse state-of-the-art machine learningmodels. What makes them so special in the eyes of image classifiers? In thispaper, we show empirically that adversarial examples mainly lie in the lowprobability regions of the training distribution, regardless of attack typesand targeted models. Using statistical hypothesis testing, we find that modernneural density models are surprisingly good at detecting imperceptible imageperturbations. Based on this discovery, we devised PixelDefend, a new approachthat purifies a maliciously perturbed image by moving it back towards thedistribution seen in the training data. The purified image is then run throughan unmodified classifier, making our method agnostic to both the classifier andthe attacking method. As a result, PixelDefend can be used to protect alreadydeployed models and be combined with other model-specific defenses. Experimentsshow that our method greatly improves resilience across a wide variety ofstate-of-the-art attacking methods, increasing accuracy on the strongest attackfrom 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '278',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.10766v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9269726813530152599&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 14: {'ID': 14,\n",
       "  'title': 'Deep Compression: Compressing Deep Neural Networks with Pruning, Trained  Quantization and Huffman Coding',\n",
       "  'authors': ['William J. Dally', 'Huizi Mao', 'Song Han'],\n",
       "  'published': '2015-10-01T09:03:44Z',\n",
       "  'updated': '2016-02-15T06:25:40Z',\n",
       "  'abstract': 'Neural networks are both computationally intensive and memory intensive,making them difficult to deploy on embedded systems with limited hardwareresources. To address this limitation, we introduce \"deep compression\", a threestage pipeline: pruning, trained quantization and Huffman coding, that worktogether to reduce the storage requirement of neural networks by 35x to 49xwithout affecting their accuracy. Our method first prunes the network bylearning only the important connections. Next, we quantize the weights toenforce weight sharing, finally, we apply Huffman coding. After the first twosteps we retrain the network to fine tune the remaining connections and thequantized centroids. Pruning, reduces the number of connections by 9x to 13x;Quantization then reduces the number of bits that represent each connectionfrom 32 to 5. On the ImageNet dataset, our method reduced the storage requiredby AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our methodreduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss ofaccuracy. This allows fitting the model into on-chip SRAM cache rather thanoff-chip DRAM memory. Our compression method also facilitates the use ofcomplex neural networks in mobile applications where application size anddownload bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU,compressed network has 3x to 4x layerwise speedup and 3x to 7x better energyefficiency.',\n",
       "  'categories': ['cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '3559',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.00149v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7860777411990654691&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 15: {'ID': 15,\n",
       "  'title': 'New directional bat algorithm for continuous optimization problems',\n",
       "  'authors': ['Asma Chakri',\n",
       "   'Xin-She Yang',\n",
       "   'Mohamed Benouaret',\n",
       "   'Rabia Khelif'],\n",
       "  'published': '2018-04-22T10:36:56Z',\n",
       "  'updated': '2018-04-22T10:36:56Z',\n",
       "  'abstract': 'Bat algorithm (BA) is a recent optimization algorithm based on swarmintelligence and inspiration from the echolocation behavior of bats. One of theissues in the standard bat algorithm is the premature convergence that canoccur due to the low exploration ability of the algorithm under someconditions. To overcome this deficiency, directional echolocation is introducedto the standard bat algorithm to enhance its exploration and exploitationcapabilities. In addition to such directional echolocation, three otherimprovements have been embedded into the standard bat algorithm to enhance itsperformance. The new proposed approach, namely the directional Bat Algorithm(dBA), has been then tested using several standard and non-standard benchmarksfrom the CEC2005 benchmark suite. The performance of dBA has been compared withten other algorithms and BA variants using non-parametric statistical tests.The statistical test results show the superiority of the directional batalgorithm.',\n",
       "  'categories': ['cs.NE', 'math.OC', '90C30, 68W20'],\n",
       "  'journal': 'Expert Systems with Applications 69, 159-175',\n",
       "  'citations': '131',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.05854v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15807104368648205349&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 16: {'ID': 16,\n",
       "  'title': 'Mixed Precision Training',\n",
       "  'authors': ['Boris Ginsburg',\n",
       "   'Hao Wu',\n",
       "   'Sharan Narang',\n",
       "   'Jonah Alben',\n",
       "   'Ganesh Venkatesh',\n",
       "   'David Garcia',\n",
       "   'Gregory Diamos',\n",
       "   'Oleksii Kuchaiev',\n",
       "   'Michael Houston',\n",
       "   'Paulius Micikevicius',\n",
       "   'Erich Elsen'],\n",
       "  'published': '2017-10-10T17:42:04Z',\n",
       "  'updated': '2018-02-15T20:04:02Z',\n",
       "  'abstract': 'Deep neural networks have enabled progress in a wide variety of applications.Growing the size of the neural network typically results in improved accuracy.As model sizes grow, the memory and compute requirements for training thesemodels also increases. We introduce a technique to train deep neural networksusing half precision floating point numbers. In our technique, weights,activations and gradients are stored in IEEE half-precision format.Half-precision floating numbers have limited numerical range compared tosingle-precision numbers. We propose two techniques to handle this loss ofinformation. Firstly, we recommend maintaining a single-precision copy of theweights that accumulates the gradients after each optimizer step. Thissingle-precision copy is rounded to half-precision format during training.Secondly, we propose scaling the loss appropriately to handle the loss ofinformation with half-precision gradients. We demonstrate that this approachworks for a wide variety of models including convolution neural networks,recurrent neural networks and generative adversarial networks. This techniqueworks for large scale models with more than 100 million parameters trained onlarge datasets. Using this approach, we can reduce the memory consumption ofdeep learning models by nearly 2x. In future processors, we can also expect asignificant computation speedup using half-precision hardware units.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '272',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.03740v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18172749567892275222&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 17: {'ID': 17,\n",
       "  'title': 'VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback',\n",
       "  'authors': ['Ruining He', 'Julian McAuley'],\n",
       "  'published': '2015-10-06T23:46:15Z',\n",
       "  'updated': '2015-10-06T23:46:15Z',\n",
       "  'abstract': \"Modern recommender systems model people and items by discovering or `teasingapart' the underlying dimensions that encode the properties of items and users'preferences toward them. Critically, such dimensions are uncovered based onuser feedback, often in implicit form (such as purchase histories, browsinglogs, etc.); in addition, some recommender systems make use of sideinformation, such as product attributes, temporal information, or review text.However one important feature that is typically ignored by existingpersonalized recommendation and ranking methods is the visual appearance of theitems being considered. In this paper we propose a scalable factorization modelto incorporate visual signals into predictors of people's opinions, which weapply to a selection of large, real-world datasets. We make use of visualfeatures extracted from product images using (pre-trained) deep networks, ontop of which we learn an additional layer that uncovers the visual dimensionsthat best explain the variation in people's feedback. This not only leads tosignificantly more accurate personalized ranking methods, but also helps toalleviate cold start issues, and qualitatively to analyze the visual dimensionsthat influence people's opinions.\",\n",
       "  'categories': ['cs.IR', 'cs.AI'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '307',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.01784v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2037226735051735416&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 18: {'ID': 18,\n",
       "  'title': 'Group Component Analysis for Multiblock Data: Common and Individual  Feature Extraction',\n",
       "  'authors': ['Yu Zhang', 'Andrzej Cichocki', 'Danilo Mandic', 'Guoxu Zhou'],\n",
       "  'published': '2012-12-17T07:56:15Z',\n",
       "  'updated': '2017-03-12T08:36:27Z',\n",
       "  'abstract': 'Very often data we encounter in practice is a collection of matrices ratherthan a single matrix. These multi-block data are naturally linked and henceoften share some common features and at the same time they have their ownindividual features, due to the background in which they are measured andcollected. In this study we proposed a new scheme of common and individualfeature analysis (CIFA) that processes multi-block data in a linked way aimingat discovering and separating their common and individual features. Accordingto whether the number of common features is given or not, two efficientalgorithms were proposed to extract the common basis which is shared by alldata. Then feature extraction is performed on the common and the individualspaces separately by incorporating the techniques such as dimensionalityreduction and blind source separation. We also discussed how the proposed CIFAcan significantly improve the performance of classification and clusteringtasks by exploiting common and individual features of samples respectively. Ourexperimental results show some encouraging features of the proposed methods incomparison to the state-of-the-art methods on synthetic and real data.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 27 (11), 2426-2439',\n",
       "  'citations': '113',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1212.3913v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=676869504525254168&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 19: {'ID': 19,\n",
       "  'title': 'Deep Learning with S-shaped Rectified Linear Activation Units',\n",
       "  'authors': ['Junjun Xiong',\n",
       "   'Yunchao Wei',\n",
       "   'Shuicheng Yan',\n",
       "   'Xiaojie Jin',\n",
       "   'Jiashi Feng',\n",
       "   'Chunyan Xu'],\n",
       "  'published': '2015-12-22T10:54:26Z',\n",
       "  'updated': '2015-12-22T10:54:26Z',\n",
       "  'abstract': 'Rectified linear activation units are important components forstate-of-the-art deep convolutional networks. In this paper, we propose a novelS-shaped rectified linear activation unit (SReLU) to learn both convex andnon-convex functions, imitating the multiple function forms given by the twofundamental laws, namely the Webner-Fechner law and the Stevens law, inpsychophysics and neural sciences. Specifically, SReLU consists of threepiecewise linear functions, which are formulated by four learnable parameters.The SReLU is learned jointly with the training of the whole deep networkthrough back propagation. During the training phase, to initialize SReLU indifferent layers, we propose a \"freezing\" method to degenerate SReLU into apredefined leaky rectified linear unit in the initial several training epochsand then adaptively learn the good initial values. SReLU can be universallyused in the existing deep networks with negligible additional parameters andcomputation cost. Experiments with two popular CNN architectures, Network inNetwork and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100,MNIST and ImageNet demonstrate that SReLU achieves remarkable improvementcompared to other activation functions.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '147',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.07030v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4300961428502272386&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 20: {'ID': 20,\n",
       "  'title': 'Unifying Count-Based Exploration and Intrinsic Motivation',\n",
       "  'authors': ['Georg Ostrovski',\n",
       "   'Sriram Srinivasan',\n",
       "   'Tom Schaul',\n",
       "   'Marc G. Bellemare',\n",
       "   'Remi Munos',\n",
       "   'David Saxton'],\n",
       "  'published': '2016-06-06T19:21:32Z',\n",
       "  'updated': '2016-11-07T21:16:21Z',\n",
       "  'abstract': \"We consider an agent's uncertainty about its environment and the problem ofgeneralizing this uncertainty across observations. Specifically, we focus onthe problem of exploration in non-tabular reinforcement learning. Drawinginspiration from the intrinsic motivation literature, we use density models tomeasure uncertainty, and propose a novel algorithm for deriving a pseudo-countfrom an arbitrary density model. This technique enables us to generalizecount-based exploration algorithms to the non-tabular case. We apply our ideasto Atari 2600 games, providing sensible pseudo-counts from raw pixels. Wetransform these pseudo-counts into intrinsic rewards and obtain significantlyimproved exploration in a number of hard games, including the infamouslydifficult Montezuma's Revenge.\",\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '555',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.01868v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7667515176664990362&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 21: {'ID': 21,\n",
       "  'title': 'Learning Latent Dynamics for Planning from Pixels',\n",
       "  'authors': ['James Davidson',\n",
       "   'Ruben Villegas',\n",
       "   'David Ha',\n",
       "   'Ian Fischer',\n",
       "   'Timothy Lillicrap',\n",
       "   'Honglak Lee',\n",
       "   'Danijar Hafner'],\n",
       "  'published': '2018-11-12T04:30:10Z',\n",
       "  'updated': '2019-06-04T18:13:09Z',\n",
       "  'abstract': 'Planning has been very successful for control tasks with known environmentdynamics. To leverage planning in unknown environments, the agent needs tolearn the dynamics from interactions with the world. However, learning dynamicsmodels that are accurate enough for planning has been a long-standingchallenge, especially in image-based domains. We propose the Deep PlanningNetwork (PlaNet), a purely model-based agent that learns the environmentdynamics from images and chooses actions through fast online planning in latentspace. To achieve high performance, the dynamics model must accurately predictthe rewards ahead for multiple time steps. We approach this using a latentdynamics model with both deterministic and stochastic transition components.Moreover, we propose a multi-step variational inference objective that we namelatent overshooting. Using only pixel observations, our agent solves continuouscontrol tasks with contact dynamics, partial observability, and sparse rewards,which exceed the difficulty of tasks that were previously solved by planningwith learned models. PlaNet uses substantially fewer episodes and reaches finalperformance close to and sometimes higher than strong model-free algorithms.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 2555-2565',\n",
       "  'citations': '178',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.04551v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15406315513072250791&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 22: {'ID': 22,\n",
       "  'title': 'Spectrally-normalized margin bounds for neural networks',\n",
       "  'authors': ['Peter Bartlett', 'Dylan J. Foster', 'Matus Telgarsky'],\n",
       "  'published': '2017-06-26T17:43:48Z',\n",
       "  'updated': '2017-12-05T06:08:38Z',\n",
       "  'abstract': 'This paper presents a margin-based multiclass generalization bound for neuralnetworks that scales with their margin-normalized \"spectral complexity\": theirLipschitz constant, meaning the product of the spectral norms of the weightmatrices, times a certain correction factor. This bound is empiricallyinvestigated for a standard AlexNet network trained with SGD on the mnist andcifar10 datasets, with both original and random labels; the bound, theLipschitz constants, and the excess risks are all in direct correlation,suggesting both that SGD selects predictors whose complexity scales with thedifficulty of the learning task, and secondly that the presented bound issensitive to this complexity.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '380',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.08498v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16170177050810544440&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 23: {'ID': 23,\n",
       "  'title': 'Good Semi-supervised Learning that Requires a Bad GAN',\n",
       "  'authors': ['William W. Cohen',\n",
       "   'Ruslan Salakhutdinov',\n",
       "   'Zhilin Yang',\n",
       "   'Zihang Dai',\n",
       "   'Fan Yang'],\n",
       "  'published': '2017-05-27T07:53:53Z',\n",
       "  'updated': '2017-11-03T17:18:43Z',\n",
       "  'abstract': 'Semi-supervised learning methods based on generative adversarial networks(GANs) obtained strong empirical results, but it is not clear 1) how thediscriminator benefits from joint training with a generator, and 2) why goodsemi-supervised classification performance and a good generator cannot beobtained at the same time. Theoretically, we show that given the discriminatorobjective, good semisupervised learning indeed requires a bad generator, andpropose the definition of a preferred generator. Empirically, we derive a novelformulation based on our analysis that substantially improves over featurematching GANs, obtaining state-of-the-art results on multiple benchmarkdatasets.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '221',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.09783v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9678350544464313908&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 24: {'ID': 24,\n",
       "  'title': 'Matrix Completion has No Spurious Local Minimum',\n",
       "  'authors': ['Jason D. Lee', 'Rong Ge', 'Tengyu Ma'],\n",
       "  'published': '2016-05-24T02:53:27Z',\n",
       "  'updated': '2018-07-22T05:20:12Z',\n",
       "  'abstract': 'Matrix completion is a basic machine learning problem that has wideapplications, especially in collaborative filtering and recommender systems.Simple non-convex optimization algorithms are popular and effective inpractice. Despite recent progress in proving various non-convex algorithmsconverge from a good initial point, it remains unclear why random or arbitraryinitialization suffices in practice. We prove that the commonly used non-convexobjective function for \\\\textit{positive semidefinite} matrix completion has nospurious local minima --- all local minima must also be global. Therefore, manypopular optimization algorithms such as (stochastic) gradient descent canprovably solve positive semidefinite matrix completion with \\\\textit{arbitrary}initialization in polynomial time. The result can be generalized to the settingwhen the observed entries contain noise. We believe that our main proofstrategy can be useful for understanding geometric properties of otherstatistical problems involving partial or noisy observations.',\n",
       "  'categories': ['cs.LG', 'cs.DS', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '399',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07272v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14724299708943701856&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 25: {'ID': 25,\n",
       "  'title': 'How Powerful are Graph Neural Networks?',\n",
       "  'authors': ['Jure Leskovec', 'Stefanie Jegelka', 'Keyulu Xu', 'Weihua Hu'],\n",
       "  'published': '2018-10-01T17:11:31Z',\n",
       "  'updated': '2019-02-22T19:15:54Z',\n",
       "  'abstract': 'Graph Neural Networks (GNNs) are an effective framework for representationlearning of graphs. GNNs follow a neighborhood aggregation scheme, where therepresentation vector of a node is computed by recursively aggregating andtransforming representation vectors of its neighboring nodes. Many GNN variantshave been proposed and have achieved state-of-the-art results on both node andgraph classification tasks. However, despite GNNs revolutionizing graphrepresentation learning, there is limited understanding of theirrepresentational properties and limitations. Here, we present a theoreticalframework for analyzing the expressive power of GNNs to capture different graphstructures. Our results characterize the discriminative power of popular GNNvariants, such as Graph Convolutional Networks and GraphSAGE, and show thatthey cannot learn to distinguish certain simple graph structures. We thendevelop a simple architecture that is provably the most expressive among theclass of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphismtest. We empirically validate our theoretical findings on a number of graphclassification benchmarks, and demonstrate that our model achievesstate-of-the-art performance.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '523',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.00826v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9955904491400591671&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 26: {'ID': 26,\n",
       "  'title': 'Are GANs Created Equal? A Large-Scale Study',\n",
       "  'authors': ['Karol Kurach',\n",
       "   'Sylvain Gelly',\n",
       "   'Olivier Bousquet',\n",
       "   'Marcin Michalski',\n",
       "   'Mario Lucic'],\n",
       "  'published': '2017-11-28T15:19:53Z',\n",
       "  'updated': '2018-10-29T15:34:15Z',\n",
       "  'abstract': 'Generative adversarial networks (GAN) are a powerful subclass of generativemodels. Despite a very rich research activity leading to numerous interestingGAN algorithms, it is still very hard to assess which algorithm(s) performbetter than others. We conduct a neutral, multi-faceted large-scale empiricalstudy on state-of-the art models and evaluation measures. We find that mostmodels can reach similar scores with enough hyperparameter optimization andrandom restarts. This suggests that improvements can arise from a highercomputational budget and tuning more than fundamental algorithmic changes. Toovercome some limitations of the current metrics, we also propose several datasets on which precision and recall can be computed. Our experimental resultssuggest that future GAN research should be based on more systematic andobjective evaluation procedures. Finally, we did not find evidence that any ofthe tested algorithms consistently outperforms the non-saturating GANintroduced in \\\\cite{goodfellow2014generative}.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '363',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.10337v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3229217754457345915&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 27: {'ID': 27,\n",
       "  'title': 'Decomposing Motion and Content for Natural Video Sequence Prediction',\n",
       "  'authors': ['Ruben Villegas',\n",
       "   'Xunyu Lin',\n",
       "   'Seunghoon Hong',\n",
       "   'Jimei Yang',\n",
       "   'Honglak Lee'],\n",
       "  'published': '2017-06-25T04:18:12Z',\n",
       "  'updated': '2018-01-08T01:21:32Z',\n",
       "  'abstract': 'We propose a deep neural network for the prediction of future frames innatural video sequences. To effectively handle complex evolution of pixels invideos, we propose to decompose the motion and content, two key componentsgenerating dynamics in videos. Our model is built upon the Encoder-DecoderConvolutional Neural Network and Convolutional LSTM for pixel-level prediction,which independently capture the spatial layout of an image and thecorresponding temporal dynamics. By independently modeling motion and content,predicting the next frame reduces to converting the extracted content featuresinto the next frame content by the identified motion features, which simplifiesthe task of prediction. Our model is end-to-end trainable over multiple timesteps, and naturally learns to decompose motion and content without separatetraining. We evaluate the proposed network architecture on human activityvideos using KTH, Weizmann action, and UCF-101 datasets. We showstate-of-the-art performance in comparison to recent approaches. To the best ofour knowledge, this is the first end-to-end trainable network architecture withmotion and content separation to model the spatiotemporal dynamics forpixel-level future prediction in natural videos.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '252',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.08033v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10892353807026411567&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 28: {'ID': 28,\n",
       "  'title': 'Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to  Action Sequences',\n",
       "  'authors': ['Matthew R. Walter', 'Mohit Bansal', 'Hongyuan Mei'],\n",
       "  'published': '2015-06-12T18:05:00Z',\n",
       "  'updated': '2015-12-17T17:57:42Z',\n",
       "  'abstract': 'We propose a neural sequence-to-sequence model for direction following, atask that is essential to realizing effective autonomous agents. Ouralignment-based encoder-decoder model with long short-term memory recurrentneural networks (LSTM-RNN) translates natural language instructions to actionsequences based upon a representation of the observable world state. Weintroduce a multi-level aligner that empowers our model to focus on sentence\"regions\" salient to the current world state by using multiple abstractions ofthe input sentence. In contrast to existing methods, our model uses nospecialized linguistic resources (e.g., parsers) or task-specific annotations(e.g., seed lexicons). It is therefore generalizable, yet still achieves thebest results reported to-date on a benchmark single-sentence dataset andcompetitive results for the limited-training multi-sentence setting. We analyzeour model through a series of ablations that elucidate the contributions of theprimary components of our model.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE', 'cs.RO'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '135',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.04089v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14897263214206352510&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 29: {'ID': 29,\n",
       "  'title': 'Rainbow: Combining Improvements in Deep Reinforcement Learning',\n",
       "  'authors': ['Hado van Hasselt',\n",
       "   'Matteo Hessel',\n",
       "   'Bilal Piot',\n",
       "   'Georg Ostrovski',\n",
       "   'Tom Schaul',\n",
       "   'Dan Horgan',\n",
       "   'David Silver',\n",
       "   'Mohammad Azar',\n",
       "   'Joseph Modayil',\n",
       "   'Will Dabney'],\n",
       "  'published': '2017-10-06T07:45:46Z',\n",
       "  'updated': '2017-10-06T07:45:46Z',\n",
       "  'abstract': 'The deep reinforcement learning community has made several independentimprovements to the DQN algorithm. However, it is unclear which of theseextensions are complementary and can be fruitfully combined. This paperexamines six extensions to the DQN algorithm and empirically studies theircombination. Our experiments show that the combination providesstate-of-the-art performance on the Atari 2600 benchmark, both in terms of dataefficiency and final performance. We also provide results from a detailedablation study that shows the contribution of each component to overallperformance.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '570',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.02298v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4556984714514611653&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 30: {'ID': 30,\n",
       "  'title': 'Efficient Neural Audio Synthesis',\n",
       "  'authors': ['Nal Kalchbrenner',\n",
       "   'Edward Lockhart',\n",
       "   'Aaron van den Oord',\n",
       "   'Norman Casagrande',\n",
       "   'Florian Stimberg',\n",
       "   'Karen Simonyan',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Seb Noury',\n",
       "   'Sander Dieleman',\n",
       "   'Erich Elsen'],\n",
       "  'published': '2018-02-23T08:20:23Z',\n",
       "  'updated': '2018-06-25T19:45:25Z',\n",
       "  'abstract': 'Sequential models achieve state-of-the-art results in audio, visual andtextual domains with respect to both estimating the data distribution andgenerating high-quality samples. Efficient sampling for this class of modelshas however remained an elusive problem. With a focus on text-to-speechsynthesis, we describe a set of general techniques for reducing sampling timewhile maintaining high output quality. We first describe a single-layerrecurrent neural network, the WaveRNN, with a dual softmax layer that matchesthe quality of the state-of-the-art WaveNet model. The compact form of thenetwork makes it possible to generate 24kHz 16-bit audio 4x faster than realtime on a GPU. Second, we apply a weight pruning technique to reduce the numberof weights in the WaveRNN. We find that, for a constant number of parameters,large sparse networks perform better than small dense networks and thisrelationship holds for sparsity levels beyond 96%. The small number of weightsin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobileCPU in real time. Finally, we propose a new generation scheme based onsubscaling that folds a long sequence into a batch of shorter sequences andallows one to generate multiple samples at once. The Subscale WaveRNN produces16 samples per step without loss of quality and offers an orthogonal method forincreasing sampling efficiency.',\n",
       "  'categories': ['cs.SD', 'cs.LG', 'eess.AS'],\n",
       "  'journal': 'ICML, 2415-2424',\n",
       "  'citations': '189',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.08435v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14599728628710698803&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 31: {'ID': 31,\n",
       "  'title': 'Stronger generalization bounds for deep nets via a compression approach',\n",
       "  'authors': ['Yi Zhang', 'Rong Ge', 'Behnam Neyshabur', 'Sanjeev Arora'],\n",
       "  'published': '2018-02-14T19:38:07Z',\n",
       "  'updated': '2018-11-26T19:31:00Z',\n",
       "  'abstract': \"Deep nets generalize well despite having more parameters than the number oftraining samples. Recent works try to give an explanation using PAC-Bayes andMargin-based analyses, but do not as yet result in sample complexity boundsbetter than naive parameter counting. The current paper shows generalizationbounds that're orders of magnitude better in practice. These rely upon newsuccinct reparametrizations of the trained net --- a compression that isexplicit and efficient. These yield generalization bounds via a simplecompression-based framework introduced here. Our results also provide sometheoretical justification for widespread empirical success in compressing deepnets. Analysis of correctness of our compression relies upon some newlyidentified \\\\textquotedblleft noise stability\\\\textquotedblright properties oftrained deep nets, which are also experimentally verified. The study of theseproperties and resulting generalization bounds are also extended toconvolutional nets, which had eluded earlier attempts on provinggeneralization.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 254-263',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.05296v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2741843082009546935&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 32: {'ID': 32,\n",
       "  'title': 'Constructing the L2-Graph for Robust Subspace Learning and Subspace  Clustering',\n",
       "  'authors': ['Zhiding Yu', 'Huajin Tang', 'Zhang Yi', 'Xi Peng'],\n",
       "  'published': '2012-09-05T01:36:11Z',\n",
       "  'updated': '2015-01-17T12:00:47Z',\n",
       "  'abstract': 'Under the framework of graph-based learning, the key to robust subspaceclustering and subspace learning is to obtain a good similarity graph thateliminates the effects of errors and retains only connections between the datapoints from the same subspace (i.e., intra-subspace data points). Recent worksachieve good performance by modeling errors into their objective functions toremove the errors from the inputs. However, these approaches face thelimitations that the structure of errors should be known prior and a complexconvex problem must be solved. In this paper, we present a novel method toeliminate the effects of the errors from the projection space (representation)rather than from the input space. We first prove that $\\\\ell_1$-, $\\\\ell_2$-,$\\\\ell_{\\\\infty}$-, and nuclear-norm based linear projection spaces share theproperty of Intra-subspace Projection Dominance (IPD), i.e., the coefficientsover intra-subspace data points are larger than those over inter-subspace datapoints. Based on this property, we introduce a method to construct a sparsesimilarity graph, called L2-Graph. The subspace clustering and subspacelearning algorithms are developed upon L2-Graph. Experiments show that L2-Graphalgorithms outperform the state-of-the-art methods for feature extraction,image clustering, and motion segmentation in terms of accuracy, robustness, andtime efficiency.',\n",
       "  'categories': ['cs.CV', 'cs.MM'],\n",
       "  'journal': 'IEEE Transactions on Cybernetics 47 (4), 1053-1066',\n",
       "  'citations': '126',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1209.0841v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12238625670556584082&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 33: {'ID': 33,\n",
       "  'title': 'Parameter Space Noise for Exploration',\n",
       "  'authors': ['Marcin Andrychowicz',\n",
       "   'Szymon Sidor',\n",
       "   'Rein Houthooft',\n",
       "   'Tamim Asfour',\n",
       "   'Xi Chen',\n",
       "   'Matthias Plappert',\n",
       "   'Prafulla Dhariwal',\n",
       "   'Richard Y. Chen',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-06-06T18:09:29Z',\n",
       "  'updated': '2018-01-31T09:05:10Z',\n",
       "  'abstract': \"Deep reinforcement learning (RL) methods generally engage in exploratorybehavior through noise injection in the action space. An alternative is to addnoise directly to the agent's parameters, which can lead to more consistentexploration and a richer set of behaviors. Methods such as evolutionarystrategies use parameter perturbations, but discard all temporal structure inthe process and require significantly more samples. Combining parameter noisewith traditional RL methods allows to combine the best of both worlds. Wedemonstrate that both off- and on-policy methods benefit from this approachthrough experimental comparison of DQN, DDPG, and TRPO on high-dimensionaldiscrete action environments as well as continuous control tasks. Our resultsshow that RL with parameter noise learns more efficiently than traditional RLwith action space noise and evolutionary strategies individually.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE', 'cs.RO', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '273',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.01905v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5517640716015156114&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 34: {'ID': 34,\n",
       "  'title': 'Text Matching as Image Recognition',\n",
       "  'authors': ['Jun Xu',\n",
       "   'Xueqi Cheng',\n",
       "   'Jiafeng Guo',\n",
       "   'Shengxian Wan',\n",
       "   'Yanyan Lan',\n",
       "   'Liang Pang'],\n",
       "  'published': '2016-02-20T02:55:11Z',\n",
       "  'updated': '2016-02-20T02:55:11Z',\n",
       "  'abstract': 'Matching two texts is a fundamental problem in many natural languageprocessing tasks. An effective way is to extract meaningful matching patternsfrom words, phrases, and sentences to produce the matching score. Inspired bythe success of convolutional neural network in image recognition, where neuronscan capture many complicated patterns based on the extracted elementary visualpatterns such as oriented edges and corners, we propose to model text matchingas the problem of image recognition. Firstly, a matching matrix whose entriesrepresent the similarities between words is constructed and viewed as an image.Then a convolutional neural network is utilized to capture rich matchingpatterns in a layer-by-layer way. We show that by resembling the compositionalhierarchies of patterns in image recognition, our model can successfullyidentify salient signals such as n-gram and n-term matchings. Experimentalresults demonstrate its superiority against the baselines.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\\xa0…',\n",
       "  'citations': '245',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.06359v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2007424235086924671&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 35: {'ID': 35,\n",
       "  'title': 'Reasoning about Entailment with Neural Attention',\n",
       "  'authors': ['Tim Rocktäschel',\n",
       "   'Tomáš Kočiský',\n",
       "   'Edward Grefenstette',\n",
       "   'Karl Moritz Hermann',\n",
       "   'Phil Blunsom'],\n",
       "  'published': '2015-09-22T16:08:24Z',\n",
       "  'updated': '2016-03-01T10:32:06Z',\n",
       "  'abstract': 'While most approaches to automatically recognizing entailment relations haveused classifiers employing hand engineered features derived from complexnatural language processing pipelines, in practice their performance has beenonly slightly better than bag-of-word pair classifiers using only lexicalsimilarity. The only attempt so far to build an end-to-end differentiableneural network for entailment failed to outperform such a simple similarityclassifier. In this paper, we propose a neural model that reads two sentencesto determine entailment using long short-term memory units. We extend thismodel with a word-by-word neural attention mechanism that encourages reasoningover entailments of pairs of words and phrases. Furthermore, we present aqualitative analysis of attention weights produced by this model, demonstratingsuch reasoning capabilities. On a large entailment dataset this modeloutperforms the previous best neural model and a classifier with engineeredfeatures by a substantial margin. It is the first generic end-to-enddifferentiable system that achieves state-of-the-art accuracy on a textualentailment dataset.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE', '68T50', 'I.2.6; I.2.7'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '582',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.06664v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11797670977640238669&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 36: {'ID': 36,\n",
       "  'title': 'Visual Instance Retrieval with Deep Convolutional Networks',\n",
       "  'authors': ['Ali Sharif Razavian',\n",
       "   'Stefan Carlsson',\n",
       "   'Atsuto Maki',\n",
       "   'Josephine Sullivan'],\n",
       "  'published': '2014-12-20T01:32:43Z',\n",
       "  'updated': '2016-05-09T08:54:31Z',\n",
       "  'abstract': 'This paper provides an extensive study on the availability of imagerepresentations based on convolutional networks (ConvNets) for the task ofvisual instance retrieval. Besides the choice of convolutional layers, wepresent an efficient pipeline exploiting multi-scale schemes to extract localfeatures, in particular, by taking geometric invariance into explicit account,i.e. positions, scales and spatial consistency. In our experiments using fivestandard image retrieval datasets, we demonstrate that generic ConvNet imagerepresentations can outperform other state-of-the-art methods if they areextracted appropriately.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '306',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6574v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15265580461229792889&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 37: {'ID': 37,\n",
       "  'title': 'Supervised learning based on temporal coding in spiking neural networks',\n",
       "  'authors': ['Hesham Mostafa'],\n",
       "  'published': '2016-06-27T08:58:29Z',\n",
       "  'updated': '2017-08-16T16:15:20Z',\n",
       "  'abstract': 'Gradient descent training techniques are remarkably successful in traininganalog-valued artificial neural networks (ANNs). Such training techniques,however, do not transfer easily to spiking networks due to the spike generationhard non-linearity and the discrete nature of spike communication. We show thatin a feedforward spiking network that uses a temporal coding scheme whereinformation is encoded in spike times instead of spike rates, the networkinput-output relation is differentiable almost everywhere. Moreover, thisrelation is piece-wise linear after a transformation of variables. Methods fortraining ANNs thus carry directly to the training of such spiking networks aswe show when training on the permutation invariant MNIST task. In contrast torate-based spiking networks that are often used to approximate the behavior ofANNs, the networks we present spike much more sparsely and their behavior cannot be directly approximated by conventional ANNs. Our results highlight a newapproach for controlling the behavior of spiking networks with realistictemporal dynamics, opening up the potential for using these networks to processspike patterns with complex temporal information.',\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (7), 3227-3235',\n",
       "  'citations': '112',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.08165v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11642829514204190384&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 38: {'ID': 38,\n",
       "  'title': 'Character-level Convolutional Networks for Text Classification',\n",
       "  'authors': ['Yann LeCun', 'Xiang Zhang', 'Junbo Zhao'],\n",
       "  'published': '2015-09-04T22:31:53Z',\n",
       "  'updated': '2016-04-04T02:34:30Z',\n",
       "  'abstract': 'This article offers an empirical exploration on the use of character-levelconvolutional networks (ConvNets) for text classification. We constructedseveral large-scale datasets to show that character-level convolutionalnetworks could achieve state-of-the-art or competitive results. Comparisons areoffered against traditional models such as bag of words, n-grams and theirTFIDF variants, and deep learning models such as word-based ConvNets andrecurrent neural networks.',\n",
       "  'categories': ['cs.LG', 'cs.CL'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '2294',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.01626v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5819400392657163601&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 39: {'ID': 39,\n",
       "  'title': 'Gradient Estimation Using Stochastic Computation Graphs',\n",
       "  'authors': ['Pieter Abbeel',\n",
       "   'John Schulman',\n",
       "   'Nicolas Heess',\n",
       "   'Theophane Weber'],\n",
       "  'published': '2015-06-17T09:32:31Z',\n",
       "  'updated': '2016-01-05T19:56:22Z',\n",
       "  'abstract': \"In a variety of problems originating in supervised, unsupervised, andreinforcement learning, the loss function is defined by an expectation over acollection of random variables, which might be part of a probabilistic model orthe external world. Estimating the gradient of this loss function, usingsamples, lies at the core of gradient-based learning algorithms for theseproblems. We introduce the formalism of stochastic computationgraphs---directed acyclic graphs that include both deterministic functions andconditional probability distributions---and describe how to easily andautomatically derive an unbiased estimator of the loss function's gradient. Theresulting algorithm for computing the gradient estimator is a simplemodification of the standard backpropagation algorithm. The generic scheme wepropose unifies estimators derived in variety of prior work, along withvariance-reduction techniques therein. It could assist researchers indeveloping intricate models involving a combination of stochastic anddeterministic operations, enabling, for example, attention, memory, and controlactions.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '226',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.05254v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8425134619086007830&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 40: {'ID': 40,\n",
       "  'title': 'Deep reinforcement learning from human preferences',\n",
       "  'authors': ['Dario Amodei',\n",
       "   'Paul Christiano',\n",
       "   'Tom B. Brown',\n",
       "   'Shane Legg',\n",
       "   'Miljan Martic',\n",
       "   'Jan Leike'],\n",
       "  'published': '2017-06-12T17:23:59Z',\n",
       "  'updated': '2017-07-13T20:18:41Z',\n",
       "  'abstract': \"For sophisticated reinforcement learning (RL) systems to interact usefullywith real-world environments, we need to communicate complex goals to thesesystems. In this work, we explore goals defined in terms of (non-expert) humanpreferences between pairs of trajectory segments. We show that this approachcan effectively solve complex RL tasks without access to the reward function,including Atari games and simulated robot locomotion, while providing feedbackon less than one percent of our agent's interactions with the environment. Thisreduces the cost of human oversight far enough that it can be practicallyapplied to state-of-the-art RL systems. To demonstrate the flexibility of ourapproach, we show that we can successfully train complex novel behaviors withabout an hour of human time. These behaviors and environments are considerablymore complex than any that have been previously learned from human feedback.\",\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.HC', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '296',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.03741v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16666410803638838470&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 41: {'ID': 41,\n",
       "  'title': 'Spatiotemporal Residual Networks for Video Action Recognition',\n",
       "  'authors': ['Axel Pinz', 'Christoph Feichtenhofer', 'Richard P. Wildes'],\n",
       "  'published': '2016-11-07T16:17:16Z',\n",
       "  'updated': '2016-11-07T16:17:16Z',\n",
       "  'abstract': 'Two-stream Convolutional Networks (ConvNets) have shown strong performancefor human action recognition in videos. Recently, Residual Networks (ResNets)have arisen as a new technique to train extremely deep architectures. In thispaper, we introduce spatiotemporal ResNets as a combination of these twoapproaches. Our novel architecture generalizes ResNets for the spatiotemporaldomain by introducing residual connections in two ways. First, we injectresidual connections between the appearance and motion pathways of a two-streamarchitecture to allow spatiotemporal interaction between the two streams.Second, we transform pretrained image ConvNets into spatiotemporal networks byequipping these with learnable convolutional filters that are initialized astemporal residual connections and operate on adjacent feature maps in time.This approach slowly increases the spatiotemporal receptive field as the depthof the model increases and naturally integrates image ConvNet designprinciples. The whole model is trained end-to-end to allow hierarchicallearning of complex spatiotemporal features. We evaluate our novelspatiotemporal ResNet using two widely used action recognition benchmarks whereit exceeds the previous state-of-the-art.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '546',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02155v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17812047066454194940&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 42: {'ID': 42,\n",
       "  'title': 'Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks',\n",
       "  'authors': ['Chelsea Finn', 'Sergey Levine', 'Pieter Abbeel'],\n",
       "  'published': '2017-03-09T18:58:03Z',\n",
       "  'updated': '2017-07-18T16:45:29Z',\n",
       "  'abstract': 'We propose an algorithm for meta-learning that is model-agnostic, in thesense that it is compatible with any model trained with gradient descent andapplicable to a variety of different learning problems, includingclassification, regression, and reinforcement learning. The goal ofmeta-learning is to train a model on a variety of learning tasks, such that itcan solve new learning tasks using only a small number of training samples. Inour approach, the parameters of the model are explicitly trained such that asmall number of gradient steps with a small amount of training data from a newtask will produce good generalization performance on that task. In effect, ourmethod trains the model to be easy to fine-tune. We demonstrate that thisapproach leads to state-of-the-art performance on two few-shot imageclassification benchmarks, produces good results on few-shot regression, andaccelerates fine-tuning for policy gradient reinforcement learning with neuralnetwork policies.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICML, 1126-1135',\n",
       "  'citations': '1834',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.03400v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17278604844873996878&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 43: {'ID': 43,\n",
       "  'title': 'Neural Architecture Search with Reinforcement Learning',\n",
       "  'authors': ['Quoc V. Le', 'Barret Zoph'],\n",
       "  'published': '2016-11-05T00:41:37Z',\n",
       "  'updated': '2017-02-15T05:28:05Z',\n",
       "  'abstract': 'Neural networks are powerful and flexible models that work well for manydifficult learning tasks in image, speech and natural language understanding.Despite their success, neural networks are still hard to design. In this paper,we use a recurrent network to generate the model descriptions of neuralnetworks and train this RNN with reinforcement learning to maximize theexpected accuracy of the generated architectures on a validation set. On theCIFAR-10 dataset, our method, starting from scratch, can design a novel networkarchitecture that rivals the best human-invented architecture in terms of testset accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is0.09 percent better and 1.05x faster than the previous state-of-the-art modelthat used a similar architectural scheme. On the Penn Treebank dataset, ourmodel can compose a novel recurrent cell that outperforms the widely-used LSTMcell, and other state-of-the-art baselines. Our cell achieves a test setperplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better thanthe previous state-of-the-art model. The cell can also be transferred to thecharacter language modeling task on PTB and achieves a state-of-the-artperplexity of 1.214.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '1657',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01578v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4164896773666247762&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 44: {'ID': 44,\n",
       "  'title': 'Mitigating Adversarial Effects Through Randomization',\n",
       "  'authors': ['Alan Yuille',\n",
       "   'Cihang Xie',\n",
       "   'Zhishuai Zhang',\n",
       "   'Jianyu Wang',\n",
       "   'Zhou Ren'],\n",
       "  'published': '2017-11-06T16:22:54Z',\n",
       "  'updated': '2018-02-28T22:39:15Z',\n",
       "  'abstract': 'Convolutional neural networks have demonstrated high accuracy on varioustasks in recent years. However, they are extremely vulnerable to adversarialexamples. For example, imperceptible perturbations added to clean images cancause convolutional neural networks to fail. In this paper, we propose toutilize randomization at inference time to mitigate adversarial effects.Specifically, we use two randomization operations: random resizing, whichresizes the input images to a random size, and random padding, which pads zerosaround the input images in a random manner. Extensive experiments demonstratethat the proposed randomization method is very effective at defending againstboth single-step and iterative attacks. Our method provides the followingadvantages: 1) no additional training or fine-tuning, 2) very few additionalcomputations, 3) compatible with other adversarial defense methods. Bycombining the proposed randomization method with an adversarially trainedmodel, it achieves a normalized score of 0.924 (ranked No.2 among 107 defenseteams) in the NIPS 2017 adversarial examples defense challenge, which is farbetter than using adversarial training alone with a normalized score of 0.773(ranked No.56). The code is public available athttps://github.com/cihangxie/NIPS2017_adv_challenge_defense.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '292',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.01991v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1119418123159333221&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 45: {'ID': 45,\n",
       "  'title': 'Adversarially Robust Generalization Requires More Data',\n",
       "  'authors': ['Dimitris Tsipras',\n",
       "   'Kunal Talwar',\n",
       "   'Shibani Santurkar',\n",
       "   'Aleksander Mądry',\n",
       "   'Ludwig Schmidt'],\n",
       "  'published': '2018-04-30T15:55:59Z',\n",
       "  'updated': '2018-05-02T05:24:33Z',\n",
       "  'abstract': 'Machine learning models are often susceptible to adversarial perturbations oftheir inputs. Even small perturbations can cause state-of-the-art classifierswith high \"standard\" accuracy to produce an incorrect prediction with highconfidence. To better understand this phenomenon, we study adversarially robustlearning from the viewpoint of generalization. We show that already in a simplenatural data model, the sample complexity of robust learning can besignificantly larger than that of \"standard\" learning. This gap is informationtheoretic and holds irrespective of the training algorithm or the model family.We complement our theoretical results with experiments on popular imageclassification datasets and show that a similar gap exists here as well. Wepostulate that the difficulty of training robust classifiers stems, at leastpartially, from this inherently larger sample complexity.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.11285v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11617408739335906297&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 46: {'ID': 46,\n",
       "  'title': 'Deep Reinforcement Learning in a Handful of Trials using Probabilistic  Dynamics Models',\n",
       "  'authors': ['Rowan McAllister',\n",
       "   'Kurtland Chua',\n",
       "   'Roberto Calandra',\n",
       "   'Sergey Levine'],\n",
       "  'published': '2018-05-30T17:55:21Z',\n",
       "  'updated': '2018-11-02T17:19:02Z',\n",
       "  'abstract': 'Model-based reinforcement learning (RL) algorithms can attain excellentsample efficiency, but often lag behind the best model-free algorithms in termsof asymptotic performance. This is especially true with high-capacityparametric function approximators, such as deep networks. In this paper, westudy how to bridge this gap, by employing uncertainty-aware dynamics models.We propose a new algorithm called probabilistic ensembles with trajectorysampling (PETS) that combines uncertainty-aware deep network dynamics modelswith sampling-based uncertainty propagation. Our comparison to state-of-the-artmodel-based and model-free deep RL algorithms shows that our approach matchesthe asymptotic performance of model-free algorithms on several challengingbenchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125times fewer samples than Soft Actor Critic and Proximal Policy Optimizationrespectively on the half-cheetah task).',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '208',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.12114v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6248399848380977147&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 47: {'ID': 47,\n",
       "  'title': 'Online Tracking by Learning Discriminative Saliency Map with  Convolutional Neural Network',\n",
       "  'authors': ['Tackgeun You', 'Bohyung Han', 'Suha Kwak', 'Seunghoon Hong'],\n",
       "  'published': '2015-02-24T13:10:32Z',\n",
       "  'updated': '2015-02-24T13:10:32Z',\n",
       "  'abstract': 'We propose an online visual tracking algorithm by learning discriminativesaliency map using Convolutional Neural Network (CNN). Given a CNN pre-trainedon a large-scale image repository in offline, our algorithm takes outputs fromhidden layers of the network as feature descriptors since they show excellentrepresentation performance in various general visual recognition problems. Thefeatures are used to learn discriminative target appearance models using anonline Support Vector Machine (SVM). In addition, we construct target-specificsaliency map by backpropagating CNN features with guidance of the SVM, andobtain the final tracking result in each frame based on the appearance modelgeneratively constructed with the saliency map. Since the saliency mapvisualizes spatial configuration of target effectively, it improves targetlocalization accuracy and enable us to achieve pixel-level target segmentation.We verify the effectiveness of our tracking algorithm through extensiveexperiment on a challenging benchmark, where our method illustrates outstandingperformance compared to the state-of-the-art tracking algorithms.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 597-606',\n",
       "  'citations': '586',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.06796v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8452657516733607725&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 48: {'ID': 48,\n",
       "  'title': 'Hadamard Product for Low-rank Bilinear Pooling',\n",
       "  'authors': ['Kyoung-Woon On',\n",
       "   'Jung-Woo Ha',\n",
       "   'Jin-Hwa Kim',\n",
       "   'Woosang Lim',\n",
       "   'Jeonghee Kim',\n",
       "   'Byoung-Tak Zhang'],\n",
       "  'published': '2016-10-14T04:29:52Z',\n",
       "  'updated': '2017-03-26T16:22:47Z',\n",
       "  'abstract': 'Bilinear models provide rich representations compared with linear models.They have been applied in various visual tasks, such as object recognition,segmentation, and visual question-answering, to get state-of-the-artperformances taking advantage of the expanded representations. However,bilinear representations tend to be high-dimensional, limiting theapplicability to computationally complex tasks. We propose low-rank bilinearpooling using Hadamard product for an efficient attention mechanism ofmultimodal learning. We show that our model outperforms compact bilinearpooling in visual question-answering tasks with the state-of-the-art results onthe VQA dataset, having a better parsimonious property.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '280',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.04325v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11247536386590839195&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 49: {'ID': 49,\n",
       "  'title': 'Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on  ImageNet',\n",
       "  'authors': ['Matthias Kümmerer', 'Lucas Theis', 'Matthias Bethge'],\n",
       "  'published': '2014-11-04T20:56:51Z',\n",
       "  'updated': '2015-04-09T09:48:11Z',\n",
       "  'abstract': 'Recent results suggest that state-of-the-art saliency models perform far fromoptimal in predicting fixations. This lack in performance has been attributedto an inability to model the influence of high-level image features such asobjects. Recent seminal advances in applying deep neural networks to tasks likeobject recognition suggests that they are able to capture this kind ofstructure. However, the enormous amount of training data necessary to trainthese networks makes them difficult to apply directly to saliency prediction.We present a novel way of reusing existing neural networks that have beenpretrained on the task of object recognition in models of fixation prediction.Using the well-known network of Krizhevsky et al. (2012), we come up with a newsaliency model that significantly outperforms all state-of-the-art models onthe MIT Saliency Benchmark. We show that the structure of this network allowsnew insights in the psychophysics of fixation selection and potentially theirneural implementation. To train our network, we build on recent work on themodeling of saliency as point processes.',\n",
       "  'categories': ['cs.CV', 'q-bio.NC', 'stat.AP'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '273',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1411.1045v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4166856723638300289&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 50: {'ID': 50,\n",
       "  'title': 'Show, Attend and Tell: Neural Image Caption Generation with Visual  Attention',\n",
       "  'authors': ['Kyunghyun Cho',\n",
       "   'Ruslan Salakhutdinov',\n",
       "   'Aaron Courville',\n",
       "   'Jimmy Ba',\n",
       "   'Kelvin Xu',\n",
       "   'Ryan Kiros',\n",
       "   'Richard Zemel',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2015-02-10T19:18:29Z',\n",
       "  'updated': '2016-04-19T16:43:09Z',\n",
       "  'abstract': 'Inspired by recent work in machine translation and object detection, weintroduce an attention based model that automatically learns to describe thecontent of images. We describe how we can train this model in a deterministicmanner using standard backpropagation techniques and stochastically bymaximizing a variational lower bound. We also show through visualization howthe model is able to automatically learn to fix its gaze on salient objectswhile generating the corresponding words in the output sequence. We validatethe use of attention with state-of-the-art performance on three benchmarkdatasets: Flickr8k, Flickr30k and MS COCO.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICML, 2048-2057',\n",
       "  'citations': '5300',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.03044v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9471583366007765258&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 51: {'ID': 51,\n",
       "  'title': 'A Knowledge-Grounded Neural Conversation Model',\n",
       "  'authors': ['Chris Brockett',\n",
       "   'Michel Galley',\n",
       "   'Bill Dolan',\n",
       "   'Wen-tau Yih',\n",
       "   'Jianfeng Gao',\n",
       "   'Ming-Wei Chang',\n",
       "   'Marjan Ghazvininejad'],\n",
       "  'published': '2017-02-07T09:16:46Z',\n",
       "  'updated': '2018-11-15T19:04:48Z',\n",
       "  'abstract': 'Neural network models are capable of generating extremely natural soundingconversational interactions. Nevertheless, these models have yet to demonstratethat they can incorporate content in the form of factual information orentity-grounded opinion that would enable them to serve in more task-orientedconversational applications. This paper presents a novel, fully data-driven,and knowledge-grounded neural conversation model aimed at producing morecontentful responses without slot filling. We generalize the widely-usedSeq2Seq approach by conditioning responses on both conversation history andexternal \"facts\", allowing the model to be versatile and applicable in anopen-domain setting. Our approach yields significant improvements over acompetitive Seq2Seq baseline. Human judges found that our outputs aresignificantly more informative.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '212',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.01932v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10303927314409501955&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 52: {'ID': 52,\n",
       "  'title': 'EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial  Examples',\n",
       "  'authors': ['Huan Zhang',\n",
       "   'Pin-Yu Chen',\n",
       "   'Cho-Jui Hsieh',\n",
       "   'Yash Sharma',\n",
       "   'Jinfeng Yi'],\n",
       "  'published': '2017-09-13T02:40:59Z',\n",
       "  'updated': '2018-02-10T04:49:12Z',\n",
       "  'abstract': 'Recent studies have highlighted the vulnerability of deep neural networks(DNNs) to adversarial examples - a visually indistinguishable adversarial imagecan easily be crafted to cause a well-trained model to misclassify. Existingmethods for crafting adversarial examples are based on $L_2$ and $L_\\\\infty$distortion metrics. However, despite the fact that $L_1$ distortion accountsfor the total variation and encourages sparsity in the perturbation, little hasbeen developed for crafting $L_1$-based adversarial examples. In this paper, weformulate the process of attacking DNNs via adversarial examples as anelastic-net regularized optimization problem. Our elastic-net attacks to DNNs(EAD) feature $L_1$-oriented adversarial examples and include thestate-of-the-art $L_2$ attack as a special case. Experimental results on MNIST,CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarialexamples with small $L_1$ distortion and attains similar attack performance tothe state-of-the-art methods in different attack scenarios. More importantly,EAD leads to improved attack transferability and complements adversarialtraining for DNNs, suggesting novel insights on leveraging $L_1$ distortion inadversarial machine learning and security implications of DNNs.',\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '211',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.04114v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12822881129295839300&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 53: {'ID': 53,\n",
       "  'title': 'Qualitatively characterizing neural network optimization problems',\n",
       "  'authors': ['Oriol Vinyals', 'Andrew M. Saxe', 'Ian J. Goodfellow'],\n",
       "  'published': '2014-12-19T21:55:01Z',\n",
       "  'updated': '2015-05-21T21:44:31Z',\n",
       "  'abstract': 'Training neural networks involves solving large-scale non-convex optimizationproblems. This task has long been believed to be extremely difficult, with fearof local minima and other obstacles motivating a variety of schemes to improveoptimization, such as unsupervised pretraining. However, modern neural networksare able to achieve negligible training error on complex tasks, using onlydirect training with stochastic gradient descent. We introduce a simpleanalysis technique to look for evidence that such networks are overcoming localoptima. We find that, in fact, on a straight path from initialization tosolution, a variety of state of the art neural networks never encounter anysignificant obstacles.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '261',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6544v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11309177599523101036&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 54: {'ID': 54,\n",
       "  'title': 'Unsupervised Cross-Domain Image Generation',\n",
       "  'authors': ['Lior Wolf', 'Adam Polyak', 'Yaniv Taigman'],\n",
       "  'published': '2016-11-07T18:14:57Z',\n",
       "  'updated': '2016-11-07T18:14:57Z',\n",
       "  'abstract': 'We study the problem of transferring a sample in one domain to an analogsample in another domain. Given two related domains, S and T, we would like tolearn a generative function G that maps an input sample from S to the domain T,such that the output of a given function f, which accepts inputs in eitherdomains, would remain unchanged. Other than the function f, the training datais unsupervised and consist of a set of samples from each domain. The DomainTransfer Network (DTN) we present employs a compound loss function thatincludes a multiclass GAN loss, an f-constancy component, and a regularizingcomponent that encourages G to map samples from T to themselves. We apply ourmethod to visual domains including digits and face images and demonstrate itsability to generate convincing novel images of previously unseen entities,while preserving their identity.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '554',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02200v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1045007962742744076&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 55: {'ID': 55,\n",
       "  'title': 'Attention-based Deep Multiple Instance Learning',\n",
       "  'authors': ['Max Welling', 'Maximilian Ilse', 'Jakub M. Tomczak'],\n",
       "  'published': '2018-02-13T16:27:19Z',\n",
       "  'updated': '2018-06-28T13:33:03Z',\n",
       "  'abstract': 'Multiple instance learning (MIL) is a variation of supervised learning wherea single class label is assigned to a bag of instances. In this paper, we statethe MIL problem as learning the Bernoulli distribution of the bag label wherethe bag label probability is fully parameterized by neural networks.Furthermore, we propose a neural network-based permutation-invariantaggregation operator that corresponds to the attention mechanism. Notably, anapplication of the proposed attention-based operator provides insight into thecontribution of each instance to the bag label. We show empirically that ourapproach achieves comparable performance to the best MIL methods on benchmarkMIL datasets and it outperforms other methods on a MNIST-based MIL dataset andtwo real-life histopathology datasets without sacrificing interpretability.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2132-2141',\n",
       "  'citations': '175',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.04712v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10689360653942822671&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 56: {'ID': 56,\n",
       "  'title': 'Probabilistic Backpropagation for Scalable Learning of Bayesian Neural  Networks',\n",
       "  'authors': ['Ryan P. Adams', 'José Miguel Hernández-Lobato'],\n",
       "  'published': '2015-02-18T18:45:17Z',\n",
       "  'updated': '2015-07-15T10:14:49Z',\n",
       "  'abstract': 'Large multilayer neural networks trained with backpropagation have recentlyachieved state-of-the-art results in a wide range of problems. However, usingbackprop for neural net learning still has some disadvantages, e.g., having totune a large number of hyperparameters to the data, lack of calibratedprobabilistic predictions, and a tendency to overfit the training data. Inprinciple, the Bayesian approach to learning neural networks does not havethese problems. However, existing Bayesian techniques lack scalability to largedataset and network sizes. In this work we present a novel scalable method forlearning Bayesian neural networks, called probabilistic backpropagation (PBP).Similar to classical backpropagation, PBP works by computing a forwardpropagation of probabilities through the network and then doing a backwardcomputation of gradients. A series of experiments on ten real-world datasetsshow that PBP is significantly faster than other techniques, while offeringcompetitive predictive abilities. Our experiments also show that PBP providesaccurate estimates of the posterior variance on the network weights.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'ICML, 1861-1869',\n",
       "  'citations': '426',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.05336v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7631378507206910182&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 57: {'ID': 57,\n",
       "  'title': 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks',\n",
       "  'authors': ['Antoine Bordes',\n",
       "   'Armand Joulin',\n",
       "   'Jason Weston',\n",
       "   'Tomas Mikolov',\n",
       "   'Alexander M. Rush',\n",
       "   'Bart van Merriënboer',\n",
       "   'Sumit Chopra'],\n",
       "  'published': '2015-02-19T20:46:10Z',\n",
       "  'updated': '2015-12-31T13:08:14Z',\n",
       "  'abstract': 'One long-term goal of machine learning research is to produce methods thatare applicable to reasoning and natural language, in particular building anintelligent dialogue agent. To measure progress towards that goal, we argue forthe usefulness of a set of proxy tasks that evaluate reading comprehension viaquestion answering. Our tasks measure understanding in several ways: whether asystem is able to answer questions via chaining facts, simple induction,deduction and many more. The tasks are designed to be prerequisites for anysystem that aims to be capable of conversing with a human. We believe manyexisting learning systems can currently not solve them, and hence our aim is toclassify these tasks into skill sets, so that researchers can identify (andthen rectify) the failings of their systems. We also extend and improve therecently introduced Memory Networks model, and show it is able to solve some,but not all, of the tasks.',\n",
       "  'categories': ['cs.AI', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '746',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.05698v10',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=886478109396958527&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 58: {'ID': 58,\n",
       "  'title': 'Discriminative Embeddings of Latent Variable Models for Structured Data',\n",
       "  'authors': ['Bo Dai', 'Le Song', 'Hanjun Dai'],\n",
       "  'published': '2016-03-17T19:29:46Z',\n",
       "  'updated': '2020-01-11T03:00:02Z',\n",
       "  'abstract': 'Kernel classifiers and regressors designed for structured data, such assequences, trees and graphs, have significantly advanced a number ofinterdisciplinary areas such as computational biology and drug design.Typically, kernels are designed beforehand for a data type which either exploitstatistics of the structures or make use of probabilistic generative models,and then a discriminative classifier is learned based on the kernels via convexoptimization. However, such an elegant two-stage approach also limited kernelmethods from scaling up to millions of data points, and exploitingdiscriminative information to learn feature representations.  We propose, structure2vec, an effective and scalable approach for structureddata representation based on the idea of embedding latent variable models intofeature spaces, and learning such feature spaces using discriminativeinformation. Interestingly, structure2vec extracts features by performing asequence of function mappings in a way similar to graphical model inferenceprocedures, such as mean field and belief propagation. In applicationsinvolving millions of data points, we showed that structure2vec runs 2 timesfaster, produces models which are $10,000$ times smaller, while at the sametime achieving the state-of-the-art predictive performance.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 2702-2711',\n",
       "  'citations': '269',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.05629v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6328035502669651426&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 59: {'ID': 59,\n",
       "  'title': 'Learning Transferable Features with Deep Adaptation Networks',\n",
       "  'authors': ['Yue Cao',\n",
       "   'Jianmin Wang',\n",
       "   'Mingsheng Long',\n",
       "   'Michael I. Jordan'],\n",
       "  'published': '2015-02-10T06:01:30Z',\n",
       "  'updated': '2015-05-27T05:28:35Z',\n",
       "  'abstract': 'Recent studies reveal that a deep neural network can learn transferablefeatures which generalize well to novel tasks for domain adaptation. However,as deep features eventually transition from general to specific along thenetwork, the feature transferability drops significantly in higher layers withincreasing domain discrepancy. Hence, it is important to formally reduce thedataset bias and enhance the transferability in task-specific layers. In thispaper, we propose a new Deep Adaptation Network (DAN) architecture, whichgeneralizes deep convolutional neural network to the domain adaptationscenario. In DAN, hidden representations of all task-specific layers areembedded in a reproducing kernel Hilbert space where the mean embeddings ofdifferent domain distributions can be explicitly matched. The domaindiscrepancy is further reduced using an optimal multi-kernel selection methodfor mean embedding matching. DAN can learn transferable features withstatistical guarantees, and can scale linearly by unbiased estimate of kernelembedding. Extensive empirical evidence shows that the proposed architectureyields state-of-the-art image classification error rates on standard domainadaptation benchmarks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 97-105',\n",
       "  'citations': '1545',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02791v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10097353709258117195&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 60: {'ID': 60,\n",
       "  'title': 'Adaptive Graph Convolutional Neural Networks',\n",
       "  'authors': ['Junzhou Huang', 'Sheng Wang', 'Feiyun Zhu', 'Ruoyu Li'],\n",
       "  'published': '2018-01-10T03:17:45Z',\n",
       "  'updated': '2018-01-10T03:17:45Z',\n",
       "  'abstract': 'Graph Convolutional Neural Networks (Graph CNNs) are generalizations ofclassical CNNs to handle graph data such as molecular data, point could andsocial networks. Current filters in graph CNNs are built for fixed and sharedgraph structure. However, for most real data, the graph structures varies inboth size and connectivity. The paper proposes a generalized and flexible graphCNN taking data of arbitrary graph structure as input. In that way atask-driven adaptive graph is learned for each graph data while training. Toefficiently learn the graph, a distance metric learning is proposed. Extensiveexperiments on nine graph-structured datasets have demonstrated the superiorperformance improvement on both convergence speed and predictive accuracy.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '130',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.03226v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7918065976159007739&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 61: {'ID': 61,\n",
       "  'title': 'Understanding the Effective Receptive Field in Deep Convolutional Neural  Networks',\n",
       "  'authors': ['Yujia Li', 'Raquel Urtasun', 'Wenjie Luo', 'Richard Zemel'],\n",
       "  'published': '2017-01-15T23:52:49Z',\n",
       "  'updated': '2017-01-25T06:32:29Z',\n",
       "  'abstract': 'We study characteristics of receptive fields of units in deep convolutionalnetworks. The receptive field size is a crucial issue in many visual tasks, asthe output must respond to large enough areas in the image to captureinformation about large objects. We introduce the notion of an effectivereceptive field, and show that it both has a Gaussian distribution and onlyoccupies a fraction of the full theoretical receptive field. We analyze theeffective receptive field in several architecture designs, and the effect ofnonlinear activations, dropout, sub-sampling and skip connections on it. Thisleads to suggestions for ways to address its tendency to be too small.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '407',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.04128v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12122802369550112103&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 62: {'ID': 62,\n",
       "  'title': 'Learning a No-Reference Quality Assessment Model of Enhanced Images With  Big Data',\n",
       "  'authors': ['Dacheng Tao', 'Junfei Qiao', 'Ke Gu', 'Weisi Lin'],\n",
       "  'published': '2019-04-18T08:14:24Z',\n",
       "  'updated': '2019-04-18T08:14:24Z',\n",
       "  'abstract': 'In this paper we investigate into the problem of image quality assessment(IQA) and enhancement via machine learning. This issue has long attracted awide range of attention in computational intelligence and image processingcommunities, since, for many practical applications, e.g. object detection andrecognition, raw images are usually needed to be appropriately enhanced toraise the visual quality (e.g. visibility and contrast). In fact, properenhancement can noticeably improve the quality of input images, even betterthan originally captured images which are generally thought to be of the bestquality. In this work, we present two most important contributions. The firstcontribution is to develop a new no-reference (NR) IQA model. Given an image,our quality measure first extracts 17 features through analysis of contrast,sharpness, brightness and more, and then yields a measre of visual qualityusing a regression module, which is learned with big-data training samples thatare much bigger than the size of relevant image datasets. Results ofexperiments on nine datasets validate the superiority and efficiency of ourblind metric compared with typical state-of-the-art full-, reduced- andno-reference IQA methods. The second contribution is that a robust imageenhancement framework is established based on quality optimization. For aninput image, by the guidance of the proposed NR-IQA measure, we conducthistogram modification to successively rectify image brightness and contrast toa proper level. Thorough tests demonstrate that our framework can well enhancenatural images, low-contrast images, low-light images and dehazed images. Thesource code will be released athttps://sites.google.com/site/guke198701/publications.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1301-1313',\n",
       "  'citations': '150',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.08632v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9186315539823553743&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 63: {'ID': 63,\n",
       "  'title': 'CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and  Expert Comparison',\n",
       "  'authors': ['Curtis P. Langlotz',\n",
       "   'Silviana Ciurea-Ilcus',\n",
       "   'Ricky Jones',\n",
       "   'Andrew Y. Ng',\n",
       "   'Pranav Rajpurkar',\n",
       "   'Jayne Seekins',\n",
       "   'Jeremy Irvin',\n",
       "   'Jesse K. Sandberg',\n",
       "   'Safwan S. Halabi',\n",
       "   'David B. Larson',\n",
       "   'Chris Chute',\n",
       "   'Yifan Yu',\n",
       "   'David A. Mong',\n",
       "   'Henrik Marklund',\n",
       "   'Katie Shpanskaya',\n",
       "   'Robyn Ball',\n",
       "   'Behzad Haghgoo',\n",
       "   'Matthew P. Lungren',\n",
       "   'Bhavik N. Patel',\n",
       "   'Michael Ko'],\n",
       "  'published': '2019-01-21T18:41:59Z',\n",
       "  'updated': '2019-01-21T18:41:59Z',\n",
       "  'abstract': 'Large, labeled datasets have driven deep learning methods to achieveexpert-level performance on a variety of medical imaging tasks. We presentCheXpert, a large dataset that contains 224,316 chest radiographs of 65,240patients. We design a labeler to automatically detect the presence of 14observations in radiology reports, capturing uncertainties inherent inradiograph interpretation. We investigate different approaches to using theuncertainty labels for training convolutional neural networks that output theprobability of these observations given the available frontal and lateralradiographs. On a validation set of 200 chest radiographic studies which weremanually annotated by 3 board-certified radiologists, we find that differentuncertainty approaches are useful for different pathologies. We then evaluateour best model on a test set composed of 500 chest radiographic studiesannotated by a consensus of 5 board-certified radiologists, and compare theperformance of our model to that of 3 additional radiologists in the detectionof 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, themodel ROC and PR curves lie above all 3 radiologist operating points. Werelease the dataset to the public as a standard benchmark to evaluateperformance of chest radiograph interpretation models.  The dataset is freely available athttps://stanfordmlgroup.github.io/competitions/chexpert .',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG', 'eess.IV'],\n",
       "  'journal': 'Proceedings of the AAAI Conference on Artificial Intelligence 33, 590-597',\n",
       "  'citations': '163',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.07031v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6830093712704163164&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 64: {'ID': 64,\n",
       "  'title': 'Gradient-based Hyperparameter Optimization through Reversible Learning',\n",
       "  'authors': ['Ryan P. Adams', 'David Duvenaud', 'Dougal Maclaurin'],\n",
       "  'published': '2015-02-11T23:52:36Z',\n",
       "  'updated': '2015-04-02T17:40:44Z',\n",
       "  'abstract': 'Tuning hyperparameters of learning algorithms is hard because gradients areusually unavailable. We compute exact gradients of cross-validation performancewith respect to all hyperparameters by chaining derivatives backwards throughthe entire training procedure. These gradients allow us to optimize thousandsof hyperparameters, including step-size and momentum schedules, weightinitialization distributions, richly parameterized regularization schemes, andneural network architectures. We compute hyperparameter gradients by exactlyreversing the dynamics of stochastic gradient descent with momentum.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 2113-2122',\n",
       "  'citations': '357',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.03492v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16427522673612533152&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 65: {'ID': 65,\n",
       "  'title': 'Learning to Communicate with Deep Multi-Agent Reinforcement Learning',\n",
       "  'authors': ['Yannis M. Assael',\n",
       "   'Jakob N. Foerster',\n",
       "   'Shimon Whiteson',\n",
       "   'Nando de Freitas'],\n",
       "  'published': '2016-05-21T17:20:04Z',\n",
       "  'updated': '2016-05-24T18:16:56Z',\n",
       "  'abstract': 'We consider the problem of multiple agents sensing and acting in environmentswith the goal of maximising their shared utility. In these environments, agentsmust learn communication protocols in order to share information that is neededto solve the tasks. By embracing deep neural networks, we are able todemonstrate end-to-end learning of protocols in complex environments inspiredby communication riddles and multi-agent computer vision problems with partialobservability. We propose two approaches for learning in these domains:Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning(DIAL). The former uses deep Q-learning, while the latter exploits the factthat, during learning, agents can backpropagate error derivatives through(noisy) communication channels. Hence, this approach uses centralised learningbut decentralised execution. Our experiments introduce new environments forstudying the learning of communication protocols and present a set ofengineering innovations that are essential for success in these domains.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.MA'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '526',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06676v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14427321615765348461&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 66: {'ID': 66,\n",
       "  'title': 'An End-to-End Spatio-Temporal Attention Model for Human Action  Recognition from Skeleton Data',\n",
       "  'authors': ['Junliang Xing',\n",
       "   'Wenjun Zeng',\n",
       "   'Jiaying Liu',\n",
       "   'Cuiling Lan',\n",
       "   'Sijie Song'],\n",
       "  'published': '2016-11-18T13:33:28Z',\n",
       "  'updated': '2016-11-18T13:33:28Z',\n",
       "  'abstract': 'Human action recognition is an important task in computer vision. Extractingdiscriminative spatial and temporal features to model the spatial and temporalevolutions of different actions plays a key role in accomplishing this task. Inthis work, we propose an end-to-end spatial and temporal attention model forhuman action recognition from skeleton data. We build our model on top of theRecurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), whichlearns to selectively focus on discriminative joints of skeleton within eachframe of the inputs and pays different levels of attention to the outputs ofdifferent frames. Furthermore, to ensure effective training of the network, wepropose a regularized cross-entropy loss to drive the model learning processand develop a joint training strategy accordingly. Experimental resultsdemonstrate the effectiveness of the proposed model,both on the small humanaction recognition data set of SBU and the currently largest NTU dataset.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '354',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.06067v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1164598227028548863&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 67: {'ID': 67,\n",
       "  'title': 'Compressing Neural Networks with the Hashing Trick',\n",
       "  'authors': ['James T. Wilson',\n",
       "   'Wenlin Chen',\n",
       "   'Stephen Tyree',\n",
       "   'Kilian Q. Weinberger',\n",
       "   'Yixin Chen'],\n",
       "  'published': '2015-04-19T04:24:15Z',\n",
       "  'updated': '2015-04-19T04:24:15Z',\n",
       "  'abstract': 'As deep nets are increasingly used in applications suited for mobile devices,a fundamental dilemma becomes apparent: the trend in deep learning is to growmodels to absorb ever-increasing data set sizes; however mobile devices aredesigned with very little memory and cannot store such large models. We presenta novel network architecture, HashedNets, that exploits inherent redundancy inneural networks to achieve drastic reductions in model sizes. HashedNets uses alow-cost hash function to randomly group connection weights into hash buckets,and all connections within the same hash bucket share a single parameter value.These parameters are tuned to adjust to the HashedNets weight sharingarchitecture with standard backprop during training. Our hashing procedureintroduces no additional memory overhead, and we demonstrate on severalbenchmark data sets that HashedNets shrink the storage requirements of neuralnetworks substantially while mostly preserving generalization performance.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 2285-2294',\n",
       "  'citations': '763',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1504.04788v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5053947540904220409&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 68: {'ID': 68,\n",
       "  'title': 'Auxiliary Deep Generative Models',\n",
       "  'authors': ['Lars Maaløe',\n",
       "   'Søren Kaae Sønderby',\n",
       "   'Casper Kaae Sønderby',\n",
       "   'Ole Winther'],\n",
       "  'published': '2016-02-17T16:24:50Z',\n",
       "  'updated': '2016-06-16T06:39:08Z',\n",
       "  'abstract': 'Deep generative models parameterized by neural networks have recentlyachieved state-of-the-art performance in unsupervised and semi-supervisedlearning. We extend deep generative models with auxiliary variables whichimproves the variational approximation. The auxiliary variables leave thegenerative model unchanged but make the variational distribution moreexpressive. Inspired by the structure of the auxiliary variable we also proposea model with two stochastic layers and skip connections. Our findings suggestthat more expressive and properly specified deep generative models convergefaster with better results. We show state-of-the-art performance withinsemi-supervised learning on MNIST, SVHN and NORB datasets.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 1445-1453',\n",
       "  'citations': '294',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.05473v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9120124950708918697&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 69: {'ID': 69,\n",
       "  'title': 'Unsupervised Learning of 3D Structure from Images',\n",
       "  'authors': ['Nicolas Heess',\n",
       "   'Max Jaderberg',\n",
       "   'Peter Battaglia',\n",
       "   'Danilo Jimenez Rezende',\n",
       "   'Shakir Mohamed',\n",
       "   'S. M. Ali Eslami'],\n",
       "  'published': '2016-07-03T17:53:11Z',\n",
       "  'updated': '2018-06-19T17:26:53Z',\n",
       "  'abstract': 'A key goal of computer vision is to recover the underlying 3D structure from2D observations of the world. In this paper we learn strong deep generativemodels of 3D structures, and recover these structures from 3D and 2D images viaprobabilistic inference. We demonstrate high-quality samples and reportlog-likelihoods on several datasets, including ShapeNet [2], and establish thefirst benchmarks in the literature. We also show how these models and theirinference networks can be trained end-to-end from 2D images. This demonstratesfor the first time the feasibility of learning to infer 3D representations ofthe world in a purely unsupervised manner.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '232',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.00662v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6886635876252957202&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 70: {'ID': 70,\n",
       "  'title': 'Toward Controlled Generation of Text',\n",
       "  'authors': ['Zhiting Hu',\n",
       "   'Ruslan Salakhutdinov',\n",
       "   'Eric P. Xing',\n",
       "   'Zichao Yang',\n",
       "   'Xiaodan Liang'],\n",
       "  'published': '2017-03-02T21:23:47Z',\n",
       "  'updated': '2018-09-13T02:16:40Z',\n",
       "  'abstract': 'Generic generation and manipulation of text is challenging and has limitedsuccess compared to recent deep generative modeling in visual domain. Thispaper aims at generating plausible natural language sentences, whose attributesare dynamically controlled by learning disentangled latent representations withdesignated semantics. We propose a new neural generative model which combinesvariational auto-encoders and holistic attribute discriminators for effectiveimposition of semantic structures. With differentiable approximation todiscrete text samples, explicit constraints on independent attribute controls,and efficient collaborative learning of generator and discriminators, our modellearns highly interpretable representations from even only word annotations,and produces realistic sentences with desired attributes. Quantitativeevaluation validates the accuracy of sentence and attribute generation.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'ICML, 1587-1596',\n",
       "  'citations': '401',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00955v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14533919283203963154&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 71: {'ID': 71,\n",
       "  'title': 'Few-Shot Learning with Graph Neural Networks',\n",
       "  'authors': ['Victor Garcia', 'Joan Bruna'],\n",
       "  'published': '2017-11-10T23:32:47Z',\n",
       "  'updated': '2018-02-20T16:52:36Z',\n",
       "  'abstract': \"We propose to study the problem of few-shot learning with the prism ofinference on a partially observed graphical model, constructed from acollection of input images whose label can be either observed or not. Byassimilating generic message-passing inference algorithms with theirneural-network counterparts, we define a graph neural network architecture thatgeneralizes several of the recently proposed few-shot learning models. Besidesproviding improved numerical performance, our framework is easily extended tovariants of few-shot learning, such as semi-supervised or active learning,demonstrating the ability of graph-based models to operate well on 'relational'tasks.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '259',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.04043v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15420545241088720867&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 72: {'ID': 72,\n",
       "  'title': 'Unsupervised Representation Learning by Predicting Image Rotations',\n",
       "  'authors': ['Nikos Komodakis', 'Praveer Singh', 'Spyros Gidaris'],\n",
       "  'published': '2018-03-21T03:21:14Z',\n",
       "  'updated': '2018-03-21T03:21:14Z',\n",
       "  'abstract': 'Over the last years, deep convolutional neural networks (ConvNets) havetransformed the field of computer vision thanks to their unparalleled capacityto learn high level semantic image features. However, in order to successfullylearn those features, they usually require massive amounts of manually labeleddata, which is both expensive and impractical to scale. Therefore, unsupervisedsemantic feature learning, i.e., learning without requiring manual annotationeffort, is of crucial importance in order to successfully harvest the vastamount of visual data that are available today. In our work we propose to learnimage features by training ConvNets to recognize the 2d rotation that isapplied to the image that it gets as input. We demonstrate both qualitativelyand quantitatively that this apparently simple task actually provides a verypowerful supervisory signal for semantic feature learning. We exhaustivelyevaluate our method in various unsupervised feature learning benchmarks and weexhibit in all of them state-of-the-art performance. Specifically, our resultson those benchmarks demonstrate dramatic improvements w.r.t. priorstate-of-the-art approaches in unsupervised representation learning and thussignificantly close the gap with supervised feature learning. For instance, inPASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet modelachieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that isonly 2.4 points lower from the supervised case. We get similarly strikingresults when we transfer our unsupervised learned features on various othertasks, such as ImageNet classification, PASCAL classification, PASCALsegmentation, and CIFAR-10 classification. The code and models of our paperwill be published on: https://github.com/gidariss/FeatureLearningRotNet .',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '333',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.07728v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12748509220929577948&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 73: {'ID': 73,\n",
       "  'title': 'Temporal Ensembling for Semi-Supervised Learning',\n",
       "  'authors': ['Samuli Laine', 'Timo Aila'],\n",
       "  'published': '2016-10-07T12:15:42Z',\n",
       "  'updated': '2017-03-15T14:22:41Z',\n",
       "  'abstract': 'In this paper, we present a simple and efficient method for training deepneural networks in a semi-supervised setting where only a small portion oftraining data is labeled. We introduce self-ensembling, where we form aconsensus prediction of the unknown labels using the outputs of thenetwork-in-training on different epochs, and most importantly, under differentregularization and input augmentation conditions. This ensemble prediction canbe expected to be a better predictor for the unknown labels than the output ofthe network at the most recent training epoch, and can thus be used as a targetfor training. Using our method, we set new records for two standardsemi-supervised learning benchmarks, reducing the (non-augmented)classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16%by enabling the standard augmentations. We additionally obtain a clearimprovement in CIFAR-100 classification accuracy by using random images fromthe Tiny Images dataset as unlabeled extra inputs during training. Finally, wedemonstrate good tolerance to incorrect labels.',\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '492',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.02242v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12742815032693937464&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 74: {'ID': 74,\n",
       "  'title': 'Sanity Checks for Saliency Maps',\n",
       "  'authors': ['Justin Gilmer',\n",
       "   'Been Kim',\n",
       "   'Julius Adebayo',\n",
       "   'Ian Goodfellow',\n",
       "   'Michael Muelly',\n",
       "   'Moritz Hardt'],\n",
       "  'published': '2018-10-08T07:27:11Z',\n",
       "  'updated': '2020-11-06T13:40:14Z',\n",
       "  'abstract': 'Saliency methods have emerged as a popular tool to highlight features in aninput deemed relevant for the prediction of a learned model. Several saliencymethods have been proposed, often guided by visual appeal on image data. Inthis work, we propose an actionable methodology to evaluate what kinds ofexplanations a given method can and cannot provide. We find that reliance,solely, on visual assessment can be misleading. Through extensive experimentswe show that some existing saliency methods are independent both of the modeland of the data generating process. Consequently, methods that fail theproposed tests are inadequate for tasks that are sensitive to either data ormodel, such as, finding outliers in the data, explaining the relationshipbetween inputs and outputs that the model learned, and debugging the model. Weinterpret our findings through an analogy with edge detection in images, atechnique that requires neither training data nor model. Theory in the case ofa linear model and a single-layer convolutional neural network supports ourexperimental findings.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '220',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.03292v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8767887416569707674&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 75: {'ID': 75,\n",
       "  'title': 'Robust Adversarial Reinforcement Learning',\n",
       "  'authors': ['Rahul Sukthankar',\n",
       "   'James Davidson',\n",
       "   'Abhinav Gupta',\n",
       "   'Lerrel Pinto'],\n",
       "  'published': '2017-03-08T04:58:51Z',\n",
       "  'updated': '2017-03-08T04:58:51Z',\n",
       "  'abstract': 'Deep neural networks coupled with fast simulation and improved computationhave led to recent successes in the field of reinforcement learning (RL).However, most current RL-based approaches fail to generalize since: (a) the gapbetween simulation and real world is so large that policy-learning approachesfail to transfer; (b) even if policy learning is done in real world, the datascarcity leads to failed generalization from training to test scenarios (e.g.,due to different friction or object masses). Inspired from H-infinity controlmethods, we note that both modeling errors and differences in training and testscenarios can be viewed as extra forces/disturbances in the system. This paperproposes the idea of robust adversarial reinforcement learning (RARL), where wetrain an agent to operate in the presence of a destabilizing adversary thatapplies disturbance forces to the system. The jointly trained adversary isreinforced -- that is, it learns an optimal destabilization policy. Weformulate the policy learning as a zero-sum, minimax objective function.Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah,Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)improves training stability; (b) is robust to differences in training/testconditions; and c) outperform the baseline even in the absence of theadversary.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.MA', 'cs.RO'],\n",
       "  'journal': 'ICML, 2817-2826',\n",
       "  'citations': '191',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.02702v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10521359398547093876&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 76: {'ID': 76,\n",
       "  'title': 'Synthesizing the preferred inputs for neurons in neural networks via  deep generator networks',\n",
       "  'authors': ['Jason Yosinski',\n",
       "   'Alexey Dosovitskiy',\n",
       "   'Thomas Brox',\n",
       "   'Jeff Clune',\n",
       "   'Anh Nguyen'],\n",
       "  'published': '2016-05-30T16:22:54Z',\n",
       "  'updated': '2016-11-23T18:41:12Z',\n",
       "  'abstract': 'Deep neural networks (DNNs) have demonstrated state-of-the-art results onmany pattern recognition tasks, especially vision classification problems.Understanding the inner workings of such computational brains is bothfascinating basic science that is interesting in its own right - similar to whywe study the human brain - and will enable researchers to further improve DNNs.One path to understanding how a neural network functions internally is to studywhat each of its neurons has learned to detect. One such method is calledactivation maximization (AM), which synthesizes an input (e.g. an image) thathighly activates a neuron. Here we dramatically improve the qualitative stateof the art of activation maximization by harnessing a powerful, learned prior:a deep generator network (DGN). The algorithm (1) generates qualitativelystate-of-the-art synthetic images that look almost real, (2) reveals thefeatures learned by each neuron in an interpretable way, (3) generalizes wellto new datasets and somewhat well to different network architectures withoutrequiring the prior to be relearned, and (4) can be considered as ahigh-quality generative method (in this case, by generating novel, creative,interesting, recognizable images).',\n",
       "  'categories': ['cs.NE', 'cs.AI', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '305',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.09304v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5242797434107730911&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 77: {'ID': 77,\n",
       "  'title': 'Scheduled Sampling for Sequence Prediction with Recurrent Neural  Networks',\n",
       "  'authors': ['Oriol Vinyals',\n",
       "   'Navdeep Jaitly',\n",
       "   'Samy Bengio',\n",
       "   'Noam Shazeer'],\n",
       "  'published': '2015-06-09T20:33:47Z',\n",
       "  'updated': '2015-09-23T16:35:42Z',\n",
       "  'abstract': 'Recurrent Neural Networks can be trained to produce sequences of tokens givensome input, as exemplified by recent results in machine translation and imagecaptioning. The current approach to training them consists of maximizing thelikelihood of each token in the sequence given the current (recurrent) stateand the previous token. At inference, the unknown previous token is thenreplaced by a token generated by the model itself. This discrepancy betweentraining and inference can yield errors that can accumulate quickly along thegenerated sequence. We propose a curriculum learning strategy to gently changethe training process from a fully guided scheme using the true previous token,towards a less guided scheme which mostly uses the generated token instead.Experiments on several sequence prediction tasks show that this approach yieldssignificant improvements. Moreover, it was used successfully in our winningentry to the MSCOCO image captioning challenge, 2015.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '897',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.03099v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4523710212567339415&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 78: {'ID': 78,\n",
       "  'title': 'Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)',\n",
       "  'authors': ['Yi Yang',\n",
       "   'Jiang Wang',\n",
       "   'Alan Yuille',\n",
       "   'Wei Xu',\n",
       "   'Junhua Mao',\n",
       "   'Zhiheng Huang'],\n",
       "  'published': '2014-12-20T08:10:04Z',\n",
       "  'updated': '2015-06-11T15:26:58Z',\n",
       "  'abstract': 'In this paper, we present a multimodal Recurrent Neural Network (m-RNN) modelfor generating novel image captions. It directly models the probabilitydistribution of generating a word given previous words and an image. Imagecaptions are generated by sampling from this distribution. The model consistsof two sub-networks: a deep recurrent neural network for sentences and a deepconvolutional network for images. These two sub-networks interact with eachother in a multimodal layer to form the whole m-RNN model. The effectiveness ofour model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K,Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. Inaddition, we apply the m-RNN model to retrieval tasks for retrieving images orsentences, and achieves significant performance improvement over thestate-of-the-art methods which directly optimize the ranking objective functionfor retrieval. The project page of this work is:www.stat.ucla.edu/~junhua.mao/m-RNN.html .',\n",
       "  'categories': ['cs.CV', 'cs.CL', 'cs.LG', 'I.2.6; I.2.7; I.2.10'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '843',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6632v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16666958166938946394&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 79: {'ID': 79,\n",
       "  'title': 'Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction  Tasks',\n",
       "  'authors': ['Ofer Lavi',\n",
       "   'Yonatan Belinkov',\n",
       "   'Einat Kermany',\n",
       "   'Yoav Goldberg',\n",
       "   'Yossi Adi'],\n",
       "  'published': '2016-08-15T08:51:38Z',\n",
       "  'updated': '2017-02-09T06:58:50Z',\n",
       "  'abstract': \"There is a lot of research interest in encoding variable length sentencesinto fixed length vectors, in a way that preserves the sentence meanings. Twocommon methods include representations based on averaging word vectors, andrepresentations based on the hidden states of recurrent neural networks such asLSTMs. The sentence vectors are used as features for subsequent machinelearning tasks or for pre-training in the context of deep learning. However,not much is known about the properties that are encoded in these sentencerepresentations and about the language information they capture. We propose aframework that facilitates better understanding of the encoded representations.We define prediction tasks around isolated aspects of sentence structure(namely sentence length, word content, and word order), and scorerepresentations by the ability to train a classifier to solve each predictiontask when using the representation as input. We demonstrate the potentialcontribution of the approach by analyzing different sentence representationmechanisms. The analysis sheds light on the relative strengths of differentsentence embedding methods with respect to these low level prediction tasks,and on the effect of the encoded vector's dimensionality on the resultingrepresentations.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.04207v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6309693306335821652&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 80: {'ID': 80,\n",
       "  'title': 'Attention-Based Models for Speech Recognition',\n",
       "  'authors': ['Jan Chorowski',\n",
       "   'Kyunghyun Cho',\n",
       "   'Dzmitry Bahdanau',\n",
       "   'Dmitriy Serdyuk',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2015-06-24T19:10:33Z',\n",
       "  'updated': '2015-06-24T19:10:33Z',\n",
       "  'abstract': 'Recurrent sequence generators conditioned on input data through an attentionmechanism have recently shown very good performance on a range of tasks in-cluding machine translation, handwriting synthesis and image caption gen-eration. We extend the attention-mechanism with features needed for speechrecognition. We show that while an adaptation of the model used for machinetranslation in reaches a competitive 18.7% phoneme error rate (PER) on theTIMIT phoneme recognition task, it can only be applied to utterances which areroughly as long as the ones it was trained on. We offer a qualitativeexplanation of this failure and propose a novel and generic method of addinglocation-awareness to the attention mechanism to alleviate this issue. The newmethod yields a model that is robust to long inputs and achieves 18% PER insingle utterances and 20% in 10-times longer (repeated) utterances. Finally, wepropose a change to the at- tention mechanism that prevents it fromconcentrating too much on single frames, which further reduces PER to 17.6%level.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1268',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.07503v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16516573035858419027&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 81: {'ID': 81,\n",
       "  'title': 'StarSpace: Embed All The Things!',\n",
       "  'authors': ['Antoine Bordes',\n",
       "   'Jason Weston',\n",
       "   'Keith Adams',\n",
       "   'Ledell Wu',\n",
       "   'Adam Fisch',\n",
       "   'Sumit Chopra'],\n",
       "  'published': '2017-09-12T14:16:56Z',\n",
       "  'updated': '2017-11-21T02:59:57Z',\n",
       "  'abstract': 'We present StarSpace, a general-purpose neural embedding model that can solvea wide variety of problems: labeling tasks such as text classification, rankingtasks such as information retrieval/web search, collaborative filtering-basedor content-based recommendation, embedding of multi-relational graphs, andlearning word, sentence or document level embeddings. In each case the modelworks by embedding those entities comprised of discrete features and comparingthem against each other -- learning similarities dependent on the task.Empirical results on a number of tasks show that StarSpace is highlycompetitive with existing methods, whilst also being generally applicable tonew cases where those methods are not.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '135',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.03856v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1391286903653880286&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 82: {'ID': 82,\n",
       "  'title': 'Censoring Representations with an Adversary',\n",
       "  'authors': ['Harrison Edwards', 'Amos Storkey'],\n",
       "  'published': '2015-11-18T18:06:24Z',\n",
       "  'updated': '2016-03-04T11:01:34Z',\n",
       "  'abstract': 'In practice, there are often explicit constraints on what representations ordecisions are acceptable in an application of machine learning. For example itmay be a legal requirement that a decision must not favour a particular group.Alternatively it can be that that representation of data must not haveidentifying information. We address these two related issues by learningflexible representations that minimize the capability of an adversarial critic.This adversary is trying to predict the relevant sensitive variable from therepresentation, and so minimizing the performance of the adversary ensuresthere is little or no information in the representation about the sensitivevariable. We demonstrate this adversarial approach on two problems: makingdecisions free from discrimination and removing private information fromimages. We formulate the adversarial model as a minimax problem, and optimizethat minimax objective using a stochastic gradient alternate min-max optimizer.We demonstrate the ability to provide discriminant free representations forstandard test problems, and compare with previous state of the art methods forfairness, showing statistically significant improvement across most cases. Theflexibility of this method is shown via a novel problem: removing annotationsfrom images, from unaligned training examples of annotated and unannotatedimages, and with no a priori knowledge of the form of annotation provided tothe model.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '204',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05897v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14450653116005073046&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 83: {'ID': 83,\n",
       "  'title': 'Fully Convolutional Multi-Class Multiple Instance Learning',\n",
       "  'authors': ['Evan Shelhamer',\n",
       "   'Jonathan Long',\n",
       "   'Trevor Darrell',\n",
       "   'Deepak Pathak'],\n",
       "  'published': '2014-12-22T20:49:54Z',\n",
       "  'updated': '2015-04-15T05:31:10Z',\n",
       "  'abstract': 'Multiple instance learning (MIL) can reduce the need for costly annotation intasks such as semantic segmentation by weakening the required degree ofsupervision. We propose a novel MIL formulation of multi-class semanticsegmentation learning by a fully convolutional network. In this setting, weseek to learn a semantic segmentation model from just weak image-level labels.The model is trained end-to-end to jointly optimize the representation whiledisambiguating the pixel-image label assignment. Fully convolutional trainingaccepts inputs of any size, does not need object proposal pre-processing, andoffers a pixelwise loss map for selecting latent instances. Our multi-class MILloss exploits the further supervision given by images with multiple labels. Weevaluate this approach through preliminary experiments on the PASCAL VOCsegmentation challenge.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.7144v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6242051221514792488&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 84: {'ID': 84,\n",
       "  'title': 'Deep Knowledge Tracing',\n",
       "  'authors': ['Mehran Sahami',\n",
       "   'Leonidas Guibas',\n",
       "   'Jonathan Huang',\n",
       "   'Jonathan Spencer',\n",
       "   'Jascha Sohl-Dickstein',\n",
       "   'Chris Piech',\n",
       "   'Surya Ganguli'],\n",
       "  'published': '2015-06-19T08:29:00Z',\n",
       "  'updated': '2015-06-19T08:29:00Z',\n",
       "  'abstract': 'Knowledge tracing---where a machine models the knowledge of a student as theyinteract with coursework---is a well established problem in computer supportededucation. Though effectively modeling student knowledge would have higheducational impact, the task has many inherent challenges. In this paper weexplore the utility of using Recurrent Neural Networks (RNNs) to model studentlearning. The RNN family of models have important advantages over previousmethods in that they do not require the explicit encoding of human domainknowledge, and can capture more complex representations of student knowledge.Using neural networks results in substantial improvements in predictionperformance on a range of knowledge tracing datasets. Moreover the learnedmodel can be used for intelligent curriculum design and allows straightforwardinterpretation and discovery of structure in student tasks. These resultssuggest a promising new line of research for knowledge tracing and an exemplaryapplication task for RNNs.',\n",
       "  'categories': ['cs.AI', 'cs.CY', 'cs.LG', 'K.3.1'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '318',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.05908v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7245594791529377875&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 85: {'ID': 85,\n",
       "  'title': 'Semi-Supervised Classification with Graph Convolutional Networks',\n",
       "  'authors': ['Max Welling', 'Thomas N. Kipf'],\n",
       "  'published': '2016-09-09T19:48:41Z',\n",
       "  'updated': '2017-02-22T09:55:36Z',\n",
       "  'abstract': 'We present a scalable approach for semi-supervised learning ongraph-structured data that is based on an efficient variant of convolutionalneural networks which operate directly on graphs. We motivate the choice of ourconvolutional architecture via a localized first-order approximation ofspectral graph convolutions. Our model scales linearly in the number of graphedges and learns hidden layer representations that encode both local graphstructure and features of nodes. In a number of experiments on citationnetworks and on a knowledge graph dataset we demonstrate that our approachoutperforms related methods by a significant margin.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '4036',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.02907v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9692529718922546949&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 86: {'ID': 86,\n",
       "  'title': 'Trust Region Policy Optimization',\n",
       "  'authors': ['Sergey Levine',\n",
       "   'Michael I. Jordan',\n",
       "   'Philipp Moritz',\n",
       "   'John Schulman',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2015-02-19T06:44:25Z',\n",
       "  'updated': '2017-04-20T18:04:12Z',\n",
       "  'abstract': 'We describe an iterative procedure for optimizing policies, with guaranteedmonotonic improvement. By making several approximations to thetheoretically-justified procedure, we develop a practical algorithm, calledTrust Region Policy Optimization (TRPO). This algorithm is similar to naturalpolicy gradient methods and is effective for optimizing large nonlinearpolicies such as neural networks. Our experiments demonstrate its robustperformance on a wide variety of tasks: learning simulated robotic swimming,hopping, and walking gaits; and playing Atari games using images of the screenas input. Despite its approximations that deviate from the theory, TRPO tendsto give monotonic improvement, with little tuning of hyperparameters.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1889-1897',\n",
       "  'citations': '2405',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.05477v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4215501129336400677&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 87: {'ID': 87,\n",
       "  'title': 'Hierarchical Deep Reinforcement Learning: Integrating Temporal  Abstraction and Intrinsic Motivation',\n",
       "  'authors': ['Tejas D. Kulkarni',\n",
       "   'Karthik R. Narasimhan',\n",
       "   'Joshua B. Tenenbaum',\n",
       "   'Ardavan Saeedi'],\n",
       "  'published': '2016-04-20T18:47:48Z',\n",
       "  'updated': '2016-05-31T14:45:58Z',\n",
       "  'abstract': \"Learning goal-directed behavior in environments with sparse feedback is amajor challenge for reinforcement learning algorithms. The primary difficultyarises due to insufficient exploration, resulting in an agent being unable tolearn robust value functions. Intrinsically motivated agents can explore newbehavior for its own sake rather than to directly solve problems. Suchintrinsic behaviors could eventually help the agent solve tasks posed by theenvironment. We present hierarchical-DQN (h-DQN), a framework to integratehierarchical value functions, operating at different temporal scales, withintrinsically motivated deep reinforcement learning. A top-level value functionlearns a policy over intrinsic goals, and a lower-level function learns apolicy over atomic actions to satisfy the given goals. h-DQN allows forflexible goal specifications, such as functions over entities and relations.This provides an efficient space for exploration in complicated environments.We demonstrate the strength of our approach on two problems with very sparse,delayed feedback: (1) a complex discrete stochastic decision process, and (2)the classic ATARI game `Montezuma's Revenge'.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '546',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.06057v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17312997916185144890&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 88: {'ID': 88,\n",
       "  'title': 'Deep Reinforcement Learning that Matters',\n",
       "  'authors': ['Philip Bachman',\n",
       "   'Riashat Islam',\n",
       "   'Doina Precup',\n",
       "   'Joelle Pineau',\n",
       "   'Peter Henderson',\n",
       "   'David Meger'],\n",
       "  'published': '2017-09-19T06:09:47Z',\n",
       "  'updated': '2019-01-30T04:21:41Z',\n",
       "  'abstract': 'In recent years, significant progress has been made in solving challengingproblems across various domains using deep reinforcement learning (RL).Reproducing existing work and accurately judging the improvements offered bynovel methods is vital to sustaining this progress. Unfortunately, reproducingresults for state-of-the-art deep RL methods is seldom straightforward. Inparticular, non-determinism in standard benchmark environments, combined withvariance intrinsic to the methods, can make reported results tough tointerpret. Without significance metrics and tighter standardization ofexperimental reporting, it is difficult to determine whether improvements overthe prior state-of-the-art are meaningful. In this paper, we investigatechallenges posed by reproducibility, proper experimental techniques, andreporting procedures. We illustrate the variability in reported metrics andresults when comparing against common baselines and suggest guidelines to makefuture results in deep RL more reproducible. We aim to spur discussion abouthow to ensure continued progress in the field by minimizing wasted effortstemming from results that are non-reproducible and easily misinterpreted.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '567',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.06560v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4728083518318824086&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 89: {'ID': 89,\n",
       "  'title': 'Certified Adversarial Robustness via Randomized Smoothing',\n",
       "  'authors': ['Elan Rosenfeld', 'J. Zico Kolter', 'Jeremy M Cohen'],\n",
       "  'published': '2019-02-08T02:08:19Z',\n",
       "  'updated': '2019-06-15T07:40:33Z',\n",
       "  'abstract': 'We show how to turn any classifier that classifies well under Gaussian noiseinto a new classifier that is certifiably robust to adversarial perturbationsunder the $\\\\ell_2$ norm. This \"randomized smoothing\" technique has beenproposed recently in the literature, but existing guarantees are loose. Weprove a tight robustness guarantee in $\\\\ell_2$ norm for smoothing with Gaussiannoise. We use randomized smoothing to obtain an ImageNet classifier with e.g. acertified top-1 accuracy of 49% under adversarial perturbations with $\\\\ell_2$norm less than 0.5 (=127/255). No certified defense has been shown feasible onImageNet except for smoothing. On smaller-scale datasets where competingapproaches to certified $\\\\ell_2$ robustness are viable, smoothing delivershigher certified accuracies. Our strong empirical results suggest thatrandomized smoothing is a promising direction for future research intoadversarially robust classification. Code and models are available athttp://github.com/locuslab/smoothing.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 1310-1320',\n",
       "  'citations': '202',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.02918v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7039519782328477041&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 90: {'ID': 90,\n",
       "  'title': 'TextBoxes: A Fast Text Detector with a Single Deep Neural Network',\n",
       "  'authors': ['Minghui Liao',\n",
       "   'Xinggang Wang',\n",
       "   'Baoguang Shi',\n",
       "   'Xiang Bai',\n",
       "   'Wenyu Liu'],\n",
       "  'published': '2016-11-21T13:35:15Z',\n",
       "  'updated': '2016-11-21T13:35:15Z',\n",
       "  'abstract': 'This paper presents an end-to-end trainable fast scene text detector, namedTextBoxes, which detects scene text with both high accuracy and efficiency in asingle network forward pass, involving no post-process except for a standardnon-maximum suppression. TextBoxes outperforms competing methods in terms oftext localization accuracy and is much faster, taking only 0.09s per image in afast implementation. Furthermore, combined with a text recognizer, TextBoxessignificantly outperforms state-of-the-art approaches on word spotting andend-to-end text recognition tasks.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '347',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.06779v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1599895949788746925&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 91: {'ID': 91,\n",
       "  'title': 'Learning Sparse Neural Networks through $L_0$ Regularization',\n",
       "  'authors': ['Max Welling', 'Christos Louizos', 'Diederik P. Kingma'],\n",
       "  'published': '2017-12-04T19:20:27Z',\n",
       "  'updated': '2018-06-22T14:54:59Z',\n",
       "  'abstract': 'We propose a practical method for $L_0$ norm regularization for neuralnetworks: pruning the network during training by encouraging weights to becomeexactly zero. Such regularization is interesting since (1) it can greatly speedup training and inference, and (2) it can improve generalization. AIC and BIC,well-known model selection criteria, are special cases of $L_0$ regularization.However, since the $L_0$ norm of weights is non-differentiable, we cannotincorporate it directly as a regularization term in the objective function. Wepropose a solution through the inclusion of a collection of non-negativestochastic gates, which collectively determine which weights to set to zero. Weshow that, somewhat surprisingly, for certain distributions over the gates, theexpected $L_0$ norm of the resulting gated weights is differentiable withrespect to the distribution parameters. We further propose the \\\\emph{hardconcrete} distribution for the gates, which is obtained by \"stretching\" abinary concrete distribution and then transforming its samples with ahard-sigmoid. The parameters of the distribution over the gates can then bejointly optimized with the original network parameters. As a result our methodallows for straightforward and efficient learning of model structures withstochastic gradient descent and allows for conditional computation in aprincipled way. We perform various experiments to demonstrate the effectivenessof the resulting approach and regularizer.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '237',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.01312v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16875065764676968506&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 92: {'ID': 92,\n",
       "  'title': 'Real-Time Adaptive Image Compression',\n",
       "  'authors': ['Oren Rippel', 'Lubomir Bourdev'],\n",
       "  'published': '2017-05-16T17:51:07Z',\n",
       "  'updated': '2017-05-16T17:51:07Z',\n",
       "  'abstract': 'We present a machine learning-based approach to lossy image compression whichoutperforms all existing codecs, while running in real-time.  Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets ofgeneric images across all quality levels. At the same time, our codec isdesigned to be lightweight and deployable: for example, it can encode or decodethe Kodak dataset in around 10ms per image on GPU.  Our architecture is an autoencoder featuring pyramidal analysis, an adaptivecoding module, and regularization of the expected codelength. We alsosupplement our approach with adversarial training specialized towards use in acompression setting: this enables us to produce visually pleasingreconstructions for very low bitrates.',\n",
       "  'categories': ['stat.ML', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICML, 2922-2930',\n",
       "  'citations': '217',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.05823v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5970681635183362212&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 93: {'ID': 93,\n",
       "  'title': 'Categorical Reparameterization with Gumbel-Softmax',\n",
       "  'authors': ['Ben Poole', 'Shixiang Gu', 'Eric Jang'],\n",
       "  'published': '2016-11-03T19:48:08Z',\n",
       "  'updated': '2017-08-05T22:45:19Z',\n",
       "  'abstract': 'Categorical variables are a natural choice for representing discretestructure in the world. However, stochastic neural networks rarely usecategorical latent variables due to the inability to backpropagate throughsamples. In this work, we present an efficient gradient estimator that replacesthe non-differentiable sample from a categorical distribution with adifferentiable sample from a novel Gumbel-Softmax distribution. Thisdistribution has the essential property that it can be smoothly annealed into acategorical distribution. We show that our Gumbel-Softmax estimator outperformsstate-of-the-art gradient estimators on structured output prediction andunsupervised generative modeling tasks with categorical latent variables, andenables large speedups on semi-supervised classification.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1224',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01144v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8563509432417332168&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 94: {'ID': 94,\n",
       "  'title': 'A Deep Hierarchical Approach to Lifelong Learning in Minecraft',\n",
       "  'authors': ['Shahar Givony',\n",
       "   'Daniel J. Mankowitz',\n",
       "   'Chen Tessler',\n",
       "   'Shie Mannor',\n",
       "   'Tom Zahavy'],\n",
       "  'published': '2016-04-25T13:45:50Z',\n",
       "  'updated': '2016-11-30T17:35:27Z',\n",
       "  'abstract': 'We propose a lifelong learning system that has the ability to reuse andtransfer knowledge from one task to another while efficiently retaining thepreviously learned knowledge-base. Knowledge is transferred by learningreusable skills to solve tasks in Minecraft, a popular video game which is anunsolved and high-dimensional lifelong learning problem. These reusable skills,which we refer to as Deep Skill Networks, are then incorporated into our novelHierarchical Deep Reinforcement Learning Network (H-DRLN) architecture usingtwo techniques: (1) a deep skill array and (2) skill distillation, our novelvariation of policy distillation (Rusu et. al. 2015) for learning skills. Skilldistillation enables the HDRLN to efficiently retain knowledge and thereforescale in lifelong learning, by accumulating knowledge and encapsulatingmultiple reusable skills into a single distilled network. The H-DRLN exhibitssuperior performance and lower learning sample complexity compared to theregular Deep Q Network (Mnih et. al. 2015) in sub-domains of Minecraft.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '194',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.07255v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15352455767272452459&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 95: {'ID': 95,\n",
       "  'title': 'Weight Normalization: A Simple Reparameterization to Accelerate Training  of Deep Neural Networks',\n",
       "  'authors': ['Diederik P. Kingma', 'Tim Salimans'],\n",
       "  'published': '2016-02-25T10:13:45Z',\n",
       "  'updated': '2016-06-04T01:21:52Z',\n",
       "  'abstract': 'We present weight normalization: a reparameterization of the weight vectorsin a neural network that decouples the length of those weight vectors fromtheir direction. By reparameterizing the weights in this way we improve theconditioning of the optimization problem and we speed up convergence ofstochastic gradient descent. Our reparameterization is inspired by batchnormalization but does not introduce any dependencies between the examples in aminibatch. This means that our method can also be applied successfully torecurrent models such as LSTMs and to noise-sensitive applications such as deepreinforcement learning or generative models, for which batch normalization isless well suited. Although our method is much simpler, it still provides muchof the speed-up of full batch normalization. In addition, the computationaloverhead of our method is lower, permitting more optimization steps to be takenin the same amount of time. We demonstrate the usefulness of our method onapplications in supervised image recognition, generative modelling, and deepreinforcement learning.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '792',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.07868v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5176697277672103356&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 96: {'ID': 96,\n",
       "  'title': 'Rethinking the Value of Network Pruning',\n",
       "  'authors': ['Gao Huang',\n",
       "   'Zhuang Liu',\n",
       "   'Tinghui Zhou',\n",
       "   'Trevor Darrell',\n",
       "   'Mingjie Sun'],\n",
       "  'published': '2018-10-11T22:15:28Z',\n",
       "  'updated': '2019-03-05T05:58:11Z',\n",
       "  'abstract': 'Network pruning is widely used for reducing the heavy inference cost of deepmodels in low-resource settings. A typical pruning algorithm is a three-stagepipeline, i.e., training (a large model), pruning and fine-tuning. Duringpruning, according to a certain criterion, redundant weights are pruned andimportant weights are kept to best preserve the accuracy. In this work, we makeseveral surprising observations which contradict common beliefs. For allstate-of-the-art structured pruning algorithms we examined, fine-tuning apruned model only gives comparable or worse performance than training thatmodel with randomly initialized weights. For pruning algorithms which assume apredefined target network architecture, one can get rid of the full pipelineand directly train the target network from scratch. Our observations areconsistent for multiple network architectures, datasets, and tasks, which implythat: 1) training a large, over-parameterized model is often not necessary toobtain an efficient final model, 2) learned \"important\" weights of the largemodel are typically not useful for the small pruned model, 3) the prunedarchitecture itself, rather than a set of inherited \"important\" weights, ismore crucial to the efficiency in the final model, which suggests that in somecases pruning can be useful as an architecture search paradigm. Our resultssuggest the need for more careful baseline evaluations in future research onstructured pruning methods. We also compare with the \"Lottery TicketHypothesis\" (Frankle &amp; Carbin 2019), and find that with optimal learning rate,the \"winning ticket\" initialization as used in Frankle &amp; Carbin (2019) does notbring improvement over random initialization.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.05270v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3601827758437367761&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 97: {'ID': 97,\n",
       "  'title': 'Large-Margin Softmax Loss for Convolutional Neural Networks',\n",
       "  'authors': ['Weiyang Liu', 'Zhiding Yu', 'Meng Yang', 'Yandong Wen'],\n",
       "  'published': '2016-12-07T15:36:11Z',\n",
       "  'updated': '2017-11-17T23:23:09Z',\n",
       "  'abstract': 'Cross-entropy loss together with softmax is arguably one of the most commonused supervision components in convolutional neural networks (CNNs). Despiteits simplicity, popularity and excellent performance, the component does notexplicitly encourage discriminative learning of features. In this paper, wepropose a generalized large-margin softmax (L-Softmax) loss which explicitlyencourages intra-class compactness and inter-class separability between learnedfeatures. Moreover, L-Softmax not only can adjust the desired margin but alsocan avoid overfitting. We also show that the L-Softmax loss can be optimized bytypical stochastic gradient descent. Extensive experiments on four benchmarkdatasets demonstrate that the deeply-learned features with L-softmax lossbecome more discriminative, hence significantly boosting the performance on avariety of visual classification and verification tasks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 507-516',\n",
       "  'citations': '511',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.02295v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=132136711413140598&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 98: {'ID': 98,\n",
       "  'title': 'Exploring Models and Data for Image Question Answering',\n",
       "  'authors': ['Ryan Kiros', 'Mengye Ren', 'Richard Zemel'],\n",
       "  'published': '2015-05-08T15:59:44Z',\n",
       "  'updated': '2015-11-29T22:45:12Z',\n",
       "  'abstract': 'This work aims to address the problem of image-based question-answering (QA)with new models and datasets. In our work, we propose to use neural networksand visual semantic embeddings, without intermediate stages such as objectdetection and image segmentation, to predict answers to simple questions aboutimages. Our model performs 1.8 times better than the only published results onan existing image QA dataset. We also present a question generation algorithmthat converts image descriptions, which are widely available, into QA form. Weused this algorithm to produce an order-of-magnitude larger dataset, with moreevenly distributed answers. A suite of baseline results on this new dataset arealso presented.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CL', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '470',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.02074v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11183301518990088958&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 99: {'ID': 99,\n",
       "  'title': 'Benchmarking Deep Reinforcement Learning for Continuous Control',\n",
       "  'authors': ['Rein Houthooft',\n",
       "   'Xi Chen',\n",
       "   'Yan Duan',\n",
       "   'John Schulman',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2016-04-22T18:57:24Z',\n",
       "  'updated': '2016-05-27T19:25:59Z',\n",
       "  'abstract': 'Recently, researchers have made significant progress combining the advancesin deep learning for learning feature representations with reinforcementlearning. Some notable examples include training agents to play Atari gamesbased on raw pixel data and to acquire advanced manipulation skills using rawsensory inputs. However, it has been difficult to quantify progress in thedomain of continuous control due to the lack of a commonly adopted benchmark.In this work, we present a benchmark suite of continuous control tasks,including classic tasks like cart-pole swing-up, tasks with very high state andaction dimensionality such as 3D humanoid locomotion, tasks with partialobservations, and tasks with hierarchical structure. We report novel findingsbased on the systematic evaluation of a range of implemented reinforcementlearning algorithms. Both the benchmark and reference implementations arereleased at https://github.com/rllab/rllab in order to facilitate experimentalreproducibility and to encourage adoption by other researchers.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO'],\n",
       "  'journal': 'ICML, 1329-1338',\n",
       "  'citations': '850',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.06778v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4776639135351919780&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 100: {'ID': 100,\n",
       "  'title': 'Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction',\n",
       "  'authors': ['Jieping Ye',\n",
       "   'Pinghua Gong',\n",
       "   'Jintao Ke',\n",
       "   'Huaxiu Yao',\n",
       "   'Zhenhui Li',\n",
       "   'Siyu Lu',\n",
       "   'Fei Wu',\n",
       "   'Xianfeng Tang',\n",
       "   'Yitian Jia'],\n",
       "  'published': '2018-02-23T19:53:13Z',\n",
       "  'updated': '2018-02-27T01:42:08Z',\n",
       "  'abstract': 'Taxi demand prediction is an important building block to enabling intelligenttransportation systems in a smart city. An accurate prediction model can helpthe city pre-allocate resources to meet travel demand and to reduce empty taxison streets which waste energy and worsen the traffic congestion. With theincreasing popularity of taxi requesting services such as Uber and Didi Chuxing(in China), we are able to collect large-scale taxi demand data continuously.How to utilize such big data to improve the demand prediction is an interestingand critical real-world problem. Traditional demand prediction methods mostlyrely on time series forecasting techniques, which fail to model the complexnon-linear spatial and temporal relations. Recent advances in deep learninghave shown superior performance on traditionally challenging tasks such asimage classification by learning the complex features and correlations fromlarge-scale data. This breakthrough has inspired researchers to explore deeplearning techniques on traffic prediction problems. However, existing methodson traffic prediction have only considered spatial relation (e.g., using CNN)or temporal relation (e.g., using LSTM) independently. We propose a DeepMulti-View Spatial-Temporal Network (DMVST-Net) framework to model both spatialand temporal relations. Specifically, our proposed model consists of threeviews: temporal view (modeling correlations between future demand values withnear time points via LSTM), spatial view (modeling local spatial correlationvia local CNN), and semantic view (modeling correlations among regions sharingsimilar temporal patterns). Experiments on large-scale real taxi demand datademonstrate effectiveness of our approach over state-of-the-art methods.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '239',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.08714v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6257175571523374999&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 101: {'ID': 101,\n",
       "  'title': 'UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional  Census Loss',\n",
       "  'authors': ['Junhwa Hur', 'Stefan Roth', 'Simon Meister'],\n",
       "  'published': '2017-11-21T15:19:26Z',\n",
       "  'updated': '2017-11-21T15:19:26Z',\n",
       "  'abstract': 'In the era of end-to-end deep learning, many advances in computer vision aredriven by large amounts of labeled data. In the optical flow setting, however,obtaining dense per-pixel ground truth for real scenes is difficult and thussuch data is rare. Therefore, recent end-to-end convolutional networks foroptical flow rely on synthetic datasets for supervision, but the domainmismatch between training and test scenarios continues to be a challenge.Inspired by classical energy-based optical flow methods, we design anunsupervised loss based on occlusion-aware bidirectional flow estimation andthe robust census transform to circumvent the need for ground truth flow. Onthe KITTI benchmarks, our unsupervised approach outperforms previousunsupervised deep networks by a large margin, and is even more accurate thansimilar supervised methods trained on synthetic datasets alone. By optionallyfine-tuning on the KITTI training data, our method achieves competitive opticalflow accuracy on the KITTI 2012 and 2015 benchmarks, thus in addition enablinggeneric pre-training of supervised networks for datasets with limited amountsof ground truth.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '177',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.07837v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15341806594437855223&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 102: {'ID': 102,\n",
       "  'title': 'Countering Adversarial Images using Input Transformations',\n",
       "  'authors': ['Moustapha Cisse',\n",
       "   'Chuan Guo',\n",
       "   'Laurens van der Maaten',\n",
       "   'Mayank Rana'],\n",
       "  'published': '2017-10-31T21:22:16Z',\n",
       "  'updated': '2018-01-25T19:04:48Z',\n",
       "  'abstract': 'This paper investigates strategies that defend against adversarial-exampleattacks on image-classification systems by transforming the inputs beforefeeding them to the system. Specifically, we study applying imagetransformations such as bit-depth reduction, JPEG compression, total varianceminimization, and image quilting before feeding the image to a convolutionalnetwork classifier. Our experiments on ImageNet show that total varianceminimization and image quilting are very effective defenses in practice, inparticular, when the network is trained on transformed images. The strength ofthose defenses lies in their non-differentiable nature and their inherentrandomness, which makes it difficult for an adversary to circumvent thedefenses. Our best defense eliminates 60% of strong gray-box and 90% of strongblack-box attacks by a variety of major attack methods',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '394',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00117v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3375700876994648267&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 103: {'ID': 103,\n",
       "  'title': 'Kernel Interpolation for Scalable Structured Gaussian Processes  (KISS-GP)',\n",
       "  'authors': ['Andrew Gordon Wilson', 'Hannes Nickisch'],\n",
       "  'published': '2015-03-03T19:06:17Z',\n",
       "  'updated': '2015-03-03T19:06:17Z',\n",
       "  'abstract': 'We introduce a new structured kernel interpolation (SKI) framework, whichgeneralises and unifies inducing point methods for scalable Gaussian processes(GPs). SKI methods produce kernel approximations for fast computations throughkernel interpolation. The SKI framework clarifies how the quality of aninducing point approach depends on the number of inducing (aka interpolation)points, interpolation strategy, and GP covariance kernel. SKI also provides amechanism to create new scalable kernel methods, through choosing differentkernel interpolation strategies. Using SKI, with local cubic kernelinterpolation, we introduce KISS-GP, which is 1) more scalable than inducingpoint alternatives, 2) naturally enables Kronecker and Toeplitz algebra forsubstantial additional gains in scalability, without requiring any grid data,and 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n)time and storage for GP inference. We evaluate KISS-GP for kernel matrixapproximation, kernel learning, and natural sound modelling.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 1775-1784',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.01057v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10688700732600694368&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 104: {'ID': 104,\n",
       "  'title': 'Meta Networks',\n",
       "  'authors': ['Hong Yu', 'Tsendsuren Munkhdalai'],\n",
       "  'published': '2017-03-02T15:52:55Z',\n",
       "  'updated': '2017-06-08T16:12:40Z',\n",
       "  'abstract': 'Neural networks have been successfully applied in applications with a largeamount of labeled data. However, the task of rapid generalization on newconcepts with small training data while preserving performances on previouslylearned ones still presents a significant challenge to neural network models.In this work, we introduce a novel meta learning method, Meta Networks(MetaNet), that learns a meta-level knowledge across tasks and shifts itsinductive biases via fast parameterization for rapid generalization. Whenevaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achievea near human-level performance and outperform the baseline approaches by up to6% accuracy. We demonstrate several appealing properties of MetaNet relating togeneralization and continual learning.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2554-2563',\n",
       "  'citations': '274',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00837v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=373430955020553964&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 105: {'ID': 105,\n",
       "  'title': 'Born Again Neural Networks',\n",
       "  'authors': ['Tommaso Furlanello',\n",
       "   'Laurent Itti',\n",
       "   'Zachary C. Lipton',\n",
       "   'Michael Tschannen',\n",
       "   'Anima Anandkumar'],\n",
       "  'published': '2018-05-12T19:48:50Z',\n",
       "  'updated': '2018-06-29T10:46:28Z',\n",
       "  'abstract': \"Knowledge distillation (KD) consists of transferring knowledge from onemachine learning model (the teacher}) to another (the student). Commonly, theteacher is a high-capacity model with formidable performance, while the studentis more compact. By transferring knowledge, one hopes to benefit from thestudent's compactness. %we desire a compact model with performance close to theteacher's. We study KD from a new perspective: rather than compressing models,we train students parameterized identically to their teachers. Surprisingly,these {Born-Again Networks (BANs), outperform their teachers significantly,both on computer vision and language modeling tasks. Our experiments with BANsbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additionalexperiments explore two distillation objectives: (i) Confidence-Weighted byTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).Both methods elucidate the essential components of KD, demonstrating a role ofthe teacher outputs on both predicted and non-predicted classes. We presentexperiments with students of various capacities, focusing on the under-exploredcase where students overpower teachers. Our experiments show significantadvantages from transferring knowledge between DenseNets and ResNets in eitherdirection.\",\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 1602-1611',\n",
       "  'citations': '186',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.04770v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7598194009838654531&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 106: {'ID': 106,\n",
       "  'title': 'Cooperative Inverse Reinforcement Learning',\n",
       "  'authors': ['Pieter Abbeel',\n",
       "   'Dylan Hadfield-Menell',\n",
       "   'Stuart Russell',\n",
       "   'Anca Dragan'],\n",
       "  'published': '2016-06-09T22:39:54Z',\n",
       "  'updated': '2016-11-12T20:33:43Z',\n",
       "  'abstract': \"For an autonomous system to be helpful to humans and to pose no unwarrantedrisks, it needs to align its values with those of the humans in its environmentin such a way that its actions contribute to the maximization of value for thehumans. We propose a formal definition of the value alignment problem ascooperative inverse reinforcement learning (CIRL). A CIRL problem is acooperative, partial-information game with two agents, human and robot; bothare rewarded according to the human's reward function, but the robot does notinitially know what this is. In contrast to classical IRL, where the human isassumed to act optimally in isolation, optimal CIRL solutions produce behaviorssuch as active teaching, active learning, and communicative actions that aremore effective in achieving value alignment. We show that computing optimaljoint policies in CIRL games can be reduced to solving a POMDP, prove thatoptimality in isolation is suboptimal in CIRL, and derive an approximate CIRLalgorithm.\",\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '221',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.03137v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15627132950356078183&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 107: {'ID': 107,\n",
       "  'title': 'On Detecting Adversarial Perturbations',\n",
       "  'authors': ['Volker Fischer',\n",
       "   'Jan Hendrik Metzen',\n",
       "   'Tim Genewein',\n",
       "   'Bastian Bischoff'],\n",
       "  'published': '2017-02-14T15:44:26Z',\n",
       "  'updated': '2017-02-21T06:53:38Z',\n",
       "  'abstract': 'Machine learning and deep learning in particular has advanced tremendously onperceptual tasks in recent years. However, it remains vulnerable againstadversarial perturbations of the input that have been crafted specifically tofool the system while being quasi-imperceptible to a human. In this work, wepropose to augment deep neural networks with a small \"detector\" subnetworkwhich is trained on the binary classification task of distinguishing genuinedata from data containing adversarial perturbations. Our method is orthogonalto prior work on addressing adversarial perturbations, which has mostly focusedon making the classification network itself more robust. We show empiricallythat adversarial perturbations can be detected surprisingly well even thoughthey are quasi-imperceptible to humans. Moreover, while the detectors have beentrained to detect only a specific adversary, they generalize to similar andweaker adversaries. In addition, we propose an adversarial attack that foolsboth the classifier and the detector and a novel training procedure for thedetector that counteracts this attack.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '398',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.04267v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2337805679039722044&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 108: {'ID': 108,\n",
       "  'title': 'Adversarial examples in the physical world',\n",
       "  'authors': ['Samy Bengio', 'Alexey Kurakin', 'Ian Goodfellow'],\n",
       "  'published': '2016-07-08T21:12:11Z',\n",
       "  'updated': '2017-02-11T00:39:39Z',\n",
       "  'abstract': 'Most existing machine learning classifiers are highly vulnerable toadversarial examples. An adversarial example is a sample of input data whichhas been modified very slightly in a way that is intended to cause a machinelearning classifier to misclassify it. In many cases, these modifications canbe so subtle that a human observer does not even notice the modification atall, yet the classifier still makes a mistake. Adversarial examples posesecurity concerns because they could be used to perform an attack on machinelearning systems, even if the adversary has no access to the underlying model.Up to now, all previous work have assumed a threat model in which the adversarycan feed data directly into the machine learning classifier. This is not alwaysthe case for systems operating in the physical world, for example those whichare using signals from cameras and other sensors as an input. This paper showsthat even in such physical world scenarios, machine learning systems arevulnerable to adversarial examples. We demonstrate this by feeding adversarialimages obtained from cell-phone camera to an ImageNet Inception classifier andmeasuring the classification accuracy of the system. We find that a largefraction of adversarial examples are classified incorrectly even when perceivedthrough the camera.',\n",
       "  'categories': ['cs.CV', 'cs.CR', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '1687',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.02533v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=263531058904899909&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 109: {'ID': 109,\n",
       "  'title': 'Visual Dynamics: Probabilistic Future Frame Synthesis via Cross  Convolutional Networks',\n",
       "  'authors': ['Jiajun Wu',\n",
       "   'Katherine L. Bouman',\n",
       "   'Tianfan Xue',\n",
       "   'William T. Freeman'],\n",
       "  'published': '2016-07-09T08:41:40Z',\n",
       "  'updated': '2016-07-09T08:41:40Z',\n",
       "  'abstract': 'We study the problem of synthesizing a number of likely future frames from asingle input image. In contrast to traditional methods, which have tackled thisproblem in a deterministic or non-parametric way, we propose a novel approachthat models future frames in a probabilistic manner. Our probabilistic modelmakes it possible for us to sample and synthesize many possible future framesfrom a single input image. Future frame synthesis is challenging, as itinvolves low- and high-level image and motion understanding. We propose a novelnetwork structure, namely a Cross Convolutional Network to aid in synthesizingfuture frames; this network structure encodes image and motion information asfeature maps and convolutional kernels, respectively. In experiments, our modelperforms well on synthetic data, such as 2D shapes and animated game sprites,as well as on real-wold videos. We also show that our model can be applied totasks such as visual analogy-making, and present an analysis of the learnednetwork representations.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '306',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.02586v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6484494541166161719&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 110: {'ID': 110,\n",
       "  'title': 'Deep Variational Information Bottleneck',\n",
       "  'authors': ['Ian Fischer',\n",
       "   'Kevin Murphy',\n",
       "   'Joshua V. Dillon',\n",
       "   'Alexander A. Alemi'],\n",
       "  'published': '2016-12-01T20:12:40Z',\n",
       "  'updated': '2019-10-23T22:47:44Z',\n",
       "  'abstract': 'We present a variational approximation to the information bottleneck ofTishby et al. (1999). This variational approach allows us to parameterize theinformation bottleneck model using a neural network and leverage thereparameterization trick for efficient training. We call this method \"DeepVariational Information Bottleneck\", or Deep VIB. We show that models trainedwith the VIB objective outperform those that are trained with other forms ofregularization, in terms of generalization performance and robustness toadversarial attack.',\n",
       "  'categories': ['cs.LG', 'cs.IT', 'math.IT'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '343',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.00410v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7425625104303674821&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 111: {'ID': 111,\n",
       "  'title': 'InfoGAN: Interpretable Representation Learning by Information Maximizing  Generative Adversarial Nets',\n",
       "  'authors': ['Rein Houthooft',\n",
       "   'Xi Chen',\n",
       "   'Yan Duan',\n",
       "   'Ilya Sutskever',\n",
       "   'John Schulman',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2016-06-12T02:14:31Z',\n",
       "  'updated': '2016-06-12T02:14:31Z',\n",
       "  'abstract': 'This paper describes InfoGAN, an information-theoretic extension to theGenerative Adversarial Network that is able to learn disentangledrepresentations in a completely unsupervised manner. InfoGAN is a generativeadversarial network that also maximizes the mutual information between a smallsubset of the latent variables and the observation. We derive a lower bound tothe mutual information objective that can be optimized efficiently, and showthat our training procedure can be interpreted as a variation of the Wake-Sleepalgorithm. Specifically, InfoGAN successfully disentangles writing styles fromdigit shapes on the MNIST dataset, pose from lighting of 3D rendered images,and background digits from the central digit on the SVHN dataset. It alsodiscovers visual concepts that include hair styles, presence/absence ofeyeglasses, and emotions on the CelebA face dataset. Experiments show thatInfoGAN learns interpretable representations that are competitive withrepresentations learned by existing fully supervised methods.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1957',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.03657v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14881367722116467754&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 112: {'ID': 112,\n",
       "  'title': 'PyTorch: An Imperative Style, High-Performance Deep Learning Library',\n",
       "  'authors': ['Alykhan Tejani',\n",
       "   'Adam Paszke',\n",
       "   'Luca Antiga',\n",
       "   'Trevor Killeen',\n",
       "   'Zach DeVito',\n",
       "   'Soumith Chintala',\n",
       "   'James Bradbury',\n",
       "   'Natalia Gimelshein',\n",
       "   'Benoit Steiner',\n",
       "   'Lu Fang',\n",
       "   'Alban Desmaison',\n",
       "   'Sasank Chilamkurthy',\n",
       "   'Junjie Bai',\n",
       "   'Edward Yang',\n",
       "   'Gregory Chanan',\n",
       "   'Adam Lerer',\n",
       "   'Francisco Massa',\n",
       "   'Zeming Lin',\n",
       "   'Sam Gross',\n",
       "   'Andreas Köpf',\n",
       "   'Martin Raison'],\n",
       "  'published': '2019-12-03T22:06:05Z',\n",
       "  'updated': '2019-12-03T22:06:05Z',\n",
       "  'abstract': 'Deep learning frameworks have often focused on either usability or speed, butnot both. PyTorch is a machine learning library that shows that these two goalsare in fact compatible: it provides an imperative and Pythonic programmingstyle that supports code as a model, makes debugging easy and is consistentwith other popular scientific computing libraries, while remaining efficientand supporting hardware accelerators such as GPUs.  In this paper, we detail the principles that drove the implementation ofPyTorch and how they are reflected in its architecture. We emphasize that everyaspect of PyTorch is a regular Python program under the full control of itsuser. We also explain how the careful and pragmatic implementation of the keycomponents of its runtime enables them to work together to achieve compellingperformance.  We demonstrate the efficiency of individual subsystems, as well as theoverall speed of PyTorch on several common benchmarks.',\n",
       "  'categories': ['cs.LG', 'cs.MS', 'stat.ML'],\n",
       "  'journal': 'NeurIPS, 8024-8035',\n",
       "  'citations': '1013',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.01703v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3528934790668989119&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 113: {'ID': 113,\n",
       "  'title': 'Sample Efficient Actor-Critic with Experience Replay',\n",
       "  'authors': ['Nicolas Heess',\n",
       "   'Nando de Freitas',\n",
       "   'Victor Bapst',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Ziyu Wang',\n",
       "   'Remi Munos',\n",
       "   'Volodymyr Mnih'],\n",
       "  'published': '2016-11-03T23:21:32Z',\n",
       "  'updated': '2017-07-10T14:38:10Z',\n",
       "  'abstract': 'This paper presents an actor-critic deep reinforcement learning agent withexperience replay that is stable, sample efficient, and performs remarkablywell on challenging environments, including the discrete 57-game Atari domainand several continuous control problems. To achieve this, the paper introducesseveral innovations, including truncated importance sampling with biascorrection, stochastic dueling network architectures, and a new trust regionpolicy optimization method.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '355',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01224v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8369222693188103740&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 114: {'ID': 114,\n",
       "  'title': 'Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks  with Symmetric Skip Connections',\n",
       "  'authors': ['Yu-Bin Yang', 'Xiao-Jiao Mao', 'Chunhua Shen'],\n",
       "  'published': '2016-03-30T07:16:05Z',\n",
       "  'updated': '2016-09-01T01:15:42Z',\n",
       "  'abstract': 'In this paper, we propose a very deep fully convolutional encoding-decodingframework for image restoration such as denoising and super-resolution. Thenetwork is composed of multiple layers of convolution and de-convolutionoperators, learning end-to-end mappings from corrupted images to the originalones. The convolutional layers act as the feature extractor, which capture theabstraction of image contents while eliminating noises/corruptions.De-convolutional layers are then used to recover the image details. We proposeto symmetrically link convolutional and de-convolutional layers with skip-layerconnections, with which the training converges much faster and attains ahigher-quality local optimum. First, The skip connections allow the signal tobe back-propagated to bottom layers directly, and thus tackles the problem ofgradient vanishing, making training deep networks easier and achievingrestoration performance gains consequently. Second, these skip connections passimage details from convolutional layers to de-convolutional layers, which isbeneficial in recovering the original image. Significantly, with the largecapacity, we can handle different levels of noises using a single model.Experimental results show that our network achieves better performance than allpreviously reported state-of-the-art methods.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '691',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.09056v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9889699634650873051&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 115: {'ID': 115,\n",
       "  'title': 'Regularization With Stochastic Transformations and Perturbations for  Deep Semi-Supervised Learning',\n",
       "  'authors': ['Tolga Tasdizen', 'Mehran Javanmardi', 'Mehdi Sajjadi'],\n",
       "  'published': '2016-06-14T22:30:08Z',\n",
       "  'updated': '2016-06-14T22:30:08Z',\n",
       "  'abstract': 'Effective convolutional neural networks are trained on large sets of labeleddata. However, creating large labeled datasets is a very costly andtime-consuming task. Semi-supervised learning uses unlabeled data to train amodel with higher accuracy when there is a limited set of labeled dataavailable. In this paper, we consider the problem of semi-supervised learningwith convolutional neural networks. Techniques such as randomized dataaugmentation, dropout and random max-pooling provide better generalization andstability for classifiers that are trained using gradient descent. Multiplepasses of an individual sample through the network might lead to differentpredictions due to the non-deterministic behavior of these techniques. Wepropose an unsupervised loss function that takes advantage of the stochasticnature of these methods and minimizes the difference between the predictions ofmultiple passes of a training sample through the network. We evaluate theproposed method on several benchmark datasets.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.04586v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=811577089436189841&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 116: {'ID': 116,\n",
       "  'title': 'Control of Memory, Active Perception, and Action in Minecraft',\n",
       "  'authors': ['Satinder Singh',\n",
       "   'Valliappa Chockalingam',\n",
       "   'Honglak Lee',\n",
       "   'Junhyuk Oh'],\n",
       "  'published': '2016-05-30T07:40:13Z',\n",
       "  'updated': '2016-05-30T07:40:13Z',\n",
       "  'abstract': 'In this paper, we introduce a new set of reinforcement learning (RL) tasks inMinecraft (a flexible 3D world). We then use these tasks to systematicallycompare and contrast existing deep reinforcement learning (DRL) architectureswith our new memory-based DRL architectures. These tasks are designed toemphasize, in a controllable manner, issues that pose challenges for RL methodsincluding partial observability (due to first-person visual observations),delayed rewards, high-dimensional visual observations, and the need to useactive perception in a correct manner so as to perform well in the tasks. Whilethese tasks are conceptually simple to describe, by virtue of having all ofthese challenges simultaneously they are difficult for current DRLarchitectures. Additionally, we evaluate the generalization performance of thearchitectures on environments not used during training. The experimentalresults show that our new architectures generalize to unseen environmentsbetter than existing DRL architectures.',\n",
       "  'categories': ['cs.AI', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICML, 2790-2799',\n",
       "  'citations': '172',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.09128v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3224107450664524795&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 117: {'ID': 117,\n",
       "  'title': 'ImageNet-trained CNNs are biased towards texture; increasing shape bias  improves accuracy and robustness',\n",
       "  'authors': ['Matthias Bethge',\n",
       "   'Claudio Michaelis',\n",
       "   'Robert Geirhos',\n",
       "   'Felix A. Wichmann',\n",
       "   'Wieland Brendel',\n",
       "   'Patricia Rubisch'],\n",
       "  'published': '2018-11-29T15:04:05Z',\n",
       "  'updated': '2019-01-14T13:59:09Z',\n",
       "  'abstract': 'Convolutional Neural Networks (CNNs) are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a texture-shape cue conflict. We show thatImageNet-trained CNNs are strongly biased towards recognising textures ratherthan shapes, which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture (ResNet-50) that learns a texture-basedrepresentation on ImageNet is able to learn a shape-based representationinstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwell-controlled psychophysical lab setting (nine experiments totalling 48,560psychophysical trials across 97 observers) and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortions,highlighting advantages of a shape-based representation.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG', 'q-bio.NC', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '318',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.12231v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14190455085351957023&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 118: {'ID': 118,\n",
       "  'title': 'Adversarial Variational Bayes: Unifying Variational Autoencoders and  Generative Adversarial Networks',\n",
       "  'authors': ['Lars Mescheder', 'Sebastian Nowozin', 'Andreas Geiger'],\n",
       "  'published': '2017-01-17T15:18:31Z',\n",
       "  'updated': '2018-06-11T12:19:02Z',\n",
       "  'abstract': 'Variational Autoencoders (VAEs) are expressive latent variable models thatcan be used to learn complex probability distributions from training data.However, the quality of the resulting model crucially relies on theexpressiveness of the inference model. We introduce Adversarial VariationalBayes (AVB), a technique for training Variational Autoencoders with arbitrarilyexpressive inference models. We achieve this by introducing an auxiliarydiscriminative network that allows to rephrase the maximum-likelihood-problemas a two-player game, hence establishing a principled connection between VAEsand Generative Adversarial Networks (GANs). We show that in the nonparametriclimit our method yields an exact maximum-likelihood assignment for theparameters of the generative model, as well as the exact posterior distributionover the latent variables given an observation. Contrary to competingapproaches which combine VAEs with GANs, our approach has a clear theoreticaljustification, retains most advantages of standard Variational Autoencoders andis easy to implement.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 2391-2400',\n",
       "  'citations': '292',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.04722v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12656834929147362081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 119: {'ID': 119,\n",
       "  'title': 'Axiomatic Attribution for Deep Networks',\n",
       "  'authors': ['Mukund Sundararajan', 'Qiqi Yan', 'Ankur Taly'],\n",
       "  'published': '2017-03-04T00:18:49Z',\n",
       "  'updated': '2017-06-13T01:52:38Z',\n",
       "  'abstract': 'We study the problem of attributing the prediction of a deep network to itsinput features, a problem previously studied by several other works. Weidentify two fundamental axioms---Sensitivity and Implementation Invariancethat attribution methods ought to satisfy. We show that they are not satisfiedby most known attribution methods, which we consider to be a fundamentalweakness of those methods. We use the axioms to guide the design of a newattribution method called Integrated Gradients. Our method requires nomodification to the original network and is extremely simple to implement; itjust needs a few calls to the standard gradient operator. We apply this methodto a couple of image models, a couple of text models and a chemistry model,demonstrating its ability to debug networks, to extract rules from a network,and to enable users to engage with models better.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 3319-3328',\n",
       "  'citations': '696',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01365v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6002490314140284060&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 120: {'ID': 120,\n",
       "  'title': 'Hierarchical Multiscale Recurrent Neural Networks',\n",
       "  'authors': ['Sungjin Ahn', 'Junyoung Chung', 'Yoshua Bengio'],\n",
       "  'published': '2016-09-06T19:37:57Z',\n",
       "  'updated': '2017-03-09T05:22:52Z',\n",
       "  'abstract': 'Learning both hierarchical and temporal representation has been among thelong-standing challenges of recurrent neural networks. Multiscale recurrentneural networks have been considered as a promising approach to resolve thisissue, yet there has been a lack of empirical evidence showing that this typeof models can actually capture the temporal dependencies by discovering thelatent hierarchical structure of the sequence. In this paper, we propose anovel multiscale approach, called the hierarchical multiscale recurrent neuralnetworks, which can capture the latent hierarchical structure in the sequenceby encoding the temporal dependencies with different timescales using a novelupdate mechanism. We show some evidence that our proposed multiscalearchitecture can discover underlying hierarchical structure in the sequenceswithout using explicit boundary information. We evaluate our proposed model oncharacter-level language modelling and handwriting sequence modelling.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '339',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.01704v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3631406206229660252&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 121: {'ID': 121,\n",
       "  'title': 'FeUdal Networks for Hierarchical Reinforcement Learning',\n",
       "  'authors': ['Alexander Sasha Vezhnevets',\n",
       "   'Nicolas Heess',\n",
       "   'Simon Osindero',\n",
       "   'Max Jaderberg',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Tom Schaul',\n",
       "   'David Silver'],\n",
       "  'published': '2017-03-03T14:05:11Z',\n",
       "  'updated': '2017-03-06T18:17:18Z',\n",
       "  'abstract': 'We introduce FeUdal Networks (FuNs): a novel architecture for hierarchicalreinforcement learning. Our approach is inspired by the feudal reinforcementlearning proposal of Dayan and Hinton, and gains power and efficacy bydecoupling end-to-end learning across multiple levels -- allowing it to utilisedifferent resolutions of time. Our framework employs a Manager module and aWorker module. The Manager operates at a lower temporal resolution and setsabstract goals which are conveyed to and enacted by the Worker. The Workergenerates primitive actions at every tick of the environment. The decoupledstructure of FuN conveys several benefits -- in addition to facilitating verylong timescale credit assignment it also encourages the emergence ofsub-policies associated with different goals set by the Manager. Theseproperties allow FuN to dramatically outperform a strong baseline agent ontasks that involve long-term credit assignment or memorisation. We demonstratethe performance of our proposed system on a range of tasks from the ATARI suiteand also from a 3D DeepMind Lab environment.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'ICML, 3540-3549',\n",
       "  'citations': '329',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01161v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2074247135017163310&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 122: {'ID': 122,\n",
       "  'title': 'Stein Variational Gradient Descent: A General Purpose Bayesian Inference  Algorithm',\n",
       "  'authors': ['Qiang Liu', 'Dilin Wang'],\n",
       "  'published': '2016-08-16T03:24:20Z',\n",
       "  'updated': '2019-09-09T17:31:39Z',\n",
       "  'abstract': \"We propose a general purpose variational inference algorithm that forms anatural counterpart of gradient descent for optimization. Our methoditeratively transports a set of particles to match the target distribution, byapplying a form of functional gradient descent that minimizes the KLdivergence. Empirical studies are performed on various real world models anddatasets, on which our method is competitive with existing state-of-the-artmethods. The derivation of our method is based on a new theoretical result thatconnects the derivative of KL divergence under smooth transforms with Stein'sidentity and a recently proposed kernelized Stein discrepancy, which is ofindependent interest.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '296',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.04471v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14137569249878560716&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 123: {'ID': 123,\n",
       "  'title': 'Provable defenses against adversarial examples via the convex outer  adversarial polytope',\n",
       "  'authors': ['Eric Wong', 'J. Zico Kolter'],\n",
       "  'published': '2017-11-02T17:59:24Z',\n",
       "  'updated': '2018-06-08T19:04:49Z',\n",
       "  'abstract': 'We propose a method to learn deep ReLU-based classifiers that are provablyrobust against norm-bounded adversarial perturbations on the training data. Forpreviously unseen examples, the approach is guaranteed to detect alladversarial examples, though it may flag some non-adversarial examples as well.The basic idea is to consider a convex outer approximation of the set ofactivations reachable through a norm-bounded perturbation, and we develop arobust optimization procedure that minimizes the worst case loss over thisouter region (via a linear program). Crucially, we show that the dual problemto this linear program can be represented itself as a deep network similar tothe backpropagation network, leading to very efficient optimization approachesthat produce guaranteed bounds on the robust loss. The end result is that byexecuting a few more forward and backward passes through a slightly modifiedversion of the original network (though possibly with much larger batch sizes),we can learn a classifier that is provably robust to any norm-boundedadversarial attack. We illustrate the approach on a number of tasks to trainclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce aconvolutional classifier that provably has less than 5.8% test error for anyadversarial attack with bounded $\\\\ell_\\\\infty$ norm less than $\\\\epsilon = 0.1$),and code for all experiments in the paper is available athttps://github.com/locuslab/convex_adversarial.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'math.OC'],\n",
       "  'journal': 'ICML, 5283-5292',\n",
       "  'citations': '348',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00851v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8192568202377907397&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 124: {'ID': 124,\n",
       "  'title': 'Robustness May Be at Odds with Accuracy',\n",
       "  'authors': ['Dimitris Tsipras',\n",
       "   'Shibani Santurkar',\n",
       "   'Logan Engstrom',\n",
       "   'Aleksander Madry',\n",
       "   'Alexander Turner'],\n",
       "  'published': '2018-05-30T18:00:32Z',\n",
       "  'updated': '2019-09-09T08:09:25Z',\n",
       "  'abstract': 'We show that there may exist an inherent tension between the goal ofadversarial robustness and that of standard generalization. Specifically,training robust models may not only be more resource-consuming, but also leadto a reduction of standard accuracy. We demonstrate that this trade-off betweenthe standard accuracy of a model and its robustness to adversarialperturbations provably exists in a fairly simple and natural setting. Thesefindings also corroborate a similar phenomenon observed empirically in morecomplex settings. Further, we argue that this phenomenon is a consequence ofrobust classifiers learning fundamentally different feature representationsthan standard classifiers. These differences, in particular, seem to result inunexpected benefits: the representations learned by robust models tend to alignbetter with salient data characteristics and human perception.',\n",
       "  'categories': ['stat.ML', 'cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '272',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.12152v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5850945088404252192&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 125: {'ID': 125,\n",
       "  'title': 'Learning both Weights and Connections for Efficient Neural Networks',\n",
       "  'authors': ['William J. Dally', 'John Tran', 'Song Han', 'Jeff Pool'],\n",
       "  'published': '2015-06-08T19:28:43Z',\n",
       "  'updated': '2015-10-30T23:29:27Z',\n",
       "  'abstract': 'Neural networks are both computationally intensive and memory intensive,making them difficult to deploy on embedded systems. Also, conventionalnetworks fix the architecture before training starts; as a result, trainingcannot improve the architecture. To address these limitations, we describe amethod to reduce the storage and computation required by neural networks by anorder of magnitude without affecting their accuracy by learning only theimportant connections. Our method prunes redundant connections using athree-step method. First, we train the network to learn which connections areimportant. Next, we prune the unimportant connections. Finally, we retrain thenetwork to fine tune the weights of the remaining connections. On the ImageNetdataset, our method reduced the number of parameters of AlexNet by a factor of9x, from 61 million to 6.7 million, without incurring accuracy loss. Similarexperiments with VGG-16 found that the number of parameters can be reduced by13x, from 138 million to 10.3 million, again with no loss of accuracy.',\n",
       "  'categories': ['cs.NE', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '2416',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02626v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6338930303179684776&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 126: {'ID': 126,\n",
       "  'title': 'Pose Guided Person Image Generation',\n",
       "  'authors': ['Qianru Sun',\n",
       "   'Xu Jia',\n",
       "   'Liqian Ma',\n",
       "   'Tinne Tuytelaars',\n",
       "   'Bernt Schiele',\n",
       "   'Luc Van Gool'],\n",
       "  'published': '2017-05-25T21:29:07Z',\n",
       "  'updated': '2018-01-28T09:25:08Z',\n",
       "  'abstract': 'This paper proposes the novel Pose Guided Person Generation Network (PG$^2$)that allows to synthesize person images in arbitrary poses, based on an imageof that person and a novel pose. Our generation framework PG$^2$ utilizes thepose information explicitly and consists of two key stages: pose integrationand image refinement. In the first stage the condition image and the targetpose are fed into a U-Net-like network to generate an initial but coarse imageof the person with the target pose. The second stage then refines the initialand blurry result by training a U-Net-like generator in an adversarial way.Extensive experimental results on both 128$\\\\times$64 re-identification imagesand 256$\\\\times$256 fashion photos show that our model generates high-qualityperson images with convincing details.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '309',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.09368v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4891149081490254273&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 127: {'ID': 127,\n",
       "  'title': 'Learning to Answer Questions From Image Using Convolutional Neural  Network',\n",
       "  'authors': ['Hang Li', 'Zhengdong Lu', 'Lin Ma'],\n",
       "  'published': '2015-06-01T03:09:49Z',\n",
       "  'updated': '2015-11-13T09:54:59Z',\n",
       "  'abstract': 'In this paper, we propose to employ the convolutional neural network (CNN)for the image question answering (QA). Our proposed CNN provides an end-to-endframework with convolutional architectures for learning not only the image andquestion representations, but also their inter-modal interactions to producethe answer. More specifically, our model consists of three CNNs: one image CNNto encode the image content, one sentence CNN to compose the words of thequestion, and one multimodal convolution layer to learn their jointrepresentation for the classification in the space of candidate answer words.We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QAdatasets, which are two benchmark datasets for the image QA, with theperformances significantly outperforming the state-of-the-art.',\n",
       "  'categories': ['cs.CL', 'cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.00333v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15810845386202392485&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 128: {'ID': 128,\n",
       "  'title': 'Multiple Object Recognition with Visual Attention',\n",
       "  'authors': ['Koray Kavukcuoglu', 'Jimmy Ba', 'Volodymyr Mnih'],\n",
       "  'published': '2014-12-24T20:58:23Z',\n",
       "  'updated': '2015-04-23T16:49:23Z',\n",
       "  'abstract': 'We present an attention-based model for recognizing multiple objects inimages. The proposed model is a deep recurrent neural network trained withreinforcement learning to attend to the most relevant regions of the inputimage. We show that the model learns to both localize and recognize multipleobjects despite being given only class labels during training. We evaluate themodel on the challenging task of transcribing house number sequences fromGoogle Street View images and show that it is both more accurate than thestate-of-the-art convolutional networks and uses fewer parameters and lesscomputation.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '702',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.7755v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9270621198392182178&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 129: {'ID': 129,\n",
       "  'title': 'Group Equivariant Convolutional Networks',\n",
       "  'authors': ['Taco S. Cohen', 'Max Welling'],\n",
       "  'published': '2016-02-24T16:17:15Z',\n",
       "  'updated': '2016-06-03T10:54:16Z',\n",
       "  'abstract': 'We introduce Group equivariant Convolutional Neural Networks (G-CNNs), anatural generalization of convolutional neural networks that reduces samplecomplexity by exploiting symmetries. G-CNNs use G-convolutions, a new type oflayer that enjoys a substantially higher degree of weight sharing than regularconvolution layers. G-convolutions increase the expressive capacity of thenetwork without increasing the number of parameters. Group convolution layersare easy to use and can be implemented with negligible computational overheadfor discrete groups generated by translations, reflections and rotations.G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2990-2999',\n",
       "  'citations': '459',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.07576v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2225506382057001717&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 130: {'ID': 130,\n",
       "  'title': 'Teaching Machines to Read and Comprehend',\n",
       "  'authors': ['Tomáš Kočiský',\n",
       "   'Will Kay',\n",
       "   'Edward Grefenstette',\n",
       "   'Mustafa Suleyman',\n",
       "   'Karl Moritz Hermann',\n",
       "   'Phil Blunsom',\n",
       "   'Lasse Espeholt'],\n",
       "  'published': '2015-06-10T14:54:39Z',\n",
       "  'updated': '2015-11-19T15:43:23Z',\n",
       "  'abstract': 'Teaching machines to read natural language documents remains an elusivechallenge. Machine reading systems can be tested on their ability to answerquestions posed on the contents of documents that they have seen, but until nowlarge scale training and test datasets have been missing for this type ofevaluation. In this work we define a new methodology that resolves thisbottleneck and provides large scale supervised reading comprehension data. Thisallows us to develop a class of attention based deep neural networks that learnto read real documents and answer complex questions with minimal priorknowledge of language structure.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1635',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.03340v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5371787459515302436&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 131: {'ID': 131,\n",
       "  'title': 'TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep  Learning',\n",
       "  'authors': ['Wei Wen',\n",
       "   'Cong Xu',\n",
       "   'Hai Li',\n",
       "   'Yiran Chen',\n",
       "   'Chunpeng Wu',\n",
       "   'Feng Yan',\n",
       "   'Yandan Wang'],\n",
       "  'published': '2017-05-22T17:42:15Z',\n",
       "  'updated': '2017-12-29T02:51:48Z',\n",
       "  'abstract': 'High network communication cost for synchronizing gradients and parameters isthe well-known bottleneck of distributed training. In this work, we proposeTernGrad that uses ternary gradients to accelerate distributed deep learning indata parallelism. Our approach requires only three numerical levels {-1,0,1},which can aggressively reduce the communication time. We mathematically provethe convergence of TernGrad under the assumption of a bound on gradients.Guided by the bound, we propose layer-wise ternarizing and gradient clipping toimprove its convergence. Our experiments show that applying TernGrad on AlexNetdoes not incur any accuracy loss and can even improve accuracy. The accuracyloss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, aperformance model is proposed to study the scalability of TernGrad. Experimentsshow significant speed gains for various deep neural networks. Our source codeis available.',\n",
       "  'categories': ['cs.LG', 'cs.DC', 'cs.NE', 'I.2.6; I.5.1'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '289',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.07878v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10878522154628533487&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 132: {'ID': 132,\n",
       "  'title': 'Machine Learning Methods for Attack Detection in the Smart Grid',\n",
       "  'authors': ['Mete Ozay',\n",
       "   'Inaki Esnaola',\n",
       "   'Sanjeev R. Kulkarni',\n",
       "   'Fatos T. Yarman Vural',\n",
       "   'H. Vincent Poor'],\n",
       "  'published': '2015-03-22T19:38:45Z',\n",
       "  'updated': '2015-03-22T19:38:45Z',\n",
       "  'abstract': 'Attack detection problems in the smart grid are posed as statistical learningproblems for different attack scenarios in which the measurements are observedin batch or online settings. In this approach, machine learning algorithms areused to classify measurements as being either secure or attacked. An attackdetection framework is provided to exploit any available prior knowledge aboutthe system and surmount constraints arising from the sparse structure of theproblem in the proposed approach. Well-known batch and online learningalgorithms (supervised and semi-supervised) are employed with decision andfeature level fusion to model the attack detection problem. The relationshipsbetween statistical and geometric properties of attack vectors employed in theattack scenarios and learning algorithms are analyzed to detect unobservableattacks using statistical learning methods. The proposed algorithms areexamined on various IEEE test systems. Experimental analyses show that machinelearning algorithms can detect attacks with performances higher than the attackdetection algorithms which employ state vector estimation methods in theproposed attack detection framework.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'cs.SY'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 27 (8), 1773-1786',\n",
       "  'citations': '196',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.06468v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8039699353196777267&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 133: {'ID': 133,\n",
       "  'title': 'Gradient Descent Finds Global Minima of Deep Neural Networks',\n",
       "  'authors': ['Liwei Wang',\n",
       "   'Jason D. Lee',\n",
       "   'Simon S. Du',\n",
       "   'Xiyu Zhai',\n",
       "   'Haochuan Li'],\n",
       "  'published': '2018-11-09T07:39:59Z',\n",
       "  'updated': '2019-05-28T19:01:22Z',\n",
       "  'abstract': 'Gradient descent finds a global minimum in training deep neural networksdespite the objective function being non-convex. The current paper provesgradient descent achieves zero training loss in polynomial time for a deepover-parameterized neural network with residual connections (ResNet). Ouranalysis relies on the particular structure of the Gram matrix induced by theneural network architecture. This structure allows us to show the Gram matrixis stable throughout the training process and this stability implies the globaloptimality of the gradient descent algorithm. We further extend our analysis todeep residual convolutional neural networks and obtain a similar convergenceresult.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 1675-1685',\n",
       "  'citations': '240',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.03804v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6996824436391186988&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 134: {'ID': 134,\n",
       "  'title': 'The Numerics of GANs',\n",
       "  'authors': ['Lars Mescheder', 'Sebastian Nowozin', 'Andreas Geiger'],\n",
       "  'published': '2017-05-30T05:54:59Z',\n",
       "  'updated': '2018-06-11T13:12:41Z',\n",
       "  'abstract': 'In this paper, we analyze the numerics of common algorithms for trainingGenerative Adversarial Networks (GANs). Using the formalism of smoothtwo-player games we analyze the associated gradient vector field of GANtraining objectives. Our findings suggest that the convergence of currentalgorithms suffers due to two factors: i) presence of eigenvalues of theJacobian of the gradient vector field with zero real-part, and ii) eigenvalueswith big imaginary part. Using these findings, we design a new algorithm thatovercomes some of these limitations and has better convergence properties.Experimentally, we demonstrate its superiority on training common GANarchitectures and show convergence on GAN architectures that are known to benotoriously hard to train.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '208',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10461v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10067526666278916016&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 135: {'ID': 135,\n",
       "  'title': 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language  Understanding',\n",
       "  'authors': ['Omer Levy',\n",
       "   'Alex Wang',\n",
       "   'Amanpreet Singh',\n",
       "   'Samuel R. Bowman',\n",
       "   'Julian Michael',\n",
       "   'Felix Hill'],\n",
       "  'published': '2018-04-20T06:35:04Z',\n",
       "  'updated': '2019-02-22T23:53:34Z',\n",
       "  'abstract': 'For natural language understanding (NLU) technology to be maximally useful,both practically and as a scientific object of study, it must be general: itmust be able to process language in a way that is not exclusively tailored toany one specific task or dataset. In pursuit of this objective, we introducethe General Language Understanding Evaluation benchmark (GLUE), a tool forevaluating and analyzing the performance of models across a diverse range ofexisting NLU tasks. GLUE is model-agnostic, but it incentivizes sharingknowledge across tasks because certain tasks have very limited training data.We further provide a hand-crafted diagnostic test suite that enables detailedlinguistic analysis of NLU models. We evaluate baselines based on currentmethods for multi-task and transfer learning and find that they do notimmediately give substantial improvements over the aggregate performance oftraining a separate model per task, indicating room for improvement indeveloping general and robust NLU systems.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '619',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.07461v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17443412968683100072&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 136: {'ID': 136,\n",
       "  'title': 'Revisiting Semi-Supervised Learning with Graph Embeddings',\n",
       "  'authors': ['Zhilin Yang', 'Ruslan Salakhutdinov', 'William W. Cohen'],\n",
       "  'published': '2016-03-29T17:46:16Z',\n",
       "  'updated': '2016-05-26T23:57:09Z',\n",
       "  'abstract': 'We present a semi-supervised learning framework based on graph embeddings.Given a graph between instances, we train an embedding for each instance tojointly predict the class label and the neighborhood context in the graph. Wedevelop both transductive and inductive variants of our method. In thetransductive variant of our method, the class labels are determined by both thelearned embeddings and input feature vectors, while in the inductive variant,the embeddings are defined as a parametric function of the feature vectors, sopredictions can be made on instances not seen during training. On a large anddiverse set of benchmark tasks, including text classification, distantlysupervised entity extraction, and entity classification, we show improvedperformance over many of the existing models.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 40-48',\n",
       "  'citations': '577',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.08861v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1517411880091060899&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 137: {'ID': 137,\n",
       "  'title': 'Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning',\n",
       "  'authors': ['Jimmy Lei Ba', 'Emilio Parisotto', 'Ruslan Salakhutdinov'],\n",
       "  'published': '2015-11-19T20:17:27Z',\n",
       "  'updated': '2016-02-22T19:59:40Z',\n",
       "  'abstract': 'The ability to act in multiple environments and transfer previous knowledgeto new situations can be considered a critical aspect of any intelligent agent.Towards this goal, we define a novel method of multitask and transfer learningthat enables an autonomous agent to learn how to behave in multiple taskssimultaneously, and then generalize its knowledge to new domains. This method,termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and modelcompression techniques to train a single policy network that learns how to actin a set of distinct tasks by using the guidance of several expert teachers. Wethen show that the representations learnt by the deep policy network arecapable of generalizing to new tasks with no prior expert guidance, speeding uplearning in novel environments. Although our method can in general be appliedto a wide range of problems, we use Atari games as a testing environment todemonstrate these methods.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '288',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06342v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10238698941349147210&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 138: {'ID': 138,\n",
       "  'title': 'Unsupervised Domain Adaptation with Residual Transfer Networks',\n",
       "  'authors': ['Jianmin Wang',\n",
       "   'Michael I. Jordan',\n",
       "   'Mingsheng Long',\n",
       "   'Han Zhu'],\n",
       "  'published': '2016-02-14T09:47:30Z',\n",
       "  'updated': '2017-02-16T07:56:49Z',\n",
       "  'abstract': 'The recent success of deep neural networks relies on massive amounts oflabeled data. For a target task where labeled data is unavailable, domainadaptation can transfer a learner from a different source domain. In thispaper, we propose a new approach to domain adaptation in deep networks that canjointly learn adaptive classifiers and transferable features from labeled datain the source domain and unlabeled data in the target domain. We relax ashared-classifier assumption made by previous methods and assume that thesource classifier and target classifier differ by a residual function. Weenable classifier adaptation by plugging several layers into deep network toexplicitly learn the residual function with reference to the target classifier.We fuse features of multiple layers with tensor product and embed them intoreproducing kernel Hilbert spaces to match distributions for featureadaptation. The adaptation can be achieved in most feed-forward models byextending them with new residual layers and loss functions, which can betrained efficiently via back-propagation. Empirical evidence shows that the newapproach outperforms state of the art methods on standard domain adaptationbenchmarks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '534',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.04433v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12070836061117770706&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 139: {'ID': 139,\n",
       "  'title': 'Entropy-SGD: Biasing Gradient Descent Into Wide Valleys',\n",
       "  'authors': ['Christian Borgs',\n",
       "   'Yann LeCun',\n",
       "   'Anna Choromanska',\n",
       "   'Stefano Soatto',\n",
       "   'Riccardo Zecchina',\n",
       "   'Jennifer Chayes',\n",
       "   'Levent Sagun',\n",
       "   'Pratik Chaudhari',\n",
       "   'Carlo Baldassi'],\n",
       "  'published': '2016-11-06T20:22:49Z',\n",
       "  'updated': '2017-04-21T07:16:30Z',\n",
       "  'abstract': 'This paper proposes a new optimization algorithm called Entropy-SGD fortraining deep neural networks that is motivated by the local geometry of theenergy landscape. Local extrema with low generalization error have a largeproportion of almost-zero eigenvalues in the Hessian with very few positive ornegative eigenvalues. We leverage upon this observation to construct alocal-entropy-based objective function that favors well-generalizable solutionslying in large flat regions of the energy landscape, while avoidingpoorly-generalizable solutions located in the sharp valleys. Conceptually, ouralgorithm resembles two nested loops of SGD where we use Langevin dynamics inthe inner loop to compute the gradient of the local entropy before each updateof the weights. We show that the new objective has a smoother energy landscapeand show improved generalization over SGD using uniform stability, undercertain assumptions. Our experiments on convolutional and recurrent networksdemonstrate that Entropy-SGD compares favorably to state-of-the-art techniquesin terms of generalization error and training time.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '281',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01838v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=496423886429566828&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 140: {'ID': 140,\n",
       "  'title': 'Safe Model-based Reinforcement Learning with Stability Guarantees',\n",
       "  'authors': ['Matteo Turchetta',\n",
       "   'Felix Berkenkamp',\n",
       "   'Angela P. Schoellig',\n",
       "   'Andreas Krause'],\n",
       "  'published': '2017-05-23T22:20:08Z',\n",
       "  'updated': '2017-11-13T18:49:54Z',\n",
       "  'abstract': 'Reinforcement learning is a powerful paradigm for learning optimal policiesfrom experimental data. However, to find optimal policies, most reinforcementlearning algorithms explore all possible actions, which may be harmful forreal-world systems. As a consequence, learning algorithms are rarely applied onsafety-critical systems in the real world. In this paper, we present a learningalgorithm that explicitly considers safety, defined in terms of stabilityguarantees. Specifically, we extend control-theoretic results on Lyapunovstability verification and show how to use statistical models of the dynamicsto obtain high-performance control policies with provable stabilitycertificates. Moreover, under additional regularity assumptions in terms of aGaussian process prior, we prove that one can effectively and safely collectdata in order to learn about the dynamics and thus both improve controlperformance and expand the safe region of the state space. In our experiments,we show how the resulting algorithm can safely optimize a neural network policyon a simulated inverted pendulum, without the pendulum ever falling down.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG', 'cs.SY'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '217',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08551v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7457682645751123115&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 141: {'ID': 141,\n",
       "  'title': 'Convergence Analysis of Two-layer Neural Networks with ReLU Activation',\n",
       "  'authors': ['Yang Yuan', 'Yuanzhi Li'],\n",
       "  'published': '2017-05-28T02:11:10Z',\n",
       "  'updated': '2017-11-01T21:42:23Z',\n",
       "  'abstract': 'In recent years, stochastic gradient descent (SGD) based techniques hasbecome the standard tools for training neural networks. However, formaltheoretical understanding of why SGD can train neural networks in practice islargely missing.  In this paper, we make progress on understanding this mystery by providing aconvergence analysis for SGD on a rich subset of two-layer feedforward networkswith ReLU activations. This subset is characterized by a special structurecalled \"identity mapping\". We prove that, if input follows from Gaussiandistribution, with standard $O(1/\\\\sqrt{d})$ initialization of the weights, SGDconverges to the global minimum in polynomial number of steps. Unlike normalvanilla networks, the \"identity mapping\" makes our network asymmetric and thusthe global minimum is unique. To complement our theory, we are also able toshow experimentally that multi-layer networks with this mapping have betterperformance compared with normal vanilla networks.  Our convergence theorem differs from traditional non-convex optimizationtechniques. We show that SGD converges to optimal in \"two phases\": In phase I,the gradient points to the wrong direction, however, a potential function $g$gradually decreases. Then in phase II, SGD enters a nice one point convexregion and converges. We also show that the identity mapping is necessary forconvergence, as it moves the initial point to a better place for optimization.Experiment verifies our claims.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '267',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.09886v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=212149420094118161&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 142: {'ID': 142,\n",
       "  'title': 'Learning to Segment Object Candidates',\n",
       "  'authors': ['Piotr Dollar', 'Pedro O. Pinheiro', 'Ronan Collobert'],\n",
       "  'published': '2015-06-20T06:36:49Z',\n",
       "  'updated': '2015-09-01T16:03:01Z',\n",
       "  'abstract': 'Recent object detection systems rely on two critical steps: (1) a set ofobject proposals is predicted as efficiently as possible, and (2) this set ofcandidate proposals is then passed to an object classifier. Such approacheshave been shown they can be fast, while achieving the state of the art indetection performance. In this paper, we propose a new way to generate objectproposals, introducing an approach based on a discriminative convolutionalnetwork. Our model is trained jointly with two objectives: given an imagepatch, the first part of the system outputs a class-agnostic segmentation mask,while the second part of the system outputs the likelihood of the patch beingcentered on a full object. At test time, the model is efficiently applied onthe whole test image and generates a set of segmentation masks, each of thembeing assigned with a corresponding object likelihood score. We show that ourmodel yields significant improvements over state-of-the-art object proposalalgorithms. In particular, compared to previous approaches, our model obtainssubstantially higher object recall using fewer proposals. We also show that ourmodel is able to generalize to unseen categories it has not seen duringtraining. Unlike all previous approaches for generating object masks, we do notrely on edges, superpixels, or any other form of low-level segmentation.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '536',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.06204v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5802251840817059987&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 143: {'ID': 143,\n",
       "  'title': 'Stochastic Configuration Networks: Fundamentals and Algorithms',\n",
       "  'authors': ['Ming Li', 'Dianhui Wang'],\n",
       "  'published': '2017-02-10T14:24:16Z',\n",
       "  'updated': '2017-02-27T14:49:35Z',\n",
       "  'abstract': 'This paper contributes to a development of randomized methods for neuralnetworks. The proposed learner model is generated incrementally by stochasticconfiguration (SC) algorithms, termed as Stochastic Configuration Networks(SCNs). In contrast to the existing randomised learning algorithms for singlelayer feed-forward neural networks (SLFNNs), we randomly assign the inputweights and biases of the hidden nodes in the light of a supervisory mechanism,and the output weights are analytically evaluated in either constructive orselective manner. As fundamentals of SCN-based data modelling techniques, weestablish some theoretical results on the universal approximation property.Three versions of SC algorithms are presented for regression problems(applicable for classification problems as well) in this work. Simulationresults concerning both function approximation and real world data regressionindicate some remarkable merits of our proposed SCNs in terms of less humanintervention on the network size setting, the scope adaptation of randomparameters, fast learning and sound generalization.',\n",
       "  'categories': ['cs.NE'],\n",
       "  'journal': 'IEEE Transactions on Cybernetics 47 (10), 3466-3479',\n",
       "  'citations': '144',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.03180v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=188615526968185965&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 144: {'ID': 144,\n",
       "  'title': 'Generating Images from Captions with Attention',\n",
       "  'authors': ['Jimmy Lei Ba',\n",
       "   'Elman Mansimov',\n",
       "   'Emilio Parisotto',\n",
       "   'Ruslan Salakhutdinov'],\n",
       "  'published': '2015-11-09T18:18:53Z',\n",
       "  'updated': '2016-02-29T17:56:29Z',\n",
       "  'abstract': 'Motivated by the recent progress in generative models, we introduce a modelthat generates images from natural language descriptions. The proposed modeliteratively draws patches on a canvas, while attending to the relevant words inthe description. After training on Microsoft COCO, we compare our model withseveral baseline generative models on image generation and retrieval tasks. Wedemonstrate that our model produces higher quality samples than otherapproaches and generates images with novel scene compositions corresponding topreviously unseen captions in the dataset.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '221',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.02793v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13416680903946375913&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 145: {'ID': 145,\n",
       "  'title': 'Deep Predictive Coding Networks for Video Prediction and Unsupervised  Learning',\n",
       "  'authors': ['Gabriel Kreiman', 'David Cox', 'William Lotter'],\n",
       "  'published': '2016-05-25T23:58:55Z',\n",
       "  'updated': '2017-03-01T01:00:54Z',\n",
       "  'abstract': 'While great strides have been made in using deep learning algorithms to solvesupervised learning tasks, the problem of unsupervised learning - leveragingunlabeled examples to learn about the structure of a domain - remains adifficult unsolved challenge. Here, we explore prediction of future frames in avideo sequence as an unsupervised learning rule for learning about thestructure of the visual world. We describe a predictive neural network(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"from the neuroscience literature. These networks learn to predict future framesin a video sequence, with each layer in the network making local predictionsand only forwarding deviations from those predictions to subsequent networklayers. We show that these networks are able to robustly learn to predict themovement of synthetic (rendered) objects, and that in doing so, the networkslearn internal representations that are useful for decoding latent objectparameters (e.g. pose) that support object recognition with fewer trainingviews. We also show that these networks can scale to complex natural imagestreams (car-mounted camera videos), capturing key aspects of both egocentricmovement and the movement of objects in the visual scene, and therepresentation learned in this setting is useful for estimating the steeringangle. Altogether, these results suggest that prediction represents a powerfulframework for unsupervised learning, allowing for implicit learning of objectand scene structure.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'q-bio.NC'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '427',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.08104v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11254875356366916799&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 146: {'ID': 146,\n",
       "  'title': 'Slimmable Neural Networks',\n",
       "  'authors': ['Linjie Yang',\n",
       "   'Thomas Huang',\n",
       "   'Jiahui Yu',\n",
       "   'Jianchao Yang',\n",
       "   'Ning Xu'],\n",
       "  'published': '2018-12-21T03:36:48Z',\n",
       "  'updated': '2018-12-21T03:36:48Z',\n",
       "  'abstract': 'We present a simple and general method to train a single neural networkexecutable at different widths (number of channels in a layer), permittinginstant and adaptive accuracy-efficiency trade-offs at runtime. Instead oftraining individual networks with different width configurations, we train ashared network with switchable batch normalization. At runtime, the network canadjust its width on the fly according to on-device benchmarks and resourceconstraints, rather than downloading and offloading different models. Ourtrained networks, named slimmable neural networks, achieve similar (and in manycases better) ImageNet classification accuracy than individually trained modelsof MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widthsrespectively. We also demonstrate better performance of slimmable modelscompared with individual ones across a wide range of applications includingCOCO bounding-box object detection, instance segmentation and person keypointdetection without tuning hyper-parameters. Lastly we visualize and discuss thelearned features of slimmable networks. Code and models are available at:https://github.com/JiahuiYu/slimmable_networks',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '247',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.08928v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15212173000600372424&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 147: {'ID': 147,\n",
       "  'title': 'Towards Accurate Binary Convolutional Neural Network',\n",
       "  'authors': ['Cong Zhao', 'Xiaofan Lin', 'Wei Pan'],\n",
       "  'published': '2017-11-30T09:58:14Z',\n",
       "  'updated': '2017-11-30T09:58:14Z',\n",
       "  'abstract': 'We introduce a novel scheme to train binary convolutional neural networks(CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time.It has been known that using binary weights and activations drastically reducememory size and accesses, and can replace arithmetic operations with moreefficient bitwise operations, leading to much faster test-time inference andlower power consumption. However, previous works on binarizing CNNs usuallyresult in severe prediction accuracy degradation. In this paper, we addressthis issue with two major innovations: (1) approximating full-precision weightswith the linear combination of multiple binary weight bases; (2) employingmultiple binary activations to alleviate information loss. The implementationof the resulting binary CNN, denoted as ABC-Net, is shown to achieve muchcloser performance to its full-precision counterpart, and even reach thecomparable prediction accuracy on ImageNet and forest trail datasets, givenadequate binary weight bases and activations.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.11294v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9345699458847974423&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 148: {'ID': 148,\n",
       "  'title': 'MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks  on Corrupted Labels',\n",
       "  'authors': ['Li-Jia Li',\n",
       "   'Thomas Leung',\n",
       "   'Li Fei-Fei',\n",
       "   'Zhengyuan Zhou',\n",
       "   'Lu Jiang'],\n",
       "  'published': '2017-12-14T00:02:37Z',\n",
       "  'updated': '2018-08-13T21:27:39Z',\n",
       "  'abstract': 'Recent deep networks are capable of memorizing the entire data even when thelabels are completely random. To overcome the overfitting on corrupted labels,we propose a novel technique of learning another neural network, calledMentorNet, to supervise the training of the base deep networks, namely,StudentNet. During training, MentorNet provides a curriculum (sample weightingscheme) for StudentNet to focus on the sample the label of which is probablycorrect. Unlike the existing curriculum that is usually predefined by humanexperts, MentorNet learns a data-driven curriculum dynamically with StudentNet.Experimental results demonstrate that our approach can significantly improvethe generalization performance of deep networks trained on corrupted trainingdata. Notably, to the best of our knowledge, we achieve the best-publishedresult on WebVision, a large benchmark containing 2.2 million images ofreal-world noisy labels. The code are at https://github.com/google/mentornet',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 2309-2318',\n",
       "  'citations': '240',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.05055v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15068880048981139697&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 149: {'ID': 149,\n",
       "  'title': 'Improved Variational Autoencoders for Text Modeling using Dilated  Convolutions',\n",
       "  'authors': ['Taylor Berg-Kirkpatrick',\n",
       "   'Zichao Yang',\n",
       "   'Zhiting Hu',\n",
       "   'Ruslan Salakhutdinov'],\n",
       "  'published': '2017-02-27T04:16:01Z',\n",
       "  'updated': '2017-06-18T00:31:34Z',\n",
       "  'abstract': \"Recent work on generative modeling of text has found that variationalauto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTMlanguage models (Bowman et al., 2015). This negative result is so far poorlyunderstood, but has been attributed to the propensity of LSTM decoders toignore conditioning information from the encoder. In this paper, we experimentwith a new type of decoder for VAE: a dilated CNN. By changing the decoder'sdilation architecture, we control the effective context from previouslygenerated words. In experiments, we find that there is a trade off between thecontextual capacity of the decoder and the amount of encoding information used.We show that with the right decoder, VAE can outperform LSTM language models.We demonstrate perplexity gains on two datasets, representing the firstpositive experimental result on the use VAE for generative modeling of text.Further, we conduct an in-depth investigation of the use of VAE (with our newdecoding architecture) for semi-supervised and unsupervised labeling tasks,demonstrating gains over several strong baselines.\",\n",
       "  'categories': ['cs.NE', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICML, 3881-3890',\n",
       "  'citations': '189',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.08139v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=123823476347966018&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 150: {'ID': 150,\n",
       "  'title': 'Learning Representations for Counterfactual Inference',\n",
       "  'authors': ['David Sontag', 'Fredrik D. Johansson', 'Uri Shalit'],\n",
       "  'published': '2016-05-12T02:59:40Z',\n",
       "  'updated': '2018-06-06T13:00:53Z',\n",
       "  'abstract': 'Observational studies are rising in importance due to the widespreadaccumulation of data in fields such as healthcare, education, employment andecology. We consider the task of answering counterfactual questions such as,\"Would this patient have lower blood sugar had she received a differentmedication?\". We propose a new algorithmic framework for counterfactualinference which brings together ideas from domain adaptation and representationlearning. In addition to a theoretical justification, we perform an empiricalcomparison with previous approaches to causal inference from observationaldata. Our deep learning algorithm significantly outperforms the previousstate-of-the-art.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 3020-3029',\n",
       "  'citations': '196',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.03661v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=364993537171423085&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 151: {'ID': 151,\n",
       "  'title': 'Semi-supervised Sequence Learning',\n",
       "  'authors': ['Quoc V. Le', 'Andrew M. Dai'],\n",
       "  'published': '2015-11-04T18:48:36Z',\n",
       "  'updated': '2015-11-04T18:48:36Z',\n",
       "  'abstract': 'We present two approaches that use unlabeled data to improve sequencelearning with recurrent networks. The first approach is to predict what comesnext in a sequence, which is a conventional language model in natural languageprocessing. The second approach is to use a sequence autoencoder, which readsthe input sequence into a vector and predicts the input sequence again. Thesetwo algorithms can be used as a \"pretraining\" step for a later supervisedsequence learning algorithm. In other words, the parameters obtained from theunsupervised step can be used as a starting point for other supervised trainingmodels. In our experiments, we find that long short term memory recurrentnetworks after being pretrained with the two approaches are more stable andgeneralize better. With pretraining, we are able to train long short termmemory recurrent networks up to a few hundred timesteps, thereby achievingstrong performance in many text classification tasks, such as IMDB, DBpedia and20 Newsgroups.',\n",
       "  'categories': ['cs.LG', 'cs.CL'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '676',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.01432v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6463821397595411961&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 152: {'ID': 152,\n",
       "  'title': 'The Variational Fair Autoencoder',\n",
       "  'authors': ['Max Welling',\n",
       "   'Christos Louizos',\n",
       "   'Kevin Swersky',\n",
       "   'Richard Zemel',\n",
       "   'Yujia Li'],\n",
       "  'published': '2015-11-03T09:27:49Z',\n",
       "  'updated': '2017-08-10T03:07:31Z',\n",
       "  'abstract': 'We investigate the problem of learning representations that are invariant tocertain nuisance or sensitive factors of variation in the data while retainingas much of the remaining information as possible. Our model is based on avariational autoencoding architecture with priors that encourage independencebetween sensitive and latent factors of variation. Any subsequent processing,such as classification, can then be performed on this purged latentrepresentation. To remove any remaining dependencies we incorporate anadditional penalty term based on the \"Maximum Mean Discrepancy\" (MMD) measure.We discuss how these architectures can be efficiently trained on data and showin experiments that this method is more effective than previous work inremoving unwanted sources of variation while maintaining informative latentrepresentations.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '225',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.00830v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13824730458224470490&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 153: {'ID': 153,\n",
       "  'title': 'Adversarial Attacks on Neural Network Policies',\n",
       "  'authors': ['Sandy Huang',\n",
       "   'Yan Duan',\n",
       "   'Ian Goodfellow',\n",
       "   'Nicolas Papernot',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-02-08T04:33:55Z',\n",
       "  'updated': '2017-02-08T04:33:55Z',\n",
       "  'abstract': 'Machine learning classifiers are known to be vulnerable to inputs maliciouslyconstructed by adversaries to force misclassification. Such adversarialexamples have been extensively studied in the context of computer visionapplications. In this work, we show adversarial attacks are also effective whentargeting neural network policies in reinforcement learning. Specifically, weshow existing adversarial example crafting techniques can be used tosignificantly degrade test-time performance of trained policies. Our threatmodel considers adversaries capable of introducing small perturbations to theraw input of the policy. We characterize the degree of vulnerability acrosstasks and training algorithms, for a subclass of adversarial-example attacks inwhite-box and black-box settings. Regardless of the learned task or trainingalgorithm, we observe a significant drop in performance, even with smalladversarial perturbations that do not interfere with human perception. Videosare available at http://rll.berkeley.edu/adversarial.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '256',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.02284v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1879545961701003590&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 154: {'ID': 154,\n",
       "  'title': 'Machine Comprehension Using Match-LSTM and Answer Pointer',\n",
       "  'authors': ['Shuohang Wang', 'Jing Jiang'],\n",
       "  'published': '2016-08-29T03:42:50Z',\n",
       "  'updated': '2016-11-07T03:39:40Z',\n",
       "  'abstract': 'Machine comprehension of text is an important problem in natural languageprocessing. A recently released dataset, the Stanford Question AnsweringDataset (SQuAD), offers a large number of real questions and their answerscreated by humans through crowdsourcing. SQuAD provides a challenging testbedfor evaluating machine comprehension algorithms, partly because compared withprevious datasets, in SQuAD the answers do not come from a small set ofcandidate answers and they have variable lengths. We propose an end-to-endneural architecture for the task. The architecture is based on match-LSTM, amodel we proposed previously for textual entailment, and Pointer Net, asequence-to-sequence model proposed by Vinyals et al.(2015) to constrain theoutput tokens to be from the input sequences. We propose two ways of usingPointer Net for our task. Our experiments show that both of our two modelssubstantially outperform the best results obtained by Rajpurkar et al.(2016)using logistic regression and manually crafted features.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '370',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.07905v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8536399820764102165&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 155: {'ID': 155,\n",
       "  'title': 'Visualizing Deep Neural Network Decisions: Prediction Difference  Analysis',\n",
       "  'authors': ['Max Welling',\n",
       "   'Tameem Adel',\n",
       "   'Taco S Cohen',\n",
       "   'Luisa M Zintgraf'],\n",
       "  'published': '2017-02-15T13:25:26Z',\n",
       "  'updated': '2017-02-15T13:25:26Z',\n",
       "  'abstract': 'This article presents the prediction difference analysis method forvisualizing the response of a deep neural network to a specific input. Whenclassifying images, the method highlights areas in a given input image thatprovide evidence for or against a certain class. It overcomes severalshortcoming of previous methods and provides great additional insight into thedecision making process of classifiers. Making neural network decisionsinterpretable through visualization is important both to improve models and toaccelerate the adoption of black-box classifiers in application areas such asmedicine. We illustrate the method in experiments on natural images (ImageNetdata), as well as medical images (MRI brain scans).',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '256',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.04595v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13321146675816614452&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 156: {'ID': 156,\n",
       "  'title': 'Deep Bayesian Active Learning with Image Data',\n",
       "  'authors': ['Zoubin Ghahramani', 'Yarin Gal', 'Riashat Islam'],\n",
       "  'published': '2017-03-08T16:53:57Z',\n",
       "  'updated': '2017-03-08T16:53:57Z',\n",
       "  'abstract': 'Even though active learning forms an important pillar of machine learning,deep learning tools are not prevalent within it. Deep learning poses severaldifficulties when used in an active learning setting. First, active learning(AL) methods generally rely on being able to learn and update models from smallamounts of data. Recent advances in deep learning, on the other hand, arenotorious for their dependence on large amounts of data. Second, many ALacquisition functions rely on model uncertainty, yet deep learning methodsrarely represent such model uncertainty. In this paper we combine recentadvances in Bayesian deep learning into the active learning framework in apractical way. We develop an active learning framework for high dimensionaldata, a task which has been extremely challenging so far, with very sparseexisting literature. Taking advantage of specialised models such as Bayesianconvolutional neural networks, we demonstrate our active learning techniqueswith image data, obtaining a significant improvement on existing activelearning approaches. We demonstrate this on both the MNIST dataset, as well asfor skin cancer diagnosis from lesion images (ISIC2016 task).',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICML, 1183-1192',\n",
       "  'citations': '339',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.02910v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14700234482257382078&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 157: {'ID': 157,\n",
       "  'title': 'Object Detection with Deep Learning: A Review',\n",
       "  'authors': ['Shou-tao Xu', 'Xindong Wu', 'Peng Zheng', 'Zhong-Qiu Zhao'],\n",
       "  'published': '2018-07-15T08:16:03Z',\n",
       "  'updated': '2019-04-16T09:24:59Z',\n",
       "  'abstract': \"Due to object detection's close relationship with video analysis and imageunderstanding, it has attracted much research attention in recent years.Traditional object detection methods are built on handcrafted features andshallow trainable architectures. Their performance easily stagnates byconstructing complex ensembles which combine multiple low-level image featureswith high-level context from object detectors and scene classifiers. With therapid development in deep learning, more powerful tools, which are able tolearn semantic, high-level, deeper features, are introduced to address theproblems existing in traditional architectures. These models behave differentlyin network architecture, training strategy and optimization function, etc. Inthis paper, we provide a review on deep learning based object detectionframeworks. Our review begins with a brief introduction on the history of deeplearning and its representative tool, namely Convolutional Neural Network(CNN). Then we focus on typical generic object detection architectures alongwith some modifications and useful tricks to improve detection performancefurther. As distinct specific detection tasks exhibit differentcharacteristics, we also briefly survey several specific tasks, includingsalient object detection, face detection and pedestrian detection. Experimentalanalyses are also provided to compare various methods and draw some meaningfulconclusions. Finally, several promising directions and tasks are provided toserve as guidelines for future work in both object detection and relevantneural network based learning systems.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 30 (11), 3212-3232',\n",
       "  'citations': '403',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1807.05511v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13346469121565650680&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 158: {'ID': 158,\n",
       "  'title': 'Importance Weighted Autoencoders',\n",
       "  'authors': ['Ruslan Salakhutdinov', 'Roger Grosse', 'Yuri Burda'],\n",
       "  'published': '2015-09-01T22:33:13Z',\n",
       "  'updated': '2016-11-07T17:29:24Z',\n",
       "  'abstract': \"The variational autoencoder (VAE; Kingma, Welling (2014)) is a recentlyproposed generative model pairing a top-down generative network with abottom-up recognition network which approximates posterior inference. Ittypically makes strong assumptions about posterior inference, for instance thatthe posterior distribution is approximately factorial, and that its parameterscan be approximated with nonlinear regression from the observations. As we showempirically, the VAE objective can lead to overly simplified representationswhich fail to use the network's entire modeling capacity. We present theimportance weighted autoencoder (IWAE), a generative model with the samearchitecture as the VAE, but which uses a strictly tighter log-likelihood lowerbound derived from importance weighting. In the IWAE, the recognition networkuses multiple samples to approximate the posterior, giving it increasedflexibility to model complex posteriors which do not fit the VAE modelingassumptions. We show empirically that IWAEs learn richer latent spacerepresentations than VAEs, leading to improved test log-likelihood on densityestimation benchmarks.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '579',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.00519v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=403810601333190474&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 159: {'ID': 159,\n",
       "  'title': 'MMD GAN: Towards Deeper Understanding of Moment Matching Network',\n",
       "  'authors': ['Yiming Yang',\n",
       "   'Yu Cheng',\n",
       "   'Barnabás Póczos',\n",
       "   'Wei-Cheng Chang',\n",
       "   'Chun-Liang Li'],\n",
       "  'published': '2017-05-24T02:20:29Z',\n",
       "  'updated': '2017-11-27T14:04:35Z',\n",
       "  'abstract': 'Generative moment matching network (GMMN) is a deep generative model thatdiffers from Generative Adversarial Network (GAN) by replacing thediscriminator in GAN with a two-sample test based on kernel maximum meandiscrepancy (MMD). Although some theoretical guarantees of MMD have beenstudied, the empirical performance of GMMN is still not as competitive as thatof GAN on challenging and large benchmark datasets. The computationalefficiency of GMMN is also less desirable in comparison with GAN, partially dueto its requirement for a rather large batch size during the training. In thispaper, we propose to improve both the model expressiveness of GMMN and itscomputational efficiency by introducing adversarial kernel learning techniques,as the replacement of a fixed Gaussian kernel in the original GMMN. The newapproach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN.The new distance measure in MMD GAN is a meaningful loss that enjoys theadvantage of weak topology and can be optimized via gradient descent withrelatively small batch sizes. In our evaluation on multiple benchmark datasets,including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GANsignificantly outperforms GMMN, and is competitive with other representativeGAN works.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08584v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13688446556700022690&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 160: {'ID': 160,\n",
       "  'title': 'Holographic Embeddings of Knowledge Graphs',\n",
       "  'authors': ['Lorenzo Rosasco', 'Tomaso Poggio', 'Maximilian Nickel'],\n",
       "  'published': '2015-10-16T16:29:07Z',\n",
       "  'updated': '2015-12-07T18:05:52Z',\n",
       "  'abstract': 'Learning embeddings of entities and relations is an efficient and versatilemethod to perform machine learning on relational data such as knowledge graphs.In this work, we propose holographic embeddings (HolE) to learn compositionalvector space representations of entire knowledge graphs. The proposed method isrelated to holographic models of associative memory in that it employs circularcorrelation to create compositional representations. By using correlation asthe compositional operator HolE can capture rich interactions butsimultaneously remains efficient to compute, easy to train, and scalable tovery large datasets. In extensive experiments we show that holographicembeddings are able to outperform state-of-the-art methods for link predictionin knowledge graphs and relational learning benchmark datasets.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML', 'I.2.6; I.2.4'],\n",
       "  'journal': 'Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\\xa0…',\n",
       "  'citations': '465',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.04935v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18446152877069174052&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 161: {'ID': 161,\n",
       "  'title': 'Variational Dropout and the Local Reparameterization Trick',\n",
       "  'authors': ['Diederik P. Kingma', 'Max Welling', 'Tim Salimans'],\n",
       "  'published': '2015-06-08T15:37:56Z',\n",
       "  'updated': '2015-12-20T16:07:38Z',\n",
       "  'abstract': 'We investigate a local reparameterizaton technique for greatly reducing thevariance of stochastic gradients for variational Bayesian inference (SGVB) of aposterior over model parameters, while retaining parallelizability. This localreparameterization translates uncertainty about global parameters into localnoise that is independent across datapoints in the minibatch. Suchparameterizations can be trivially parallelized and have variance that isinversely proportional to the minibatch size, generally leading to much fasterconvergence. Additionally, we explore a connection with dropout: Gaussiandropout objectives correspond to SGVB with local reparameterization, ascale-invariant prior and proportionally fixed posterior variance. Our methodallows inference of more flexibly parameterized posteriors; specifically, wepropose variational dropout, a generalization of Gaussian dropout where thedropout rates are learned, often leading to better models. The method isdemonstrated through several experiments.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'stat.CO'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '534',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02557v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5114094121420596303&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 162: {'ID': 162,\n",
       "  'title': 'Train faster, generalize better: Stability of stochastic gradient  descent',\n",
       "  'authors': ['Moritz Hardt', 'Benjamin Recht', 'Yoram Singer'],\n",
       "  'published': '2015-09-03T19:53:40Z',\n",
       "  'updated': '2016-02-07T17:06:58Z',\n",
       "  'abstract': 'We show that parametric models trained by a stochastic gradient method (SGM)with few iterations have vanishing generalization error. We prove our resultsby arguing that SGM is algorithmically stable in the sense of Bousquet andElisseeff. Our analysis only employs elementary tools from convex andcontinuous optimization. We derive stability bounds for both convex andnon-convex optimization under standard Lipschitz and smoothness assumptions.  Applying our results to the convex case, we provide new insights for whymultiple epochs of stochastic gradient methods generalize well in practice. Inthe non-convex case, we give a new interpretation of common practices in neuralnetworks, and formally show that popular techniques for training large deepmodels are indeed stability-promoting. Our findings conceptually underscore theimportance of reducing training time beyond its obvious benefit.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 1225-1234',\n",
       "  'citations': '455',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.01240v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4563905800844853958&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 163: {'ID': 163,\n",
       "  'title': 'Value Iteration Networks',\n",
       "  'authors': ['Garrett Thomas',\n",
       "   'Sergey Levine',\n",
       "   'Aviv Tamar',\n",
       "   'Yi Wu',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2016-02-09T05:44:36Z',\n",
       "  'updated': '2017-03-20T21:41:51Z',\n",
       "  'abstract': \"We introduce the value iteration network (VIN): a fully differentiable neuralnetwork with a `planning module' embedded within. VINs can learn to plan, andare suitable for predicting outcomes that involve planning-based reasoning,such as policies for reinforcement learning. Key to our approach is a noveldifferentiable approximation of the value-iteration algorithm, which can berepresented as a convolutional neural network, and trained end-to-end usingstandard backpropagation. We evaluate VIN based policies on discrete andcontinuous path-planning domains, and on a natural-language based search task.We show that by learning an explicit planning computation, VIN policiesgeneralize better to new, unseen domains.\",\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '344',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02867v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9903414776362829253&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 164: {'ID': 164,\n",
       "  'title': 'Disentangling by Factorising',\n",
       "  'authors': ['Andriy Mnih', 'Hyunjik Kim'],\n",
       "  'published': '2018-02-16T15:43:43Z',\n",
       "  'updated': '2019-07-09T10:43:41Z',\n",
       "  'abstract': 'We define and address the problem of unsupervised learning of disentangledrepresentations on data generated from independent factors of variation. Wepropose FactorVAE, a method that disentangles by encouraging the distributionof representations to be factorial and hence independent across the dimensions.We show that it improves upon $\\\\beta$-VAE by providing a better trade-offbetween disentanglement and reconstruction quality. Moreover, we highlight theproblems of a commonly used disentanglement metric and introduce a new metricthat does not suffer from them.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 2654-2663',\n",
       "  'citations': '283',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.05983v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4010663500903508201&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 165: {'ID': 165,\n",
       "  'title': 'A Neural Representation of Sketch Drawings',\n",
       "  'authors': ['David Ha', 'Douglas Eck'],\n",
       "  'published': '2017-04-11T18:09:01Z',\n",
       "  'updated': '2017-05-19T16:40:16Z',\n",
       "  'abstract': 'We present sketch-rnn, a recurrent neural network (RNN) able to constructstroke-based drawings of common objects. The model is trained on thousands ofcrude human-drawn images representing hundreds of classes. We outline aframework for conditional and unconditional sketch generation, and describe newrobust training methods for generating coherent sketch drawings in a vectorformat.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '289',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.03477v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2337146750300919321&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 166: {'ID': 166,\n",
       "  'title': 'Multi-Adversarial Domain Adaptation',\n",
       "  'authors': ['Jianmin Wang', 'Zhongyi Pei', 'Zhangjie Cao', 'Mingsheng Long'],\n",
       "  'published': '2018-09-04T20:54:48Z',\n",
       "  'updated': '2018-09-04T20:54:48Z',\n",
       "  'abstract': 'Recent advances in deep domain adaptation reveal that adversarial learningcan be embedded into deep networks to learn transferable features that reducedistribution discrepancy between the source and target domains. Existing domainadversarial adaptation methods based on single domain discriminator only alignthe source and target data distributions without exploiting the complexmultimode structures. In this paper, we present a multi-adversarial domainadaptation (MADA) approach, which captures multimode structures to enablefine-grained alignment of different data distributions based on multiple domaindiscriminators. The adaptation can be achieved by stochastic gradient descentwith the gradients computed by back-propagation in linear-time. Empiricalevidence demonstrates that the proposed model outperforms state of the artmethods on standard domain adaptation datasets.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '142',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.02176v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7147882118203212526&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 167: {'ID': 167,\n",
       "  'title': 'Semantic Image Segmentation with Deep Convolutional Nets and Fully  Connected CRFs',\n",
       "  'authors': ['Alan L. Yuille',\n",
       "   'Liang-Chieh Chen',\n",
       "   'Iasonas Kokkinos',\n",
       "   'George Papandreou',\n",
       "   'Kevin Murphy'],\n",
       "  'published': '2014-12-22T17:18:33Z',\n",
       "  'updated': '2016-06-07T04:00:08Z',\n",
       "  'abstract': 'Deep Convolutional Neural Networks (DCNNs) have recently shown state of theart performance in high level vision tasks, such as image classification andobject detection. This work brings together methods from DCNNs andprobabilistic graphical models for addressing the task of pixel-levelclassification (also called \"semantic image segmentation\"). We show thatresponses at the final layer of DCNNs are not sufficiently localized foraccurate object segmentation. This is due to the very invariance propertiesthat make DCNNs good for high level tasks. We overcome this poor localizationproperty of deep networks by combining the responses at the final DCNN layerwith a fully connected Conditional Random Field (CRF). Qualitatively, our\"DeepLab\" system is able to localize segment boundaries at a level of accuracywhich is beyond previous methods. Quantitatively, our method sets the newstate-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching71.6% IOU accuracy in the test set. We show how these results can be obtainedefficiently: Careful network re-purposing and a novel application of the \\'hole\\'algorithm from the wavelet community allow dense computation of neural netresponses at 8 frames per second on a modern GPU.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '2496',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.7062v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12556287530133233148&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 168: {'ID': 168,\n",
       "  'title': 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations',\n",
       "  'authors': ['Tegan Maharaj',\n",
       "   'János Kramár',\n",
       "   'Chris Pal',\n",
       "   'David Krueger',\n",
       "   'Aaron Courville',\n",
       "   'Mohammad Pezeshki',\n",
       "   'Anirudh Goyal',\n",
       "   'Nicolas Ballas',\n",
       "   'Nan Rosemary Ke',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2016-06-03T23:31:47Z',\n",
       "  'updated': '2017-09-22T20:43:09Z',\n",
       "  'abstract': 'We propose zoneout, a novel method for regularizing RNNs. At each timestep,zoneout stochastically forces some hidden units to maintain their previousvalues. Like dropout, zoneout uses random noise to train a pseudo-ensemble,improving generalization. But by preserving instead of dropping hidden units,gradient information and state information are more readily propagated throughtime, as in feedforward stochastic depth networks. We perform an empiricalinvestigation of various RNN regularizers, and find that zoneout givessignificant performance improvements across tasks. We achieve competitiveresults with relatively simple models in character- and word-level languagemodelling on the Penn Treebank and Text8 datasets, and combining with recurrentbatch normalization yields state-of-the-art results on permuted sequentialMNIST.',\n",
       "  'categories': ['cs.NE', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '203',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.01305v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13800900548977291683&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 169: {'ID': 169,\n",
       "  'title': 'Sharp Minima Can Generalize For Deep Nets',\n",
       "  'authors': ['Laurent Dinh',\n",
       "   'Razvan Pascanu',\n",
       "   'Samy Bengio',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2017-03-15T05:12:25Z',\n",
       "  'updated': '2017-05-15T23:33:19Z',\n",
       "  'abstract': 'Despite their overwhelming capacity to overfit, deep learning architecturestend to generalize relatively well to unseen data, allowing them to be deployedin practice. However, explaining why this is the case is still an open area ofresearch. One standing hypothesis that is gaining popularity, e.g. Hochreiter &amp;Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of theloss function found by stochastic gradient based methods results in goodgeneralization. This paper argues that most notions of flatness are problematicfor deep models and can not be directly applied to explain generalization.Specifically, when focusing on deep networks with rectifier units, we canexploit the particular geometry of parameter space induced by the inherentsymmetries that these architectures exhibit to build equivalent modelscorresponding to arbitrarily sharper minima. Furthermore, if we allow toreparametrize a function, the geometry of its parameters can change drasticallywithout affecting its generalization properties.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1019-1028',\n",
       "  'citations': '246',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.04933v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4474448870091274183&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 170: {'ID': 170,\n",
       "  'title': 'FractalNet: Ultra-Deep Neural Networks without Residuals',\n",
       "  'authors': ['Gustav Larsson', 'Gregory Shakhnarovich', 'Michael Maire'],\n",
       "  'published': '2016-05-24T20:28:53Z',\n",
       "  'updated': '2017-05-26T18:53:56Z',\n",
       "  'abstract': 'We introduce a design strategy for neural network macro-architecture based onself-similarity. Repeated application of a simple expansion rule generates deepnetworks whose structural layouts are precisely truncated fractals. Thesenetworks contain interacting subpaths of different lengths, but do not includeany pass-through or residual connections; every internal signal is transformedby a filter and nonlinearity before being seen by subsequent layers. Inexperiments, fractal networks match the excellent performance of standardresidual networks on both CIFAR and ImageNet classification tasks, therebydemonstrating that residual representations may not be fundamental to thesuccess of extremely deep convolutional neural networks. Rather, the key may bethe ability to transition, during training, from effectively shallow to deep.We note similarities with student-teacher behavior and develop drop-path, anatural extension of dropout, to regularize co-adaptation of subpaths infractal architectures. Such regularization allows extraction ofhigh-performance fixed-depth subnetworks. Additionally, fractal networksexhibit an anytime property: shallow subnetworks provide a quick answer, whiledeeper subnetworks, with higher latency, provide a more accurate answer.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '467',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07648v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15300779753326541860&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 171: {'ID': 171,\n",
       "  'title': 'Emergence of Grounded Compositional Language in Multi-Agent Populations',\n",
       "  'authors': ['Igor Mordatch', 'Pieter Abbeel'],\n",
       "  'published': '2017-03-15T03:30:13Z',\n",
       "  'updated': '2018-07-24T04:13:05Z',\n",
       "  'abstract': 'By capturing statistical patterns in large corpora, machine learning hasenabled significant advances in natural language processing, including inmachine translation, question answering, and sentiment analysis. However, foragents to intelligently interact with humans, simply capturing the statisticalpatterns is insufficient. In this paper we investigate if, and how, groundedcompositional language can emerge as a means to achieve goals in multi-agentpopulations. Towards this end, we propose a multi-agent learning environmentand learning methods that bring about emergence of a basic compositionallanguage. This language is represented as streams of abstract discrete symbolsuttered by agents over time, but nonetheless has a coherent structure thatpossesses a defined vocabulary and syntax. We also observe emergence ofnon-verbal communication such as pointing and guiding when languagecommunication is unavailable.',\n",
       "  'categories': ['cs.AI', 'cs.CL'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '251',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.04908v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13990608325011462923&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 172: {'ID': 172,\n",
       "  'title': 'Learning to Transduce with Unbounded Memory',\n",
       "  'authors': ['Edward Grefenstette',\n",
       "   'Phil Blunsom',\n",
       "   'Mustafa Suleyman',\n",
       "   'Karl Moritz Hermann'],\n",
       "  'published': '2015-06-08T14:23:30Z',\n",
       "  'updated': '2015-11-03T14:07:29Z',\n",
       "  'abstract': 'Recently, strong results have been demonstrated by Deep Recurrent NeuralNetworks on natural language transduction problems. In this paper we explorethe representational power of these models using synthetic grammars designed toexhibit phenomena similar to those found in real transduction problems such asmachine translation. These experiments lead us to propose new memory-basedrecurrent networks that implement continuously differentiable analogues oftraditional data structures such as Stacks, Queues, and DeQues. We show thatthese architectures exhibit superior generalisation performance to Deep RNNsand are often able to learn the underlying generating algorithms in ourtransduction experiments.',\n",
       "  'categories': ['cs.NE', 'cs.CL', 'cs.LG', '68T05', 'I.5.1; I.2.6; I.2.7'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '217',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02516v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6724672567965731171&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 173: {'ID': 173,\n",
       "  'title': 'Dueling Network Architectures for Deep Reinforcement Learning',\n",
       "  'authors': ['Hado van Hasselt',\n",
       "   'Nando de Freitas',\n",
       "   'Matteo Hessel',\n",
       "   'Marc Lanctot',\n",
       "   'Tom Schaul',\n",
       "   'Ziyu Wang'],\n",
       "  'published': '2015-11-20T13:07:54Z',\n",
       "  'updated': '2016-04-05T09:03:06Z',\n",
       "  'abstract': 'In recent years there have been many successes of using deep representationsin reinforcement learning. Still, many of these applications use conventionalarchitectures, such as convolutional networks, LSTMs, or auto-encoders. In thispaper, we present a new neural network architecture for model-freereinforcement learning. Our dueling network represents two separate estimators:one for the state value function and one for the state-dependent actionadvantage function. The main benefit of this factoring is to generalizelearning across actions without imposing any change to the underlyingreinforcement learning algorithm. Our results show that this architecture leadsto better policy evaluation in the presence of many similar-valued actions.Moreover, the dueling architecture enables our RL agent to outperform thestate-of-the-art on the Atari 2600 domain.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1995-2003',\n",
       "  'citations': '1169',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06581v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12521843669488478464&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 174: {'ID': 174,\n",
       "  'title': 'Disentangling factors of variation in deep representations using  adversarial training',\n",
       "  'authors': ['Michael Mathieu',\n",
       "   'Yann LeCun',\n",
       "   'Junbo Zhao',\n",
       "   'Aditya Ramesh',\n",
       "   'Pablo Sprechmann'],\n",
       "  'published': '2016-11-10T16:24:16Z',\n",
       "  'updated': '2016-11-10T16:24:16Z',\n",
       "  'abstract': 'We introduce a conditional generative model for learning to disentangle thehidden factors of variation within a set of labeled observations, and separatethem into complementary codes. One code summarizes the specified factors ofvariation associated with the labels. The other summarizes the remainingunspecified variability. During training, the only available source ofsupervision comes from our ability to distinguish among different observationsbelonging to the same class. Examples of such observations include images of aset of labeled objects captured at different viewpoints, or recordings of setof speakers dictating multiple phrases. In both instances, the intra-classdiversity is the source of the unspecified factors of variation: each object isobserved at multiple viewpoints, and each speaker dictates multiple phrases.Learning to disentangle the specified factors from the unspecified ones becomeseasier when strong supervision is possible. Suppose that during training, wehave access to pairs of images, where each pair shows two different objectscaptured from the same viewpoint. This source of alignment allows us to solveour task using existing methods. However, labels for the unspecified factorsare usually unavailable in realistic scenarios where data acquisition is notstrictly controlled. We address the problem of disentanglement in this moregeneral setting by combining deep convolutional autoencoders with a form ofadversarial training. Both factors of variation are implicitly captured in theorganization of the learned embedding space, and can be used for solvingsingle-image analogies. Experimental results on synthetic and real datasetsshow that the proposed method is capable of generalizing to unseen classes andintra-class variabilities.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.03383v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17487472987754617699&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 175: {'ID': 175,\n",
       "  'title': 'Amortised MAP Inference for Image Super-resolution',\n",
       "  'authors': ['Ferenc Huszár',\n",
       "   'Wenzhe Shi',\n",
       "   'Casper Kaae Sønderby',\n",
       "   'Lucas Theis',\n",
       "   'Jose Caballero'],\n",
       "  'published': '2016-10-14T14:58:44Z',\n",
       "  'updated': '2017-02-21T13:08:24Z',\n",
       "  'abstract': \"Image super-resolution (SR) is an underdetermined inverse problem, where alarge number of plausible high-resolution images can explain the samedownsampled image. Most current single image SR methods use empirical riskminimisation, often with a pixel-wise mean squared error (MSE) loss. However,the outputs from such methods tend to be blurry, over-smoothed and generallyappear implausible. A more desirable approach would employ Maximum a Posteriori(MAP) inference, preferring solutions that always have a high probability underthe image prior, and thus appear more plausible. Direct MAP estimation for SRis non-trivial, as it requires us to build a model for the image prior fromsamples. Furthermore, MAP inference is often performed via optimisation-basediterative algorithms which don't compare well with the efficiency ofneural-network-based alternatives. Here we introduce new methods for amortisedMAP inference whereby we calculate the MAP estimate directly using aconvolutional neural network. We first introduce a novel neural networkarchitecture that performs a projection to the affine subspace of valid SRsolutions ensuring that the high resolution output of the network is alwaysconsistent with the low resolution input. We show that, using thisarchitecture, the amortised MAP inference problem reduces to minimising thecross-entropy between two distributions, similar to training generative models.We propose three methods to solve this optimisation problem: (1) GenerativeAdversarial Networks (GAN) (2) denoiser-guided SR which backpropagatesgradient-estimates from denoising to train the network, and (3) a baselinemethod using a maximum-likelihood-trained image prior. Our experiments showthat the GAN based approach performs best on real image data. Lastly, weestablish a connection between GANs and amortised variational inference as ine.g. variational autoencoders.\",\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '265',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.04490v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14286004747394736744&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 176: {'ID': 176,\n",
       "  'title': 'From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label  Classification',\n",
       "  'authors': ['Ramón Fernandez Astudillo', 'André F. T. Martins'],\n",
       "  'published': '2016-02-05T15:49:02Z',\n",
       "  'updated': '2016-02-08T09:41:36Z',\n",
       "  'abstract': 'We propose sparsemax, a new activation function similar to the traditionalsoftmax, but able to output sparse probabilities. After deriving itsproperties, we show how its Jacobian can be efficiently computed, enabling itsuse in a network trained with backpropagation. Then, we propose a new smoothand convex loss function which is the sparsemax analogue of the logistic loss.We reveal an unexpected connection between this new loss and the Huberclassification loss. We obtain promising empirical results in multi-labelclassification problems and in attention-based neural networks for naturallanguage inference. For the latter, we achieve a similar performance as thetraditional softmax, but with a selective, more compact, attention focus.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 1614-1623',\n",
       "  'citations': '190',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02068v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15219879151044186751&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 177: {'ID': 177,\n",
       "  'title': 'Incremental Network Quantization: Towards Lossless CNNs with  Low-Precision Weights',\n",
       "  'authors': ['Yurong Chen',\n",
       "   'Anbang Yao',\n",
       "   'Lin Xu',\n",
       "   'Yiwen Guo',\n",
       "   'Aojun Zhou'],\n",
       "  'published': '2017-02-10T02:30:22Z',\n",
       "  'updated': '2017-08-25T13:21:18Z',\n",
       "  'abstract': 'This paper presents incremental network quantization (INQ), a novel method,targeting to efficiently convert any pre-trained full-precision convolutionalneural network (CNN) model into a low-precision version whose weights areconstrained to be either powers of two or zero. Unlike existing methods whichare struggled in noticeable accuracy loss, our INQ has the potential to resolvethis issue, as benefiting from two innovations. On one hand, we introduce threeinterdependent operations, namely weight partition, group-wise quantization andre-training. A well-proven measure is employed to divide the weights in eachlayer of a pre-trained CNN model into two disjoint groups. The weights in thefirst group are responsible to form a low-precision base, thus they arequantized by a variable-length encoding method. The weights in the other groupare responsible to compensate for the accuracy loss from the quantization, thusthey are the ones to be re-trained. On the other hand, these three operationsare repeated on the latest re-trained group in an iterative manner until allthe weights are converted into low-precision ones, acting as an incrementalnetwork quantization and accuracy enhancement procedure. Extensive experimentson the ImageNet classification task using almost all known deep CNNarchitectures including AlexNet, VGG-16, GoogleNet and ResNets well testify theefficacy of the proposed method. Specifically, at 5-bit quantization, ourmodels have improved accuracy than the 32-bit floating-point references. TakingResNet-18 as an example, we further show that our quantized models with 4-bit,3-bit and 2-bit ternary weights have improved or very similar accuracy againstits 32-bit floating-point baseline. Besides, impressive results with thecombination of network pruning and INQ are also reported. The code is availableat https://github.com/Zhouaojun/Incremental-Network-Quantization.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '455',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.03044v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10552103322105352604&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 178: {'ID': 178,\n",
       "  'title': 'Reading Scene Text in Deep Convolutional Sequences',\n",
       "  'authors': ['Xiaoou Tang',\n",
       "   'Weilin Huang',\n",
       "   'Pan He',\n",
       "   'Chen Change Loy',\n",
       "   'Yu Qiao'],\n",
       "  'published': '2015-06-14T13:34:10Z',\n",
       "  'updated': '2015-12-20T21:06:23Z',\n",
       "  'abstract': 'We develop a Deep-Text Recurrent Network (DTRN) that regards scene textreading as a sequence labelling problem. We leverage recent advances of deepconvolutional neural networks to generate an ordered high-level sequence from awhole word image, avoiding the difficult character segmentation problem. Then adeep recurrent model, building on long short-term memory (LSTM), is developedto robustly recognize the generated CNN sequences, departing from most existingapproaches recognising each character independently. Our model has a number ofappealing properties in comparison to existing scene text recognition methods:(i) It can recognise highly ambiguous words by leveraging meaningful contextinformation, allowing it to work reliably without either pre- orpost-processing; (ii) the deep CNN feature is robust to various imagedistortions; (iii) it retains the explicit order information in word image,which is essential to discriminate word strings; (iv) the model does not dependon pre-defined dictionary, and it can process unknown words and arbitrarystrings. Codes for the DTRN will be available.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '167',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.04395v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5124474383995369775&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 179: {'ID': 179,\n",
       "  'title': 'Train longer, generalize better: closing the generalization gap in large  batch training of neural networks',\n",
       "  'authors': ['Daniel Soudry', 'Itay Hubara', 'Elad Hoffer'],\n",
       "  'published': '2017-05-24T13:17:27Z',\n",
       "  'updated': '2018-01-01T08:49:43Z',\n",
       "  'abstract': 'Background: Deep learning models are typically trained using stochasticgradient descent or one of its variants. These methods update the weights usingtheir gradient, estimated from a small fraction of the training data. It hasbeen observed that when using large batch sizes there is a persistentdegradation in generalization performance - known as the \"generalization gap\"phenomena. Identifying the origin of this gap and closing it had remained anopen problem.  Contributions: We examine the initial high learning rate training phase. Wefind that the weight distance from its initialization grows logarithmicallywith the number of weight updates. We therefore propose a \"random walk onrandom landscape\" statistical model which is known to exhibit similar\"ultra-slow\" diffusion behavior. Following this hypothesis we conductedexperiments to show empirically that the \"generalization gap\" stems from therelatively small number of updates rather than the batch size, and can becompletely eliminated by adapting the training regime used. We furtherinvestigate different techniques to train models in the large-batch regime andpresent a novel algorithm named \"Ghost Batch Normalization\" which enablessignificant decrease in the generalization gap without increasing the number ofupdates. To validate our findings we conduct several additional experiments onMNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practicesand beliefs concerning training of deep models and suggest they may not beoptimal to achieve good generalization.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '280',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08741v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11429742229244735024&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 180: {'ID': 180,\n",
       "  'title': 'A Closer Look at Memorization in Deep Networks',\n",
       "  'authors': ['Tegan Maharaj',\n",
       "   'Simon Lacoste-Julien',\n",
       "   'David Krueger',\n",
       "   'Aaron Courville',\n",
       "   'Emmanuel Bengio',\n",
       "   'Maxinder S. Kanwal',\n",
       "   'Stanisław Jastrzębski',\n",
       "   'Nicolas Ballas',\n",
       "   'Asja Fischer',\n",
       "   'Devansh Arpit',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2017-06-16T18:11:09Z',\n",
       "  'updated': '2017-07-01T14:26:51Z',\n",
       "  'abstract': 'We examine the role of memorization in deep learning, drawing connections tocapacity, generalization, and adversarial robustness. While deep networks arecapable of memorizing noise data, our results suggest that they tend toprioritize learning simple patterns first. In our experiments, we exposequalitative differences in gradient-based optimization of deep neural networks(DNNs) on noise vs. real data. We also demonstrate that for appropriately tunedexplicit regularization (e.g., dropout) we can degrade DNN training performanceon noise datasets without compromising generalization on real data. Ouranalysis suggests that the notions of effective capacity which are datasetindependent are unlikely to explain the generalization performance of deepnetworks when trained with gradient based methods because training data itselfplays an important role in determining the degree of memorization.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 233-242',\n",
       "  'citations': '329',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.05394v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=158427493479385371&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 181: {'ID': 181,\n",
       "  'title': 'Learning Physical Intuition of Block Towers by Example',\n",
       "  'authors': ['Adam Lerer', 'Sam Gross', 'Rob Fergus'],\n",
       "  'published': '2016-03-03T22:59:35Z',\n",
       "  'updated': '2016-03-03T22:59:35Z',\n",
       "  'abstract': 'Wooden blocks are a common toy for infants, allowing them to develop motorskills and gain intuition about the physical behavior of the world. In thispaper, we explore the ability of deep feed-forward models to learn suchintuitive physics. Using a 3D game engine, we create small towers of woodenblocks whose stability is randomized and render them collapsing (or remainingupright). This data allows us to train large convolutional network models whichcan accurately predict the outcome, as well as estimating the blocktrajectories. The models are also able to generalize in two important ways: (i)to new physical scenarios, e.g. towers with an additional block and (ii) toimages of real wooden blocks, where it obtains a performance comparable tohuman subjects.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'ICML, 430-438',\n",
       "  'citations': '193',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.01312v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12846348306706460250&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 182: {'ID': 182,\n",
       "  'title': 'Attention Is All You Need',\n",
       "  'authors': ['Illia Polosukhin',\n",
       "   'Aidan N. Gomez',\n",
       "   'Niki Parmar',\n",
       "   'Ashish Vaswani',\n",
       "   'Lukasz Kaiser',\n",
       "   'Llion Jones',\n",
       "   'Jakob Uszkoreit',\n",
       "   'Noam Shazeer'],\n",
       "  'published': '2017-06-12T17:57:34Z',\n",
       "  'updated': '2017-12-06T03:30:32Z',\n",
       "  'abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder-decoder configuration. The bestperforming models also connect the encoder and decoder through an attentionmechanism. We propose a new simple network architecture, the Transformer, basedsolely on attention mechanisms, dispensing with recurrence and convolutionsentirely. Experiments on two machine translation tasks show these models to besuperior in quality while being more parallelizable and requiring significantlyless time to train. Our model achieves 28.4 BLEU on the WMT 2014English-to-German translation task, improving over the existing best results,including ensembles by over 2 BLEU. On the WMT 2014 English-to-Frenchtranslation task, our model establishes a new single-model state-of-the-artBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fractionof the training costs of the best models from the literature. We show that theTransformer generalizes well to other tasks by applying it successfully toEnglish constituency parsing both with large and limited training data.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '9885',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.03762v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2960712678066186980&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 183: {'ID': 183,\n",
       "  'title': 'Deep Reinforcement Learning with Double Q-learning',\n",
       "  'authors': ['David Silver', 'Arthur Guez', 'Hado van Hasselt'],\n",
       "  'published': '2015-09-22T04:40:22Z',\n",
       "  'updated': '2015-12-08T21:19:16Z',\n",
       "  'abstract': 'The popular Q-learning algorithm is known to overestimate action values undercertain conditions. It was not previously known whether, in practice, suchoverestimations are common, whether they harm performance, and whether they cangenerally be prevented. In this paper, we answer all these questionsaffirmatively. In particular, we first show that the recent DQN algorithm,which combines Q-learning with a deep neural network, suffers from substantialoverestimations in some games in the Atari 2600 domain. We then show that theidea behind the Double Q-learning algorithm, which was introduced in a tabularsetting, can be generalized to work with large-scale function approximation. Wepropose a specific adaptation to the DQN algorithm and show that the resultingalgorithm not only reduces the observed overestimations, as hypothesized, butthat this also leads to much better performance on several games.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '2152',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.06461v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=249468315505163542&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 184: {'ID': 184,\n",
       "  'title': 'Order Matters: Sequence to sequence for sets',\n",
       "  'authors': ['Oriol Vinyals', 'Samy Bengio', 'Manjunath Kudlur'],\n",
       "  'published': '2015-11-19T21:31:26Z',\n",
       "  'updated': '2016-02-23T22:25:12Z',\n",
       "  'abstract': 'Sequences have become first class citizens in supervised learning thanks tothe resurgence of recurrent neural networks. Many complex tasks that requiremapping from or to a sequence of observations can now be formulated with thesequence-to-sequence (seq2seq) framework which employs the chain rule toefficiently represent the joint probability of sequences. In many cases,however, variable sized inputs and/or outputs might not be naturally expressedas sequences. For instance, it is not clear how to input a set of numbers intoa model where the task is to sort them; similarly, we do not know how toorganize outputs when they correspond to random variables and the task is tomodel their unknown joint probability. In this paper, we first show usingvarious examples that the order in which we organize input and/or output datamatters significantly when learning an underlying model. We then discuss anextension of the seq2seq framework that goes beyond sequences and handles inputsets in a principled way. In addition, we propose a loss which, by searchingover possible orders during training, deals with the lack of structure ofoutput sets. We show empirical evidence of our claims regarding ordering, andon the modifications to the seq2seq framework on benchmark language modelingand parsing tasks, as well as two artificial tasks -- sorting numbers andestimating the joint probability of unknown graphical models.',\n",
       "  'categories': ['stat.ML', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '346',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06391v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16770614183391051493&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 185: {'ID': 185,\n",
       "  'title': 'Understanding deep learning requires rethinking generalization',\n",
       "  'authors': ['Samy Bengio',\n",
       "   'Benjamin Recht',\n",
       "   'Chiyuan Zhang',\n",
       "   'Oriol Vinyals',\n",
       "   'Moritz Hardt'],\n",
       "  'published': '2016-11-10T22:02:36Z',\n",
       "  'updated': '2017-02-26T19:36:40Z',\n",
       "  'abstract': 'Despite their massive size, successful deep artificial neural networks canexhibit a remarkably small difference between training and test performance.Conventional wisdom attributes small generalization error either to propertiesof the model family, or to the regularization techniques used during training.  Through extensive systematic experiments, we show how these traditionalapproaches fail to explain why large neural networks generalize well inpractice. Specifically, our experiments establish that state-of-the-artconvolutional networks for image classification trained with stochasticgradient methods easily fit a random labeling of the training data. Thisphenomenon is qualitatively unaffected by explicit regularization, and occurseven if we replace the true images by completely unstructured random noise. Wecorroborate these experimental findings with a theoretical construction showingthat simple depth two neural networks already have perfect finite sampleexpressivity as soon as the number of parameters exceeds the number of datapoints as it usually does in practice.  We interpret our experimental findings by comparison with traditional models.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '1800',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.03530v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4613672282544622621&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 186: {'ID': 186,\n",
       "  'title': 'A Convolutional Attention Network for Extreme Summarization of Source  Code',\n",
       "  'authors': ['Charles Sutton', 'Hao Peng', 'Miltiadis Allamanis'],\n",
       "  'published': '2016-02-09T14:36:49Z',\n",
       "  'updated': '2016-05-25T12:18:28Z',\n",
       "  'abstract': \"Attention mechanisms in neural networks have proved useful for problems inwhich the input and output do not have fixed dimension. Often there existfeatures that are locally translation invariant and would be valuable fordirecting the model's attention, but previous attentional architectures are notconstructed to learn such features specifically. We introduce an attentionalneural network that employs convolution on the input tokens to detect localtime-invariant and long-range topical attention features in a context-dependentway. We apply this architecture to the problem of extreme summarization ofsource code snippets into short, descriptive function name-like summaries.Using those features, the model sequentially generates a summary bymarginalizing over two attention mechanisms: one that predicts the next summarytoken based on the attention weights of the input tokens and another that isable to copy a code token as-is directly into the summary. We demonstrate ourconvolutional attention neural network's performance on 10 popular Javaprojects showing that it achieves better performance compared to previousattentional mechanisms.\",\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.SE'],\n",
       "  'journal': 'ICML, 2091-2100',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.03001v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4589077170845352419&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 187: {'ID': 187,\n",
       "  'title': 'Hierarchical Variational Models',\n",
       "  'authors': ['Dustin Tran', 'David M. Blei', 'Rajesh Ranganath'],\n",
       "  'published': '2015-11-07T19:01:48Z',\n",
       "  'updated': '2016-05-30T21:16:38Z',\n",
       "  'abstract': 'Black box variational inference allows researchers to easily prototype andevaluate an array of models. Recent advances allow such algorithms to scale tohigh dimensions. However, a central question remains: How to specify anexpressive variational distribution that maintains efficient computation? Toaddress this, we develop hierarchical variational models (HVMs). HVMs augment avariational approximation with a prior on its parameters, which allows it tocapture complex structure for both discrete and continuous latent variables.The algorithm we develop is black box, can be used for any HVM, and has thesame computational efficiency as the original approximation. We study HVMs on avariety of deep discrete latent variable models. HVMs generalize otherexpressive variational distributions and maintains higher fidelity to theposterior.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'stat.CO', 'stat.ME'],\n",
       "  'journal': 'ICML, 324-333',\n",
       "  'citations': '181',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.02386v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11945393107618844933&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 188: {'ID': 188,\n",
       "  'title': 'ConceptNet 5.5: An Open Multilingual Graph of General Knowledge',\n",
       "  'authors': ['Catherine Havasi', 'Robyn Speer', 'Joshua Chin'],\n",
       "  'published': '2016-12-12T23:54:52Z',\n",
       "  'updated': '2018-12-11T16:27:17Z',\n",
       "  'abstract': 'Machine learning about language can be improved by supplying it with specificknowledge and sources of external information. We present here a new version ofthe linked open data resource ConceptNet that is particularly well suited to beused with modern NLP techniques such as word embeddings.  ConceptNet is a knowledge graph that connects words and phrases of naturallanguage with labeled edges. Its knowledge is collected from many sources thatinclude expert-created resources, crowd-sourcing, and games with a purpose. Itis designed to represent the general knowledge involved in understandinglanguage, improving natural language applications by allowing the applicationto better understand the meanings behind the words people use.  When ConceptNet is combined with word embeddings acquired from distributionalsemantics (such as word2vec), it provides applications with understanding thatthey would not acquire from distributional semantics alone, nor from narrowerresources such as WordNet or DBPedia. We demonstrate this with state-of-the-artresults on intrinsic evaluations of word relatedness that translate intoimprovements on applications of word vectors, including solving SAT-styleanalogies.',\n",
       "  'categories': ['cs.CL', 'I.2.7'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '436',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.03975v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7089916805257737701&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 189: {'ID': 189,\n",
       "  'title': 'Toward Multimodal Image-to-Image Translation',\n",
       "  'authors': ['Alexei A. Efros',\n",
       "   'Eli Shechtman',\n",
       "   'Deepak Pathak',\n",
       "   'Trevor Darrell',\n",
       "   'Oliver Wang',\n",
       "   'Richard Zhang',\n",
       "   'Jun-Yan Zhu'],\n",
       "  'published': '2017-11-30T18:59:01Z',\n",
       "  'updated': '2018-10-24T00:29:43Z',\n",
       "  'abstract': 'Many image-to-image translation problems are ambiguous, as a single inputimage may correspond to multiple possible outputs. In this work, we aim tomodel a \\\\emph{distribution} of possible outputs in a conditional generativemodeling setting. The ambiguity of the mapping is distilled in alow-dimensional latent vector, which can be randomly sampled at test time. Agenerator learns to map the given input, combined with this latent code, to theoutput. We explicitly encourage the connection between output and the latentcode to be invertible. This helps prevent a many-to-one mapping from the latentcode to the output during training, also known as the problem of mode collapse,and produces more diverse results. We explore several variants of this approachby employing different training objectives, network architectures, and methodsof injecting the latent code. Our proposed method encourages bijectiveconsistency between the latent encoding and output modes. We present asystematic comparison of our method and other variants on both perceptualrealism and diversity.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '504',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.11586v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4719212061533508568&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 190: {'ID': 190,\n",
       "  'title': 'Deep Voice 2: Multi-Speaker Neural Text-to-Speech',\n",
       "  'authors': ['Sercan Arik',\n",
       "   'Wei Ping',\n",
       "   'Jonathan Raiman',\n",
       "   'Yanqi Zhou',\n",
       "   'John Miller',\n",
       "   'Andrew Gibiansky',\n",
       "   'Gregory Diamos',\n",
       "   'Kainan Peng'],\n",
       "  'published': '2017-05-24T19:53:13Z',\n",
       "  'updated': '2017-09-20T21:43:18Z',\n",
       "  'abstract': 'We introduce a technique for augmenting neural text-to-speech (TTS) withlowdimensional trainable speaker embeddings to generate different voices from asingle model. As a starting point, we show improvements over the twostate-ofthe-art approaches for single-speaker neural TTS: Deep Voice 1 andTacotron. We introduce Deep Voice 2, which is based on a similar pipeline withDeep Voice 1, but constructed with higher performance building blocks anddemonstrates a significant audio quality improvement over Deep Voice 1. Weimprove Tacotron by introducing a post-processing neural vocoder, anddemonstrate a significant audio quality improvement. We then demonstrate ourtechnique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotronon two multi-speaker TTS datasets. We show that a single neural TTS system canlearn hundreds of unique voices from less than half an hour of data perspeaker, while achieving high audio quality synthesis and preserving thespeaker identities almost perfectly.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '222',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08947v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=188402189689268087&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 191: {'ID': 191,\n",
       "  'title': 'Not Just a Black Box: Learning Important Features Through Propagating  Activation Differences',\n",
       "  'authors': ['Peyton Greenside',\n",
       "   'Anshul Kundaje',\n",
       "   'Anna Shcherbina',\n",
       "   'Avanti Shrikumar'],\n",
       "  'published': '2016-05-05T19:52:32Z',\n",
       "  'updated': '2017-04-11T15:58:48Z',\n",
       "  'abstract': 'Note: This paper describes an older version of DeepLIFT. Seehttps://arxiv.org/abs/1704.02685 for the newer version. Original abstractfollows: The purported \"black box\" nature of neural networks is a barrier toadoption in applications where interpretability is essential. Here we presentDeepLIFT (Learning Important FeaTures), an efficient and effective method forcomputing importance scores in a neural network. DeepLIFT compares theactivation of each neuron to its \\'reference activation\\' and assignscontribution scores according to the difference. We apply DeepLIFT to modelstrained on natural images and genomic data, and show significant advantagesover gradient-based methods.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICML, 3145-3153',\n",
       "  'citations': '605',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.01713v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3870608604214378324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 192: {'ID': 192,\n",
       "  'title': 'Robust Image Sentiment Analysis Using Progressively Trained and Domain  Transferred Deep Networks',\n",
       "  'authors': ['Jiebo Luo', 'Quanzeng You', 'Jianchao Yang', 'Hailin Jin'],\n",
       "  'published': '2015-09-20T18:36:01Z',\n",
       "  'updated': '2015-09-20T18:36:01Z',\n",
       "  'abstract': 'Sentiment analysis of online user generated content is important for manysocial media analytics tasks. Researchers have largely relied on textualsentiment analysis to develop systems to predict political elections, measureeconomic indicators, and so on. Recently, social media users are increasinglyusing images and videos to express their opinions and share their experiences.Sentiment analysis of such large scale visual content can help better extractuser sentiments toward events or topics, such as those in image tweets, so thatprediction of sentiment from visual content is complementary to textualsentiment analysis. Motivated by the needs in leveraging large scale yet noisytraining data to solve the extremely challenging problem of image sentimentanalysis, we employ Convolutional Neural Networks (CNN). We first design asuitable CNN architecture for image sentiment analysis. We obtain half amillion training samples by using a baseline sentiment algorithm to labelFlickr images. To make use of such noisy machine labeled data, we employ aprogressive strategy to fine-tune the deep network. Furthermore, we improve theperformance on Twitter images by inducing domain transfer with a small numberof manually labeled Twitter images. We have conducted extensive experiments onmanually labeled Twitter images. The results show that the proposed CNN canachieve better performance in image sentiment analysis than competingalgorithms.',\n",
       "  'categories': ['cs.CV', 'cs.IR', 'cs.LG'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '309',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.06041v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5622309859830710042&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 193: {'ID': 193,\n",
       "  'title': 'On the Convergence of Adam and Beyond',\n",
       "  'authors': ['Sanjiv Kumar', 'Sashank J. Reddi', 'Satyen Kale'],\n",
       "  'published': '2019-04-19T16:21:38Z',\n",
       "  'updated': '2019-04-19T16:21:38Z',\n",
       "  'abstract': \"Several recently proposed stochastic optimization methods that have beensuccessfully used in training deep networks such as RMSProp, Adam, Adadelta,Nadam are based on using gradient updates scaled by square roots of exponentialmoving averages of squared past gradients. In many applications, e.g. learningwith large output spaces, it has been empirically observed that thesealgorithms fail to converge to an optimal solution (or a critical point innonconvex settings). We show that one cause for such failures is theexponential moving average used in the algorithms. We provide an explicitexample of a simple convex optimization setting where Adam does not converge tothe optimal solution, and describe the precise problems with the previousanalysis of Adam algorithm. Our analysis suggests that the convergence issuescan be fixed by endowing such algorithms with `long-term memory' of pastgradients, and propose new variants of the Adam algorithm which not only fixthe convergence issues but often also lead to improved empirical performance.\",\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '732',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.09237v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7572152545124305671&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 194: {'ID': 194,\n",
       "  'title': 'Unsupervised Learning of Video Representations using LSTMs',\n",
       "  'authors': ['Elman Mansimov', 'Nitish Srivastava', 'Ruslan Salakhutdinov'],\n",
       "  'published': '2015-02-16T20:00:07Z',\n",
       "  'updated': '2016-01-04T00:42:07Z',\n",
       "  'abstract': 'We use multilayer Long Short Term Memory (LSTM) networks to learnrepresentations of video sequences. Our model uses an encoder LSTM to map aninput sequence into a fixed length representation. This representation isdecoded using single or multiple decoder LSTMs to perform different tasks, suchas reconstructing the input sequence, or predicting the future sequence. Weexperiment with two kinds of input sequences - patches of image pixels andhigh-level representations (\"percepts\") of video frames extracted using apretrained convolutional net. We explore different design choices such aswhether the decoder LSTMs should condition on the generated output. We analyzethe outputs of the model qualitatively to see how well the model canextrapolate the learned video representation into the future and into the past.We try to visualize and interpret the learned features. We stress test themodel by running it on longer time scales and on out-of-domain data. We furtherevaluate the representations by finetuning them for a supervised learningproblem - human action recognition on the UCF-101 and HMDB-51 datasets. We showthat the representations help improve classification accuracy, especially whenthere are only a few training examples. Even models pretrained on unrelateddatasets (300 hours of YouTube videos) can help action recognition performance.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICML, 843-852',\n",
       "  'citations': '1486',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.04681v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6890473943204323716&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 195: {'ID': 195,\n",
       "  'title': 'Neural Programmer: Inducing Latent Programs with Gradient Descent',\n",
       "  'authors': ['Ilya Sutskever', 'Quoc V. Le', 'Arvind Neelakantan'],\n",
       "  'published': '2015-11-16T06:03:58Z',\n",
       "  'updated': '2016-08-04T18:23:03Z',\n",
       "  'abstract': 'Deep neural networks have achieved impressive supervised classificationperformance in many tasks including image recognition, speech recognition, andsequence to sequence learning. However, this success has not been translated toapplications like question answering that may involve complex arithmetic andlogic reasoning. A major limitation of these models is in their inability tolearn even simple arithmetic and logic operations. For example, it has beenshown that neural networks fail to learn to add two binary numbers reliably. Inthis work, we propose Neural Programmer, an end-to-end differentiable neuralnetwork augmented with a small set of basic arithmetic and logic operations.Neural Programmer can call these augmented operations over several steps,thereby inducing compositional programs that are more complex than the built-inoperations. The model learns from a weak supervision signal which is the resultof execution of the correct program, hence it does not require expensiveannotation of the correct program itself. The decisions of what operations tocall, and what data segments to apply to are inferred by Neural Programmer.Such decisions, during training, are done in a differentiable fashion so thatthe entire network can be trained jointly by gradient descent. We find thattraining the model is difficult, but it can be greatly improved by addingrandom noise to the gradient. On a fairly complex synthetic table-comprehensiondataset, traditional recurrent networks and attentional models perform poorlywhile Neural Programmer typically obtains nearly perfect accuracy.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.04834v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10960563963124584900&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 196: {'ID': 196,\n",
       "  'title': 'Improved Techniques for Training GANs',\n",
       "  'authors': ['Vicki Cheung',\n",
       "   'Xi Chen',\n",
       "   'Ian Goodfellow',\n",
       "   'Tim Salimans',\n",
       "   'Wojciech Zaremba',\n",
       "   'Alec Radford'],\n",
       "  'published': '2016-06-10T22:53:35Z',\n",
       "  'updated': '2016-06-10T22:53:35Z',\n",
       "  'abstract': 'We present a variety of new architectural features and training proceduresthat we apply to the generative adversarial networks (GANs) framework. We focuson two applications of GANs: semi-supervised learning, and the generation ofimages that humans find visually realistic. Unlike most work on generativemodels, our primary goal is not to train a model that assigns high likelihoodto test data, nor do we require the model to be able to learn well withoutusing any labels. Using our new techniques, we achieve state-of-the-art resultsin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generatedimages are of high quality as confirmed by a visual Turing test: our modelgenerates MNIST samples that humans cannot distinguish from real data, andCIFAR-10 samples that yield a human error rate of 21.3%. We also presentImageNet samples with unprecedented resolution and show that our methods enablethe model to learn recognizable features of ImageNet classes.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '3522',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.03498v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2151481962498772342&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 197: {'ID': 197,\n",
       "  'title': 'Spherical CNNs',\n",
       "  'authors': ['Taco S. Cohen', 'Max Welling', 'Mario Geiger', 'Jonas Koehler'],\n",
       "  'published': '2018-01-30T18:28:30Z',\n",
       "  'updated': '2018-02-25T13:43:49Z',\n",
       "  'abstract': 'Convolutional Neural Networks (CNNs) have become the method of choice forlearning problems involving 2D planar images. However, a number of problems ofrecent interest have created a demand for models that can analyze sphericalimages. Examples include omnidirectional vision for drones, robots, andautonomous cars, molecular regression problems, and global weather and climatemodelling. A naive application of convolutional networks to a planar projectionof the spherical signal is destined to fail, because the space-varyingdistortions introduced by such a projection will make translational weightsharing ineffective.  In this paper we introduce the building blocks for constructing sphericalCNNs. We propose a definition for the spherical cross-correlation that is bothexpressive and rotation-equivariant. The spherical correlation satisfies ageneralized Fourier theorem, which allows us to compute it efficiently using ageneralized (non-commutative) Fast Fourier Transform (FFT) algorithm. Wedemonstrate the computational efficiency, numerical accuracy, and effectivenessof spherical CNNs applied to 3D model recognition and atomization energyregression.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '251',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.10130v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6361332838540502667&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 198: {'ID': 198,\n",
       "  'title': 'Snapshot Ensembles: Train 1, get M for free',\n",
       "  'authors': ['Gao Huang',\n",
       "   'Zhuang Liu',\n",
       "   'Yixuan Li',\n",
       "   'Kilian Q. Weinberger',\n",
       "   'John E. Hopcroft',\n",
       "   'Geoff Pleiss'],\n",
       "  'published': '2017-04-01T02:42:55Z',\n",
       "  'updated': '2017-04-01T02:42:55Z',\n",
       "  'abstract': 'Ensembles of neural networks are known to be much more robust and accuratethan individual networks. However, training multiple deep networks for modelaveraging is computationally expensive. In this paper, we propose a method toobtain the seemingly contradictory goal of ensembling multiple neural networksat no additional training cost. We achieve this goal by training a singleneural network, converging to several local minima along its optimization pathand saving the model parameters. To obtain repeated rapid convergence, weleverage recent work on cyclic learning rate schedules. The resultingtechnique, which we refer to as Snapshot Ensembling, is simple, yetsurprisingly effective. We show in a series of experiments that our approach iscompatible with diverse network architectures and learning tasks. Itconsistently yields lower error rates than state-of-the-art single models at noadditional training cost, and compares favorably with traditional networkensembles. On CIFAR-10 and CIFAR-100 our DenseNet Snapshot Ensembles obtainerror rates of 3.4% and 17.4% respectively.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.00109v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13258787322136448860&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 199: {'ID': 199,\n",
       "  'title': 'High-Dimensional Continuous Control Using Generalized Advantage  Estimation',\n",
       "  'authors': ['Sergey Levine',\n",
       "   'Philipp Moritz',\n",
       "   'John Schulman',\n",
       "   'Michael Jordan',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2015-06-08T11:12:48Z',\n",
       "  'updated': '2018-10-20T18:55:07Z',\n",
       "  'abstract': 'Policy gradient methods are an appealing approach in reinforcement learningbecause they directly optimize the cumulative reward and can straightforwardlybe used with nonlinear function approximators such as neural networks. The twomain challenges are the large number of samples typically required, and thedifficulty of obtaining stable and steady improvement despite thenonstationarity of the incoming data. We address the first challenge by usingvalue functions to substantially reduce the variance of policy gradientestimates at the cost of some bias, with an exponentially-weighted estimator ofthe advantage function that is analogous to TD(lambda). We address the secondchallenge by using trust region optimization procedure for both the policy andthe value function, which are represented by neural networks.  Our approach yields strong empirical results on highly challenging 3Dlocomotion tasks, learning running gaits for bipedal and quadrupedal simulatedrobots, and learning a policy for getting the biped to stand up from startingout lying on the ground. In contrast to a body of prior work that useshand-crafted policy representations, our neural network policies map directlyfrom raw kinematics to joint torques. Our algorithm is fully model-free, andthe amount of simulated experience required for the learning tasks on 3D bipedscorresponds to 1-2 weeks of real time.',\n",
       "  'categories': ['cs.LG', 'cs.RO', 'cs.SY'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '875',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02438v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7176097012963036784&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 200: {'ID': 200,\n",
       "  'title': 'Formal Guarantees on the Robustness of a Classifier against Adversarial  Manipulation',\n",
       "  'authors': ['Maksym Andriushchenko', 'Matthias Hein'],\n",
       "  'published': '2017-05-23T18:48:20Z',\n",
       "  'updated': '2017-11-05T20:58:09Z',\n",
       "  'abstract': 'Recent work has shown that state-of-the-art classifiers are quite brittle, inthe sense that a small adversarial change of an originally with high confidencecorrectly classified input leads to a wrong classification again with highconfidence. This raises concerns that such classifiers are vulnerable toattacks and calls into question their usage in safety-critical systems. We showin this paper for the first time formal guarantees on the robustness of aclassifier by giving instance-specific lower bounds on the norm of the inputmanipulation required to change the classifier decision. Based on this analysiswe propose the Cross-Lipschitz regularization functional. We show that usingthis form of regularization in kernel methods resp. neural networks improvesthe robustness of the classifier without any loss in prediction performance.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '198',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08475v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7126535280922614101&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 201: {'ID': 201,\n",
       "  'title': 'Multi-task Sequence to Sequence Learning',\n",
       "  'authors': ['Minh-Thang Luong',\n",
       "   'Ilya Sutskever',\n",
       "   'Oriol Vinyals',\n",
       "   'Lukasz Kaiser',\n",
       "   'Quoc V. Le'],\n",
       "  'published': '2015-11-19T10:24:14Z',\n",
       "  'updated': '2016-03-01T10:55:58Z',\n",
       "  'abstract': 'Sequence to sequence learning has recently emerged as a new paradigm insupervised learning. To date, most of its applications focused on only one taskand not much work explored this framework for multiple tasks. This paperexamines three multi-task learning (MTL) settings for sequence to sequencemodels: (a) the oneto-many setting - where the encoder is shared betweenseveral tasks such as machine translation and syntactic parsing, (b) themany-to-one setting - useful when only the decoder can be shared, as in thecase of translation and image caption generation, and (c) the many-to-manysetting - where multiple encoders and decoders are shared, which is the casewith unsupervised objectives and translation. Our results show that training ona small amount of parsing and image caption data can improve the translationquality between English and German by up to 1.5 BLEU points over strongsingle-task baselines on the WMT benchmarks. Furthermore, we have established anew state-of-the-art result in constituent parsing with 93.0 F1. Lastly, wereveal interesting properties of the two unsupervised learning objectives,autoencoder and skip-thought, in the MTL context: autoencoder helps less interms of perplexities but more on BLEU scores compared to skip-thought.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '546',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06114v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6045967109711129604&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 202: {'ID': 202,\n",
       "  'title': 'QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding',\n",
       "  'authors': ['Ryota Tomioka',\n",
       "   'Milan Vojnovic',\n",
       "   'Dan Alistarh',\n",
       "   'Jerry Li',\n",
       "   'Demjan Grubic'],\n",
       "  'published': '2016-10-07T03:44:34Z',\n",
       "  'updated': '2017-12-06T18:28:32Z',\n",
       "  'abstract': 'Parallel implementations of stochastic gradient descent (SGD) have receivedsignificant research attention, thanks to excellent scalability properties ofthis algorithm, and to its efficiency in the context of training deep neuralnetworks. A fundamental barrier for parallelizing large-scale SGD is the factthat the cost of communicating the gradient updates between nodes can be verylarge. Consequently, lossy compression heuristics have been proposed, by whichnodes only communicate quantized gradients. Although effective in practice,these heuristics do not always provably converge, and it is not clear whetherthey are optimal.  In this paper, we propose Quantized SGD (QSGD), a family of compressionschemes which allow the compression of gradient updates at each node, whileguaranteeing convergence under standard assumptions. QSGD allows the user totrade off compression and convergence time: it can communicate a sublinearnumber of bits per iteration in the model dimension, and can achieveasymptotically optimal communication cost. We complement our theoreticalresults with empirical data, showing that QSGD can significantly reducecommunication cost, while being competitive with standard uncompressedtechniques on a variety of real tasks.  In particular, experiments show that gradient quantization applied totraining of deep neural networks for image classification and automated speechrecognition can lead to significant reductions in communication cost, andend-to-end training time. For instance, on 16 GPUs, we are able to train aResNet-152 network on ImageNet 1.8x faster to full accuracy. Of note, we showthat there exist generic parameter settings under which all known networkarchitectures preserve or slightly improve their full accuracy when usingquantization.',\n",
       "  'categories': ['cs.LG', 'cs.DS'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '287',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.02132v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14481730973283095659&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 203: {'ID': 203,\n",
       "  'title': 'Learning Continuous Control Policies by Stochastic Value Gradients',\n",
       "  'authors': ['Yuval Tassa',\n",
       "   'Greg Wayne',\n",
       "   'Nicolas Heess',\n",
       "   'Timothy Lillicrap',\n",
       "   'Tom Erez',\n",
       "   'David Silver'],\n",
       "  'published': '2015-10-30T16:07:51Z',\n",
       "  'updated': '2015-10-30T16:07:51Z',\n",
       "  'abstract': 'We present a unified framework for learning continuous control policies usingbackpropagation. It supports stochastic control by treating stochasticity inthe Bellman equation as a deterministic function of exogenous noise. Theproduct is a spectrum of general policy gradient algorithms that range frommodel-free methods with value functions to model-based methods without valuefunctions. We use learned models but only require observations from theenvironment in- stead of observations from model-predicted trajectories,minimizing the impact of compounded model errors. We apply these algorithmsfirst to a toy stochastic control problem and then to several physics-basedcontrol problems in simulation. One of these variants, SVG(1), shows theeffectiveness of learning models, value functions, and policies simultaneouslyin continuous domains.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '313',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.09142v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2728724061281364322&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 204: {'ID': 204,\n",
       "  'title': 'Neural Message Passing for Quantum Chemistry',\n",
       "  'authors': ['Justin Gilmer',\n",
       "   'Patrick F. Riley',\n",
       "   'Oriol Vinyals',\n",
       "   'Samuel S. Schoenholz',\n",
       "   'George E. Dahl'],\n",
       "  'published': '2017-04-04T23:00:44Z',\n",
       "  'updated': '2017-06-12T20:52:56Z',\n",
       "  'abstract': 'Supervised learning on molecules has incredible potential to be useful inchemistry, drug discovery, and materials science. Luckily, several promisingand closely related neural network models invariant to molecular symmetrieshave already been described in the literature. These models learn a messagepassing algorithm and aggregation procedure to compute a function of theirentire input graph. At this point, the next step is to find a particularlyeffective variant of this general approach and apply it to chemical predictionbenchmarks until we either solve them or reach the limits of the approach. Inthis paper, we reformulate existing models into a single common framework wecall Message Passing Neural Networks (MPNNs) and explore additional novelvariations within this framework. Using MPNNs we demonstrate state of the artresults on an important molecular property prediction benchmark; these resultsare strong enough that we believe future work should focus on datasets withlarger molecules or more accurate ground truth labels.',\n",
       "  'categories': ['cs.LG', 'I.2.6'],\n",
       "  'journal': 'ICML, 1263-1272',\n",
       "  'citations': '1151',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.01212v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6135306581977403485&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 205: {'ID': 205,\n",
       "  'title': 'Deep Convolutional Inverse Graphics Network',\n",
       "  'authors': ['Pushmeet Kohli',\n",
       "   'Tejas D. Kulkarni',\n",
       "   'Joshua B. Tenenbaum',\n",
       "   'Will Whitney'],\n",
       "  'published': '2015-03-11T04:08:42Z',\n",
       "  'updated': '2015-06-22T02:10:00Z',\n",
       "  'abstract': \"This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), amodel that learns an interpretable representation of images. Thisrepresentation is disentangled with respect to transformations such asout-of-plane rotations and lighting variations. The DC-IGN model is composed ofmultiple layers of convolution and de-convolution operators and is trainedusing the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose atraining procedure to encourage neurons in the graphics code layer to representa specific transformation (e.g. pose or light). Given a single input image, ourmodel can generate new images of the same object with variations in pose andlighting. We present qualitative and quantitative results of the model'sefficacy at learning a 3D rendering engine.\",\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '649',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.03167v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17778197936641141684&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 206: {'ID': 206,\n",
       "  'title': 'End-To-End Memory Networks',\n",
       "  'authors': ['Arthur Szlam',\n",
       "   'Jason Weston',\n",
       "   'Sainbayar Sukhbaatar',\n",
       "   'Rob Fergus'],\n",
       "  'published': '2015-03-31T03:05:37Z',\n",
       "  'updated': '2015-11-24T19:41:57Z',\n",
       "  'abstract': 'We introduce a neural network with a recurrent attention model over apossibly large external memory. The architecture is a form of Memory Network(Weston et al., 2015) but unlike the model in that work, it is trainedend-to-end, and hence requires significantly less supervision during training,making it more generally applicable in realistic settings. It can also be seenas an extension of RNNsearch to the case where multiple computational steps(hops) are performed per output symbol. The flexibility of the model allows usto apply it to tasks as diverse as (synthetic) question answering and tolanguage modeling. For the former our approach is competitive with MemoryNetworks, but with less supervision. For the latter, on the Penn TreeBank andText8 datasets our approach demonstrates comparable performance to RNNs andLSTMs. In both cases we show that the key concept of multiple computationalhops yields improved results.',\n",
       "  'categories': ['cs.NE', 'cs.CL'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1720',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.08895v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9907515383987281804&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 207: {'ID': 207,\n",
       "  'title': 'Label-Free Supervision of Neural Networks with Physics and Domain  Knowledge',\n",
       "  'authors': ['Russell Stewart', 'Stefano Ermon'],\n",
       "  'published': '2016-09-18T23:16:14Z',\n",
       "  'updated': '2016-09-18T23:16:14Z',\n",
       "  'abstract': 'In many machine learning applications, labeled data is scarce and obtainingmore labels is expensive. We introduce a new approach to supervising neuralnetworks by specifying constraints that should hold over the output space,rather than direct examples of input-output pairs. These constraints arederived from prior domain knowledge, e.g., from known laws of physics. Wedemonstrate the effectiveness of this approach on real world and simulatedcomputer vision tasks. We are able to train a convolutional neural network todetect and track objects without any labeled examples. Our approach cansignificantly reduce the need for labeled training data, but introduces newchallenges for encoding prior knowledge into appropriate loss functions.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '148',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.05566v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16817242517861584671&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 208: {'ID': 208,\n",
       "  'title': 'Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments',\n",
       "  'authors': ['Igor Mordatch',\n",
       "   'Ryan Lowe',\n",
       "   'Aviv Tamar',\n",
       "   'Jean Harb',\n",
       "   'Yi Wu',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-06-07T17:35:00Z',\n",
       "  'updated': '2020-03-14T20:33:00Z',\n",
       "  'abstract': 'We explore deep reinforcement learning methods for multi-agent domains. Webegin by analyzing the difficulty of traditional algorithms in the multi-agentcase: Q-learning is challenged by an inherent non-stationarity of theenvironment, while policy gradient suffers from a variance that increases asthe number of agents grows. We then present an adaptation of actor-criticmethods that considers action policies of other agents and is able tosuccessfully learn policies that require complex multi-agent coordination.Additionally, we introduce a training regimen utilizing an ensemble of policiesfor each agent that leads to more robust multi-agent policies. We show thestrength of our approach compared to existing methods in cooperative as well ascompetitive scenarios, where agent populations are able to discover variousphysical and informational coordination strategies.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '724',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02275v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11728876531627940507&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 209: {'ID': 209,\n",
       "  'title': 'Reinforcement Learning with Deep Energy-Based Policies',\n",
       "  'authors': ['Tuomas Haarnoja',\n",
       "   'Haoran Tang',\n",
       "   'Sergey Levine',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-02-27T07:16:41Z',\n",
       "  'updated': '2017-07-21T20:25:54Z',\n",
       "  'abstract': 'We propose a method for learning expressive energy-based policies forcontinuous states and actions, which has been feasible only in tabular domainsbefore. We apply our method to learning maximum entropy policies, resultinginto a new algorithm, called soft Q-learning, that expresses the optimal policyvia a Boltzmann distribution. We use the recently proposed amortized Steinvariational gradient descent to learn a stochastic sampling network thatapproximates samples from this distribution. The benefits of the proposedalgorithm include improved exploration and compositionality that allowstransferring skills between tasks, which we confirm in simulated experimentswith swimming and walking robots. We also draw a connection to actor-criticmethods, which can be viewed performing approximate inference on thecorresponding energy-based model.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'ICML, 1352-1361',\n",
       "  'citations': '369',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.08165v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10187244454208251417&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 210: {'ID': 210,\n",
       "  'title': 'Is feature selection secure against training data poisoning?',\n",
       "  'authors': ['Battista Biggio',\n",
       "   'Giorgio Fumera',\n",
       "   'Claudia Eckert',\n",
       "   'Fabio Roli',\n",
       "   'Gavin Brown',\n",
       "   'Huang Xiao'],\n",
       "  'published': '2018-04-21T10:18:46Z',\n",
       "  'updated': '2018-04-21T10:18:46Z',\n",
       "  'abstract': 'Learning in adversarial settings is becoming an important task forapplication domains where attackers may inject malicious data into the trainingset to subvert normal operation of data-driven technologies. Feature selectionhas been widely used in machine learning for security applications to improvegeneralization and computational efficiency, although it is not clear whetherits use may be beneficial or even counterproductive when training data arepoisoned by intelligent attackers. In this work, we shed light on this issue byproviding a framework to investigate the robustness of popular featureselection methods, including LASSO, ridge regression and the elastic net. Ourresults on malware detection show that feature selection methods can besignificantly compromised under attack (we can reduce LASSO to almost randomchoices of feature sets by careful insertion of less than 5% poisoned trainingsamples), highlighting the need for specific countermeasures.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'cs.GT', 'stat.ML'],\n",
       "  'journal': 'ICML, 1689-1698',\n",
       "  'citations': '180',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.07933v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1517576158054536968&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 211: {'ID': 211,\n",
       "  'title': 'A Compositional Object-Based Approach to Learning Physical Dynamics',\n",
       "  'authors': ['Antonio Torralba',\n",
       "   'Joshua B. Tenenbaum',\n",
       "   'Tomer Ullman',\n",
       "   'Michael B. Chang'],\n",
       "  'published': '2016-12-01T16:39:04Z',\n",
       "  'updated': '2017-03-04T17:44:06Z',\n",
       "  'abstract': \"We present the Neural Physics Engine (NPE), a framework for learningsimulators of intuitive physics that naturally generalize across variableobject count and different scene configurations. We propose a factorization ofa physical scene into composable object-based representations and a neuralnetwork architecture whose compositional structure factorizes object dynamicsinto pairwise interactions. Like a symbolic physics engine, the NPE is endowedwith generic notions of objects and their interactions; realized as a neuralnetwork, it can be trained via stochastic gradient descent to adapt to specificobject properties and dynamics of different worlds. We evaluate the efficacy ofour approach on simple rigid body dynamics in two-dimensional worlds. Bycomparing to less structured architectures, we show that the NPE'scompositional representation of the structure in physical interactions improvesits ability to predict movement, generalize across variable object count anddifferent scene configurations, and infer latent properties of objects such asmass.\",\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '220',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.00341v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9706972547667418204&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 212: {'ID': 212,\n",
       "  'title': 'Word Translation Without Parallel Data',\n",
       "  'authors': ['Alexis Conneau',\n",
       "   'Guillaume Lample',\n",
       "   'Ludovic Denoyer',\n",
       "   'Hervé Jégou',\n",
       "   \"Marc'Aurelio Ranzato\"],\n",
       "  'published': '2017-10-11T14:24:28Z',\n",
       "  'updated': '2018-01-30T14:41:51Z',\n",
       "  'abstract': 'State-of-the-art methods for learning cross-lingual word embeddings haverelied on bilingual dictionaries or parallel corpora. Recent studies showedthat the need for parallel data supervision can be alleviated withcharacter-level information. While these methods showed encouraging results,they are not on par with their supervised counterparts and are limited to pairsof languages sharing a common alphabet. In this work, we show that we can builda bilingual dictionary between two languages without using any parallelcorpora, by aligning monolingual word embedding spaces in an unsupervised way.Without using any character information, our model even outperforms existingsupervised methods on cross-lingual tasks for some language pairs. Ourexperiments demonstrate that our method works very well also for distantlanguage pairs, like English-Russian or English-Chinese. We finally describeexperiments on the English-Esperanto low-resource language pair, on which thereonly exists a limited amount of parallel data, to show the potential impact ofour method in fully unsupervised machine translation. Our code, embeddings anddictionaries are publicly available.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '658',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.04087v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10646845124593498896&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 213: {'ID': 213,\n",
       "  'title': 'PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture  Likelihood and Other Modifications',\n",
       "  'authors': ['Diederik P. Kingma',\n",
       "   'Xi Chen',\n",
       "   'Andrej Karpathy',\n",
       "   'Tim Salimans'],\n",
       "  'published': '2017-01-19T17:29:06Z',\n",
       "  'updated': '2017-01-19T17:29:06Z',\n",
       "  'abstract': 'PixelCNNs are a recently proposed class of powerful generative models withtractable likelihood. Here we discuss our implementation of PixelCNNs which wemake available at https://github.com/openai/pixel-cnn. Our implementationcontains a number of modifications to the original model that both simplify itsstructure and improve its performance. 1) We use a discretized logistic mixturelikelihood on the pixels, rather than a 256-way softmax, which we find to speedup training. 2) We condition on whole pixels, rather than R/G/B sub-pixels,simplifying the model structure. 3) We use downsampling to efficiently capturestructure at multiple resolutions. 4) We introduce additional short-cutconnections to further speed up optimization. 5) We regularize the model usingdropout. Finally, we present state-of-the-art log likelihood results onCIFAR-10 to demonstrate the usefulness of these modifications.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '337',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.05517v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3764972270987352239&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 214: {'ID': 214,\n",
       "  'title': 'Avoiding Discrimination through Causal Reasoning',\n",
       "  'authors': ['Bernhard Schölkopf',\n",
       "   'Niki Kilbertus',\n",
       "   'Dominik Janzing',\n",
       "   'Giambattista Parascandolo',\n",
       "   'Moritz Hardt',\n",
       "   'Mateo Rojas-Carulla'],\n",
       "  'published': '2017-06-08T19:50:56Z',\n",
       "  'updated': '2018-01-21T16:39:51Z',\n",
       "  'abstract': 'Recent work on fairness in machine learning has focused on variousstatistical discrimination criteria and how they trade off. Most of thesecriteria are observational: They depend only on the joint distribution ofpredictor, protected attribute, features, and outcome. While convenient to workwith, observational criteria have severe inherent limitations that prevent themfrom resolving matters of fairness conclusively.  Going beyond observational criteria, we frame the problem of discriminationbased on protected attributes in the language of causal reasoning. Thisviewpoint shifts attention from \"What is the right fairness criterion?\" to\"What do we want to assume about the causal data generating process?\" Throughthe lens of causality, we make several contributions. First, we crisplyarticulate why and when observational criteria fail, thus formalizing what wasbefore a matter of opinion. Second, our approach exposes previously ignoredsubtleties and why they are fundamental to the problem. Finally, we put forwardnatural causal non-discrimination criteria and develop algorithms that satisfythem.',\n",
       "  'categories': ['stat.ML', 'cs.CY', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '213',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02744v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1456063515469711783&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 215: {'ID': 215,\n",
       "  'title': 'Learning Deep Embeddings with Histogram Loss',\n",
       "  'authors': ['Evgeniya Ustinova', 'Victor Lempitsky'],\n",
       "  'published': '2016-11-02T21:48:32Z',\n",
       "  'updated': '2016-11-02T21:48:32Z',\n",
       "  'abstract': 'We suggest a loss for learning deep embeddings. The new loss does notintroduce parameters that need to be tuned and results in very good embeddingsacross a range of datasets and problems. The loss is computed by estimating twodistribution of similarities for positive (matching) and negative(non-matching) sample pairs, and then computing the probability of a positivepair to have a lower similarity score than a negative pair based on theestimated similarity distributions. We show that such operations can beperformed in a simple and piecewise-differentiable manner using 1D histogramswith soft assignment operations. This makes the proposed loss suitable forlearning deep embeddings using stochastic optimization. In the experiments, thenew loss performs favourably compared to recently proposed alternatives.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '205',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.00822v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6994791028704777674&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 216: {'ID': 216,\n",
       "  'title': 'Convolutional LSTM Network: A Machine Learning Approach for  Precipitation Nowcasting',\n",
       "  'authors': ['Wai-kin Wong',\n",
       "   'Wang-chun Woo',\n",
       "   'Xingjian Shi',\n",
       "   'Dit-Yan Yeung',\n",
       "   'Hao Wang',\n",
       "   'Zhourong Chen'],\n",
       "  'published': '2015-06-13T03:19:24Z',\n",
       "  'updated': '2015-09-19T11:02:03Z',\n",
       "  'abstract': 'The goal of precipitation nowcasting is to predict the future rainfallintensity in a local region over a relatively short period of time. Very fewprevious studies have examined this crucial and challenging weather forecastingproblem from the machine learning perspective. In this paper, we formulateprecipitation nowcasting as a spatiotemporal sequence forecasting problem inwhich both the input and the prediction target are spatiotemporal sequences. Byextending the fully connected LSTM (FC-LSTM) to have convolutional structuresin both the input-to-state and state-to-state transitions, we propose theconvolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable modelfor the precipitation nowcasting problem. Experiments show that our ConvLSTMnetwork captures spatiotemporal correlations better and consistentlyoutperforms FC-LSTM and the state-of-the-art operational ROVER algorithm forprecipitation nowcasting.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '2059',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.04214v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5469943753756181884&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 217: {'ID': 217,\n",
       "  'title': 'IMPALA: Scalable Distributed Deep-RL with Importance Weighted  Actor-Learner Architectures',\n",
       "  'authors': ['Vlad Firoiu',\n",
       "   'Tom Ward',\n",
       "   'Tim Harley',\n",
       "   'Volodymir Mnih',\n",
       "   'Shane Legg',\n",
       "   'Karen Simonyan',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Iain Dunning',\n",
       "   'Hubert Soyer',\n",
       "   'Yotam Doron',\n",
       "   'Remi Munos',\n",
       "   'Lasse Espeholt'],\n",
       "  'published': '2018-02-05T18:47:30Z',\n",
       "  'updated': '2018-06-28T06:54:39Z',\n",
       "  'abstract': 'In this work we aim to solve a large collection of tasks using a singlereinforcement learning agent with a single set of parameters. A key challengeis to handle the increased amount of data and extended training time. We havedeveloped a new distributed agent IMPALA (Importance Weighted Actor-LearnerArchitecture) that not only uses resources more efficiently in single-machinetraining but also scales to thousands of machines without sacrificing dataefficiency or resource utilisation. We achieve stable learning at highthroughput by combining decoupled acting and learning with a novel off-policycorrection method called V-trace. We demonstrate the effectiveness of IMPALAfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from theDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all availableAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Ourresults show that IMPALA is able to achieve better performance than previousagents with less data, and crucially exhibits positive transfer between tasksas a result of its multi-task approach.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'ICML, 1406-1415',\n",
       "  'citations': '373',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.01561v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14673826846490570917&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 218: {'ID': 218,\n",
       "  'title': 'Long Text Generation via Adversarial Training with Leaked Information',\n",
       "  'authors': ['Sidi Lu',\n",
       "   'Yong Yu',\n",
       "   'Weinan Zhang',\n",
       "   'Jiaxian Guo',\n",
       "   'Han Cai',\n",
       "   'Jun Wang'],\n",
       "  'published': '2017-09-24T13:35:08Z',\n",
       "  'updated': '2017-12-08T18:53:52Z',\n",
       "  'abstract': 'Automatically generating coherent and semantically meaningful text has manyapplications in machine translation, dialogue systems, image captioning, etc.Recently, by combining with policy gradient, Generative Adversarial Nets (GAN)that use a discriminative model to guide the training of the generative modelas a reinforcement learning policy has shown promising results in textgeneration. However, the scalar guiding signal is only available after theentire text has been generated and lacks intermediate information about textstructure during the generative process. As such, it limits its success whenthe length of the generated text samples is long (more than 20 words). In thispaper, we propose a new framework, called LeakGAN, to address the problem forlong text generation. We allow the discriminative net to leak its ownhigh-level extracted features to the generative net to further help theguidance. The generator incorporates such informative signals into allgeneration steps through an additional Manager module, which takes theextracted features of current generated words and outputs a latent vector toguide the Worker module for next-word generation. Our extensive experiments onsynthetic data and various real-world tasks with Turing test demonstrate thatLeakGAN is highly effective in long text generation and also improves theperformance in short text generation scenarios. More importantly, without anysupervision, LeakGAN would be able to implicitly learn sentence structures onlythrough the interaction between Manager and Worker.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '162',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.08624v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10032525507167574810&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 219: {'ID': 219,\n",
       "  'title': 'Dynamic Routing Between Capsules',\n",
       "  'authors': ['Nicholas Frosst', 'Sara Sabour', 'Geoffrey E Hinton'],\n",
       "  'published': '2017-10-26T17:49:04Z',\n",
       "  'updated': '2017-11-07T19:26:38Z',\n",
       "  'abstract': 'A capsule is a group of neurons whose activity vector represents theinstantiation parameters of a specific type of entity such as an object or anobject part. We use the length of the activity vector to represent theprobability that the entity exists and its orientation to represent theinstantiation parameters. Active capsules at one level make predictions, viatransformation matrices, for the instantiation parameters of higher-levelcapsules. When multiple predictions agree, a higher level capsule becomesactive. We show that a discrimininatively trained, multi-layer capsule systemachieves state-of-the-art performance on MNIST and is considerably better thana convolutional net at recognizing highly overlapping digits. To achieve theseresults we use an iterative routing-by-agreement mechanism: A lower-levelcapsule prefers to send its output to higher level capsules whose activityvectors have a big scalar product with the prediction coming from thelower-level capsule.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1620',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.09829v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5914955692202761908&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 220: {'ID': 220,\n",
       "  'title': 'Neural Variational Inference for Text Processing',\n",
       "  'authors': ['Yishu Miao', 'Lei Yu', 'Phil Blunsom'],\n",
       "  'published': '2015-11-19T01:23:28Z',\n",
       "  'updated': '2016-06-04T06:41:58Z',\n",
       "  'abstract': 'Recent advances in neural variational inference have spawned a renaissance indeep latent variable models. In this paper we introduce a generic variationalinference framework for generative and conditional models of text. Whiletraditional variational methods derive an analytic approximation for theintractable distributions over latent variables, here we construct an inferencenetwork conditioned on the discrete text input to provide the variationaldistribution. We validate this framework on two very different text modellingapplications, generative document modelling and supervised question answering.Our neural variational document model combines a continuous stochastic documentrepresentation with a bag-of-words generative model and achieves the lowestreported perplexities on two standard test corpora. The neural answer selectionmodel employs a stochastic representation layer within an attention mechanismto extract the semantics between a question and answer pair. On two questionanswering benchmarks this model exceeds all previous published benchmarks.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 1727-1736',\n",
       "  'citations': '323',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06038v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7999736886109588436&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 221: {'ID': 221,\n",
       "  'title': 'A Structured Self-attentive Sentence Embedding',\n",
       "  'authors': ['Cicero Nogueira dos Santos',\n",
       "   'Bing Xiang',\n",
       "   'Mo Yu',\n",
       "   'Zhouhan Lin',\n",
       "   'Minwei Feng',\n",
       "   'Yoshua Bengio',\n",
       "   'Bowen Zhou'],\n",
       "  'published': '2017-03-09T04:42:30Z',\n",
       "  'updated': '2017-03-09T04:42:30Z',\n",
       "  'abstract': 'This paper proposes a new model for extracting an interpretable sentenceembedding by introducing self-attention. Instead of using a vector, we use a2-D matrix to represent the embedding, with each row of the matrix attending ona different part of the sentence. We also propose a self-attention mechanismand a special regularization term for the model. As a side effect, theembedding comes with an easy way of visualizing what specific parts of thesentence are encoded into the embedding. We evaluate our model on 3 differenttasks: author profiling, sentiment classification, and textual entailment.Results show that our model yields a significant performance gain compared toother sentence embedding methods in all of the 3 tasks.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '893',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.03130v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3666844900655302515&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 222: {'ID': 222,\n",
       "  'title': 'Residual Networks Behave Like Ensembles of Relatively Shallow Networks',\n",
       "  'authors': ['Andreas Veit', 'Michael Wilber', 'Serge Belongie'],\n",
       "  'published': '2016-05-20T16:44:03Z',\n",
       "  'updated': '2016-10-27T00:43:58Z',\n",
       "  'abstract': 'In this work we propose a novel interpretation of residual networks showingthat they can be seen as a collection of many paths of differing length.Moreover, residual networks seem to enable very deep networks by leveragingonly the short paths during training. To support this observation, we rewriteresidual networks as an explicit collection of paths. Unlike traditionalmodels, paths through residual networks vary in length. Further, a lesion studyreveals that these paths show ensemble-like behavior in the sense that they donot strongly depend on each other. Finally, and most surprising, most paths areshorter than one might expect, and only the short paths are needed duringtraining, as longer paths do not contribute any gradient. For example, most ofthe gradient in a residual network with 110 layers comes from paths that areonly 10-34 layers deep. Our results reveal one of the key characteristics thatseem to enable the training of very deep networks: Residual networks avoid thevanishing gradient problem by introducing short paths which can carry gradientthroughout the extent of very deep networks.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '455',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06431v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17069814828377193048&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 223: {'ID': 223,\n",
       "  'title': 'Noise2Noise: Learning Image Restoration without Clean Data',\n",
       "  'authors': ['Samuli Laine',\n",
       "   'Jaakko Lehtinen',\n",
       "   'Tero Karras',\n",
       "   'Jacob Munkberg',\n",
       "   'Jon Hasselgren',\n",
       "   'Timo Aila',\n",
       "   'Miika Aittala'],\n",
       "  'published': '2018-03-12T11:07:58Z',\n",
       "  'updated': '2018-10-29T10:29:23Z',\n",
       "  'abstract': 'We apply basic statistical reasoning to signal reconstruction by machinelearning -- learning to map corrupted observations to clean signals -- with asimple and powerful conclusion: it is possible to learn to restore images byonly looking at corrupted examples, at performance at and sometimes exceedingtraining using clean data, without explicit image priors or likelihood modelsof the corruption. In practice, we show that a single model learns photographicnoise removal, denoising synthetic Monte Carlo images, and reconstruction ofundersampled MRI scans -- all corrupted by different processes -- based onnoisy data only.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2971-2980',\n",
       "  'citations': '225',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.04189v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16764673643469433149&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 224: {'ID': 224,\n",
       "  'title': 'Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders',\n",
       "  'authors': ['Jesse Engel',\n",
       "   'Mohammad Norouzi',\n",
       "   'Karen Simonyan',\n",
       "   'Adam Roberts',\n",
       "   'Cinjon Resnick',\n",
       "   'Sander Dieleman',\n",
       "   'Douglas Eck'],\n",
       "  'published': '2017-04-05T06:34:22Z',\n",
       "  'updated': '2017-04-05T06:34:22Z',\n",
       "  'abstract': 'Generative models in vision have seen rapid progress due to algorithmicimprovements and the availability of high-quality image datasets. In thispaper, we offer contributions in both these areas to enable similar progress inaudio modeling. First, we detail a powerful new WaveNet-style autoencoder modelthat conditions an autoregressive decoder on temporal codes learned from theraw audio waveform. Second, we introduce NSynth, a large-scale and high-qualitydataset of musical notes that is an order of magnitude larger than comparablepublic datasets. Using NSynth, we demonstrate improved qualitative andquantitative performance of the WaveNet autoencoder over a well-tuned spectralautoencoder baseline. Finally, we show that the model learns a manifold ofembeddings that allows for morphing between instruments, meaningfullyinterpolating in timbre to create new types of sounds that are realistic andexpressive.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SD'],\n",
       "  'journal': 'ICML, 1068-1077',\n",
       "  'citations': '221',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.01279v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5597311454772920979&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 225: {'ID': 225,\n",
       "  'title': 'Learning deep representations by mutual information estimation and  maximization',\n",
       "  'authors': ['Samuel Lavoie-Marchildon',\n",
       "   'Adam Trischler',\n",
       "   'Karan Grewal',\n",
       "   'Alex Fedorov',\n",
       "   'Phil Bachman',\n",
       "   'R Devon Hjelm',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2018-08-20T19:52:51Z',\n",
       "  'updated': '2019-02-22T18:38:15Z',\n",
       "  'abstract': \"In this work, we perform unsupervised learning of representations bymaximizing mutual information between an input and the output of a deep neuralnetwork encoder. Importantly, we show that structure matters: incorporatingknowledge about locality of the input to the objective can greatly influence arepresentation's suitability for downstream tasks. We further controlcharacteristics of the representation by matching to a prior distributionadversarially. Our method, which we call Deep InfoMax (DIM), outperforms anumber of popular unsupervised learning methods and competes withfully-supervised learning on several classification tasks. DIM opens newavenues for unsupervised learning of representations and is an important steptowards flexible formulations of representation-learning objectives forspecific end-goals.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '266',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1808.06670v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9102831258285751412&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 226: {'ID': 226,\n",
       "  'title': 'Meta-Learning for Semi-Supervised Few-Shot Classification',\n",
       "  'authors': ['Jake Snell',\n",
       "   'Richard S. Zemel',\n",
       "   'Hugo Larochelle',\n",
       "   'Joshua B. Tenenbaum',\n",
       "   'Kevin Swersky',\n",
       "   'Sachin Ravi',\n",
       "   'Mengye Ren',\n",
       "   'Eleni Triantafillou'],\n",
       "  'published': '2018-03-02T01:07:49Z',\n",
       "  'updated': '2018-03-02T01:07:49Z',\n",
       "  'abstract': 'In few-shot classification, we are interested in learning algorithms thattrain a classifier from only a handful of labeled examples. Recent progress infew-shot classification has featured meta-learning, in which a parameterizedmodel for a learning algorithm is defined and trained on episodes representingdifferent classification problems, each with a small labeled training set andits corresponding test set. In this work, we advance this few-shotclassification paradigm towards a scenario where unlabeled examples are alsoavailable within each episode. We consider two situations: one where allunlabeled examples are assumed to belong to the same set of classes as thelabeled examples of the episode, as well as the more challenging situationwhere examples from other distractor classes are also provided. To address thisparadigm, we propose novel extensions of Prototypical Networks (Snell et al.,2017) that are augmented with the ability to use unlabeled examples whenproducing prototypes. These models are trained in an end-to-end way onepisodes, to learn to leverage the unlabeled examples successfully. We evaluatethese methods on versions of the Omniglot and miniImageNet benchmarks, adaptedto this new framework augmented with unlabeled examples. We also propose a newsplit of ImageNet, consisting of a large set of classes, with a hierarchicalstructure. Our experiments confirm that our Prototypical Networks can learn toimprove their predictions due to unlabeled examples, much like asemi-supervised algorithm would.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.00676v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=798380540199769906&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 227: {'ID': 227,\n",
       "  'title': 'Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic  Forecasting',\n",
       "  'authors': ['Yaguang Li', 'Rose Yu', 'Cyrus Shahabi', 'Yan Liu'],\n",
       "  'published': '2017-07-06T18:20:59Z',\n",
       "  'updated': '2018-02-22T19:52:51Z',\n",
       "  'abstract': 'Spatiotemporal forecasting has various applications in neuroscience, climateand transportation domain. Traffic forecasting is one canonical example of suchlearning task. The task is challenging due to (1) complex spatial dependency onroad networks, (2) non-linear temporal dynamics with changing road conditionsand (3) inherent difficulty of long-term forecasting. To address thesechallenges, we propose to model the traffic flow as a diffusion process on adirected graph and introduce Diffusion Convolutional Recurrent Neural Network(DCRNN), a deep learning framework for traffic forecasting that incorporatesboth spatial and temporal dependency in the traffic flow. Specifically, DCRNNcaptures the spatial dependency using bidirectional random walks on the graph,and the temporal dependency using the encoder-decoder architecture withscheduled sampling. We evaluate the framework on two real-world large scaleroad network traffic datasets and observe consistent improvement of 12% - 15%over state-of-the-art baselines.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '330',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.01926v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6301301566407555232&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 228: {'ID': 228,\n",
       "  'title': 'Scalable trust-region method for deep reinforcement learning using  Kronecker-factored approximation',\n",
       "  'authors': ['Yuhuai Wu',\n",
       "   'Elman Mansimov',\n",
       "   'Shun Liao',\n",
       "   'Jimmy Ba',\n",
       "   'Roger Grosse'],\n",
       "  'published': '2017-08-17T06:14:48Z',\n",
       "  'updated': '2017-08-18T11:16:36Z',\n",
       "  'abstract': 'In this work, we propose to apply trust region optimization to deepreinforcement learning using a recently proposed Kronecker-factoredapproximation to the curvature. We extend the framework of natural policygradient and propose to optimize both the actor and the critic usingKronecker-factored approximate curvature (K-FAC) with trust region; hence wecall our method Actor Critic using Kronecker-Factored Trust Region (ACKTR). Tothe best of our knowledge, this is the first scalable trust region naturalgradient method for actor-critic methods. It is also a method that learnsnon-trivial tasks in continuous control as well as discrete control policiesdirectly from raw pixel inputs. We tested our approach across discrete domainsin Atari games as well as continuous domains in the MuJoCo environment. Withthe proposed methods, we are able to achieve higher rewards and a 2- to 3-foldimprovement in sample efficiency on average, compared to previousstate-of-the-art on-policy actor-critic methods. Code is available athttps://github.com/openai/baselines',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '279',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.05144v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7666242084036831847&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 229: {'ID': 229,\n",
       "  'title': 'Hierarchical Representations for Efficient Architecture Search',\n",
       "  'authors': ['Chrisantha Fernando',\n",
       "   'Karen Simonyan',\n",
       "   'Oriol Vinyals',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Hanxiao Liu'],\n",
       "  'published': '2017-11-01T16:46:27Z',\n",
       "  'updated': '2018-02-22T22:31:30Z',\n",
       "  'abstract': 'We explore efficient neural architecture search methods and show that asimple yet powerful evolutionary algorithm can discover new architectures withexcellent performance. Our approach combines a novel hierarchical geneticrepresentation scheme that imitates the modularized design pattern commonlyadopted by human experts, and an expressive search space that supports complextopologies. Our algorithm efficiently discovers architectures that outperform alarge number of manually designed models for image classification, obtainingtop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, whichis competitive with the best existing neural architecture search approaches. Wealso present results using random search, achieving 0.3% less top-1 accuracy onCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36hours down to 1 hour.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '333',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00436v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8727964422666186494&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 230: {'ID': 230,\n",
       "  'title': 'Style Transfer in Text: Exploration and Evaluation',\n",
       "  'authors': ['Nanyun Peng',\n",
       "   'Rui Yan',\n",
       "   'Dongyan Zhao',\n",
       "   'Xiaoye Tan',\n",
       "   'Zhenxin Fu'],\n",
       "  'published': '2017-11-18T13:33:15Z',\n",
       "  'updated': '2017-11-27T07:46:16Z',\n",
       "  'abstract': 'Style transfer is an important problem in natural language processing (NLP).However, the progress in language style transfer is lagged behind otherdomains, such as computer vision, mainly because of the lack of parallel dataand principle evaluation metrics. In this paper, we propose to learn styletransfer with non-parallel data. We explore two models to achieve this goal,and the key idea behind the proposed models is to learn separate contentrepresentations and style representations using adversarial networks. We alsopropose novel evaluation metrics which measure two aspects of style transfer:transfer strength and content preservation. We access our models and theevaluation metrics on two tasks: paper-news title transfer, andpositive-negative review transfer. Results show that the proposed contentpreservation metric is highly correlate to human judgments, and the proposedmodels are able to generate sentences with higher style transfer strength andsimilar content preservation score comparing to auto-encoder.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '177',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.06861v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9103690709456613215&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 231: {'ID': 231,\n",
       "  'title': 'Batch Renormalization: Towards Reducing Minibatch Dependence in  Batch-Normalized Models',\n",
       "  'authors': ['Sergey Ioffe'],\n",
       "  'published': '2017-02-10T18:27:17Z',\n",
       "  'updated': '2017-03-30T17:58:32Z',\n",
       "  'abstract': 'Batch Normalization is quite effective at accelerating and improving thetraining of deep models. However, its effectiveness diminishes when thetraining minibatches are small, or do not consist of independent samples. Wehypothesize that this is due to the dependence of model layer inputs on all theexamples in the minibatch, and different activations being produced betweentraining and inference. We propose Batch Renormalization, a simple andeffective extension to ensure that the training and inference models generatethe same outputs that depend on individual examples rather than the entireminibatch. Models trained with Batch Renormalization perform substantiallybetter than batchnorm when training with small or non-i.i.d. minibatches. Atthe same time, Batch Renormalization retains the benefits of batchnorm such asinsensitivity to initialization and training efficiency.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '203',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.03275v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7372640422096944906&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 232: {'ID': 232,\n",
       "  'title': 'Gradient Episodic Memory for Continual Learning',\n",
       "  'authors': [\"Marc'Aurelio Ranzato\", 'David Lopez-Paz'],\n",
       "  'published': '2017-06-26T14:53:34Z',\n",
       "  'updated': '2017-11-04T13:11:18Z',\n",
       "  'abstract': 'One major obstacle towards AI is the poor ability of models to solve newproblems quicker, and without forgetting previously acquired knowledge. Tobetter understand this issue, we study the problem of continual learning, wherethe model observes, once and one by one, examples concerning a sequence oftasks. First, we propose a set of metrics to evaluate models learning over acontinuum of data. These metrics characterize models not only by their testaccuracy, but also in terms of their ability to transfer knowledge acrosstasks. Second, we propose a model for continual learning, called GradientEpisodic Memory (GEM) that alleviates forgetting, while allowing beneficialtransfer of knowledge to previous tasks. Our experiments on variants of theMNIST and CIFAR-100 datasets demonstrate the strong performance of GEM whencompared to the state-of-the-art.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '311',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.08840v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17788496987696818587&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 233: {'ID': 233,\n",
       "  'title': 'Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic',\n",
       "  'authors': ['Zoubin Ghahramani',\n",
       "   'Richard E. Turner',\n",
       "   'Sergey Levine',\n",
       "   'Timothy Lillicrap',\n",
       "   'Shixiang Gu'],\n",
       "  'published': '2016-11-07T20:09:16Z',\n",
       "  'updated': '2017-02-27T21:48:25Z',\n",
       "  'abstract': \"Model-free deep reinforcement learning (RL) methods have been successful in awide variety of simulated domains. However, a major obstacle facing deep RL inthe real world is their high sample complexity. Batch policy gradient methodsoffer stable learning, but at the cost of high variance, which often requireslarge batches. TD-style methods, such as off-policy actor-critic andQ-learning, are more sample-efficient but biased, and often require costlyhyperparameter sweeps to stabilize. In this work, we aim to develop methodsthat combine the stability of policy gradients with the efficiency ofoff-policy RL. We present Q-Prop, a policy gradient method that uses a Taylorexpansion of the off-policy critic as a control variate. Q-Prop is both sampleefficient and stable, and effectively combines the benefits of on-policy andoff-policy methods. We analyze the connection between Q-Prop and existingmodel-free algorithms, and use control variate theory to derive two variants ofQ-Prop with conservative and aggressive adaptation. We show that conservativeQ-Prop provides substantial gains in sample efficiency over trust region policyoptimization (TRPO) with generalized advantage estimation (GAE), and improvesstability over deep deterministic policy gradient (DDPG), the state-of-the-arton-policy and off-policy methods, on OpenAI Gym's MuJoCo continuous controlenvironments.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '213',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02247v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9727184745997671136&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 234: {'ID': 234,\n",
       "  'title': 'Universal Style Transfer via Feature Transforms',\n",
       "  'authors': ['Chen Fang',\n",
       "   'Zhaowen Wang',\n",
       "   'Xin Lu',\n",
       "   'Jimei Yang',\n",
       "   'Ming-Hsuan Yang',\n",
       "   'Yijun Li'],\n",
       "  'published': '2017-05-23T06:10:58Z',\n",
       "  'updated': '2017-11-17T18:30:43Z',\n",
       "  'abstract': 'Universal style transfer aims to transfer arbitrary visual styles to contentimages. Existing feed-forward based methods, while enjoying the inferenceefficiency, are mainly limited by inability of generalizing to unseen styles orcompromised visual quality. In this paper, we present a simple yet effectivemethod that tackles these limitations without training on any pre-definedstyles. The key ingredient of our method is a pair of feature transforms,whitening and coloring, that are embedded to an image reconstruction network.The whitening and coloring transforms reflect a direct matching of featurecovariance of the content image to a given style image, which shares similarspirits with the optimization of Gram matrix based cost in neural styletransfer. We demonstrate the effectiveness of our algorithm by generatinghigh-quality stylized images with comparisons to a number of recent methods. Wealso analyze our method by visualizing the whitened features and synthesizingtextures via simple feature coloring.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '227',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08086v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7001062204457348357&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 235: {'ID': 235,\n",
       "  'title': 'A Convergence Theory for Deep Learning via Over-Parameterization',\n",
       "  'authors': ['Zeyuan Allen-Zhu', 'Zhao Song', 'Yuanzhi Li'],\n",
       "  'published': '2018-11-09T15:16:13Z',\n",
       "  'updated': '2019-06-17T06:39:04Z',\n",
       "  'abstract': 'Deep neural networks (DNNs) have demonstrated dominating performance in manyfields; since AlexNet, networks used in practice are going wider and deeper. Onthe theoretical side, a long line of works has been focusing on training neuralnetworks with one hidden layer. The theory of multi-layer networks remainslargely unsettled.  In this work, we prove why stochastic gradient descent (SGD) can find$\\\\textit{global minima}$ on the training objective of DNNs in$\\\\textit{polynomial time}$. We only make two assumptions: the inputs arenon-degenerate and the network is over-parameterized. The latter means thenetwork width is sufficiently large: $\\\\textit{polynomial}$ in $L$, the numberof layers and in $n$, the number of samples.  Our key technique is to derive that, in a sufficiently large neighborhood ofthe random initialization, the optimization landscape is almost-convex andsemi-smooth even with ReLU activations. This implies an equivalence betweenover-parameterized neural networks and neural tangent kernel (NTK) in thefinite (and polynomial) width setting.  As concrete examples, starting from randomly initialized weights, we provethat SGD can attain 100% training accuracy in classification tasks, or minimizeregression loss in linear convergence speed, with running time polynomial in$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,and to any smooth and possibly non-convex loss functions. In terms of networkarchitectures, our theory at least applies to fully-connected neural networks,convolutional neural networks (CNN), and residual neural networks (ResNet).',\n",
       "  'categories': ['cs.LG', 'cs.DS', 'cs.NE', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 242-252',\n",
       "  'citations': '278',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.03962v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2380732574076098684&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 236: {'ID': 236,\n",
       "  'title': 'Large-Scale Evolution of Image Classifiers',\n",
       "  'authors': ['Esteban Real',\n",
       "   'Yutaka Leon Suematsu',\n",
       "   'Alex Kurakin',\n",
       "   'Sherry Moore',\n",
       "   'Quoc Le',\n",
       "   'Andrew Selle',\n",
       "   'Saurabh Saxena',\n",
       "   'Jie Tan'],\n",
       "  'published': '2017-03-03T05:41:30Z',\n",
       "  'updated': '2017-06-11T08:42:28Z',\n",
       "  'abstract': 'Neural networks have proven effective at solving difficult problems butdesigning their architectures can be challenging, even for image classificationproblems alone. Our goal is to minimize human participation, so we employevolutionary algorithms to discover such networks automatically. Despitesignificant computational requirements, we show that it is now possible toevolve models with accuracies within the range of those published in the lastyear. Specifically, we employ simple evolutionary techniques at unprecedentedscales to discover models for the CIFAR-10 and CIFAR-100 datasets, startingfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% forensemble) and 77.0%, respectively. To do this, we use novel and intuitivemutation operators that navigate large search spaces; we stress that no humanparticipation is required once evolution starts and that the output is afully-trained model. Throughout this work, we place special emphasis on therepeatability of results, the variability in the outcomes and the computationalrequirements.',\n",
       "  'categories': ['cs.NE', 'cs.AI', 'cs.CV', 'cs.DC', 'I.2.6; I.5.1; I.5.2'],\n",
       "  'journal': 'ICML, 2902-2911',\n",
       "  'citations': '605',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01041v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2681013556507309683&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 237: {'ID': 237,\n",
       "  'title': 'Deep learning with Elastic Averaging SGD',\n",
       "  'authors': ['Sixin Zhang', 'Yann LeCun', 'Anna Choromanska'],\n",
       "  'published': '2014-12-20T13:22:23Z',\n",
       "  'updated': '2015-10-25T12:12:52Z',\n",
       "  'abstract': 'We study the problem of stochastic optimization for deep learning in theparallel computing environment under communication constraints. A new algorithmis proposed in this setting where the communication and coordination of workamong concurrent processes (local workers), is based on an elastic force whichlinks the parameters they compute with a center variable stored by theparameter server (master). The algorithm enables the local workers to performmore exploration, i.e. the algorithm allows the local variables to fluctuatefurther from the center variable by reducing the amount of communicationbetween local workers and the master. We empirically demonstrate that in thedeep learning setting, due to the existence of many local optima, allowing moreexploration can lead to the improved performance. We propose synchronous andasynchronous variants of the new algorithm. We provide the stability analysisof the asynchronous variant in the round-robin scheme and compare it with themore common parallelized method ADMM. We show that the stability of EASGD isguaranteed when a simple stability condition is satisfied, which is not thecase for ADMM. We additionally propose the momentum-based version of ouralgorithm that can be applied in both synchronous and asynchronous settings.Asynchronous variant of the algorithm is applied to train convolutional neuralnetworks for image classification on the CIFAR and ImageNet datasets.Experiments demonstrate that the new algorithm accelerates the training of deeparchitectures compared to DOWNPOUR and other common baseline approaches andfurthermore is very communication efficient.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '356',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6651v8',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18355366617755570418&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 238: {'ID': 238,\n",
       "  'title': 'OptNet: Differentiable Optimization as a Layer in Neural Networks',\n",
       "  'authors': ['Brandon Amos', 'J. Zico Kolter'],\n",
       "  'published': '2017-03-01T18:58:48Z',\n",
       "  'updated': '2019-10-14T18:03:26Z',\n",
       "  'abstract': 'This paper presents OptNet, a network architecture that integratesoptimization problems (here, specifically in the form of quadratic programs) asindividual layers in larger end-to-end trainable deep networks. These layersencode constraints and complex dependencies between the hidden states thattraditional convolutional and fully-connected layers often cannot capture. Inthis paper, we explore the foundations for such an architecture: we show howtechniques from sensitivity analysis, bilevel optimization, and implicitdifferentiation can be used to exactly differentiate through these layers andwith respect to layer parameters; we develop a highly efficient solver forthese layers that exploits fast GPU-based batch solves within a primal-dualinterior point method, and which provides backpropagation gradients withvirtually no additional cost on top of the solve; and we highlight theapplication of these approaches in several problems. In one notable example, weshow that the method is capable of learning to play mini-Sudoku (4x4) givenjust input and output games, with no a priori information about the rules ofthe game; this highlights the ability of our architecture to learn hardconstraints better than other neural architectures.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 136-145',\n",
       "  'citations': '176',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00443v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9740292310844529830&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 239: {'ID': 239,\n",
       "  'title': 'A Complete Recipe for Stochastic Gradient MCMC',\n",
       "  'authors': ['Yi-An Ma', 'Tianqi Chen', 'Emily B. Fox'],\n",
       "  'published': '2015-06-15T18:32:37Z',\n",
       "  'updated': '2015-11-01T00:18:32Z',\n",
       "  'abstract': 'Many recent Markov chain Monte Carlo (MCMC) samplers leverage continuousdynamics to define a transition kernel that efficiently explores a targetdistribution. In tandem, a focus has been on devising scalable variants thatsubsample the data and use stochastic gradients in place of full-data gradientsin the dynamic simulations. However, such stochastic gradient MCMC samplershave lagged behind their full-data counterparts in terms of the complexity ofdynamics considered since proving convergence in the presence of the stochasticgradient noise is non-trivial. Even with simple dynamics, significant physicalintuition is often required to modify the dynamical system to account for thestochastic gradient noise. In this paper, we provide a general recipe forconstructing MCMC samplers--including stochastic gradient versions--based oncontinuous Markov processes specified via two matrices. We constructively provethat the framework is complete. That is, any continuous Markov process thatprovides samples from the target distribution can be written in our framework.We show how previous continuous-dynamic samplers can be trivially \"reinvented\"in our framework, avoiding the complicated sampler-specific proofs. We likewiseuse our recipe to straightforwardly propose a new state-adaptive sampler:stochastic gradient Riemann Hamiltonian Monte Carlo (SGRHMC). Our experimentson simulated data and a streaming Wikipedia analysis demonstrate that theproposed SGRHMC sampler inherits the benefits of Riemann HMC, with thescalability of stochastic gradient methods.',\n",
       "  'categories': ['math.ST', 'stat.ME', 'stat.ML', 'stat.TH'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '223',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.04696v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13273505320087374669&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 240: {'ID': 240,\n",
       "  'title': 'CyCADA: Cycle-Consistent Adversarial Domain Adaptation',\n",
       "  'authors': ['Alexei A. Efros',\n",
       "   'Phillip Isola',\n",
       "   'Judy Hoffman',\n",
       "   'Eric Tzeng',\n",
       "   'Trevor Darrell',\n",
       "   'Taesung Park',\n",
       "   'Kate Saenko',\n",
       "   'Jun-Yan Zhu'],\n",
       "  'published': '2017-11-08T23:54:52Z',\n",
       "  'updated': '2017-12-29T05:00:37Z',\n",
       "  'abstract': 'Domain adaptation is critical for success in new, unseen environments.Adversarial adaptation models applied in feature spaces discover domaininvariant representations, but are difficult to visualize and sometimes fail tocapture pixel-level and low-level domain shifts. Recent work has shown thatgenerative adversarial networks combined with cycle-consistency constraints aresurprisingly effective at mapping images between domains, even without the useof aligned image pairs. We propose a novel discriminatively-trainedCycle-Consistent Adversarial Domain Adaptation model. CyCADA adaptsrepresentations at both the pixel-level and feature-level, enforcescycle-consistency while leveraging a task loss, and does not require alignedpairs. Our model can be applied in a variety of visual recognition andprediction settings. We show new state-of-the-art results across multipleadaptation tasks, including digit classification and semantic segmentation ofroad scenes demonstrating transfer from synthetic to real world domains.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 1994-2003',\n",
       "  'citations': '708',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.03213v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12837244440606171486&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 241: {'ID': 241,\n",
       "  'title': 'Domain Separation Networks',\n",
       "  'authors': ['Dilip Krishnan',\n",
       "   'George Trigeorgis',\n",
       "   'Konstantinos Bousmalis',\n",
       "   'Dumitru Erhan',\n",
       "   'Nathan Silberman'],\n",
       "  'published': '2016-08-22T00:12:27Z',\n",
       "  'updated': '2016-08-22T00:12:27Z',\n",
       "  'abstract': \"The cost of large scale data collection and annotation often makes theapplication of machine learning algorithms to new tasks or datasetsprohibitively expensive. One approach circumventing this cost is trainingmodels on synthetic data where annotations are provided automatically. Despitetheir appeal, such models often fail to generalize from synthetic to realimages, necessitating domain adaptation algorithms to manipulate these modelsbefore they can be successfully applied. Existing approaches focus either onmapping representations from one domain to the other, or on learning to extractfeatures that are invariant to the domain from which they were extracted.However, by focusing only on creating a mapping or shared representationbetween the two domains, they ignore the individual characteristics of eachdomain. We suggest that explicitly modeling what is unique to each domain canimprove a model's ability to extract domain-invariant features. Inspired bywork on private-shared component analysis, we explicitly learn to extract imagerepresentations that are partitioned into two subspaces: one component which isprivate to each domain and one which is shared across domains. Our model istrained not only to perform the task we care about in the source domain, butalso to use the partitioned representation to reconstruct the images from bothdomains. Our novel architecture results in a model that outperforms thestate-of-the-art on a range of unsupervised domain adaptation scenarios andadditionally produces visualizations of the private and shared representationsenabling interpretation of the domain adaptation process.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '573',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.06019v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6506097335216287854&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 242: {'ID': 242,\n",
       "  'title': 'Finding a Collective Set of Items: From Proportional Multirepresentation  to Group Recommendation',\n",
       "  'authors': ['Piotr Skowron', 'Piotr Faliszewski', 'Jerome Lang'],\n",
       "  'published': '2014-02-13T07:14:28Z',\n",
       "  'updated': '2016-01-08T19:51:00Z',\n",
       "  'abstract': \"We consider the following problem: There is a set of items (e.g., movies) anda group of agents (e.g., passengers on a plane); each agent has some intrinsicutility for each of the items. Our goal is to pick a set of $K$ items thatmaximize the total derived utility of all the agents (i.e., in our example weare to pick $K$ movies that we put on the plane's entertainment system).However, the actual utility that an agent derives from a given item is only afraction of its intrinsic one, and this fraction depends on how the agent ranksthe item among the chosen, available, ones. We provide a formal specificationof the model and provide concrete examples and settings where it is applicable.We show that the problem is hard in general, but we show a number oftractability results for its natural special cases.\",\n",
       "  'categories': ['cs.GT', 'cs.AI', 'cs.MA'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '134',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1402.3044v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=860117861628466866&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 243: {'ID': 243,\n",
       "  'title': 'Continuous control with deep reinforcement learning',\n",
       "  'authors': ['Yuval Tassa',\n",
       "   'Nicolas Heess',\n",
       "   'Jonathan J. Hunt',\n",
       "   'Alexander Pritzel',\n",
       "   'Tom Erez',\n",
       "   'David Silver',\n",
       "   'Timothy P. Lillicrap',\n",
       "   'Daan Wierstra'],\n",
       "  'published': '2015-09-09T23:01:36Z',\n",
       "  'updated': '2019-07-05T10:47:27Z',\n",
       "  'abstract': 'We adapt the ideas underlying the success of Deep Q-Learning to thecontinuous action domain. We present an actor-critic, model-free algorithmbased on the deterministic policy gradient that can operate over continuousaction spaces. Using the same learning algorithm, network architecture andhyper-parameters, our algorithm robustly solves more than 20 simulated physicstasks, including classic problems such as cartpole swing-up, dexterousmanipulation, legged locomotion and car driving. Our algorithm is able to findpolicies whose performance is competitive with those found by a planningalgorithm with full access to the dynamics of the domain and its derivatives.We further demonstrate that for many of the tasks the algorithm can learnpolicies end-to-end: directly from raw pixel inputs.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '3683',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.02971v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4133004576987558805&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 244: {'ID': 244,\n",
       "  'title': 'Compression of Deep Convolutional Neural Networks for Fast and Low Power  Mobile Applications',\n",
       "  'authors': ['Taelim Choi',\n",
       "   'Sungjoo Yoo',\n",
       "   'Lu Yang',\n",
       "   'Yong-Deok Kim',\n",
       "   'Dongjun Shin',\n",
       "   'Eunhyeok Park'],\n",
       "  'published': '2015-11-20T09:20:08Z',\n",
       "  'updated': '2016-02-24T11:52:12Z',\n",
       "  'abstract': 'Although the latest high-end smartphone has powerful CPU and GPU, runningdeeper convolutional neural networks (CNNs) for complex tasks such as ImageNetclassification on mobile devices is challenging. To deploy deep CNNs on mobiledevices, we present a simple and effective scheme to compress the entire CNN,which we call one-shot whole network compression. The proposed scheme consistsof three steps: (1) rank selection with variational Bayesian matrixfactorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuningto recover accumulated loss of accuracy, and each step can be easilyimplemented using publicly available tools. We demonstrate the effectiveness ofthe proposed scheme by testing the performance of various compressed CNNs(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significantreductions in model size, runtime, and energy consumption are obtained, at thecost of small loss in accuracy. In addition, we address the importantimplementation level issue on 1?1 convolution, which is a key operation ofinception module of GoogLeNet as well as CNNs compressed by our proposedscheme.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '470',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06530v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=271868299753778474&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 245: {'ID': 245,\n",
       "  'title': 'Graph Convolutional Networks for Text Classification',\n",
       "  'authors': ['Liang Yao', 'Chengsheng Mao', 'Yuan Luo'],\n",
       "  'published': '2018-09-15T09:13:12Z',\n",
       "  'updated': '2018-11-13T05:23:40Z',\n",
       "  'abstract': 'Text classification is an important and classical problem in natural languageprocessing. There have been a number of studies that applied convolutionalneural networks (convolution on regular grid, e.g., sequence) toclassification. However, only a limited number of studies have explored themore flexible graph convolutional neural networks (convolution on non-grid,e.g., arbitrary graph) for the task. In this work, we propose to use graphconvolutional networks for text classification. We build a single text graphfor a corpus based on word co-occurrence and document word relations, thenlearn a Text Graph Convolutional Network (Text GCN) for the corpus. Our TextGCN is initialized with one-hot representation for word and document, it thenjointly learns the embeddings for both words and documents, as supervised bythe known class labels for documents. Our experimental results on multiplebenchmark datasets demonstrate that a vanilla Text GCN without any externalword embeddings or knowledge outperforms state-of-the-art methods for textclassification. On the other hand, Text GCN also learns predictive word anddocument embeddings. In addition, experimental results show that theimprovement of Text GCN over state-of-the-art comparison methods become moreprominent as we lower the percentage of training data, suggesting therobustness of Text GCN to less training data in text classification.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the AAAI Conference on Artificial Intelligence 33, 7370-7377',\n",
       "  'citations': '138',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.05679v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8652850659505697306&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 246: {'ID': 246,\n",
       "  'title': 'Progressive Growing of GANs for Improved Quality, Stability, and  Variation',\n",
       "  'authors': ['Samuli Laine', 'Timo Aila', 'Jaakko Lehtinen', 'Tero Karras'],\n",
       "  'published': '2017-10-27T15:28:35Z',\n",
       "  'updated': '2018-02-26T15:33:34Z',\n",
       "  'abstract': 'We describe a new training methodology for generative adversarial networks.The key idea is to grow both the generator and discriminator progressively:starting from a low resolution, we add new layers that model increasingly finedetails as training progresses. This both speeds the training up and greatlystabilizes it, allowing us to produce images of unprecedented quality, e.g.,CelebA images at 1024^2. We also propose a simple way to increase the variationin generated images, and achieve a record inception score of 8.80 inunsupervised CIFAR10. Additionally, we describe several implementation detailsthat are important for discouraging unhealthy competition between the generatorand discriminator. Finally, we suggest a new metric for evaluating GAN results,both in terms of image quality and variation. As an additional contribution, weconstruct a higher-quality version of the CelebA dataset.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '1819',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.10196v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11486098150916361186&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 247: {'ID': 247,\n",
       "  'title': 'Exploring Generalization in Deep Learning',\n",
       "  'authors': ['David McAllester',\n",
       "   'Srinadh Bhojanapalli',\n",
       "   'Behnam Neyshabur',\n",
       "   'Nathan Srebro'],\n",
       "  'published': '2017-06-27T17:20:06Z',\n",
       "  'updated': '2017-07-06T17:10:40Z',\n",
       "  'abstract': 'With a goal of understanding what drives generalization in deep networks, weconsider several recently suggested explanations, including norm-based control,sharpness and robustness. We study how these measures can ensuregeneralization, highlighting the importance of scale normalization, and makinga connection between sharpness and PAC-Bayes theory. We then investigate howwell the measures explain different observed phenomena.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '349',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.08947v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16285731102067380229&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 248: {'ID': 248,\n",
       "  'title': 'Deep Learning with Limited Numerical Precision',\n",
       "  'authors': ['Suyog Gupta',\n",
       "   'Ankur Agrawal',\n",
       "   'Kailash Gopalakrishnan',\n",
       "   'Pritish Narayanan'],\n",
       "  'published': '2015-02-09T16:37:29Z',\n",
       "  'updated': '2015-02-09T16:37:29Z',\n",
       "  'abstract': \"Training of large-scale deep neural networks is often constrained by theavailable computational resources. We study the effect of limited precisiondata representation and computation on neural network training. Within thecontext of low-precision fixed-point computations, we observe the roundingscheme to play a crucial role in determining the network's behavior duringtraining. Our results show that deep networks can be trained using only 16-bitwide fixed-point number representation when using stochastic rounding, andincur little to no degradation in the classification accuracy. We alsodemonstrate an energy-efficient hardware accelerator that implementslow-precision fixed-point arithmetic with stochastic rounding.\",\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 1737-1746',\n",
       "  'citations': '1092',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02551v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14109789955727767115&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 249: {'ID': 249,\n",
       "  'title': 'Structured Inference Networks for Nonlinear State Space Models',\n",
       "  'authors': ['David Sontag', 'Uri Shalit', 'Rahul G. Krishnan'],\n",
       "  'published': '2016-09-30T19:53:11Z',\n",
       "  'updated': '2016-12-05T19:10:10Z',\n",
       "  'abstract': 'Gaussian state space models have been used for decades as generative modelsof sequential data. They admit an intuitive probabilistic interpretation, havea simple functional form, and enjoy widespread adoption. We introduce a unifiedalgorithm to efficiently learn a broad class of linear and non-linear statespace models, including variants where the emission and transitiondistributions are modeled by deep neural networks. Our learning algorithmsimultaneously learns a compiled inference network and the generative model,leveraging a structured variational approximation parameterized by recurrentneural networks to mimic the posterior distribution. We apply the learningalgorithm to both synthetic and real-world datasets, demonstrating itsscalability and versatility. We find that using the structured approximation tothe posterior results in models with significantly higher held-out likelihood.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '179',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.09869v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17763269236884701463&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 250: {'ID': 250,\n",
       "  'title': 'SoundNet: Learning Sound Representations from Unlabeled Video',\n",
       "  'authors': ['Antonio Torralba', 'Yusuf Aytar', 'Carl Vondrick'],\n",
       "  'published': '2016-10-27T20:23:39Z',\n",
       "  'updated': '2016-10-27T20:23:39Z',\n",
       "  'abstract': 'We learn rich natural sound representations by capitalizing on large amountsof unlabeled sound data collected in the wild. We leverage the naturalsynchronization between vision and sound to learn an acoustic representationusing two-million unlabeled videos. Unlabeled video has the advantage that itcan be economically acquired at massive scales, yet contains useful signalsabout natural sound. We propose a student-teacher training procedure whichtransfers discriminative visual knowledge from well established visualrecognition models into the sound modality using unlabeled video as a bridge.Our sound representation yields significant performance improvements over thestate-of-the-art results on standard benchmarks for acoustic scene/objectclassification. Visualizations suggest some high-level semantics automaticallyemerge in the sound network, even though it is trained without ground truthlabels.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.SD'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '472',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.09001v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10397330204607504126&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 251: {'ID': 251,\n",
       "  'title': 'Fast and Accurate Deep Network Learning by Exponential Linear Units  (ELUs)',\n",
       "  'authors': ['Djork-Arné Clevert', 'Sepp Hochreiter', 'Thomas Unterthiner'],\n",
       "  'published': '2015-11-23T15:58:05Z',\n",
       "  'updated': '2016-02-22T07:02:58Z',\n",
       "  'abstract': 'We introduce the \"exponential linear unit\" (ELU) which speeds up learning indeep neural networks and leads to higher classification accuracies. Likerectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs(PReLUs), ELUs alleviate the vanishing gradient problem via the identity forpositive values. However, ELUs have improved learning characteristics comparedto the units with other activation functions. In contrast to ReLUs, ELUs havenegative values which allows them to push mean unit activations closer to zerolike batch normalization but with lower computational complexity. Mean shiftstoward zero speed up learning by bringing the normal gradient closer to theunit natural gradient because of a reduced bias shift effect. While LReLUs andPReLUs have negative values, too, they do not ensure a noise-robustdeactivation state. ELUs saturate to a negative value with smaller inputs andthereby decrease the forward propagated variation and information. Therefore,ELUs code the degree of presence of particular phenomena in the input, whilethey do not quantitatively model the degree of their absence. In experiments,ELUs lead not only to faster learning, but also to significantly bettergeneralization performance than ReLUs and LReLUs on networks with more than 5layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks withbatch normalization while batch normalization does not improve ELU networks.ELU networks are among the top 10 reported CIFAR-10 results and yield the bestpublished result on CIFAR-100, without resorting to multi-view evaluation ormodel averaging. On ImageNet, ELU networks considerably speed up learningcompared to a ReLU network with the same architecture, obtaining less than 10%classification error for a single crop, single model network.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '2436',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.07289v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13103600599147838489&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 252: {'ID': 252,\n",
       "  'title': 'Learning to Diagnose with LSTM Recurrent Neural Networks',\n",
       "  'authors': ['Zachary C. Lipton',\n",
       "   'Charles Elkan',\n",
       "   'Randall Wetzel',\n",
       "   'David C. Kale'],\n",
       "  'published': '2015-11-11T21:01:28Z',\n",
       "  'updated': '2017-03-21T21:29:50Z',\n",
       "  'abstract': \"Clinical medical data, especially in the intensive care unit (ICU), consistof multivariate time series of observations. For each patient visit (orepisode), sensor data and lab test results are recorded in the patient'sElectronic Health Record (EHR). While potentially containing a wealth ofinsights, the data is difficult to mine effectively, owing to varying length,irregular sampling and missing data. Recurrent Neural Networks (RNNs),particularly those using Long Short-Term Memory (LSTM) hidden units, arepowerful and increasingly popular models for learning from sequence data. Theyeffectively model varying length sequences and capture long range dependencies.We present the first study to empirically evaluate the ability of LSTMs torecognize patterns in multivariate time series of clinical measurements.Specifically, we consider multilabel classification of diagnoses, training amodel to classify 128 diagnoses given 13 frequently but irregularly sampledclinical measurements. First, we establish the effectiveness of a simple LSTMnetwork for modeling clinical data. Then we demonstrate a straightforward andeffective training strategy in which we replicate targets at each sequencestep. Trained only on raw time series, our models outperform several strongbaselines, including a multilayer perceptron trained on hand-engineeredfeatures.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '635',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.03677v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8027693791853042695&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 253: {'ID': 253,\n",
       "  'title': 'Arbitrary Style Transfer in Real-time with Adaptive Instance  Normalization',\n",
       "  'authors': ['Xun Huang', 'Serge Belongie'],\n",
       "  'published': '2017-03-20T17:51:31Z',\n",
       "  'updated': '2017-07-30T09:32:17Z',\n",
       "  'abstract': 'Gatys et al. recently introduced a neural algorithm that renders a contentimage in the style of another image, achieving so-called style transfer.However, their framework requires a slow iterative optimization process, whichlimits its practical application. Fast approximations with feed-forward neuralnetworks have been proposed to speed up neural style transfer. Unfortunately,the speed improvement comes at a cost: the network is usually tied to a fixedset of styles and cannot adapt to arbitrary new styles. In this paper, wepresent a simple yet effective approach that for the first time enablesarbitrary style transfer in real-time. At the heart of our method is a noveladaptive instance normalization (AdaIN) layer that aligns the mean and varianceof the content features with those of the style features. Our method achievesspeed comparable to the fastest existing approach, without the restriction to apre-defined set of styles. In addition, our approach allows flexible usercontrols such as content-style trade-off, style interpolation, color &amp; spatialcontrols, all using a single feed-forward neural network.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '672',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.06868v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6462913724934880335&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 254: {'ID': 254,\n",
       "  'title': 'Adversarial Machine Learning at Scale',\n",
       "  'authors': ['Samy Bengio', 'Alexey Kurakin', 'Ian Goodfellow'],\n",
       "  'published': '2016-11-04T01:11:02Z',\n",
       "  'updated': '2017-02-11T00:15:46Z',\n",
       "  'abstract': 'Adversarial examples are malicious inputs designed to fool machine learningmodels. They often transfer from one model to another, allowing attackers tomount black box attacks without knowledge of the target model\\'s parameters.Adversarial training is the process of explicitly training a model onadversarial examples, in order to make it more robust to attack or to reduceits test error on clean inputs. So far, adversarial training has primarily beenapplied to small problems. In this research, we apply adversarial training toImageNet. Our contributions include: (1) recommendations for how to succesfullyscale adversarial training to large models and datasets, (2) the observationthat adversarial training confers robustness to single-step attack methods, (3)the finding that multi-step attack methods are somewhat less transferable thansingle-step attack methods, so single-step attacks are the best for mountingblack-box attacks, and (4) resolution of a \"label leaking\" effect that causesadversarially trained models to perform better on adversarial examples than onclean examples, because the adversarial example construction process uses thetrue label and the model can learn to exploit regularities in the constructionprocess.',\n",
       "  'categories': ['cs.CV', 'cs.CR', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '922',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01236v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8221212997031548134&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 255: {'ID': 255,\n",
       "  'title': 'Convolutional Neural Networks on Graphs with Fast Localized Spectral  Filtering',\n",
       "  'authors': ['Xavier Bresson', 'Pierre Vandergheynst', 'Michaël Defferrard'],\n",
       "  'published': '2016-06-30T07:42:13Z',\n",
       "  'updated': '2017-02-05T17:04:39Z',\n",
       "  'abstract': \"In this work, we are interested in generalizing convolutional neural networks(CNNs) from low-dimensional regular grids, where image, video and speech arerepresented, to high-dimensional irregular domains, such as social networks,brain connectomes or words' embedding, represented by graphs. We present aformulation of CNNs in the context of spectral graph theory, which provides thenecessary mathematical background and efficient numerical schemes to designfast localized convolutional filters on graphs. Importantly, the proposedtechnique offers the same linear computational complexity and constant learningcomplexity as classical CNNs, while being universal to any graph structure.Experiments on MNIST and 20NEWS demonstrate the ability of this novel deeplearning system to learn local, stationary, and compositional features ongraphs.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '2027',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.09375v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18205894503371115148&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 256: {'ID': 256,\n",
       "  'title': 'Lazier Than Lazy Greedy',\n",
       "  'authors': ['Jan Vondrak',\n",
       "   'Ashwinkumar Badanidiyuru',\n",
       "   'Baharan Mirzasoleiman',\n",
       "   'Amin Karbasi',\n",
       "   'Andreas Krause'],\n",
       "  'published': '2014-09-28T18:06:23Z',\n",
       "  'updated': '2014-11-28T13:06:54Z',\n",
       "  'abstract': 'Is it possible to maximize a monotone submodular function faster than thewidely used lazy greedy algorithm (also known as accelerated greedy), both intheory and practice? In this paper, we develop the first linear-time algorithmfor maximizing a general monotone submodular function subject to a cardinalityconstraint. We show that our randomized algorithm, STOCHASTIC-GREEDY, canachieve a $(1-1/e-\\\\varepsilon)$ approximation guarantee, in expectation, to theoptimum solution in time linear in the size of the data and independent of thecardinality constraint. We empirically demonstrate the effectiveness of ouralgorithm on submodular functions arising in data summarization, includingtraining large-scale kernel methods, exemplar-based clustering, and sensorplacement. We observe that STOCHASTIC-GREEDY practically achieves the sameutility value as lazy greedy but runs much faster. More surprisingly, weobserve that in many practical scenarios STOCHASTIC-GREEDY does not evaluatethe whole fraction of data points even once and still achievesindistinguishable results compared to lazy greedy.',\n",
       "  'categories': ['cs.LG', 'cs.DS', 'cs.IR'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '176',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1409.7938v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8147030613819583144&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 257: {'ID': 257,\n",
       "  'title': 'Optimizing Neural Networks with Kronecker-factored Approximate Curvature',\n",
       "  'authors': ['James Martens', 'Roger Grosse'],\n",
       "  'published': '2015-03-19T08:30:24Z',\n",
       "  'updated': '2020-06-08T01:28:58Z',\n",
       "  'abstract': \"We propose an efficient method for approximating natural gradient descent inneural networks which we call Kronecker-Factored Approximate Curvature (K-FAC).K-FAC is based on an efficiently invertible approximation of a neural network'sFisher information matrix which is neither diagonal nor low-rank, and in somecases is completely non-sparse. It is derived by approximating various largeblocks of the Fisher (corresponding to entire layers) as being the Kroneckerproduct of two much smaller matrices. While only several times more expensiveto compute than the plain stochastic gradient, the updates produced by K-FACmake much more progress optimizing the objective, which results in an algorithmthat can be much faster than stochastic gradient descent with momentum inpractice. And unlike some previously proposed approximatenatural-gradient/Newton methods which use high-quality non-diagonal curvaturematrices (such as Hessian-free optimization), K-FAC works very well in highlystochastic optimization regimes. This is because the cost of storing andinverting K-FAC's approximation to the curvature matrix does not depend on theamount of data used to estimate it, which is a feature typically associatedonly with diagonal or low-rank approximations to the curvature matrix.\",\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 2408-2417',\n",
       "  'citations': '314',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.05671v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11551045348725818062&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 258: {'ID': 258,\n",
       "  'title': 'Variational Dropout Sparsifies Deep Neural Networks',\n",
       "  'authors': ['Dmitry Vetrov', 'Arsenii Ashukha', 'Dmitry Molchanov'],\n",
       "  'published': '2017-01-19T10:44:55Z',\n",
       "  'updated': '2017-06-13T11:01:55Z',\n",
       "  'abstract': 'We explore a recently proposed Variational Dropout technique that provided anelegant Bayesian interpretation to Gaussian Dropout. We extend VariationalDropout to the case when dropout rates are unbounded, propose a way to reducethe variance of the gradient estimator and report first experimental resultswith individual dropout rates per weight. Interestingly, it leads to extremelysparse solutions both in fully-connected and convolutional layers. This effectis similar to automatic relevance determination effect in empirical Bayes buthas a number of advantages. We reduce the number of parameters up to 280 timeson LeNet architectures and up to 68 times on VGG-like networks with anegligible decrease of accuracy.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 2498-2507',\n",
       "  'citations': '311',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.05369v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11014728550012194230&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 259: {'ID': 259,\n",
       "  'title': 'Character-Aware Neural Language Models',\n",
       "  'authors': ['David Sontag',\n",
       "   'Yoon Kim',\n",
       "   'Yacine Jernite',\n",
       "   'Alexander M. Rush'],\n",
       "  'published': '2015-08-26T19:25:34Z',\n",
       "  'updated': '2015-12-01T22:59:24Z',\n",
       "  'abstract': 'We describe a simple neural language model that relies only oncharacter-level inputs. Predictions are still made at the word-level. Our modelemploys a convolutional neural network (CNN) and a highway network overcharacters, whose output is given to a long short-term memory (LSTM) recurrentneural network language model (RNN-LM). On the English Penn Treebank the modelis on par with the existing state-of-the-art despite having 60% fewerparameters. On languages with rich morphology (Arabic, Czech, French, German,Spanish, Russian), the model outperforms word-level/morpheme-level LSTMbaselines, again with fewer parameters. The results suggest that on manylanguages, character inputs are sufficient for language modeling. Analysis ofword representations obtained from the character composition part of the modelreveals that the model is able to encode, from characters only, both semanticand orthographic information.',\n",
       "  'categories': ['cs.CL', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '1278',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1508.06615v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3272758346108198795&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 260: {'ID': 260,\n",
       "  'title': 'Adversarial Training Methods for Semi-Supervised Text Classification',\n",
       "  'authors': ['Takeru Miyato', 'Ian Goodfellow', 'Andrew M. Dai'],\n",
       "  'published': '2016-05-25T04:25:45Z',\n",
       "  'updated': '2017-05-06T20:16:03Z',\n",
       "  'abstract': 'Adversarial training provides a means of regularizing supervised learningalgorithms while virtual adversarial training is able to extend supervisedlearning algorithms to the semi-supervised setting. However, both methodsrequire making small perturbations to numerous entries of the input vector,which is inappropriate for sparse high-dimensional inputs such as one-hot wordrepresentations. We extend adversarial and virtual adversarial training to thetext domain by applying perturbations to the word embeddings in a recurrentneural network rather than to the original input itself. The proposed methodachieves state of the art results on multiple benchmark semi-supervised andpurely supervised tasks. We provide visualizations and analysis showing thatthe learned word embeddings have improved in quality and that while training,the model is less prone to overfitting.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '275',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07725v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6594257289645930121&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 261: {'ID': 261,\n",
       "  'title': 'A Universal Catalyst for First-Order Optimization',\n",
       "  'authors': ['Zaid Harchaoui', 'Julien Mairal', 'Hongzhou Lin'],\n",
       "  'published': '2015-06-06T19:49:48Z',\n",
       "  'updated': '2015-10-25T10:57:08Z',\n",
       "  'abstract': 'We introduce a generic scheme for accelerating first-order optimizationmethods in the sense of Nesterov, which builds upon a new analysis of theaccelerated proximal point algorithm. Our approach consists of minimizing aconvex objective by approximately solving a sequence of well-chosen auxiliaryproblems, leading to faster convergence. This strategy applies to a large classof algorithms, including gradient descent, block coordinate descent, SAG, SAGA,SDCA, SVRG, Finito/MISO, and their proximal variants. For all of these methods,we provide acceleration and explicit support for non-strongly convexobjectives. In addition to theoretical speed-up, we also show that accelerationis useful in practice, especially for ill-conditioned problems where we measuresignificant improvements.',\n",
       "  'categories': ['math.OC'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '318',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02186v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1451579851477033920&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 262: {'ID': 262,\n",
       "  'title': 'The Option-Critic Architecture',\n",
       "  'authors': ['Jean Harb', 'Doina Precup', 'Pierre-Luc Bacon'],\n",
       "  'published': '2016-09-16T17:05:55Z',\n",
       "  'updated': '2016-12-03T02:47:51Z',\n",
       "  'abstract': 'Temporal abstraction is key to scaling up learning and planning inreinforcement learning. While planning with temporally extended actions is wellunderstood, creating such abstractions autonomously from data has remainedchallenging. We tackle this problem in the framework of options [Sutton, Precup&amp; Singh, 1999; Precup, 2000]. We derive policy gradient theorems for optionsand propose a new option-critic architecture capable of learning both theinternal policies and the termination conditions of options, in tandem with thepolicy over options, and without the need to provide any additional rewards orsubgoals. Experimental results in both discrete and continuous environmentsshowcase the flexibility and efficiency of the framework.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '384',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.05140v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=107676057328336895&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 263: {'ID': 263,\n",
       "  'title': 'Complex Embeddings for Simple Link Prediction',\n",
       "  'authors': ['Éric Gaussier',\n",
       "   'Johannes Welbl',\n",
       "   'Théo Trouillon',\n",
       "   'Guillaume Bouchard',\n",
       "   'Sebastian Riedel'],\n",
       "  'published': '2016-06-20T22:52:48Z',\n",
       "  'updated': '2016-06-20T22:52:48Z',\n",
       "  'abstract': 'In statistical relational learning, the link prediction problem is key toautomatically understand the structure of large knowledge bases. As in previousstudies, we propose to solve this problem through latent factorization.However, here we make use of complex valued embeddings. The composition ofcomplex embeddings can handle a large variety of binary relations, among themsymmetric and antisymmetric relations. Compared to state-of-the-art models suchas Neural Tensor Network and Holographic Embeddings, our approach based oncomplex embeddings is arguably simpler, as it only uses the Hermitian dotproduct, the complex counterpart of the standard dot product between realvectors. Our approach is scalable to large datasets as it remains linear inboth space and time, while consistently outperforming alternative approaches onstandard link prediction benchmarks.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2071-2080',\n",
       "  'citations': '542',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.06357v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3538792764263491534&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 264: {'ID': 264,\n",
       "  'title': 'Doubly Robust Off-policy Value Evaluation for Reinforcement Learning',\n",
       "  'authors': ['Lihong Li', 'Nan Jiang'],\n",
       "  'published': '2015-11-11T22:59:51Z',\n",
       "  'updated': '2016-05-26T15:43:08Z',\n",
       "  'abstract': \"We study the problem of off-policy value evaluation in reinforcement learning(RL), where one aims to estimate the value of a new policy based on datacollected by a different policy. This problem is often a critical step whenapplying RL in real-world problems. Despite its importance, existing generalmethods either have uncontrolled bias or suffer high variance. In this work, weextend the doubly robust estimator for bandits to sequential decision-makingproblems, which gets the best of both worlds: it is guaranteed to be unbiasedand can have a much lower variance than the popular importance samplingestimators. We demonstrate the estimator's accuracy in several benchmarkproblems, and illustrate its use as a subroutine in safe policy improvement. Wealso provide theoretical results on the hardness of the problem, and show thatour estimator can match the lower bound in certain scenarios.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SY', 'stat.ME', 'stat.ML'],\n",
       "  'journal': 'ICML, 652-661',\n",
       "  'citations': '198',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.03722v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5974463330118879206&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 265: {'ID': 265,\n",
       "  'title': 'Convolutional 2D Knowledge Graph Embeddings',\n",
       "  'authors': ['Pontus Stenetorp',\n",
       "   'Pasquale Minervini',\n",
       "   'Sebastian Riedel',\n",
       "   'Tim Dettmers'],\n",
       "  'published': '2017-07-05T17:18:17Z',\n",
       "  'updated': '2018-07-04T09:53:46Z',\n",
       "  'abstract': 'Link prediction for knowledge graphs is the task of predicting missingrelationships between entities. Previous work on link prediction has focused onshallow, fast models which can scale to large knowledge graphs. However, thesemodels learn less expressive features than deep, multi-layer models -- whichpotentially limits performance. In this work, we introduce ConvE, a multi-layerconvolutional network model for link prediction, and report state-of-the-artresults for several established datasets. We also show that the model is highlyparameter efficient, yielding the same performance as DistMult and R-GCN with8x and 17x fewer parameters. Analysis of our model suggests that it isparticularly effective at modelling nodes with high indegree -- which arecommon in highly-connected, complex knowledge graphs such as Freebase andYAGO3. In addition, it has been noted that the WN18 and FB15k datasets sufferfrom test set leakage, due to inverse relations from the training set beingpresent in the test set -- however, the extent of this issue has so far notbeen quantified. We find this problem to be severe: a simple rule-based modelcan achieve state-of-the-art results on both WN18 and FB15k. To ensure thatmodels are evaluated on datasets where simply exploiting inverse relationscannot yield competitive results, we investigate and validate several commonlyused datasets -- deriving robust variants where necessary. We then performexperiments on these robust datasets for our own and several previouslyproposed models and find that ConvE achieves state-of-the-art Mean ReciprocalRank across most datasets.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '349',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.01476v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18086027355742564589&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 266: {'ID': 266,\n",
       "  'title': 'Pointer Sentinel Mixture Models',\n",
       "  'authors': ['James Bradbury',\n",
       "   'Richard Socher',\n",
       "   'Caiming Xiong',\n",
       "   'Stephen Merity'],\n",
       "  'published': '2016-09-26T04:06:13Z',\n",
       "  'updated': '2016-09-26T04:06:13Z',\n",
       "  'abstract': 'Recent neural network sequence models with softmax classifiers have achievedtheir best language modeling performance only with very large hidden states andlarge vocabularies. Even then they struggle to predict rare or unseen wordseven if the context makes the prediction unambiguous. We introduce the pointersentinel mixture architecture for neural sequence models which has the abilityto either reproduce a word from the recent context or produce a word from astandard softmax classifier. Our pointer sentinel-LSTM model achieves state ofthe art language modeling performance on the Penn Treebank (70.9 perplexity)while using far fewer parameters than a standard softmax LSTM. In order toevaluate how well language models can exploit longer contexts and deal withmore realistic vocabularies and larger corpora we also introduce the freelyavailable WikiText corpus.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '517',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.07843v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17812832384777278922&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 267: {'ID': 267,\n",
       "  'title': 'Meta-Learning with Latent Embedding Optimization',\n",
       "  'authors': ['Raia Hadsell',\n",
       "   'Jakub Sygnowski',\n",
       "   'Dushyant Rao',\n",
       "   'Simon Osindero',\n",
       "   'Oriol Vinyals',\n",
       "   'Razvan Pascanu',\n",
       "   'Andrei A. Rusu'],\n",
       "  'published': '2018-07-16T16:35:29Z',\n",
       "  'updated': '2019-03-26T13:36:45Z',\n",
       "  'abstract': 'Gradient-based meta-learning techniques are both widely applicable andproficient at solving challenging few-shot learning and fast adaptationproblems. However, they have practical difficulties when operating onhigh-dimensional parameter spaces in extreme low-data regimes. We show that itis possible to bypass these limitations by learning a data-dependent latentgenerative representation of model parameters, and performing gradient-basedmeta-learning in this low-dimensional latent space. The resulting approach,latent embedding optimization (LEO), decouples the gradient-based adaptationprocedure from the underlying high-dimensional space of model parameters. Ourevaluation shows that LEO can achieve state-of-the-art performance on thecompetitive miniImageNet and tieredImageNet few-shot classification tasks.Further analysis indicates LEO is able to capture uncertainty in the data, andcan perform adaptation more effectively by optimizing in latent space.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '211',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1807.05960v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11552536411545683614&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 268: {'ID': 268,\n",
       "  'title': 'Towards Fast Computation of Certified Robustness for ReLU Networks',\n",
       "  'authors': ['Duane Boning',\n",
       "   'Huan Zhang',\n",
       "   'Inderjit S. Dhillon',\n",
       "   'Tsui-Wei Weng',\n",
       "   'Cho-Jui Hsieh',\n",
       "   'Luca Daniel',\n",
       "   'Zhao Song',\n",
       "   'Hongge Chen'],\n",
       "  'published': '2018-04-25T17:47:56Z',\n",
       "  'updated': '2018-10-02T08:25:08Z',\n",
       "  'abstract': 'Verifying the robustness property of a general Rectified Linear Unit (ReLU)network is an NP-complete problem [Katz, Barrett, Dill, Julian and KochenderferCAV17]. Although finding the exact minimum adversarial distortion is hard,giving a certified lower bound of the minimum distortion is possible. Currentavailable methods of computing such a bound are either time-consuming ordelivering low quality bounds that are too loose to be useful. In this paper,we exploit the special structure of ReLU networks and provide twocomputationally efficient algorithms Fast-Lin and Fast-Lip that are able tocertify non-trivial lower bounds of minimum distortions, by bounding the ReLUunits with appropriate linear functions Fast-Lin, or by bounding the localLipschitz constant Fast-Lip. Experiments show that (1) our proposed methodsdeliver bounds close to (the gap is 2-3X) exact minimum distortion found byReluplex in small MNIST networks while our algorithms are more than 10,000times faster; (2) our methods deliver similar quality of bounds (the gap iswithin 35% and usually around 10%; sometimes our bounds are even better) forlarger networks compared to the methods based on solving linear programmingproblems but our algorithms are 33-14,000 times faster; (3) our method iscapable of solving large MNIST and CIFAR networks up to 7 layers with more than10,000 neurons within tens of seconds on a single CPU core.  In addition, we show that, in fact, there is no polynomial time algorithmthat can approximately find the minimum $\\\\ell_1$ adversarial distortion of aReLU network with a $0.99\\\\ln n$ approximation ratio unless$\\\\mathsf{NP}$=$\\\\mathsf{P}$, where $n$ is the number of neurons in the network.',\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICML, 5273-5282',\n",
       "  'citations': '175',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.09699v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13154362274812885800&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 269: {'ID': 269,\n",
       "  'title': 'Deep metric learning using Triplet network',\n",
       "  'authors': ['Nir Ailon', 'Elad Hoffer'],\n",
       "  'published': '2014-12-20T07:34:50Z',\n",
       "  'updated': '2018-12-04T15:35:35Z',\n",
       "  'abstract': 'Deep learning has proven itself as a successful set of models for learninguseful semantic representations of data. These, however, are mostly implicitlylearned as part of a classification task. In this paper we propose the tripletnetwork model, which aims to learn useful representations by distancecomparisons. A similar model was defined by Wang et al. (2014), tailor made forlearning a ranking for image information retrieval. Here we demonstrate usingvarious datasets that our model learns a better representation than that of itsimmediate competitor, the Siamese network. We also discuss future possibleusage as a framework for unsupervised learning.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '734',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6622v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3566033986180947389&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 270: {'ID': 270,\n",
       "  'title': 'Black-box Adversarial Attacks with Limited Queries and Information',\n",
       "  'authors': ['Andrew Ilyas', 'Jessy Lin', 'Logan Engstrom', 'Anish Athalye'],\n",
       "  'published': '2018-04-23T17:46:34Z',\n",
       "  'updated': '2018-07-11T13:51:00Z',\n",
       "  'abstract': 'Current neural network-based classifiers are susceptible to adversarialexamples even in the black-box setting, where the attacker only has queryaccess to the model. In practice, the threat model for real-world systems isoften more restrictive than the typical black-box model where the adversary canobserve the full output of the network on arbitrarily many chosen inputs. Wedefine three realistic threat models that more accurately characterize manyreal-world classifiers: the query-limited setting, the partial-informationsetting, and the label-only setting. We develop new attacks that foolclassifiers under these more restrictive threat models, where previous methodswould be impractical or ineffective. We demonstrate that our methods areeffective against an ImageNet classifier under our proposed threat models. Wealso demonstrate a targeted black-box attack against a commercial classifier,overcoming the challenges of limited query access, partial information, andother practical issues to break the Google Cloud Vision API.',\n",
       "  'categories': ['cs.CV', 'cs.CR', 'stat.ML'],\n",
       "  'journal': 'ICML, 2142-2151',\n",
       "  'citations': '237',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.08598v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15556405409493863238&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 271: {'ID': 271,\n",
       "  'title': 'Practical and Optimal LSH for Angular Distance',\n",
       "  'authors': ['Thijs Laarhoven',\n",
       "   'Ilya Razenshteyn',\n",
       "   'Ludwig Schmidt',\n",
       "   'Alexandr Andoni',\n",
       "   'Piotr Indyk'],\n",
       "  'published': '2015-09-09T19:24:33Z',\n",
       "  'updated': '2015-09-09T19:24:33Z',\n",
       "  'abstract': 'We show the existence of a Locality-Sensitive Hashing (LSH) family for theangular distance that yields an approximate Near Neighbor Search algorithm withthe asymptotically optimal running time exponent. Unlike earlier algorithmswith this property (e.g., Spherical LSH [Andoni, Indyk, Nguyen, Razenshteyn2014], [Andoni, Razenshteyn 2015]), our algorithm is also practical, improvingupon the well-studied hyperplane LSH [Charikar, 2002] in practice. We alsointroduce a multiprobe version of this algorithm, and conduct experimentalevaluation on real and synthetic data sets.  We complement the above positive results with a fine-grained lower bound forthe quality of any LSH family for angular distance. Our lower bound impliesthat the above LSH family exhibits a trade-off between evaluation time andquality that is close to optimal for a natural class of LSH functions.',\n",
       "  'categories': ['cs.DS', 'cs.CG', 'cs.IR'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '258',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.02897v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11203696302950509806&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 272: {'ID': 272,\n",
       "  'title': 'Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning',\n",
       "  'authors': ['Philip S. Thomas', 'Emma Brunskill'],\n",
       "  'published': '2016-04-04T15:56:52Z',\n",
       "  'updated': '2016-04-04T15:56:52Z',\n",
       "  'abstract': 'In this paper we present a new way of predicting the performance of areinforcement learning policy given historical data that may have beengenerated by a different policy. The ability to evaluate a policy fromhistorical data is important for applications where the deployment of a badpolicy can be dangerous or costly. We show empirically that our algorithmproduces estimates that often have orders of magnitude lower mean squared errorthan existing methods---it makes more efficient use of the available data. Ournew estimator is based on two advances: an extension of the doubly robustestimator (Jiang and Li, 2015), and a new way to mix between model basedestimates and importance sampling based estimates.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'ICML, 2139-2148',\n",
       "  'citations': '184',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.00923v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6145775850954387286&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 273: {'ID': 273,\n",
       "  'title': 'Learning Representations and Generative Models for 3D Point Clouds',\n",
       "  'authors': ['Ioannis Mitliagkas',\n",
       "   'Olga Diamanti',\n",
       "   'Leonidas Guibas',\n",
       "   'Panos Achlioptas'],\n",
       "  'published': '2017-07-08T03:44:49Z',\n",
       "  'updated': '2018-06-12T04:27:00Z',\n",
       "  'abstract': 'Three-dimensional geometric data offer an excellent domain for studyingrepresentation learning and generative modeling. In this paper, we look atgeometric data represented as point clouds. We introduce a deep AutoEncoder(AE) network with state-of-the-art reconstruction quality and generalizationability. The learned representations outperform existing methods on 3Drecognition tasks and enable shape editing via simple algebraic manipulations,such as semantic part editing, shape analogies and shape interpolation, as wellas shape completion. We perform a thorough study of different generative modelsincluding GANs operating on the raw point clouds, significantly improved GANstrained in the fixed latent space of our AEs, and Gaussian Mixture Models(GMMs). To quantitatively evaluate generative models we introduce measures ofsample fidelity and diversity based on matchings between sets of point clouds.Interestingly, our evaluation of generalization, fidelity and diversity revealsthat GMMs trained in the latent space of our AEs yield the best resultsoverall.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '224',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.02392v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12802077524133497194&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 274: {'ID': 274,\n",
       "  'title': 'Transfer Learning from Deep Features for Remote Sensing and Poverty  Mapping',\n",
       "  'authors': ['Stefano Ermon',\n",
       "   'Michael Xie',\n",
       "   'Marshall Burke',\n",
       "   'David Lobell',\n",
       "   'Neal Jean'],\n",
       "  'published': '2015-10-01T03:04:29Z',\n",
       "  'updated': '2016-02-27T23:21:48Z',\n",
       "  'abstract': 'The lack of reliable data in developing countries is a major obstacle tosustainable development, food security, and disaster relief. Poverty data, forexample, is typically scarce, sparse in coverage, and labor-intensive toobtain. Remote sensing data such as high-resolution satellite imagery, on theother hand, is becoming increasingly available and inexpensive. Unfortunately,such data is highly unstructured and currently no techniques exist toautomatically extract useful insights to inform policy decisions and helpdirect humanitarian efforts. We propose a novel machine learning approach toextract large-scale socioeconomic indicators from high-resolution satelliteimagery. The main challenge is that training data is very scarce, making itdifficult to apply modern techniques such as Convolutional Neural Networks(CNN). We therefore propose a transfer learning approach where nighttime lightintensities are used as a data-rich proxy. We train a fully convolutional CNNmodel to predict nighttime lights from daytime imagery, simultaneously learningfeatures that are useful for poverty prediction. The model learns filtersidentifying different terrains and man-made structures, including roads,buildings, and farmlands, without any supervision beyond nighttime lights. Wedemonstrate that these learned features are highly informative for povertymapping, even approaching the predictive performance of survey data collectedin the field.',\n",
       "  'categories': ['cs.CV', 'cs.CY'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '178',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.00098v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17072828246968526595&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 275: {'ID': 275,\n",
       "  'title': 'The Expressive Power of Neural Networks: A View from the Width',\n",
       "  'authors': ['Liwei Wang',\n",
       "   'Hongming Pu',\n",
       "   'Zhiqiang Hu',\n",
       "   'Feicheng Wang',\n",
       "   'Zhou Lu'],\n",
       "  'published': '2017-09-08T05:00:20Z',\n",
       "  'updated': '2017-11-01T08:50:32Z',\n",
       "  'abstract': 'The expressive power of neural networks is important for understanding deeplearning. Most existing works consider this problem from the view of the depthof a network. In this paper, we study how width affects the expressiveness ofneural networks. Classical results state that depth-bounded (e.g. depth-$2$)networks with suitable activation functions are universal approximators. Weshow a universal approximation theorem for width-bounded ReLU networks:width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universalapproximators. Moreover, except for a measure zero set, all functions cannot beapproximated by width-$n$ ReLU networks, which exhibits a phase transition.Several recent works demonstrate the benefits of depth by proving thedepth-efficiency of neural networks. That is, there are classes of deepnetworks which cannot be realized by any shallow network whose size is no morethan an exponential bound. Here we pose the dual question on thewidth-efficiency of ReLU networks: Are there wide networks that cannot berealized by narrow networks whose size is not substantially larger? We showthat there exist classes of wide networks which cannot be realized by anynarrow network whose depth is no more than a polynomial bound. On the otherhand, we demonstrate by extensive experiments that narrow networks whose sizeexceed the polynomial bound by a constant factor can approximate wide andshallow network with high accuracy. Our results provide more comprehensiveevidence that depth is more effective than width for the expressiveness of ReLUnetworks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '211',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.02540v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11989002681809936407&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 276: {'ID': 276,\n",
       "  'title': 'Deep Sets',\n",
       "  'authors': ['Ruslan Salakhutdinov',\n",
       "   'Manzil Zaheer',\n",
       "   'Siamak Ravanbakhsh',\n",
       "   'Alexander Smola',\n",
       "   'Satwik Kottur',\n",
       "   'Barnabas Poczos'],\n",
       "  'published': '2017-03-10T21:02:53Z',\n",
       "  'updated': '2018-04-14T18:54:19Z',\n",
       "  'abstract': 'We study the problem of designing models for machine learning tasks definedon \\\\emph{sets}. In contrast to traditional approach of operating on fixeddimensional vectors, we consider objective functions defined on sets that areinvariant to permutations. Such problems are widespread, ranging fromestimation of population statistics \\\\cite{poczos13aistats}, to anomalydetection in piezometer data of embankment dams \\\\cite{Jung15Exploration}, tocosmology \\\\cite{Ntampaka16Dynamical,Ravanbakhsh16ICML1}. Our main theoremcharacterizes the permutation invariant functions and provides a family offunctions to which any permutation invariant objective function must belong.This family of functions has a special structure which enables us to design adeep network architecture that can operate on sets and which can be deployed ona variety of scenarios including both unsupervised and supervised learningtasks. We also derive the necessary and sufficient conditions for permutationequivariance in deep models. We demonstrate the applicability of our method onpopulation statistic estimation, point cloud classification, set expansion, andoutlier detection.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '535',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.06114v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2295404778383262980&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 277: {'ID': 277,\n",
       "  'title': 'DeepCoder: Learning to Write Programs',\n",
       "  'authors': ['Alexander L. Gaunt',\n",
       "   'Daniel Tarlow',\n",
       "   'Matej Balog',\n",
       "   'Sebastian Nowozin',\n",
       "   'Marc Brockschmidt'],\n",
       "  'published': '2016-11-07T11:09:45Z',\n",
       "  'updated': '2017-03-08T11:50:33Z',\n",
       "  'abstract': \"We develop a first line of attack for solving programming competition-styleproblems from input-output examples using deep learning. The approach is totrain a neural network to predict properties of the program that generated theoutputs from the inputs. We use the neural network's predictions to augmentsearch techniques from the programming languages community, includingenumerative search and an SMT-based solver. Empirically, we show that ourapproach leads to an order of magnitude speedup over the strong non-augmentedbaselines and a Recurrent Neural Network approach, and that we are able tosolve problems of difficulty comparable to the simplest problems on programmingcompetition websites.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '248',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01989v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14663434925594619820&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 278: {'ID': 278,\n",
       "  'title': 'Constrained Policy Optimization',\n",
       "  'authors': ['Pieter Abbeel', 'David Held', 'Joshua Achiam', 'Aviv Tamar'],\n",
       "  'published': '2017-05-30T10:07:31Z',\n",
       "  'updated': '2017-05-30T10:07:31Z',\n",
       "  'abstract': 'For many applications of reinforcement learning it can be more convenient tospecify both a reward function and constraints, rather than trying to designbehavior through the reward function. For example, systems that physicallyinteract with or around humans should satisfy safety constraints. Recentadvances in policy search algorithms (Mnih et al., 2016, Schulman et al., 2015,Lillicrap et al., 2016, Levine et al., 2016) have enabled new capabilities inhigh-dimensional control, but do not consider the constrained setting.  We propose Constrained Policy Optimization (CPO), the first general-purposepolicy search algorithm for constrained reinforcement learning with guaranteesfor near-constraint satisfaction at each iteration. Our method allows us totrain neural network policies for high-dimensional control while makingguarantees about policy behavior all throughout training. Our guarantees arebased on a new theoretical result, which is of independent interest: we prove abound relating the expected returns of two policies to an average divergencebetween them. We demonstrate the effectiveness of our approach on simulatedrobot locomotion tasks where the agent must satisfy constraints motivated bysafety.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 22-31',\n",
       "  'citations': '227',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10528v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6114366704163518185&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 279: {'ID': 279,\n",
       "  'title': 'PixelLink: Detecting Scene Text via Instance Segmentation',\n",
       "  'authors': ['Dan Deng', 'Haifeng Liu', 'Xuelong Li', 'Deng Cai'],\n",
       "  'published': '2018-01-04T11:48:21Z',\n",
       "  'updated': '2018-01-04T11:48:21Z',\n",
       "  'abstract': 'Most state-of-the-art scene text detection algorithms are deep learning basedmethods that depend on bounding box regression and perform at least two kindsof predictions: text/non-text classification and location regression.Regression plays a key role in the acquisition of bounding boxes in thesemethods, but it is not indispensable because text/non-text prediction can alsobe considered as a kind of semantic segmentation that contains full locationinformation in itself. However, text instances in scene images often lie veryclose to each other, making them very difficult to separate via semanticsegmentation. Therefore, instance segmentation is needed to address thisproblem. In this paper, PixelLink, a novel scene text detection algorithm basedon instance segmentation, is proposed. Text instances are first segmented outby linking pixels within the same instance together. Text bounding boxes arethen extracted directly from the segmentation result without locationregression. Experiments show that, compared with regression-based methods,PixelLink can achieve better or comparable performance on several benchmarks,while requiring many fewer training iterations and less training data.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '170',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.01315v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5813094506011573938&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 280: {'ID': 280,\n",
       "  'title': 'The Implicit Bias of Gradient Descent on Separable Data',\n",
       "  'authors': ['Mor Shpigel Nacson',\n",
       "   'Nathan Srebro',\n",
       "   'Elad Hoffer',\n",
       "   'Suriya Gunasekar',\n",
       "   'Daniel Soudry'],\n",
       "  'published': '2017-10-27T21:47:58Z',\n",
       "  'updated': '2018-12-28T10:51:36Z',\n",
       "  'abstract': 'We examine gradient descent on unregularized logistic regression problems,with homogeneous linear predictors on linearly separable datasets. We show thepredictor converges to the direction of the max-margin (hard margin SVM)solution. The result also generalizes to other monotone decreasing lossfunctions with an infimum at infinity, to multi-class problems, and to traininga weight layer in a deep network in a certain restricted setting. Furthermore,we show this convergence is very slow, and only logarithmic in the convergenceof the loss itself. This can help explain the benefit of continuing to optimizethe logistic or cross-entropy loss even after the training error is zero andthe training loss is extremely small, and, as we show, even if the validationloss increases. Our methodology can also aid in understanding implicitregularization n more complex models and with other optimization methods.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '218',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.10345v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8363232294125339657&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 281: {'ID': 281,\n",
       "  'title': 'Masked Autoregressive Flow for Density Estimation',\n",
       "  'authors': ['George Papamakarios', 'Theo Pavlakou', 'Iain Murray'],\n",
       "  'published': '2017-05-19T15:42:54Z',\n",
       "  'updated': '2018-06-14T10:28:12Z',\n",
       "  'abstract': 'Autoregressive models are among the best performing neural densityestimators. We describe an approach for increasing the flexibility of anautoregressive model, based on modelling the random numbers that the model usesinternally when generating data. By constructing a stack of autoregressivemodels, each modelling the random numbers of the next model in the stack, weobtain a type of normalizing flow suitable for density estimation, which wecall Masked Autoregressive Flow. This type of flow is closely related toInverse Autoregressive Flow and is a generalization of Real NVP. MaskedAutoregressive Flow achieves state-of-the-art performance in a range ofgeneral-purpose density estimation tasks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '288',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.07057v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11200642106543542089&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 282: {'ID': 282,\n",
       "  'title': 'Challenging Common Assumptions in the Unsupervised Learning of  Disentangled Representations',\n",
       "  'authors': ['Bernhard Schölkopf',\n",
       "   'Sylvain Gelly',\n",
       "   'Gunnar Rätsch',\n",
       "   'Stefan Bauer',\n",
       "   'Francesco Locatello',\n",
       "   'Olivier Bachem',\n",
       "   'Mario Lucic'],\n",
       "  'published': '2018-11-29T18:10:40Z',\n",
       "  'updated': '2019-06-18T08:58:18Z',\n",
       "  'abstract': \"The key idea behind the unsupervised learning of disentangled representationsis that real-world data is generated by a few explanatory factors of variationwhich can be recovered by unsupervised learning algorithms. In this paper, weprovide a sober look at recent progress in the field and challenge some commonassumptions. We first theoretically show that the unsupervised learning ofdisentangled representations is fundamentally impossible without inductivebiases on both the models and the data. Then, we train more than 12000 modelscovering most prominent methods and evaluation metrics in a reproduciblelarge-scale experimental study on seven different data sets. We observe thatwhile the different methods successfully enforce properties ``encouraged'' bythe corresponding losses, well-disentangled models seemingly cannot beidentified without supervision. Furthermore, increased disentanglement does notseem to lead to a decreased sample complexity of learning for downstream tasks.Our results suggest that future work on disentanglement learning should beexplicit about the role of inductive biases and (implicit) supervision,investigate concrete benefits of enforcing disentanglement of the learnedrepresentations, and consider a reproducible experimental setup coveringseveral data sets.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 4114-4124',\n",
       "  'citations': '172',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.12359v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15156765665179946120&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 283: {'ID': 283,\n",
       "  'title': 'Variational Inference with Normalizing Flows',\n",
       "  'authors': ['Shakir Mohamed', 'Danilo Jimenez Rezende'],\n",
       "  'published': '2015-05-21T15:36:37Z',\n",
       "  'updated': '2016-06-14T09:01:36Z',\n",
       "  'abstract': 'The choice of approximate posterior distribution is one of the core problemsin variational inference. Most applications of variational inference employsimple families of posterior approximations in order to allow for efficientinference, focusing on mean-field or other simple structured approximations.This restriction has a significant impact on the quality of inferences madeusing variational methods. We introduce a new approach for specifying flexible,arbitrarily complex and scalable approximate posterior distributions. Ourapproximations are distributions constructed through a normalizing flow,whereby a simple initial density is transformed into a more complex one byapplying a sequence of invertible transformations until a desired level ofcomplexity is attained. We use this view of normalizing flows to developcategories of finite and infinitesimal flows and provide a unified view ofapproaches for constructing rich posterior approximations. We demonstrate thatthe theoretical advantages of having posteriors that better match the trueposterior, combined with the scalability of amortized variational approaches,provides a clear improvement in performance and applicability of variationalinference.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG', 'stat.CO', 'stat.ME'],\n",
       "  'journal': 'ICML, 1530-1538',\n",
       "  'citations': '988',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.05770v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6765826181105442087&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 284: {'ID': 284,\n",
       "  'title': 'Beyond Bilinear: Generalized Multimodal Factorized High-order Pooling  for Visual Question Answering',\n",
       "  'authors': ['Dacheng Tao',\n",
       "   'Jianping Fan',\n",
       "   'Chenchao Xiang',\n",
       "   'Zhou Yu',\n",
       "   'Jun Yu'],\n",
       "  'published': '2017-08-10T09:09:23Z',\n",
       "  'updated': '2019-05-16T04:16:57Z',\n",
       "  'abstract': \"Visual question answering (VQA) is challenging because it requires asimultaneous understanding of both visual content of images and textual contentof questions. To support the VQA task, we need to find good solutions for thefollowing three issues: 1) fine-grained feature representations for both theimage and the question; 2) multi-modal feature fusion that is able to capturethe complex interactions between multi-modal features; 3) automatic answerprediction that is able to consider the complex correlations between multiplediverse answers for the same question. For fine-grained image and questionrepresentations, a `co-attention' mechanism is developed by using a deep neuralnetwork architecture to jointly learn the attentions for both the image and thequestion, which can allow us to reduce the irrelevant features effectively andobtain more discriminative features for image and question representations. Formulti-modal feature fusion, a generalized Multi-modal Factorized High-orderpooling approach (MFH) is developed to achieve more effective fusion ofmulti-modal features by exploiting their correlations sufficiently, which canfurther result in superior VQA performance as compared with thestate-of-the-art approaches. For answer prediction, the KL (Kullback-Leibler)divergence is used as the loss function to achieve precise characterization ofthe complex correlations between multiple diverse answers with the same orsimilar meaning, which can allow us to achieve faster convergence rate andobtain slightly better accuracy on answer prediction. A deep neural networkarchitecture is designed to integrate all these aforementioned modules into aunified model for achieving superior VQA performance. With an ensemble of ourMFH models, we achieve the state-of-the-art performance on the large-scale VQAdatasets and win the runner-up in VQA Challenge 2017.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (12), 5947-5959',\n",
       "  'citations': '142',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.03619v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12743862933043798233&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 285: {'ID': 285,\n",
       "  'title': 'Understanding Black-box Predictions via Influence Functions',\n",
       "  'authors': ['Pang Wei Koh', 'Percy Liang'],\n",
       "  'published': '2017-03-14T21:07:01Z',\n",
       "  'updated': '2020-12-29T22:40:43Z',\n",
       "  'abstract': \"How can we explain the predictions of a black-box model? In this paper, weuse influence functions -- a classic technique from robust statistics -- totrace a model's prediction through the learning algorithm and back to itstraining data, thereby identifying training points most responsible for a givenprediction. To scale up influence functions to modern machine learningsettings, we develop a simple, efficient implementation that requires onlyoracle access to gradients and Hessian-vector products. We show that even onnon-convex and non-differentiable models where the theory breaks down,approximations to influence functions can still provide valuable information.On linear models and convolutional neural networks, we demonstrate thatinfluence functions are useful for multiple purposes: understanding modelbehavior, debugging models, detecting dataset errors, and even creatingvisually-indistinguishable training-set attacks.\",\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 1885-1894',\n",
       "  'citations': '715',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.04730v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3459384850898992895&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 286: {'ID': 286,\n",
       "  'title': 'Multiplicative Normalizing Flows for Variational Bayesian Neural  Networks',\n",
       "  'authors': ['Max Welling', 'Christos Louizos'],\n",
       "  'published': '2017-03-06T16:39:16Z',\n",
       "  'updated': '2017-06-12T21:05:58Z',\n",
       "  'abstract': 'We reinterpret multiplicative noise in neural networks as auxiliary randomvariables that augment the approximate posterior in a variational setting forBayesian neural networks. We show that through this interpretation it is bothefficient and straightforward to improve the approximation by employingnormalizing flows while still allowing for local reparametrizations and atractable lower bound. In experiments we show that with this new approximationwe can significantly improve upon classical mean field for Bayesian neuralnetworks on both predictive accuracy as well as predictive uncertainty.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 2218-2227',\n",
       "  'citations': '172',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01961v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1022009274958609654&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 287: {'ID': 287,\n",
       "  'title': 'TADAM: Task dependent adaptive metric for improved few-shot learning',\n",
       "  'authors': ['Pau Rodriguez', 'Alexandre Lacoste', 'Boris N. Oreshkin'],\n",
       "  'published': '2018-05-23T20:17:59Z',\n",
       "  'updated': '2019-01-25T18:47:30Z',\n",
       "  'abstract': 'Few-shot learning has become essential for producing models that generalizefrom few examples. In this work, we identify that metric scaling and metrictask conditioning are important to improve the performance of few-shotalgorithms. Our analysis reveals that simple metric scaling completely changesthe nature of few-shot algorithm parameter updates. Metric scaling providesimprovements up to 14% in accuracy for certain metrics on the mini-Imagenet5-way 5-shot classification task. We further propose a simple and effective wayof conditioning a learner on the task sample set, resulting in learning atask-dependent metric space. Moreover, we propose and empirically test apractical end-to-end optimization procedure based on auxiliary task co-trainingto learn a task-dependent metric space. The resulting few-shot learning modelbased on the task-dependent scaled metric achieves state of the art onmini-Imagenet. We confirm these results on another few-shot dataset that weintroduce in this paper based on CIFAR100. Our code is publicly available athttps://github.com/ElementAI/TADAM.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '202',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.10123v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15025574335418226526&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 288: {'ID': 288,\n",
       "  'title': 'Topic Aware Neural Response Generation',\n",
       "  'authors': ['Yu Wu',\n",
       "   'Chen Xing',\n",
       "   'Wei-Ying Ma',\n",
       "   'Ming Zhou',\n",
       "   'Jie Liu',\n",
       "   'Yalou Huang',\n",
       "   'Wei Wu'],\n",
       "  'published': '2016-06-21T05:47:59Z',\n",
       "  'updated': '2016-09-19T02:09:13Z',\n",
       "  'abstract': 'We consider incorporating topic information into the sequence-to-sequenceframework to generate informative and interesting responses for chatbots. Tothis end, we propose a topic aware sequence-to-sequence (TA-Seq2Seq) model. Themodel utilizes topics to simulate prior knowledge of human that guides them toform informative and interesting responses in conversation, and leverages thetopic information in generation by a joint attention mechanism and a biasedgeneration probability. The joint attention mechanism summarizes the hiddenvectors of an input message as context vectors by message attention,synthesizes topic vectors by topic attention from the topic words of themessage obtained from a pre-trained LDA model, and let these vectors jointlyaffect the generation of words in decoding. To increase the possibility oftopic words appearing in responses, the model modifies the generationprobability of topic words by adding an extra probability item to bias theoverall distribution. Empirical study on both automatic evaluation metrics andhuman annotations shows that TA-Seq2Seq can generate more informative andinteresting responses, and significantly outperform the-state-of-the-artresponse generation models.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '233',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.08340v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17700327900700043147&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 289: {'ID': 289,\n",
       "  'title': 'Conditional Image Generation with PixelCNN Decoders',\n",
       "  'authors': ['Nal Kalchbrenner',\n",
       "   'Alex Graves',\n",
       "   'Aaron van den Oord',\n",
       "   'Oriol Vinyals',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Lasse Espeholt'],\n",
       "  'published': '2016-06-16T19:40:56Z',\n",
       "  'updated': '2016-06-18T15:44:24Z',\n",
       "  'abstract': 'This work explores conditional image generation with a new image densitymodel based on the PixelCNN architecture. The model can be conditioned on anyvector, including descriptive labels or tags, or latent embeddings created byother networks. When conditioned on class labels from the ImageNet database,the model is able to generate diverse, realistic scenes representing distinctanimals, objects, landscapes and structures. When conditioned on an embeddingproduced by a convolutional network given a single image of an unseen face, itgenerates a variety of new portraits of the same person with different facialexpressions, poses and lighting conditions. We also show that conditionalPixelCNN can serve as a powerful decoder in an image autoencoder. Additionally,the gated convolutional layers in the proposed model improve the log-likelihoodof PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet,with greatly reduced computational cost.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '991',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.05328v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8587297613215686995&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 290: {'ID': 290,\n",
       "  'title': 'SGDR: Stochastic Gradient Descent with Warm Restarts',\n",
       "  'authors': ['Frank Hutter', 'Ilya Loshchilov'],\n",
       "  'published': '2016-08-13T13:46:05Z',\n",
       "  'updated': '2017-05-03T16:28:09Z',\n",
       "  'abstract': 'Restart techniques are common in gradient-free optimization to deal withmultimodal functions. Partial warm restarts are also gaining popularity ingradient-based optimization to improve the rate of convergence in acceleratedgradient schemes to deal with ill-conditioned functions. In this paper, wepropose a simple warm restart technique for stochastic gradient descent toimprove its anytime performance when training deep neural networks. Weempirically study its performance on the CIFAR-10 and CIFAR-100 datasets, wherewe demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively.We also demonstrate its advantages on a dataset of EEG recordings and on adownsampled version of the ImageNet dataset. Our source code is available athttps://github.com/loshchil/SGDR',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'math.OC'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '869',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.03983v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9496349859848656559&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 291: {'ID': 291,\n",
       "  'title': 'Neural Combinatorial Optimization with Reinforcement Learning',\n",
       "  'authors': ['Samy Bengio',\n",
       "   'Hieu Pham',\n",
       "   'Mohammad Norouzi',\n",
       "   'Irwan Bello',\n",
       "   'Quoc V. Le'],\n",
       "  'published': '2016-11-29T23:22:39Z',\n",
       "  'updated': '2017-01-12T23:55:36Z',\n",
       "  'abstract': 'This paper presents a framework to tackle combinatorial optimization problemsusing neural networks and reinforcement learning. We focus on the travelingsalesman problem (TSP) and train a recurrent network that, given a set of citycoordinates, predicts a distribution over different city permutations. Usingnegative tour length as the reward signal, we optimize the parameters of therecurrent network using a policy gradient method. We compare learning thenetwork parameters on a set of training graphs against learning them onindividual test graphs. Despite the computational expense, without muchengineering and heuristic designing, Neural Combinatorial Optimization achievesclose to optimal results on 2D Euclidean graphs with up to 100 nodes. Appliedto the KnapSack, another NP-hard problem, the same method obtains optimalsolutions for instances with up to 200 items.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '311',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.09940v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13936411244086798707&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 292: {'ID': 292,\n",
       "  'title': 'Learning Multiagent Communication with Backpropagation',\n",
       "  'authors': ['Arthur Szlam', 'Sainbayar Sukhbaatar', 'Rob Fergus'],\n",
       "  'published': '2016-05-25T05:33:21Z',\n",
       "  'updated': '2016-10-31T17:29:58Z',\n",
       "  'abstract': 'Many tasks in AI require the collaboration of multiple agents. Typically, thecommunication protocol between agents is manually specified and not alteredduring training. In this paper we explore a simple neural model, calledCommNet, that uses continuous communication for fully cooperative tasks. Themodel consists of multiple agents and the communication between them is learnedalongside their policy. We apply this model to a diverse set of tasks,demonstrating the ability of the agents to learn to communicate amongstthemselves, yielding improved performance over non-communicative agents andbaselines. In some cases, it is possible to interpret the language devised bythe agents, revealing simple but effective strategies for solving the task athand.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '422',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07736v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5233243549252503864&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 293: {'ID': 293,\n",
       "  'title': 'Calibrating Energy-based Generative Adversarial Networks',\n",
       "  'authors': ['Philip Bachman',\n",
       "   'Aaron Courville',\n",
       "   'Zihang Dai',\n",
       "   'Eduard Hovy',\n",
       "   'Amjad Almahairi'],\n",
       "  'published': '2017-02-06T16:30:13Z',\n",
       "  'updated': '2017-02-24T01:38:09Z',\n",
       "  'abstract': 'In this paper, we propose to equip Generative Adversarial Networks with theability to produce direct energy estimates for samples.Specifically, we proposea flexible adversarial training framework, and prove this framework not onlyensures the generator converges to the true data distribution, but also enablesthe discriminator to retain the density information at the global optimal. Wederive the analytic form of the induced solution, and analyze the properties.In order to make the proposed framework trainable in practice, we introduce twoeffective approximation techniques. Empirically, the experiment results closelymatch our theoretical analysis, verifying the discriminator is able to recoverthe energy of data distribution.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '770',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.01691v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15426746467469595309&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 294: {'ID': 294,\n",
       "  'title': 'Decorrelation of Neutral Vector Variables: Theory and Applications',\n",
       "  'authors': ['Jun Guo',\n",
       "   'Zhen Yang',\n",
       "   'Zheng-Hua Tan',\n",
       "   'Zhanyu Ma',\n",
       "   'Jing-Hao Xue',\n",
       "   'Arne Leijon'],\n",
       "  'published': '2017-05-30T09:53:11Z',\n",
       "  'updated': '2017-05-30T09:53:11Z',\n",
       "  'abstract': 'In this paper, we propose novel strategies for neutral vector variabledecorrelation. Two fundamental invertible transformations, namely serialnonlinear transformation and parallel nonlinear transformation, are proposed tocarry out the decorrelation. For a neutral vector variable, which is notmultivariate Gaussian distributed, the conventional principal componentanalysis (PCA) cannot yield mutually independent scalar variables. With the twoproposed transformations, a highly negatively correlated neutral vector can betransformed to a set of mutually independent scalar variables with the samedegrees of freedom. We also evaluate the decorrelation performances for thevectors generated from a single Dirichlet distribution and a mixture ofDirichlet distributions. The mutual independence is verified with the distancecorrelation measurement. The advantages of the proposed decorrelationstrategies are intensively studied and demonstrated with synthesized data andpractical application evaluations.',\n",
       "  'categories': ['cs.CV', 'stat.ML'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (1), 129-143',\n",
       "  'citations': '115',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10524v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8968952400382235129&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 295: {'ID': 295,\n",
       "  'title': 'Density estimation using Real NVP',\n",
       "  'authors': ['Laurent Dinh', 'Samy Bengio', 'Jascha Sohl-Dickstein'],\n",
       "  'published': '2016-05-27T21:24:32Z',\n",
       "  'updated': '2017-02-27T23:21:10Z',\n",
       "  'abstract': 'Unsupervised learning of probabilistic models is a central yet challengingproblem in machine learning. Specifically, designing models with tractablelearning, sampling, inference and evaluation is crucial in solving this task.We extend the space of such models using real-valued non-volume preserving(real NVP) transformations, a set of powerful invertible and learnabletransformations, resulting in an unsupervised learning algorithm with exactlog-likelihood computation, exact sampling, exact inference of latentvariables, and an interpretable latent space. We demonstrate its ability tomodel natural images on four datasets through sampling, log-likelihoodevaluation and latent variable manipulations.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '737',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.08803v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6875639475985157714&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 296: {'ID': 296,\n",
       "  'title': 'ProxylessNAS: Direct Neural Architecture Search on Target Task and  Hardware',\n",
       "  'authors': ['Song Han', 'Ligeng Zhu', 'Han Cai'],\n",
       "  'published': '2018-12-02T05:29:53Z',\n",
       "  'updated': '2019-02-23T01:36:47Z',\n",
       "  'abstract': 'Neural architecture search (NAS) has a great impact by automaticallydesigning effective neural network architectures. However, the prohibitivecomputational demand of conventional NAS algorithms (e.g. $10^4$ GPU hours)makes it difficult to \\\\emph{directly} search the architectures on large-scaletasks (e.g. ImageNet). Differentiable NAS can reduce the cost of GPU hours viaa continuous representation of network architecture but suffers from the highGPU memory consumption issue (grow linearly w.r.t. candidate set size). As aresult, they need to utilize~\\\\emph{proxy} tasks, such as training on a smallerdataset, or learning with only a few blocks, or training just for a few epochs.These architectures optimized on proxy tasks are not guaranteed to be optimalon the target task. In this paper, we present \\\\emph{ProxylessNAS} that can\\\\emph{directly} learn the architectures for large-scale target tasks and targethardware platforms. We address the high memory consumption issue ofdifferentiable NAS and reduce the computational cost (GPU hours and GPU memory)to the same level of regular training while still allowing a large candidateset. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness ofdirectness and specialization. On CIFAR-10, our model achieves 2.08\\\\% testerror with only 5.7M parameters, better than the previous state-of-the-artarchitecture AmoebaNet-B, while using 6$\\\\times$ fewer parameters. On ImageNet,our model achieves 3.1\\\\% better top-1 accuracy than MobileNetV2, while being1.2$\\\\times$ faster with measured GPU latency. We also apply ProxylessNAS tospecialize neural architectures for hardware with direct hardware metrics (e.g.latency) and provide insights for efficient CNN architecture design.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '355',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.00332v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18033301425061747520&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 297: {'ID': 297,\n",
       "  'title': 'Fixed Point Quantization of Deep Convolutional Networks',\n",
       "  'authors': ['Sachin S. Talathi',\n",
       "   'Darryl D. Lin',\n",
       "   'V. Sreekanth Annapureddy'],\n",
       "  'published': '2015-11-19T21:37:06Z',\n",
       "  'updated': '2016-06-02T06:21:42Z',\n",
       "  'abstract': 'In recent years increasingly complex architectures for deep convolutionnetworks (DCNs) have been proposed to boost the performance on imagerecognition tasks. However, the gains in performance have come at a cost ofsubstantial increase in computation and model storage resources. Fixed pointimplementation of DCNs has the potential to alleviate some of thesecomplexities and facilitate potential deployment on embedded hardware. In thispaper, we propose a quantizer design for fixed point implementation of DCNs. Weformulate and solve an optimization problem to identify optimal fixed pointbit-width allocation across DCN layers. Our experiments show that in comparisonto equal bit-width settings, the fixed point DCNs with optimized bit widthallocation offer &gt;20% reduction in the model size without any loss in accuracyon CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhancethe accuracy of fixed point DCNs beyond that of the original floating pointmodel. In doing so, we report a new state-of-the-art fixed point performance of6.78% error-rate on CIFAR-10 benchmark.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 2849-2858',\n",
       "  'citations': '407',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06393v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14355326039529078697&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 298: {'ID': 298,\n",
       "  'title': 'Trained Ternary Quantization',\n",
       "  'authors': ['William J. Dally', 'Huizi Mao', 'Song Han', 'Chenzhuo Zhu'],\n",
       "  'published': '2016-12-04T05:00:22Z',\n",
       "  'updated': '2017-02-23T06:52:28Z',\n",
       "  'abstract': \"Deep neural networks are widely used in machine learning applications.However, the deployment of large neural networks models can be difficult todeploy on mobile devices with limited power budgets. To solve this problem, wepropose Trained Ternary Quantization (TTQ), a method that can reduce theprecision of weights in neural networks to ternary values. This method has verylittle accuracy degradation and can even improve the accuracy of some models(32, 44, 56-layer ResNet) on CIFAR-10 and AlexNet on ImageNet. And our AlexNetmodel is trained from scratch, which means it's as easy as to train normal fullprecision model. We highlight our trained quantization method that can learnboth ternary values and ternary assignment. During inference, only ternaryvalues (2-bit weights) and scaling factors are needed, therefore our models arenearly 16x smaller than full-precision models. Our ternary models can also beviewed as sparse binary weight networks, which can potentially be acceleratedwith custom circuit. Experiments on CIFAR-10 show that the ternary modelsobtained by trained quantization method outperform full-precision models ofResNet-32,44,56 by 0.04%, 0.16%, 0.36%, respectively. On ImageNet, our modeloutperforms full-precision AlexNet model by 0.3% of Top-1 accuracy andoutperforms previous ternary models by 3%.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '520',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.01064v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12956735651240747861&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 299: {'ID': 299,\n",
       "  'title': 'Learning Combinatorial Optimization Algorithms over Graphs',\n",
       "  'authors': ['Hanjun Dai',\n",
       "   'Yuyu Zhang',\n",
       "   'Elias B. Khalil',\n",
       "   'Bistra Dilkina',\n",
       "   'Le Song'],\n",
       "  'published': '2017-04-05T23:08:07Z',\n",
       "  'updated': '2018-02-21T19:47:20Z',\n",
       "  'abstract': 'The design of good heuristics or approximation algorithms for NP-hardcombinatorial optimization problems often requires significant specializedknowledge and trial-and-error. Can we automate this challenging, tediousprocess, and learn the algorithms instead? In many real-world applications, itis typically the case that the same optimization problem is solved again andagain on a regular basis, maintaining the same problem structure but differingin the data. This provides an opportunity for learning heuristic algorithmsthat exploit the structure of such recurring problems. In this paper, wepropose a unique combination of reinforcement learning and graph embedding toaddress this challenge. The learned greedy policy behaves like a meta-algorithmthat incrementally constructs a solution, and the action is determined by theoutput of a graph embedding network capturing the current state of thesolution. We show that our framework can be applied to a diverse range ofoptimization problems over graphs, and learns effective algorithms for theMinimum Vertex Cover, Maximum Cut and Traveling Salesman problems.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '305',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.01665v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6935751850601868852&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 300: {'ID': 300,\n",
       "  'title': 'Unsupervised Machine Translation Using Monolingual Corpora Only',\n",
       "  'authors': ['Guillaume Lample',\n",
       "   \"Marc'Aurelio Ranzato\",\n",
       "   'Alexis Conneau',\n",
       "   'Ludovic Denoyer'],\n",
       "  'published': '2017-10-31T18:31:11Z',\n",
       "  'updated': '2018-04-13T13:30:28Z',\n",
       "  'abstract': 'Machine translation has recently achieved impressive performance thanks torecent advances in deep learning and the availability of large-scale parallelcorpora. There have been numerous attempts to extend these successes tolow-resource language pairs, yet requiring tens of thousands of parallelsentences. In this work, we take this research direction to the extreme andinvestigate whether it is possible to learn to translate even without anyparallel data. We propose a model that takes sentences from monolingual corporain two different languages and maps them into the same latent space. Bylearning to reconstruct in both languages from this shared feature space, themodel effectively learns to translate without using any labeled data. Wedemonstrate our model on two widely used datasets and two language pairs,reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-Frenchdatasets, without using even a single parallel sentence at training time.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '428',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00043v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=682955820897938264&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 301: {'ID': 301,\n",
       "  'title': 'Joint Distribution Optimal Transportation for Domain Adaptation',\n",
       "  'authors': ['Alain Rakotomamonjy',\n",
       "   'Nicolas Courty',\n",
       "   'Rémi Flamary',\n",
       "   'Amaury Habrard'],\n",
       "  'published': '2017-05-24T16:34:41Z',\n",
       "  'updated': '2017-10-22T12:16:35Z',\n",
       "  'abstract': 'This paper deals with the unsupervised domain adaptation problem, where onewants to estimate a prediction function $f$ in a given target domain withoutany labeled sample by exploiting the knowledge available from a source domainwhere labels are known. Our work makes the following assumption: there exists anon-linear transformation between the joint feature/label space distributionsof the two domain $\\\\mathcal{P}_s$ and $\\\\mathcal{P}_t$. We propose a solution ofthis problem with optimal transport, that allows to recover an estimated target$\\\\mathcal{P}^f_t=(X,f(X))$ by optimizing simultaneously the optimal couplingand $f$. We show that our method corresponds to the minimization of a bound onthe target error, and provide an efficient algorithmic solution, for whichconvergence is proved. The versatility of our approach, both in terms of classof hypothesis or loss functions is demonstrated with real world classificationand regression problems, for which we reach or surpass state-of-the-artresults.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '367',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08848v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3838459407382849555&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 302: {'ID': 302,\n",
       "  'title': 'Bidirectional Attention Flow for Machine Comprehension',\n",
       "  'authors': ['Ali Farhadi',\n",
       "   'Hannaneh Hajishirzi',\n",
       "   'Aniruddha Kembhavi',\n",
       "   'Minjoon Seo'],\n",
       "  'published': '2016-11-05T04:49:00Z',\n",
       "  'updated': '2018-06-21T10:53:20Z',\n",
       "  'abstract': 'Machine comprehension (MC), answering a query about a given contextparagraph, requires modeling complex interactions between the context and thequery. Recently, attention mechanisms have been successfully extended to MC.Typically these methods use attention to focus on a small portion of thecontext and summarize it with a fixed-size vector, couple attentionstemporally, and/or often form a uni-directional attention. In this paper weintroduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stagehierarchical process that represents the context at different levels ofgranularity and uses bi-directional attention flow mechanism to obtain aquery-aware context representation without early summarization. Ourexperimental evaluations show that our model achieves the state-of-the-artresults in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail clozetest.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1032',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01603v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=199178676793208244&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 303: {'ID': 303,\n",
       "  'title': 'Attend, Infer, Repeat: Fast Scene Understanding with Generative Models',\n",
       "  'authors': ['Yuval Tassa',\n",
       "   'Nicolas Heess',\n",
       "   'Geoffrey E. Hinton',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Theophane Weber',\n",
       "   'David Szepesvari',\n",
       "   'S. M. Ali Eslami'],\n",
       "  'published': '2016-03-28T21:59:08Z',\n",
       "  'updated': '2016-08-12T16:05:08Z',\n",
       "  'abstract': 'We present a framework for efficient inference in structured image modelsthat explicitly reason about objects. We achieve this by performingprobabilistic inference using a recurrent neural network that attends to sceneelements and processes them one at a time. Crucially, the model itself learnsto choose the appropriate number of inference steps. We use this scheme tolearn to perform inference in partially specified 2D models (variable-sizedvariational auto-encoders) and fully specified 3D models (probabilisticrenderers). We show that such models learn to identify multiple objects -counting, locating and classifying the elements of a scene - without anysupervision, e.g., decomposing 3D images with various numbers of objects in asingle forward pass of a neural network. We further show that the networksproduce accurate inferences when compared to supervised counterparts, and thattheir structure leads to improved generalization.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '226',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.08575v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17841381849984749111&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 304: {'ID': 304,\n",
       "  'title': 'Learning with a Wasserstein Loss',\n",
       "  'authors': ['Tomaso Poggio',\n",
       "   'Chiyuan Zhang',\n",
       "   'Charlie Frogner',\n",
       "   'Hossein Mobahi',\n",
       "   'Mauricio Araya-Polo'],\n",
       "  'published': '2015-06-17T19:36:41Z',\n",
       "  'updated': '2015-12-30T01:08:11Z',\n",
       "  'abstract': \"Learning to predict multi-label outputs is challenging, but in many problemsthere is a natural metric on the outputs that can be used to improvepredictions. In this paper we develop a loss function for multi-label learning,based on the Wasserstein distance. The Wasserstein distance provides a naturalnotion of dissimilarity for probability measures. Although optimizing withrespect to the exact Wasserstein distance is costly, recent work has describeda regularized approximation that is efficiently computed. We describe anefficient learning algorithm based on this regularization, as well as a novelextension of the Wasserstein distance from probability measures to unnormalizedmeasures. We also describe a statistical learning bound for the loss. TheWasserstein loss can encourage smoothness of the predictions with respect to achosen metric on the output space. We demonstrate this property on a real-datatag prediction problem, using the Yahoo Flickr Creative Commons dataset,outperforming a baseline that doesn't use the metric.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '248',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.05439v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12544095470577774181&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 305: {'ID': 305,\n",
       "  'title': 'Surpassing Human-Level Face Verification Performance on LFW with  GaussianFace',\n",
       "  'authors': ['Chaochao Lu', 'Xiaoou Tang'],\n",
       "  'published': '2014-04-15T07:51:23Z',\n",
       "  'updated': '2014-12-20T03:37:36Z',\n",
       "  'abstract': 'Face verification remains a challenging problem in very complex conditionswith large variations such as pose, illumination, expression, and occlusions.This problem is exacerbated when we rely unrealistically on a single trainingdata source, which is often insufficient to cover the intrinsically complexface variations. This paper proposes a principled multi-task learning approachbased on Discriminative Gaussian Process Latent Variable Model, namedGaussianFace, to enrich the diversity of training data. In comparison toexisting methods, our model exploits additional data from multiplesource-domains to improve the generalization performance of face verificationin an unknown target-domain. Importantly, our model can adapt automatically tocomplex data distributions, and therefore can well capture complex facevariations inherent in multiple sources. Extensive experiments demonstrate theeffectiveness of the proposed model in learning from diverse data sources andgeneralize to unseen domain. Specifically, the accuracy of our algorithmachieves an impressive accuracy rate of 98.52% on the well-known andchallenging Labeled Faces in the Wild (LFW) benchmark. For the first time, thehuman-level performance in face verification (97.53%) on LFW is surpassed.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '270',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1404.3840v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11575983753307386058&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 306: {'ID': 306,\n",
       "  'title': 'Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural  Networks',\n",
       "  'authors': ['Changyou Chen',\n",
       "   'David Carlson',\n",
       "   'Lawrence Carin',\n",
       "   'Chunyuan Li'],\n",
       "  'published': '2015-12-23T23:45:03Z',\n",
       "  'updated': '2015-12-23T23:45:03Z',\n",
       "  'abstract': 'Effective training of deep neural networks suffers from two main issues. Thefirst is that the parameter spaces of these models exhibit pathologicalcurvature. Recent methods address this problem by using adaptivepreconditioning for Stochastic Gradient Descent (SGD). These methods improveconvergence by adapting to the local geometry of parameter space. A secondissue is overfitting, which is typically addressed by early stopping. However,recent work has demonstrated that Bayesian model averaging mitigates thisproblem. The posterior can be sampled by using Stochastic Gradient LangevinDynamics (SGLD). However, the rapidly changing curvature renders default SGLDmethods inefficient. Here, we propose combining adaptive preconditioners withSGLD. In support of this idea, we give theoretical properties on asymptoticconvergence and predictive risk. We also provide empirical results for LogisticRegression, Feedforward Neural Nets, and Convolutional Neural Nets,demonstrating that our preconditioned SGLD method gives state-of-the-artperformance on these models.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\\xa0…',\n",
       "  'citations': '141',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.07666v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7279308262670948916&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 307: {'ID': 307,\n",
       "  'title': 'Perspective Transformer Nets: Learning Single-View 3D Object  Reconstruction without 3D Supervision',\n",
       "  'authors': ['Xinchen Yan',\n",
       "   'Ersin Yumer',\n",
       "   'Yijie Guo',\n",
       "   'Jimei Yang',\n",
       "   'Honglak Lee'],\n",
       "  'published': '2016-12-01T05:51:37Z',\n",
       "  'updated': '2017-08-13T02:40:50Z',\n",
       "  'abstract': \"Understanding the 3D world is a fundamental problem in computer vision.However, learning a good representation of 3D objects is still an open problemdue to the high dimensionality of the data and many factors of variationinvolved. In this work, we investigate the task of single-view 3D objectreconstruction from a learning agent's perspective. We formulate the learningprocess as an interaction between 3D and 2D representations and propose anencoder-decoder network with a novel projection loss defined by the perspectivetransformation. More importantly, the projection loss enables the unsupervisedlearning using 2D observation without explicit 3D supervision. We demonstratethe ability of the model in generating 3D volume from a single 2D image withthree sets of experiments: (1) learning from single-class objects; (2) learningfrom multi-class objects and (3) testing on novel object classes. Results showsuperior performance and better generalization ability for 3D objectreconstruction when the projection loss is involved.\",\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '314',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.00814v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13986075700848568161&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 308: {'ID': 308,\n",
       "  'title': 'Simultaneous Spectral-Spatial Feature Selection and Extraction for  Hyperspectral Images',\n",
       "  'authors': ['Bo Du',\n",
       "   'Dacheng Tao',\n",
       "   'Xin Huang',\n",
       "   'Qian Zhang',\n",
       "   'Lefei Zhang',\n",
       "   'Yuan Yan Tang'],\n",
       "  'published': '2019-04-08T12:05:59Z',\n",
       "  'updated': '2019-04-08T12:05:59Z',\n",
       "  'abstract': \"In hyperspectral remote sensing data mining, it is important to take intoaccount of both spectral and spatial information, such as the spectralsignature, texture feature and morphological property, to improve theperformances, e.g., the image classification accuracy. In a featurerepresentation point of view, a nature approach to handle this situation is toconcatenate the spectral and spatial features into a single but highdimensional vector and then apply a certain dimension reduction techniquedirectly on that concatenated vector before feed it into the subsequentclassifier. However, multiple features from various domains definitely havedifferent physical meanings and statistical properties, and thus suchconcatenation hasn't efficiently explore the complementary properties amongdifferent features, which should benefit for boost the featurediscriminability. Furthermore, it is also difficult to interpret thetransformed results of the concatenated vector. Consequently, finding aphysically meaningful consensus low dimensional feature representation oforiginal multiple features is still a challenging task. In order to address thethese issues, we propose a novel feature learning framework, i.e., thesimultaneous spectral-spatial feature selection and extraction algorithm, forhyperspectral images spectral-spatial feature representation andclassification. Specifically, the proposed method learns a latent lowdimensional subspace by projecting the spectral-spatial feature into a commonfeature space, where the complementary information has been effectivelyexploited, and simultaneously, only the most significant original features havebeen transformed. Encouraging experimental results on three public availablehyperspectral remote sensing datasets confirm that our proposed method iseffective and efficient.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Cybernetics 48 (1), 16-28',\n",
       "  'citations': '122',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.03982v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10288918583770083724&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 309: {'ID': 309,\n",
       "  'title': 'Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer',\n",
       "  'authors': ['Geoffrey Hinton',\n",
       "   'Jeff Dean',\n",
       "   'Quoc Le',\n",
       "   'Krzysztof Maziarz',\n",
       "   'Azalia Mirhoseini',\n",
       "   'Andy Davis',\n",
       "   'Noam Shazeer'],\n",
       "  'published': '2017-01-23T18:10:00Z',\n",
       "  'updated': '2017-01-23T18:10:00Z',\n",
       "  'abstract': 'The capacity of a neural network to absorb information is limited by itsnumber of parameters. Conditional computation, where parts of the network areactive on a per-example basis, has been proposed in theory as a way ofdramatically increasing model capacity without a proportional increase incomputation. In practice, however, there are significant algorithmic andperformance challenges. In this work, we address these challenges and finallyrealize the promise of conditional computation, achieving greater than 1000ximprovements in model capacity with only minor losses in computationalefficiency on modern GPU clusters. We introduce a Sparsely-GatedMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forwardsub-networks. A trainable gating network determines a sparse combination ofthese experts to use for each example. We apply the MoE to the tasks oflanguage modeling and machine translation, where model capacity is critical forabsorbing the vast quantities of knowledge available in the training corpora.We present model architectures in which a MoE with up to 137 billion parametersis applied convolutionally between stacked LSTM layers. On large languagemodeling and machine translation benchmarks, these models achieve significantlybetter results than state-of-the-art at lower computational cost.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '456',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.06538v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15166356379734033992&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 310: {'ID': 310,\n",
       "  'title': 'Distributed Gaussian Processes',\n",
       "  'authors': ['Marc Peter Deisenroth', 'Jun Wei Ng'],\n",
       "  'published': '2015-02-10T10:31:41Z',\n",
       "  'updated': '2015-05-22T06:46:11Z',\n",
       "  'abstract': 'To scale Gaussian processes (GPs) to large data sets we introduce the robustBayesian Committee Machine (rBCM), a practical and scalable product-of-expertsmodel for large-scale distributed GP regression. Unlike state-of-the-art sparseGP approximations, the rBCM is conceptually simple and does not rely oninducing or variational parameters. The key idea is to recursively distributecomputations to independent computational units and, subsequently, recombinethem to form an overall result. Efficient closed-form inference allows forstraightforward parallelisation and distributed computations with a smallmemory footprint. The rBCM is independent of the computational graph and can beused on heterogeneous computing infrastructures, ranging from laptops toclusters. With sufficient computing resources our distributed GP model canhandle arbitrarily large data sets.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'ICML, 1481-1490',\n",
       "  'citations': '199',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02843v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12328519706788425295&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 311: {'ID': 311,\n",
       "  'title': 'Accelerating Eulerian Fluid Simulation With Convolutional Networks',\n",
       "  'authors': ['Ken Perlin',\n",
       "   'Jonathan Tompson',\n",
       "   'Pablo Sprechmann',\n",
       "   'Kristofer Schlachter'],\n",
       "  'published': '2016-07-13T05:57:59Z',\n",
       "  'updated': '2017-06-22T17:28:58Z',\n",
       "  'abstract': 'Efficient simulation of the Navier-Stokes equations for fluid flow is a longstanding problem in applied mathematics, for which state-of-the-art methodsrequire large compute resources. In this work, we propose a data-drivenapproach that leverages the approximation power of deep-learning with theprecision of standard solvers to obtain fast and highly realistic simulations.Our method solves the incompressible Euler equations using the standardoperator splitting method, in which a large sparse linear system with many freeparameters must be solved. We use a Convolutional Network with a highlytailored architecture, trained using a novel unsupervised learning framework tosolve the linear system. We present real-time 2D and 3D simulations thatoutperform recently proposed data-driven methods; the obtained results arerealistic and show good generalization properties.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '214',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.03597v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9137335732064258642&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 312: {'ID': 312,\n",
       "  'title': 'Dropout as a Bayesian Approximation: Representing Model Uncertainty in  Deep Learning',\n",
       "  'authors': ['Zoubin Ghahramani', 'Yarin Gal'],\n",
       "  'published': '2015-06-06T12:30:43Z',\n",
       "  'updated': '2016-10-04T16:50:26Z',\n",
       "  'abstract': \"Deep learning tools have gained tremendous attention in applied machinelearning. However such tools for regression and classification do not capturemodel uncertainty. In comparison, Bayesian models offer a mathematicallygrounded framework to reason about model uncertainty, but usually come with aprohibitive computational cost. In this paper we develop a new theoreticalframework casting dropout training in deep neural networks (NNs) as approximateBayesian inference in deep Gaussian processes. A direct result of this theorygives us tools to model uncertainty with dropout NNs -- extracting informationfrom existing models that has been thrown away so far. This mitigates theproblem of representing uncertainty in deep learning without sacrificing eithercomputational complexity or test accuracy. We perform an extensive study of theproperties of dropout's uncertainty. Various network architectures andnon-linearities are assessed on tasks of regression and classification, usingMNIST as an example. We show a considerable improvement in predictivelog-likelihood and RMSE compared to existing state-of-the-art methods, andfinish by using dropout's uncertainty in deep reinforcement learning.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 1050-1059',\n",
       "  'citations': '2029',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.02142v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13759824860264424817&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 313: {'ID': 313,\n",
       "  'title': 'Mean teachers are better role models: Weight-averaged consistency  targets improve semi-supervised deep learning results',\n",
       "  'authors': ['Antti Tarvainen', 'Harri Valpola'],\n",
       "  'published': '2017-03-06T09:34:56Z',\n",
       "  'updated': '2018-04-16T10:39:11Z',\n",
       "  'abstract': 'The recently proposed Temporal Ensembling has achieved state-of-the-artresults in several semi-supervised learning benchmarks. It maintains anexponential moving average of label predictions on each training example, andpenalizes predictions that are inconsistent with this target. However, becausethe targets change only once per epoch, Temporal Ensembling becomes unwieldywhen learning large datasets. To overcome this problem, we propose MeanTeacher, a method that averages model weights instead of label predictions. Asan additional benefit, Mean Teacher improves test accuracy and enables trainingwith fewer labels than Temporal Ensembling. Without changing the networkarchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250labels, outperforming Temporal Ensembling trained with 1000 labels. We alsoshow that a good network architecture is crucial to performance. Combining MeanTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labelsfrom 35.24% to 9.11%.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '480',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01780v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3256042804843589088&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 314: {'ID': 314,\n",
       "  'title': 'Semi-supervised Convolutional Neural Networks for Text Categorization  via Region Embedding',\n",
       "  'authors': ['Rie Johnson', 'Tong Zhang'],\n",
       "  'published': '2015-04-06T10:42:07Z',\n",
       "  'updated': '2015-11-01T15:26:16Z',\n",
       "  'abstract': 'This paper presents a new semi-supervised framework with convolutional neuralnetworks (CNNs) for text categorization. Unlike the previous approaches thatrely on word embeddings, our method learns embeddings of small text regionsfrom unlabeled data for integration into a supervised CNN. The proposed schemefor embedding learning is based on the idea of two-view semi-supervisedlearning, which is intended to be useful for the task of interest even thoughthe training is done on unlabeled data. Our models achieve better results thanprevious approaches on sentiment classification and topic classification tasks.',\n",
       "  'categories': ['stat.ML', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '252',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1504.01255v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3888849217733730450&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 315: {'ID': 315,\n",
       "  'title': 'Neural Photo Editing with Introspective Adversarial Networks',\n",
       "  'authors': ['Nick Weston', 'Andrew Brock', 'Theodore Lim', 'J. M. Ritchie'],\n",
       "  'published': '2016-09-22T18:07:56Z',\n",
       "  'updated': '2017-02-06T18:46:50Z',\n",
       "  'abstract': 'The increasingly photorealistic sample quality of generative image modelssuggests their feasibility in applications beyond image generation. We presentthe Neural Photo Editor, an interface that leverages the power of generativeneural networks to make large, semantically coherent changes to existingimages. To tackle the challenge of achieving accurate reconstructions withoutloss of feature quality, we introduce the Introspective Adversarial Network, anovel hybridization of the VAE and GAN. Our model efficiently captureslong-range dependencies through use of a computational block based onweight-shared dilated convolutions, and improves generalization performancewith Orthogonal Regularization, a novel weight regularization method. Wevalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samplesand reconstructions with high visual fidelity.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '238',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.07093v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13506818224034936115&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 316: {'ID': 316,\n",
       "  'title': 'Stochastic Variance Reduction for Nonconvex Optimization',\n",
       "  'authors': ['Sashank J. Reddi',\n",
       "   'Ahmed Hefny',\n",
       "   'Suvrit Sra',\n",
       "   'Alex Smola',\n",
       "   'Barnabas Poczos'],\n",
       "  'published': '2016-03-19T23:37:38Z',\n",
       "  'updated': '2016-04-04T23:08:20Z',\n",
       "  'abstract': 'We study nonconvex finite-sum problems and analyze stochastic variancereduced gradient (SVRG) methods for them. SVRG and related methods haverecently surged into prominence for convex optimization given their edge overstochastic gradient descent (SGD); but their theoretical analysis almostexclusively assumes convexity. In contrast, we prove non-asymptotic rates ofconvergence (to stationary points) of SVRG for nonconvex optimization, and showthat it is provably faster than SGD and gradient descent. We also analyze asubclass of nonconvex problems on which SVRG attains linear convergence to theglobal optimum. We extend our analysis to mini-batch variants of SVRG, showing(theoretical) linear speedup due to mini-batching in parallel settings.',\n",
       "  'categories': ['math.OC', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 314-323',\n",
       "  'citations': '341',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.06160v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11798684571364229600&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 317: {'ID': 317,\n",
       "  'title': 'Understanding and Improving Convolutional Neural Networks via  Concatenated Rectified Linear Units',\n",
       "  'authors': ['Diogo Almeida', 'Wenling Shang', 'Honglak Lee', 'Kihyuk Sohn'],\n",
       "  'published': '2016-03-16T18:17:36Z',\n",
       "  'updated': '2016-07-19T05:18:36Z',\n",
       "  'abstract': 'Recently, convolutional neural networks (CNNs) have been used as a powerfultool to solve many problems of machine learning and computer vision. In thispaper, we aim to provide insight on the property of convolutional neuralnetworks, as well as a generic method to improve the performance of many CNNarchitectures. Specifically, we first examine existing CNN models and observean intriguing property that the filters in the lower layers form pairs (i.e.,filters with opposite phase). Inspired by our observation, we propose a novel,simple yet effective activation scheme called concatenated ReLU (CRelu) andtheoretically analyze its reconstruction property in CNNs. We integrate CReluinto several state-of-the-art CNN architectures and demonstrate improvement intheir recognition performance on CIFAR-10/100 and ImageNet datasets with fewertrainable parameters. Our results suggest that better understanding of theproperties of CNNs can lead to significant performance improvement with asimple modification.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICML, 2217-2225',\n",
       "  'citations': '262',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.05201v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6969201205550299393&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 318: {'ID': 318,\n",
       "  'title': 'Semi-supervised Knowledge Transfer for Deep Learning from Private  Training Data',\n",
       "  'authors': ['Kunal Talwar',\n",
       "   'Ian Goodfellow',\n",
       "   'Nicolas Papernot',\n",
       "   'Martín Abadi',\n",
       "   'Úlfar Erlingsson'],\n",
       "  'published': '2016-10-18T19:37:37Z',\n",
       "  'updated': '2017-03-03T18:56:43Z',\n",
       "  'abstract': 'Some machine learning applications involve training data that is sensitive,such as the medical histories of patients in a clinical trial. A model mayinadvertently and implicitly store some of its training data; careful analysisof the model may therefore reveal sensitive information.  To address this problem, we demonstrate a generally applicable approach toproviding strong privacy guarantees for training data: Private Aggregation ofTeacher Ensembles (PATE). The approach combines, in a black-box fashion,multiple models trained with disjoint datasets, such as records from differentsubsets of users. Because they rely directly on sensitive data, these modelsare not published, but instead used as \"teachers\" for a \"student\" model. Thestudent learns to predict an output chosen by noisy voting among all of theteachers, and cannot directly access an individual teacher or the underlyingdata or parameters. The student\\'s privacy properties can be understood bothintuitively (since no single teacher and thus no single dataset dictates thestudent\\'s training) and formally, in terms of differential privacy. Theseproperties hold even if an adversary can not only query the student but alsoinspect its internal workings.  Compared with previous work, the approach imposes only weak assumptions onhow teachers are trained: it applies to any model, including non-convex modelslike DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST andSVHN thanks to an improved privacy analysis and semi-supervised learning.',\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '292',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.05755v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7453137533162499463&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 319: {'ID': 319,\n",
       "  'title': 'How to Escape Saddle Points Efficiently',\n",
       "  'authors': ['Sham M. Kakade',\n",
       "   'Praneeth Netrapalli',\n",
       "   'Rong Ge',\n",
       "   'Michael I. Jordan',\n",
       "   'Chi Jin'],\n",
       "  'published': '2017-03-02T18:35:24Z',\n",
       "  'updated': '2017-03-02T18:35:24Z',\n",
       "  'abstract': 'This paper shows that a perturbed form of gradient descent converges to asecond-order stationary point in a number iterations which depends onlypoly-logarithmically on dimension (i.e., it is almost \"dimension-free\"). Theconvergence rate of this procedure matches the well-known convergence rate ofgradient descent to first-order stationary points, up to log factors. When allsaddle points are non-degenerate, all second-order stationary points are localminima, and our result thus shows that perturbed gradient descent can escapesaddle points almost for free. Our results can be directly applied to manymachine learning applications, including deep learning. As a particularconcrete example of such an application, we show that our results can be useddirectly to establish sharp global convergence rates for matrix factorization.Our results rely on a novel characterization of the geometry around saddlepoints, which may be of independent interest to the non-convex optimizationcommunity.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 1724-1732',\n",
       "  'citations': '365',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00887v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4868890107031817813&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 320: {'ID': 320,\n",
       "  'title': 'Exponential expressivity in deep neural networks through transient chaos',\n",
       "  'authors': ['Ben Poole',\n",
       "   'Maithra Raghu',\n",
       "   'Subhaneil Lahiri',\n",
       "   'Jascha Sohl-Dickstein',\n",
       "   'Surya Ganguli'],\n",
       "  'published': '2016-06-16T19:59:57Z',\n",
       "  'updated': '2016-06-17T18:13:20Z',\n",
       "  'abstract': 'We combine Riemannian geometry with the mean field theory of high dimensionalchaos to study the nature of signal propagation in generic, deep neuralnetworks with random weights. Our results reveal an order-to-chaos expressivityphase transition, with networks in the chaotic phase computing nonlinearfunctions whose global curvature grows exponentially with depth but not width.We prove this generic class of deep random functions cannot be efficientlycomputed by any shallow network, going beyond prior work restricted to theanalysis of single functions. Moreover, we formalize and quantitativelydemonstrate the long conjectured idea that deep networks can disentangle highlycurved manifolds in input space into flat manifolds in hidden space. Ourtheoretical analysis of the expressive power of deep networks broadly appliesto arbitrary nonlinearities, and provides a quantitative underpinning forpreviously abstract notions about the geometry of deep functions.',\n",
       "  'categories': ['stat.ML', 'cond-mat.dis-nn', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '248',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.05340v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10408494153995210425&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 321: {'ID': 321,\n",
       "  'title': 'Learning to learn by gradient descent by gradient descent',\n",
       "  'authors': ['Misha Denil',\n",
       "   'Marcin Andrychowicz',\n",
       "   'Brendan Shillingford',\n",
       "   'Nando de Freitas',\n",
       "   'David Pfau',\n",
       "   'Tom Schaul',\n",
       "   'Matthew W. Hoffman',\n",
       "   'Sergio Gomez'],\n",
       "  'published': '2016-06-14T17:49:32Z',\n",
       "  'updated': '2016-11-30T16:45:45Z',\n",
       "  'abstract': 'The move from hand-designed features to learned features in machine learninghas been wildly successful. In spite of this, optimization algorithms are stilldesigned by hand. In this paper we show how the design of an optimizationalgorithm can be cast as a learning problem, allowing the algorithm to learn toexploit structure in the problems of interest in an automatic way. Our learnedalgorithms, implemented by LSTMs, outperform generic, hand-designed competitorson the tasks for which they are trained, and also generalize well to new taskswith similar structure. We demonstrate this on a number of tasks, includingsimple convex problems, training neural networks, and styling images withneural art.',\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '793',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.04474v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17211876730630533152&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 322: {'ID': 322,\n",
       "  'title': 'Learning to Generate Long-term Future via Hierarchical Prediction',\n",
       "  'authors': ['Sungryull Sohn',\n",
       "   'Ruben Villegas',\n",
       "   'Xunyu Lin',\n",
       "   'Jimei Yang',\n",
       "   'Honglak Lee',\n",
       "   'Yuliang Zou'],\n",
       "  'published': '2017-04-19T17:25:56Z',\n",
       "  'updated': '2018-01-08T01:24:36Z',\n",
       "  'abstract': 'We propose a hierarchical approach for making long-term predictions of futureframes. To avoid inherent compounding errors in recursive pixel-levelprediction, we propose to first estimate high-level structure in the inputframes, then predict how that structure evolves in the future, and finally byobserving a single frame from the past and the predicted high-level structure,we construct the future frames without having to observe any of the pixel-levelpredictions. Long-term video prediction is difficult to perform by recurrentlyobserving the predicted frames because the small errors in pixel spaceexponentially amplify as predictions are made deeper into the future. Ourapproach prevents pixel-level error propagation from happening by removing theneed to observe the predicted frames. Our model is built with a combination ofLSTM and analogy based encoder-decoder convolutional neural networks, whichindependently predict the video structure and generate the future frames,respectively. In experiments, our model is evaluated on the Human3.6M and PennAction datasets on the task of long-term pixel-level video prediction of humansperforming actions and demonstrate significantly better results than thestate-of-the-art.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 3560-3569',\n",
       "  'citations': '195',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.05831v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=307545796405932708&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 323: {'ID': 323,\n",
       "  'title': 'Supervised and Semi-Supervised Text Categorization using LSTM for Region  Embeddings',\n",
       "  'authors': ['Rie Johnson', 'Tong Zhang'],\n",
       "  'published': '2016-02-07T14:05:58Z',\n",
       "  'updated': '2016-05-26T15:26:34Z',\n",
       "  'abstract': \"One-hot CNN (convolutional neural network) has been shown to be effective fortext categorization (Johnson &amp; Zhang, 2015). We view it as a special case of ageneral framework which jointly trains a linear model with a non-linear featuregenerator consisting of `text region embedding + pooling'. Under thisframework, we explore a more sophisticated region embedding method using LongShort-Term Memory (LSTM). LSTM can embed text regions of variable (and possiblylarge) sizes, whereas the region size needs to be fixed in a CNN. We seekeffective and efficient use of LSTM for this purpose in the supervised andsemi-supervised settings. The best results were obtained by combining regionembeddings in the form of LSTM and convolution layers trained on unlabeleddata. The results indicate that on this task, embeddings of text regions, whichcan convey complex concepts, are more useful than embeddings of single words inisolation. We report performances exceeding the previous best results on fourbenchmark datasets.\",\n",
       "  'categories': ['stat.ML', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICML, 526-534',\n",
       "  'citations': '171',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02373v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=734642960293024734&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 324: {'ID': 324,\n",
       "  'title': 'Policy Distillation',\n",
       "  'authors': ['Sergio Gomez Colmenarejo',\n",
       "   'Raia Hadsell',\n",
       "   'James Kirkpatrick',\n",
       "   'Guillaume Desjardins',\n",
       "   'Razvan Pascanu',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Caglar Gulcehre',\n",
       "   'Volodymyr Mnih',\n",
       "   'Andrei A. Rusu'],\n",
       "  'published': '2015-11-19T18:38:47Z',\n",
       "  'updated': '2016-01-07T18:43:03Z',\n",
       "  'abstract': 'Policies for complex visual tasks have been successfully learned with deepreinforcement learning, using an approach called deep Q-networks (DQN), butrelatively large (task-specific) networks and extensive training are needed toachieve good performance. In this work, we present a novel method called policydistillation that can be used to extract the policy of a reinforcement learningagent and train a new network that performs at the expert level while beingdramatically smaller and more efficient. Furthermore, the same method can beused to consolidate multiple task-specific policies into a single policy. Wedemonstrate these claims using the Atari domain and show that the multi-taskdistilled agent outperforms the single-task teachers as well as ajointly-trained DQN agent.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '259',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06295v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7257674603698705150&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 325: {'ID': 325,\n",
       "  'title': 'Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization',\n",
       "  'authors': ['Xiangru Lian', 'Yijun Huang', 'Yuncheng Li', 'Ji Liu'],\n",
       "  'published': '2015-06-27T08:41:50Z',\n",
       "  'updated': '2019-04-18T18:25:04Z',\n",
       "  'abstract': 'Asynchronous parallel implementations of stochastic gradient (SG) have beenbroadly used in solving deep neural network and received many successes inpractice recently. However, existing theories cannot explain their convergenceand speedup properties, mainly due to the nonconvexity of most deep learningformulations and the asynchronous parallel mechanism. To fill the gaps intheory and provide theoretical supports, this paper studies two asynchronousparallel implementations of SG: one is on the computer network and the other ison the shared memory system. We establish an ergodic convergence rate$O(1/\\\\sqrt{K})$ for both algorithms and prove that the linear speedup isachievable if the number of workers is bounded by $\\\\sqrt{K}$ ($K$ is the totalnumber of iterations). Our results generalize and improve existing analysis forconvex minimization.',\n",
       "  'categories': ['math.OC', 'cs.NA', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '257',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.08272v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14750704835510307295&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 326: {'ID': 326,\n",
       "  'title': 'Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word  Embeddings',\n",
       "  'authors': ['Kai-Wei Chang',\n",
       "   'Adam Kalai',\n",
       "   'James Zou',\n",
       "   'Tolga Bolukbasi',\n",
       "   'Venkatesh Saligrama'],\n",
       "  'published': '2016-07-21T22:26:20Z',\n",
       "  'updated': '2016-07-21T22:26:20Z',\n",
       "  'abstract': 'The blind application of machine learning runs the risk of amplifying biasespresent in data. Such a danger is facing us with word embedding, a popularframework to represent text data as vectors which has been used in many machinelearning and natural language processing tasks. We show that even wordembeddings trained on Google News articles exhibit female/male genderstereotypes to a disturbing extent. This raises concerns because theirwidespread use, as we describe, often tends to amplify these biases.Geometrically, gender bias is first shown to be captured by a direction in theword embedding. Second, gender neutral words are shown to be linearly separablefrom gender definition words in the word embedding. Using these properties, weprovide a methodology for modifying an embedding to remove gender stereotypes,such as the association between between the words receptionist and female,while maintaining desired associations such as between the words queen andfemale. We define metrics to quantify both direct and indirect gender biases inembeddings, and develop algorithms to \"debias\" the embedding. Usingcrowd-worker evaluation as well as standard benchmarks, we empiricallydemonstrate that our algorithms significantly reduce gender bias in embeddingswhile preserving the its useful properties such as the ability to clusterrelated concepts and to solve analogy tasks. The resulting embeddings can beused in applications without amplifying gender bias.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '822',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.06520v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1143892262062010100&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 327: {'ID': 327,\n",
       "  'title': 'Quasi-Recurrent Neural Networks',\n",
       "  'authors': ['James Bradbury',\n",
       "   'Richard Socher',\n",
       "   'Caiming Xiong',\n",
       "   'Stephen Merity'],\n",
       "  'published': '2016-11-05T00:31:25Z',\n",
       "  'updated': '2016-11-21T20:52:34Z',\n",
       "  'abstract': \"Recurrent neural networks are a powerful tool for modeling sequential data,but the dependence of each timestep's computation on the previous timestep'soutput limits parallelism and makes RNNs unwieldy for very long sequences. Weintroduce quasi-recurrent neural networks (QRNNs), an approach to neuralsequence modeling that alternates convolutional layers, which apply in parallelacross timesteps, and a minimalist recurrent pooling function that applies inparallel across channels. Despite lacking trainable recurrent layers, stackedQRNNs have better predictive accuracy than stacked LSTMs of the same hiddensize. Due to their increased parallelism, they are up to 16 times faster attrain and test time. Experiments on language modeling, sentimentclassification, and character-level neural machine translation demonstratethese advantages and underline the viability of QRNNs as a basic building blockfor a variety of sequence tasks.\",\n",
       "  'categories': ['cs.NE', 'cs.AI', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '256',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01576v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4062513269935809949&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 328: {'ID': 328,\n",
       "  'title': 'One-Shot Generalization in Deep Generative Models',\n",
       "  'authors': ['Daan Wierstra',\n",
       "   'Danilo Jimenez Rezende',\n",
       "   'Ivo Danihelka',\n",
       "   'Karol Gregor',\n",
       "   'Shakir Mohamed'],\n",
       "  'published': '2016-03-16T14:10:00Z',\n",
       "  'updated': '2016-05-25T12:57:19Z',\n",
       "  'abstract': 'Humans have an impressive ability to reason about new concepts andexperiences from just a single example. In particular, humans have an abilityfor one-shot generalization: an ability to encounter a new concept, understandits structure, and then be able to generate compelling alternative variationsof the concept. We develop machine learning systems with this importantcapacity by developing new deep generative models, models that combine therepresentational power of deep learning with the inferential power of Bayesianreasoning. We develop a class of sequential generative models that are built onthe principles of feedback and attention. These two characteristics lead togenerative models that are among the state-of-the art in density estimation andimage generation. We demonstrate the one-shot generalization ability of ourmodels using three tasks: unconditional sampling, generating new exemplars of agiven concept, and generating new exemplars of a family of concepts. In allcases our models are able to generate compelling and diverse samples---havingseen new examples just once---providing an important class of general-purposemodels for one-shot machine learning.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 1521-1529',\n",
       "  'citations': '180',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.05106v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16418227374416270076&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 329: {'ID': 329,\n",
       "  'title': 'Dynamic Coattention Networks For Question Answering',\n",
       "  'authors': ['Richard Socher', 'Victor Zhong', 'Caiming Xiong'],\n",
       "  'published': '2016-11-05T04:53:40Z',\n",
       "  'updated': '2018-03-06T22:45:53Z',\n",
       "  'abstract': 'Several deep learning models have been proposed for question answering.However, due to their single-pass nature, they have no way to recover fromlocal maxima corresponding to incorrect answers. To address this problem, weintroduce the Dynamic Coattention Network (DCN) for question answering. The DCNfirst fuses co-dependent representations of the question and the document inorder to focus on relevant parts of both. Then a dynamic pointing decoderiterates over potential answer spans. This iterative procedure enables themodel to recover from initial local maxima corresponding to incorrect answers.On the Stanford question answering dataset, a single DCN model improves theprevious state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains80.4% F1.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '433',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01604v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7601883970857280608&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 330: {'ID': 330,\n",
       "  'title': 'Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows  Prediction',\n",
       "  'authors': ['Dekang Qi', 'Yu Zheng', 'Junbo Zhang'],\n",
       "  'published': '2016-10-01T03:56:13Z',\n",
       "  'updated': '2017-01-10T09:53:16Z',\n",
       "  'abstract': 'Forecasting the flow of crowds is of great importance to traffic managementand public safety, yet a very challenging task affected by many complexfactors, such as inter-region traffic, events and weather. In this paper, wepropose a deep-learning-based approach, called ST-ResNet, to collectivelyforecast the in-flow and out-flow of crowds in each and every region through acity. We design an end-to-end structure of ST-ResNet based on unique propertiesof spatio-temporal data. More specifically, we employ the framework of theresidual neural networks to model the temporal closeness, period, and trendproperties of the crowd traffic, respectively. For each property, we design abranch of residual convolutional units, each of which models the spatialproperties of the crowd traffic. ST-ResNet learns to dynamically aggregate theoutput of the three residual neural networks based on data, assigning differentweights to different branches and regions. The aggregation is further combinedwith external factors, such as weather and day of the week, to predict thefinal traffic of crowds in each and every region. We evaluate ST-ResNet basedon two types of crowd flows in Beijing and NYC, finding that its performanceexceeds six well-know methods.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '551',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.00081v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10585174952970430867&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 331: {'ID': 331,\n",
       "  'title': 'On Calibration of Modern Neural Networks',\n",
       "  'authors': ['Geoff Pleiss', 'Kilian Q. Weinberger', 'Chuan Guo', 'Yu Sun'],\n",
       "  'published': '2017-06-14T17:33:50Z',\n",
       "  'updated': '2017-08-03T13:29:46Z',\n",
       "  'abstract': 'Confidence calibration -- the problem of predicting probability estimatesrepresentative of the true correctness likelihood -- is important forclassification models in many applications. We discover that modern neuralnetworks, unlike those from a decade ago, are poorly calibrated. Throughextensive experiments, we observe that depth, width, weight decay, and BatchNormalization are important factors influencing calibration. We evaluate theperformance of various post-processing calibration methods on state-of-the-artarchitectures with image and document classification datasets. Our analysis andexperiments not only offer insights into neural network learning, but alsoprovide a simple and straightforward recipe for practical settings: on mostdatasets, temperature scaling -- a single-parameter variant of Platt Scaling --is surprisingly effective at calibrating predictions.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1321-1330',\n",
       "  'citations': '672',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.04599v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13350219683390288487&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 332: {'ID': 332,\n",
       "  'title': 'Weight Uncertainty in Neural Networks',\n",
       "  'authors': ['Koray Kavukcuoglu',\n",
       "   'Charles Blundell',\n",
       "   'Daan Wierstra',\n",
       "   'Julien Cornebise'],\n",
       "  'published': '2015-05-20T15:39:48Z',\n",
       "  'updated': '2015-05-21T14:07:23Z',\n",
       "  'abstract': 'We introduce a new, efficient, principled and backpropagation-compatiblealgorithm for learning a probability distribution on the weights of a neuralnetwork, called Bayes by Backprop. It regularises the weights by minimising acompression cost, known as the variational free energy or the expected lowerbound on the marginal likelihood. We show that this principled kind ofregularisation yields comparable performance to dropout on MNISTclassification. We then demonstrate how the learnt uncertainty in the weightscan be used to improve generalisation in non-linear regression problems, andhow this weight uncertainty can be used to drive the exploration-exploitationtrade-off in reinforcement learning.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 1613-1622',\n",
       "  'citations': '935',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.05424v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14542735200645169180&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 333: {'ID': 333,\n",
       "  'title': 'Deep learning with Elastic Averaging SGD',\n",
       "  'authors': ['Sixin Zhang', 'Yann LeCun', 'Anna Choromanska'],\n",
       "  'published': '2014-12-20T13:22:23Z',\n",
       "  'updated': '2015-10-25T12:12:52Z',\n",
       "  'abstract': 'We study the problem of stochastic optimization for deep learning in theparallel computing environment under communication constraints. A new algorithmis proposed in this setting where the communication and coordination of workamong concurrent processes (local workers), is based on an elastic force whichlinks the parameters they compute with a center variable stored by theparameter server (master). The algorithm enables the local workers to performmore exploration, i.e. the algorithm allows the local variables to fluctuatefurther from the center variable by reducing the amount of communicationbetween local workers and the master. We empirically demonstrate that in thedeep learning setting, due to the existence of many local optima, allowing moreexploration can lead to the improved performance. We propose synchronous andasynchronous variants of the new algorithm. We provide the stability analysisof the asynchronous variant in the round-robin scheme and compare it with themore common parallelized method ADMM. We show that the stability of EASGD isguaranteed when a simple stability condition is satisfied, which is not thecase for ADMM. We additionally propose the momentum-based version of ouralgorithm that can be applied in both synchronous and asynchronous settings.Asynchronous variant of the algorithm is applied to train convolutional neuralnetworks for image classification on the CIFAR and ImageNet datasets.Experiments demonstrate that the new algorithm accelerates the training of deeparchitectures compared to DOWNPOUR and other common baseline approaches andfurthermore is very communication efficient.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '356',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6651v8',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18355366617755570418&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 334: {'ID': 334,\n",
       "  'title': 'Associative Embedding: End-to-End Learning for Joint Detection and  Grouping',\n",
       "  'authors': ['Jia Deng', 'Alejandro Newell', 'Zhiao Huang'],\n",
       "  'published': '2016-11-16T20:04:28Z',\n",
       "  'updated': '2017-06-09T16:13:48Z',\n",
       "  'abstract': 'We introduce associative embedding, a novel method for supervisingconvolutional neural networks for the task of detection and grouping. A numberof computer vision problems can be framed in this manner including multi-personpose estimation, instance segmentation, and multi-object tracking. Usually thegrouping of detections is achieved with multi-stage pipelines, instead wepropose an approach that teaches a network to simultaneously output detectionsand group assignments. This technique can be easily integrated into anystate-of-the-art network architecture that produces pixel-wise predictions. Weshow how to apply this method to both multi-person pose estimation and instancesegmentation and report state-of-the-art performance for multi-person pose onthe MPII and MS-COCO datasets.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '259',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.05424v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17872365231417177678&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 335: {'ID': 335,\n",
       "  'title': 'Dual Path Networks',\n",
       "  'authors': ['Shuicheng Yan',\n",
       "   'Jianan Li',\n",
       "   'Yunpeng Chen',\n",
       "   'Xiaojie Jin',\n",
       "   'Huaxin Xiao',\n",
       "   'Jiashi Feng'],\n",
       "  'published': '2017-07-06T04:05:14Z',\n",
       "  'updated': '2017-08-01T01:15:57Z',\n",
       "  'abstract': 'In this work, we present a simple, highly efficient and modularized Dual PathNetwork (DPN) for image classification which presents a new topology ofconnection paths internally. By revealing the equivalence of thestate-of-the-art Residual Network (ResNet) and Densely Convolutional Network(DenseNet) within the HORNN framework, we find that ResNet enables featurere-usage while DenseNet enables new features exploration which are bothimportant for learning good representations. To enjoy the benefits from bothpath topologies, our proposed Dual Path Network shares common features whilemaintaining the flexibility to explore new features through dual patharchitectures. Extensive experiments on three benchmark datasets, ImagNet-1k,Places365 and PASCAL VOC, clearly demonstrate superior performance of theproposed DPN over state-of-the-arts. In particular, on the ImagNet-1k dataset,a shallow DPN surpasses the best ResNeXt-101(64x4d) with 26% smaller modelsize, 25% less computational cost and 8% lower memory consumption, and a deeperDPN (DPN-131) further pushes the state-of-the-art single model performance withabout 2 times faster training speed. Experiments on the Places365 large-scalescene dataset, PASCAL VOC detection dataset, and PASCAL VOC segmentationdataset also demonstrate its consistently better performance than DenseNet,ResNet and the latest ResNeXt model over various applications.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '383',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.01629v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11426486763420133960&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 336: {'ID': 336,\n",
       "  'title': 'Continuous Deep Q-Learning with Model-based Acceleration',\n",
       "  'authors': ['Timothy Lillicrap',\n",
       "   'Sergey Levine',\n",
       "   'Shixiang Gu',\n",
       "   'Ilya Sutskever'],\n",
       "  'published': '2016-03-02T15:28:25Z',\n",
       "  'updated': '2016-03-02T15:28:25Z',\n",
       "  'abstract': 'Model-free reinforcement learning has been successfully applied to a range ofchallenging problems, and has recently been extended to handle large neuralnetwork policies and value functions. However, the sample complexity ofmodel-free algorithms, particularly when using high-dimensional functionapproximators, tends to limit their applicability to physical systems. In thispaper, we explore algorithms and representations to reduce the samplecomplexity of deep reinforcement learning for continuous control tasks. Wepropose two complementary techniques for improving the efficiency of suchalgorithms. First, we derive a continuous variant of the Q-learning algorithm,which we call normalized adantage functions (NAF), as an alternative to themore commonly used policy gradient and actor-critic methods. NAF representationallows us to apply Q-learning with experience replay to continuous tasks, andsubstantially improves performance on a set of simulated robotic control tasks.To further improve the efficiency of our approach, we explore the use oflearned models for accelerating model-free reinforcement learning. We show thatiteratively refitted local linear models are especially effective for this, anddemonstrate substantially faster learning on domains where such models areapplicable.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO', 'cs.SY'],\n",
       "  'journal': 'ICML, 2829-2838',\n",
       "  'citations': '553',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.00748v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11808487067838603398&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 337: {'ID': 337,\n",
       "  'title': 'SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient',\n",
       "  'authors': ['Yong Yu', 'Jun Wang', 'Lantao Yu', 'Weinan Zhang'],\n",
       "  'published': '2016-09-18T11:42:23Z',\n",
       "  'updated': '2017-08-25T16:22:57Z',\n",
       "  'abstract': 'As a new way of training generative models, Generative Adversarial Nets (GAN)that uses a discriminative model to guide the training of the generative modelhas enjoyed considerable success in generating real-valued data. However, ithas limitations when the goal is for generating sequences of discrete tokens. Amajor reason lies in that the discrete outputs from the generative model makeit difficult to pass the gradient update from the discriminative model to thegenerative model. Also, the discriminative model can only assess a completesequence, while for a partially generated sequence, it is non-trivial tobalance its current score and the future one once the entire sequence has beengenerated. In this paper, we propose a sequence generation framework, calledSeqGAN, to solve the problems. Modeling the data generator as a stochasticpolicy in reinforcement learning (RL), SeqGAN bypasses the generatordifferentiation problem by directly performing gradient policy update. The RLreward signal comes from the GAN discriminator judged on a complete sequence,and is passed back to the intermediate state-action steps using Monte Carlosearch. Extensive experiments on synthetic data and real-world tasksdemonstrate significant improvements over strong baselines.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '1020',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.05473v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13783508915327278077&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 338: {'ID': 338,\n",
       "  'title': 'Certifying Some Distributional Robustness with Principled Adversarial  Training',\n",
       "  'authors': ['John Duchi',\n",
       "   'Hongseok Namkoong',\n",
       "   'Riccardo Volpi',\n",
       "   'Aman Sinha'],\n",
       "  'published': '2017-10-29T07:27:57Z',\n",
       "  'updated': '2020-05-01T07:29:34Z',\n",
       "  'abstract': 'Neural networks are vulnerable to adversarial examples and researchers haveproposed many heuristic attack and defense mechanisms. We address this problemthrough the principled lens of distributionally robust optimization, whichguarantees performance under adversarial input perturbations. By considering aLagrangian penalty formulation of perturbing the underlying data distributionin a Wasserstein ball, we provide a training procedure that augments modelparameter updates with worst-case perturbations of training data. For smoothlosses, our procedure provably achieves moderate levels of robustness withlittle computational or statistical cost relative to empirical riskminimization. Furthermore, our statistical guarantees allow us to efficientlycertify robustness for the population loss. For imperceptible perturbations,our method matches or outperforms heuristic approaches.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.10571v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5504610656672947417&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 339: {'ID': 339,\n",
       "  'title': 'SARAH: A Novel Method for Machine Learning Problems Using Stochastic  Recursive Gradient',\n",
       "  'authors': ['Lam M. Nguyen', 'Jie Liu', 'Katya Scheinberg', 'Martin Takáč'],\n",
       "  'published': '2017-03-01T02:08:32Z',\n",
       "  'updated': '2017-06-03T07:30:20Z',\n",
       "  'abstract': 'In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH),as well as its practical variant SARAH+, as a novel approach to the finite-summinimization problems. Different from the vanilla SGD and other modernstochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simplerecursive framework for updating stochastic gradient estimates; when comparingto SAG/SAGA, SARAH does not require a storage of past gradients. The linearconvergence rate of SARAH is proven under strong convexity assumption. We alsoprove a linear convergence rate (in the strongly convex case) for an inner loopof SARAH, the property that SVRG does not possess. Numerical experimentsdemonstrate the efficiency of our algorithm.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'math.OC'],\n",
       "  'journal': 'ICML, 2613-2621',\n",
       "  'citations': '171',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00102v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15168434346098746144&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 340: {'ID': 340,\n",
       "  'title': 'Which Training Methods for GANs do actually Converge?',\n",
       "  'authors': ['Lars Mescheder', 'Sebastian Nowozin', 'Andreas Geiger'],\n",
       "  'published': '2018-01-13T09:42:26Z',\n",
       "  'updated': '2018-07-31T16:28:15Z',\n",
       "  'abstract': 'Recent work has shown local convergence of GAN training for absolutelycontinuous data and generator distributions. In this paper, we show that therequirement of absolute continuity is necessary: we describe a simple yetprototypical counterexample showing that in the more realistic case ofdistributions that are not absolutely continuous, unregularized GAN training isnot always convergent. Furthermore, we discuss regularization strategies thatwere recently proposed to stabilize GAN training. Our analysis shows that GANtraining with instance noise or zero-centered gradient penalties converges. Onthe other hand, we show that Wasserstein-GANs and WGAN-GP with a finite numberof discriminator updates per generator update do not always converge to theequilibrium point. We discuss these results, leading us to a new explanationfor the stability problems of GAN training. Based on our analysis, we extendour convergence results to more general GANs and prove local convergence forsimplified gradient penalties even if the generator and data distribution lieon lower dimensional manifolds. We find these penalties to work well inpractice and use them to learn high-resolution generative image models for avariety of datasets with little hyperparameter tuning.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.GT'],\n",
       "  'journal': 'ICML, 3478-3487',\n",
       "  'citations': '304',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.04406v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11334901664651510839&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 341: {'ID': 341,\n",
       "  'title': 'Learning End-to-End Goal-Oriented Dialog',\n",
       "  'authors': ['Antoine Bordes', 'Y-Lan Boureau', 'Jason Weston'],\n",
       "  'published': '2016-05-24T23:09:58Z',\n",
       "  'updated': '2017-03-30T23:02:22Z',\n",
       "  'abstract': 'Traditional dialog systems used in goal-oriented applications require a lotof domain-specific handcrafting, which hinders scaling up to new domains.End-to-end dialog systems, in which all components are trained from the dialogsthemselves, escape this limitation. But the encouraging success recentlyobtained in chit-chat dialog may not carry over to goal-oriented settings. Thispaper proposes a testbed to break down the strengths and shortcomings ofend-to-end dialog systems in goal-oriented applications. Set in the context ofrestaurant reservation, our tasks require manipulating sentences and symbols,so as to properly conduct conversations, issue API calls and use the outputs ofsuch calls. We show that an end-to-end dialog system based on Memory Networkscan reach promising, yet imperfect, performance and learn to performnon-trivial operations. We confirm those results by comparing our system to ahand-crafted slot-filling baseline on data from the second Dialog StateTracking Challenge (Henderson et al., 2014a). We show similar result patternson data extracted from an online concierge service.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '504',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07683v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14624523216814088198&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 342: {'ID': 342,\n",
       "  'title': 'Convolutional neural networks with low-rank regularization',\n",
       "  'authors': ['Xiaogang Wang',\n",
       "   'Weinan E',\n",
       "   'Yi Zhang',\n",
       "   'Cheng Tai',\n",
       "   'Tong Xiao'],\n",
       "  'published': '2015-11-19T06:13:55Z',\n",
       "  'updated': '2016-02-14T03:46:09Z',\n",
       "  'abstract': 'Large CNNs have delivered impressive performance in various computer visionapplications. But the storage and computation requirements make it problematicfor deploying these models on mobile devices. Recently, tensor decompositionshave been used for speeding up CNNs. In this paper, we further develop thetensor decomposition technique. We propose a new algorithm for computing thelow-rank tensor decomposition for removing the redundancy in the convolutionkernels. The algorithm finds the exact global optimizer of the decompositionand is more effective than iterative methods. Based on the decomposition, wefurther propose a new method for training low-rank constrained CNNs fromscratch. Interestingly, while achieving a significant speedup, sometimes thelow-rank constrained CNNs delivers significantly better performance than theirnon-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rankNIN model achieves $91.31\\\\%$ accuracy (without data augmentation), which alsoimproves upon state-of-the-art result. We evaluated the proposed method onCIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 isreduced by half while the performance is still comparable. Empirical successsuggests that low-rank tensor decompositions can be a very useful tool forspeeding up large CNNs.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '236',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06067v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=21602892819366205&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 343: {'ID': 343,\n",
       "  'title': 'Towards Deep Learning Models Resistant to Adversarial Attacks',\n",
       "  'authors': ['Adrian Vladu',\n",
       "   'Dimitris Tsipras',\n",
       "   'Aleksandar Makelov',\n",
       "   'Ludwig Schmidt',\n",
       "   'Aleksander Madry'],\n",
       "  'published': '2017-06-19T17:53:11Z',\n",
       "  'updated': '2019-09-04T18:53:10Z',\n",
       "  'abstract': 'Recent work has demonstrated that deep neural networks are vulnerable toadversarial examples---inputs that are almost indistinguishable from naturaldata and yet classified incorrectly by the network. In fact, some of the latestfindings suggest that the existence of adversarial attacks may be an inherentweakness of deep learning models. To address this problem, we study theadversarial robustness of neural networks through the lens of robustoptimization. This approach provides us with a broad and unifying view on muchof the prior work on this topic. Its principled nature also enables us toidentify methods for both training and attacking neural networks that arereliable and, in a certain sense, universal. In particular, they specify aconcrete security guarantee that would protect against any adversary. Thesemethods let us train networks with significantly improved resistance to a widerange of adversarial attacks. They also suggest the notion of security againsta first-order adversary as a natural and broad security guarantee. We believethat robustness against such well-defined classes of adversaries is animportant stepping stone towards fully resistant deep learning models. Code andpre-trained models are available at https://github.com/MadryLab/mnist_challengeand https://github.com/MadryLab/cifar10_challenge.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1791',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.06083v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14165082781627851489&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 344: {'ID': 344,\n",
       "  'title': 'Playing FPS Games with Deep Reinforcement Learning',\n",
       "  'authors': ['Guillaume Lample', 'Devendra Singh Chaplot'],\n",
       "  'published': '2016-09-18T17:52:28Z',\n",
       "  'updated': '2018-01-29T15:13:59Z',\n",
       "  'abstract': 'Advances in deep reinforcement learning have allowed autonomous agents toperform well on Atari games, often outperforming humans, using only raw pixelsto make their decisions. However, most of these games take place in 2Denvironments that are fully observable to the agent. In this paper, we presentthe first architecture to tackle 3D environments in first-person shooter games,that involve partially observable states. Typically, deep reinforcementlearning methods only utilize visual input for training. We present a method toaugment these models to exploit game feature information such as the presenceof enemies or items, during the training phase. Our model is trained tosimultaneously learn these features along with minimizing a Q-learningobjective, which is shown to dramatically improve the training speed andperformance of our agent. Our architecture is also modularized to allowdifferent models to be independently trained for different phases of the game.We show that the proposed architecture substantially outperforms built-in AIagents of the game as well as humans in deathmatch scenarios.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '306',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.05521v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11485614925940495388&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 345: {'ID': 345,\n",
       "  'title': 'Unsupervised Representation Learning with Deep Convolutional Generative  Adversarial Networks',\n",
       "  'authors': ['Luke Metz', 'Soumith Chintala', 'Alec Radford'],\n",
       "  'published': '2015-11-19T22:50:32Z',\n",
       "  'updated': '2016-01-07T23:09:39Z',\n",
       "  'abstract': 'In recent years, supervised learning with convolutional networks (CNNs) hasseen huge adoption in computer vision applications. Comparatively, unsupervisedlearning with CNNs has received less attention. In this work we hope to helpbridge the gap between the success of CNNs for supervised learning andunsupervised learning. We introduce a class of CNNs called deep convolutionalgenerative adversarial networks (DCGANs), that have certain architecturalconstraints, and demonstrate that they are a strong candidate for unsupervisedlearning. Training on various image datasets, we show convincing evidence thatour deep convolutional adversarial pair learns a hierarchy of representationsfrom object parts to scenes in both the generator and discriminator.Additionally, we use the learned features for novel tasks - demonstrating theirapplicability as general image representations.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '6544',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06434v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3321343160055675528&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 346: {'ID': 346,\n",
       "  'title': 'On the State of the Art of Evaluation in Neural Language Models',\n",
       "  'authors': ['Phil Blunsom', 'Gábor Melis', 'Chris Dyer'],\n",
       "  'published': '2017-07-18T12:35:53Z',\n",
       "  'updated': '2017-11-20T17:57:58Z',\n",
       "  'abstract': 'Ongoing innovations in recurrent neural network architectures have provided asteady influx of apparently state-of-the-art results on language modellingbenchmarks. However, these have been evaluated using differing code bases andlimited computational resources, which represent uncontrolled sources ofexperimental variation. We reevaluate several popular architectures andregularisation methods with large-scale automatic black-box hyperparametertuning and arrive at the somewhat surprising conclusion that standard LSTMarchitectures, when properly regularised, outperform more recent models. Weestablish a new state of the art on the Penn Treebank and Wikitext-2 corpora,as well as strong baselines on the Hutter Prize dataset.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '271',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.05589v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10520579957359692654&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 347: {'ID': 347,\n",
       "  'title': 'Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical  Volumetric Image Segmentation',\n",
       "  'authors': ['Marijn F. Stollenga',\n",
       "   'Wonmin Byeon',\n",
       "   'Juergen Schmidhuber',\n",
       "   'Marcus Liwicki'],\n",
       "  'published': '2015-06-24T16:26:51Z',\n",
       "  'updated': '2015-06-24T16:26:51Z',\n",
       "  'abstract': 'Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3Dvideos to segment them. They have a fixed input size and typically perceiveonly small local contexts of the pixels to be classified as foreground orbackground. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceivethe entire spatio-temporal context of each pixel in a few sweeps through allpixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despitethese theoretical advantages, however, unlike CNNs, previous MD-LSTM variantswere hard to parallelize on GPUs. Here we re-arrange the traditional cuboidorder of computations in MD-LSTM in pyramidal fashion. The resultingPyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks ofbrain slice images. PyraMiD-LSTM achieved best known pixel-wise brain imagesegmentation results on MRBrainS13 (and competitive results on EM-ISBI12).',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '219',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.07452v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3236346698623785406&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 348: {'ID': 348,\n",
       "  'title': 'Object Detectors Emerge in Deep Scene CNNs',\n",
       "  'authors': ['Aude Oliva',\n",
       "   'Antonio Torralba',\n",
       "   'Bolei Zhou',\n",
       "   'Agata Lapedriza',\n",
       "   'Aditya Khosla'],\n",
       "  'published': '2014-12-22T01:14:01Z',\n",
       "  'updated': '2015-04-15T19:06:41Z',\n",
       "  'abstract': 'With the success of new computational architectures for visual processing,such as convolutional neural networks (CNN) and access to image databases withmillions of labeled examples (e.g., ImageNet, Places), the state of the art incomputer vision is advancing rapidly. One important factor for continuedprogress is to understand the representations that are learned by the innerlayers of these deep architectures. Here we show that object detectors emergefrom training CNNs to perform scene classification. As scenes are composed ofobjects, the CNN for scene classification automatically discovers meaningfulobjects detectors, representative of the learned scene categories. With objectdetectors emerging as a result of learning to recognize scenes, our workdemonstrates that the same network can perform both scene recognition andobject localization in a single forward-pass, without ever having beenexplicitly taught the notion of objects.',\n",
       "  'categories': ['cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '736',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6856v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=889391300182990037&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 349: {'ID': 349,\n",
       "  'title': 'Deep Transfer Learning with Joint Adaptation Networks',\n",
       "  'authors': ['Jianmin Wang',\n",
       "   'Michael I. Jordan',\n",
       "   'Mingsheng Long',\n",
       "   'Han Zhu'],\n",
       "  'published': '2016-05-21T12:56:14Z',\n",
       "  'updated': '2017-08-17T07:35:59Z',\n",
       "  'abstract': 'Deep networks have been successfully applied to learn transferable featuresfor adapting models from a source domain to a different target domain. In thispaper, we present joint adaptation networks (JAN), which learn a transfernetwork by aligning the joint distributions of multiple domain-specific layersacross domains based on a joint maximum mean discrepancy (JMMD) criterion.Adversarial training strategy is adopted to maximize JMMD such that thedistributions of the source and target domains are made more distinguishable.Learning can be performed by stochastic gradient descent with the gradientscomputed by back-propagation in linear-time. Experiments testify that our modelyields state of the art results on standard datasets.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2208-2217',\n",
       "  'citations': '595',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06636v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3758970819381872485&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 350: {'ID': 350,\n",
       "  'title': 'A Deep Reinforced Model for Abstractive Summarization',\n",
       "  'authors': ['Richard Socher', 'Romain Paulus', 'Caiming Xiong'],\n",
       "  'published': '2017-05-11T17:39:35Z',\n",
       "  'updated': '2017-11-13T20:11:26Z',\n",
       "  'abstract': 'Attentional, RNN-based encoder-decoder models for abstractive summarizationhave achieved good performance on short input and output sequences. For longerdocuments and summaries however these models often include repetitive andincoherent phrases. We introduce a neural network model with a novelintra-attention that attends over the input and continuously generated outputseparately, and a new training method that combines standard supervised wordprediction and reinforcement learning (RL). Models trained only with supervisedlearning often exhibit \"exposure bias\" - they assume ground truth is providedat each step during training. However, when standard word prediction iscombined with the global sequence prediction training of RL the resultingsummaries become more readable. We evaluate this model on the CNN/Daily Mailand New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on theCNN/Daily Mail dataset, an improvement over previous state-of-the-art models.Human evaluation also shows that our model produces higher quality summaries.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '641',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.04304v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=439043726958667778&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 351: {'ID': 351,\n",
       "  'title': 'FiLM: Visual Reasoning with a General Conditioning Layer',\n",
       "  'authors': ['Ethan Perez',\n",
       "   'Aaron Courville',\n",
       "   'Florian Strub',\n",
       "   'Vincent Dumoulin',\n",
       "   'Harm de Vries'],\n",
       "  'published': '2017-09-22T17:54:12Z',\n",
       "  'updated': '2017-12-18T21:25:53Z',\n",
       "  'abstract': 'We introduce a general-purpose conditioning method for neural networks calledFiLM: Feature-wise Linear Modulation. FiLM layers influence neural networkcomputation via a simple, feature-wise affine transformation based onconditioning information. We show that FiLM layers are highly effective forvisual reasoning - answering image-related questions which require amulti-step, high-level process - a task which has proven difficult for standarddeep learning methods that do not explicitly model reasoning. Specifically, weshow on visual reasoning tasks that FiLM layers 1) halve state-of-the-art errorfor the CLEVR benchmark, 2) modulate features in a coherent manner, 3) arerobust to ablations and architectural modifications, and 4) generalize well tochallenging, new data from few examples or even zero-shot.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '327',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.07871v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14710363985853844282&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 352: {'ID': 352,\n",
       "  'title': 'Deep multi-scale video prediction beyond mean square error',\n",
       "  'authors': ['Michael Mathieu', 'Yann LeCun', 'Camille Couprie'],\n",
       "  'published': '2015-11-17T15:36:32Z',\n",
       "  'updated': '2016-02-26T22:10:30Z',\n",
       "  'abstract': 'Learning to predict future images from a video sequence involves theconstruction of an internal representation that models the image evolutionaccurately, and therefore, to some degree, its content and dynamics. This iswhy pixel-space video prediction may be viewed as a promising avenue forunsupervised feature learning. In addition, while optical flow has been a verystudied problem in computer vision for a long time, future frame prediction israrely approached. Still, many vision applications could benefit from theknowledge of the next frames of videos, that does not require the complexity oftracking every pixel trajectories. In this work, we train a convolutionalnetwork to generate future frames given an input sequence. To deal with theinherently blurry predictions obtained from the standard Mean Squared Error(MSE) loss function, we propose three different and complementary featurelearning strategies: a multi-scale architecture, an adversarial trainingmethod, and an image gradient difference loss function. We compare ourpredictions to different published results based on recurrent neural networkson the UCF101 dataset',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1072',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05440v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2726105701998692678&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 353: {'ID': 353,\n",
       "  'title': 'Counterfactual Multi-Agent Policy Gradients',\n",
       "  'authors': ['Gregory Farquhar',\n",
       "   'Nantas Nardelli',\n",
       "   'Triantafyllos Afouras',\n",
       "   'Shimon Whiteson',\n",
       "   'Jakob Foerster'],\n",
       "  'published': '2017-05-24T18:52:17Z',\n",
       "  'updated': '2017-12-14T14:50:34Z',\n",
       "  'abstract': \"Cooperative multi-agent systems can be naturally used to model many realworld problems, such as network packet routing and the coordination ofautonomous vehicles. There is a great need for new reinforcement learningmethods that can efficiently learn decentralised policies for such systems. Tothis end, we propose a new multi-agent actor-critic method calledcounterfactual multi-agent (COMA) policy gradients. COMA uses a centralisedcritic to estimate the Q-function and decentralised actors to optimise theagents' policies. In addition, to address the challenges of multi-agent creditassignment, it uses a counterfactual baseline that marginalises out a singleagent's action, while keeping the other agents' actions fixed. COMA also uses acritic representation that allows the counterfactual baseline to be computedefficiently in a single forward pass. We evaluate COMA in the testbed ofStarCraft unit micromanagement, using a decentralised variant with significantpartial observability. COMA significantly improves average performance overother multi-agent actor-critic methods in this setting, and the best performingagents are competitive with state-of-the-art centralised controllers that getaccess to the full state.\",\n",
       "  'categories': ['cs.AI', 'cs.MA'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '404',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08926v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2943188170099558937&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 354: {'ID': 354,\n",
       "  'title': 'Identity Matters in Deep Learning',\n",
       "  'authors': ['Moritz Hardt', 'Tengyu Ma'],\n",
       "  'published': '2016-11-14T02:44:18Z',\n",
       "  'updated': '2018-07-20T04:38:23Z',\n",
       "  'abstract': 'An emerging design principle in deep learning is that each layer of a deepartificial neural network should be able to easily express the identitytransformation. This idea not only motivated various normalization techniques,such as \\\\emph{batch normalization}, but was also key to the immense success of\\\\emph{residual networks}.  In this work, we put the principle of \\\\emph{identity parameterization} on amore solid theoretical footing alongside further empirical progress. We firstgive a strikingly simple proof that arbitrarily deep linear residual networkshave no spurious local optima. The same result for linear feed-forward networksin their standard parameterization is substantially more delicate. Second, weshow that residual networks with ReLu activations have universal finite-sampleexpressivity in the sense that the network can represent any function of itssample provided that the model has more parameters than the sample size.  Directly inspired by our theory, we experiment with a radically simpleresidual architecture consisting of only residual convolutional layers and ReLuactivations, but no batch normalization, dropout, or max pool. Our modelimproves significantly on previous all-convolutional networks on the CIFAR10,CIFAR100, and ImageNet classification benchmarks.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '207',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.04231v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13607975019730988794&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 355: {'ID': 355,\n",
       "  'title': 'SummaRuNNer: A Recurrent Neural Network based Sequence Model for  Extractive Summarization of Documents',\n",
       "  'authors': ['Feifei Zhai', 'Ramesh Nallapati', 'Bowen Zhou'],\n",
       "  'published': '2016-11-14T02:44:14Z',\n",
       "  'updated': '2016-11-14T02:44:14Z',\n",
       "  'abstract': 'We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence modelfor extractive summarization of documents and show that it achieves performancebetter than or comparable to state-of-the-art. Our model has the additionaladvantage of being very interpretable, since it allows visualization of itspredictions broken up by abstract features such as information content,salience and novelty. Another novel contribution of our work is abstractivetraining of our extractive model that can train on human generated referencesummaries alone, eliminating the need for sentence-level extractive labels.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '430',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.04230v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15743603261336170924&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 356: {'ID': 356,\n",
       "  'title': 'Regularizing Neural Networks by Penalizing Confident Output  Distributions',\n",
       "  'authors': ['Jan Chorowski',\n",
       "   'Geoffrey Hinton',\n",
       "   'Łukasz Kaiser',\n",
       "   'Gabriel Pereyra',\n",
       "   'George Tucker'],\n",
       "  'published': '2017-01-23T18:35:28Z',\n",
       "  'updated': '2017-01-23T18:35:28Z',\n",
       "  'abstract': \"We systematically explore regularizing neural networks by penalizing lowentropy output distributions. We show that penalizing low entropy outputdistributions, which has been shown to improve exploration in reinforcementlearning, acts as a strong regularizer in supervised learning. Furthermore, weconnect a maximum entropy based confidence penalty to label smoothing throughthe direction of the KL divergence. We exhaustively evaluate the proposedconfidence penalty and label smoothing on 6 common benchmarks: imageclassification (MNIST and Cifar-10), language modeling (Penn Treebank), machinetranslation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ).We find that both label smoothing and the confidence penalty improvestate-of-the-art models across benchmarks without modifying existinghyperparameters, suggesting the wide applicability of these regularizers.\",\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '332',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.06548v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17169779076640319067&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 357: {'ID': 357,\n",
       "  'title': 'Isolating Sources of Disentanglement in Variational Autoencoders',\n",
       "  'authors': ['Ricky T. Q. Chen',\n",
       "   'David Duvenaud',\n",
       "   'Roger Grosse',\n",
       "   'Xuechen Li'],\n",
       "  'published': '2018-02-14T03:48:06Z',\n",
       "  'updated': '2019-04-23T17:20:14Z',\n",
       "  'abstract': 'We decompose the evidence lower bound to show the existence of a termmeasuring the total correlation between latent variables. We use this tomotivate our $\\\\beta$-TCVAE (Total Correlation Variational Autoencoder), arefinement of the state-of-the-art $\\\\beta$-VAE objective for learningdisentangled representations, requiring no additional hyperparameters duringtraining. We further propose a principled classifier-free measure ofdisentanglement called the mutual information gap (MIG). We perform extensivequantitative and qualitative experiments, in both restricted and non-restrictedsettings, and show a strong relation between total correlation anddisentanglement, when the latent variables model is trained using ourframework.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.04942v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11372263911361899725&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 358: {'ID': 358,\n",
       "  'title': 'Skip-Thought Vectors',\n",
       "  'authors': ['Ruslan Salakhutdinov',\n",
       "   'Richard S. Zemel',\n",
       "   'Yukun Zhu',\n",
       "   'Ryan Kiros',\n",
       "   'Sanja Fidler',\n",
       "   'Antonio Torralba',\n",
       "   'Raquel Urtasun'],\n",
       "  'published': '2015-06-22T19:33:40Z',\n",
       "  'updated': '2015-06-22T19:33:40Z',\n",
       "  'abstract': 'We describe an approach for unsupervised learning of a generic, distributedsentence encoder. Using the continuity of text from books, we train anencoder-decoder model that tries to reconstruct the surrounding sentences of anencoded passage. Sentences that share semantic and syntactic properties arethus mapped to similar vector representations. We next introduce a simplevocabulary expansion method to encode words that were not seen as part oftraining, allowing us to expand our vocabulary to a million words. Aftertraining our model, we extract and evaluate our vectors with linear models on 8tasks: semantic relatedness, paraphrase detection, image-sentence ranking,question-type classification and 4 benchmark sentiment and subjectivitydatasets. The end result is an off-the-shelf encoder that can produce highlygeneric sentence representations that are robust and perform well in practice.We will make our encoder publicly available.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1734',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.06726v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10194299428367499234&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 359: {'ID': 359,\n",
       "  'title': 'Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using  Generative Models',\n",
       "  'authors': ['Maya Kabkab', 'Rama Chellappa', 'Pouya Samangouei'],\n",
       "  'published': '2018-05-17T05:38:55Z',\n",
       "  'updated': '2018-05-18T00:20:52Z',\n",
       "  'abstract': 'In recent years, deep neural network approaches have been widely adopted formachine learning tasks, including classification. However, they were shown tobe vulnerable to adversarial perturbations: carefully crafted smallperturbations can cause misclassification of legitimate images. We proposeDefense-GAN, a new framework leveraging the expressive capability of generativemodels to defend deep neural networks against such attacks. Defense-GAN istrained to model the distribution of unperturbed images. At inference time, itfinds a close output to a given image which does not contain the adversarialchanges. This output is then fed to the classifier. Our proposed method can beused with any classification model and does not modify the classifier structureor training procedure. It can also be used as a defense against any attack asit does not assume knowledge of the process for generating the adversarialexamples. We empirically show that Defense-GAN is consistently effectiveagainst different attack methods and improves on existing defense strategies.Our code has been made publicly available athttps://github.com/kabkabm/defensegan',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '403',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.06605v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4356922002684962280&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 360: {'ID': 360,\n",
       "  'title': 'Learning Deep Structured Models',\n",
       "  'authors': ['Liang-Chieh Chen',\n",
       "   'Raquel Urtasun',\n",
       "   'Alexander G. Schwing',\n",
       "   'Alan L. Yuille'],\n",
       "  'published': '2014-07-09T15:54:27Z',\n",
       "  'updated': '2015-04-27T21:11:32Z',\n",
       "  'abstract': 'Many problems in real-world applications involve predicting several randomvariables which are statistically related. Markov random fields (MRFs) are agreat mathematical tool to encode such relationships. The goal of this paper isto combine MRFs with deep learning algorithms to estimate complexrepresentations while taking into account the dependencies between the outputrandom variables. Towards this goal, we propose a training algorithm that isable to learn structured models jointly with deep features that form the MRFpotentials. Our approach is efficient as it blends learning and inference andmakes use of GPU acceleration. We demonstrate the effectiveness of ouralgorithm in the tasks of predicting words from noisy images, as well asmulti-class classification of Flickr photographs. We show that joint learningof the deep features and the MRF parameters results in significant performancegains.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '212',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1407.2538v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4006467637565747418&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 361: {'ID': 361,\n",
       "  'title': 'Ensemble Adversarial Training: Attacks and Defenses',\n",
       "  'authors': ['Patrick McDaniel',\n",
       "   'Ian Goodfellow',\n",
       "   'Nicolas Papernot',\n",
       "   'Florian Tramèr',\n",
       "   'Alexey Kurakin',\n",
       "   'Dan Boneh'],\n",
       "  'published': '2017-05-19T21:56:43Z',\n",
       "  'updated': '2020-04-26T22:20:25Z',\n",
       "  'abstract': \"Adversarial examples are perturbed inputs designed to fool machine learningmodels. Adversarial training injects such examples into training data toincrease robustness. To scale this technique to large datasets, perturbationsare crafted using fast single-step methods that maximize a linear approximationof the model's loss. We show that this form of adversarial training convergesto a degenerate global minimum, wherein small curvature artifacts near the datapoints obfuscate a linear approximation of the loss. The model thus learns togenerate weak perturbations, rather than defend against strong ones. As aresult, we find that adversarial training remains vulnerable to black-boxattacks, where we transfer perturbations computed on undefended models, as wellas to a powerful novel single-step attack that escapes the non-smooth vicinityof the input data via a small random step. We further introduce EnsembleAdversarial Training, a technique that augments training data withperturbations transferred from other models. On ImageNet, Ensemble AdversarialTraining yields models with strong robustness to black-box attacks. Inparticular, our most robust model won the first round of the NIPS 2017competition on Defenses against Adversarial Attacks. However, subsequent workfound that more elaborate black-box attacks could significantly enhancetransferability and reduce the accuracy of our models.\",\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '832',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.07204v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10511209374384426640&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 362: {'ID': 362,\n",
       "  'title': 'Variance Reduction for Faster Non-Convex Optimization',\n",
       "  'authors': ['Zeyuan Allen-Zhu', 'Elad Hazan'],\n",
       "  'published': '2016-03-17T19:55:12Z',\n",
       "  'updated': '2016-08-25T02:34:00Z',\n",
       "  'abstract': 'We consider the fundamental problem in non-convex optimization of efficientlyreaching a stationary point. In contrast to the convex case, in the longhistory of this basic problem, the only known theoretical results onfirst-order non-convex optimization remain to be full gradient descent thatconverges in $O(1/\\\\varepsilon)$ iterations for smooth objectives, andstochastic gradient descent that converges in $O(1/\\\\varepsilon^2)$ iterationsfor objectives that are sum of smooth functions.  We provide the first improvement in this line of research. Our result isbased on the variance reduction trick recently introduced to convexoptimization, as well as a brand new analysis of variance reduction that issuitable for non-convex optimization. For objectives that are sum of smoothfunctions, our first-order minibatch stochastic method converges with an$O(1/\\\\varepsilon)$ rate, and is faster than full gradient descent by$\\\\Omega(n^{1/3})$.  We demonstrate the effectiveness of our methods on empirical riskminimizations with non-convex loss functions and training neural nets.',\n",
       "  'categories': ['math.OC', 'cs.DS', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 699-707',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.05643v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16191703712221356547&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 363: {'ID': 363,\n",
       "  'title': 'Weakly-supervised Disentangling with Recurrent Transformations for 3D  View Synthesis',\n",
       "  'authors': ['Ming-Hsuan Yang', 'Scott Reed', 'Honglak Lee', 'Jimei Yang'],\n",
       "  'published': '2016-01-05T00:08:09Z',\n",
       "  'updated': '2016-01-05T00:08:09Z',\n",
       "  'abstract': 'An important problem for both graphics and vision is to synthesize novelviews of a 3D object from a single image. This is particularly challenging dueto the partial observability inherent in projecting a 3D object onto the imagespace, and the ill-posedness of inferring object shape and pose. However, wecan train a neural network to address the problem if we restrict our attentionto specific object categories (in our case faces and chairs) for which we cangather ample training data. In this paper, we propose a novel recurrentconvolutional encoder-decoder network that is trained end-to-end on the task ofrendering rotated objects starting from a single image. The recurrent structureallows our model to capture long-term dependencies along a sequence oftransformations. We demonstrate the quality of its predictions for human faceson the Multi-PIE dataset and for a dataset of 3D chair models, and also showits ability to disentangle latent factors of variation (e.g., identity andpose) without using full supervision.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '226',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1601.00706v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9366321653656639999&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 364: {'ID': 364,\n",
       "  'title': 'BilBOWA: Fast Bilingual Distributed Representations without Word  Alignments',\n",
       "  'authors': ['Greg Corrado', 'Yoshua Bengio', 'Stephan Gouws'],\n",
       "  'published': '2014-10-09T13:41:18Z',\n",
       "  'updated': '2016-02-04T05:51:59Z',\n",
       "  'abstract': 'We introduce BilBOWA (Bilingual Bag-of-Words without Alignments), a simpleand computationally-efficient model for learning bilingual distributedrepresentations of words which can scale to large monolingual datasets and doesnot require word-aligned parallel training data. Instead it trains directly onmonolingual data and extracts a bilingual signal from a smaller set of raw-textsentence-aligned data. This is achieved using a novel sampled bag-of-wordscross-lingual objective, which is used to regularize two noise-contrastivelanguage models for efficient cross-lingual feature learning. We show thatbilingual embeddings learned using the proposed model outperformstate-of-the-art methods on a cross-lingual document classification task aswell as a lexical translation task on WMT11 data.',\n",
       "  'categories': ['stat.ML', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICML, 748-756',\n",
       "  'citations': '301',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1410.2455v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2719170563629478824&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 365: {'ID': 365,\n",
       "  'title': 'Explaining and Harnessing Adversarial Examples',\n",
       "  'authors': ['Christian Szegedy', 'Ian J. Goodfellow', 'Jonathon Shlens'],\n",
       "  'published': '2014-12-20T01:17:12Z',\n",
       "  'updated': '2015-03-20T20:19:16Z',\n",
       "  'abstract': \"Several machine learning models, including neural networks, consistentlymisclassify adversarial examples---inputs formed by applying small butintentionally worst-case perturbations to examples from the dataset, such thatthe perturbed input results in the model outputting an incorrect answer withhigh confidence. Early attempts at explaining this phenomenon focused onnonlinearity and overfitting. We argue instead that the primary cause of neuralnetworks' vulnerability to adversarial perturbation is their linear nature.This explanation is supported by new quantitative results while giving thefirst explanation of the most intriguing fact about them: their generalizationacross architectures and training sets. Moreover, this view yields a simple andfast method of generating adversarial examples. Using this approach to provideexamples for adversarial training, we reduce the test set error of a maxoutnetwork on the MNIST dataset.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '4827',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6572v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14908107896544813002&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 366: {'ID': 366,\n",
       "  'title': 'Unrolled Generative Adversarial Networks',\n",
       "  'authors': ['Jascha Sohl-Dickstein', 'Ben Poole', 'David Pfau', 'Luke Metz'],\n",
       "  'published': '2016-11-07T16:42:09Z',\n",
       "  'updated': '2017-05-12T23:52:12Z',\n",
       "  'abstract': \"We introduce a method to stabilize Generative Adversarial Networks (GANs) bydefining the generator objective with respect to an unrolled optimization ofthe discriminator. This allows training to be adjusted between using theoptimal discriminator in the generator's objective, which is ideal butinfeasible in practice, and using the current value of the discriminator, whichis often unstable and leads to poor solutions. We show how this techniquesolves the common problem of mode collapse, stabilizes training of GANs withcomplex recurrent generators, and increases diversity and coverage of the datadistribution by the generator.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1012',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02163v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14141685069487796752&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 367: {'ID': 367,\n",
       "  'title': 'Word Representations via Gaussian Embedding',\n",
       "  'authors': ['Luke Vilnis', 'Andrew McCallum'],\n",
       "  'published': '2014-12-20T07:42:40Z',\n",
       "  'updated': '2015-05-01T10:14:58Z',\n",
       "  'abstract': 'Current work in lexical distributed representations maps each word to a pointvector in low-dimensional space. Mapping instead to a density provides manyinteresting advantages, including better capturing uncertainty about arepresentation and its relationships, expressing asymmetries more naturallythan dot product or cosine similarity, and enabling more expressiveparameterization of decision boundaries. This paper advocates for density-baseddistributed embeddings and presents a method for learning representations inthe space of Gaussian distributions. We compare performance on various wordembedding benchmarks, investigate the ability of these embeddings to modelentailment and other asymmetric relationships, and explore novel properties ofthe representation.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '234',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6623v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4128677461296445631&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 368: {'ID': 368,\n",
       "  'title': 'Striving for Simplicity: The All Convolutional Net',\n",
       "  'authors': ['Martin Riedmiller',\n",
       "   'Jost Tobias Springenberg',\n",
       "   'Alexey Dosovitskiy',\n",
       "   'Thomas Brox'],\n",
       "  'published': '2014-12-21T16:16:37Z',\n",
       "  'updated': '2015-04-13T07:58:17Z',\n",
       "  'abstract': 'Most modern convolutional neural networks (CNNs) used for object recognitionare built using the same principles: Alternating convolution and max-poolinglayers followed by a small number of fully connected layers. We re-evaluate thestate of the art for object recognition from small images with convolutionalnetworks, questioning the necessity of different components in the pipeline. Wefind that max-pooling can simply be replaced by a convolutional layer withincreased stride without loss in accuracy on several image recognitionbenchmarks. Following this finding -- and building on other recent work forfinding simple network structures -- we propose a new architecture thatconsists solely of convolutional layers and yields competitive or state of theart performance on several object recognition datasets (CIFAR-10, CIFAR-100,ImageNet). To analyze the network we introduce a new variant of the\"deconvolution approach\" for visualizing features learned by CNNs, which can beapplied to a broader range of network structures than existing approaches.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '2175',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6806v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18200872134920294831&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 369: {'ID': 369,\n",
       "  'title': 'Interaction Networks for Learning about Objects, Relations and Physics',\n",
       "  'authors': ['Peter W. Battaglia',\n",
       "   'Danilo Rezende',\n",
       "   'Matthew Lai',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Razvan Pascanu'],\n",
       "  'published': '2016-12-01T12:34:54Z',\n",
       "  'updated': '2016-12-01T12:34:54Z',\n",
       "  'abstract': 'Reasoning about objects, relations, and physics is central to humanintelligence, and a key goal of artificial intelligence. Here we introduce theinteraction network, a model which can reason about how objects in complexsystems interact, supporting dynamical predictions, as well as inferences aboutthe abstract properties of the system. Our model takes graphs as input,performs object- and relation-centric reasoning in a way that is analogous to asimulation, and is implemented using deep neural networks. We evaluate itsability to reason about several challenging physical domains: n-body problems,rigid-body collision, and non-rigid dynamics. Our results show it can betrained to accurately simulate the physical trajectories of dozens of objectsover thousands of time steps, estimate abstract quantities such as energy, andgeneralize automatically to systems with different numbers and configurationsof objects and relations. Our interaction network implementation is the firstgeneral-purpose, learnable physics engine, and a powerful general framework forreasoning about object and relations in a wide variety of complex real-worlddomains.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '469',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.00222v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17057667931848922246&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 370: {'ID': 370,\n",
       "  'title': 'Deeper Insights into Graph Convolutional Networks for Semi-Supervised  Learning',\n",
       "  'authors': ['Xiao-Ming Wu', 'Qimai Li', 'Zhichao Han'],\n",
       "  'published': '2018-01-22T15:24:24Z',\n",
       "  'updated': '2018-01-22T15:24:24Z',\n",
       "  'abstract': 'Many interesting problems in machine learning are being revisited with newdeep learning tools. For graph-based semisupervised learning, a recentimportant development is graph convolutional networks (GCNs), which nicelyintegrate local vertex features and graph topology in the convolutional layers.Although the GCN model compares favorably with other state-of-the-art methods,its mechanisms are not clear and it still requires a considerable amount oflabeled data for validation and model selection. In this paper, we developdeeper insights into the GCN model and address its fundamental limits. First,we show that the graph convolution of the GCN model is actually a special formof Laplacian smoothing, which is the key reason why GCNs work, but it alsobrings potential concerns of over-smoothing with many convolutional layers.Second, to overcome the limits of the GCN model with shallow architectures, wepropose both co-training and self-training approaches to train GCNs. Ourapproaches significantly improve GCNs in learning with very few labels, andexempt them from requiring additional labels for validation. Extensiveexperiments on benchmarks have verified our theory and proposals.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '276',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.07606v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6910084038111478554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 371: {'ID': 371,\n",
       "  'title': 'Coupled Generative Adversarial Networks',\n",
       "  'authors': ['Ming-Yu Liu', 'Oncel Tuzel'],\n",
       "  'published': '2016-06-24T01:20:06Z',\n",
       "  'updated': '2016-09-20T17:01:49Z',\n",
       "  'abstract': 'We propose coupled generative adversarial network (CoGAN) for learning ajoint distribution of multi-domain images. In contrast to the existingapproaches, which require tuples of corresponding images in different domainsin the training set, CoGAN can learn a joint distribution without any tuple ofcorresponding images. It can learn a joint distribution with just samples drawnfrom the marginal distributions. This is achieved by enforcing a weight-sharingconstraint that limits the network capacity and favors a joint distributionsolution over a product of marginal distributions one. We apply CoGAN toseveral joint distribution learning tasks, including learning a jointdistribution of color and depth images, and learning a joint distribution offace images with different attributes. For each task it successfully learns thejoint distribution without any tuple of corresponding images. We alsodemonstrate its applications to domain adaptation and image transformation.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '844',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.07536v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9131569704953326400&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 372: {'ID': 372,\n",
       "  'title': 'DeepBach: a Steerable Model for Bach Chorales Generation',\n",
       "  'authors': ['Frank Nielsen', 'Gaëtan Hadjeres', 'François Pachet'],\n",
       "  'published': '2016-12-03T19:17:29Z',\n",
       "  'updated': '2017-06-17T17:25:58Z',\n",
       "  'abstract': \"This paper introduces DeepBach, a graphical model aimed at modelingpolyphonic music and specifically hymn-like pieces. We claim that, after beingtrained on the chorale harmonizations by Johann Sebastian Bach, our model iscapable of generating highly convincing chorales in the style of Bach.DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with anadapted representation of musical data. This is in contrast with many automaticmusic composition approaches which tend to compose music sequentially. Ourmodel is also steerable in the sense that a user can constrain the generationby imposing positional constraints such as notes, rhythms or cadences in thegenerated score. We also provide a plugin on top of the MuseScore music editormaking the interaction with DeepBach easy to use.\",\n",
       "  'categories': ['cs.AI', 'cs.SD'],\n",
       "  'journal': 'ICML, 1362-1371',\n",
       "  'citations': '188',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.01010v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5309798703109779304&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 373: {'ID': 373,\n",
       "  'title': 'Lossy Image Compression with Compressive Autoencoders',\n",
       "  'authors': ['Wenzhe Shi',\n",
       "   'Andrew Cunningham',\n",
       "   'Ferenc Huszár',\n",
       "   'Lucas Theis'],\n",
       "  'published': '2017-03-01T17:13:47Z',\n",
       "  'updated': '2017-03-01T17:13:47Z',\n",
       "  'abstract': 'We propose a new approach to the problem of optimizing autoencoders for lossyimage compression. New media formats, changing hardware technology, as well asdiverse requirements and content types create a need for compression algorithmswhich are more flexible than existing codecs. Autoencoders have the potentialto address this need, but are difficult to optimize directly due to theinherent non-differentiabilty of the compression loss. We here show thatminimal changes to the loss are sufficient to train deep autoencoderscompetitive with JPEG 2000 and outperforming recently proposed approaches basedon RNNs. Our network is furthermore computationally efficient thanks to asub-pixel architecture, which makes it suitable for high-resolution images.This is in contrast to previous work on autoencoders for compression usingcoarser approximations, shallower architectures, computationally expensivemethods, or focusing on small images.',\n",
       "  'categories': ['stat.ML', 'cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '343',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00395v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13226490013777095959&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 374: {'ID': 374,\n",
       "  'title': 'A Distributional Perspective on Reinforcement Learning',\n",
       "  'authors': ['Marc G. Bellemare', 'Rémi Munos', 'Will Dabney'],\n",
       "  'published': '2017-07-21T13:21:54Z',\n",
       "  'updated': '2017-07-21T13:21:54Z',\n",
       "  'abstract': \"In this paper we argue for the fundamental importance of the valuedistribution: the distribution of the random return received by a reinforcementlearning agent. This is in contrast to the common approach to reinforcementlearning which models the expectation of this return, or value. Although thereis an established body of literature studying the value distribution, thus farit has always been used for a specific purpose such as implementing risk-awarebehaviour. We begin with theoretical results in both the policy evaluation andcontrol settings, exposing a significant distributional instability in thelatter. We then use the distributional perspective to design a new algorithmwhich applies Bellman's equation to the learning of approximate valuedistributions. We evaluate our algorithm using the suite of games from theArcade Learning Environment. We obtain both state-of-the-art results andanecdotal evidence demonstrating the importance of the value distribution inapproximate reinforcement learning. Finally, we combine theoretical andempirical evidence to highlight the ways in which the value distributionimpacts learning in the approximate setting.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 449-458',\n",
       "  'citations': '381',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.06887v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16746050446953182873&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 375: {'ID': 375,\n",
       "  'title': 'Bayesian Robust Tensor Factorization for Incomplete Multiway Data',\n",
       "  'authors': ['Shun-ichi Amari',\n",
       "   'Qibin Zhao',\n",
       "   'Liqing Zhang',\n",
       "   'Andrzej Cichocki',\n",
       "   'Guoxu Zhou'],\n",
       "  'published': '2014-10-09T08:50:31Z',\n",
       "  'updated': '2015-04-16T05:36:23Z',\n",
       "  'abstract': 'We propose a generative model for robust tensor factorization in the presenceof both missing data and outliers. The objective is to explicitly infer theunderlying low-CP-rank tensor capturing the global information and a sparsetensor capturing the local information (also considered as outliers), thusproviding the robust predictive distribution over missing entries. Thelow-CP-rank tensor is modeled by multilinear interactions between multiplelatent factors on which the column sparsity is enforced by a hierarchicalprior, while the sparse tensor is modeled by a hierarchical view of Student-$t$distribution that associates an individual hyperparameter with each elementindependently. For model learning, we develop an efficient closed-formvariational inference under a fully Bayesian treatment, which can effectivelyprevent the overfitting problem and scales linearly with data size. In contrastto existing related works, our method can perform model selection automaticallyand implicitly without need of tuning parameters. More specifically, it candiscover the groundtruth of CP rank and automatically adapt the sparsityinducing priors to various types of outliers. In addition, the tradeoff betweenthe low-rank approximation and the sparse representation can be optimized inthe sense of maximum model evidence. The extensive experiments and comparisonswith many state-of-the-art algorithms on both synthetic and real-world datasetsdemonstrate the superiorities of our method from several perspectives.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 27 (4), 736-748',\n",
       "  'citations': '109',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1410.2386v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3736451354071696313&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 376: {'ID': 376,\n",
       "  'title': 'Sequence Level Training with Recurrent Neural Networks',\n",
       "  'authors': ['Michael Auli',\n",
       "   \"Marc'Aurelio Ranzato\",\n",
       "   'Wojciech Zaremba',\n",
       "   'Sumit Chopra'],\n",
       "  'published': '2015-11-20T19:25:54Z',\n",
       "  'updated': '2016-05-06T21:18:46Z',\n",
       "  'abstract': 'Many natural language processing applications use language models to generatetext. These models are typically trained to predict the next word in asequence, given the previous words and some context such as an image. However,at test time the model is expected to generate the entire sequence fromscratch. This discrepancy makes generation brittle, as errors may accumulatealong the way. We address this issue by proposing a novel sequence leveltraining algorithm that directly optimizes the metric used at test time, suchas BLEU or ROUGE. On three different tasks, our approach outperforms severalstrong baselines for greedy generation. The method is also competitive whenthese baselines employ beam search, while being several times faster.',\n",
       "  'categories': ['cs.LG', 'cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '822',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06732v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4877899442083611721&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 377: {'ID': 377,\n",
       "  'title': 'A Hierarchical Latent Variable Encoder-Decoder Model for Generating  Dialogues',\n",
       "  'authors': ['Alessandro Sordoni',\n",
       "   'Laurent Charlin',\n",
       "   'Aaron Courville',\n",
       "   'Iulian Vlad Serban',\n",
       "   'Joelle Pineau',\n",
       "   'Ryan Lowe',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2016-05-19T17:59:02Z',\n",
       "  'updated': '2016-06-14T02:21:04Z',\n",
       "  'abstract': 'Sequential data often possesses a hierarchical structure with complexdependencies between subsequences, such as found between the utterances in adialogue. In an effort to model this kind of generative process, we propose aneural network-based generative architecture, with latent stochastic variablesthat span a variable number of time steps. We apply the proposed model to thetask of dialogue response generation and compare it with recent neural networkarchitectures. We evaluate the model performance through automatic evaluationmetrics and by carrying out a human evaluation. The experiments demonstratethat our model improves upon recently proposed models and that the latentvariables facilitate the generation of long outputs and maintain the context.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE', 'I.5.1; I.2.7'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '597',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06069v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7853689277795107592&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 378: {'ID': 378,\n",
       "  'title': 'Learning Convolutional Neural Networks for Graphs',\n",
       "  'authors': ['Konstantin Kutzkov', 'Mohamed Ahmed', 'Mathias Niepert'],\n",
       "  'published': '2016-05-17T18:13:13Z',\n",
       "  'updated': '2016-06-08T11:40:13Z',\n",
       "  'abstract': 'Numerous important problems can be framed as learning from graph data. Wepropose a framework for learning convolutional neural networks for arbitrarygraphs. These graphs may be undirected, directed, and with both discrete andcontinuous node and edge attributes. Analogous to image-based convolutionalnetworks that operate on locally connected regions of the input, we present ageneral approach to extracting locally connected regions from graphs. Usingestablished benchmark data sets, we demonstrate that the learned featurerepresentations are competitive with state of the art graph kernels and thattheir computation is highly efficient.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 2014-2023',\n",
       "  'citations': '870',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.05273v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9917957179670149192&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 379: {'ID': 379,\n",
       "  'title': 'Searching for Activation Functions',\n",
       "  'authors': ['Quoc V. Le', 'Prajit Ramachandran', 'Barret Zoph'],\n",
       "  'published': '2017-10-16T18:05:45Z',\n",
       "  'updated': '2017-10-27T17:45:21Z',\n",
       "  'abstract': 'The choice of activation functions in deep networks has a significant effecton the training dynamics and task performance. Currently, the most successfuland widely-used activation function is the Rectified Linear Unit (ReLU).Although various hand-designed alternatives to ReLU have been proposed, nonehave managed to replace it due to inconsistent gains. In this work, we proposeto leverage automatic search techniques to discover new activation functions.Using a combination of exhaustive and reinforcement learning-based search, wediscover multiple novel activation functions. We verify the effectiveness ofthe searches by conducting an empirical evaluation with the best discoveredactivation function. Our experiments show that the best discovered activationfunction, $f(x) = x \\\\cdot \\\\text{sigmoid}(\\\\beta x)$, which we name Swish, tendsto work better than ReLU on deeper models across a number of challengingdatasets. For example, simply replacing ReLUs with Swish units improves top-1classification accuracy on ImageNet by 0.9\\\\% for Mobile NASNet-A and 0.6\\\\% forInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make iteasy for practitioners to replace ReLUs with Swish units in any neural network.',\n",
       "  'categories': ['cs.NE', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '517',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.05941v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=665017396840630897&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 380: {'ID': 380,\n",
       "  'title': 'Gated Feedback Recurrent Neural Networks',\n",
       "  'authors': ['Kyunghyun Cho',\n",
       "   'Caglar Gulcehre',\n",
       "   'Junyoung Chung',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2015-02-09T05:25:54Z',\n",
       "  'updated': '2015-06-17T06:26:21Z',\n",
       "  'abstract': 'In this work, we propose a novel recurrent neural network (RNN) architecture.The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach ofstacking multiple recurrent layers by allowing and controlling signals flowingfrom upper recurrent layers to lower layers using a global gating unit for eachpair of layers. The recurrent signals exchanged between layers are gatedadaptively based on the previous hidden states and the current input. Weevaluated the proposed GF-RNN with different types of recurrent units, such astanh, long short-term memory and gated recurrent units, on the tasks ofcharacter-level language modeling and Python program evaluation. Our empiricalevaluation of different RNN units, revealed that in both tasks, the GF-RNNoutperforms the conventional approaches to build deep stacked RNNs. We suggestthat the improvement arises because the GF-RNN can adaptively assign differentlayers to different timescales and layer-to-layer interactions (including thetop-down ones which are not usually present in a stacked RNN) by learning togate these interactions.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 2067-2075',\n",
       "  'citations': '553',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02367v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9646941875979474208&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 381: {'ID': 381,\n",
       "  'title': 'Learning Representations from EEG with Deep Recurrent-Convolutional  Neural Networks',\n",
       "  'authors': ['Noel Codella',\n",
       "   'Mohammed Yeasin',\n",
       "   'Pouya Bashivan',\n",
       "   'Irina Rish'],\n",
       "  'published': '2015-11-19T23:29:55Z',\n",
       "  'updated': '2016-02-29T21:33:45Z',\n",
       "  'abstract': 'One of the challenges in modeling cognitive events from electroencephalogram(EEG) data is finding representations that are invariant to inter- andintra-subject differences, as well as to inherent noise associated with suchdata. Herein, we propose a novel approach for learning such representationsfrom multi-channel EEG time-series, and demonstrate its advantages in thecontext of mental load classification task. First, we transform EEG activitiesinto a sequence of topology-preserving multi-spectral images, as opposed tostandard EEG analysis techniques that ignore such spatial information. Next, wetrain a deep recurrent-convolutional network inspired by state-of-the-art videoclassification to learn robust representations from the sequence of images. Theproposed approach is designed to preserve the spatial, spectral, and temporalstructure of EEG which leads to finding features that are less sensitive tovariations and distortions within each dimension. Empirical evaluation on thecognitive load classification task demonstrated significant improvements inclassification accuracy over current state-of-the-art approaches in this field.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '343',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06448v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4319242413507858773&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 382: {'ID': 382,\n",
       "  'title': 'Representation Learning on Graphs with Jumping Knowledge Networks',\n",
       "  'authors': ['Tomohiro Sonobe',\n",
       "   'Yonglong Tian',\n",
       "   'Ken-ichi Kawarabayashi',\n",
       "   'Chengtao Li',\n",
       "   'Keyulu Xu',\n",
       "   'Stefanie Jegelka'],\n",
       "  'published': '2018-06-09T19:49:57Z',\n",
       "  'updated': '2018-06-25T19:52:28Z',\n",
       "  'abstract': 'Recent deep learning approaches for representation learning on graphs followa neighborhood aggregation procedure. We analyze some important properties ofthese models, and propose a strategy to overcome those. In particular, therange of \"neighboring\" nodes that a node\\'s representation draws from stronglydepends on the graph structure, analogous to the spread of a random walk. Toadapt to local neighborhood properties and tasks, we explore an architecture --jumping knowledge (JK) networks -- that flexibly leverages, for each node,different neighborhood ranges to enable better structure-aware representation.In a number of experiments on social, bioinformatics and citation networks, wedemonstrate that our model achieves state-of-the-art performance. Furthermore,combining the JK framework with models like Graph Convolutional Networks,GraphSAGE and Graph Attention Networks consistently improves those models\\'performance.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICML, 5449-5458',\n",
       "  'citations': '181',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.03536v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12324071567307935777&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 383: {'ID': 383,\n",
       "  'title': 'A General Analysis of the Convergence of ADMM',\n",
       "  'authors': ['Andrew Packard',\n",
       "   'Benjamin Recht',\n",
       "   'Michael I. Jordan',\n",
       "   'Laurent Lessard',\n",
       "   'Robert Nishihara'],\n",
       "  'published': '2015-02-06T20:01:58Z',\n",
       "  'updated': '2015-05-19T03:20:51Z',\n",
       "  'abstract': 'We provide a new proof of the linear convergence of the alternating directionmethod of multipliers (ADMM) when one of the objective terms is stronglyconvex. Our proof is based on a framework for analyzing optimization algorithmsintroduced in Lessard et al. (2014), reducing algorithm convergence toverifying the stability of a dynamical system. This approach generalizes anumber of existing results and obviates any assumptions about specific choicesof algorithm parameters. On a numerical example, we demonstrate that minimizingthe derived bound on the convergence rate provides a practical approach toselecting algorithm parameters for particular ADMM instances. We complement ourupper bound by constructing a nearly-matching lower bound on the worst-caserate of convergence.',\n",
       "  'categories': ['math.OC', 'cs.NA'],\n",
       "  'journal': 'ICML, 343-352',\n",
       "  'citations': '176',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02009v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9935674567319083530&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 384: {'ID': 384,\n",
       "  'title': 'Diffusion-Convolutional Neural Networks',\n",
       "  'authors': ['James Atwood', 'Don Towsley'],\n",
       "  'published': '2015-11-06T16:09:32Z',\n",
       "  'updated': '2016-07-08T15:05:17Z',\n",
       "  'abstract': 'We present diffusion-convolutional neural networks (DCNNs), a new model forgraph-structured data. Through the introduction of a diffusion-convolutionoperation, we show how diffusion-based representations can be learned fromgraph-structured data and used as an effective basis for node classification.DCNNs have several attractive qualities, including a latent representation forgraphical data that is invariant under isomorphism, as well as polynomial-timeprediction and learning that can be represented as tensor operations andefficiently implemented on the GPU. Through several experiments with realstructured datasets, we demonstrate that DCNNs are able to outperformprobabilistic relational models and kernel-on-graph methods at relational nodeclassification tasks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '418',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.02136v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17241458867032154450&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 385: {'ID': 385,\n",
       "  'title': 'Safe and Efficient Off-Policy Reinforcement Learning',\n",
       "  'authors': ['Anna Harutyunyan',\n",
       "   'Rémi Munos',\n",
       "   'Marc G. Bellemare',\n",
       "   'Tom Stepleton'],\n",
       "  'published': '2016-06-08T17:34:13Z',\n",
       "  'updated': '2016-11-07T21:26:31Z',\n",
       "  'abstract': 'In this work, we take a fresh look at some old and new algorithms foroff-policy, return-based reinforcement learning. Expressing these in a commonform, we derive a novel algorithm, Retrace($\\\\lambda$), with three desiredproperties: (1) it has low variance; (2) it safely uses samples collected fromany behaviour policy, whatever its degree of \"off-policyness\"; and (3) it isefficient as it makes the best use of samples collected from near on-policybehaviour policies. We analyze the contractive nature of the related operatorunder both off-policy policy evaluation and control settings and derive onlinesample-based algorithms. We believe this is the first return-based off-policycontrol algorithm converging a.s. to $Q^*$ without the GLIE assumption (Greedyin the Limit with Infinite Exploration). As a corollary, we prove theconvergence of Watkins\\' Q($\\\\lambda$), which was an open problem since 1989. Weillustrate the benefits of Retrace($\\\\lambda$) on a standard suite of Atari 2600games.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '278',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.02647v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10236232618386583112&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 386: {'ID': 386,\n",
       "  'title': 'Generative Adversarial Text to Image Synthesis',\n",
       "  'authors': ['Xinchen Yan',\n",
       "   'Scott Reed',\n",
       "   'Zeynep Akata',\n",
       "   'Lajanugen Logeswaran',\n",
       "   'Honglak Lee',\n",
       "   'Bernt Schiele'],\n",
       "  'published': '2016-05-17T23:09:15Z',\n",
       "  'updated': '2016-06-05T13:39:27Z',\n",
       "  'abstract': 'Automatic synthesis of realistic images from text would be interesting anduseful, but current AI systems are still far from this goal. However, in recentyears generic and powerful recurrent neural network architectures have beendeveloped to learn discriminative text feature representations. Meanwhile, deepconvolutional generative adversarial networks (GANs) have begun to generatehighly compelling images of specific categories, such as faces, album covers,and room interiors. In this work, we develop a novel deep architecture and GANformulation to effectively bridge these advances in text and image model- ing,translating visual concepts from characters to pixels. We demonstrate thecapability of our model to generate plausible images of birds and flowers fromdetailed text descriptions.',\n",
       "  'categories': ['cs.NE', 'cs.CV'],\n",
       "  'journal': 'ICML, 1060-1069',\n",
       "  'citations': '1528',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.05396v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8255440757806230750&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 387: {'ID': 387,\n",
       "  'title': 'Learning to Discover Cross-Domain Relations with Generative Adversarial  Networks',\n",
       "  'authors': ['Jung Kwon Lee',\n",
       "   'Taeksoo Kim',\n",
       "   'Jiwon Kim',\n",
       "   'Hyunsoo Kim',\n",
       "   'Moonsu Cha'],\n",
       "  'published': '2017-03-15T14:53:15Z',\n",
       "  'updated': '2017-05-15T05:04:38Z',\n",
       "  'abstract': 'While humans easily recognize relations between data from different domainswithout any supervision, learning to automatically discover them is in generalvery challenging and needs many ground-truth pairs that illustrate therelations. To avoid costly pairing, we address the task of discoveringcross-domain relations given unpaired data. We propose a method based ongenerative adversarial networks that learns to discover relations betweendifferent domains (DiscoGAN). Using the discovered relations, our proposednetwork successfully transfers style from one domain to another whilepreserving key attributes such as orientation and face identity. Source codefor official implementation is publicly availablehttps://github.com/SKTBrain/DiscoGAN',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 1857-1865',\n",
       "  'citations': '908',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.05192v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=463778412690777341&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 388: {'ID': 388,\n",
       "  'title': 'Junction Tree Variational Autoencoder for Molecular Graph Generation',\n",
       "  'authors': ['Wengong Jin', 'Regina Barzilay', 'Tommi Jaakkola'],\n",
       "  'published': '2018-02-12T21:19:39Z',\n",
       "  'updated': '2019-03-29T14:44:43Z',\n",
       "  'abstract': 'We seek to automate the design of molecules based on specific chemicalproperties. In computational terms, this task involves continuous embedding andgeneration of molecular graphs. Our primary contribution is the directrealization of molecular graphs, a task previously approached by generatinglinear SMILES strings instead of graphs. Our junction tree variationalautoencoder generates molecular graphs in two phases, by first generating atree-structured scaffold over chemical substructures, and then combining theminto a molecule with a graph message passing network. This approach allows usto incrementally expand molecules while maintaining chemical validity at everystep. We evaluate our model on multiple tasks ranging from molecular generationto optimization. Across these tasks, our model outperforms previousstate-of-the-art baselines by a significant margin.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 2328-2337',\n",
       "  'citations': '220',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.04364v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14713480171095443338&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 389: {'ID': 389,\n",
       "  'title': 'Action-Conditional Video Prediction using Deep Networks in Atari Games',\n",
       "  'authors': ['Junhyuk Oh',\n",
       "   'Richard Lewis',\n",
       "   'Xiaoxiao Guo',\n",
       "   'Honglak Lee',\n",
       "   'Satinder Singh'],\n",
       "  'published': '2015-07-31T04:43:30Z',\n",
       "  'updated': '2015-12-22T04:26:54Z',\n",
       "  'abstract': 'Motivated by vision-based reinforcement learning (RL) problems, in particularAtari games from the recent benchmark Aracade Learning Environment (ALE), weconsider spatio-temporal prediction problems where future (image-)frames aredependent on control variables or actions as well as previous frames. While notcomposed of natural scenes, frames in Atari games are high-dimensional in size,can involve tens of objects with one or more objects being controlled by theactions directly and many other objects being influenced indirectly, caninvolve entry and departure of objects, and can involve deep partialobservability. We propose and evaluate two deep neural network architecturesthat consist of encoding, action-conditional transformation, and decodinglayers based on convolutional neural networks and recurrent neural networks.Experimental results show that the proposed architectures are able to generatevisually-realistic frames that are also useful for control over approximately100-step action-conditional futures in some games. To the best of ourknowledge, this paper is the first to make and evaluate long-term predictionson high-dimensional video conditioned by control inputs.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '559',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.08750v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7752998563568486920&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 390: {'ID': 390,\n",
       "  'title': 'PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric  Space',\n",
       "  'authors': ['Li Yi', 'Charles R. Qi', 'Leonidas J. Guibas', 'Hao Su'],\n",
       "  'published': '2017-06-07T23:37:44Z',\n",
       "  'updated': '2017-06-07T23:37:44Z',\n",
       "  'abstract': 'Few prior works study deep learning on point sets. PointNet by Qi et al. is apioneer in this direction. However, by design PointNet does not capture localstructures induced by the metric space points live in, limiting its ability torecognize fine-grained patterns and generalizability to complex scenes. In thiswork, we introduce a hierarchical neural network that applies PointNetrecursively on a nested partitioning of the input point set. By exploitingmetric space distances, our network is able to learn local features withincreasing contextual scales. With further observation that point sets areusually sampled with varying densities, which results in greatly decreasedperformance for networks trained on uniform densities, we propose novel setlearning layers to adaptively combine features from multiple scales.Experiments show that our network called PointNet++ is able to learn deep pointset features efficiently and robustly. In particular, results significantlybetter than state-of-the-art have been obtained on challenging benchmarks of 3Dpoint clouds.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1458',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02413v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12360107934915291237&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 391: {'ID': 391,\n",
       "  'title': 'Measuring Catastrophic Forgetting in Neural Networks',\n",
       "  'authors': ['Tyler Hayes',\n",
       "   'Ronald Kemker',\n",
       "   'Angelina Abitino',\n",
       "   'Christopher Kanan',\n",
       "   'Marc McClure'],\n",
       "  'published': '2017-08-07T11:18:43Z',\n",
       "  'updated': '2017-11-09T14:53:07Z',\n",
       "  'abstract': 'Deep neural networks are used in many state-of-the-art systems for machineperception. Once a network is trained to do a specific task, e.g., birdclassification, it cannot easily be trained to do new tasks, e.g.,incrementally learning to recognize additional bird species or learning anentirely different task such as flower recognition. When new tasks are added,typical deep neural networks are prone to catastrophically forgetting previoustasks. Networks that are capable of assimilating new information incrementally,much like how humans form new memories over time, will be more efficient thanre-training the model from scratch each time a new task needs to be learned.There have been multiple attempts to develop schemes that mitigate catastrophicforgetting, but these methods have not been directly compared, the tests usedto evaluate them vary considerably, and these methods have only been evaluatedon small-scale problems (e.g., MNIST). In this paper, we introduce new metricsand benchmarks for directly comparing five different mechanisms designed tomitigate catastrophic forgetting in neural networks: regularization,ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments onreal-world images and sounds show that the mechanism(s) that are critical foroptimal performance vary based on the incremental training paradigm and type ofdata being used, but they all demonstrate that the catastrophic forgettingproblem has yet to be solved.',\n",
       "  'categories': ['cs.AI', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '139',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.02072v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1358572155151187767&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 392: {'ID': 392,\n",
       "  'title': 'Learning Important Features Through Propagating Activation Differences',\n",
       "  'authors': ['Peyton Greenside', 'Anshul Kundaje', 'Avanti Shrikumar'],\n",
       "  'published': '2017-04-10T02:23:57Z',\n",
       "  'updated': '2019-10-12T22:13:28Z',\n",
       "  'abstract': 'The purported \"black box\" nature of neural networks is a barrier to adoptionin applications where interpretability is essential. Here we present DeepLIFT(Deep Learning Important FeaTures), a method for decomposing the outputprediction of a neural network on a specific input by backpropagating thecontributions of all neurons in the network to every feature of the input.DeepLIFT compares the activation of each neuron to its \\'reference activation\\'and assigns contribution scores according to the difference. By optionallygiving separate consideration to positive and negative contributions, DeepLIFTcan also reveal dependencies which are missed by other approaches. Scores canbe computed efficiently in a single backward pass. We apply DeepLIFT to modelstrained on MNIST and simulated genomic data, and show significant advantagesover gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides:bit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code:http://goo.gl/RM8jvH.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 3145-3153',\n",
       "  'citations': '605',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.02685v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3870608604214378324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 393: {'ID': 393,\n",
       "  'title': 'Asymmetric Tri-training for Unsupervised Domain Adaptation',\n",
       "  'authors': ['Kuniaki Saito', 'Tatsuya Harada', 'Yoshitaka Ushiku'],\n",
       "  'published': '2017-02-27T17:48:17Z',\n",
       "  'updated': '2017-05-13T05:44:03Z',\n",
       "  'abstract': 'Deep-layered models trained on a large number of labeled samples boost theaccuracy of many tasks. It is important to apply such models to differentdomains because collecting many labeled samples in various domains isexpensive. In unsupervised domain adaptation, one needs to train a classifierthat works well on a target domain when provided with labeled source samplesand unlabeled target samples. Although many methods aim to match thedistributions of source and target samples, simply matching the distributioncannot ensure accuracy on the target domain. To learn discriminativerepresentations for the target domain, we assume that artificially labelingtarget samples can result in a good representation. Tri-training leveragesthree classifiers equally to give pseudo-labels to unlabeled samples, but themethod does not assume labeling samples generated from a different domain.Inthis paper, we propose an asymmetric tri-training method for unsuperviseddomain adaptation, where we assign pseudo-labels to unlabeled samples and trainneural networks as if they are true labels. In our work, we use three networksasymmetrically. By asymmetric, we mean that two networks are used to labelunlabeled target samples and one network is trained by the samples to obtaintarget-discriminative representations. We evaluate our method on digitrecognition and sentiment analysis datasets. Our proposed method achievesstate-of-the-art performance on the benchmark digit recognition datasets ofdomain adaptation.',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'journal': 'ICML, 2988-2997',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.08400v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4676245797797796956&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 394: {'ID': 394,\n",
       "  'title': 'Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks',\n",
       "  'authors': ['Christopher Morris',\n",
       "   'Jan Eric Lenssen',\n",
       "   'Gaurav Rattan',\n",
       "   'Martin Ritzert',\n",
       "   'William L. Hamilton',\n",
       "   'Martin Grohe',\n",
       "   'Matthias Fey'],\n",
       "  'published': '2018-10-04T14:31:57Z',\n",
       "  'updated': '2020-02-14T15:55:24Z',\n",
       "  'abstract': 'In recent years, graph neural networks (GNNs) have emerged as a powerfulneural architecture to learn vector representations of nodes and graphs in asupervised, end-to-end fashion. Up to now, GNNs have only been evaluatedempirically---showing promising results. The following work investigates GNNsfrom a theoretical point of view and relates them to the $1$-dimensionalWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs havethe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based onthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs($k$-GNNs), which can take higher-order graph structures at multiple scalesinto account. These higher-order structures play an essential role in thecharacterization of social networks and molecule graphs. Our experimentalevaluation confirms our theoretical findings as well as confirms thathigher-order information is useful in the task of graph classification andregression.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the AAAI Conference on Artificial Intelligence 33, 4602-4609',\n",
       "  'citations': '132',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.02244v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13309831317058857316&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 395: {'ID': 395,\n",
       "  'title': 'Video Pixel Networks',\n",
       "  'authors': ['Nal Kalchbrenner',\n",
       "   'Aaron van den Oord',\n",
       "   'Alex Graves',\n",
       "   'Karen Simonyan',\n",
       "   'Oriol Vinyals',\n",
       "   'Ivo Danihelka',\n",
       "   'Koray Kavukcuoglu'],\n",
       "  'published': '2016-10-03T13:06:40Z',\n",
       "  'updated': '2016-10-03T13:06:40Z',\n",
       "  'abstract': 'We propose a probabilistic video model, the Video Pixel Network (VPN), thatestimates the discrete joint distribution of the raw pixel values in a video.The model and the neural architecture reflect the time, space and colorstructure of video tensors and encode it as a four-dimensional dependencychain. The VPN approaches the best possible performance on the Moving MNISTbenchmark, a leap over the previous state of the art, and the generated videosshow only minor deviations from the ground truth. The VPN also producesdetailed samples on the action-conditional Robotic Pushing benchmark andgeneralizes to the motion of novel objects.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICML, 1771-1779',\n",
       "  'citations': '233',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.00527v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7561856894820666460&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 396: {'ID': 396,\n",
       "  'title': 'Grammar as a Foreign Language',\n",
       "  'authors': ['Geoffrey Hinton',\n",
       "   'Oriol Vinyals',\n",
       "   'Ilya Sutskever',\n",
       "   'Terry Koo',\n",
       "   'Slav Petrov',\n",
       "   'Lukasz Kaiser'],\n",
       "  'published': '2014-12-23T17:16:24Z',\n",
       "  'updated': '2015-06-09T22:41:07Z',\n",
       "  'abstract': 'Syntactic constituency parsing is a fundamental problem in natural languageprocessing and has been the subject of intensive research and engineering fordecades. As a result, the most accurate parsers are domain specific, complex,and inefficient. In this paper we show that the domain agnosticattention-enhanced sequence-to-sequence model achieves state-of-the-art resultson the most widely used syntactic constituency parsing dataset, when trained ona large synthetic corpus that was annotated using existing parsers. It alsomatches the performance of standard parsers when trained only on a smallhuman-annotated dataset, which shows that this model is highly data-efficient,in contrast to sequence-to-sequence models without the attention mechanism. Ourparser is also fast, processing over a hundred sentences per second with anunoptimized CPU implementation.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '781',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.7449v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12237083531601847428&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 397: {'ID': 397,\n",
       "  'title': 'Evaluating the visualization of what a Deep Neural Network has learned',\n",
       "  'authors': ['Sebastian Bach',\n",
       "   'Grégoire Montavon',\n",
       "   'Klaus-Robert Müller',\n",
       "   'Wojciech Samek',\n",
       "   'Alexander Binder'],\n",
       "  'published': '2015-09-21T17:36:22Z',\n",
       "  'updated': '2015-09-21T17:36:22Z',\n",
       "  'abstract': \"Deep Neural Networks (DNNs) have demonstrated impressive performance incomplex machine learning tasks such as image classification or speechrecognition. However, due to their multi-layer nonlinear structure, they arenot transparent, i.e., it is hard to grasp what makes them arrive at aparticular classification or recognition decision given a new unseen datasample. Recently, several approaches have been proposed enabling one tounderstand and interpret the reasoning embodied in a DNN for a single testimage. These methods quantify the ''importance'' of individual pixels wrt theclassification decision and allow a visualization in terms of a heatmap inpixel/input space. While the usefulness of heatmaps can be judged subjectivelyby a human, an objective quality measure is missing. In this paper we present ageneral methodology based on region perturbation for evaluating orderedcollections of pixels such as heatmaps. We compare heatmaps computed by threedifferent methods on the SUN397, ILSVRC2012 and MIT Places data sets. Our mainresult is that the recently proposed Layer-wise Relevance Propagation (LRP)algorithm qualitatively and quantitatively provides a better explanation ofwhat made a DNN arrive at a particular classification decision than thesensitivity-based approach or the deconvolution method. We provide theoreticalarguments to explain this result and discuss its practical implications.Finally, we investigate the use of heatmaps for unsupervised assessment ofneural network performance.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 28 (11), 2660-2673',\n",
       "  'citations': '351',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.06321v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7349251395468541741&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 398: {'ID': 398,\n",
       "  'title': 'Enhancing The Reliability of Out-of-distribution Image Detection in  Neural Networks',\n",
       "  'authors': ['R. Srikant', 'Shiyu Liang', 'Yixuan Li'],\n",
       "  'published': '2017-06-08T17:43:56Z',\n",
       "  'updated': '2020-08-30T16:50:36Z',\n",
       "  'abstract': 'We consider the problem of detecting out-of-distribution images in neuralnetworks. We propose ODIN, a simple and effective method that does not requireany change to a pre-trained neural network. Our method is based on theobservation that using temperature scaling and adding small perturbations tothe input can separate the softmax score distributions between in- andout-of-distribution images, allowing for more effective detection. We show in aseries of experiments that ODIN is compatible with diverse networkarchitectures and datasets. It consistently outperforms the baseline approachby a large margin, establishing a new state-of-the-art performance on thistask. For example, ODIN reduces the false positive rate from the baseline 34.7%to 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is95%.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '238',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02690v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7536099354022278878&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 399: {'ID': 399,\n",
       "  'title': 'Generating Images with Perceptual Similarity Metrics based on Deep  Networks',\n",
       "  'authors': ['Alexey Dosovitskiy', 'Thomas Brox'],\n",
       "  'published': '2016-02-08T16:50:28Z',\n",
       "  'updated': '2016-02-09T09:36:36Z',\n",
       "  'abstract': 'Image-generating machine learning models are typically trained with lossfunctions based on distance in the image space. This often leads toover-smoothed results. We propose a class of loss functions, which we call deepperceptual similarity metrics (DeePSiM), that mitigate this problem. Instead ofcomputing distances in the image space, we compute distances between imagefeatures extracted by deep neural networks. This metric better reflectsperceptually similarity of images and thus leads to better results. We showthree applications: autoencoder training, a modification of a variationalautoencoder, and inversion of deep convolutional networks. In all cases, thegenerated images look sharp and resemble natural images.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '585',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02644v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1915913556489044934&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 400: {'ID': 400,\n",
       "  'title': 'A simple neural network module for relational reasoning',\n",
       "  'authors': ['David G. T. Barrett',\n",
       "   'Razvan Pascanu',\n",
       "   'Peter Battaglia',\n",
       "   'Timothy Lillicrap',\n",
       "   'Adam Santoro',\n",
       "   'Mateusz Malinowski',\n",
       "   'David Raposo'],\n",
       "  'published': '2017-06-05T17:17:18Z',\n",
       "  'updated': '2017-06-05T17:17:18Z',\n",
       "  'abstract': 'Relational reasoning is a central component of generally intelligentbehavior, but has proven difficult for neural networks to learn. In this paperwe describe how to use Relation Networks (RNs) as a simple plug-and-play moduleto solve problems that fundamentally hinge on relational reasoning. We testedRN-augmented networks on three tasks: visual question answering using achallenging dataset called CLEVR, on which we achieve state-of-the-art,super-human performance; text-based question answering using the bAbI suite oftasks; and complex reasoning about dynamic physical systems. Then, using acurated dataset called Sort-of-CLEVR we show that powerful convolutionalnetworks do not have a general capacity to solve relational questions, but cangain this capacity when augmented with RNs. Our work shows how a deep learningarchitecture equipped with an RN module can implicitly discover and learn toreason about entities and their relations.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '699',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.01427v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7624683168776555686&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 401: {'ID': 401,\n",
       "  'title': 'VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning  Problem',\n",
       "  'authors': ['Niki Trigoni',\n",
       "   'Ronald Clark',\n",
       "   'Hongkai Wen',\n",
       "   'Andrew Markham',\n",
       "   'Sen Wang'],\n",
       "  'published': '2017-01-29T13:34:22Z',\n",
       "  'updated': '2017-04-02T17:11:53Z',\n",
       "  'abstract': 'In this paper we present an on-manifold sequence-to-sequence learningapproach to motion estimation using visual and inertial sensors. It is to thebest of our knowledge the first end-to-end trainable method for visual-inertialodometry which performs fusion of the data at an intermediatefeature-representation level. Our method has numerous advantages overtraditional approaches. Specifically, it eliminates the need for tedious manualsynchronization of the camera and IMU as well as eliminating the need formanual calibration between the IMU and camera. A further advantage is that ourmodel naturally and elegantly incorporates domain specific information whichsignificantly mitigates drift. We show that our approach is competitive withstate-of-the-art traditional methods when accurate calibration data isavailable and can be trained to outperform them in the presence of calibrationand synchronization errors.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '145',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1701.08376v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7432089327423732629&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 402: {'ID': 402,\n",
       "  'title': 'Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk  Minimization',\n",
       "  'authors': ['Lin Xiao', 'Yuchen Zhang'],\n",
       "  'published': '2014-09-10T21:25:22Z',\n",
       "  'updated': '2015-09-09T05:37:23Z',\n",
       "  'abstract': 'We consider a generic convex optimization problem associated with regularizedempirical risk minimization of linear predictors. The problem structure allowsus to reformulate it as a convex-concave saddle point problem. We propose astochastic primal-dual coordinate (SPDC) method, which alternates betweenmaximizing over a randomly chosen dual variable and minimizing over the primalvariable. An extrapolation step on the primal variable is performed to obtainaccelerated convergence rate. We also develop a mini-batch version of the SPDCmethod which facilitates parallel computing, and an extension with weightedsampling probabilities on the dual variables, which has a better complexitythan uniform sampling on unnormalized data. Both theoretically and empirically,we show that the SPDC method has comparable or better performance than severalstate-of-the-art optimization methods.',\n",
       "  'categories': ['math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 353-361',\n",
       "  'citations': '184',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1409.3257v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14588707342837179622&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 403: {'ID': 403,\n",
       "  'title': 'Unsupervised Learning of Disentangled Representations from Video',\n",
       "  'authors': ['Emily Denton', 'Vighnesh Birodkar'],\n",
       "  'published': '2017-05-31T02:12:19Z',\n",
       "  'updated': '2017-05-31T02:12:19Z',\n",
       "  'abstract': 'We present a new model DrNET that learns disentangled image representationsfrom video. Our approach leverages the temporal coherence of video and a noveladversarial loss to learn a representation that factorizes each frame into astationary part and a temporally varying component. The disentangledrepresentation can be used for a range of tasks. For example, applying astandard LSTM to the time-vary components enables prediction of future frames.We evaluate our approach on a range of synthetic and real videos, demonstratingthe ability to coherently generate hundreds of steps into the future.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '253',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10915v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9768655920777432327&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 404: {'ID': 404,\n",
       "  'title': 'Dynamic Memory Networks for Visual and Textual Question Answering',\n",
       "  'authors': ['Richard Socher', 'Caiming Xiong', 'Stephen Merity'],\n",
       "  'published': '2016-03-04T10:40:28Z',\n",
       "  'updated': '2016-03-04T10:40:28Z',\n",
       "  'abstract': 'Neural network architectures with memory and attention mechanisms exhibitcertain reasoning capabilities required for question answering. One sucharchitecture, the dynamic memory network (DMN), obtained high accuracy on avariety of language tasks. However, it was not shown whether the architectureachieves strong results for question answering when supporting facts are notmarked during training or whether it could be applied to other modalities suchas images. Based on an analysis of the DMN, we propose several improvements toits memory and input modules. Together with these changes we introduce a novelinput module for images in order to be able to answer visual questions. Our newDMN+ model improves the state of the art on both the Visual Question Answeringdataset and the \\\\babi-10k text question-answering dataset without supportingfact supervision.',\n",
       "  'categories': ['cs.NE', 'cs.CL', 'cs.CV'],\n",
       "  'journal': 'ICML, 2397-2406',\n",
       "  'citations': '512',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.01417v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8393808929765185624&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 405: {'ID': 405,\n",
       "  'title': 'Language Modeling with Gated Convolutional Networks',\n",
       "  'authors': ['Angela Fan',\n",
       "   'Michael Auli',\n",
       "   'Yann N. Dauphin',\n",
       "   'David Grangier'],\n",
       "  'published': '2016-12-23T20:32:33Z',\n",
       "  'updated': '2017-09-08T22:26:49Z',\n",
       "  'abstract': 'The pre-dominant approach to language modeling to date is based on recurrentneural networks. Their success on this task is often linked to their ability tocapture unbounded context. In this paper we develop a finite context approachthrough stacked convolutions, which can be more efficient since they allowparallelization over sequential tokens. We propose a novel simplified gatingmechanism that outperforms Oord et al (2016) and investigate the impact of keyarchitectural decisions. The proposed approach achieves state-of-the-art on theWikiText-103 benchmark, even though it features long-term dependencies, as wellas competitive results on the Google Billion Words benchmark. Our model reducesthe latency to score a sentence by an order of magnitude compared to arecurrent baseline. To our knowledge, this is the first time a non-recurrentapproach is competitive with strong recurrent models on these large scalelanguage tasks.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICML, 933-941',\n",
       "  'citations': '733',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.08083v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15192587613931188105&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 406: {'ID': 406,\n",
       "  'title': 'One-Shot Imitation Learning',\n",
       "  'authors': ['Marcin Andrychowicz',\n",
       "   'Jonathan Ho',\n",
       "   'Jonas Schneider',\n",
       "   'Yan Duan',\n",
       "   'Ilya Sutskever',\n",
       "   'Bradly C. Stadie',\n",
       "   'Wojciech Zaremba',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-03-21T17:22:29Z',\n",
       "  'updated': '2017-12-04T21:53:23Z',\n",
       "  'abstract': 'Imitation learning has been commonly applied to solve different tasks inisolation. This usually requires either careful feature engineering, or asignificant number of samples. This is far from what we desire: ideally, robotsshould be able to learn from very few demonstrations of any given task, andinstantly generalize to new situations of the same task, without requiringtask-specific engineering. In this paper, we propose a meta-learning frameworkfor achieving such capability, which we call one-shot imitation learning.  Specifically, we consider the setting where there is a very large set oftasks, and each task has many instantiations. For example, a task could be tostack all blocks on a table into a single tower, another task could be to placeall blocks on a table into two-block towers, etc. In each case, differentinstances of the task would consist of different sets of blocks with differentinitial states. At training time, our algorithm is presented with pairs ofdemonstrations for a subset of all tasks. A neural net is trained that takes asinput one demonstration and the current state (which initially is the initialstate of the other demonstration of the pair), and outputs an action with thegoal that the resulting sequence of states and actions matches as closely aspossible with the second demonstration. At test time, a demonstration of asingle instance of a new task is presented, and the neural net is expected toperform well on new instances of this new task. The use of soft attentionallows the model to generalize to conditions and tasks unseen in the trainingdata. We anticipate that by training this model on a much greater variety oftasks and settings, we will obtain a general system that can turn anydemonstrations into robust policies that can accomplish an overwhelming varietyof tasks.  Videos available at https://bit.ly/nips2017-oneshot .',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.NE', 'cs.RO'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '329',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.07326v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3870865527815598360&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 407: {'ID': 407,\n",
       "  'title': 'Adversarial Feature Learning',\n",
       "  'authors': ['Philipp Krähenbühl', 'Trevor Darrell', 'Jeff Donahue'],\n",
       "  'published': '2016-05-31T19:37:29Z',\n",
       "  'updated': '2017-04-03T20:34:36Z',\n",
       "  'abstract': 'The ability of the Generative Adversarial Networks (GANs) framework to learngenerative models mapping from simple latent distributions to arbitrarilycomplex data distributions has been demonstrated empirically, with compellingresults showing that the latent space of such generators captures semanticvariation in the data distribution. Intuitively, models trained to predictthese semantic latent representations given data may serve as useful featurerepresentations for auxiliary problems where semantics are relevant. However,in their existing form, GANs have no means of learning the inverse mapping --projecting data back into the latent space. We propose Bidirectional GenerativeAdversarial Networks (BiGANs) as a means of learning this inverse mapping, anddemonstrate that the resulting learned feature representation is useful forauxiliary supervised discrimination tasks, competitive with contemporaryapproaches to unsupervised and self-supervised feature learning.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '845',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.09782v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10661655492543733137&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 408: {'ID': 408,\n",
       "  'title': 'Towards better understanding of gradient-based attribution methods for  Deep Neural Networks',\n",
       "  'authors': ['Cengiz Öztireli',\n",
       "   'Enea Ceolini',\n",
       "   'Markus Gross',\n",
       "   'Marco Ancona'],\n",
       "  'published': '2017-11-16T14:19:29Z',\n",
       "  'updated': '2018-03-07T10:49:28Z',\n",
       "  'abstract': 'Understanding the flow of information in Deep Neural Networks (DNNs) is achallenging problem that has gain increasing attention over the last few years.While several methods have been proposed to explain network predictions, therehave been only a few attempts to compare them from a theoretical perspective.What is more, no exhaustive empirical comparison has been performed in thepast. In this work, we analyze four gradient-based attribution methods andformally prove conditions of equivalence and approximation between them. Byreformulating two of these methods, we construct a unified framework whichenables a direct comparison, as well as an easier implementation. Finally, wepropose a novel evaluation metric, called Sensitivity-n and test thegradient-based attribution methods alongside with a simple perturbation-basedattribution method on several datasets in the domains of image and textclassification, using various network architectures.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '226',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.06104v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7129422820232184089&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 409: {'ID': 409,\n",
       "  'title': 'A Reductions Approach to Fair Classification',\n",
       "  'authors': ['Miroslav Dudík',\n",
       "   'John Langford',\n",
       "   'Alekh Agarwal',\n",
       "   'Alina Beygelzimer',\n",
       "   'Hanna Wallach'],\n",
       "  'published': '2018-03-06T22:39:58Z',\n",
       "  'updated': '2018-07-16T15:06:37Z',\n",
       "  'abstract': 'We present a systematic approach for achieving fairness in a binaryclassification setting. While we focus on two well-known quantitativedefinitions of fairness, our approach encompasses many other previously studieddefinitions as special cases. The key idea is to reduce fair classification toa sequence of cost-sensitive classification problems, whose solutions yield arandomized classifier with the lowest (empirical) error subject to the desiredconstraints. We introduce two reductions that work for any representation ofthe cost-sensitive classifier and compare favorably to prior baselines on avariety of data sets, while overcoming several of their disadvantages.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 60-69',\n",
       "  'citations': '213',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.02453v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16870675827052455946&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 410: {'ID': 410,\n",
       "  'title': 'DARTS: Differentiable Architecture Search',\n",
       "  'authors': ['Yiming Yang', 'Karen Simonyan', 'Hanxiao Liu'],\n",
       "  'published': '2018-06-24T00:06:13Z',\n",
       "  'updated': '2019-04-23T06:29:32Z',\n",
       "  'abstract': 'This paper addresses the scalability challenge of architecture search byformulating the task in a differentiable manner. Unlike conventional approachesof applying evolution or reinforcement learning over a discrete andnon-differentiable search space, our method is based on the continuousrelaxation of the architecture representation, allowing efficient search of thearchitecture using gradient descent. Extensive experiments on CIFAR-10,ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels indiscovering high-performance convolutional architectures for imageclassification and recurrent architectures for language modeling, while beingorders of magnitude faster than state-of-the-art non-differentiable techniques.Our implementation has been made publicly available to facilitate furtherresearch on efficient architecture search algorithms.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '681',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.09055v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=895422516420751823&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 411: {'ID': 411,\n",
       "  'title': 'Regularized Evolution for Image Classifier Architecture Search',\n",
       "  'authors': ['Esteban Real', 'Quoc V Le', 'Alok Aggarwal', 'Yanping Huang'],\n",
       "  'published': '2018-02-05T18:20:52Z',\n",
       "  'updated': '2019-02-16T23:28:16Z',\n",
       "  'abstract': 'The effort devoted to hand-crafting neural network image classifiers hasmotivated the use of architecture search to discover them automatically.Although evolutionary algorithms have been repeatedly applied to neural networktopologies, the image classifiers thus discovered have remained inferior tohuman-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---thatsurpasses hand-designs for the first time. To do this, we modify the tournamentselection evolutionary algorithm by introducing an age property to favor theyounger genotypes. Matching size, AmoebaNet-A has comparable accuracy tocurrent state-of-the-art ImageNet models discovered with more complexarchitecture-search methods. Scaled to larger size, AmoebaNet-A sets a newstate-of-the-art 83.9% / 96.6% top-5 ImageNet accuracy. In a controlledcomparison against a well known reinforcement learning algorithm, we giveevidence that evolution can obtain results faster with the same hardware,especially at the earlier stages of the search. This is relevant when fewercompute resources are available. Evolution is, thus, a simple method toeffectively discover high-quality architectures.',\n",
       "  'categories': ['cs.NE', 'cs.AI', 'cs.CV', 'cs.DC', 'I.2.6; I.5.1; I.5.2'],\n",
       "  'journal': 'Proceedings of the AAAI Conference on Artificial Intelligence 33, 4780-4789',\n",
       "  'citations': '632',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.01548v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6463563114710686585&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 412: {'ID': 412,\n",
       "  'title': 'Conditional Adversarial Domain Adaptation',\n",
       "  'authors': ['Jianmin Wang',\n",
       "   'Zhangjie Cao',\n",
       "   'Mingsheng Long',\n",
       "   'Michael I. Jordan'],\n",
       "  'published': '2017-05-26T00:50:36Z',\n",
       "  'updated': '2018-12-29T16:43:57Z',\n",
       "  'abstract': 'Adversarial learning has been embedded into deep networks to learndisentangled and transferable representations for domain adaptation. Existingadversarial domain adaptation methods may not effectively align differentdomains of multimodal distributions native in classification problems. In thispaper, we present conditional adversarial domain adaptation, a principledframework that conditions the adversarial adaptation models on discriminativeinformation conveyed in the classifier predictions. Conditional domainadversarial networks (CDANs) are designed with two novel conditioningstrategies: multilinear conditioning that captures the cross-covariance betweenfeature representations and classifier predictions to improve thediscriminability, and entropy conditioning that controls the uncertainty ofclassifier predictions to guarantee the transferability. With theoreticalguarantees and a few lines of codes, the approach has exceeded state-of-the-artresults on five datasets.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '215',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10667v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=951003799487024572&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 413: {'ID': 413,\n",
       "  'title': 'Mode Regularized Generative Adversarial Networks',\n",
       "  'authors': ['Yanran Li',\n",
       "   'Athul Paul Jacob',\n",
       "   'Tong Che',\n",
       "   'Yoshua Bengio',\n",
       "   'Wenjie Li'],\n",
       "  'published': '2016-12-07T07:45:38Z',\n",
       "  'updated': '2017-03-02T06:28:13Z',\n",
       "  'abstract': 'Although Generative Adversarial Networks achieve state-of-the-art results ona variety of generative tasks, they are regarded as highly unstable and proneto miss modes. We argue that these bad behaviors of GANs are due to the veryparticular functional shape of the trained discriminators in high dimensionalspaces, which can easily make training stuck or push probability mass in thewrong direction, towards that of higher concentration than that of the datagenerating distribution. We introduce several ways of regularizing theobjective, which can dramatically stabilize the training of GAN models. We alsoshow that our regularizers can help the fair distribution of probability massacross the modes of the data generating distribution, during the early phasesof training and thus providing a unified solution to the missing modes problem.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '277',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.02136v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8235362476181771248&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 414: {'ID': 414,\n",
       "  'title': 'Recovery Guarantees for One-hidden-layer Neural Networks',\n",
       "  'authors': ['Kai Zhong',\n",
       "   'Inderjit S. Dhillon',\n",
       "   'Prateek Jain',\n",
       "   'Zhao Song',\n",
       "   'Peter L. Bartlett'],\n",
       "  'published': '2017-06-10T02:56:39Z',\n",
       "  'updated': '2017-06-10T02:56:39Z',\n",
       "  'abstract': 'In this paper, we consider regression problems with one-hidden-layer neuralnetworks (1NNs). We distill some properties of activation functions that leadto $\\\\mathit{local~strong~convexity}$ in the neighborhood of the ground-truthparameters for the 1NN squared-loss objective. Most popular nonlinearactivation functions satisfy the distilled properties, including rectifiedlinear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activationfunctions that are also smooth, we show $\\\\mathit{local~linear~convergence}$guarantees of gradient descent under a resampling rule. For homogeneousactivations, we show tensor methods are able to initialize the parameters tofall into the local strong convexity region. As a result, tensor initializationfollowed by gradient descent is guaranteed to recover the ground truth withsample complexity $ d \\\\cdot \\\\log(1/\\\\epsilon) \\\\cdot \\\\mathrm{poly}(k,\\\\lambda )$and computational complexity $n\\\\cdot d \\\\cdot \\\\mathrm{poly}(k,\\\\lambda) $ forsmooth homogeneous activations with high probability, where $d$ is thedimension of the input, $k$ ($k\\\\leq d$) is the number of hidden nodes,$\\\\lambda$ is a conditioning property of the ground-truth parameter matrixbetween the input layer and the hidden layer, $\\\\epsilon$ is the targetedprecision and $n$ is the number of samples. To the best of our knowledge, thisis the first work that provides recovery guarantees for 1NNs with both samplecomplexity and computational complexity $\\\\mathit{linear}$ in the inputdimension and $\\\\mathit{logarithmic}$ in the precision.',\n",
       "  'categories': ['cs.LG', 'cs.DS', 'stat.ML'],\n",
       "  'journal': 'ICML, 4140-4149',\n",
       "  'citations': '173',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.03175v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11965390343759936388&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 415: {'ID': 415,\n",
       "  'title': 'Grammar Variational Autoencoder',\n",
       "  'authors': ['José Miguel Hernández-Lobato',\n",
       "   'Matt J. Kusner',\n",
       "   'Brooks Paige'],\n",
       "  'published': '2017-03-06T15:36:37Z',\n",
       "  'updated': '2017-03-06T15:36:37Z',\n",
       "  'abstract': 'Deep generative models have been wildly successful at learning coherentlatent representations for continuous data such as video and audio. However,generative modeling of discrete data such as arithmetic expressions andmolecular structures still poses significant challenges. Crucially,state-of-the-art methods often produce outputs that are not valid. We make thekey observation that frequently, discrete data can be represented as a parsetree from a context-free grammar. We propose a variational autoencoder whichencodes and decodes directly to and from these parse trees, ensuring thegenerated outputs are always valid. Surprisingly, we show that not only doesour model more often generate valid outputs, it also learns a more coherentlatent space in which nearby points decode to similar discrete outputs. Wedemonstrate the effectiveness of our learned models by showing their improvedperformance in Bayesian optimization for symbolic regression and molecularsynthesis.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'ICML, 1945-1954',\n",
       "  'citations': '243',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01925v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4080460899049502885&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 416: {'ID': 416,\n",
       "  'title': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding',\n",
       "  'authors': ['Ruslan Salakhutdinov',\n",
       "   'Zhilin Yang',\n",
       "   'Yiming Yang',\n",
       "   'Zihang Dai',\n",
       "   'Jaime Carbonell',\n",
       "   'Quoc V. Le'],\n",
       "  'published': '2019-06-19T17:35:48Z',\n",
       "  'updated': '2020-01-02T12:48:08Z',\n",
       "  'abstract': 'With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, undercomparable experiment settings, XLNet outperforms BERT on 20 tasks, often by alarge margin, including question answering, natural language inference,sentiment analysis, and document ranking.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'NeurIPS, 5754-5764',\n",
       "  'citations': '855',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.08237v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14487406216105917109&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 417: {'ID': 417,\n",
       "  'title': 'Neural Machine Translation with Reconstruction',\n",
       "  'authors': ['Zhaopeng Tu',\n",
       "   'Xiaohua Liu',\n",
       "   'Hang Li',\n",
       "   'Yang Liu',\n",
       "   'Lifeng Shang'],\n",
       "  'published': '2016-11-07T02:03:55Z',\n",
       "  'updated': '2016-11-21T09:47:22Z',\n",
       "  'abstract': 'Although end-to-end Neural Machine Translation (NMT) has achieved remarkableprogress in the past two years, it suffers from a major drawback: translationsgenerated by NMT systems often lack of adequacy. It has been widely observedthat NMT tends to repeatedly translate some source words while mistakenlyignoring other words. To alleviate this problem, we propose a novelencoder-decoder-reconstructor framework for NMT. The reconstructor,incorporated into the NMT model, manages to reconstruct the input sourcesentence from the hidden layer of the output target sentence, to ensure thatthe information in the source side is transformed to the target side as much aspossible. Experiments show that the proposed framework significantly improvesthe adequacy of NMT output and achieves superior translation result overstate-of-the-art NMT and statistical MT systems.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '129',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01874v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1310099558617172101&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 418: {'ID': 418,\n",
       "  'title': 'Curiosity-driven Exploration by Self-supervised Prediction',\n",
       "  'authors': ['Pulkit Agrawal',\n",
       "   'Trevor Darrell',\n",
       "   'Alexei A. Efros',\n",
       "   'Deepak Pathak'],\n",
       "  'published': '2017-05-15T17:56:22Z',\n",
       "  'updated': '2017-05-15T17:56:22Z',\n",
       "  'abstract': \"In many real-world scenarios, rewards extrinsic to the agent are extremelysparse, or absent altogether. In such cases, curiosity can serve as anintrinsic reward signal to enable the agent to explore its environment andlearn skills that might be useful later in its life. We formulate curiosity asthe error in an agent's ability to predict the consequence of its own actionsin a visual feature space learned by a self-supervised inverse dynamics model.Our formulation scales to high-dimensional continuous state spaces like images,bypasses the difficulties of directly predicting pixels, and, critically,ignores the aspects of the environment that cannot affect the agent. Theproposed approach is evaluated in two environments: VizDoom and Super MarioBros. Three broad settings are investigated: 1) sparse extrinsic reward, wherecuriosity allows for far fewer interactions with the environment to reach thegoal; 2) exploration with no extrinsic reward, where curiosity pushes the agentto explore more efficiently; and 3) generalization to unseen scenarios (e.g.new levels of the same game) where the knowledge gained from earlier experiencehelps the agent explore new places much faster than starting from scratch. Demovideo and code available at https://pathak22.github.io/noreward-rl/\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.RO', 'stat.ML'],\n",
       "  'journal': 'ICML, 2778-2787',\n",
       "  'citations': '678',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.05363v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9379743003299559904&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 419: {'ID': 419,\n",
       "  'title': 'Gradient Descent Provably Optimizes Over-parameterized Neural Networks',\n",
       "  'authors': ['Aarti Singh', 'Xiyu Zhai', 'Simon S. Du', 'Barnabas Poczos'],\n",
       "  'published': '2018-10-04T04:47:47Z',\n",
       "  'updated': '2019-02-05T01:59:59Z',\n",
       "  'abstract': 'One of the mysteries in the success of neural networks is randomlyinitialized first order methods like gradient descent can achieve zero trainingloss even though the objective function is non-convex and non-smooth. Thispaper demystifies this surprising phenomenon for two-layer fully connected ReLUactivated neural networks. For an $m$ hidden node shallow neural network withReLU activation and $n$ training data, we show as long as $m$ is large enoughand no two inputs are parallel, randomly initialized gradient descent convergesto a globally optimal solution at a linear convergence rate for the quadraticloss function.  Our analysis relies on the following observation: over-parameterization andrandom initialization jointly restrict every weight vector to be close to itsinitialization for all iterations, which allows us to exploit a strongconvexity-like property to show that gradient descent converges at a globallinear rate to the global optimum. We believe these insights are also useful inanalyzing deep models and other first order methods.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '279',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.02054v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8128763459913409987&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 420: {'ID': 420,\n",
       "  'title': 'Neural Machine Translation by Jointly Learning to Align and Translate',\n",
       "  'authors': ['Kyunghyun Cho', 'Dzmitry Bahdanau', 'Yoshua Bengio'],\n",
       "  'published': '2014-09-01T16:33:02Z',\n",
       "  'updated': '2016-05-19T21:53:22Z',\n",
       "  'abstract': 'Neural machine translation is a recently proposed approach to machinetranslation. Unlike the traditional statistical machine translation, the neuralmachine translation aims at building a single neural network that can bejointly tuned to maximize the translation performance. The models proposedrecently for neural machine translation often belong to a family ofencoder-decoders and consists of an encoder that encodes a source sentence intoa fixed-length vector from which a decoder generates a translation. In thispaper, we conjecture that the use of a fixed-length vector is a bottleneck inimproving the performance of this basic encoder-decoder architecture, andpropose to extend this by allowing a model to automatically (soft-)search forparts of a source sentence that are relevant to predicting a target word,without having to form these parts as a hard segment explicitly. With this newapproach, we achieve a translation performance comparable to the existingstate-of-the-art phrase-based system on the task of English-to-Frenchtranslation. Furthermore, qualitative analysis reveals that the(soft-)alignments found by the model agree well with our intuition.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '13000',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1409.0473v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9430221802571417838&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 421: {'ID': 421,\n",
       "  'title': 'Generating Wikipedia by Summarizing Long Sequences',\n",
       "  'authors': ['Mohammad Saleh',\n",
       "   'Noam Shazeer',\n",
       "   'Ben Goodrich',\n",
       "   'Peter J. Liu',\n",
       "   'Lukasz Kaiser',\n",
       "   'Etienne Pot',\n",
       "   'Ryan Sepassi'],\n",
       "  'published': '2018-01-30T20:07:01Z',\n",
       "  'updated': '2018-01-30T20:07:01Z',\n",
       "  'abstract': 'We show that generating English Wikipedia articles can be approached as amulti- document summarization of source documents. We use extractivesummarization to coarsely identify salient information and a neural abstractivemodel to generate the article. For the abstractive model, we introduce adecoder-only architecture that can scalably attend to very long sequences, muchlonger than typical encoder- decoder architectures used in sequencetransduction. We show that this model can generate fluent, coherentmulti-sentence paragraphs and even whole Wikipedia articles. When givenreference documents, we show it can extract relevant factual information asreflected in perplexity, ROUGE scores and human evaluations.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '212',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.10198v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9480555348664414627&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 422: {'ID': 422,\n",
       "  'title': 'Adversarial Feature Selection against Evasion Attacks',\n",
       "  'authors': ['Battista Biggio',\n",
       "   'Patrick P. K. Chan',\n",
       "   'Daniel S. Yeung',\n",
       "   'Fei Zhang',\n",
       "   'Fabio Roli'],\n",
       "  'published': '2020-05-25T15:05:51Z',\n",
       "  'updated': '2020-05-25T15:05:51Z',\n",
       "  'abstract': \"Pattern recognition and machine learning techniques have been increasinglyadopted in adversarial settings such as spam, intrusion and malware detection,although their security against well-crafted attacks that aim to evadedetection by manipulating data at test time has not yet been thoroughlyassessed. While previous work has been mainly focused on devisingadversary-aware classification algorithms to counter evasion attempts, only fewauthors have considered the impact of using reduced feature sets on classifiersecurity against the same attacks. An interesting, preliminary result is thatclassifier security to evasion may be even worsened by the application offeature selection. In this paper, we provide a more detailed investigation ofthis aspect, shedding some light on the security properties of featureselection against evasion attacks. Inspired by previous work on adversary-awareclassifiers, we propose a novel adversary-aware feature selection model thatcan improve classifier security against evasion attacks, by incorporatingspecific assumptions on the adversary's data manipulation strategy. We focus onan efficient, wrapper-based implementation of our approach, and experimentallyvalidate its soundness on different application examples, including spam andmalware detection.\",\n",
       "  'categories': ['cs.LG', 'cs.CR', 'stat.ML'],\n",
       "  'journal': 'IEEE Transactions on Cybernetics 46 (3), 766-777',\n",
       "  'citations': '141',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.12154v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1282505468086475104&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 423: {'ID': 423,\n",
       "  'title': 'Unitary Evolution Recurrent Neural Networks',\n",
       "  'authors': ['Amar Shah', 'Martin Arjovsky', 'Yoshua Bengio'],\n",
       "  'published': '2015-11-20T00:37:33Z',\n",
       "  'updated': '2016-05-25T23:34:38Z',\n",
       "  'abstract': 'Recurrent neural networks (RNNs) are notoriously difficult to train. When theeigenvalues of the hidden to hidden weight matrix deviate from absolute value1, optimization becomes difficult due to the well studied issue of vanishingand exploding gradients, especially when trying to learn long-termdependencies. To circumvent this problem, we propose a new architecture thatlearns a unitary weight matrix, with eigenvalues of absolute value exactly 1.The challenge we address is that of parametrizing unitary matrices in a waythat does not require expensive computations (such as eigendecomposition) aftereach weight update. We construct an expressive unitary weight matrix bycomposing several structured matrices that act as building blocks withparameters to be learned. Optimization with this parameterization becomesfeasible only when considering hidden states in the complex domain. Wedemonstrate the potential of this architecture by achieving state of the artresults in several hard tasks involving very long-term dependencies.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 1120-1128',\n",
       "  'citations': '352',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06464v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5030720785335451277&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 424: {'ID': 424,\n",
       "  'title': 'Realistic Evaluation of Deep Semi-Supervised Learning Algorithms',\n",
       "  'authors': ['Avital Oliver',\n",
       "   'Colin Raffel',\n",
       "   'Ian J. Goodfellow',\n",
       "   'Augustus Odena',\n",
       "   'Ekin D. Cubuk'],\n",
       "  'published': '2018-04-24T17:54:44Z',\n",
       "  'updated': '2019-06-17T11:48:53Z',\n",
       "  'abstract': 'Semi-supervised learning (SSL) provides a powerful framework for leveragingunlabeled data when labels are limited or expensive to obtain. SSL algorithmsbased on deep neural networks have recently proven successful on standardbenchmark tasks. However, we argue that these benchmarks fail to address manyissues that these algorithms would face in real-world applications. Aftercreating a unified reimplementation of various widely-used SSL techniques, wetest them in a suite of experiments designed to address these issues. We findthat the performance of simple baselines which do not use unlabeled data isoften underreported, that SSL methods differ in sensitivity to the amount oflabeled and unlabeled data, and that performance can degrade substantially whenthe unlabeled dataset contains out-of-class examples. To help guide SSLresearch towards real-world applicability, we make our unified reimplementionand evaluation platform publicly available.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '226',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.09170v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15456844754123849487&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 425: {'ID': 425,\n",
       "  'title': 'Unsupervised and Semi-supervised Learning with Categorical Generative  Adversarial Networks',\n",
       "  'authors': ['Jost Tobias Springenberg'],\n",
       "  'published': '2015-11-19T21:26:58Z',\n",
       "  'updated': '2016-04-30T21:23:46Z',\n",
       "  'abstract': 'In this paper we present a method for learning a discriminative classifierfrom unlabeled or partially labeled data. Our approach is based on an objectivefunction that trades-off mutual information between observed examples and theirpredicted categorical class distribution, against robustness of the classifierto an adversarial generative model. The resulting algorithm can either beinterpreted as a natural generalization of the generative adversarial networks(GAN) framework or as an extension of the regularized information maximization(RIM) framework to robust classification against an optimal adversary. Weempirically evaluate our method - which we dub categorical generativeadversarial networks (or CatGAN) - on synthetic data as well as on challengingimage classification tasks, demonstrating the robustness of the learnedclassifiers. We further qualitatively assess the fidelity of samples generatedby the adversarial generator that is learned alongside the discriminativeclassifier, and identify links between the CatGAN objective and discriminativeclustering algorithms (such as RIM).',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '465',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06390v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3077106609105382524&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 426: {'ID': 426,\n",
       "  'title': 'End-to-end Optimized Image Compression',\n",
       "  'authors': ['Johannes Ballé', 'Eero P. Simoncelli', 'Valero Laparra'],\n",
       "  'published': '2016-11-05T21:39:53Z',\n",
       "  'updated': '2017-03-03T14:53:13Z',\n",
       "  'abstract': 'We describe an image compression method, consisting of a nonlinear analysistransformation, a uniform quantizer, and a nonlinear synthesis transformation.The transforms are constructed in three successive stages of convolutionallinear filters and nonlinear activation functions. Unlike most convolutionalneural networks, the joint nonlinearity is chosen to implement a form of localgain control, inspired by those used to model biological neurons. Using avariant of stochastic gradient descent, we jointly optimize the entire modelfor rate-distortion performance over a database of training images, introducinga continuous proxy for the discontinuous loss function arising from thequantizer. Under certain conditions, the relaxed loss function may beinterpreted as the log likelihood of a generative model, as implemented by avariational autoencoder. Unlike these models, however, the compression modelmust operate at any given point along the rate-distortion curve, as specifiedby a trade-off parameter. Across an independent set of test images, we findthat the optimized method generally exhibits better rate-distortion performancethan the standard JPEG and JPEG 2000 compression methods. More importantly, weobserve a dramatic improvement in visual quality for all images at all bitrates, which is supported by objective quality estimates using MS-SSIM.',\n",
       "  'categories': ['cs.CV', 'cs.IT', 'math.IT'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '354',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01704v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1152338433659809765&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 427: {'ID': 427,\n",
       "  'title': 'Hierarchical Question-Image Co-Attention for Visual Question Answering',\n",
       "  'authors': ['Jiasen Lu', 'Dhruv Batra', 'Jianwei Yang', 'Devi Parikh'],\n",
       "  'published': '2016-05-31T22:02:01Z',\n",
       "  'updated': '2017-01-19T05:03:33Z',\n",
       "  'abstract': 'A number of recent works have proposed attention models for Visual QuestionAnswering (VQA) that generate spatial maps highlighting image regions relevantto answering the question. In this paper, we argue that in addition to modeling\"where to look\" or visual attention, it is equally important to model \"whatwords to listen to\" or question attention. We present a novel co-attentionmodel for VQA that jointly reasons about image and question attention. Inaddition, our model reasons about the question (and consequently the image viathe co-attention mechanism) in a hierarchical fashion via a novel 1-dimensionalconvolution neural networks (CNN). Our model improves the state-of-the-art onthe VQA dataset from 60.3% to 60.5%, and from 61.6% to 63.3% on the COCO-QAdataset. By using ResNet, the performance is further improved to 62.1% for VQAand 65.4% for COCO-QA.',\n",
       "  'categories': ['cs.CV', 'cs.CL'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '744',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.00061v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15146345852176060026&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 428: {'ID': 428,\n",
       "  'title': 'What Uncertainties Do We Need in Bayesian Deep Learning for Computer  Vision?',\n",
       "  'authors': ['Yarin Gal', 'Alex Kendall'],\n",
       "  'published': '2017-03-15T07:27:12Z',\n",
       "  'updated': '2017-10-05T13:04:51Z',\n",
       "  'abstract': 'There are two major types of uncertainty one can model. Aleatoric uncertaintycaptures noise inherent in the observations. On the other hand, epistemicuncertainty accounts for uncertainty in the model -- uncertainty which can beexplained away given enough data. Traditionally it has been difficult to modelepistemic uncertainty in computer vision, but with new Bayesian deep learningtools this is now possible. We study the benefits of modeling epistemic vs.aleatoric uncertainty in Bayesian deep learning models for vision tasks. Forthis we present a Bayesian deep learning framework combining input-dependentaleatoric uncertainty together with epistemic uncertainty. We study modelsunder the framework with per-pixel semantic segmentation and depth regressiontasks. Further, our explicit uncertainty formulation leads to new lossfunctions for these tasks, which can be interpreted as learned attenuation.This makes the loss more robust to noisy data, also giving new state-of-the-artresults on segmentation and depth regression benchmarks.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '960',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.04977v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6063636260641358531&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 429: {'ID': 429,\n",
       "  'title': 'Deep Voice: Real-time Neural Text-to-Speech',\n",
       "  'authors': ['Andrew Ng',\n",
       "   'Yongguo Kang',\n",
       "   'Sercan O. Arik',\n",
       "   'Mike Chrzanowski',\n",
       "   'Jonathan Raiman',\n",
       "   'John Miller',\n",
       "   'Mohammad Shoeybi',\n",
       "   'Xian Li',\n",
       "   'Andrew Gibiansky',\n",
       "   'Gregory Diamos',\n",
       "   'Shubho Sengupta',\n",
       "   'Adam Coates'],\n",
       "  'published': '2017-02-25T03:11:04Z',\n",
       "  'updated': '2017-03-07T23:09:23Z',\n",
       "  'abstract': 'We present Deep Voice, a production-quality text-to-speech system constructedentirely from deep neural networks. Deep Voice lays the groundwork for trulyend-to-end neural speech synthesis. The system comprises five major buildingblocks: a segmentation model for locating phoneme boundaries, agrapheme-to-phoneme conversion model, a phoneme duration prediction model, afundamental frequency prediction model, and an audio synthesis model. For thesegmentation model, we propose a novel way of performing phoneme boundarydetection with deep neural networks using connectionist temporal classification(CTC) loss. For the audio synthesis model, we implement a variant of WaveNetthat requires fewer parameters and trains faster than the original. By using aneural network for each component, our system is simpler and more flexible thantraditional text-to-speech systems, where each component requires laboriousfeature engineering and extensive domain expertise. Finally, we show thatinference with our system can be performed faster than real time and describeoptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400xspeedups over existing implementations.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.NE', 'cs.SD'],\n",
       "  'journal': 'ICML, 195-204',\n",
       "  'citations': '292',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.07825v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11354813425104850759&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 430: {'ID': 430,\n",
       "  'title': 'Deep Learning of Part-based Representation of Data Using Sparse  Autoencoders with Nonnegativity Constraints',\n",
       "  'authors': ['Olfa Nasraoui', 'Jacek M. Zurada', 'Ehsan Hosseini-Asl'],\n",
       "  'published': '2016-01-12T05:33:03Z',\n",
       "  'updated': '2016-01-12T05:33:03Z',\n",
       "  'abstract': 'We demonstrate a new deep learning autoencoder network, trained by anonnegativity constraint algorithm (NCAE), that learns features which showpart-based representation of data. The learning algorithm is based onconstraining negative weights. The performance of the algorithm is assessedbased on decomposing data into parts and its prediction performance is testedon three standard image data sets and one text dataset. The results indicatethat the nonnegativity constraint forces the autoencoder to learn features thatamount to a part-based representation of data, while improving sparsity andreconstruction quality in comparison with the traditional sparse autoencoderand Nonnegative Matrix Factorization. It is also shown that this newly acquiredrepresentation improves the prediction performance of a deep neural network.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 27 (12), 2486-2498',\n",
       "  'citations': '139',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1601.02733v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15650513078438307377&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 431: {'ID': 431,\n",
       "  'title': 'Improving zero-shot learning by mitigating the hubness problem',\n",
       "  'authors': ['Marco Baroni', 'Georgiana Dinu', 'Angeliki Lazaridou'],\n",
       "  'published': '2014-12-20T01:03:46Z',\n",
       "  'updated': '2015-04-15T13:10:07Z',\n",
       "  'abstract': 'The zero-shot paradigm exploits vector-based word representations extractedfrom text corpora with unsupervised methods to learn general mapping functionsfrom other feature spaces onto word space, where the words associated to thenearest neighbours of the mapped vectors are used as their linguistic labels.We show that the neighbourhoods of the mapped elements are strongly polluted byhubs, vectors that tend to be near a high proportion of items, pushing theircorrect labels down the neighbour list. After illustrating the problemempirically, we propose a simple method to correct it by taking the proximitydistribution of potential neighbours across many mapped vectors into account.We show that this correction leads to consistent improvements in realisticzero-shot experiments in the cross-lingual, image labeling and image retrievaldomains.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '249',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6568v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4810137765860435505&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 432: {'ID': 432,\n",
       "  'title': 'Net2Net: Accelerating Learning via Knowledge Transfer',\n",
       "  'authors': ['Tianqi Chen', 'Ian Goodfellow', 'Jonathon Shlens'],\n",
       "  'published': '2015-11-18T02:09:20Z',\n",
       "  'updated': '2016-04-23T23:14:39Z',\n",
       "  'abstract': 'We introduce techniques for rapidly transferring the information stored inone neural net into another neural net. The main purpose is to accelerate thetraining of a significantly larger neural net. During real-world workflows, oneoften trains very many different neural networks during the experimentation anddesign process. This is a wasteful process in which each new model is trainedfrom scratch. Our Net2Net technique accelerates the experimentation process byinstantaneously transferring the knowledge from a previous network to each newdeeper or wider network. Our techniques are based on the concept offunction-preserving transformations between neural network specifications. Thisdiffers from previous approaches to pre-training that altered the functionrepresented by a neural net when adding layers to it. Using our knowledgetransfer mechanism to add depth to Inception modules, we demonstrate a newstate of the art accuracy rating on the ImageNet dataset.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '315',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05641v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2686528528183414981&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 433: {'ID': 433,\n",
       "  'title': 'Consensus of Hybrid Multi-agent Systems',\n",
       "  'authors': ['Long Wang', 'Yuanshi Zheng', 'Jingying Ma'],\n",
       "  'published': '2015-12-10T09:34:22Z',\n",
       "  'updated': '2015-12-10T09:34:22Z',\n",
       "  'abstract': 'In this paper, we consider the consensus problem of hybrid multi-agentsystem. First, the hybrid multi-agent system is proposed which is composed ofcontinuous-time and discrete-time dynamic agents. Then, three kinds ofconsensus protocols are presented for hybrid multi-agent system. The analysistool developed in this paper is based on the matrix theory and graph theory.With different restrictions of the sampling period, some necessary andsufficient conditions are established for solving the consensus of hybridmulti-agent system. The consensus states are also obtained under differentprotocols. Finally, simulation examples are provided to demonstrate theeffectiveness of our theoretical results.',\n",
       "  'categories': ['cs.SY'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (4), 1359-1365',\n",
       "  'citations': '169',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.03189v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5829776190810116561&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 434: {'ID': 434,\n",
       "  'title': 'A Learned Representation For Artistic Style',\n",
       "  'authors': ['Vincent Dumoulin', 'Manjunath Kudlur', 'Jonathon Shlens'],\n",
       "  'published': '2016-10-24T20:06:54Z',\n",
       "  'updated': '2017-02-09T16:29:09Z',\n",
       "  'abstract': 'The diversity of painting styles represents a rich visual vocabulary for theconstruction of an image. The degree to which one may learn and parsimoniouslycapture this visual vocabulary measures our understanding of the higher levelfeatures of paintings, if not images in general. In this work we investigatethe construction of a single, scalable deep network that can parsimoniouslycapture the artistic style of a diversity of paintings. We demonstrate thatsuch a network generalizes across a diversity of artistic styles by reducing apainting to a point in an embedding space. Importantly, this model permits auser to explore new painting styles by arbitrarily combining the styles learnedfrom individual paintings. We hope that this work provides a useful steptowards building rich models of paintings and offers a window on to thestructure of the learned representation of artistic style.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '424',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.07629v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7122040962029266183&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 435: {'ID': 435,\n",
       "  'title': 'Neural GPUs Learn Algorithms',\n",
       "  'authors': ['Ilya Sutskever', 'Łukasz Kaiser'],\n",
       "  'published': '2015-11-25T21:17:43Z',\n",
       "  'updated': '2016-03-15T00:20:54Z',\n",
       "  'abstract': 'Learning an algorithm from examples is a fundamental problem that has beenwidely studied. Recently it has been addressed using neural networks, inparticular by Neural Turing Machines (NTMs). These are fully differentiablecomputers that use backpropagation to learn their own programming. Despitetheir appeal NTMs have a weakness that is caused by their sequential nature:they are not parallel and are are hard to train due to their large depth whenunfolded.  We present a neural network architecture to address this problem: the NeuralGPU. It is based on a type of convolutional gated recurrent unit and, like theNTM, is computationally universal. Unlike the NTM, the Neural GPU is highlyparallel which makes it easier to train and efficient to run.  An essential property of algorithms is their ability to handle inputs ofarbitrary size. We show that the Neural GPU can be trained on short instancesof an algorithmic task and successfully generalize to long instances. Weverified it on a number of tasks including long addition and longmultiplication of numbers represented in binary. We train the Neural GPU onnumbers with upto 20 bits and observe no errors whatsoever while testing it,even on much longer numbers.  To achieve these results we introduce a technique for training deep recurrentnetworks: parameter sharing relaxation. We also found a small amount of dropoutand gradient noise to have a large positive effect on learning andgeneralization.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '215',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.08228v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16991695263235885456&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 436: {'ID': 436,\n",
       "  'title': 'Neural Discrete Representation Learning',\n",
       "  'authors': ['Oriol Vinyals', 'Koray Kavukcuoglu', 'Aaron van den Oord'],\n",
       "  'published': '2017-11-02T21:14:44Z',\n",
       "  'updated': '2018-05-30T14:58:27Z',\n",
       "  'abstract': 'Learning useful representations without supervision remains a key challengein machine learning. In this paper, we propose a simple yet powerful generativemodel that learns such discrete representations. Our model, the VectorQuantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways:the encoder network outputs discrete, rather than continuous, codes; and theprior is learnt rather than static. In order to learn a discrete latentrepresentation, we incorporate ideas from vector quantisation (VQ). Using theVQ method allows the model to circumvent issues of \"posterior collapse\" --where the latents are ignored when they are paired with a powerfulautoregressive decoder -- typically observed in the VAE framework. Pairingthese representations with an autoregressive prior, the model can generate highquality images, videos, and speech as well as doing high quality speakerconversion and unsupervised learning of phonemes, providing further evidence ofthe utility of the learnt representations.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '354',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00937v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9141153084529999933&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 437: {'ID': 437,\n",
       "  'title': 'The Concrete Distribution: A Continuous Relaxation of Discrete Random  Variables',\n",
       "  'authors': ['Andriy Mnih', 'Yee Whye Teh', 'Chris J. Maddison'],\n",
       "  'published': '2016-11-02T18:25:40Z',\n",
       "  'updated': '2017-03-05T16:59:44Z',\n",
       "  'abstract': 'The reparameterization trick enables optimizing large scale stochasticcomputation graphs via gradient descent. The essence of the trick is torefactor each stochastic node into a differentiable function of its parametersand a random variable with fixed distribution. After refactoring, the gradientsof the loss propagated by the chain rule through the graph are low varianceunbiased estimators of the gradients of the expected loss. While manycontinuous random variables have such reparameterizations, discrete randomvariables lack useful reparameterizations due to the discontinuous nature ofdiscrete states. In this work we introduce Concrete randomvariables---continuous relaxations of discrete random variables. The Concretedistribution is a new family of distributions with closed form densities and asimple reparameterization. Whenever a discrete stochastic node of a computationgraph can be refactored into a one-hot bit representation that is treatedcontinuously, Concrete stochastic nodes can be used with automaticdifferentiation to produce low-variance biased gradients of objectives(including objectives that depend on the log-probability of latent stochasticnodes) on the corresponding discrete graph. We demonstrate the effectiveness ofConcrete relaxations on density estimation and structured prediction tasksusing neural networks.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '846',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.00712v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16482228288411412158&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 438: {'ID': 438,\n",
       "  'title': 'Ladder Variational Autoencoders',\n",
       "  'authors': ['Lars Maaløe',\n",
       "   'Tapani Raiko',\n",
       "   'Casper Kaae Sønderby',\n",
       "   'Søren Kaae Sønderby',\n",
       "   'Ole Winther'],\n",
       "  'published': '2016-02-06T17:32:48Z',\n",
       "  'updated': '2016-05-27T09:05:10Z',\n",
       "  'abstract': 'Variational Autoencoders are powerful models for unsupervised learning.However deep models with several layers of dependent stochastic variables aredifficult to train which limits the improvements obtained using these highlyexpressive models. We propose a new inference model, the Ladder VariationalAutoencoder, that recursively corrects the generative distribution by a datadependent approximate likelihood in a process resembling the recently proposedLadder Network. We show that this model provides state of the art predictivelog-likelihood and tighter log-likelihood lower bound compared to the purelybottom-up inference in layered Variational Autoencoders and other generativemodels. We provide a detailed analysis of the learned hierarchical latentrepresentation and show that our new inference model is qualitatively differentand utilizes a deeper more distributed hierarchy of latent variables. Finally,we observe that batch normalization and deterministic warm-up (graduallyturning on the KL-term) are crucial for training variational models with manystochastic layers.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '337',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02282v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1323199474868567922&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 439: {'ID': 439,\n",
       "  'title': 'Count-Based Exploration with Neural Density Models',\n",
       "  'authors': ['Georg Ostrovski',\n",
       "   'Marc G. Bellemare',\n",
       "   'Remi Munos',\n",
       "   'Aaron van den Oord'],\n",
       "  'published': '2017-03-03T19:07:53Z',\n",
       "  'updated': '2017-06-14T13:56:28Z',\n",
       "  'abstract': \"Bellemare et al. (2016) introduced the notion of a pseudo-count, derived froma density model, to generalize count-based exploration to non-tabularreinforcement learning. This pseudo-count was used to generate an explorationbonus for a DQN agent and combined with a mixed Monte Carlo update wassufficient to achieve state of the art on the Atari 2600 game Montezuma'sRevenge. We consider two questions left open by their work: First, howimportant is the quality of the density model for exploration? Second, whatrole does the Monte Carlo update play in exploration? We answer the firstquestion by demonstrating the use of PixelCNN, an advanced neural density modelfor images, to supply a pseudo-count. In particular, we examine the intrinsicdifficulties in adapting Bellemare et al.'s approach when assumptions about themodel are violated. The result is a more practical and general algorithmrequiring no special apparatus. We combine PixelCNN pseudo-counts withdifferent agent architectures to dramatically improve the state of the art onseveral hard Atari games. One surprising finding is that the mixed Monte Carloupdate is a powerful facilitator of exploration in the sparsest of settings,including Montezuma's Revenge.\",\n",
       "  'categories': ['cs.AI'],\n",
       "  'journal': 'ICML, 2721-2730',\n",
       "  'citations': '219',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01310v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7236095966352642924&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 440: {'ID': 440,\n",
       "  'title': 'Unsupervised Image-to-Image Translation Networks',\n",
       "  'authors': ['Thomas Breuel', 'Ming-Yu Liu', 'Jan Kautz'],\n",
       "  'published': '2017-03-02T16:29:30Z',\n",
       "  'updated': '2018-07-23T03:39:28Z',\n",
       "  'abstract': 'Unsupervised image-to-image translation aims at learning a joint distributionof images in different domains by using images from the marginal distributionsin individual domains. Since there exists an infinite set of jointdistributions that can arrive the given marginal distributions, one could infernothing about the joint distribution from the marginal distributions withoutadditional assumptions. To address the problem, we make a shared-latent spaceassumption and propose an unsupervised image-to-image translation frameworkbased on Coupled GANs. We compare the proposed framework with competingapproaches and present high quality image translation results on variouschallenging unsupervised image translation tasks, including street scene imagetranslation, animal image translation, and face image translation. We alsoapply the proposed framework to domain adaptation and achieve state-of-the-artperformance on benchmark datasets. Code and additional results are available inhttps://github.com/mingyuliutw/unit .',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1057',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00848v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14169741715291172305&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 441: {'ID': 441,\n",
       "  'title': 'Simple and Scalable Predictive Uncertainty Estimation using Deep  Ensembles',\n",
       "  'authors': ['Balaji Lakshminarayanan',\n",
       "   'Charles Blundell',\n",
       "   'Alexander Pritzel'],\n",
       "  'published': '2016-12-05T18:54:43Z',\n",
       "  'updated': '2017-11-04T01:33:43Z',\n",
       "  'abstract': 'Deep neural networks (NNs) are powerful black box predictors that haverecently achieved impressive performance on a wide spectrum of tasks.Quantifying predictive uncertainty in NNs is a challenging and yet unsolvedproblem. Bayesian NNs, which learn a distribution over weights, are currentlythe state-of-the-art for estimating predictive uncertainty; however theserequire significant modifications to the training procedure and arecomputationally expensive compared to standard (non-Bayesian) NNs. We proposean alternative to Bayesian NNs that is simple to implement, readilyparallelizable, requires very little hyperparameter tuning, and yields highquality predictive uncertainty estimates. Through a series of experiments onclassification and regression benchmarks, we demonstrate that our methodproduces well-calibrated uncertainty estimates which are as good or better thanapproximate Bayesian NNs. To assess robustness to dataset shift, we evaluatethe predictive uncertainty on test examples from known and unknowndistributions, and show that our method is able to express higher uncertaintyon out-of-distribution examples. We demonstrate the scalability of our methodby evaluating predictive uncertainty estimates on ImageNet.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '732',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.01474v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15810892316109997085&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 442: {'ID': 442,\n",
       "  'title': 'GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash  Equilibrium',\n",
       "  'authors': ['Martin Heusel',\n",
       "   'Sepp Hochreiter',\n",
       "   'Bernhard Nessler',\n",
       "   'Hubert Ramsauer',\n",
       "   'Thomas Unterthiner'],\n",
       "  'published': '2017-06-26T17:45:23Z',\n",
       "  'updated': '2018-01-12T14:05:44Z',\n",
       "  'abstract': 'Generative Adversarial Networks (GANs) excel at creating realistic imageswith complex models for which maximum likelihood is infeasible. However, theconvergence of GAN training has still not been proved. We propose a twotime-scale update rule (TTUR) for training GANs with stochastic gradientdescent on arbitrary GAN loss functions. TTUR has an individual learning ratefor both the discriminator and the generator. Using the theory of stochasticapproximation, we prove that the TTUR converges under mild assumptions to astationary local Nash equilibrium. The convergence carries over to the popularAdam optimization, for which we prove that it follows the dynamics of a heavyball with friction and thus prefers flat minima in the objective landscape. Forthe evaluation of the performance of GANs at image generation, we introduce the\"Fr\\\\\\'echet Inception Distance\" (FID) which captures the similarity of generatedimages to real ones better than the Inception Score. In experiments, TTURimproves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUNBedrooms, and the One Billion Word Benchmark.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1554',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.08500v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15143899073250151317&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 443: {'ID': 443,\n",
       "  'title': 'SampleRNN: An Unconditional End-to-End Neural Audio Generation Model',\n",
       "  'authors': ['Shubham Jain',\n",
       "   'Aaron Courville',\n",
       "   'Kundan Kumar',\n",
       "   'Rithesh Kumar',\n",
       "   'Soroush Mehri',\n",
       "   'Jose Sotelo',\n",
       "   'Yoshua Bengio',\n",
       "   'Ishaan Gulrajani'],\n",
       "  'published': '2016-12-22T23:28:47Z',\n",
       "  'updated': '2017-02-11T20:04:46Z',\n",
       "  'abstract': 'In this paper we propose a novel model for unconditional audio generationbased on generating one audio sample at a time. We show that our model, whichprofits from combining memory-less modules, namely autoregressive multilayerperceptrons, and stateful recurrent neural networks in a hierarchical structureis able to capture underlying sources of variations in the temporal sequencesover very long time spans, on three datasets of different nature. Humanevaluation on the generated samples indicate that our model is preferred overcompeting models. We also show how each component of the model contributes tothe exhibited performance.',\n",
       "  'categories': ['cs.SD', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '292',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.07837v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18296195672519025121&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 444: {'ID': 444,\n",
       "  'title': 'Emotional Chatting Machine: Emotional Conversation Generation with  Internal and External Memory',\n",
       "  'authors': ['Minlie Huang',\n",
       "   'Xiaoyan Zhu',\n",
       "   'Tianyang Zhang',\n",
       "   'Hao Zhou',\n",
       "   'Bing Liu'],\n",
       "  'published': '2017-04-04T15:44:48Z',\n",
       "  'updated': '2018-06-01T03:38:59Z',\n",
       "  'abstract': 'Perception and expression of emotion are key factors to the success ofdialogue systems or conversational agents. However, this problem has not beenstudied in large-scale conversation generation so far. In this paper, wepropose Emotional Chatting Machine (ECM) that can generate appropriateresponses not only in content (relevant and grammatical) but also in emotion(emotionally consistent). To the best of our knowledge, this is the first workthat addresses the emotion factor in large-scale conversation generation. ECMaddresses the factor using three new mechanisms that respectively (1) modelsthe high-level abstraction of emotion expressions by embedding emotioncategories, (2) captures the change of implicit internal emotion states, and(3) uses explicit emotion expressions with an external emotion vocabulary.Experiments show that the proposed model can generate responses appropriate notonly in content but also in emotion.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '250',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.01074v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13075172936856719627&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 445: {'ID': 445,\n",
       "  'title': 'Efficient Architecture Search by Network Transformation',\n",
       "  'authors': ['Yong Yu',\n",
       "   'Weinan Zhang',\n",
       "   'Tianyao Chen',\n",
       "   'Han Cai',\n",
       "   'Jun Wang'],\n",
       "  'published': '2017-07-16T12:39:02Z',\n",
       "  'updated': '2017-11-21T08:38:04Z',\n",
       "  'abstract': 'Techniques for automatically designing deep neural network architectures suchas reinforcement learning based approaches have recently shown promisingresults. However, their success is based on vast computational resources (e.g.hundreds of GPUs), making them difficult to be widely used. A noticeablelimitation is that they still design and train each network from scratch duringthe exploration of the architecture space, which is highly inefficient. In thispaper, we propose a new framework toward efficient architecture search byexploring the architecture space based on the current network and reusing itsweights. We employ a reinforcement learning agent as the meta-controller, whoseaction is to grow the network depth or layer width with function-preservingtransformations. As such, the previously validated networks can be reused forfurther exploration, thus saves a large amount of computational cost. We applyour method to explore the architecture space of the plain convolutional neuralnetworks (no skip-connections, branching etc.) on image benchmark datasets(CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our methodcan design highly competitive networks that outperform existing networks usingthe same design scheme. On CIFAR-10, our model without skip-connectionsachieves 4.23\\\\% test error rate, exceeding a vast majority of modernarchitectures and approaching DenseNet. Furthermore, by applying our method toexplore the DenseNet architecture space, we are able to achieve more accuratenetworks with fewer parameters.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '195',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.04873v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2416480494986570854&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 446: {'ID': 446,\n",
       "  'title': 'Can Decentralized Algorithms Outperform Centralized Algorithms? A Case  Study for Decentralized Parallel Stochastic Gradient Descent',\n",
       "  'authors': ['Ce Zhang',\n",
       "   'Ji Liu',\n",
       "   'Huan Zhang',\n",
       "   'Cho-Jui Hsieh',\n",
       "   'Xiangru Lian',\n",
       "   'Wei Zhang'],\n",
       "  'published': '2017-05-25T05:58:17Z',\n",
       "  'updated': '2017-09-11T04:21:43Z',\n",
       "  'abstract': 'Most distributed machine learning systems nowadays, including TensorFlow andCNTK, are built in a centralized fashion. One bottleneck of centralizedalgorithms lies on high communication cost on the central node. Motivated bythis, we ask, can decentralized algorithms be faster than its centralizedcounterpart?  Although decentralized PSGD (D-PSGD) algorithms have been studied by thecontrol community, existing analysis and theory do not show any advantage overcentralized PSGD (C-PSGD) algorithms, simply assuming the application scenariowhere only the decentralized network is available. In this paper, we study aD-PSGD algorithm and provide the first theoretical analysis that indicates aregime in which decentralized algorithms might outperform centralizedalgorithms for distributed stochastic gradient descent. This is because D-PSGDhas comparable total computational complexities to C-PSGD but requires muchless communication cost on the busiest node. We further conduct an empiricalstudy to validate our theoretical analysis across multiple frameworks (CNTK andTorch), different network configurations, and computation platforms up to 112GPUs. On network configurations with low bandwidth or high latency, D-PSGD canbe up to one order of magnitude faster than its well-optimized centralizedcounterparts.',\n",
       "  'categories': ['math.OC', 'cs.DC', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '219',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.09056v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18334580252706636011&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 447: {'ID': 447,\n",
       "  'title': 'Deep Gradient Compression: Reducing the Communication Bandwidth for  Distributed Training',\n",
       "  'authors': ['William J. Dally',\n",
       "   'Yu Wang',\n",
       "   'Song Han',\n",
       "   'Huizi Mao',\n",
       "   'Yujun Lin'],\n",
       "  'published': '2017-12-05T19:48:11Z',\n",
       "  'updated': '2020-06-23T03:28:30Z',\n",
       "  'abstract': 'Large-scale distributed training requires significant communication bandwidthfor gradient exchange that limits the scalability of multi-node training, andrequires expensive high-bandwidth network infrastructure. The situation getseven worse with distributed training on mobile devices (federated learning),which suffers from higher latency, lower throughput, and intermittent poorconnections. In this paper, we find 99.9% of the gradient exchange indistributed SGD is redundant, and propose Deep Gradient Compression (DGC) togreatly reduce the communication bandwidth. To preserve accuracy duringcompression, DGC employs four methods: momentum correction, local gradientclipping, momentum factor masking, and warm-up training. We have applied DeepGradient Compression to image classification, speech recognition, and languagemodeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, andLibrispeech Corpus. On these scenarios, Deep Gradient Compression achieves agradient compression ratio from 270x to 600x without losing accuracy, cuttingthe gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from488MB to 0.74MB. Deep gradient compression enables large-scale distributedtraining on inexpensive commodity 1Gbps Ethernet and facilitates distributedtraining on mobile. Code is available at:https://github.com/synxlin/deep-gradient-compression.',\n",
       "  'categories': ['cs.CV', 'cs.DC', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '298',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.01887v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2485379403852124678&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 448: {'ID': 448,\n",
       "  'title': 'Bayesian Compression for Deep Learning',\n",
       "  'authors': ['Max Welling', 'Christos Louizos', 'Karen Ullrich'],\n",
       "  'published': '2017-05-24T09:07:01Z',\n",
       "  'updated': '2017-11-06T12:46:40Z',\n",
       "  'abstract': 'Compression and computational efficiency in deep learning have become aproblem of great significance. In this work, we argue that the most principledand effective way to attack this problem is by adopting a Bayesian point ofview, where through sparsity inducing priors we prune large parts of thenetwork. We introduce two novelties in this paper: 1) we use hierarchicalpriors to prune nodes instead of individual weights, and 2) we use theposterior uncertainties to determine the optimal fixed point precision toencode the weights. Both factors significantly contribute to achieving thestate of the art in terms of compression rates, while still staying competitivewith methods designed to optimize for speed or energy efficiency.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '232',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08665v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12642526032245768258&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 449: {'ID': 449,\n",
       "  'title': 'Mean teachers are better role models: Weight-averaged consistency  targets improve semi-supervised deep learning results',\n",
       "  'authors': ['Antti Tarvainen', 'Harri Valpola'],\n",
       "  'published': '2017-03-06T09:34:56Z',\n",
       "  'updated': '2018-04-16T10:39:11Z',\n",
       "  'abstract': 'The recently proposed Temporal Ensembling has achieved state-of-the-artresults in several semi-supervised learning benchmarks. It maintains anexponential moving average of label predictions on each training example, andpenalizes predictions that are inconsistent with this target. However, becausethe targets change only once per epoch, Temporal Ensembling becomes unwieldywhen learning large datasets. To overcome this problem, we propose MeanTeacher, a method that averages model weights instead of label predictions. Asan additional benefit, Mean Teacher improves test accuracy and enables trainingwith fewer labels than Temporal Ensembling. Without changing the networkarchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250labels, outperforming Temporal Ensembling trained with 1000 labels. We alsoshow that a good network architecture is crucial to performance. Combining MeanTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labelsfrom 35.24% to 9.11%.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '480',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.01780v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3256042804843589088&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 450: {'ID': 450,\n",
       "  'title': 'Are You Talking to a Machine? Dataset and Methods for Multilingual Image  Question Answering',\n",
       "  'authors': ['Jie Zhou',\n",
       "   'Haoyuan Gao',\n",
       "   'Lei Wang',\n",
       "   'Wei Xu',\n",
       "   'Junhua Mao',\n",
       "   'Zhiheng Huang'],\n",
       "  'published': '2015-05-21T06:09:36Z',\n",
       "  'updated': '2015-11-02T21:12:15Z',\n",
       "  'abstract': 'In this paper, we present the mQA model, which is able to answer questionsabout the content of an image. The answer can be a sentence, a phrase or asingle word. Our model contains four components: a Long Short-Term Memory(LSTM) to extract the question representation, a Convolutional Neural Network(CNN) to extract the visual representation, an LSTM for storing the linguisticcontext in an answer, and a fusing component to combine the information fromthe first three components and generate the answer. We construct a FreestyleMultilingual Image Question Answering (FM-IQA) dataset to train and evaluateour mQA model. It contains over 150,000 images and 310,000 freestyle Chinesequestion-answer pairs and their English translations. The quality of thegenerated answers of our mQA model on this dataset is evaluated by human judgesthrough a Turing Test. Specifically, we mix the answers provided by humans andour model. The human judges need to distinguish our model from the human. Theywill also provide a score (i.e. 0, 1, 2, the larger the better) indicating thequality of the answer. We propose strategies to monitor the quality of thisevaluation process. The experiments show that in 64.7% of cases, the humanjudges cannot distinguish our model from humans. The average score is 1.454(1.918 for human). The details of this work, including the FM-IQA dataset, canbe found on the project page: http://idl.baidu.com/FM-IQA.html',\n",
       "  'categories': ['cs.CV', 'cs.CL', 'cs.LG', 'I.2.6; I.2.7; I.2.10'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '362',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.05612v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14623509836487873093&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 451: {'ID': 451,\n",
       "  'title': 'Generalization and Equilibrium in Generative Adversarial Nets (GANs)',\n",
       "  'authors': ['Sanjeev Arora',\n",
       "   'Yingyu Liang',\n",
       "   'Rong Ge',\n",
       "   'Tengyu Ma',\n",
       "   'Yi Zhang'],\n",
       "  'published': '2017-03-02T01:14:03Z',\n",
       "  'updated': '2017-08-01T19:51:56Z',\n",
       "  'abstract': 'We show that training of generative adversarial network (GAN) may not havegood generalization properties; e.g., training may appear successful but thetrained distribution may be far from target distribution in standard metrics.However, generalization does occur for a weaker metric called neural netdistance. It is also shown that an approximate pure equilibrium exists in thediscriminator/generator game for a special class of generators with naturaltraining objectives when generator capacity and training set sizes aremoderate.  This existence of equilibrium inspires MIX+GAN protocol, which can becombined with any existing GAN training, and empirically shown to improve someof them.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 224-232',\n",
       "  'citations': '309',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.00573v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11124082639758751800&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 452: {'ID': 452,\n",
       "  'title': 'Building End-To-End Dialogue Systems Using Generative Hierarchical  Neural Network Models',\n",
       "  'authors': ['Alessandro Sordoni',\n",
       "   'Iulian V. Serban',\n",
       "   'Aaron Courville',\n",
       "   'Joelle Pineau',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2015-07-17T00:21:39Z',\n",
       "  'updated': '2016-04-06T23:20:41Z',\n",
       "  'abstract': 'We investigate the task of building open domain, conversational dialoguesystems based on large dialogue corpora using generative models. Generativemodels produce system responses that are autonomously generated word-by-word,opening up the possibility for realistic, flexible interactions. In support ofthis goal, we extend the recently proposed hierarchical recurrentencoder-decoder neural network to the dialogue domain, and demonstrate thatthis model is competitive with state-of-the-art neural language models andback-off n-gram models. We investigate the limitations of this and similarapproaches, and show how its performance can be improved by bootstrapping thelearning from a larger question-answer pair corpus and from pretrained wordembeddings.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE', 'I.5.1; I.2.7'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '1067',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.04808v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2745297076509838691&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 453: {'ID': 453,\n",
       "  'title': 'R-FCN: Object Detection via Region-based Fully Convolutional Networks',\n",
       "  'authors': ['Jifeng Dai', 'Yi Li', 'Jian Sun', 'Kaiming He'],\n",
       "  'published': '2016-05-20T15:50:11Z',\n",
       "  'updated': '2016-06-21T15:28:57Z',\n",
       "  'abstract': 'We present region-based, fully convolutional networks for accurate andefficient object detection. In contrast to previous region-based detectors suchas Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds oftimes, our region-based detector is fully convolutional with almost allcomputation shared on the entire image. To achieve this goal, we proposeposition-sensitive score maps to address a dilemma betweentranslation-invariance in image classification and translation-variance inobject detection. Our method can thus naturally adopt fully convolutional imageclassifier backbones, such as the latest Residual Networks (ResNets), forobject detection. We show competitive results on the PASCAL VOC datasets (e.g.,83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result isachieved at a test-time speed of 170ms per image, 2.5-20x faster than theFaster R-CNN counterpart. Code is made publicly available at:https://github.com/daijifeng001/r-fcn',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '2676',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06409v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14880935744314366653&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 454: {'ID': 454,\n",
       "  'title': 'Variational Autoencoder for Deep Learning of Images, Labels and Captions',\n",
       "  'authors': ['Zhe Gan',\n",
       "   'Lawrence Carin',\n",
       "   'Chunyuan Li',\n",
       "   'Yunchen Pu',\n",
       "   'Ricardo Henao',\n",
       "   'Andrew Stevens',\n",
       "   'Xin Yuan'],\n",
       "  'published': '2016-09-28T15:56:15Z',\n",
       "  'updated': '2016-09-28T15:56:15Z',\n",
       "  'abstract': 'A novel variational autoencoder is developed to model images, as well asassociated labels or captions. The Deep Generative Deconvolutional Network(DGDN) is used as a decoder of the latent image features, and a deepConvolutional Neural Network (CNN) is used as an image encoder; the CNN is usedto approximate a distribution for the latent DGDN features/code. The latentcode is also linked to generative models for labels (Bayesian support vectormachine) or captions (recurrent neural network). When predicting alabel/caption for a new image at test, averaging is performed across thedistribution of latent codes; this is computationally efficient as aconsequence of the learned CNN-based encoder. Since the framework is capable ofmodeling the image in the presence/absence of associated labels/captions, a newsemi-supervised setting is manifested for CNN learning with images; theframework even allows unsupervised CNN learning, based on images alone.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '325',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.08976v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6882187919491425397&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 455: {'ID': 455,\n",
       "  'title': 'Professor Forcing: A New Algorithm for Training Recurrent Networks',\n",
       "  'authors': ['Aaron Courville',\n",
       "   'Ying Zhang',\n",
       "   'Anirudh Goyal',\n",
       "   'Alex Lamb',\n",
       "   'Yoshua Bengio',\n",
       "   'Saizheng Zhang'],\n",
       "  'published': '2016-10-27T23:54:31Z',\n",
       "  'updated': '2016-10-27T23:54:31Z',\n",
       "  'abstract': \"The Teacher Forcing algorithm trains recurrent networks by supplying observedsequence values as inputs during training and using the network's ownone-step-ahead predictions to do multi-step sampling. We introduce theProfessor Forcing algorithm, which uses adversarial domain adaptation toencourage the dynamics of the recurrent network to be the same when trainingthe network and when sampling from the network over multiple time steps. Weapply Professor Forcing to language modeling, vocal synthesis on raw waveforms,handwriting generation, and image generation. Empirically we find thatProfessor Forcing acts as a regularizer, improving test likelihood on characterlevel Penn Treebank and sequential MNIST. We also find that the modelqualitatively improves samples, especially when sampling for a large number oftime steps. This is supported by human evaluation of sample quality. Trade-offsbetween Professor Forcing and Scheduled Sampling are discussed. We produceT-SNEs showing that Professor Forcing successfully makes the dynamics of thenetwork during training and sampling more similar.\",\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '267',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.09038v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17198780094986434106&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 456: {'ID': 456,\n",
       "  'title': 'Prioritized Experience Replay',\n",
       "  'authors': ['Tom Schaul', 'John Quan', 'David Silver', 'Ioannis Antonoglou'],\n",
       "  'published': '2015-11-18T20:54:44Z',\n",
       "  'updated': '2016-02-25T17:55:31Z',\n",
       "  'abstract': 'Experience replay lets online reinforcement learning agents remember andreuse experiences from the past. In prior work, experience transitions wereuniformly sampled from a replay memory. However, this approach simply replaystransitions at the same frequency that they were originally experienced,regardless of their significance. In this paper we develop a framework forprioritizing experience, so as to replay important transitions more frequently,and therefore learn more efficiently. We use prioritized experience replay inDeep Q-Networks (DQN), a reinforcement learning algorithm that achievedhuman-level performance across many Atari games. DQN with prioritizedexperience replay achieves a new state-of-the-art, outperforming DQN withuniform replay on 41 out of 49 games.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1312',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05952v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10780652695290317509&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 457: {'ID': 457,\n",
       "  'title': 'Spectral Normalization for Generative Adversarial Networks',\n",
       "  'authors': ['Takeru Miyato',\n",
       "   'Toshiki Kataoka',\n",
       "   'Masanori Koyama',\n",
       "   'Yuichi Yoshida'],\n",
       "  'published': '2018-02-16T14:41:39Z',\n",
       "  'updated': '2018-02-16T14:41:39Z',\n",
       "  'abstract': 'One of the challenges in the study of generative adversarial networks is theinstability of its training. In this paper, we propose a novel weightnormalization technique called spectral normalization to stabilize the trainingof the discriminator. Our new normalization technique is computationally lightand easy to incorporate into existing implementations. We tested the efficacyof spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and weexperimentally confirmed that spectrally normalized GANs (SN-GANs) is capableof generating images of better or equal quality relative to the previoustraining stabilization techniques.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '1167',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.05957v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=973410365172845184&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 458: {'ID': 458,\n",
       "  'title': 'Learning through Dialogue Interactions by Asking Questions',\n",
       "  'authors': ['Jason Weston',\n",
       "   'Jiwei Li',\n",
       "   'Alexander H. Miller',\n",
       "   \"Marc'Aurelio Ranzato\",\n",
       "   'Sumit Chopra'],\n",
       "  'published': '2016-12-15T05:46:27Z',\n",
       "  'updated': '2017-02-13T17:30:42Z',\n",
       "  'abstract': 'A good dialogue agent should have the ability to interact with users by bothresponding to questions and by asking questions, and importantly to learn fromboth types of interaction. In this work, we explore this direction by designinga simulator and a set of synthetic tasks in the movie domain that allow suchinteractions between a learner and a teacher. We investigate how a learner canbenefit from asking questions in both offline and online reinforcement learningsettings, and demonstrate that the learner improves when asking questions.Finally, real experiments with Mechanical Turk validate the approach. Our workrepresents a first step in developing such end-to-end learned interactivedialogue agents.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '247',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.04936v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16142141925331698351&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 459: {'ID': 459,\n",
       "  'title': 'Composing graphical models with neural networks for structured  representations and fast inference',\n",
       "  'authors': ['Ryan P. Adams',\n",
       "   'Alexander B. Wiltschko',\n",
       "   'Sandeep R. Datta',\n",
       "   'David Duvenaud',\n",
       "   'Matthew J. Johnson'],\n",
       "  'published': '2016-03-20T22:01:02Z',\n",
       "  'updated': '2017-07-07T16:00:42Z',\n",
       "  'abstract': 'We propose a general modeling and inference framework that composesprobabilistic graphical models with deep learning methods and combines theirrespective strengths. Our model family augments graphical structure in latentvariables with neural network observation models. For inference, we extendvariational autoencoders to use graphical model approximating distributionswith recognition networks that output conjugate potentials. All components ofthese models are learned simultaneously with a single objective, giving ascalable algorithm that leverages stochastic variational inference, naturalgradients, graphical model message passing, and the reparameterization trick.We illustrate this framework with several example models and an application tomouse behavioral phenotyping.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '270',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.06277v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12286587149980999415&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 460: {'ID': 460,\n",
       "  'title': 'Deep Q-learning from Demonstrations',\n",
       "  'authors': ['Joel Z. Leibo',\n",
       "   'Gabriel Dulac-Arnold',\n",
       "   'John Agapiou',\n",
       "   'Audrunas Gruslys',\n",
       "   'Ian Osband',\n",
       "   'Marc Lanctot',\n",
       "   'Tom Schaul',\n",
       "   'Dan Horgan',\n",
       "   'John Quan',\n",
       "   'Olivier Pietquin',\n",
       "   'Todd Hester',\n",
       "   'Matej Vecerik',\n",
       "   'Andrew Sendonaris',\n",
       "   'Bilal Piot'],\n",
       "  'published': '2017-04-12T12:44:37Z',\n",
       "  'updated': '2017-11-22T21:18:31Z',\n",
       "  'abstract': \"Deep reinforcement learning (RL) has achieved several high profile successesin difficult decision-making problems. However, these algorithms typicallyrequire a huge amount of data before they reach reasonable performance. Infact, their performance during learning can be extremely poor. This may beacceptable for a simulator, but it severely limits the applicability of deep RLto many real-world tasks, where the agent must learn in the real environment.In this paper we study a setting where the agent may access data from previouscontrol of the system. We present an algorithm, Deep Q-learning fromDemonstrations (DQfD), that leverages small sets of demonstration data tomassively accelerate the learning process even from relatively small amounts ofdemonstration data and is able to automatically assess the necessary ratio ofdemonstration data while learning thanks to a prioritized replay mechanism.DQfD works by combining temporal difference updates with supervisedclassification of the demonstrator's actions. We show that DQfD has betterinitial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN)as it starts with better scores on the first million steps on 41 of 42 gamesand on average it takes PDD DQN 83 million steps to catch up to DQfD'sperformance. DQfD learns to out-perform the best demonstration given in 14 of42 games. In addition, DQfD leverages human demonstrations to achievestate-of-the-art results for 11 games. Finally, we show that DQfD performsbetter than three related algorithms for incorporating demonstration data intoDQN.\",\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '284',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.03732v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6225249527608914570&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 461: {'ID': 461,\n",
       "  'title': 'Estimating individual treatment effect: generalization bounds and  algorithms',\n",
       "  'authors': ['David Sontag', 'Fredrik D. Johansson', 'Uri Shalit'],\n",
       "  'published': '2016-06-13T14:40:57Z',\n",
       "  'updated': '2017-05-16T15:11:15Z',\n",
       "  'abstract': 'There is intense interest in applying machine learning to problems of causalinference in fields such as healthcare, economics and education. In particular,individual-level causal inference has important applications such as precisionmedicine. We give a new theoretical analysis and family of algorithms forpredicting individual treatment effect (ITE) from observational data, under theassumption known as strong ignorability. The algorithms learn a \"balanced\"representation such that the induced treated and control distributions looksimilar. We give a novel, simple and intuitive generalization-error boundshowing that the expected ITE estimation error of a representation is boundedby a sum of the standard generalization-error of that representation and thedistance between the treated and control distributions induced by therepresentation. We use Integral Probability Metrics to measure distancesbetween distributions, deriving explicit bounds for the Wasserstein and MaximumMean Discrepancy (MMD) distances. Experiments on real and simulated data showthe new algorithms match or outperform the state-of-the-art.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 3076-3085',\n",
       "  'citations': '176',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.03976v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6525552873144020693&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 462: {'ID': 462,\n",
       "  'title': 'Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action  Recognition',\n",
       "  'authors': ['Sijie Yan', 'Yuanjun Xiong', 'Dahua Lin'],\n",
       "  'published': '2018-01-23T09:48:47Z',\n",
       "  'updated': '2018-01-25T07:17:02Z',\n",
       "  'abstract': 'Dynamics of human body skeletons convey significant information for humanaction recognition. Conventional approaches for modeling skeletons usually relyon hand-crafted parts or traversal rules, thus resulting in limited expressivepower and difficulties of generalization. In this work, we propose a novelmodel of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks(ST-GCN), which moves beyond the limitations of previous methods byautomatically learning both the spatial and temporal patterns from data. Thisformulation not only leads to greater expressive power but also strongergeneralization capability. On two large datasets, Kinetics and NTU-RGBD, itachieves substantial improvements over mainstream methods.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '464',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.07455v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6585893634007378631&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 463: {'ID': 463,\n",
       "  'title': 'Stabilising Experience Replay for Deep Multi-Agent Reinforcement  Learning',\n",
       "  'authors': ['Gregory Farquhar',\n",
       "   'Nantas Nardelli',\n",
       "   'Pushmeet Kohli',\n",
       "   'Triantafyllos Afouras',\n",
       "   'Shimon Whiteson',\n",
       "   'Philip H. S. Torr',\n",
       "   'Jakob Foerster'],\n",
       "  'published': '2017-02-28T17:56:41Z',\n",
       "  'updated': '2018-05-21T08:24:02Z',\n",
       "  'abstract': \"Many real-world problems, such as network packet routing and urban trafficcontrol, are naturally modeled as multi-agent reinforcement learning (RL)problems. However, existing multi-agent RL methods typically scale poorly inthe problem size. Therefore, a key challenge is to translate the success ofdeep learning on single-agent RL to the multi-agent setting. A major stumblingblock is that independent Q-learning, the most popular multi-agent RL method,introduces nonstationarity that makes it incompatible with the experiencereplay memory on which deep Q-learning relies. This paper proposes two methodsthat address this problem: 1) using a multi-agent variant of importancesampling to naturally decay obsolete data and 2) conditioning each agent'svalue function on a fingerprint that disambiguates the age of the data sampledfrom the replay memory. Results on a challenging decentralised variant ofStarCraft unit micromanagement confirm that these methods enable the successfulcombination of experience replay with multi-agent RL.\",\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.MA'],\n",
       "  'journal': 'ICML, 1146-1155',\n",
       "  'citations': '237',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.08887v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16652030977272114047&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 464: {'ID': 464,\n",
       "  'title': 'QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent  Reinforcement Learning',\n",
       "  'authors': ['Gregory Farquhar',\n",
       "   'Mikayel Samvelyan',\n",
       "   'Tabish Rashid',\n",
       "   'Shimon Whiteson',\n",
       "   'Christian Schroeder de Witt',\n",
       "   'Jakob Foerster'],\n",
       "  'published': '2018-03-30T14:23:39Z',\n",
       "  'updated': '2018-06-06T17:58:09Z',\n",
       "  'abstract': 'In many real-world settings, a team of agents must coordinate their behaviourwhile acting in a decentralised way. At the same time, it is often possible totrain the agents in a centralised fashion in a simulated or laboratory setting,where global state information is available and communication constraints arelifted. Learning joint action-values conditioned on extra state information isan attractive way to exploit centralised learning, but the best strategy forthen extracting decentralised policies is unclear. Our solution is QMIX, anovel value-based method that can train decentralised policies in a centralisedend-to-end fashion. QMIX employs a network that estimates joint action-valuesas a complex non-linear combination of per-agent values that condition only onlocal observations. We structurally enforce that the joint-action value ismonotonic in the per-agent values, which allows tractable maximisation of thejoint action-value in off-policy learning, and guarantees consistency betweenthe centralised and decentralised policies. We evaluate QMIX on a challengingset of StarCraft II micromanagement tasks, and show that QMIX significantlyoutperforms existing value-based multi-agent reinforcement learning methods.',\n",
       "  'categories': ['cs.LG', 'cs.MA', 'stat.ML'],\n",
       "  'journal': 'ICML, 4292-4301',\n",
       "  'citations': '179',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.11485v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11167932629570793337&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 465: {'ID': 465,\n",
       "  'title': 'Learning the Number of Neurons in Deep Networks',\n",
       "  'authors': ['Jose M Alvarez', 'Mathieu Salzmann'],\n",
       "  'published': '2016-11-19T07:18:17Z',\n",
       "  'updated': '2018-10-11T07:18:09Z',\n",
       "  'abstract': 'Nowadays, the number of layers and of neurons in each layer of a deep networkare typically set manually. While very deep and wide networks have proveneffective in general, they come at a high memory and computation cost, thusmaking them impractical for constrained platforms. These networks, however, areknown to have many redundant parameters, and could thus, in principle, bereplaced by more compact architectures. In this paper, we introduce an approachto automatically determining the number of neurons in each layer of a deepnetwork during learning. To this end, we propose to make use of structuredsparsity during learning. More precisely, we use a group sparsity regularizeron the parameters of the network, where each group is defined to act on asingle neuron. Starting from an overcomplete network, we show that our approachcan reduce the number of parameters by up to 80\\\\% while retaining or evenimproving the network accuracy.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '209',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.06321v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7560041967181663482&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 466: {'ID': 466,\n",
       "  'title': 'Improving the Adversarial Robustness and Interpretability of Deep Neural  Networks by Regularizing their Input Gradients',\n",
       "  'authors': ['Andrew Slavin Ross', 'Finale Doshi-Velez'],\n",
       "  'published': '2017-11-26T15:20:46Z',\n",
       "  'updated': '2017-11-26T15:20:46Z',\n",
       "  'abstract': 'Deep neural networks have proven remarkably effective at solving manyclassification problems, but have been criticized recently for two majorweaknesses: the reasons behind their predictions are uninterpretable, and thepredictions themselves can often be fooled by small adversarial perturbations.These problems pose major obstacles for the adoption of neural networks indomains that require security or transparency. In this work, we evaluate theeffectiveness of defenses that differentiably penalize the degree to whichsmall changes in inputs can alter model predictions. Across multiple attacks,architectures, defenses, and datasets, we find that neural networks trainedwith this input gradient regularization exhibit robustness to transferredadversarial examples generated to fool all of the other models. We also findthat adversarial examples generated to fool gradient-regularized models foolall other models equally well, and actually lead to more \"legitimate,\"interpretable misclassifications as rated by people (which we confirm in ahuman subject experiment). Finally, we demonstrate that regularizing inputgradients makes them more naturally interpretable as rationales for modelpredictions. We conclude by discussing this relationship betweeninterpretability and robustness in deep neural networks.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '161',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.09404v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10549843532884126759&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 467: {'ID': 467,\n",
       "  'title': 'Dynamic Filter Networks',\n",
       "  'authors': ['Xu Jia',\n",
       "   'Tinne Tuytelaars',\n",
       "   'Luc Van Gool',\n",
       "   'Bert De Brabandere'],\n",
       "  'published': '2016-05-31T15:29:36Z',\n",
       "  'updated': '2016-06-06T15:39:10Z',\n",
       "  'abstract': 'In a traditional convolutional layer, the learned filters stay fixed aftertraining. In contrast, we introduce a new framework, the Dynamic FilterNetwork, where filters are generated dynamically conditioned on an input. Weshow that this architecture is a powerful one, with increased flexibilitythanks to its adaptive nature, yet without an excessive increase in the numberof model parameters. A wide variety of filtering operations can be learned thisway, including local spatial transformations, but also others like selective(de)blurring or adaptive feature extraction. Moreover, multiple such layers canbe combined, e.g. in a recurrent architecture. We demonstrate the effectivenessof the dynamic filter network on the tasks of video and stereo prediction, andreach state-of-the-art performance on the moving MNIST dataset with a muchsmaller model. By visualizing the learned filters, we illustrate that thenetwork has picked up flow information by only looking at unlabelled trainingdata. This suggests that the network can be used to pretrain networks forvarious supervised tasks in an unsupervised way, like optical flow and depthestimation.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '350',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.09673v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6402271951989310264&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 468: {'ID': 468,\n",
       "  'title': 'Triple Generative Adversarial Nets',\n",
       "  'authors': ['Kun Xu', 'Chongxuan Li', 'Bo Zhang', 'Jun Zhu'],\n",
       "  'published': '2017-03-07T09:26:56Z',\n",
       "  'updated': '2017-11-05T17:25:11Z',\n",
       "  'abstract': 'Generative Adversarial Nets (GANs) have shown promise in image generation andsemi-supervised learning (SSL). However, existing GANs in SSL have twoproblems: (1) the generator and the discriminator (i.e. the classifier) may notbe optimal at the same time; and (2) the generator cannot control the semanticsof the generated samples. The problems essentially arise from the two-playerformulation, where a single discriminator shares incompatible roles ofidentifying fake samples and predicting labels and it only estimates the datawithout considering the labels. To address the problems, we present triplegenerative adversarial net (Triple-GAN), which consists of three players---agenerator, a discriminator and a classifier. The generator and the classifiercharacterize the conditional distributions between images and labels, and thediscriminator solely focuses on identifying fake image-label pairs. We designcompatible utilities to ensure that the distributions characterized by theclassifier and the generator both converge to the data distribution. Ourresults on various datasets demonstrate that Triple-GAN as a unified model cansimultaneously (1) achieve the state-of-the-art classification results amongdeep generative models, and (2) disentangle the classes and styles of the inputand transfer smoothly in the data space via interpolation in the latent spaceclass-conditionally.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '199',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.02291v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1723215698193163728&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 469: {'ID': 469,\n",
       "  'title': 'MADE: Masked Autoencoder for Distribution Estimation',\n",
       "  'authors': ['Karol Gregor',\n",
       "   'Iain Murray',\n",
       "   'Hugo Larochelle',\n",
       "   'Mathieu Germain'],\n",
       "  'published': '2015-02-12T02:06:07Z',\n",
       "  'updated': '2015-06-05T14:37:32Z',\n",
       "  'abstract': \"There has been a lot of recent interest in designing neural network models toestimate a distribution from a set of examples. We introduce a simplemodification for autoencoder neural networks that yields powerful generativemodels. Our method masks the autoencoder's parameters to respect autoregressiveconstraints: each input is reconstructed only from previous inputs in a givenordering. Constrained this way, the autoencoder outputs can be interpreted as aset of conditional probabilities, and their product, the full jointprobability. We can also train a single network that can decompose the jointprobability in multiple different orderings. Our simple framework can beapplied to multiple architectures, including deep ones. Vectorizedimplementations, such as on GPUs, are simple and fast. Experiments demonstratethat this approach is competitive with state-of-the-art tractable distributionestimators. At test time, the method is significantly faster and scales betterthan other autoregressive estimators.\",\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 881-889',\n",
       "  'citations': '273',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.03509v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3269243854142729843&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 470: {'ID': 470,\n",
       "  'title': 'Recurrent Batch Normalization',\n",
       "  'authors': ['Aaron Courville',\n",
       "   'Çağlar Gülçehre',\n",
       "   'César Laurent',\n",
       "   'Nicolas Ballas',\n",
       "   'Tim Cooijmans'],\n",
       "  'published': '2016-03-30T02:57:20Z',\n",
       "  'updated': '2017-02-28T00:59:42Z',\n",
       "  'abstract': 'We propose a reparameterization of LSTM that brings the benefits of batchnormalization to recurrent neural networks. Whereas previous works only applybatch normalization to the input-to-hidden transformation of RNNs, wedemonstrate that it is both possible and beneficial to batch-normalize thehidden-to-hidden transition, thereby reducing internal covariate shift betweentime steps. We evaluate our proposal on various sequential problems such assequence classification, language modeling and question answering. Ourempirical results show that our batch-normalized LSTM consistently leads tofaster convergence and improved generalization.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '312',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.09025v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16437445141311981298&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 471: {'ID': 471,\n",
       "  'title': 'Counterfactual Fairness',\n",
       "  'authors': ['Joshua R. Loftus',\n",
       "   'Matt J. Kusner',\n",
       "   'Chris Russell',\n",
       "   'Ricardo Silva'],\n",
       "  'published': '2017-03-20T17:18:57Z',\n",
       "  'updated': '2018-03-08T11:23:13Z',\n",
       "  'abstract': 'Machine learning can impact people with legal or ethical consequences when itis used to automate decisions in areas such as insurance, lending, hiring, andpredictive policing. In many of these scenarios, previous decisions have beenmade that are unfairly biased against certain subpopulations, for example thoseof a particular race, gender, or sexual orientation. Since this past data maybe biased, machine learning predictors must account for this to avoidperpetuating or creating discriminatory practices. In this paper, we develop aframework for modeling fairness using tools from causal inference. Ourdefinition of counterfactual fairness captures the intuition that a decision isfair towards an individual if it is the same in (a) the actual world and (b) acounterfactual world where the individual belonged to a different demographicgroup. We demonstrate our framework on a real-world problem of fair predictionof success in law school.',\n",
       "  'categories': ['stat.ML', 'cs.CY', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '348',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.06856v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13115459093902017069&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 472: {'ID': 472,\n",
       "  'title': 'Variable Rate Image Compression with Recurrent Neural Networks',\n",
       "  'authors': ['David Minnen',\n",
       "   'Shumeet Baluja',\n",
       "   'Rahul Sukthankar',\n",
       "   \"Sean M. O'Malley\",\n",
       "   'Michele Covell',\n",
       "   'George Toderici',\n",
       "   'Sung Jin Hwang',\n",
       "   'Damien Vincent'],\n",
       "  'published': '2015-11-19T07:50:46Z',\n",
       "  'updated': '2016-03-01T22:13:44Z',\n",
       "  'abstract': 'A large fraction of Internet traffic is now driven by requests from mobiledevices with relatively small screens and often stringent bandwidthrequirements. Due to these factors, it has become the norm for moderngraphics-heavy websites to transmit low-resolution, low-bytecount imagepreviews (thumbnails) as part of the initial page load process to improveapparent page responsiveness. Increasing thumbnail compression beyond thecapabilities of existing codecs is therefore a current research focus, as anybyte savings will significantly enhance the experience of mobile device users.Toward this end, we propose a general framework for variable-rate imagecompression and a novel architecture based on convolutional and deconvolutionalLSTM recurrent networks. Our models address the main issues that have preventedautoencoder neural networks from competing with existing image compressionalgorithms: (1) our networks only need to be trained once (not per-image),regardless of input image dimensions and the desired compression rate; (2) ournetworks are progressive, meaning that the more bits are sent, the moreaccurate the image reconstruction; and (3) the proposed architecture is atleast as efficient as a standard purpose-trained autoencoder for a given numberof bits. On a large-scale benchmark of 32$\\\\times$32 thumbnails, our LSTM-basedapproaches provide better visual quality than (headerless) JPEG, JPEG2000 andWebP, with a storage size that is reduced by 10% or more.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '233',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06085v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4340654873051667262&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 473: {'ID': 473,\n",
       "  'title': 'Generative Moment Matching Networks',\n",
       "  'authors': ['Yujia Li', 'Kevin Swersky', 'Richard Zemel'],\n",
       "  'published': '2015-02-10T02:54:58Z',\n",
       "  'updated': '2015-02-10T02:54:58Z',\n",
       "  'abstract': 'We consider the problem of learning deep generative models from data. Weformulate a method that generates an independent sample via a singlefeedforward pass through a multilayer perceptron, as in the recently proposedgenerative adversarial networks (Goodfellow et al., 2014). Training agenerative adversarial network, however, requires careful optimization of adifficult minimax program. Instead, we utilize a technique from statisticalhypothesis testing known as maximum mean discrepancy (MMD), which leads to asimple objective that can be interpreted as matching all orders of statisticsbetween a dataset and samples from the model, and can be trained bybackpropagation. We further boost the performance of this approach by combiningour generative network with an auto-encoder network, using MMD to learn togenerate codes that can then be decoded to produce samples. We show that thecombination of these techniques yields excellent generative models compared tobaseline approaches as measured on MNIST and the Toronto Face Database.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 1718-1727',\n",
       "  'citations': '460',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.02761v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18115566463777766587&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 474: {'ID': 474,\n",
       "  'title': 'Tensorizing Neural Networks',\n",
       "  'authors': ['Dmitry Vetrov',\n",
       "   'Alexander Novikov',\n",
       "   'Dmitry Podoprikhin',\n",
       "   'Anton Osokin'],\n",
       "  'published': '2015-09-22T12:31:03Z',\n",
       "  'updated': '2015-12-20T11:44:05Z',\n",
       "  'abstract': 'Deep neural networks currently demonstrate state-of-the-art performance inseveral domains. At the same time, models of this class are very demanding interms of computational resources. In particular, a large amount of memory isrequired by commonly used fully-connected layers, making it hard to use themodels on low-end devices and stopping the further increase of the model size.In this paper we convert the dense weight matrices of the fully-connectedlayers to the Tensor Train format such that the number of parameters is reducedby a huge factor and at the same time the expressive power of the layer ispreserved. In particular, for the Very Deep VGG networks we report thecompression factor of the dense weight matrix of a fully-connected layer up to200000 times leading to the compression factor of the whole network up to 7times.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '387',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.06569v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15959182859518738418&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 475: {'ID': 475,\n",
       "  'title': 'FitNets: Hints for Thin Deep Nets',\n",
       "  'authors': ['Carlo Gatta',\n",
       "   'Antoine Chassang',\n",
       "   'Adriana Romero',\n",
       "   'Samira Ebrahimi Kahou',\n",
       "   'Nicolas Ballas',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2014-12-19T22:40:51Z',\n",
       "  'updated': '2015-03-27T11:52:28Z',\n",
       "  'abstract': \"While depth tends to improve network performances, it also makesgradient-based training more difficult since deeper networks tend to be morenon-linear. The recently proposed knowledge distillation approach is aimed atobtaining small and fast-to-execute models, and it has shown that a studentnetwork could imitate the soft output of a larger teacher network or ensembleof networks. In this paper, we extend this idea to allow the training of astudent that is deeper and thinner than the teacher, using not only the outputsbut also the intermediate representations learned by the teacher as hints toimprove the training process and final performance of the student. Because thestudent intermediate hidden layer will generally be smaller than the teacher'sintermediate hidden layer, additional parameters are introduced to map thestudent hidden layer to the prediction of the teacher hidden layer. This allowsone to train deeper students that can generalize better or run faster, atrade-off that is controlled by the chosen student capacity. For example, onCIFAR-10, a deep student network with almost 10.4 times less parametersoutperforms a larger, state-of-the-art teacher network.\",\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1065',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6550v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10225516876101179571&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 476: {'ID': 476,\n",
       "  'title': 'Detecting change points in the large-scale structure of evolving  networks',\n",
       "  'authors': ['Aaron Clauset', 'Leto Peel'],\n",
       "  'published': '2014-03-05T02:28:38Z',\n",
       "  'updated': '2014-11-14T19:40:26Z',\n",
       "  'abstract': 'Interactions among people or objects are often dynamic in nature and can berepresented as a sequence of networks, each providing a snapshot of theinteractions over a brief period of time. An important task in analyzing suchevolving networks is change-point detection, in which we both identify thetimes at which the large-scale pattern of interactions changes fundamentallyand quantify how large and what kind of change occurred. Here, we formalize forthe first time the network change-point detection problem within an onlineprobabilistic learning framework and introduce a method that can reliably solveit. This method combines a generalized hierarchical random graph model with aBayesian hypothesis test to quantitatively determine if, when, and preciselyhow a change point has occurred. We analyze the detectability of our methodusing synthetic data with known change points of different types andmagnitudes, and show that this method is more accurate than several previouslyused alternatives. Applied to two high-resolution evolving social networks,this method identifies a sequence of change points that align with knownexternal \"shocks\" to these networks.',\n",
       "  'categories': ['cs.SI', 'physics.soc-ph', 'stat.ML'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '161',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1403.0989v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14760901904113071948&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 477: {'ID': 477,\n",
       "  'title': 'Generative Adversarial Imitation Learning',\n",
       "  'authors': ['Stefano Ermon', 'Jonathan Ho'],\n",
       "  'published': '2016-06-10T20:51:29Z',\n",
       "  'updated': '2016-06-10T20:51:29Z',\n",
       "  'abstract': \"Consider learning a policy from example expert behavior, without interactionwith the expert or access to reinforcement signal. One approach is to recoverthe expert's cost function with inverse reinforcement learning, then extract apolicy from that cost function with reinforcement learning. This approach isindirect and can be slow. We propose a new general framework for directlyextracting a policy from data, as if it were obtained by reinforcement learningfollowing inverse reinforcement learning. We show that a certain instantiationof our framework draws an analogy between imitation learning and generativeadversarial networks, from which we derive a model-free imitation learningalgorithm that obtains significant performance gains over existing model-freemethods in imitating complex behaviors in large, high-dimensional environments.\",\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '778',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.03476v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9944023855119495996&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 478: {'ID': 478,\n",
       "  'title': 'Applications of Deep Learning and Reinforcement Learning to Biological  Data',\n",
       "  'authors': ['Amir Hussain',\n",
       "   'M. Shamim Kaiser',\n",
       "   'Mufti Mahmud',\n",
       "   'Stefano Vassanelli'],\n",
       "  'published': '2017-11-10T19:06:46Z',\n",
       "  'updated': '2018-01-07T07:06:20Z',\n",
       "  'abstract': 'Rapid advances of hardware-based technologies during the past decades haveopened up new possibilities for Life scientists to gather multimodal data invarious application domains (e.g., Omics, Bioimaging, Medical Imaging, and[Brain/Body]-Machine Interfaces), thus generating novel opportunities fordevelopment of dedicated data intensive machine learning techniques. Overall,recent research in Deep learning (DL), Reinforcement learning (RL), and theircombination (Deep RL) promise to revolutionize Artificial Intelligence. Thegrowth in computational power accompanied by faster and increased data storageand declining computing costs have already allowed scientists in various fieldsto apply these techniques on datasets that were previously intractable fortheir size and complexity. This review article provides a comprehensive surveyon the application of DL, RL, and Deep RL techniques in mining Biological data.In addition, we compare performances of DL techniques when applied to differentdatasets across various application domains. Finally, we outline open issues inthis challenging research area and discuss future development perspectives.',\n",
       "  'categories': ['cs.LG', 'stat.ML', 'A.1, I.2, I.5, J.3'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (6), 2063-2079',\n",
       "  'citations': '178',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.03985v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10338561298388727665&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 479: {'ID': 479,\n",
       "  'title': 'Exploiting Cyclic Symmetry in Convolutional Neural Networks',\n",
       "  'authors': ['Sander Dieleman', 'Koray Kavukcuoglu', 'Jeffrey De Fauw'],\n",
       "  'published': '2016-02-08T17:37:16Z',\n",
       "  'updated': '2016-05-26T11:47:18Z',\n",
       "  'abstract': 'Many classes of images exhibit rotational symmetry. Convolutional neuralnetworks are sometimes trained using data augmentation to exploit this, butthey are still required to learn the rotation equivariance properties from thedata. Encoding these properties into the network architecture, as we arealready used to doing for translation equivariance by using convolutionallayers, could result in a more efficient use of the parameter budget byrelieving the model from learning them. We introduce four operations which canbe inserted into neural network models as layers, and which can be combined tomake these models partially equivariant to rotations. They also enableparameter sharing across different orientations. We evaluate the effect ofthese architectural modifications on three datasets which exhibit rotationalsymmetry and demonstrate improved performance with smaller models.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'ICML, 1889-1898',\n",
       "  'citations': '172',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.02660v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7548774008979787811&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 480: {'ID': 480,\n",
       "  'title': 'Convolutional Networks on Graphs for Learning Molecular Fingerprints',\n",
       "  'authors': ['Jorge Aguilera-Iparraguirre',\n",
       "   'Ryan P. Adams',\n",
       "   'Rafael Gómez-Bombarelli',\n",
       "   'Alán Aspuru-Guzik',\n",
       "   'Timothy Hirzel',\n",
       "   'David Duvenaud',\n",
       "   'Dougal Maclaurin'],\n",
       "  'published': '2015-09-30T18:33:50Z',\n",
       "  'updated': '2015-11-03T17:18:32Z',\n",
       "  'abstract': 'We introduce a convolutional neural network that operates directly on graphs.These networks allow end-to-end learning of prediction pipelines whose inputsare graphs of arbitrary size and shape. The architecture we present generalizesstandard molecular feature extraction methods based on circular fingerprints.We show that these data-driven features are more interpretable, and have betterpredictive performance on a variety of tasks.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1303',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1509.09292v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13332347053275193739&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 481: {'ID': 481,\n",
       "  'title': 'Neural Tangent Kernel: Convergence and Generalization in Neural Networks',\n",
       "  'authors': ['Arthur Jacot', 'Franck Gabriel', 'Clément Hongler'],\n",
       "  'published': '2018-06-20T06:35:46Z',\n",
       "  'updated': '2020-02-10T08:39:09Z',\n",
       "  'abstract': 'At initialization, artificial neural networks (ANNs) are equivalent toGaussian processes in the infinite-width limit, thus connecting them to kernelmethods. We prove that the evolution of an ANN during training can also bedescribed by a kernel: during gradient descent on the parameters of an ANN, thenetwork function $f_\\\\theta$ (which maps input vectors to output vectors)follows the kernel gradient of the functional cost (which is convex, incontrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel(NTK). This kernel is central to describe the generalization features of ANNs.While the NTK is random at initialization and varies during training, in theinfinite-width limit it converges to an explicit limiting kernel and it staysconstant during training. This makes it possible to study the training of ANNsin function space instead of parameter space. Convergence of the training canthen be related to the positive-definiteness of the limiting NTK. We prove thepositive-definiteness of the limiting NTK when the data is supported on thesphere and the non-linearity is non-polynomial. We then focus on the setting ofleast-squares regression and show that in the infinite-width limit, the networkfunction $f_\\\\theta$ follows a linear differential equation during training. Theconvergence is fastest along the largest kernel principal components of theinput data with respect to the NTK, hence suggesting a theoretical motivationfor early stopping. Finally we study the NTK numerically, observe its behaviorfor wide networks, and compare it to the infinite-width limit.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'math.PR', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '332',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.07572v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15521977800069603597&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 482: {'ID': 482,\n",
       "  'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples  in Neural Networks',\n",
       "  'authors': ['Dan Hendrycks', 'Kevin Gimpel'],\n",
       "  'published': '2016-10-07T04:06:01Z',\n",
       "  'updated': '2018-10-03T07:32:57Z',\n",
       "  'abstract': 'We consider the two related problems of detecting if an example ismisclassified or out-of-distribution. We present a simple baseline thatutilizes probabilities from softmax distributions. Correctly classifiedexamples tend to have greater maximum softmax probabilities than erroneouslyclassified and out-of-distribution examples, allowing for their detection. Weassess performance by defining several tasks in computer vision, naturallanguage processing, and automatic speech recognition, showing theeffectiveness of this baseline across all. We then show the baseline cansometimes be surpassed, demonstrating the room for future research on theseunderexplored detection tasks.',\n",
       "  'categories': ['cs.NE', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '362',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.02136v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14505244835813531476&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 483: {'ID': 483,\n",
       "  'title': 'Regularizing and Optimizing LSTM Language Models',\n",
       "  'authors': ['Richard Socher', 'Nitish Shirish Keskar', 'Stephen Merity'],\n",
       "  'published': '2017-08-07T16:03:44Z',\n",
       "  'updated': '2017-08-07T16:03:44Z',\n",
       "  'abstract': 'Recurrent neural networks (RNNs), such as long short-term memory networks(LSTMs), serve as a fundamental building block for many sequence learningtasks, including machine translation, language modeling, and questionanswering. In this paper, we consider the specific problem of word-levellanguage modeling and investigate strategies for regularizing and optimizingLSTM-based models. We propose the weight-dropped LSTM which uses DropConnect onhidden-to-hidden weights as a form of recurrent regularization. Further, weintroduce NT-ASGD, a variant of the averaged stochastic gradient method,wherein the averaging trigger is determined using a non-monotonic condition asopposed to being tuned by the user. Using these and other regularizationstrategies, we achieve state-of-the-art word level perplexities on two datasets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring theeffectiveness of a neural cache in conjunction with our proposed model, weachieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and52.0 on WikiText-2.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '508',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.02182v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10613038919449342432&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 484: {'ID': 484,\n",
       "  'title': 'Towards Universal Paraphrastic Sentence Embeddings',\n",
       "  'authors': ['Mohit Bansal', 'Kevin Gimpel', 'Karen Livescu', 'John Wieting'],\n",
       "  'published': '2015-11-25T20:52:15Z',\n",
       "  'updated': '2016-03-04T20:54:30Z',\n",
       "  'abstract': 'We consider the problem of learning general-purpose, paraphrastic sentenceembeddings based on supervision from the Paraphrase Database (Ganitkevitch etal., 2013). We compare six compositional architectures, evaluating them onannotated textual similarity datasets drawn both from the same distribution asthe training data and from a wide range of other domains. We find that the mostcomplex architectures, such as long short-term memory (LSTM) recurrent neuralnetworks, perform best on the in-domain data. However, in out-of-domainscenarios, simple architectures such as word averaging vastly outperform LSTMs.Our simplest averaging model is even competitive with systems tuned for theparticular tasks while also being extremely efficient and easy to use.  In order to better understand how these architectures compare, we conductfurther experiments on three supervised NLP tasks: sentence similarity,entailment, and sentiment classification. We again find that the word averagingmodels perform well for sentence similarity and entailment, outperformingLSTMs. However, on sentiment classification, we find that the LSTM performsvery strongly-even recording new state-of-the-art performance on the StanfordSentiment Treebank.  We then demonstrate how to combine our pretrained sentence embeddings withthese supervised tasks, using them both as a prior and as a black box featureextractor. This leads to performance rivaling the state of the art on the SICKsimilarity and entailment tasks. We release all of our resources to theresearch community with the hope that they can serve as the new baseline forfurther work on universal sentence embeddings.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '397',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.08198v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8275054724533958638&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 485: {'ID': 485,\n",
       "  'title': 'Learning a Probabilistic Latent Space of Object Shapes via 3D  Generative-Adversarial Modeling',\n",
       "  'authors': ['Jiajun Wu',\n",
       "   'William T. Freeman',\n",
       "   'Joshua B. Tenenbaum',\n",
       "   'Tianfan Xue',\n",
       "   'Chengkai Zhang'],\n",
       "  'published': '2016-10-24T19:53:41Z',\n",
       "  'updated': '2017-01-04T18:35:52Z',\n",
       "  'abstract': 'We study the problem of 3D object generation. We propose a novel framework,namely 3D Generative Adversarial Network (3D-GAN), which generates 3D objectsfrom a probabilistic space by leveraging recent advances in volumetricconvolutional networks and generative adversarial nets. The benefits of ourmodel are three-fold: first, the use of an adversarial criterion, instead oftraditional heuristic criteria, enables the generator to capture objectstructure implicitly and to synthesize high-quality 3D objects; second, thegenerator establishes a mapping from a low-dimensional probabilistic space tothe space of 3D objects, so that we can sample objects without a referenceimage or CAD models, and explore the 3D object manifold; third, the adversarialdiscriminator provides a powerful 3D shape descriptor which, learned withoutsupervision, has wide applications in 3D object recognition. Experimentsdemonstrate that our method generates high-quality 3D objects, and ourunsupervisedly learned features achieve impressive performance on 3D objectrecognition, comparable with those of supervised learning methods.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '849',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.07584v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1838944634579790374&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 486: {'ID': 486,\n",
       "  'title': 'Dynamic Network Surgery for Efficient DNNs',\n",
       "  'authors': ['Yurong Chen', 'Anbang Yao', 'Yiwen Guo'],\n",
       "  'published': '2016-08-16T06:23:05Z',\n",
       "  'updated': '2016-11-10T00:17:25Z',\n",
       "  'abstract': 'Deep learning has become a ubiquitous technology to improve machineintelligence. However, most of the existing deep models are structurally verycomplex, making them difficult to be deployed on the mobile platforms withlimited computational power. In this paper, we propose a novel networkcompression method called dynamic network surgery, which can remarkably reducethe network complexity by making on-the-fly connection pruning. Unlike theprevious methods which accomplish this task in a greedy way, we properlyincorporate connection splicing into the whole process to avoid incorrectpruning and make it as a continual network maintenance. The effectiveness ofour method is proved with experiments. Without any accuracy loss, our methodcan efficiently compress the number of parameters in LeNet-5 and AlexNet by afactor of $\\\\bm{108}\\\\times$ and $\\\\bm{17.7}\\\\times$ respectively, proving that itoutperforms the recent pruning method by considerable margins. Code and somemodels are available at https://github.com/yiwenguo/Dynamic-Network-Surgery.',\n",
       "  'categories': ['cs.NE', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '438',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.04493v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8401919167089401684&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 487: {'ID': 487,\n",
       "  'title': 'Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement  Learning with a Stochastic Actor',\n",
       "  'authors': ['Tuomas Haarnoja',\n",
       "   'Aurick Zhou',\n",
       "   'Sergey Levine',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2018-01-04T09:50:50Z',\n",
       "  'updated': '2018-08-08T21:27:08Z',\n",
       "  'abstract': 'Model-free deep reinforcement learning (RL) algorithms have been demonstratedon a range of challenging decision making and control tasks. However, thesemethods typically suffer from two major challenges: very high sample complexityand brittle convergence properties, which necessitate meticulous hyperparametertuning. Both of these challenges severely limit the applicability of suchmethods to complex, real-world domains. In this paper, we propose softactor-critic, an off-policy actor-critic deep RL algorithm based on the maximumentropy reinforcement learning framework. In this framework, the actor aims tomaximize expected reward while also maximizing entropy. That is, to succeed atthe task while acting as randomly as possible. Prior deep RL methods based onthis framework have been formulated as Q-learning methods. By combiningoff-policy updates with a stable stochastic actor-critic formulation, ourmethod achieves state-of-the-art performance on a range of continuous controlbenchmark tasks, outperforming prior on-policy and off-policy methods.Furthermore, we demonstrate that, in contrast to other off-policy algorithms,our approach is very stable, achieving very similar performance acrossdifferent random seeds.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'journal': 'ICML, 1856-1865',\n",
       "  'citations': '698',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.01290v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13282174879342015249&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 488: {'ID': 488,\n",
       "  'title': 'Session-based Recommendations with Recurrent Neural Networks',\n",
       "  'authors': ['Linas Baltrunas',\n",
       "   'Balázs Hidasi',\n",
       "   'Alexandros Karatzoglou',\n",
       "   'Domonkos Tikk'],\n",
       "  'published': '2015-11-21T23:42:59Z',\n",
       "  'updated': '2016-03-29T14:52:58Z',\n",
       "  'abstract': 'We apply recurrent neural networks (RNN) on a new domain, namely recommendersystems. Real-life recommender systems often face the problem of having to baserecommendations only on short session-based data (e.g. a small sportswarewebsite) instead of long user histories (as in the case of Netflix). In thissituation the frequently praised matrix factorization approaches are notaccurate. This problem is usually overcome in practice by resorting toitem-to-item recommendations, i.e. recommending similar items. We argue that bymodeling the whole session, more accurate recommendations can be provided. Wetherefore propose an RNN-based approach for session-based recommendations. Ourapproach also considers practical aspects of the task and introduces severalmodifications to classic RNNs such as a ranking loss function that make it moreviable for this specific problem. Experimental results on two data-sets showmarked improvements over widely used approaches.',\n",
       "  'categories': ['cs.LG', 'cs.IR', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '635',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06939v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10894551747136395106&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 489: {'ID': 489,\n",
       "  'title': 'Learning Efficient Point Cloud Generation for Dense 3D Object  Reconstruction',\n",
       "  'authors': ['Chen-Hsuan Lin', 'Chen Kong', 'Simon Lucey'],\n",
       "  'published': '2017-06-21T17:56:59Z',\n",
       "  'updated': '2017-06-21T17:56:59Z',\n",
       "  'abstract': 'Conventional methods of 3D object generative modeling learn volumetricpredictions using deep networks with 3D convolutional operations, which aredirect analogies to classical 2D ones. However, these methods arecomputationally wasteful in attempt to predict 3D shapes, where information isrich only on the surfaces. In this paper, we propose a novel 3D generativemodeling framework to efficiently generate object shapes in the form of densepoint clouds. We use 2D convolutional operations to predict the 3D structurefrom multiple viewpoints and jointly apply geometric reasoning with 2Dprojection optimization. We introduce the pseudo-renderer, a differentiablemodule to approximate the true rendering operation, to synthesize novel depthmaps for optimization. Experimental results for single-image 3D objectreconstruction tasks show that we outperforms state-of-the-art methods in termsof shape similarity and prediction density.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '129',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.07036v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5371374397764333012&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 490: {'ID': 490,\n",
       "  'title': 'The Use of Machine Learning Algorithms in Recommender Systems: A  Systematic Review',\n",
       "  'authors': ['Donald Cowan', 'Ivens Portugal', 'Paulo Alencar'],\n",
       "  'published': '2015-11-17T03:14:46Z',\n",
       "  'updated': '2016-02-24T18:58:32Z',\n",
       "  'abstract': 'Recommender systems use algorithms to provide users with product or servicerecommendations. Recently, these systems have been using machine learningalgorithms from the field of artificial intelligence. However, choosing asuitable machine learning algorithm for a recommender system is difficultbecause of the number of algorithms described in the literature. Researchersand practitioners developing recommender systems are left with littleinformation about the current approaches in algorithm usage. Moreover, thedevelopment of a recommender system using a machine learning algorithm oftenhas problems and open questions that must be evaluated, so software engineersknow where to focus research efforts. This paper presents a systematic reviewof the literature that analyzes the use of machine learning algorithms inrecommender systems and identifies research opportunities for softwareengineering research. The study concludes that Bayesian and decision treealgorithms are widely used in recommender systems because of their relativesimplicity, and that requirement and design phases of recommender systemdevelopment appear to offer opportunities for further research.',\n",
       "  'categories': ['cs.SE', 'cs.IR', 'cs.LG'],\n",
       "  'journal': 'Expert Systems with Applications 97, 205-227',\n",
       "  'citations': '204',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05263v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11285524639657957777&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 491: {'ID': 491,\n",
       "  'title': 'Fader Networks: Manipulating Images by Sliding Attributes',\n",
       "  'authors': ['Antoine Bordes',\n",
       "   'Guillaume Lample',\n",
       "   'Neil Zeghidour',\n",
       "   'Ludovic Denoyer',\n",
       "   \"Marc'Aurelio Ranzato\",\n",
       "   'Nicolas Usunier'],\n",
       "  'published': '2017-06-01T17:48:24Z',\n",
       "  'updated': '2018-01-28T16:12:14Z',\n",
       "  'abstract': 'This paper introduces a new encoder-decoder architecture that is trained toreconstruct images by disentangling the salient information of the image andthe values of attributes directly in the latent space. As a result, aftertraining, our model can generate different realistic versions of an input imageby varying the attribute values. By using continuous attribute values, we canchoose how much a specific attribute is perceivable in the generated image.This property could allow for applications where users can modify an imageusing sliding knobs, like faders on a mixing console, to change the facialexpression of a portrait, or to update the color of some objects. Compared tothe state-of-the-art which mostly relies on training adversarial networks inpixel space by altering attribute values at train time, our approach results inmuch simpler training schemes and nicely scales to multiple attributes. Wepresent evidence that our model can significantly change the perceived value ofthe attributes while preserving the naturalness of images.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '238',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.00409v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7253031520963581223&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 492: {'ID': 492,\n",
       "  'title': 'Equality of Opportunity in Supervised Learning',\n",
       "  'authors': ['Moritz Hardt', 'Eric Price', 'Nathan Srebro'],\n",
       "  'published': '2016-10-07T20:16:29Z',\n",
       "  'updated': '2016-10-07T20:16:29Z',\n",
       "  'abstract': 'We propose a criterion for discrimination against a specified sensitiveattribute in supervised learning, where the goal is to predict some targetbased on available features. Assuming data about the predictor, target, andmembership in the protected group are available, we show how to optimallyadjust any learned predictor so as to remove discrimination according to ourdefinition. Our framework also improves incentives by shifting the cost of poorclassification from disadvantaged groups to the decision maker, who can respondby improving the classification accuracy.  In line with other studies, our notion is oblivious: it depends only on thejoint statistics of the predictor, the target and the protected attribute, butnot on interpretation of individualfeatures. We study the inherent limits ofdefining and identifying biases based on such oblivious measures, outliningwhat can and cannot be inferred from different oblivious tests.  We illustrate our notion using a case study of FICO credit scores.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '937',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.02413v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2062984936384963570&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 493: {'ID': 493,\n",
       "  'title': 'An Actor-Critic Algorithm for Sequence Prediction',\n",
       "  'authors': ['Dzmitry Bahdanau',\n",
       "   'Philemon Brakel',\n",
       "   'Aaron Courville',\n",
       "   'Kelvin Xu',\n",
       "   'Anirudh Goyal',\n",
       "   'Joelle Pineau',\n",
       "   'Ryan Lowe',\n",
       "   'Yoshua Bengio'],\n",
       "  'published': '2016-07-24T20:05:07Z',\n",
       "  'updated': '2017-03-03T15:43:52Z',\n",
       "  'abstract': 'We present an approach to training neural networks to generate sequencesusing actor-critic methods from reinforcement learning (RL). Currentlog-likelihood training methods are limited by the discrepancy between theirtraining and testing modes, as models must generate tokens conditioned on theirprevious guesses rather than the ground-truth tokens. We address this problemby introducing a \\\\textit{critic} network that is trained to predict the valueof an output token, given the policy of an \\\\textit{actor} network. This resultsin a training procedure that is much closer to the test phase, and allows us todirectly optimize for a task-specific score such as BLEU. Crucially, since weleverage these techniques in the supervised learning setting rather than thetraditional RL setting, we condition the critic network on the ground-truthoutput. We show that our method leads to improved performance on both asynthetic task, and for German-English machine translation. Our analysis pavesthe way for such methods to be applied in natural language generation tasks,such as machine translation, caption generation, and dialogue modelling.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '348',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.07086v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5228204938243984917&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 494: {'ID': 494,\n",
       "  'title': 'Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets',\n",
       "  'authors': ['Tomas Mikolov', 'Armand Joulin'],\n",
       "  'published': '2015-03-03T16:50:28Z',\n",
       "  'updated': '2015-06-01T20:37:55Z',\n",
       "  'abstract': 'Despite the recent achievements in machine learning, we are still very farfrom achieving real artificial intelligence. In this paper, we discuss thelimitations of standard deep learning approaches and show that some of theselimitations can be overcome by learning how to grow the complexity of a modelin a structured way. Specifically, we study the simplest sequence predictionproblems that are beyond the scope of what is learnable with standard recurrentnetworks, algorithmically generated sequences which can only be learned bymodels which have the capacity to count and to memorize sequences. We show thatsome basic algorithms can be learned from sequential data using a recurrentnetwork associated with a trainable memory.',\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '290',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1503.01007v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3528545098584451867&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 495: {'ID': 495,\n",
       "  'title': 'mixup: Beyond Empirical Risk Minimization',\n",
       "  'authors': ['Moustapha Cisse',\n",
       "   'Yann N. Dauphin',\n",
       "   'David Lopez-Paz',\n",
       "   'Hongyi Zhang'],\n",
       "  'published': '2017-10-25T18:30:49Z',\n",
       "  'updated': '2018-04-27T21:39:25Z',\n",
       "  'abstract': 'Large deep neural networks are powerful, but exhibit undesirable behaviorssuch as memorization and sensitivity to adversarial examples. In this work, wepropose mixup, a simple learning principle to alleviate these issues. Inessence, mixup trains a neural network on convex combinations of pairs ofexamples and their labels. By doing so, mixup regularizes the neural network tofavor simple linear behavior in-between training examples. Our experiments onthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets showthat mixup improves the generalization of state-of-the-art neural networkarchitectures. We also find that mixup reduces the memorization of corruptlabels, increases the robustness to adversarial examples, and stabilizes thetraining of generative adversarial networks.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '782',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.09412v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12669856454801555406&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 496: {'ID': 496,\n",
       "  'title': 'Pruning Convolutional Neural Networks for Resource Efficient Inference',\n",
       "  'authors': ['Tero Karras',\n",
       "   'Pavlo Molchanov',\n",
       "   'Stephen Tyree',\n",
       "   'Timo Aila',\n",
       "   'Jan Kautz'],\n",
       "  'published': '2016-11-19T22:48:30Z',\n",
       "  'updated': '2017-06-08T19:53:26Z',\n",
       "  'abstract': 'We propose a new formulation for pruning convolutional kernels in neuralnetworks to enable efficient inference. We interleave greedy criteria-basedpruning with fine-tuning by backpropagation - a computationally efficientprocedure that maintains good generalization in the pruned network. We proposea new criterion based on Taylor expansion that approximates the change in thecost function induced by pruning network parameters. We focus on transferlearning, where large pretrained networks are adapted to specialized tasks. Theproposed criterion demonstrates superior performance compared to othercriteria, e.g. the norm of kernel weights or feature map activation, forpruning large CNNs after adaptation to fine-grained classification tasks(Birds-200 and Flowers-102) relaying only on the first order gradientinformation. We also show that pruning can lead to more than 10x theoretical(5x practical) reduction in adapted 3D-convolutional filters with a small dropin accuracy in a recurrent gesture classifier. Finally, we show results for thelarge-scale ImageNet dataset to emphasize the flexibility of our approach.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '636',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.06440v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13741786010220230474&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 497: {'ID': 497,\n",
       "  'title': 'Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box  Machine Learning Models',\n",
       "  'authors': ['Jonas Rauber', 'Wieland Brendel', 'Matthias Bethge'],\n",
       "  'published': '2017-12-12T11:36:26Z',\n",
       "  'updated': '2018-02-16T14:40:42Z',\n",
       "  'abstract': 'Many machine learning algorithms are vulnerable to almost imperceptibleperturbations of their inputs. So far it was unclear how much risk adversarialperturbations carry for the safety of real-world machine learning applicationsbecause most methods used to generate such perturbations rely either ondetailed model information (gradient-based attacks) or on confidence scoressuch as class probabilities (score-based attacks), neither of which areavailable in most real-world scenarios. In many such cases one currently needsto retreat to transfer-based attacks which rely on cumbersome substitutemodels, need access to the training data and can be defended against. Here weemphasise the importance of attacks which solely rely on the final modeldecision. Such decision-based attacks are (1) applicable to real-worldblack-box models such as autonomous cars, (2) need less knowledge and areeasier to apply than transfer-based attacks and (3) are more robust to simpledefences than gradient- or score-based attacks. Previous attacks in thiscategory were limited to simple models or simple datasets. Here we introducethe Boundary Attack, a decision-based attack that starts from a largeadversarial perturbation and then seeks to reduce the perturbation whilestaying adversarial. The attack is conceptually simple, requires close to nohyperparameter tuning, does not rely on substitute models and is competitivewith the best gradient-based attacks in standard computer vision tasks likeImageNet. We apply the attack on two black-box algorithms from Clarifai.com.The Boundary Attack in particular and the class of decision-based attacks ingeneral open new avenues to study the robustness of machine learning models andraise new questions regarding the safety of deployed machine learning systems.An implementation of the attack is available as part of Foolbox athttps://github.com/bethgelab/foolbox .',\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '294',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.04248v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1222517566911879461&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 498: {'ID': 498,\n",
       "  'title': 'Multi-Scale Context Aggregation by Dilated Convolutions',\n",
       "  'authors': ['Fisher Yu', 'Vladlen Koltun'],\n",
       "  'published': '2015-11-23T07:32:14Z',\n",
       "  'updated': '2016-04-30T18:19:37Z',\n",
       "  'abstract': 'State-of-the-art models for semantic segmentation are based on adaptations ofconvolutional networks that had originally been designed for imageclassification. However, dense prediction and image classification arestructurally different. In this work, we develop a new convolutional networkmodule that is specifically designed for dense prediction. The presented moduleuses dilated convolutions to systematically aggregate multi-scale contextualinformation without losing resolution. The architecture is based on the factthat dilated convolutions support exponential expansion of the receptive fieldwithout loss of resolution or coverage. We show that the presented contextmodule increases the accuracy of state-of-the-art semantic segmentationsystems. In addition, we examine the adaptation of image classificationnetworks to dense prediction and show that simplifying the adapted network canincrease accuracy.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '3314',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.07122v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=381540638710125131&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 499: {'ID': 499,\n",
       "  'title': \"Don't Decay the Learning Rate, Increase the Batch Size\",\n",
       "  'authors': ['Pieter-Jan Kindermans',\n",
       "   'Chris Ying',\n",
       "   'Quoc V. Le',\n",
       "   'Samuel L. Smith'],\n",
       "  'published': '2017-11-01T18:04:31Z',\n",
       "  'updated': '2018-02-24T00:16:12Z',\n",
       "  'abstract': 'It is common practice to decay the learning rate. Here we show one canusually obtain the same learning curve on both training and test sets byinstead increasing the batch size during training. This procedure is successfulfor stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum,and Adam. It reaches equivalent test accuracies after the same number oftraining epochs, but with fewer parameter updates, leading to greaterparallelism and shorter training times. We can further reduce the number ofparameter updates by increasing the learning rate $\\\\epsilon$ and scaling thebatch size $B \\\\propto \\\\epsilon$. Finally, one can increase the momentumcoefficient $m$ and scale $B \\\\propto 1/(1-m)$, although this tends to slightlyreduce the test accuracy. Crucially, our techniques allow us to repurposeexisting training schedules for large batch training with no hyper-parametertuning. We train ResNet-50 on ImageNet to $76.1\\\\%$ validation accuracy in under30 minutes.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.DC', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '330',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.00489v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3840223745264283290&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 500: {'ID': 500,\n",
       "  'title': 'Learning shape correspondence with anisotropic convolutional neural  networks',\n",
       "  'authors': ['Emanuele Rodolà',\n",
       "   'Jonathan Masci',\n",
       "   'Davide Boscaini',\n",
       "   'Michael M. Bronstein'],\n",
       "  'published': '2016-05-20T17:02:40Z',\n",
       "  'updated': '2016-05-20T17:02:40Z',\n",
       "  'abstract': \"Establishing correspondence between shapes is a fundamental problem ingeometry processing, arising in a wide variety of applications. The problem isespecially difficult in the setting of non-isometric deformations, as well asin the presence of topological noise and missing parts, mainly due to thelimited capability to model such deformations axiomatically. Several recentworks showed that invariance to complex shape transformations can be learnedfrom examples. In this paper, we introduce an intrinsic convolutional neuralnetwork architecture based on anisotropic diffusion kernels, which we termAnisotropic Convolutional Neural Network (ACNN). In our construction, wegeneralize convolutions to non-Euclidean domains by constructing a set oforiented anisotropic diffusion kernels, creating in this way a local intrinsicpolar representation of the data (`patch'), which is then correlated with afilter. Several cascades of such filters, linear, and non-linear operators arestacked to form a deep neural network whose parameters are learned byminimizing a task-specific cost. We use ACNNs to effectively learn intrinsicdense correspondences between deformable shapes in very challenging settings,achieving state-of-the-art results on some of the most difficult recentcorrespondence benchmarks.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '279',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.06437v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8736265664125680677&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 501: {'ID': 501,\n",
       "  'title': 'Ask Me Anything: Dynamic Memory Networks for Natural Language Processing',\n",
       "  'authors': ['Richard Socher',\n",
       "   'Romain Paulus',\n",
       "   'Victor Zhong',\n",
       "   'Ozan Irsoy',\n",
       "   'Mohit Iyyer',\n",
       "   'James Bradbury',\n",
       "   'Ankit Kumar',\n",
       "   'Peter Ondruska',\n",
       "   'Ishaan Gulrajani'],\n",
       "  'published': '2015-06-24T08:27:02Z',\n",
       "  'updated': '2016-03-05T20:18:55Z',\n",
       "  'abstract': \"Most tasks in natural language processing can be cast into question answering(QA) problems over language input. We introduce the dynamic memory network(DMN), a neural network architecture which processes input sequences andquestions, forms episodic memories, and generates relevant answers. Questionstrigger an iterative attention process which allows the model to condition itsattention on the inputs and the result of previous iterations. These resultsare then reasoned over in a hierarchical recurrent sequence model to generateanswers. The DMN can be trained end-to-end and obtains state-of-the-art resultson several types of tasks and datasets: question answering (Facebook's bAbIdataset), text classification for sentiment analysis (Stanford SentimentTreebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). Thetraining for these different tasks relies exclusively on trained word vectorrepresentations and input-question-answer triplets.\",\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 1378-1387',\n",
       "  'citations': '867',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.07285v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7594599060018037557&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 502: {'ID': 502,\n",
       "  'title': 'Convolutional Sequence to Sequence Learning',\n",
       "  'authors': ['Michael Auli',\n",
       "   'David Grangier',\n",
       "   'Yann N. Dauphin',\n",
       "   'Denis Yarats',\n",
       "   'Jonas Gehring'],\n",
       "  'published': '2017-05-08T23:25:30Z',\n",
       "  'updated': '2017-07-25T01:40:57Z',\n",
       "  'abstract': \"The prevalent approach to sequence to sequence learning maps an inputsequence to a variable length output sequence via recurrent neural networks. Weintroduce an architecture based entirely on convolutional neural networks.Compared to recurrent models, computations over all elements can be fullyparallelized during training and optimization is easier since the number ofnon-linearities is fixed and independent of the input length. Our use of gatedlinear units eases gradient propagation and we equip each decoder layer with aseparate attention module. We outperform the accuracy of the deep LSTM setup ofWu et al. (2016) on both WMT'14 English-German and WMT'14 English-Frenchtranslation at an order of magnitude faster speed, both on GPU and CPU.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICML, 1243-1252',\n",
       "  'citations': '1529',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.03122v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9032432574575787905&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 503: {'ID': 503,\n",
       "  'title': 'Texture Networks: Feed-forward Synthesis of Textures and Stylized Images',\n",
       "  'authors': ['Vadim Lebedev',\n",
       "   'Andrea Vedaldi',\n",
       "   'Victor Lempitsky',\n",
       "   'Dmitry Ulyanov'],\n",
       "  'published': '2016-03-10T20:45:40Z',\n",
       "  'updated': '2016-03-10T20:45:40Z',\n",
       "  'abstract': 'Gatys et al. recently demonstrated that deep networks can generate beautifultextures and stylized images from a single texture example. However, theirmethods requires a slow and memory-consuming optimization process. We proposehere an alternative approach that moves the computational burden to a learningstage. Given a single example of a texture, our approach trains compactfeed-forward convolutional networks to generate multiple samples of the sametexture of arbitrary size and to transfer artistic style from a given image toany other image. The resulting networks are remarkably light-weight and cangenerate textures of quality comparable to Gatys~et~al., but hundreds of timesfaster. More generally, our approach highlights the power and flexibility ofgenerative feed-forward models trained with complex and expressive lossfunctions.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 1349-1357',\n",
       "  'citations': '488',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.03417v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5452588382099665760&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 504: {'ID': 504,\n",
       "  'title': 'Parseval Networks: Improving Robustness to Adversarial Examples',\n",
       "  'authors': ['Moustapha Cisse',\n",
       "   'Yann Dauphin',\n",
       "   'Piotr Bojanowski',\n",
       "   'Edouard Grave',\n",
       "   'Nicolas Usunier'],\n",
       "  'published': '2017-04-28T08:43:55Z',\n",
       "  'updated': '2017-05-02T01:11:21Z',\n",
       "  'abstract': 'We introduce Parseval networks, a form of deep neural networks in which theLipschitz constant of linear, convolutional and aggregation layers isconstrained to be smaller than 1. Parseval networks are empirically andtheoretically motivated by an analysis of the robustness of the predictionsmade by deep neural networks when their input is subject to an adversarialperturbation. The most important feature of Parseval networks is to maintainweight matrices of linear and convolutional layers to be (approximately)Parseval tight frames, which are extensions of orthogonal matrices tonon-square matrices. We describe how these constraints can be maintainedefficiently during SGD. We show that Parseval networks match thestate-of-the-art in terms of accuracy on CIFAR-10/100 and Street View HouseNumbers (SVHN) while being more robust than their vanilla counterpart againstadversarial examples. Incidentally, Parseval networks also tend to train fasterand make a better usage of the full capacity of the networks.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.CR', 'cs.LG'],\n",
       "  'journal': 'ICML, 854-863',\n",
       "  'citations': '329',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.08847v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11979400639430622244&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 505: {'ID': 505,\n",
       "  'title': 'Addressing Function Approximation Error in Actor-Critic Methods',\n",
       "  'authors': ['Herke van Hoof', 'Scott Fujimoto', 'David Meger'],\n",
       "  'published': '2018-02-26T17:54:49Z',\n",
       "  'updated': '2018-10-22T17:37:07Z',\n",
       "  'abstract': 'In value-based reinforcement learning methods such as deep Q-learning,function approximation errors are known to lead to overestimated valueestimates and suboptimal policies. We show that this problem persists in anactor-critic setting and propose novel mechanisms to minimize its effects onboth the actor and the critic. Our algorithm builds on Double Q-learning, bytaking the minimum value between a pair of critics to limit overestimation. Wedraw the connection between target networks and overestimation bias, andsuggest delaying policy updates to reduce per-update error and further improveperformance. We evaluate our method on the suite of OpenAI gym tasks,outperforming the state of the art in every environment tested.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 1582-1591',\n",
       "  'citations': '389',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.09477v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2930747733592680111&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 506: {'ID': 506,\n",
       "  'title': 'How Does Batch Normalization Help Optimization?',\n",
       "  'authors': ['Aleksander Madry',\n",
       "   'Andrew Ilyas',\n",
       "   'Shibani Santurkar',\n",
       "   'Dimitris Tsipras'],\n",
       "  'published': '2018-05-29T17:42:00Z',\n",
       "  'updated': '2019-04-15T02:34:55Z',\n",
       "  'abstract': 'Batch Normalization (BatchNorm) is a widely adopted technique that enablesfaster and more stable training of deep neural networks (DNNs). Despite itspervasiveness, the exact reasons for BatchNorm\\'s effectiveness are still poorlyunderstood. The popular belief is that this effectiveness stems fromcontrolling the change of the layers\\' input distributions during training toreduce the so-called \"internal covariate shift\". In this work, we demonstratethat such distributional stability of layer inputs has little to do with thesuccess of BatchNorm. Instead, we uncover a more fundamental impact ofBatchNorm on the training process: it makes the optimization landscapesignificantly smoother. This smoothness induces a more predictive and stablebehavior of the gradients, allowing for faster training.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '255',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.11604v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9444562420324395093&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 507: {'ID': 507,\n",
       "  'title': 'Noisy Networks for Exploration',\n",
       "  'authors': ['Demis Hassabis',\n",
       "   'Alex Graves',\n",
       "   'Mohammad Gheshlaghi Azar',\n",
       "   'Shane Legg',\n",
       "   'Charles Blundell',\n",
       "   'Ian Osband',\n",
       "   'Remi Munos',\n",
       "   'Olivier Pietquin',\n",
       "   'Jacob Menick',\n",
       "   'Meire Fortunato',\n",
       "   'Bilal Piot',\n",
       "   'Vlad Mnih'],\n",
       "  'published': '2017-06-30T17:56:19Z',\n",
       "  'updated': '2019-07-09T09:57:23Z',\n",
       "  'abstract': \"We introduce NoisyNet, a deep reinforcement learning agent with parametricnoise added to its weights, and show that the induced stochasticity of theagent's policy can be used to aid efficient exploration. The parameters of thenoise are learned with gradient descent along with the remaining networkweights. NoisyNet is straightforward to implement and adds little computationaloverhead. We find that replacing the conventional exploration heuristics forA3C, DQN and dueling agents (entropy reward and $\\\\epsilon$-greedy respectively)with NoisyNet yields substantially higher scores for a wide range of Atarigames, in some cases advancing the agent from sub to super-human performance.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '285',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.10295v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13916735202249031707&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 508: {'ID': 508,\n",
       "  'title': 'Order-Embeddings of Images and Language',\n",
       "  'authors': ['Ryan Kiros', 'Ivan Vendrov', 'Raquel Urtasun', 'Sanja Fidler'],\n",
       "  'published': '2015-11-19T20:56:14Z',\n",
       "  'updated': '2016-03-01T08:23:50Z',\n",
       "  'abstract': 'Hypernymy, textual entailment, and image captioning can be seen as specialcases of a single visual-semantic hierarchy over words, sentences, and images.In this paper we advocate for explicitly modeling the partial order structureof this hierarchy. Towards this goal, we introduce a general method forlearning ordered representations, and show how it can be applied to a varietyof tasks involving images and language. We show that the resultingrepresentations improve performance over current approaches for hypernymprediction and image-caption retrieval.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.CV'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '332',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06361v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13175166350768143063&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 509: {'ID': 509,\n",
       "  'title': 'Return of Frustratingly Easy Domain Adaptation',\n",
       "  'authors': ['Kate Saenko', 'Jiashi Feng', 'Baochen Sun'],\n",
       "  'published': '2015-11-17T20:53:26Z',\n",
       "  'updated': '2015-12-09T05:39:43Z',\n",
       "  'abstract': 'Unlike human learning, machine learning often fails to handle changes betweentraining (source) and test (target) input distributions. Such domain shifts,common in practical scenarios, severely damage the performance of conventionalmachine learning methods. Supervised domain adaptation methods have beenproposed for the case when the target data have labels, including some thatperform very well despite being \"frustratingly easy\" to implement. However, inpractice, the target domain is often unlabeled, requiring unsupervisedadaptation. We propose a simple, effective, and efficient method forunsupervised domain adaptation called CORrelation ALignment (CORAL). CORALminimizes domain shift by aligning the second-order statistics of source andtarget distributions, without requiring any target labels. Even though it isextraordinarily simple--it can be implemented in four lines of Matlabcode--CORAL performs remarkably well in extensive evaluations on standardbenchmark datasets.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '574',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05547v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5209185556385462018&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 510: {'ID': 510,\n",
       "  'title': 'A note on the evaluation of generative models',\n",
       "  'authors': ['Matthias Bethge', 'Lucas Theis', 'Aäron van den Oord'],\n",
       "  'published': '2015-11-05T18:22:44Z',\n",
       "  'updated': '2016-04-24T20:03:35Z',\n",
       "  'abstract': 'Probabilistic generative models can be used for compression, denoising,inpainting, texture synthesis, semi-supervised learning, unsupervised featurelearning, and other tasks. Given this wide range of applications, it is notsurprising that a lot of heterogeneity exists in the way these models areformulated, trained, and evaluated. As a consequence, direct comparison betweenmodels is often difficult. This article reviews mostly known but oftenunderappreciated properties relating to the evaluation and interpretation ofgenerative models with a focus on image models. In particular, we show thatthree of the currently most commonly used criteria---average log-likelihood,Parzen window estimates, and visual fidelity of samples---are largelyindependent of each other when the data is high-dimensional. Good performancewith respect to one criterion therefore need not imply good performance withrespect to the other criteria. Our results show that extrapolation from onecriterion to another is not warranted and generative models need to beevaluated directly with respect to the application(s) they were intended for.In addition, we provide examples demonstrating that Parzen window estimatesshould generally be avoided.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '597',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.01844v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11726515919678318873&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 511: {'ID': 511,\n",
       "  'title': 'Adversarial Risk and the Dangers of Evaluating Against Weak Attacks',\n",
       "  'authors': ['Pushmeet Kohli',\n",
       "   'Jonathan Uesato',\n",
       "   \"Brendan O'Donoghue\",\n",
       "   'Aaron van den Oord'],\n",
       "  'published': '2018-02-15T17:13:18Z',\n",
       "  'updated': '2018-06-12T14:20:27Z',\n",
       "  'abstract': \"This paper investigates recently proposed approaches for defending againstadversarial examples and evaluating adversarial robustness. We motivate'adversarial risk' as an objective for achieving models robust to worst-caseinputs. We then frame commonly used attacks and evaluation metrics as defininga tractable surrogate objective to the true adversarial risk. This suggeststhat models may optimize this surrogate rather than the true adversarial risk.We formalize this notion as 'obscurity to an adversary,' and develop tools andheuristics for identifying obscured models and designing transparent models. Wedemonstrate that this is a significant problem in practice by repurposinggradient-free optimization techniques into adversarial attacks, which we use todecrease the accuracy of several recently proposed defenses to near zero. Ourhope is that our formulations and results will help researchers to develop morepowerful defenses.\",\n",
       "  'categories': ['cs.LG', 'cs.CR', 'stat.ML'],\n",
       "  'journal': 'ICML, 5032-5041',\n",
       "  'citations': '172',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.05666v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11987569658631907048&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 512: {'ID': 512,\n",
       "  'title': 'Learned in Translation: Contextualized Word Vectors',\n",
       "  'authors': ['James Bradbury',\n",
       "   'Richard Socher',\n",
       "   'Bryan McCann',\n",
       "   'Caiming Xiong'],\n",
       "  'published': '2017-08-01T00:05:34Z',\n",
       "  'updated': '2018-06-20T13:15:06Z',\n",
       "  'abstract': 'Computer vision has benefited from initializing multiple deep layers withweights pretrained on large supervised training sets like ImageNet. Naturallanguage processing (NLP) typically sees initialization of only the lowestlayer of deep models with pretrained word vectors. In this paper, we use a deepLSTM encoder from an attentional sequence-to-sequence model trained for machinetranslation (MT) to contextualize word vectors. We show that adding thesecontext vectors (CoVe) improves performance over using only unsupervised wordand character vectors on a wide variety of common NLP tasks: sentiment analysis(SST, IMDb), question classification (TREC), entailment (SNLI), and questionanswering (SQuAD). For fine-grained sentiment analysis and entailment, CoVeimproves performance of our baseline models to the state of the art.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '494',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.00107v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12356231721397988330&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 513: {'ID': 513,\n",
       "  'title': \"The Goldilocks Principle: Reading Children's Books with Explicit Memory  Representations\",\n",
       "  'authors': ['Antoine Bordes', 'Felix Hill', 'Jason Weston', 'Sumit Chopra'],\n",
       "  'published': '2015-11-07T04:36:20Z',\n",
       "  'updated': '2016-04-01T05:31:33Z',\n",
       "  'abstract': \"We introduce a new test of how well language models capture meaning inchildren's books. Unlike standard language modelling benchmarks, itdistinguishes the task of predicting syntactic function words from that ofpredicting lower-frequency words, which carry greater semantic content. Wecompare a range of state-of-the-art models, each with a different way ofencoding what has been previously read. We show that models which storeexplicit representations of long-term contexts outperform state-of-the-artneural language models at predicting semantic content words, although thisadvantage is not observed for syntactic function words. Interestingly, we findthat the amount of text encoded in a single memory representation is highlyinfluential to the performance: there is a sweet-spot, not too big and not toosmall, between single words and full sentences that allows the most meaningfulinformation in a text to be effectively retained and recalled. Further, theattention over such window-based memories can be trained effectively throughself-supervision. We then assess the generality of this principle by applyingit to the CNN QA benchmark, which involves identifying named entities inparaphrased summaries of news articles, and achieve state-of-the-artperformance.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '408',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.02301v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14633685640258770614&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 514: {'ID': 514,\n",
       "  'title': 'Spatial As Deep: Spatial CNN for Traffic Scene Understanding',\n",
       "  'authors': ['Xiaogang Wang',\n",
       "   'Xiaoou Tang',\n",
       "   'Jianping Shi',\n",
       "   'Ping Luo',\n",
       "   'Xingang Pan'],\n",
       "  'published': '2017-12-17T09:37:52Z',\n",
       "  'updated': '2017-12-17T09:37:52Z',\n",
       "  'abstract': 'Convolutional neural networks (CNNs) are usually built by stackingconvolutional operations layer-by-layer. Although CNN has shown strongcapability to extract semantics from raw pixels, its capacity to capturespatial relationships of pixels across rows and columns of an image is notfully explored. These relationships are important to learn semantic objectswith strong shape priors but weak appearance coherences, such as traffic lanes,which are often occluded or not even painted on the road surface as shown inFig. 1 (a). In this paper, we propose Spatial CNN (SCNN), which generalizestraditional deep layer-by-layer convolutions to slice-byslice convolutionswithin feature maps, thus enabling message passings between pixels across rowsand columns in a layer. Such SCNN is particular suitable for long continuousshape structure or large objects, with strong spatial relationship but lessappearance clues, such as traffic lanes, poles, and wall. We apply SCNN on anewly released very challenging traffic lane detection dataset and Cityscapsedataset. The results show that SCNN could learn the spatial relationship forstructure output and significantly improves the performance. We show that SCNNoutperforms the recurrent neural network (RNN) based ReNet and MRF+CNN (MRFNet)in the lane detection dataset by 8.7% and 4.6% respectively. Moreover, our SCNNwon the 1st place on the TuSimple Benchmark Lane Detection Challenge, with anaccuracy of 96.53%.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '129',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.06080v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7356833526698200169&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 515: {'ID': 515,\n",
       "  'title': 'VIME: Variational Information Maximizing Exploration',\n",
       "  'authors': ['Rein Houthooft',\n",
       "   'Xi Chen',\n",
       "   'Yan Duan',\n",
       "   'Pieter Abbeel',\n",
       "   'John Schulman',\n",
       "   'Filip De Turck'],\n",
       "  'published': '2016-05-31T15:34:36Z',\n",
       "  'updated': '2017-01-27T09:26:28Z',\n",
       "  'abstract': \"Scalable and effective exploration remains a key challenge in reinforcementlearning (RL). While there are methods with optimality guarantees in thesetting of discrete state and action spaces, these methods cannot be applied inhigh-dimensional deep RL scenarios. As such, most contemporary RL relies onsimple heuristics such as epsilon-greedy exploration or adding Gaussian noiseto the controls. This paper introduces Variational Information MaximizingExploration (VIME), an exploration strategy based on maximization ofinformation gain about the agent's belief of environment dynamics. We propose apractical implementation, using variational inference in Bayesian neuralnetworks which efficiently handles continuous state and action spaces. VIMEmodifies the MDP reward function, and can be applied with several differentunderlying RL algorithms. We demonstrate that VIME achieves significantlybetter performance compared to heuristic exploration methods across a varietyof continuous control tasks and algorithms, including tasks with very sparserewards.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '313',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.09674v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4965361873864842159&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 516: {'ID': 516,\n",
       "  'title': 'A Unified Approach to Interpreting Model Predictions',\n",
       "  'authors': ['Su-In Lee', 'Scott Lundberg'],\n",
       "  'published': '2017-05-22T17:38:10Z',\n",
       "  'updated': '2017-11-25T03:53:32Z',\n",
       "  'abstract': \"Understanding why a model makes a certain prediction can be as crucial as theprediction's accuracy in many applications. However, the highest accuracy forlarge modern datasets is often achieved by complex models that even expertsstruggle to interpret, such as ensemble or deep learning models, creating atension between accuracy and interpretability. In response, various methodshave recently been proposed to help users interpret the predictions of complexmodels, but it is often unclear how these methods are related and when onemethod is preferable over another. To address this problem, we present aunified framework for interpreting predictions, SHAP (SHapley AdditiveexPlanations). SHAP assigns each feature an importance value for a particularprediction. Its novel components include: (1) the identification of a new classof additive feature importance measures, and (2) theoretical results showingthere is a unique solution in this class with a set of desirable properties.The new class unifies six existing methods, notable because several recentmethods in the class lack the proposed desirable properties. Based on insightsfrom this unification, we present new methods that show improved computationalperformance and/or better consistency with human intuition than previousapproaches.\",\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1229',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.07874v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6828961408019591083&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 517: {'ID': 517,\n",
       "  'title': 'Self-Normalizing Neural Networks',\n",
       "  'authors': ['Andreas Mayr',\n",
       "   'Sepp Hochreiter',\n",
       "   'Günter Klambauer',\n",
       "   'Thomas Unterthiner'],\n",
       "  'published': '2017-06-08T11:14:24Z',\n",
       "  'updated': '2017-09-07T10:39:00Z',\n",
       "  'abstract': 'Deep Learning has revolutionized vision via convolutional neural networks(CNNs) and natural language processing via recurrent neural networks (RNNs).However, success stories of Deep Learning with standard feed-forward neuralnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,therefore cannot exploit many levels of abstract representations. We introduceself-normalizing neural networks (SNNs) to enable high-level abstractrepresentations. While batch normalization requires explicit normalization,neuron activations of SNNs automatically converge towards zero mean and unitvariance. The activation function of SNNs are \"scaled exponential linear units\"(SELUs), which induce self-normalizing properties. Using the Banach fixed-pointtheorem, we prove that activations close to zero mean and unit variance thatare propagated through many network layers will converge towards zero mean andunit variance -- even under the presence of noise and perturbations. Thisconvergence property of SNNs allows to (1) train deep networks with manylayers, (2) employ strong regularization, and (3) to make learning highlyrobust. Furthermore, for activations not close to unit variance, we prove anupper and lower bound on the variance, thus, vanishing and exploding gradientsare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learningrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks withstandard FNNs and other machine learning methods such as random forests andsupport vector machines. SNNs significantly outperformed all competing FNNmethods at 121 UCI tasks, outperformed all competing methods at the Tox21dataset, and set a new record at an astronomy data set. The winning SNNarchitectures are often very deep. Implementations are available at:github.com/bioinf-jku/SNNs.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '963',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02515v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3659160383490046744&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 518: {'ID': 518,\n",
       "  'title': 'Energy-based Generative Adversarial Network',\n",
       "  'authors': ['Michael Mathieu', 'Yann LeCun', 'Junbo Zhao'],\n",
       "  'published': '2016-09-11T07:11:13Z',\n",
       "  'updated': '2017-03-06T22:52:53Z',\n",
       "  'abstract': 'We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)which views the discriminator as an energy function that attributes lowenergies to the regions near the data manifold and higher energies to otherregions. Similar to the probabilistic GANs, a generator is seen as beingtrained to produce contrastive samples with minimal energies, while thediscriminator is trained to assign high energies to these generated samples.Viewing the discriminator as an energy function allows to use a wide variety ofarchitectures and loss functionals in addition to the usual binary classifierwith logistic output. Among them, we show one instantiation of EBGAN frameworkas using an auto-encoder architecture, with the energy being the reconstructionerror, in place of the discriminator. We show that this form of EBGAN exhibitsmore stable behavior than regular GANs during training. We also show that asingle-scale architecture can be trained to generate high-resolution images.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '770',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.03126v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15426746467469595309&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 519: {'ID': 519,\n",
       "  'title': 'Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation',\n",
       "  'authors': ['Hyeonwoo Noh', 'Bohyung Han', 'Seunghoon Hong'],\n",
       "  'published': '2015-06-16T11:20:04Z',\n",
       "  'updated': '2015-06-17T08:38:32Z',\n",
       "  'abstract': 'We propose a novel deep neural network architecture for semi-supervisedsemantic segmentation using heterogeneous annotations. Contrary to existingapproaches posing semantic segmentation as a single task of region-basedclassification, our algorithm decouples classification and segmentation, andlearns a separate network for each task. In this architecture, labelsassociated with an image are identified by classification network, and binarysegmentation is subsequently performed for each identified label insegmentation network. The decoupled architecture enables us to learnclassification and segmentation networks separately based on the training datawith image-level and pixel-wise class labels, respectively. It facilitates toreduce search space for segmentation effectively by exploiting class-specificactivation maps obtained from bridging layers. Our algorithm shows outstandingperformance compared to other semi-supervised approaches even with much lesstraining images with strong annotations in PASCAL VOC dataset.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '254',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.04924v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15385340253531275638&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 520: {'ID': 520,\n",
       "  'title': 'Pruning Filters for Efficient ConvNets',\n",
       "  'authors': ['Hanan Samet',\n",
       "   'Hans Peter Graf',\n",
       "   'Hao Li',\n",
       "   'Asim Kadav',\n",
       "   'Igor Durdanovic'],\n",
       "  'published': '2016-08-31T02:29:59Z',\n",
       "  'updated': '2017-03-10T17:57:56Z',\n",
       "  'abstract': 'The success of CNNs in various applications is accompanied by a significantincrease in the computation and parameter storage costs. Recent efforts towardreducing these overheads involve pruning and compressing the weights of variouslayers without hurting original accuracy. However, magnitude-based pruning ofweights reduces a significant number of parameters from the fully connectedlayers and may not adequately reduce the computation costs in the convolutionallayers due to irregular sparsity in the pruned networks. We present anacceleration method for CNNs, where we prune filters from CNNs that areidentified as having a small effect on the output accuracy. By removing wholefilters in the network together with their connecting feature maps, thecomputation costs are reduced significantly. In contrast to pruning weights,this approach does not result in sparse connectivity patterns. Hence, it doesnot need the support of sparse convolution libraries and can work with existingefficient BLAS libraries for dense matrix multiplications. We show that evensimple filter pruning techniques can reduce inference costs for VGG-16 by up to34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to theoriginal accuracy by retraining the networks.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '1073',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.08710v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10756249335825111134&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 521: {'ID': 521,\n",
       "  'title': 'Continual Learning with Deep Generative Replay',\n",
       "  'authors': ['Jung Kwon Lee', 'Jiwon Kim', 'Jaehong Kim', 'Hanul Shin'],\n",
       "  'published': '2017-05-24T10:37:38Z',\n",
       "  'updated': '2017-12-12T02:14:21Z',\n",
       "  'abstract': 'Attempts to train a comprehensive artificial intelligence capable of solvingmultiple tasks have been impeded by a chronic problem called catastrophicforgetting. Although simply replaying all previous data alleviates the problem,it requires large memory and even worse, often infeasible in real worldapplications where the access to past data is limited. Inspired by thegenerative nature of hippocampus as a short-term memory system in primatebrain, we propose the Deep Generative Replay, a novel framework with acooperative dual model architecture consisting of a deep generative model(\"generator\") and a task solving model (\"solver\"). With only these two models,training data for previous tasks can easily be sampled and interleaved withthose for a new task. We test our methods in several sequential learningsettings involving image classification tasks.',\n",
       "  'categories': ['cs.AI', 'cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '264',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08690v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5696060555916548471&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 522: {'ID': 522,\n",
       "  'title': 'On the Expressive Power of Deep Neural Networks',\n",
       "  'authors': ['Ben Poole',\n",
       "   'Maithra Raghu',\n",
       "   'Jon Kleinberg',\n",
       "   'Jascha Sohl-Dickstein',\n",
       "   'Surya Ganguli'],\n",
       "  'published': '2016-06-16T19:55:29Z',\n",
       "  'updated': '2017-06-18T13:24:34Z',\n",
       "  'abstract': 'We propose a new approach to the problem of neural network expressivity,which seeks to characterize how structural properties of a neural networkfamily affect the functions it is able to compute. Our approach is based on aninterrelated set of measures of expressivity, unified by the novel notion oftrajectory length, which measures how the output of a network changes as theinput sweeps along a one-dimensional path. Our findings can be summarized asfollows:  (1) The complexity of the computed function grows exponentially with depth.  (2) All weights are not equal: trained networks are more sensitive to theirlower (initial) layer weights.  (3) Regularizing on trajectory length (trajectory regularization) is asimpler alternative to batch normalization, with the same performance.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICML, 2847-2854',\n",
       "  'citations': '309',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.05336v6',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12198207364825963041&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 523: {'ID': 523,\n",
       "  'title': 'On Large-Batch Training for Deep Learning: Generalization Gap and Sharp  Minima',\n",
       "  'authors': ['Dheevatsa Mudigere',\n",
       "   'Mikhail Smelyanskiy',\n",
       "   'Nitish Shirish Keskar',\n",
       "   'Ping Tak Peter Tang',\n",
       "   'Jorge Nocedal'],\n",
       "  'published': '2016-09-15T20:03:06Z',\n",
       "  'updated': '2017-02-09T20:38:16Z',\n",
       "  'abstract': 'The stochastic gradient descent (SGD) method and its variants are algorithmsof choice for many Deep Learning tasks. These methods operate in a small-batchregime wherein a fraction of the training data, say $32$-$512$ data points, issampled to compute an approximation to the gradient. It has been observed inpractice that when using a larger batch there is a degradation in the qualityof the model, as measured by its ability to generalize. We investigate thecause for this generalization drop in the large-batch regime and presentnumerical evidence that supports the view that large-batch methods tend toconverge to sharp minimizers of the training and testing functions - and as iswell known, sharp minima lead to poorer generalization. In contrast,small-batch methods consistently converge to flat minimizers, and ourexperiments support a commonly held view that this is due to the inherent noisein the gradient estimation. We discuss several strategies to attempt to helplarge-batch methods eliminate this generalization gap.',\n",
       "  'categories': ['cs.LG', 'math.OC'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '943',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.04836v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2526562489715623205&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 524: {'ID': 524,\n",
       "  'title': 'Multiresolution Recurrent Neural Networks: An Application to Dialogue  Response Generation',\n",
       "  'authors': ['Gerald Tesauro',\n",
       "   'Aaron Courville',\n",
       "   'Kartik Talamadupula',\n",
       "   'Iulian Vlad Serban',\n",
       "   'Tim Klinger',\n",
       "   'Yoshua Bengio',\n",
       "   'Bowen Zhou'],\n",
       "  'published': '2016-06-02T17:37:31Z',\n",
       "  'updated': '2016-06-14T02:01:16Z',\n",
       "  'abstract': 'We introduce the multiresolution recurrent neural network, which extends thesequence-to-sequence framework to model natural language generation as twoparallel discrete stochastic processes: a sequence of high-level coarse tokens,and a sequence of natural language tokens. There are many ways to estimate orlearn the high-level coarse tokens, but we argue that a simple extractionprocedure is sufficient to capture a wealth of high-level discourse semantics.Such procedure allows training the multiresolution recurrent neural network bymaximizing the exact joint log-likelihood over both sequences. In contrast tothe standard log- likelihood objective w.r.t. natural language tokens (wordperplexity), optimizing the joint log-likelihood biases the model towardsmodeling high-level abstractions. We apply the proposed model to the task ofdialogue response generation in two challenging domains: the Ubuntu technicalsupport domain, and Twitter conversations. On Ubuntu, the model outperformscompeting approaches by a substantial margin, achieving state-of-the-artresults according to both automatic evaluation metrics and a human evaluationstudy. On Twitter, the model appears to generate more relevant and on-topicresponses according to automatic evaluation metrics. Finally, our experimentsdemonstrate that the proposed model is more adept at overcoming the sparsity ofnatural language and is better able to capture long-term structure.',\n",
       "  'categories': ['cs.CL',\n",
       "   'cs.AI',\n",
       "   'cs.LG',\n",
       "   'cs.NE',\n",
       "   'stat.ML',\n",
       "   'I.5.1; I.2.7'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '147',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.00776v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4269931547013111900&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 525: {'ID': 525,\n",
       "  'title': 'Particular object retrieval with integral max-pooling of CNN activations',\n",
       "  'authors': ['Hervé Jégou', 'Giorgos Tolias', 'Ronan Sicre'],\n",
       "  'published': '2015-11-18T17:02:59Z',\n",
       "  'updated': '2016-02-24T15:14:34Z',\n",
       "  'abstract': 'Recently, image representation built upon Convolutional Neural Network (CNN)has been shown to provide effective descriptors for image search, outperformingpre-CNN features as short-vector representations. Yet such models are notcompatible with geometry-aware re-ranking methods and still outperformed, onsome particular object retrieval benchmarks, by traditional image searchsystems relying on precise descriptor matching, geometric re-ranking, or queryexpansion. This work revisits both retrieval stages, namely initial search andre-ranking, by employing the same primitive information derived from the CNN.We build compact feature vectors that encode several image regions without theneed to feed multiple inputs to the network. Furthermore, we extend integralimages to handle max-pooling on convolutional layer activations, allowing us toefficiently localize matching objects. The resulting bounding box is finallyused for image re-ranking. As a result, this paper significantly improvesexisting CNN-based recognition pipeline: We report for the first time resultscompeting with traditional methods on the challenging Oxford5k and Paris6kdatasets.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '535',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05879v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2928499544278774292&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 526: {'ID': 526,\n",
       "  'title': 'Learning to Navigate in Complex Environments',\n",
       "  'authors': ['Misha Denil',\n",
       "   'Raia Hadsell',\n",
       "   'Fabio Viola',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Andrew J. Ballard',\n",
       "   'Hubert Soyer',\n",
       "   'Ross Goroshin',\n",
       "   'Laurent Sifre',\n",
       "   'Razvan Pascanu',\n",
       "   'Andrea Banino',\n",
       "   'Dharshan Kumaran',\n",
       "   'Piotr Mirowski'],\n",
       "  'published': '2016-11-11T12:14:45Z',\n",
       "  'updated': '2017-01-13T11:15:22Z',\n",
       "  'abstract': 'Learning to navigate in complex environments with dynamic elements is animportant milestone in developing AI agents. In this work we formulate thenavigation question as a reinforcement learning problem and show that dataefficiency and task performance can be dramatically improved by relying onadditional auxiliary tasks leveraging multimodal sensory inputs. In particularwe consider jointly learning the goal-driven reinforcement learning problemwith auxiliary depth prediction and loop closure classification tasks. Thisapproach can learn to navigate from raw sensory input in complicated 3D mazes,approaching human-level performance even under conditions where the goallocation changes frequently. We provide detailed analysis of the agentbehaviour, its ability to localise, and its network activity dynamics, showingthat the agent implicitly learns key navigation abilities.',\n",
       "  'categories': ['cs.AI', 'cs.CV', 'cs.LG', 'cs.RO'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '411',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.03673v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17642659027854201917&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 527: {'ID': 527,\n",
       "  'title': 'Paying More Attention to Attention: Improving the Performance of  Convolutional Neural Networks via Attention Transfer',\n",
       "  'authors': ['Sergey Zagoruyko', 'Nikos Komodakis'],\n",
       "  'published': '2016-12-12T21:15:57Z',\n",
       "  'updated': '2017-02-12T22:05:47Z',\n",
       "  'abstract': 'Attention plays a critical role in human visual experience. Furthermore, ithas recently been demonstrated that attention can also play an important rolein the context of applying artificial neural networks to a variety of tasksfrom fields such as computer vision and NLP. In this work we show that, byproperly defining attention for convolutional neural networks, we can actuallyuse this type of information in order to significantly improve the performanceof a student CNN network by forcing it to mimic the attention maps of apowerful teacher network. To that end, we propose several novel methods oftransferring attention, showing consistent improvement across a variety ofdatasets and convolutional neural network architectures. Code and models forour experiments are available athttps://github.com/szagoruyko/attention-transfer',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '380',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.03928v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8439472615885524081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 528: {'ID': 528,\n",
       "  'title': 'EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks',\n",
       "  'authors': ['Quoc V. Le', 'Mingxing Tan'],\n",
       "  'published': '2019-05-28T17:05:32Z',\n",
       "  'updated': '2020-09-11T05:08:01Z',\n",
       "  'abstract': 'Convolutional Neural Networks (ConvNets) are commonly developed at a fixedresource budget, and then scaled up for better accuracy if more resources areavailable. In this paper, we systematically study model scaling and identifythat carefully balancing network depth, width, and resolution can lead tobetter performance. Based on this observation, we propose a new scaling methodthat uniformly scales all dimensions of depth/width/resolution using a simpleyet highly effective compound coefficient. We demonstrate the effectiveness ofthis method on scaling up MobileNets and ResNet.  To go even further, we use neural architecture search to design a newbaseline network and scale it up to obtain a family of models, calledEfficientNets, which achieve much better accuracy and efficiency than previousConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3%top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster oninference than the best existing ConvNet. Our EfficientNets also transfer welland achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%),and 3 other transfer learning datasets, with an order of magnitude fewerparameters. Source code is athttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICML, 6105-6114',\n",
       "  'citations': '535',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.11946v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5472015514843683656&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 529: {'ID': 529,\n",
       "  'title': 'No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified  Geometric Analysis',\n",
       "  'authors': ['Yi Zheng', 'Chi Jin', 'Rong Ge'],\n",
       "  'published': '2017-04-03T17:49:02Z',\n",
       "  'updated': '2017-04-03T17:49:02Z',\n",
       "  'abstract': 'In this paper we develop a new framework that captures the common landscapeunderlying the common non-convex low-rank matrix problems including matrixsensing, matrix completion and robust PCA. In particular, we show for all aboveproblems (including asymmetric cases): 1) all local minima are also globallyoptimal; 2) no high-order saddle points exists. These results explain whysimple algorithms such as stochastic gradient descent have global converge, andefficiently optimize these non-convex objective functions in practice. Ourframework connects and simplifies the existing analyses on optimizationlandscapes for matrix sensing and symmetric matrix completion. The frameworknaturally leads to new results for asymmetric matrix completion and robust PCA.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 1233-1242',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1704.00708v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7908586163390330077&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 530: {'ID': 530,\n",
       "  'title': 'Global Optimality of Local Search for Low Rank Matrix Recovery',\n",
       "  'authors': ['Srinadh Bhojanapalli', 'Behnam Neyshabur', 'Nathan Srebro'],\n",
       "  'published': '2016-05-23T22:05:42Z',\n",
       "  'updated': '2016-05-27T00:54:17Z',\n",
       "  'abstract': 'We show that there are no spurious local minima in the non-convex factorizedparametrization of low-rank matrix recovery from incoherent linearmeasurements. With noisy measurements we show all local minima are very closeto a global optimum. Together with a curvature bound at saddle points, thisyields a polynomial time global convergence guarantee for stochastic gradientdescent {\\\\em from random initialization}.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'math.OC'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '248',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07221v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13377495735395555335&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 531: {'ID': 531,\n",
       "  'title': 'Semi-Supervised Learning with Ladder Networks',\n",
       "  'authors': ['Harri Valpola',\n",
       "   'Mikko Honkala',\n",
       "   'Antti Rasmus',\n",
       "   'Tapani Raiko',\n",
       "   'Mathias Berglund'],\n",
       "  'published': '2015-07-09T19:52:19Z',\n",
       "  'updated': '2015-11-24T09:22:23Z',\n",
       "  'abstract': 'We combine supervised learning with unsupervised learning in deep neuralnetworks. The proposed model is trained to simultaneously minimize the sum ofsupervised and unsupervised cost functions by backpropagation, avoiding theneed for layer-wise pre-training. Our work builds on the Ladder networkproposed by Valpola (2015), which we extend by combining the model withsupervision. We show that the resulting model reaches state-of-the-artperformance in semi-supervised MNIST and CIFAR-10 classification, in additionto permutation-invariant MNIST classification with all labels.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '802',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.02672v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8134619000009445277&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 532: {'ID': 532,\n",
       "  'title': 'Pixel Recurrent Neural Networks',\n",
       "  'authors': ['Koray Kavukcuoglu', 'Nal Kalchbrenner', 'Aaron van den Oord'],\n",
       "  'published': '2016-01-25T20:34:24Z',\n",
       "  'updated': '2016-08-19T14:10:16Z',\n",
       "  'abstract': 'Modeling the distribution of natural images is a landmark problem inunsupervised learning. This task requires an image model that is at onceexpressive, tractable and scalable. We present a deep neural network thatsequentially predicts the pixels in an image along the two spatial dimensions.Our method models the discrete probability of the raw pixel values and encodesthe complete set of dependencies in the image. Architectural novelties includefast two-dimensional recurrent layers and an effective use of residualconnections in deep recurrent networks. We achieve log-likelihood scores onnatural images that are considerably better than the previous state of the art.Our main results also provide benchmarks on the diverse ImageNet dataset.Samples generated from the model appear crisp, varied and globally coherent.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 1747-1756',\n",
       "  'citations': '1098',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1601.06759v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13078391055138994928&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 533: {'ID': 533,\n",
       "  'title': 'All you need is a good init',\n",
       "  'authors': ['Dmytro Mishkin', 'Jiri Matas'],\n",
       "  'published': '2015-11-19T22:19:15Z',\n",
       "  'updated': '2016-02-19T14:37:10Z',\n",
       "  'abstract': 'Layer-sequential unit-variance (LSUV) initialization - a simple method forweight initialization for deep net learning - is proposed. The method consistsof the two steps. First, pre-initialize weights of each convolution orinner-product layer with orthonormal matrices. Second, proceed from the firstto the final layer, normalizing the variance of the output of each layer to beequal to one.  Experiment with different activation functions (maxout, ReLU-family, tanh)show that the proposed initialization leads to learning of very deep nets that(i) produces networks with test accuracy better or equal to standard methodsand (ii) is at least as fast as the complex schemes proposed specifically forvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastavaet al. (2015)).  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual netsand the state-of-the-art, or very close to it, is achieved on the MNIST,CIFAR-10/100 and ImageNet datasets.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '373',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06422v7',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6062006264661009371&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 534: {'ID': 534,\n",
       "  'title': 'Embedding Entities and Relations for Learning and Inference in Knowledge  Bases',\n",
       "  'authors': ['Bishan Yang',\n",
       "   'Wen-tau Yih',\n",
       "   'Li Deng',\n",
       "   'Jianfeng Gao',\n",
       "   'Xiaodong He'],\n",
       "  'published': '2014-12-20T01:37:16Z',\n",
       "  'updated': '2015-08-29T15:08:45Z',\n",
       "  'abstract': 'We consider learning representations of entities and relations in KBs usingthe neural-embedding approach. We show that most existing models, including NTN(Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalizedunder a unified learning framework, where entities are low-dimensional vectorslearned from a neural network and relations are bilinear and/or linear mappingfunctions. Under this framework, we compare a variety of embedding models onthe link prediction task. We show that a simple bilinear formulation achievesnew state-of-the-art results for the task (achieving a top-10 accuracy of 73.2%vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approachthat utilizes the learned relation embeddings to mine logical rules such as\"BornInCity(a,b) and CityInCountry(b,c) =&gt; Nationality(a,c)\". We find thatembeddings learned from the bilinear objective are particularly good atcapturing relational semantics and that the composition of relations ischaracterized by matrix multiplication. More interestingly, we demonstrate thatour embedding-based rule extraction approach successfully outperforms astate-of-the-art confidence-based rule mining approach in mining Horn rulesthat involve compositional reasoning.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '669',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1412.6575v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14658345583368412090&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 535: {'ID': 535,\n",
       "  'title': 'Interpretability Beyond Feature Attribution: Quantitative Testing with  Concept Activation Vectors (TCAV)',\n",
       "  'authors': ['James Wexler',\n",
       "   'Justin Gilmer',\n",
       "   'Fernanda Viegas',\n",
       "   'Rory Sayres',\n",
       "   'Martin Wattenberg',\n",
       "   'Carrie Cai',\n",
       "   'Been Kim'],\n",
       "  'published': '2017-11-30T09:26:12Z',\n",
       "  'updated': '2018-06-07T04:33:27Z',\n",
       "  'abstract': 'The interpretation of deep learning models is a challenge due to their size,complexity, and often opaque internal state. In addition, many systems, such asimage classifiers, operate on low-level features rather than high-levelconcepts. To address these challenges, we introduce Concept Activation Vectors(CAVs), which provide an interpretation of a neural net\\'s internal state interms of human-friendly concepts. The key idea is to view the high-dimensionalinternal state of a neural net as an aid, not an obstacle. We show how to useCAVs as part of a technique, Testing with CAVs (TCAV), that uses directionalderivatives to quantify the degree to which a user-defined concept is importantto a classification result--for example, how sensitive a prediction of \"zebra\"is to the presence of stripes. Using the domain of image classification as atesting ground, we describe how CAVs may be used to explore hypotheses andgenerate insights for a standard image classification network as well as amedical application.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'ICML, 2673-2682',\n",
       "  'citations': '189',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.11279v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9394087570430993813&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 536: {'ID': 536,\n",
       "  'title': 'DISC: Deep Image Saliency Computing via Progressive Representation  Learning',\n",
       "  'authors': ['Lingbo Liu',\n",
       "   'Xiaonan Luo',\n",
       "   'Liang Lin',\n",
       "   'Tianshui Chen',\n",
       "   'Xuelong Li'],\n",
       "  'published': '2015-11-13T07:14:13Z',\n",
       "  'updated': '2015-12-10T13:11:23Z',\n",
       "  'abstract': 'Salient object detection increasingly receives attention as an importantcomponent or step in several pattern recognition and image processing tasks.Although a variety of powerful saliency models have been intensively proposed,they usually involve heavy feature (or model) engineering based on priors (orassumptions) about the properties of objects and backgrounds. Inspired by theeffectiveness of recently developed feature learning, we provide a novel DeepImage Saliency Computing (DISC) framework for fine-grained image saliencycomputing. In particular, we model the image saliency from both the coarse- andfine-level observations, and utilize the deep convolutional neural network(CNN) to learn the saliency representation in a progressive manner.Specifically, our saliency model is built upon two stacked CNNs. The first CNNgenerates a coarse-level saliency map by taking the overall image as the input,roughly identifying saliency regions in the global context. Furthermore, weintegrate superpixel-based local context information in the first CNN to refinethe coarse-level saliency map. Guided by the coarse saliency map, the secondCNN focuses on the local context to produce fine-grained and accurate saliencymap while preserving object details. For a testing image, the two CNNscollaboratively conduct the saliency computing in one shot. Our DISC frameworkis capable of uniformly highlighting the objects-of-interest from complexbackground while preserving well object details. Extensive experiments onseveral standard benchmarks suggest that DISC outperforms otherstate-of-the-art methods and it also generalizes well across datasets withoutadditional training. The executable version of DISC is available online:http://vision.sysu.edu.cn/projects/DISC.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 27 (6), 1135-1149',\n",
       "  'citations': '119',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.04192v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9085929998973538234&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 537: {'ID': 537,\n",
       "  'title': 'A Simple Neural Attentive Meta-Learner',\n",
       "  'authors': ['Pieter Abbeel',\n",
       "   'Xi Chen',\n",
       "   'Mostafa Rohaninejad',\n",
       "   'Nikhil Mishra'],\n",
       "  'published': '2017-07-11T06:21:31Z',\n",
       "  'updated': '2018-02-25T04:55:20Z',\n",
       "  'abstract': 'Deep neural networks excel in regimes with large amounts of data, but tend tostruggle when data is scarce or when they need to adapt quickly to changes inthe task. In response, recent work in meta-learning proposes training ameta-learner on a distribution of similar tasks, in the hopes of generalizationto novel but related tasks by learning a high-level strategy that captures theessence of the problem it is asked to solve. However, many recent meta-learningapproaches are extensively hand-designed, either using architecturesspecialized to a particular application, or hard-coding algorithmic componentsthat constrain how the meta-learner solves the task. We propose a class ofsimple and generic meta-learner architectures that use a novel combination oftemporal convolutions and soft attention; the former to aggregate informationfrom past experience and the latter to pinpoint specific pieces of information.In the most extensive set of meta-learning experiments to date, we evaluate theresulting Simple Neural AttentIve Learner (or SNAIL) on severalheavily-benchmarked tasks. On all tasks, in both supervised and reinforcementlearning, SNAIL attains state-of-the-art performance by significant margins.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '345',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.03141v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13155723657744889520&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 538: {'ID': 538,\n",
       "  'title': 'On the Global Linear Convergence of Frank-Wolfe Optimization Variants',\n",
       "  'authors': ['Simon Lacoste-Julien', 'Martin Jaggi'],\n",
       "  'published': '2015-11-18T20:24:43Z',\n",
       "  'updated': '2015-11-18T20:24:43Z',\n",
       "  'abstract': \"The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularitythanks in particular to its ability to nicely handle the structured constraintsappearing in machine learning applications. However, its convergence rate isknown to be slow (sublinear) when the solution lies at the boundary. A simpleless-known fix is to add the possibility to take 'away steps' duringoptimization, an operation that importantly does not require a feasibilityoracle. In this paper, we highlight and clarify several variants of theFrank-Wolfe optimization algorithm that have been successfully applied inpractice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimumnorm point algorithm, and prove for the first time that they all enjoy globallinear convergence, under a weaker condition than strong convexity of theobjective. The constant in the convergence rate has an elegant interpretationas the product of the (classical) condition number of the function with a novelgeometric quantity that plays the role of a 'condition number' of theconstraint set. We provide pointers to where these algorithms have made adifference in practice, in particular with the flow polytope, the marginalpolytope and the base polytope for submodular optimization.\",\n",
       "  'categories': ['math.OC',\n",
       "   'cs.LG',\n",
       "   'stat.ML',\n",
       "   '90C52, 90C90, 68T05',\n",
       "   'G.1.6; I.2.6'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '230',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05932v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9906218516207641081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 539: {'ID': 539,\n",
       "  'title': 'Neural Networks with Few Multiplications',\n",
       "  'authors': ['Yoshua Bengio',\n",
       "   'Zhouhan Lin',\n",
       "   'Matthieu Courbariaux',\n",
       "   'Roland Memisevic'],\n",
       "  'published': '2015-10-11T04:32:39Z',\n",
       "  'updated': '2016-02-26T05:24:30Z',\n",
       "  'abstract': 'For most deep learning algorithms training is notoriously time consuming.Since most of the computation in training neural networks is typically spent onfloating point multiplications, we investigate an approach to training thateliminates the need for most of these. Our method consists of two parts: Firstwe stochastically binarize weights to convert multiplications involved incomputing hidden states to sign changes. Second, while back-propagating errorderivatives, in addition to binarizing the weights, we quantize therepresentations at each layer to convert the remaining multiplications intobinary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10,SVHN) show that this approach not only does not hurt classification performancebut can result in even better performance than standard stochastic gradientdescent training, paving the way to fast, hardware-friendly training of neuralnetworks.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '239',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1510.03009v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6931378573591664631&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 540: {'ID': 540,\n",
       "  'title': 'Grid Long Short-Term Memory',\n",
       "  'authors': ['Ivo Danihelka', 'Nal Kalchbrenner', 'Alex Graves'],\n",
       "  'published': '2015-07-06T16:30:05Z',\n",
       "  'updated': '2016-01-07T18:39:48Z',\n",
       "  'abstract': 'This paper introduces Grid Long Short-Term Memory, a network of LSTM cellsarranged in a multidimensional grid that can be applied to vectors, sequencesor higher dimensional data such as images. The network differs from existingdeep LSTM architectures in that the cells are connected between network layersas well as along the spatiotemporal dimensions of the data. The networkprovides a unified way of using LSTM for both deep and sequential computation.We apply the model to algorithmic tasks such as 15-digit integer addition andsequence memorization, where it is able to significantly outperform thestandard LSTM. We then give results for two empirical tasks. We find that 2DGrid LSTM achieves 1.47 bits per character on the Wikipedia characterprediction benchmark, which is state-of-the-art among neural approaches. Inaddition, we use the Grid LSTM to define a novel two-dimensional translationmodel, the Reencoder, and show that it outperforms a phrase-based referencesystem on a Chinese-to-English translation task.',\n",
       "  'categories': ['cs.NE', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '278',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.01526v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14303206616495742373&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 541: {'ID': 541,\n",
       "  'title': 'DRAW: A Recurrent Neural Network For Image Generation',\n",
       "  'authors': ['Alex Graves',\n",
       "   'Danilo Jimenez Rezende',\n",
       "   'Ivo Danihelka',\n",
       "   'Karol Gregor',\n",
       "   'Daan Wierstra'],\n",
       "  'published': '2015-02-16T16:48:56Z',\n",
       "  'updated': '2015-05-20T15:29:42Z',\n",
       "  'abstract': 'This paper introduces the Deep Recurrent Attentive Writer (DRAW) neuralnetwork architecture for image generation. DRAW networks combine a novelspatial attention mechanism that mimics the foveation of the human eye, with asequential variational auto-encoding framework that allows for the iterativeconstruction of complex images. The system substantially improves on the stateof the art for generative models on MNIST, and, when trained on the Street ViewHouse Numbers dataset, it generates images that cannot be distinguished fromreal data with the naked eye.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 1462-1471',\n",
       "  'citations': '1363',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.04623v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8022513888710268841&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 542: {'ID': 542,\n",
       "  'title': 'Adversarial Feature Matching for Text Generation',\n",
       "  'authors': ['Zhe Gan',\n",
       "   'Lawrence Carin',\n",
       "   'Kai Fan',\n",
       "   'Ricardo Henao',\n",
       "   'Zhi Chen',\n",
       "   'Yizhe Zhang',\n",
       "   'Dinghan Shen'],\n",
       "  'published': '2017-06-12T20:55:51Z',\n",
       "  'updated': '2017-11-18T18:40:04Z',\n",
       "  'abstract': 'The Generative Adversarial Network (GAN) has achieved great success ingenerating realistic (real-valued) synthetic data. However, convergence issuesand difficulties dealing with discrete data hinder the applicability of GAN totext. We propose a framework for generating realistic text via adversarialtraining. We employ a long short-term memory network as generator, and aconvolutional network as discriminator. Instead of using the standard objectiveof GAN, we propose matching the high-dimensional latent feature distributionsof real and synthetic sentences, via a kernelized discrepancy metric. Thiseases adversarial training by alleviating the mode-collapsing problem. Ourexperiments show superior performance in quantitative evaluation, anddemonstrate that our model can generate realistic-looking sentences.',\n",
       "  'categories': ['stat.ML', 'cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICML, 4006-4015',\n",
       "  'citations': '176',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.03850v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11561684801033759674&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 543: {'ID': 543,\n",
       "  'title': 'Compressed Sensing using Generative Models',\n",
       "  'authors': ['Alexandros G. Dimakis',\n",
       "   'Eric Price',\n",
       "   'Ajil Jalal',\n",
       "   'Ashish Bora'],\n",
       "  'published': '2017-03-09T10:11:03Z',\n",
       "  'updated': '2017-03-09T10:11:03Z',\n",
       "  'abstract': 'The goal of compressed sensing is to estimate a vector from anunderdetermined system of noisy linear measurements, by making use of priorknowledge on the structure of vectors in the relevant domain. For almost allresults in this literature, the structure is represented by sparsity in awell-chosen basis. We show how to achieve guarantees similar to standardcompressed sensing but without employing sparsity at all. Instead, we supposethat vectors lie near the range of a generative model $G: \\\\mathbb{R}^k \\\\to\\\\mathbb{R}^n$. Our main theorem is that, if $G$ is $L$-Lipschitz, then roughly$O(k \\\\log L)$ random Gaussian measurements suffice for an $\\\\ell_2/\\\\ell_2$recovery guarantee. We demonstrate our results using generative models frompublished variational autoencoder and generative adversarial networks. Ourmethod can use $5$-$10$x fewer measurements than Lasso for the same accuracy.',\n",
       "  'categories': ['stat.ML', 'cs.IT', 'cs.LG', 'math.IT'],\n",
       "  'journal': 'ICML, 537-546',\n",
       "  'citations': '248',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.03208v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14786655061233662443&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 544: {'ID': 544,\n",
       "  'title': 'Neural Programmer-Interpreters',\n",
       "  'authors': ['Scott Reed', 'Nando de Freitas'],\n",
       "  'published': '2015-11-19T17:49:32Z',\n",
       "  'updated': '2016-02-29T11:12:36Z',\n",
       "  'abstract': 'We propose the neural programmer-interpreter (NPI): a recurrent andcompositional neural network that learns to represent and execute programs. NPIhas three learnable components: a task-agnostic recurrent core, a persistentkey-value program memory, and domain-specific encoders that enable a single NPIto operate in multiple perceptually diverse environments with distinctaffordances. By learning to compose lower-level programs to expresshigher-level programs, NPI reduces sample complexity and increasesgeneralization ability compared to sequence-to-sequence LSTMs. The programmemory allows efficient learning of additional tasks by building on existingprograms. NPI can also harness the environment (e.g. a scratch pad withread-write pointers) to cache intermediate results of computation, lesseningthe long-term memory burden on recurrent hidden units. In this work we trainthe NPI with fully-supervised execution traces; each program has examplesequences of calls to the immediate subprograms conditioned on the input.Rather than training on a huge number of relatively weak labels, NPI learnsfrom a small number of rich examples. We demonstrate the capability of ourmodel to learn several types of compositional programs: addition, sorting, andcanonicalizing 3D models. Furthermore, a single NPI learns to execute theseprograms and all 21 associated subprograms.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '310',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06279v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14095885171607870380&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 545: {'ID': 545,\n",
       "  'title': 'Dual Learning for Machine Translation',\n",
       "  'authors': ['Liwei Wang',\n",
       "   'Tie-Yan Liu',\n",
       "   'Yingce Xia',\n",
       "   'Wei-Ying Ma',\n",
       "   'Tao Qin',\n",
       "   'Di He',\n",
       "   'Nenghai Yu'],\n",
       "  'published': '2016-11-01T10:38:29Z',\n",
       "  'updated': '2016-11-01T10:38:29Z',\n",
       "  'abstract': 'While neural machine translation (NMT) is making good progress in the pasttwo years, tens of millions of bilingual sentence pairs are needed for itstraining. However, human labeling is very costly. To tackle this training databottleneck, we develop a dual-learning mechanism, which can enable an NMTsystem to automatically learn from unlabeled data through a dual-learning game.This mechanism is inspired by the following observation: any machinetranslation task has a dual task, e.g., English-to-French translation (primal)versus French-to-English translation (dual); the primal and dual tasks can forma closed loop, and generate informative feedback signals to train thetranslation models, even if without the involvement of a human labeler. In thedual-learning mechanism, we use one agent to represent the model for the primaltask and the other agent to represent the model for the dual task, then askthem to teach each other through a reinforcement learning process. Based on thefeedback signals generated during this process (e.g., the language-modellikelihood of the output of a model, and the reconstruction error of theoriginal sentence after the primal and dual translations), we can iterativelyupdate the two models until convergence (e.g., using the policy gradientmethods). We call the corresponding approach to neural machine translation\\\\emph{dual-NMT}. Experiments show that dual-NMT works very well onEnglish$\\\\leftrightarrow$French translation; especially, by learning frommonolingual data (with 10% bilingual data for warm start), it achieves acomparable accuracy to NMT trained from the full bilingual data for theFrench-to-English translation task.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '355',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.00179v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15841765927830550600&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 546: {'ID': 546,\n",
       "  'title': 'Scalable Bayesian Optimization Using Deep Neural Networks',\n",
       "  'authors': ['Prabhat',\n",
       "   'Ryan P. Adams',\n",
       "   'Md. Mostofa Ali Patwary',\n",
       "   'Ryan Kiros',\n",
       "   'Kevin Swersky',\n",
       "   'Nadathur Satish',\n",
       "   'Narayanan Sundaram',\n",
       "   'Oren Rippel',\n",
       "   'Jasper Snoek'],\n",
       "  'published': '2015-02-19T20:51:27Z',\n",
       "  'updated': '2015-07-13T15:47:13Z',\n",
       "  'abstract': 'Bayesian optimization is an effective methodology for the global optimizationof functions with expensive evaluations. It relies on querying a distributionover functions defined by a relatively cheap surrogate model. An accurate modelfor this distribution over functions is critical to the effectiveness of theapproach, and is typically fit using Gaussian processes (GPs). However, sinceGPs scale cubically with the number of observations, it has been challenging tohandle objectives whose optimization requires many evaluations, and as such,massively parallelizing the optimization.  In this work, we explore the use of neural networks as an alternative to GPsto model distributions over functions. We show that performing adaptive basisfunction regression with a neural network as the parametric form performscompetitively with state-of-the-art GP-based approaches, but scales linearlywith the number of data rather than cubically. This allows us to achieve apreviously intractable degree of parallelism, which we apply to large scalehyperparameter optimization, rapidly finding competitive models on benchmarkobject recognition tasks using convolutional networks, and image captiongeneration using neural language models.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'journal': 'ICML, 2171-2180',\n",
       "  'citations': '444',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1502.05700v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7151760993960049125&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 547: {'ID': 547,\n",
       "  'title': 'Empower Sequence Labeling with Task-Aware Neural Language Model',\n",
       "  'authors': ['Jingbo Shang',\n",
       "   'Frank F. Xu',\n",
       "   'Liyuan Liu',\n",
       "   'Huan Gui',\n",
       "   'Jiawei Han',\n",
       "   'Jian Peng',\n",
       "   'Xiang Ren'],\n",
       "  'published': '2017-09-13T02:13:25Z',\n",
       "  'updated': '2017-11-23T23:12:40Z',\n",
       "  'abstract': 'Linguistic sequence labeling is a general modeling approach that encompassesa variety of problems, such as part-of-speech tagging and named entityrecognition. Recent advances in neural networks (NNs) make it possible to buildreliable models without handcrafted features. However, in many cases, it ishard to obtain sufficient annotations to train these models. In this study, wedevelop a novel neural framework to extract abundant knowledge hidden in rawtexts to empower the sequence labeling task. Besides word-level knowledgecontained in pre-trained word embeddings, character-aware neural languagemodels are incorporated to extract character-level knowledge. Transfer learningtechniques are further adopted to mediate different components and guide thelanguage model towards the key knowledge. Comparing to previous methods, thesetask-specific knowledge allows us to adopt a more concise model and conductmore efficient training. Different from most transfer learning methods, theproposed framework does not rely on any additional supervision. It extractsknowledge from self-contained order information of training sequences.Extensive experiments on benchmark datasets demonstrate the effectiveness ofleveraging character-level knowledge and the efficiency of co-training. Forexample, on the CoNLL03 NER task, model training completes in about 6 hours ona single GPU, reaching F1 score of 91.71$\\\\pm$0.10 without using any extraannotation.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '163',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.04109v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16154865990911474666&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 548: {'ID': 548,\n",
       "  'title': 'Gated Graph Sequence Neural Networks',\n",
       "  'authors': ['Yujia Li',\n",
       "   'Daniel Tarlow',\n",
       "   'Marc Brockschmidt',\n",
       "   'Richard Zemel'],\n",
       "  'published': '2015-11-17T18:10:12Z',\n",
       "  'updated': '2017-09-22T21:36:00Z',\n",
       "  'abstract': 'Graph-structured data appears frequently in domains including chemistry,natural language semantics, social networks, and knowledge bases. In this work,we study feature learning techniques for graph-structured inputs. Our startingpoint is previous work on Graph Neural Networks (Scarselli et al., 2009), whichwe modify to use gated recurrent units and modern optimization techniques andthen extend to output sequences. The result is a flexible and broadly usefulclass of neural network models that has favorable inductive biases relative topurely sequence-based models (e.g., LSTMs) when the problem isgraph-structured. We demonstrate the capabilities on some simple AI (bAbI) andgraph algorithm learning tasks. We then show it achieves state-of-the-artperformance on a problem from program verification, in which subgraphs need tobe matched to abstract data structures.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '945',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.05493v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16266567510296342081&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 549: {'ID': 549,\n",
       "  'title': 'Towards K-means-friendly Spaces: Simultaneous Deep Learning and  Clustering',\n",
       "  'authors': ['Bo Yang', 'Xiao Fu', 'Nicholas D. Sidiropoulos', 'Mingyi Hong'],\n",
       "  'published': '2016-10-15T22:51:06Z',\n",
       "  'updated': '2017-06-13T22:40:26Z',\n",
       "  'abstract': \"Most learning approaches treat dimensionality reduction (DR) and clusteringseparately (i.e., sequentially), but recent research has shown that optimizingthe two tasks jointly can substantially improve the performance of both. Thepremise behind the latter genre is that the data samples are obtained vialinear transformation of latent representations that are easy to cluster; butin practice, the transformation from the latent space to the data can be morecomplicated. In this work, we assume that this transformation is an unknown andpossibly nonlinear function. To recover the `clustering-friendly' latentrepresentations and to better cluster the data, we propose a joint DR andK-means clustering approach in which DR is accomplished via learning a deepneural network (DNN). The motivation is to keep the advantages of jointlyoptimizing the two tasks, while exploiting the deep neural network's ability toapproximate any nonlinear function. This way, the proposed approach can workwell for a broad class of generative models. Towards this end, we carefullydesign the DNN structure and the associated joint optimization criterion, andpropose an effective and scalable algorithm to handle the formulatedoptimization problem. Experiments using different real datasets are employed toshowcase the effectiveness of the proposed approach.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 3861-3870',\n",
       "  'citations': '220',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.04794v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6015973098028169119&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 550: {'ID': 550,\n",
       "  'title': 'BinaryConnect: Training Deep Neural Networks with binary weights during  propagations',\n",
       "  'authors': ['Jean-Pierre David', 'Matthieu Courbariaux', 'Yoshua Bengio'],\n",
       "  'published': '2015-11-02T02:50:05Z',\n",
       "  'updated': '2016-04-18T13:11:45Z',\n",
       "  'abstract': 'Deep Neural Networks (DNN) have achieved state-of-the-art results in a widerange of tasks, with the best results obtained with large training sets andlarge models. In the past, GPUs enabled these breakthroughs because of theirgreater computational speed. In the future, faster computation at both trainingand test time is likely to be crucial for further progress and for consumerapplications on low-power devices. As a result, there is much interest inresearch and development of dedicated hardware for Deep Learning (DL). Binaryweights, i.e., weights which are constrained to only two possible values (e.g.-1 or 1), would bring great benefits to specialized DL hardware by replacingmany multiply-accumulate operations by simple accumulations, as multipliers arethe most space and power-hungry components of the digital implementation ofneural networks. We introduce BinaryConnect, a method which consists intraining a DNN with binary weights during the forward and backwardpropagations, while retaining precision of the stored weights in whichgradients are accumulated. Like other dropout schemes, we show thatBinaryConnect acts as regularizer and we obtain near state-of-the-art resultswith BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1466',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.00363v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9513509971843797855&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 551: {'ID': 551,\n",
       "  'title': 'Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under  Partial Observability',\n",
       "  'authors': ['Jason Pazis',\n",
       "   'Christopher Amato',\n",
       "   'John Vian',\n",
       "   'Jonathan P. How',\n",
       "   'Shayegan Omidshafiei'],\n",
       "  'published': '2017-03-17T19:32:38Z',\n",
       "  'updated': '2017-07-13T17:34:34Z',\n",
       "  'abstract': 'Many real-world tasks involve multiple agents with partial observability andlimited communication. Learning is challenging in these settings due to localviewpoints of agents, which perceive the world as non-stationary due toconcurrently-exploring teammates. Approaches that learn specialized policiesfor individual tasks face problems when applied to the real world: not only doagents have to learn and store distinct policies for each task, but in practiceidentities of tasks are often non-observable, making these approachesinapplicable. This paper formalizes and addresses the problem of multi-taskmulti-agent reinforcement learning under partial observability. We introduce adecentralized single-task learning approach that is robust to concurrentinteractions of teammates, and present an approach for distilling single-taskpolicies into a unified policy that performs well across multiple relatedtasks, without explicit provision of task identity.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.MA'],\n",
       "  'journal': 'ICML, 2681-2690',\n",
       "  'citations': '186',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.06182v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14362474747446780618&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 552: {'ID': 552,\n",
       "  'title': 'Efficient Neural Architecture Search via Parameter Sharing',\n",
       "  'authors': ['Hieu Pham',\n",
       "   'Barret Zoph',\n",
       "   'Melody Y. Guan',\n",
       "   'Jeff Dean',\n",
       "   'Quoc V. Le'],\n",
       "  'published': '2018-02-09T14:14:37Z',\n",
       "  'updated': '2018-02-12T03:34:00Z',\n",
       "  'abstract': 'We propose Efficient Neural Architecture Search (ENAS), a fast andinexpensive approach for automatic model design. In ENAS, a controller learnsto discover neural network architectures by searching for an optimal subgraphwithin a large computational graph. The controller is trained with policygradient to select a subgraph that maximizes the expected reward on thevalidation set. Meanwhile the model corresponding to the selected subgraph istrained to minimize a canonical cross entropy loss. Thanks to parameter sharingbetween child models, ENAS is fast: it delivers strong empirical performancesusing much fewer GPU-hours than all existing automatic model design approaches,and notably, 1000x less expensive than standard Neural Architecture Search. Onthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves atest perplexity of 55.8, establishing a new state-of-the-art among all methodswithout post-training processing. On the CIFAR-10 dataset, ENAS designs novelarchitectures that achieve a test error of 2.89%, which is on par with NASNet(Zoph et al., 2018), whose test error is 2.65%.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.CV', 'cs.NE', 'stat.ML'],\n",
       "  'journal': 'ICML, 4092-4101',\n",
       "  'citations': '682',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.03268v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15692975197474124336&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 553: {'ID': 553,\n",
       "  'title': 'Poincaré Embeddings for Learning Hierarchical Representations',\n",
       "  'authors': ['Maximilian Nickel', 'Douwe Kiela'],\n",
       "  'published': '2017-05-22T23:14:36Z',\n",
       "  'updated': '2017-05-26T17:40:55Z',\n",
       "  'abstract': \"Representation learning has become an invaluable approach for learning fromsymbolic data such as text and graphs. However, while complex symbolic datasetsoften exhibit a latent hierarchical structure, state-of-the-art methodstypically learn embeddings in Euclidean vector spaces, which do not account forthis property. For this purpose, we introduce a new approach for learninghierarchical representations of symbolic data by embedding them into hyperbolicspace -- or more precisely into an n-dimensional Poincar\\\\'e ball. Due to theunderlying hyperbolic geometry, this allows us to learn parsimoniousrepresentations of symbolic data by simultaneously capturing hierarchy andsimilarity. We introduce an efficient algorithm to learn the embeddings basedon Riemannian optimization and show experimentally that Poincar\\\\'e embeddingsoutperform Euclidean embeddings significantly on data with latent hierarchies,both in terms of representation capacity and in terms of generalizationability.\",\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '343',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.08039v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=6233393442090324202&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 554: {'ID': 554,\n",
       "  'title': 'Asynchronous Methods for Deep Reinforcement Learning',\n",
       "  'authors': ['Alex Graves',\n",
       "   'Tim Harley',\n",
       "   'Mehdi Mirza',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Adrià Puigdomènech Badia',\n",
       "   'David Silver',\n",
       "   'Timothy P. Lillicrap',\n",
       "   'Volodymyr Mnih'],\n",
       "  'published': '2016-02-04T18:38:41Z',\n",
       "  'updated': '2016-06-16T16:38:45Z',\n",
       "  'abstract': 'We propose a conceptually simple and lightweight framework for deepreinforcement learning that uses asynchronous gradient descent for optimizationof deep neural network controllers. We present asynchronous variants of fourstandard reinforcement learning algorithms and show that parallelactor-learners have a stabilizing effect on training allowing all four methodsto successfully train neural network controllers. The best performing method,an asynchronous variant of actor-critic, surpasses the current state-of-the-arton the Atari domain while training for half the time on a single multi-core CPUinstead of a GPU. Furthermore, we show that asynchronous actor-critic succeedson a wide variety of continuous motor control problems as well as on a new taskof navigating random 3D mazes using a visual input.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICML, 1928-1937',\n",
       "  'citations': '3403',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.01783v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14460380466928185185&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 555: {'ID': 555,\n",
       "  'title': 'Unsupervised Deep Embedding for Clustering Analysis',\n",
       "  'authors': ['Junyuan Xie', 'Ross Girshick', 'Ali Farhadi'],\n",
       "  'published': '2015-11-19T20:06:14Z',\n",
       "  'updated': '2016-05-24T22:27:35Z',\n",
       "  'abstract': 'Clustering is central to many data-driven application domains and has beenstudied extensively in terms of distance functions and grouping algorithms.Relatively little work has focused on learning representations for clustering.In this paper, we propose Deep Embedded Clustering (DEC), a method thatsimultaneously learns feature representations and cluster assignments usingdeep neural networks. DEC learns a mapping from the data space to alower-dimensional feature space in which it iteratively optimizes a clusteringobjective. Our experimental evaluations on image and text corpora showsignificant improvement over state-of-the-art methods.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'journal': 'ICML, 478-487',\n",
       "  'citations': '712',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06335v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18273828742645455219&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 556: {'ID': 556,\n",
       "  'title': 'Malware Detection by Eating a Whole EXE',\n",
       "  'authors': ['Charles Nicholas',\n",
       "   'Jon Barker',\n",
       "   'Jared Sylvester',\n",
       "   'Robert Brandon',\n",
       "   'Edward Raff',\n",
       "   'Bryan Catanzaro'],\n",
       "  'published': '2017-10-25T19:48:54Z',\n",
       "  'updated': '2017-10-25T19:48:54Z',\n",
       "  'abstract': 'In this work we introduce malware detection from raw byte sequences as afruitful research area to the larger machine learning community. Building aneural network for such a problem presents a number of interesting challengesthat have not occurred in tasks such as image processing or NLP. In particular,we note that detection from raw bytes presents a sequence problem with over twomillion time steps and a problem where batch normalization appear to hinder thelearning process. We present our initial work in building a solution to tacklethis problem, which has linear complexity dependence on the sequence length,and allows for interpretable sub-regions of the binary to be identified. Indoing so we will discuss the many challenges in building a neural network toprocess data at this scale, and the methods we used to work around them.',\n",
       "  'categories': ['stat.ML', 'cs.CR', 'cs.LG'],\n",
       "  'journal': 'AAAI Workshops, 268-276',\n",
       "  'citations': '132',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.09435v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3220751781952104973&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 557: {'ID': 557,\n",
       "  'title': 'Hindsight Experience Replay',\n",
       "  'authors': ['Marcin Andrychowicz',\n",
       "   'Peter Welinder',\n",
       "   'Wojciech Zaremba',\n",
       "   'Josh Tobin',\n",
       "   'Rachel Fong',\n",
       "   'Jonas Schneider',\n",
       "   'Filip Wolski',\n",
       "   'Alex Ray',\n",
       "   'Bob McGrew',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2017-07-05T17:55:53Z',\n",
       "  'updated': '2018-02-23T10:04:20Z',\n",
       "  'abstract': 'Dealing with sparse rewards is one of the biggest challenges in ReinforcementLearning (RL). We present a novel technique called Hindsight Experience Replaywhich allows sample-efficient learning from rewards which are sparse and binaryand therefore avoid the need for complicated reward engineering. It can becombined with an arbitrary off-policy RL algorithm and may be seen as a form ofimplicit curriculum.  We demonstrate our approach on the task of manipulating objects with arobotic arm. In particular, we run experiments on three different tasks:pushing, sliding, and pick-and-place, in each case using only binary rewardsindicating whether or not the task is completed. Our ablation studies show thatHindsight Experience Replay is a crucial ingredient which makes trainingpossible in these challenging environments. We show that our policies trainedon a physics simulation can be deployed on a physical robot and successfullycomplete the task.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE', 'cs.RO'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '606',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.01495v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14733084267697271284&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 558: {'ID': 558,\n",
       "  'title': 'Visualizing the Loss Landscape of Neural Nets',\n",
       "  'authors': ['Tom Goldstein',\n",
       "   'Hao Li',\n",
       "   'Zheng Xu',\n",
       "   'Gavin Taylor',\n",
       "   'Christoph Studer'],\n",
       "  'published': '2017-12-28T16:15:42Z',\n",
       "  'updated': '2018-11-07T06:25:20Z',\n",
       "  'abstract': 'Neural network training relies on our ability to find \"good\" minimizers ofhighly non-convex loss functions. It is well-known that certain networkarchitecture designs (e.g., skip connections) produce loss functions that traineasier, and well-chosen training parameters (batch size, learning rate,optimizer) produce minimizers that generalize better. However, the reasons forthese differences, and their effects on the underlying loss landscape, are notwell understood. In this paper, we explore the structure of neural lossfunctions, and the effect of loss landscapes on generalization, using a rangeof visualization methods. First, we introduce a simple \"filter normalization\"method that helps us visualize loss function curvature and make meaningfulside-by-side comparisons between loss functions. Then, using a variety ofvisualizations, we explore how network architecture affects the loss landscape,and how training parameters affect the shape of minimizers.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '343',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.09913v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11650483902238288010&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 559: {'ID': 559,\n",
       "  'title': 'Continual Learning Through Synaptic Intelligence',\n",
       "  'authors': ['Friedemann Zenke', 'Ben Poole', 'Surya Ganguli'],\n",
       "  'published': '2017-03-13T00:02:48Z',\n",
       "  'updated': '2017-06-12T19:57:42Z',\n",
       "  'abstract': 'While deep learning has led to remarkable advances across diverseapplications, it struggles in domains where the data distribution changes overthe course of learning. In stark contrast, biological neural networkscontinually adapt to changing domains, possibly by leveraging complex molecularmachinery to solve many tasks simultaneously. In this study, we introduceintelligent synapses that bring some of this biological complexity intoartificial neural networks. Each synapse accumulates task relevant informationover time, and exploits this information to rapidly store new memories withoutforgetting old ones. We evaluate our approach on continual learning ofclassification tasks, and show that it dramatically reduces forgetting whilemaintaining computational efficiency.',\n",
       "  'categories': ['cs.LG', 'q-bio.NC', 'stat.ML'],\n",
       "  'journal': 'ICML, 3987-3995',\n",
       "  'citations': '380',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.04200v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=13353907805622310554&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 560: {'ID': 560,\n",
       "  'title': 'Adversarially Learned Inference',\n",
       "  'authors': ['Aaron Courville',\n",
       "   'Ben Poole',\n",
       "   'Olivier Mastropietro',\n",
       "   'Alex Lamb',\n",
       "   'Ishmael Belghazi',\n",
       "   'Martin Arjovsky',\n",
       "   'Vincent Dumoulin'],\n",
       "  'published': '2016-06-02T14:43:37Z',\n",
       "  'updated': '2017-02-21T18:28:22Z',\n",
       "  'abstract': 'We introduce the adversarially learned inference (ALI) model, which jointlylearns a generation network and an inference network using an adversarialprocess. The generation network maps samples from stochastic latent variablesto the data space while the inference network maps training examples in dataspace to the space of latent variables. An adversarial game is cast betweenthese two networks and a discriminative network is trained to distinguishbetween joint latent/data-space samples from the generative network and jointsamples from the inference network. We illustrate the ability of the model tolearn mutually coherent inference and generation networks through theinspections of model samples and reconstructions and confirm the usefulness ofthe learned representations by obtaining a performance competitive withstate-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '769',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.00704v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10451598130846693107&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 561: {'ID': 561,\n",
       "  'title': 'Justified Representation in Approval-Based Committee Voting',\n",
       "  'authors': ['Edith Elkind',\n",
       "   'Toby Walsh',\n",
       "   'Rupert Freeman',\n",
       "   'Haris Aziz',\n",
       "   'Vincent Conitzer',\n",
       "   'Markus Brill'],\n",
       "  'published': '2014-07-31T03:51:34Z',\n",
       "  'updated': '2016-09-12T01:02:43Z',\n",
       "  'abstract': 'We consider approval-based committee voting, i.e. the setting where eachvoter approves a subset of candidates, and these votes are then used to selecta fixed-size set of winners (committee). We propose a natural axiom for thissetting, which we call justified representation (JR). This axiom requires thatif a large enough group of voters exhibits agreement by supporting the samecandidate, then at least one voter in this group has an approved candidate inthe winning committee. We show that for every list of ballots it is possible toselect a committee that provides JR. However, it turns out that severalprominent approval-based voting rules may fail to output such a committee. Inparticular, while Proportional Approval Voting (PAV) always outputs a committeethat provides JR, Reweighted Approval Voting (RAV), a tractable approximationto PAV, does not have this property. We then introduce a stronger version ofthe JR axiom, which we call extended justified representation (EJR), and showthat PAV satisfies EJR, while other rules we consider do not; indeed, EJR canbe used to characterize PAV within the class of weighted PAV rules. We alsoconsider several other questions related to JR and EJR, including therelationship between JR/EJR and core stability, and the complexity of theassociated algorithmic problems.',\n",
       "  'categories': ['cs.MA', 'cs.GT', '91A12, 68Q15', 'J.4; I.2.11; F.2'],\n",
       "  'journal': 'Twenty-Ninth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '159',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1407.8269v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9171385458786328885&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 562: {'ID': 562,\n",
       "  'title': 'Deep Generative Image Models using a Laplacian Pyramid of Adversarial  Networks',\n",
       "  'authors': ['Arthur Szlam',\n",
       "   'Emily Denton',\n",
       "   'Rob Fergus',\n",
       "   'Soumith Chintala'],\n",
       "  'published': '2015-06-18T17:03:54Z',\n",
       "  'updated': '2015-06-18T17:03:54Z',\n",
       "  'abstract': 'In this paper we introduce a generative parametric model capable of producinghigh quality samples of natural images. Our approach uses a cascade ofconvolutional networks within a Laplacian pyramid framework to generate imagesin a coarse-to-fine fashion. At each level of the pyramid, a separategenerative convnet model is trained using the Generative Adversarial Nets (GAN)approach (Goodfellow et al.). Samples drawn from our model are of significantlyhigher quality than alternate approaches. In a quantitative assessment by humanevaluators, our CIFAR10 samples were mistaken for real images around 40% of thetime, compared to 10% for samples drawn from a GAN baseline model. We also showsamples from models trained on the higher resolution images of the LSUN scenedataset.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1517',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.05751v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8031319294003741632&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 563: {'ID': 563,\n",
       "  'title': 'Learning to Poke by Poking: Experiential Learning of Intuitive Physics',\n",
       "  'authors': ['Sergey Levine',\n",
       "   'Pulkit Agrawal',\n",
       "   'Jitendra Malik',\n",
       "   'Ashvin Nair',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2016-06-23T19:42:57Z',\n",
       "  'updated': '2017-02-15T22:53:52Z',\n",
       "  'abstract': \"We investigate an experiential learning paradigm for acquiring an internalmodel of intuitive physics. Our model is evaluated on a real-world roboticmanipulation task that requires displacing objects to target locations bypoking. The robot gathered over 400 hours of experience by executing more than100K pokes on different objects. We propose a novel approach based on deepneural networks for modeling the dynamics of robot's interactions directly fromimages, by jointly estimating forward and inverse models of dynamics. Theinverse model objective provides supervision to construct informative visualfeatures, which the forward model can then predict and in turn regularize thefeature space for the inverse model. The interplay between these two objectivescreates useful, accurate models that can then be used for multi-step decisionmaking. This formulation has the additional benefit that it is possible tolearn forward models in an abstract feature space and thus alleviate the needof predicting pixels. Our experiments show that this joint modeling approachoutperforms alternative methods.\",\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.RO'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '291',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.07419v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=4353677612815002221&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 564: {'ID': 564,\n",
       "  'title': 'Reinforcement Learning with Unsupervised Auxiliary Tasks',\n",
       "  'authors': ['Wojciech Marian Czarnecki',\n",
       "   'Joel Z Leibo',\n",
       "   'Max Jaderberg',\n",
       "   'Koray Kavukcuoglu',\n",
       "   'Tom Schaul',\n",
       "   'David Silver',\n",
       "   'Volodymyr Mnih'],\n",
       "  'published': '2016-11-16T18:21:29Z',\n",
       "  'updated': '2016-11-16T18:21:29Z',\n",
       "  'abstract': 'Deep reinforcement learning agents have achieved state-of-the-art results bydirectly maximising cumulative reward. However, environments contain a muchwider variety of possible training signals. In this paper, we introduce anagent that also maximises many other pseudo-reward functions simultaneously byreinforcement learning. All of these tasks share a common representation that,like unsupervised learning, continues to develop in the absence of extrinsicrewards. We also introduce a novel mechanism for focusing this representationupon extrinsic rewards, so that learning can rapidly adapt to the most relevantaspects of the actual task. Our agent significantly outperforms the previousstate-of-the-art on Atari, averaging 880\\\\% expert human performance, and achallenging suite of first-person, three-dimensional \\\\emph{Labyrinth} tasksleading to a mean speedup in learning of 10$\\\\times$ and averaging 87\\\\% experthuman performance on Labyrinth.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '563',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.05397v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14888805482854497974&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 565: {'ID': 565,\n",
       "  'title': 'Designing Neural Network Architectures using Reinforcement Learning',\n",
       "  'authors': ['Ramesh Raskar', 'Otkrist Gupta', 'Nikhil Naik', 'Bowen Baker'],\n",
       "  'published': '2016-11-07T16:49:43Z',\n",
       "  'updated': '2017-03-22T20:08:30Z',\n",
       "  'abstract': 'At present, designing convolutional neural network (CNN) architecturesrequires both human expertise and labor. New architectures are handcrafted bycareful experimentation or modified from a handful of existing networks. Weintroduce MetaQNN, a meta-modeling algorithm based on reinforcement learning toautomatically generate high-performing CNN architectures for a given learningtask. The learning agent is trained to sequentially choose CNN layers using$Q$-learning with an $\\\\epsilon$-greedy exploration strategy and experiencereplay. The agent explores a large but finite space of possible architecturesand iteratively discovers designs with improved performance on the learningtask. On image classification benchmarks, the agent-designed networks(consisting of only standard convolution, pooling, and fully-connected layers)beat existing networks designed with the same layer types and are competitiveagainst the state-of-the-art methods that use more complex layer types. We alsooutperform existing meta-modeling approaches for network design on imageclassification tasks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '562',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02167v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1457104897417222523&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 566: {'ID': 566,\n",
       "  'title': 'Variational Lossy Autoencoder',\n",
       "  'authors': ['Diederik P. Kingma',\n",
       "   'Xi Chen',\n",
       "   'Prafulla Dhariwal',\n",
       "   'Yan Duan',\n",
       "   'Tim Salimans',\n",
       "   'Ilya Sutskever',\n",
       "   'John Schulman',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2016-11-08T21:43:34Z',\n",
       "  'updated': '2017-03-04T06:19:22Z',\n",
       "  'abstract': 'Representation learning seeks to expose certain aspects of observed data in alearned representation that\\'s amenable to downstream tasks like classification.For instance, a good representation for 2D images might be one that describesonly global structure and discards information about detailed texture. In thispaper, we present a simple but principled method to learn such globalrepresentations by combining Variational Autoencoder (VAE) with neuralautoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAEmodel allows us to have control over what the global latent code can learn and, by designing the architecture accordingly, we can force the global latentcode to discard irrelevant information such as texture in 2D images, and hencethe VAE only \"autoencodes\" data in a lossy fashion. In addition, by leveragingautoregressive models as both prior distribution $p(z)$ and decodingdistribution $p(x|z)$, we can greatly improve generative modeling performanceof VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT andCaltech-101 Silhouettes density estimation tasks.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '345',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02731v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11833073722642726902&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 567: {'ID': 567,\n",
       "  'title': 'Delving into Transferable Adversarial Examples and Black-box Attacks',\n",
       "  'authors': ['Yanpei Liu', 'Dawn Song', 'Xinyun Chen', 'Chang Liu'],\n",
       "  'published': '2016-11-08T23:25:00Z',\n",
       "  'updated': '2017-02-07T14:24:44Z',\n",
       "  'abstract': 'An intriguing property of deep neural networks is the existence ofadversarial examples, which can transfer among different architectures. Thesetransferable adversarial examples may severely hinder deep neural network-basedapplications. Previous works mostly study the transferability using small scaledatasets. In this work, we are the first to conduct an extensive study of thetransferability over large models and a large scale dataset, and we are alsothe first to study the transferability of targeted adversarial examples withtheir target labels. We study both non-targeted and targeted adversarialexamples, and show that while transferable non-targeted adversarial examplesare easy to find, targeted adversarial examples generated using existingapproaches almost never transfer with their target labels. Therefore, wepropose novel ensemble-based approaches to generating transferable adversarialexamples. Using such approaches, we observe a large proportion of targetedadversarial examples that are able to transfer with their target labels for thefirst time. We also present some geometric studies to help understanding thetransferable adversarial examples. Finally, we show that the adversarialexamples generated using ensemble-based approaches can successfully attackClarifai.com, which is a black-box image classification system.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '603',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.02770v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11918479105697515542&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 568: {'ID': 568,\n",
       "  'title': 'GraphGAN: Graph Representation Learning with Generative Adversarial Nets',\n",
       "  'authors': ['Xing Xie',\n",
       "   'Weinan Zhang',\n",
       "   'Miao Zhao',\n",
       "   'Jia Wang',\n",
       "   'Hongwei Wang',\n",
       "   'Minyi Guo',\n",
       "   'Fuzheng Zhang',\n",
       "   'Jialin Wang'],\n",
       "  'published': '2017-11-22T13:20:17Z',\n",
       "  'updated': '2017-11-22T13:20:17Z',\n",
       "  'abstract': 'The goal of graph representation learning is to embed each vertex in a graphinto a low-dimensional vector space. Existing graph representation learningmethods can be classified into two categories: generative models that learn theunderlying connectivity distribution in the graph, and discriminative modelsthat predict the probability of edge existence between a pair of vertices. Inthis paper, we propose GraphGAN, an innovative graph representation learningframework unifying above two classes of methods, in which the generative modeland discriminative model play a game-theoretical minimax game. Specifically,for a given vertex, the generative model tries to fit its underlying trueconnectivity distribution over all other vertices and produces \"fake\" samplesto fool the discriminative model, while the discriminative model tries todetect whether the sampled vertex is from ground truth or generated by thegenerative model. With the competition between these two models, both of themcan alternately and iteratively boost their performance. Moreover, whenconsidering the implementation of generative model, we propose a novel graphsoftmax to overcome the limitations of traditional softmax function, which canbe proven satisfying desirable properties of normalization, graph structureawareness, and computational efficiency. Through extensive experiments onreal-world datasets, we demonstrate that GraphGAN achieves substantial gains ina variety of applications, including link prediction, node classification, andrecommendation, over state-of-the-art baselines.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '180',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.08267v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11414835106213661900&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 569: {'ID': 569,\n",
       "  'title': 'Autoencoding beyond pixels using a learned similarity metric',\n",
       "  'authors': ['Hugo Larochelle',\n",
       "   'Anders Boesen Lindbo Larsen',\n",
       "   'Søren Kaae Sønderby',\n",
       "   'Ole Winther'],\n",
       "  'published': '2015-12-31T14:53:39Z',\n",
       "  'updated': '2016-02-10T21:18:27Z',\n",
       "  'abstract': 'We present an autoencoder that leverages learned representations to bettermeasure similarities in data space. By combining a variational autoencoder witha generative adversarial network we can use learned feature representations inthe GAN discriminator as basis for the VAE reconstruction objective. Thereby,we replace element-wise errors with feature-wise errors to better capture thedata distribution while offering invariance towards e.g. translation. We applyour method to images of faces and show that it outperforms VAEs withelement-wise similarity measures in terms of visual fidelity. Moreover, we showthat the method learns an embedding in which high-level abstract visualfeatures (e.g. wearing glasses) can be modified using simple arithmetic.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'ICML, 1558-1566',\n",
       "  'citations': '965',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.09300v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12417620106993504772&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 570: {'ID': 570,\n",
       "  'title': 'Learning Structured Sparsity in Deep Neural Networks',\n",
       "  'authors': ['Wei Wen', 'Hai Li', 'Yiran Chen', 'Chunpeng Wu', 'Yandan Wang'],\n",
       "  'published': '2016-08-12T03:20:43Z',\n",
       "  'updated': '2016-10-18T04:03:41Z',\n",
       "  'abstract': 'High demand for computation resources severely hinders deployment oflarge-scale Deep Neural Networks (DNN) in resource constrained devices. In thiswork, we propose a Structured Sparsity Learning (SSL) method to regularize thestructures (i.e., filters, channels, filter shapes, and layer depth) of DNNs.SSL can: (1) learn a compact structure from a bigger DNN to reduce computationcost; (2) obtain a hardware-friendly structured sparsity of DNN to efficientlyaccelerate the DNNs evaluation. Experimental results show that SSL achieves onaverage 5.1x and 3.1x speedups of convolutional layer computation of AlexNetagainst CPU and GPU, respectively, with off-the-shelf libraries. These speedupsare about twice speedups of non-structured sparsity; (3) regularize the DNNstructure to improve classification accuracy. The results show that forCIFAR-10, regularization on layer depth can reduce 20 layers of a Deep ResidualNetwork (ResNet) to 18 layers while improve the accuracy from 91.25% to 92.60%,which is still slightly higher than that of original ResNet with 32 layers. ForAlexNet, structure regularization by SSL also reduces the error by around ~1%.Open source code is in https://github.com/wenwei202/caffe/tree/scnn',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML', 'I.2.6; I.5.1'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '977',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1608.03665v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14407046964194758297&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 571: {'ID': 571,\n",
       "  'title': 'Low-rank Solutions of Linear Matrix Equations via Procrustes Flow',\n",
       "  'authors': ['Stephen Tu',\n",
       "   'Benjamin Recht',\n",
       "   'Ross Boczar',\n",
       "   'Max Simchowitz',\n",
       "   'Mahdi Soltanolkotabi'],\n",
       "  'published': '2015-07-13T19:45:28Z',\n",
       "  'updated': '2016-02-05T20:34:55Z',\n",
       "  'abstract': 'In this paper we study the problem of recovering a low-rank matrix fromlinear measurements. Our algorithm, which we call Procrustes Flow, starts froman initial estimate obtained by a thresholding scheme followed by gradientdescent on a non-convex objective. We show that as long as the measurementsobey a standard restricted isometry property, our algorithm converges to theunknown matrix at a geometric rate. In the case of Gaussian measurements, suchconvergence occurs for a $n_1 \\\\times n_2$ matrix of rank $r$ when the number ofmeasurements exceeds a constant times $(n_1+n_2)r$.',\n",
       "  'categories': ['math.OC'],\n",
       "  'journal': 'ICML, 964-973',\n",
       "  'citations': '246',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.03566v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1139387413638481008&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 572: {'ID': 572,\n",
       "  'title': 'Deep Exploration via Bootstrapped DQN',\n",
       "  'authors': ['Alexander Pritzel',\n",
       "   'Charles Blundell',\n",
       "   'Ian Osband',\n",
       "   'Benjamin Van Roy'],\n",
       "  'published': '2016-02-15T10:54:20Z',\n",
       "  'updated': '2016-07-04T17:11:52Z',\n",
       "  'abstract': 'Efficient exploration in complex environments remains a major challenge forreinforcement learning. We propose bootstrapped DQN, a simple algorithm thatexplores in a computationally and statistically efficient manner through use ofrandomized value functions. Unlike dithering strategies such as epsilon-greedyexploration, bootstrapped DQN carries out temporally-extended (or deep)exploration; this can lead to exponentially faster learning. We demonstratethese benefits in complex stochastic MDPs and in the large-scale ArcadeLearning Environment. Bootstrapped DQN substantially improves learning timesand performance across most Atari games.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SY', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '500',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.04621v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1614250880059729675&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 573: {'ID': 573,\n",
       "  'title': 'Inductive Representation Learning on Large Graphs',\n",
       "  'authors': ['Jure Leskovec', 'William L. Hamilton', 'Rex Ying'],\n",
       "  'published': '2017-06-07T14:51:05Z',\n",
       "  'updated': '2018-09-10T14:26:58Z',\n",
       "  'abstract': \"Low-dimensional embeddings of nodes in large graphs have proved extremelyuseful in a variety of prediction tasks, from content recommendation toidentifying protein functions. However, most existing approaches require thatall nodes in the graph are present during training of the embeddings; theseprevious approaches are inherently transductive and do not naturally generalizeto unseen nodes. Here we present GraphSAGE, a general, inductive framework thatleverages node feature information (e.g., text attributes) to efficientlygenerate node embeddings for previously unseen data. Instead of trainingindividual embeddings for each node, we learn a function that generatesembeddings by sampling and aggregating features from a node's localneighborhood. Our algorithm outperforms strong baselines on three inductivenode-classification benchmarks: we classify the category of unseen nodes inevolving information graphs based on citation and Reddit post data, and we showthat our algorithm generalizes to completely unseen graphs using a multi-graphdataset of protein-protein interactions.\",\n",
       "  'categories': ['cs.SI', 'cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1617',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.02216v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10802896480404413344&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 574: {'ID': 574,\n",
       "  'title': 'A Multi-task Deep Network for Person Re-identification',\n",
       "  'authors': ['Jianguo Zhang', 'Weihua Chen', 'Xiaotang Chen', 'Kaiqi Huang'],\n",
       "  'published': '2016-07-19T01:59:02Z',\n",
       "  'updated': '2016-11-25T06:22:57Z',\n",
       "  'abstract': 'Person re-identification (ReID) focuses on identifying people acrossdifferent scenes in video surveillance, which is usually formulated as a binaryclassification task or a ranking task in current person ReID approaches. Inthis paper, we take both tasks into account and propose a multi-task deepnetwork (MTDnet) that makes use of their own advantages and jointly optimizethe two tasks simultaneously for person ReID. To the best of our knowledge, weare the first to integrate both tasks in one network to solve the person ReID.We show that our proposed architecture significantly boosts the performance.Furthermore, deep architecture in general requires a sufficient dataset fortraining, which is usually not met in person ReID. To cope with this situation,we further extend the MTDnet and propose a cross-domain architecture that iscapable of using an auxiliary set to assist training on small target sets. Inthe experiments, our approach outperforms most of existing person ReIDalgorithms on representative datasets including CUHK03, CUHK01, VIPeR, iLIDSand PRID2011, which clearly demonstrates the effectiveness of the proposedapproach.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'Thirty-First AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '145',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.05369v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8761948355560963456&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 575: {'ID': 575,\n",
       "  'title': 'Learning feed-forward one-shot learners',\n",
       "  'authors': ['Jack Valmadre',\n",
       "   'Luca Bertinetto',\n",
       "   'João F. Henriques',\n",
       "   'Andrea Vedaldi',\n",
       "   'Philip H. S. Torr'],\n",
       "  'published': '2016-06-16T15:49:26Z',\n",
       "  'updated': '2016-06-16T15:49:26Z',\n",
       "  'abstract': 'One-shot learning is usually tackled by using generative models ordiscriminative embeddings. Discriminative methods based on deep learning, whichare very effective in other learning scenarios, are ill-suited for one-shotlearning as they need large amounts of training data. In this paper, we proposea method to learn the parameters of a deep model in one shot. We construct thelearner as a second deep network, called a learnet, which predicts theparameters of a pupil network from a single exemplar. In this manner we obtainan efficient feed-forward one-shot learner, trained end-to-end by minimizing aone-shot classification objective in a learning to learn formulation. In orderto make the construction feasible, we propose a number of factorizations of theparameters of the pupil network. We demonstrate encouraging results by learningcharacters from single exemplars in Omniglot, and by tracking visual objectsfrom a single initial exemplar in the Visual Object Tracking benchmark.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '229',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.05233v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8558583381725749208&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 576: {'ID': 576,\n",
       "  'title': 'Synthesizing Robust Adversarial Examples',\n",
       "  'authors': ['Andrew Ilyas', 'Logan Engstrom', 'Kevin Kwok', 'Anish Athalye'],\n",
       "  'published': '2017-07-24T04:17:33Z',\n",
       "  'updated': '2018-06-07T16:25:12Z',\n",
       "  'abstract': 'Standard methods for generating adversarial examples for neural networks donot consistently fool neural network classifiers in the physical world due to acombination of viewpoint shifts, camera noise, and other naturaltransformations, limiting their relevance to real-world systems. We demonstratethe existence of robust 3D adversarial objects, and we present the firstalgorithm for synthesizing examples that are adversarial over a chosendistribution of transformations. We synthesize two-dimensional adversarialimages that are robust to noise, distortion, and affine transformation. Weapply our algorithm to complex three-dimensional objects, using 3D-printing tomanufacture the first physical adversarial objects. Our results demonstrate theexistence of 3D adversarial objects in the physical world.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICML, 284-293',\n",
       "  'citations': '518',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.07397v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10751510407294386830&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 577: {'ID': 577,\n",
       "  'title': 'Convolutional Neural Networks over Tree Structures for Programming  Language Processing',\n",
       "  'authors': ['Ge Li', 'Zhi Jin', 'Tao Wang', 'Lu Zhang', 'Lili Mou'],\n",
       "  'published': '2014-09-18T06:50:52Z',\n",
       "  'updated': '2015-12-08T12:31:51Z',\n",
       "  'abstract': \"Programming language processing (similar to natural language processing) is ahot research topic in the field of software engineering; it has also arousedgrowing interest in the artificial intelligence community. However, differentfrom a natural language sentence, a program contains rich, explicit, andcomplicated structural information. Hence, traditional NLP models may beinappropriate for programs. In this paper, we propose a novel tree-basedconvolutional neural network (TBCNN) for programming language processing, inwhich a convolution kernel is designed over programs' abstract syntax trees tocapture structural information. TBCNN is a generic architecture for programminglanguage processing; our experiments show its effectiveness in two differentprogram analysis tasks: classifying programs according to functionality, anddetecting code snippets of certain patterns. TBCNN outperforms baselinemethods, including several neural models for NLP.\",\n",
       "  'categories': ['cs.LG', 'cs.NE', 'cs.SE'],\n",
       "  'journal': 'Thirtieth AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '227',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1409.5718v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12324937124370515795&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 578: {'ID': 578,\n",
       "  'title': 'Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs',\n",
       "  'authors': ['Alon Brutzkus', 'Amir Globerson'],\n",
       "  'published': '2017-02-26T01:12:20Z',\n",
       "  'updated': '2017-02-26T01:12:20Z',\n",
       "  'abstract': 'Deep learning models are often successfully trained using gradient descent,despite the worst case hardness of the underlying non-convex optimizationproblem. The key question is then under what conditions can one prove thatoptimization will succeed. Here we provide a strong result of this kind. Weconsider a neural net with one hidden layer and a convolutional structure withno overlap and a ReLU activation function. For this architecture we show thatlearning is NP-complete in the general case, but that when the inputdistribution is Gaussian, gradient descent converges to the global optimum inpolynomial time. To the best of our knowledge, this is the first globaloptimality guarantee of gradient descent on a convolutional neural network withReLU activations.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'journal': 'ICML, 605-614',\n",
       "  'citations': '184',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.07966v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5580029596128142672&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 579: {'ID': 579,\n",
       "  'title': 'Offline bilingual word vectors, orthogonal transformations and the  inverted softmax',\n",
       "  'authors': ['Steven Hamblin',\n",
       "   'Nils Y. Hammerla',\n",
       "   'David H. P. Turban',\n",
       "   'Samuel L. Smith'],\n",
       "  'published': '2017-02-13T16:31:06Z',\n",
       "  'updated': '2017-02-13T16:31:06Z',\n",
       "  'abstract': 'Usually bilingual word vectors are trained \"online\". Mikolov et al. showedthey can also be found \"offline\", whereby two pre-trained embeddings arealigned with a linear transformation, using dictionaries compiled from expertknowledge. In this work, we prove that the linear transformation between twospaces should be orthogonal. This transformation can be obtained using thesingular value decomposition. We introduce a novel \"inverted softmax\" foridentifying translation pairs, with which we improve the precision @1 ofMikolov\\'s original mapping from 34% to 43%, when translating a test setcomposed of both common and rare English words into Italian. Orthogonaltransformations are more robust to noise, enabling us to learn thetransformation without expert bilingual signal by constructing a\"pseudo-dictionary\" from the identical character strings which appear in bothlanguages, achieving 40% precision on the same test set. Finally, we extend ourmethod to retrieve the true translations of English sentences from a corpus of200k Italian sentences with a precision @1 of 68%.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.IR'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '301',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.03859v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5636639417293949985&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 580: {'ID': 580,\n",
       "  'title': 'Deep Semantic Role Labeling with Self-Attention',\n",
       "  'authors': ['Jun Xie',\n",
       "   'Mingxuan Wang',\n",
       "   'Zhixing Tan',\n",
       "   'Yidong Chen',\n",
       "   'Xiaodong Shi'],\n",
       "  'published': '2017-12-05T11:48:51Z',\n",
       "  'updated': '2017-12-05T11:48:51Z',\n",
       "  'abstract': 'Semantic Role Labeling (SRL) is believed to be a crucial step towards naturallanguage understanding and has been widely studied. Recent years, end-to-endSRL with recurrent neural networks (RNN) has gained increasing attention.However, it remains a major challenge for RNNs to handle structural informationand long range dependencies. In this paper, we present a simple and effectivearchitecture for SRL which aims to address these problems. Our model is basedon self-attention which can directly capture the relationships between twotokens regardless of their distance. Our single model achieves F$_1=83.4$ onthe CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared taskdataset, which outperforms the previous state-of-the-art results by $1.8$ and$1.0$ F$_1$ score respectively. Besides, our model is computationallyefficient, and the parsing speed is 50K tokens per second on a single Titan XGPU.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '150',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.01586v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9226285893444450718&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 581: {'ID': 581,\n",
       "  'title': 'Conditional Image Synthesis With Auxiliary Classifier GANs',\n",
       "  'authors': ['Christopher Olah', 'Augustus Odena', 'Jonathon Shlens'],\n",
       "  'published': '2016-10-30T00:29:31Z',\n",
       "  'updated': '2017-07-20T20:23:31Z',\n",
       "  'abstract': 'Synthesizing high resolution photorealistic images has been a long-standingchallenge in machine learning. In this paper we introduce new methods for theimproved training of generative adversarial networks (GANs) for imagesynthesis. We construct a variant of GANs employing label conditioning thatresults in 128x128 resolution image samples exhibiting global coherence. Weexpand on previous work for image quality assessment to provide two newanalyses for assessing the discriminability and diversity of samples fromclass-conditional image synthesis models. These analyses demonstrate that highresolution samples provide class information not present in low resolutionsamples. Across 1000 ImageNet classes, 128x128 samples are more than twice asdiscriminable as artificially resized 32x32 samples. In addition, 84.7% of theclasses have samples exhibiting diversity comparable to real ImageNet data.',\n",
       "  'categories': ['stat.ML', 'cs.CV'],\n",
       "  'journal': 'ICML, 2642-2651',\n",
       "  'citations': '1236',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.09585v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12065133258161328182&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 582: {'ID': 582,\n",
       "  'title': 'Ensemble of Example-Dependent Cost-Sensitive Decision Trees',\n",
       "  'authors': ['Alejandro Correa Bahnsen', 'Bjorn Ottersten', 'Djamila Aouada'],\n",
       "  'published': '2015-05-18T13:43:53Z',\n",
       "  'updated': '2015-05-18T13:43:53Z',\n",
       "  'abstract': 'Several real-world classification problems are example-dependentcost-sensitive in nature, where the costs due to misclassification vary betweenexamples and not only within classes. However, standard classification methodsdo not take these costs into account, and assume a constant cost ofmisclassification errors. In previous works, some methods that take intoaccount the financial costs into the training of different algorithms have beenproposed, with the example-dependent cost-sensitive decision tree algorithmbeing the one that gives the highest savings. In this paper we propose a newframework of ensembles of example-dependent cost-sensitive decision-trees. Theframework consists in creating different example-dependent cost-sensitivedecision trees on random subsamples of the training set, and then combiningthem using three different combination approaches. Moreover, we propose two newcost-sensitive combination approaches; cost-sensitive weighted voting andcost-sensitive stacking, the latter being based on the cost-sensitive logisticregression method. Finally, using five different databases, from fourreal-world applications: credit card fraud detection, churn modeling, creditscoring and direct marketing, we evaluate the proposed method againststate-of-the-art example-dependent cost-sensitive techniques, namely,cost-proportionate sampling, Bayes minimum risk and cost-sensitive decisiontrees. The results show that the proposed algorithms have better results forall databases, in the sense of higher savings.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'Expert Systems with Applications 42 (19), 6609-6619',\n",
       "  'citations': '119',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.04637v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17692807637486467277&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 583: {'ID': 583,\n",
       "  'title': 'Unsupervised Learning for Physical Interaction through Video Prediction',\n",
       "  'authors': ['Chelsea Finn', 'Sergey Levine', 'Ian Goodfellow'],\n",
       "  'published': '2016-05-23T19:45:55Z',\n",
       "  'updated': '2016-10-17T20:09:56Z',\n",
       "  'abstract': 'A core challenge for an agent learning to interact with the world is topredict how its actions affect objects in its environment. Many existingmethods for learning the dynamics of physical interactions require labeledobject information. However, to scale real-world interaction learning to avariety of scenes and objects, acquiring labeled data becomes increasinglyimpractical. To learn about physical object motion without labels, we developan action-conditioned video prediction model that explicitly models pixelmotion, by predicting a distribution over pixel motion from previous frames.Because our model explicitly predicts motion, it is partially invariant toobject appearance, enabling it to generalize to previously unseen objects. Toexplore video prediction for real-world interactive agents, we also introduce adataset of 59,000 robot interactions involving pushing motions, including atest set with novel objects. In this dataset, accurate prediction of videosconditioned on the robot\\'s future actions amounts to learning a \"visualimagination\" of different futures based on different courses of action. Ourexperiments show that our proposed method produces more accurate videopredictions both quantitatively and qualitatively, when compared to priormethods.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.RO'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '560',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07157v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=5380767711147691375&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 584: {'ID': 584,\n",
       "  'title': 'Recurrent Highway Networks',\n",
       "  'authors': ['Jan Koutník',\n",
       "   'Rupesh Kumar Srivastava',\n",
       "   'Julian Georg Zilly',\n",
       "   'Jürgen Schmidhuber'],\n",
       "  'published': '2016-07-12T19:36:50Z',\n",
       "  'updated': '2017-07-04T19:29:23Z',\n",
       "  'abstract': \"Many sequential processing tasks require complex nonlinear transitionfunctions from one step to the next. However, recurrent neural networks with'deep' transition functions remain difficult to train, even when using LongShort-Term Memory (LSTM) networks. We introduce a novel theoretical analysis ofrecurrent networks based on Gersgorin's circle theorem that illuminates severalmodeling and optimization issues and improves our understanding of the LSTMcell. Based on this analysis we propose Recurrent Highway Networks, whichextend the LSTM architecture to allow step-to-step transition depths largerthan one. Several language modeling experiments demonstrate that the proposedarchitecture results in powerful and efficient models. On the Penn Treebankcorpus, solely increasing the transition depth from 1 to 10 improves word-levelperplexity from 90.6 to 65.4 using the same number of parameters. On the largerWikipedia datasets for character prediction (text8 and enwik8), RHNs outperformall previous results and achieve an entropy of 1.27 bits per character.\",\n",
       "  'categories': ['cs.LG', 'cs.CL', 'cs.NE'],\n",
       "  'journal': 'ICML, 4189-4198',\n",
       "  'citations': '326',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1607.03474v5',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12472656521661483543&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 585: {'ID': 585,\n",
       "  'title': 'Learning to Reweight Examples for Robust Deep Learning',\n",
       "  'authors': ['Raquel Urtasun', 'Bin Yang', 'Mengye Ren', 'Wenyuan Zeng'],\n",
       "  'published': '2018-03-24T03:41:59Z',\n",
       "  'updated': '2019-05-05T15:21:40Z',\n",
       "  'abstract': 'Deep neural networks have been shown to be very powerful modeling tools formany supervised learning tasks involving complex input patterns. However, theycan also easily overfit to training set biases and label noises. In addition tovarious regularizers, example reweighting algorithms are popular solutions tothese problems, but they require careful tuning of additional hyperparameters,such as example mining schedules and regularization hyperparameters. Incontrast to past reweighting methods, which typically consist of functions ofthe cost value of each example, in this work we propose a novel meta-learningalgorithm that learns to assign weights to training examples based on theirgradient directions. To determine the example weights, our method performs ameta gradient descent step on the current mini-batch example weights (which areinitialized from zero) to minimize the loss on a clean unbiased validation set.Our proposed method can be easily implemented on any type of deep network, doesnot require any additional hyperparameter tuning, and achieves impressiveperformance on class imbalance and corrupted label problems where only a smallamount of clean validation data is available.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 4331-4340',\n",
       "  'citations': '222',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.09050v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17871432661582272860&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 586: {'ID': 586,\n",
       "  'title': 'Prototypical Networks for Few-shot Learning',\n",
       "  'authors': ['Richard S. Zemel', 'Kevin Swersky', 'Jake Snell'],\n",
       "  'published': '2017-03-15T14:31:55Z',\n",
       "  'updated': '2017-06-19T22:48:54Z',\n",
       "  'abstract': 'We propose prototypical networks for the problem of few-shot classification,where a classifier must generalize to new classes not seen in the training set,given only a small number of examples of each new class. Prototypical networkslearn a metric space in which classification can be performed by computingdistances to prototype representations of each class. Compared to recentapproaches for few-shot learning, they reflect a simpler inductive bias that isbeneficial in this limited-data regime, and achieve excellent results. Weprovide an analysis showing that some simple design decisions can yieldsubstantial improvements over recent approaches involving complicatedarchitectural choices and meta-learning. We further extend prototypicalnetworks to zero-shot learning and achieve state-of-the-art results on theCU-Birds dataset.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1208',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.05175v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=8721743270682962846&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 587: {'ID': 587,\n",
       "  'title': 'Generating Videos with Scene Dynamics',\n",
       "  'authors': ['Antonio Torralba', 'Carl Vondrick', 'Hamed Pirsiavash'],\n",
       "  'published': '2016-09-08T22:29:52Z',\n",
       "  'updated': '2016-10-26T13:58:10Z',\n",
       "  'abstract': \"We capitalize on large amounts of unlabeled video in order to learn a modelof scene dynamics for both video recognition tasks (e.g. action classification)and video generation tasks (e.g. future prediction). We propose a generativeadversarial network for video with a spatio-temporal convolutional architecturethat untangles the scene's foreground from the background. Experiments suggestthis model can generate tiny videos up to a second at full frame rate betterthan simple baselines, and we show its utility at predicting plausible futuresof static images. Moreover, experiments and visualizations show the modelinternally learns useful features for recognizing actions with minimalsupervision, suggesting scene dynamics are a promising signal forrepresentation learning. We believe generative video models can impact manyapplications in video understanding and simulation.\",\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '736',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1609.02612v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12629733064507558057&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 588: {'ID': 588,\n",
       "  'title': 'Theoretically Principled Trade-off between Robustness and Accuracy',\n",
       "  'authors': ['Yaodong Yu',\n",
       "   'Jiantao Jiao',\n",
       "   'Eric P. Xing',\n",
       "   'Hongyang Zhang',\n",
       "   'Laurent El Ghaoui',\n",
       "   'Michael I. Jordan'],\n",
       "  'published': '2019-01-24T18:43:57Z',\n",
       "  'updated': '2019-06-24T07:04:11Z',\n",
       "  'abstract': 'We identify a trade-off between robustness and accuracy that serves as aguiding principle in the design of defenses against adversarial examples.Although this problem has been widely studied empirically, much remains unknownconcerning the theory underlying this trade-off. In this work, we decompose theprediction error for adversarial examples (robust error) as the sum of thenatural (classification) error and boundary error, and provide a differentiableupper bound using the theory of classification-calibrated loss, which is shownto be the tightest possible upper bound uniform over all probabilitydistributions and measurable predictors. Inspired by our theoretical analysis,we also design a new defense method, TRADES, to trade adversarial robustnessoff against accuracy. Our proposed algorithm performs well experimentally inreal-world datasets. The methodology is the foundation of our entry to theNeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of~2,000 submissions, surpassing the runner-up approach by $11.41\\\\%$ in terms ofmean $\\\\ell_2$ perturbation distance.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICML, 7472-7482',\n",
       "  'citations': '206',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.08573v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3311622924435738798&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 589: {'ID': 589,\n",
       "  'title': 'QANet: Combining Local Convolution with Global Self-Attention for  Reading Comprehension',\n",
       "  'authors': ['Rui Zhao',\n",
       "   'Minh-Thang Luong',\n",
       "   'Adams Wei Yu',\n",
       "   'Mohammad Norouzi',\n",
       "   'David Dohan',\n",
       "   'Quoc V. Le',\n",
       "   'Kai Chen'],\n",
       "  'published': '2018-04-23T11:33:43Z',\n",
       "  'updated': '2018-04-23T11:33:43Z',\n",
       "  'abstract': 'Current end-to-end machine reading and question answering (Q\\\\&amp;A) models areprimarily based on recurrent neural networks (RNNs) with attention. Despitetheir success, these models are often slow for both training and inference dueto the sequential nature of RNNs. We propose a new Q\\\\&amp;A architecture calledQANet, which does not require recurrent networks: Its encoder consistsexclusively of convolution and self-attention, where convolution models localinteractions and self-attention models global interactions. On the SQuADdataset, our model is 3x to 13x faster in training and 4x to 9x faster ininference, while achieving equivalent accuracy to recurrent models. Thespeed-up gain allows us to train the model with much more data. We hencecombine our model with data generated by backtranslation from a neural machinetranslation model. On the SQuAD dataset, our single model, trained withaugmented data, achieves 84.6 F1 score on the test set, which is significantlybetter than the best published F1 score of 81.8.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '371',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.09541v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15745561136241294753&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 590: {'ID': 590,\n",
       "  'title': 'Training Very Deep Networks',\n",
       "  'authors': ['Rupesh Kumar Srivastava', 'Jürgen Schmidhuber', 'Klaus Greff'],\n",
       "  'published': '2015-07-22T15:29:14Z',\n",
       "  'updated': '2015-11-23T16:25:30Z',\n",
       "  'abstract': 'Theoretical and empirical evidence indicates that the depth of neuralnetworks is crucial for their success. However, training becomes more difficultas depth increases, and training of very deep networks remains an open problem.Here we introduce a new architecture designed to overcome this. Our so-calledhighway networks allow unimpeded information flow across many layers oninformation highways. They are inspired by Long Short-Term Memory recurrentnetworks and use adaptive gating units to regulate the information flow. Evenwith hundreds of layers, highway networks can be trained directly throughsimple gradient descent. This enables the study of extremely deep and efficientarchitectures.',\n",
       "  'categories': ['cs.LG', 'cs.NE', '68T01', 'I.2.6; G.1.6'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '1066',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1507.06228v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14374917385640982609&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 591: {'ID': 591,\n",
       "  'title': 'Texture Synthesis Using Convolutional Neural Networks',\n",
       "  'authors': ['Matthias Bethge', 'Leon A. Gatys', 'Alexander S. Ecker'],\n",
       "  'published': '2015-05-27T15:29:52Z',\n",
       "  'updated': '2015-11-06T13:55:09Z',\n",
       "  'abstract': 'Here we introduce a new model of natural textures based on the feature spacesof convolutional neural networks optimised for object recognition. Samples fromthe model are of high perceptual quality demonstrating the generative power ofneural networks trained in a purely discriminative fashion. Within the model,textures are represented by the correlations between feature maps in severallayers of the network. We show that across layers the texture representationsincreasingly capture the statistical properties of natural images while makingobject information more and more explicit. The model provides a new tool togenerate stimuli for neuroscience and might offer insights into the deeprepresentations learned by convolutional neural networks.',\n",
       "  'categories': ['cs.CV', 'cs.NE', 'q-bio.NC'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '659',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.07376v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16960830956248393695&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 592: {'ID': 592,\n",
       "  'title': 'Unsupervised Domain Adaptation by Backpropagation',\n",
       "  'authors': ['Yaroslav Ganin', 'Victor Lempitsky'],\n",
       "  'published': '2014-09-26T08:22:21Z',\n",
       "  'updated': '2015-02-27T14:54:37Z',\n",
       "  'abstract': 'Top-performing deep architectures are trained on massive amounts of labeleddata. In the absence of labeled data for a certain task, domain adaptationoften provides an attractive option given that labeled data of similar naturebut from a different domain (e.g. synthetic images) are available. Here, wepropose a new approach to domain adaptation in deep architectures that can betrained on large amount of labeled data from the source domain and large amountof unlabeled data from the target domain (no labeled target-domain data isnecessary).  As the training progresses, the approach promotes the emergence of \"deep\"features that are (i) discriminative for the main learning task on the sourcedomain and (ii) invariant with respect to the shift between the domains. Weshow that this adaptation behaviour can be achieved in almost any feed-forwardmodel by augmenting it with few standard layers and a simple new gradientreversal layer. The resulting augmented architecture can be trained usingstandard backpropagation.  Overall, the approach can be implemented with little effort using any of thedeep-learning packages. The method performs very well in a series of imageclassification experiments, achieving adaptation effect in the presence of bigdomain shifts and outperforming previous state-of-the-art on Office datasets.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICML, 1180-1189',\n",
       "  'citations': '1581',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1409.7495v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1240308825085771392&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 593: {'ID': 593,\n",
       "  'title': 'Embed to Control: A Locally Linear Latent Dynamics Model for Control  from Raw Images',\n",
       "  'authors': ['Manuel Watter',\n",
       "   'Jost Tobias Springenberg',\n",
       "   'Joschka Boedecker',\n",
       "   'Martin Riedmiller'],\n",
       "  'published': '2015-06-24T13:48:51Z',\n",
       "  'updated': '2015-11-20T14:49:18Z',\n",
       "  'abstract': 'We introduce Embed to Control (E2C), a method for model learning and controlof non-linear dynamical systems from raw pixel images. E2C consists of a deepgenerative model, belonging to the family of variational autoencoders, thatlearns to generate image trajectories from a latent space in which the dynamicsis constrained to be locally linear. Our model is derived directly from anoptimal control formulation in latent space, supports long-term prediction ofimage sequences and exhibits strong performance on a variety of complex controlproblems.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '374',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1506.07365v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14464025381144196926&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 594: {'ID': 594,\n",
       "  'title': 'DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language  Understanding',\n",
       "  'authors': ['Tianyi Zhou',\n",
       "   'Guodong Long',\n",
       "   'Chengqi Zhang',\n",
       "   'Shirui Pan',\n",
       "   'Jing Jiang',\n",
       "   'Tao Shen'],\n",
       "  'published': '2017-09-14T10:42:44Z',\n",
       "  'updated': '2017-11-20T23:39:11Z',\n",
       "  'abstract': 'Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widelyused on NLP tasks to capture the long-term and local dependencies,respectively. Attention mechanisms have recently attracted enormous interestdue to their highly parallelizable computation, significantly less trainingtime, and flexibility in modeling dependencies. We propose a novel attentionmechanism in which the attention between elements from input sequence(s) isdirectional and multi-dimensional (i.e., feature-wise). A light-weight neuralnet, \"Directional Self-Attention Network (DiSAN)\", is then proposed to learnsentence embedding, based solely on the proposed attention without any RNN/CNNstructure. DiSAN is only composed of a directional self-attention with temporalorder encoded, followed by a multi-dimensional attention that compresses thesequence into a vector representation. Despite its simple form, DiSANoutperforms complicated RNN models on both prediction quality and timeefficiency. It achieves the best test accuracy among all sentence encodingmethods and improves the most recent best result by 1.02% on the StanfordNatural Language Inference (SNLI) dataset, and shows state-of-the-art testaccuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural languageinference (MultiNLI), Sentences Involving Compositional Knowledge (SICK),Customer Review, MPQA, TREC question-type classification and Subjectivity(SUBJ) datasets.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'journal': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'citations': '294',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.04696v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=7314091737208199325&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 595: {'ID': 595,\n",
       "  'title': 'The Composition Theorem for Differential Privacy',\n",
       "  'authors': ['Sewoong Oh', 'Peter Kairouz', 'Pramod Viswanath'],\n",
       "  'published': '2013-11-04T17:22:00Z',\n",
       "  'updated': '2015-12-06T22:06:01Z',\n",
       "  'abstract': 'Sequential querying of differentially private mechanisms degrades the overallprivacy level. In this paper, we answer the fundamental question ofcharacterizing the level of overall privacy degradation as a function of thenumber of queries and the privacy levels maintained by each privatizationmechanism. Our solution is complete: we prove an upper bound on the overallprivacy level and construct a sequence of privatization mechanisms thatachieves this bound. The key innovation is the introduction of an operationalinterpretation of differential privacy (involving hypothesis testing) and theuse of new data processing inequalities. Our result improves over thestate-of-the-art, and has immediate applications in several problems studied inthe literature including differentially private multi-party computation.',\n",
       "  'categories': ['cs.DS', 'cs.CR', 'cs.IT', 'math.IT'],\n",
       "  'journal': 'ICML, 1376-1385',\n",
       "  'citations': '200',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1311.0776v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17631243245787694869&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 596: {'ID': 596,\n",
       "  'title': 'Solving Random Quadratic Systems of Equations Is Nearly as Easy as  Solving Linear Systems',\n",
       "  'authors': ['Yuxin Chen', 'Emmanuel J. Candes'],\n",
       "  'published': '2015-05-19T18:37:07Z',\n",
       "  'updated': '2016-03-22T17:05:16Z',\n",
       "  'abstract': 'We consider the fundamental problem of solving quadratic systems of equationsin $n$ variables, where $y_i = |\\\\langle \\\\boldsymbol{a}_i, \\\\boldsymbol{x}\\\\rangle|^2$, $i = 1, \\\\ldots, m$ and $\\\\boldsymbol{x} \\\\in \\\\mathbb{R}^n$ isunknown. We propose a novel method, which starting with an initial guesscomputed by means of a spectral method, proceeds by minimizing a nonconvexfunctional as in the Wirtinger flow approach. There are several keydistinguishing features, most notably, a distinct objective functional andnovel update rules, which operate in an adaptive fashion and drop terms bearingtoo much influence on the search direction. These careful selection rulesprovide a tighter initial guess, better descent directions, and thus enhancedpractical performance. On the theoretical side, we prove that for certainunstructured models of quadratic systems, our algorithms return the correctsolution in linear time, i.e. in time proportional to reading the data$\\\\{\\\\boldsymbol{a}_i\\\\}$ and $\\\\{y_i\\\\}$ as soon as the ratio $m/n$ between thenumber of equations and unknowns exceeds a fixed numerical constant. We extendthe theory to deal with noisy systems in which we only have $y_i \\\\approx|\\\\langle \\\\boldsymbol{a}_i, \\\\boldsymbol{x} \\\\rangle|^2$ and prove that ouralgorithms achieve a statistical accuracy, which is nearly un-improvable. Wecomplement our theoretical study with numerical examples showing that solvingrandom quadratic systems is both computationally and statistically not muchharder than solving linear systems of the same size---hence the title of thispaper. For instance, we demonstrate empirically that the computational cost ofour algorithm is about four times that of solving a least-squares problem ofthe same size.',\n",
       "  'categories': ['cs.IT',\n",
       "   'cs.LG',\n",
       "   'math.IT',\n",
       "   'math.NA',\n",
       "   'math.ST',\n",
       "   'stat.ML',\n",
       "   'stat.TH'],\n",
       "  'journal': 'Proceedings of the 28th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '303',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1505.05114v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11224976403044841324&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 597: {'ID': 597,\n",
       "  'title': 'Large Scale GAN Training for High Fidelity Natural Image Synthesis',\n",
       "  'authors': ['Andrew Brock', 'Jeff Donahue', 'Karen Simonyan'],\n",
       "  'published': '2018-09-28T15:38:49Z',\n",
       "  'updated': '2019-02-25T21:32:06Z',\n",
       "  'abstract': 'Despite recent progress in generative image modeling, successfully generatinghigh-resolution, diverse samples from complex datasets such as ImageNet remainsan elusive goal. To this end, we train Generative Adversarial Networks at thelargest scale yet attempted, and study the instabilities specific to suchscale. We find that applying orthogonal regularization to the generator rendersit amenable to a simple \"truncation trick,\" allowing fine control over thetrade-off between sample fidelity and variety by reducing the variance of theGenerator\\'s input. Our modifications lead to models which set the new state ofthe art in class-conditional image synthesis. When trained on ImageNet at128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previousbest IS of 52.52 and FID of 18.6.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '912',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.11096v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=9573828555610570748&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 598: {'ID': 598,\n",
       "  'title': 'Data Programming: Creating Large Training Sets, Quickly',\n",
       "  'authors': ['Daniel Selsam',\n",
       "   'Christopher Ré',\n",
       "   'Sen Wu',\n",
       "   'Alexander Ratner',\n",
       "   'Christopher De Sa'],\n",
       "  'published': '2016-05-25T04:14:59Z',\n",
       "  'updated': '2017-01-08T19:48:53Z',\n",
       "  'abstract': 'Large labeled training sets are the critical building blocks of supervisedlearning methods and are key enablers of deep learning techniques. For someapplications, creating labeled training sets is the most time-consuming andexpensive part of applying machine learning. We therefore propose a paradigmfor the programmatic creation of training sets called data programming in whichusers express weak supervision strategies or domain heuristics as labelingfunctions, which are programs that label subsets of the data, but that arenoisy and may conflict. We show that by explicitly representing this trainingset labeling process as a generative model, we can \"denoise\" the generatedtraining set, and establish theoretically that we can recover the parameters ofthese generative models in a handful of settings. We then show how to modify adiscriminative loss function to make it noise-aware, and demonstrate our methodover a range of discriminative models including logistic regression and LSTMs.Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that dataprogramming would have led to a new winning score, and also show that applyingdata programming to an LSTM model leads to a TAC-KBP score almost 6 F1 pointsover a state-of-the-art LSTM baseline (and into second place in thecompetition). Additionally, in initial user studies we observed that dataprogramming may be an easier way for non-experts to create machine learningmodels when training data is limited or unavailable.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '263',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07723v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14359672499909857504&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 599: {'ID': 599,\n",
       "  'title': 'SMASH: One-Shot Model Architecture Search through HyperNetworks',\n",
       "  'authors': ['Nick Weston', 'Andrew Brock', 'Theodore Lim', 'J. M. Ritchie'],\n",
       "  'published': '2017-08-17T16:03:33Z',\n",
       "  'updated': '2017-08-17T16:03:33Z',\n",
       "  'abstract': \"Designing architectures for deep neural networks requires expert knowledgeand substantial computation time. We propose a technique to acceleratearchitecture selection by learning an auxiliary HyperNet that generates theweights of a main model conditioned on that model's architecture. By comparingthe relative validation performance of networks with HyperNet-generatedweights, we can effectively search over a wide range of architectures at thecost of a single training run. To facilitate this search, we develop a flexiblemechanism based on memory read-writes that allows us to define a wide range ofnetwork connectivity patterns, with ResNet, DenseNet, and FractalNet blocks asspecial cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100,STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance withsimilarly-sized hand-designed networks. Our code is available athttps://github.com/ajbrock/SMASH\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '245',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.05344v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10456857144668119976&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 600: {'ID': 600,\n",
       "  'title': 'Obfuscated Gradients Give a False Sense of Security: Circumventing  Defenses to Adversarial Examples',\n",
       "  'authors': ['Nicholas Carlini', 'David Wagner', 'Anish Athalye'],\n",
       "  'published': '2018-02-01T18:20:05Z',\n",
       "  'updated': '2018-07-31T00:09:56Z',\n",
       "  'abstract': 'We identify obfuscated gradients, a kind of gradient masking, as a phenomenonthat leads to a false sense of security in defenses against adversarialexamples. While defenses that cause obfuscated gradients appear to defeatiterative optimization-based attacks, we find defenses relying on this effectcan be circumvented. We describe characteristic behaviors of defensesexhibiting the effect, and for each of the three types of obfuscated gradientswe discover, we develop attack techniques to overcome it. In a case study,examining non-certified white-box-secure defenses at ICLR 2018, we findobfuscated gradients are a common occurrence, with 7 of 9 defenses relying onobfuscated gradients. Our new attacks successfully circumvent 6 completely, and1 partially, in the original threat model each paper considers.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CR'],\n",
       "  'journal': 'ICML, 274-283',\n",
       "  'citations': '914',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1802.00420v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16371153415378772336&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 601: {'ID': 601,\n",
       "  'title': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model',\n",
       "  'authors': ['William W. Cohen',\n",
       "   'Zhilin Yang',\n",
       "   'Zihang Dai',\n",
       "   'Ruslan Salakhutdinov'],\n",
       "  'published': '2017-11-10T18:29:00Z',\n",
       "  'updated': '2018-03-02T20:20:52Z',\n",
       "  'abstract': 'We formulate language modeling as a matrix factorization problem, and showthat the expressiveness of Softmax-based models (including the majority ofneural language models) is limited by a Softmax bottleneck. Given that naturallanguage is highly context-dependent, this further implies that in practiceSoftmax with distributed word embeddings does not have enough capacity to modelnatural language. We propose a simple and effective method to address thisissue, and improve the state-of-the-art perplexities on Penn Treebank andWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels onthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 pointsin perplexity.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'ICLR',\n",
       "  'citations': '204',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.03953v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=15538946355362697879&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 602: {'ID': 602,\n",
       "  'title': 'Learning What and Where to Draw',\n",
       "  'authors': ['Scott Reed',\n",
       "   'Zeynep Akata',\n",
       "   'Samuel Tenka',\n",
       "   'Honglak Lee',\n",
       "   'Bernt Schiele',\n",
       "   'Santosh Mohan'],\n",
       "  'published': '2016-10-08T00:27:57Z',\n",
       "  'updated': '2016-10-08T00:27:57Z',\n",
       "  'abstract': 'Generative Adversarial Networks (GANs) have recently demonstrated thecapability to synthesize compelling real-world images, such as room interiors,album covers, manga, faces, birds, and flowers. While existing models cansynthesize images based on global constraints such as a class label or caption,they do not provide control over pose or object location. We propose a newmodel, the Generative Adversarial What-Where Network (GAWWN), that synthesizesimages given instructions describing what content to draw in which location. Weshow high-quality 128 x 128 image synthesis on the Caltech-UCSD Birds dataset,conditioned on both informal text descriptions and also object location. Oursystem exposes control over both the bounding box around the bird and itsconstituent parts. By modeling the conditional distributions over partlocations, our system also enables conditioning on arbitrary subsets of parts(e.g. only the beak and tail), yielding an efficient interface for picking partlocations. We also show preliminary results on the more challenging domain oftext- and location-controllable synthesis of images of human actions on theMPII Human Pose dataset.',\n",
       "  'categories': ['cs.CV', 'cs.NE'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '327',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.02454v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2100133886684978488&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 603: {'ID': 603,\n",
       "  'title': 'Style Transfer from Non-Parallel Text by Cross-Alignment',\n",
       "  'authors': ['Tianxiao Shen', 'Regina Barzilay', 'Tommi Jaakkola', 'Tao Lei'],\n",
       "  'published': '2017-05-26T17:40:12Z',\n",
       "  'updated': '2017-11-06T15:07:03Z',\n",
       "  'abstract': 'This paper focuses on style transfer on the basis of non-parallel text. Thisis an instance of a broad family of problems including machine translation,decipherment, and sentiment modification. The key challenge is to separate thecontent from other aspects such as style. We assume a shared latent contentdistribution across different text corpora, and propose a method that leveragesrefined alignment of latent representations to perform style transfer. Thetransferred sentences from one style should match example sentences from theother style as a population. We demonstrate the effectiveness of thiscross-alignment method on three tasks: sentiment modification, decipherment ofword substitution ciphers, and recovery of word order.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 31st International Conference on Neural Information\\xa0…',\n",
       "  'citations': '295',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.09655v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14976647505606347245&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 604: {'ID': 604,\n",
       "  'title': 'Video-to-Video Synthesis',\n",
       "  'authors': ['Bryan Catanzaro',\n",
       "   'Ting-Chun Wang',\n",
       "   'Ming-Yu Liu',\n",
       "   'Andrew Tao',\n",
       "   'Guilin Liu',\n",
       "   'Jan Kautz',\n",
       "   'Jun-Yan Zhu'],\n",
       "  'published': '2018-08-20T17:58:42Z',\n",
       "  'updated': '2018-12-03T15:12:44Z',\n",
       "  'abstract': 'We study the problem of video-to-video synthesis, whose goal is to learn amapping function from an input source video (e.g., a sequence of semanticsegmentation masks) to an output photorealistic video that precisely depictsthe content of the source video. While its image counterpart, theimage-to-image synthesis problem, is a popular topic, the video-to-videosynthesis problem is less explored in the literature. Without understandingtemporal dynamics, directly applying existing image synthesis approaches to aninput video often results in temporally incoherent videos of low visualquality. In this paper, we propose a novel video-to-video synthesis approachunder the generative adversarial learning framework. Through carefully-designedgenerator and discriminator architectures, coupled with a spatio-temporaladversarial objective, we achieve high-resolution, photorealistic, temporallycoherent video results on a diverse set of input formats including segmentationmasks, sketches, and poses. Experiments on multiple benchmarks show theadvantage of our method compared to strong baselines. In particular, our modelis capable of synthesizing 2K resolution videos of street scenes up to 30seconds long, which significantly advances the state-of-the-art of videosynthesis. Finally, we apply our approach to future video prediction,outperforming several state-of-the-art competing systems.',\n",
       "  'categories': ['cs.CV', 'cs.GR', 'cs.LG'],\n",
       "  'journal': 'Proceedings of the 32nd International Conference on Neural Information\\xa0…',\n",
       "  'citations': '295',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1808.06601v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=3120460092236365926&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 605: {'ID': 605,\n",
       "  'title': 'Deep Biaffine Attention for Neural Dependency Parsing',\n",
       "  'authors': ['Christopher D. Manning', 'Timothy Dozat'],\n",
       "  'published': '2016-11-06T07:26:38Z',\n",
       "  'updated': '2017-03-10T04:37:03Z',\n",
       "  'abstract': 'This paper builds off recent work from Kiperwasser &amp; Goldberg (2016) usingneural attention in a simple graph-based dependency parser. We use a larger butmore thoroughly regularized parser than other recent BiLSTM-based approaches,with biaffine classifiers to predict arcs and labels. Our parser gets state ofthe art or near state of the art performance on standard treebanks for sixdifferent languages, achieving 95.7% UAS and 94.1% LAS on the most popularEnglish PTB dataset. This makes it the highest-performing graph-based parser onthis benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and2.2%---and comparable to the highest performing transition-based parser(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also showwhich hyperparameter choices had a significant effect on parsing accuracy,allowing us to achieve large gains over other graph-based approaches.',\n",
       "  'categories': ['cs.CL', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '375',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01734v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2220752205833525649&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 606: {'ID': 606,\n",
       "  'title': 'FastGCN: Fast Learning with Graph Convolutional Networks via Importance  Sampling',\n",
       "  'authors': ['Cao Xiao', 'Jie Chen', 'Tengfei Ma'],\n",
       "  'published': '2018-01-30T22:36:16Z',\n",
       "  'updated': '2018-01-30T22:36:16Z',\n",
       "  'abstract': 'The graph convolutional networks (GCN) recently proposed by Kipf and Wellingare an effective graph model for semi-supervised learning. This model, however,was originally designed to be learned with the presence of both training andtest data. Moreover, the recursive neighborhood expansion across layers posestime and memory challenges for training with large, dense graphs. To relax therequirement of simultaneous availability of test data, we interpret graphconvolutions as integral transforms of embedding functions under probabilitymeasures. Such an interpretation allows for the use of Monte Carlo approachesto consistently estimate the integrals, which in turn leads to a batchedtraining scheme as we propose in this work---FastGCN. Enhanced with importancesampling, FastGCN not only is efficient for training but also generalizes wellfor inference. We show a comprehensive set of experiments to demonstrate itseffectiveness compared with GCN and related models. In particular, training isorders of magnitude more efficient while predictions remain comparablyaccurate.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '244',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.10247v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18054036108684442257&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 607: {'ID': 607,\n",
       "  'title': 'Certified Defenses against Adversarial Examples',\n",
       "  'authors': ['Percy Liang', 'Aditi Raghunathan', 'Jacob Steinhardt'],\n",
       "  'published': '2018-01-29T02:08:21Z',\n",
       "  'updated': '2020-10-31T23:38:30Z',\n",
       "  'abstract': 'While neural networks have achieved high accuracy on standard imageclassification benchmarks, their accuracy drops to nearly zero in the presenceof small adversarial perturbations to test inputs. Defenses based onregularization and adversarial training have been proposed, but often followedby new, stronger attacks that defeat these defenses. Can we somehow end thisarms race? In this work, we study this problem for neural networks with onehidden layer. We first propose a method based on a semidefinite relaxation thatoutputs a certificate that for a given network and test input, no attack canforce the error to exceed a certain value. Second, as this certificate isdifferentiable, we jointly optimize it with the network parameters, providingan adaptive regularizer that encourages robustness against all attacks. OnMNIST, our approach produces a network and a certificate that no attack thatperturbs each pixel by at most \\\\epsilon = 0.1 can cause more than 35% testerror.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '367',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.09344v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=17145877608540180848&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 608: {'ID': 608,\n",
       "  'title': 'Guided Cost Learning: Deep Inverse Optimal Control via Policy  Optimization',\n",
       "  'authors': ['Chelsea Finn', 'Sergey Levine', 'Pieter Abbeel'],\n",
       "  'published': '2016-03-01T20:35:56Z',\n",
       "  'updated': '2016-05-27T16:53:46Z',\n",
       "  'abstract': 'Reinforcement learning can acquire complex behaviors from high-levelspecifications. However, defining a cost function that can be optimizedeffectively and encodes the correct task is challenging in practice. We explorehow inverse optimal control (IOC) can be used to learn behaviors fromdemonstrations, with applications to torque control of high-dimensional roboticsystems. Our method addresses two key challenges in inverse optimal control:first, the need for informative features and effective regularization to imposestructure on the cost, and second, the difficulty of learning the cost functionunder unknown dynamics for high-dimensional continuous systems. To address theformer challenge, we present an algorithm capable of learning arbitrarynonlinear cost functions, such as neural networks, without meticulous featureengineering. To address the latter challenge, we formulate an efficientsample-based approximation for MaxEnt IOC. We evaluate our method on a seriesof simulated tasks and real-world robotic manipulation problems, demonstratingsubstantial improvement over prior methods both in terms of task complexity andsample efficiency.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO'],\n",
       "  'journal': 'ICML, 49-58',\n",
       "  'citations': '380',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.00448v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=10967669170920763264&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 609: {'ID': 609,\n",
       "  'title': 'Cost Sensitive Learning of Deep Feature Representations from Imbalanced  Data',\n",
       "  'authors': ['Salman H. Khan',\n",
       "   'Ferdous Sohel',\n",
       "   'Mohammed Bennamoun',\n",
       "   'Roberto Togneri',\n",
       "   'Munawar Hayat'],\n",
       "  'published': '2015-08-14T05:23:30Z',\n",
       "  'updated': '2017-03-23T10:57:10Z',\n",
       "  'abstract': 'Class imbalance is a common problem in the case of real-world objectdetection and classification tasks. Data of some classes is abundant makingthem an over-represented majority, and data of other classes is scarce, makingthem an under-represented minority. This imbalance makes it challenging for aclassifier to appropriately learn the discriminating boundaries of the majorityand minority classes. In this work, we propose a cost sensitive deep neuralnetwork which can automatically learn robust feature representations for boththe majority and minority classes. During training, our learning procedurejointly optimizes the class dependent costs and the neural network parameters.The proposed approach is applicable to both binary and multi-class problemswithout any modification. Moreover, as opposed to data level approaches, we donot alter the original data distribution which results in a lower computationalcost during the training process. We report the results of our experiments onsix major image classification datasets and show that the proposed approachsignificantly outperforms the baseline algorithms. Comparisons with populardata sampling techniques and cost sensitive classifiers demonstrate thesuperior performance of our proposed method.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'IEEE Transactions on Neural Networks and Learning Systems 29 (8), 3573-3587',\n",
       "  'citations': '259',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1508.03422v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=1674347993943612794&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 610: {'ID': 610,\n",
       "  'title': 'Delving Deeper into Convolutional Networks for Learning Video  Representations',\n",
       "  'authors': ['Nicolas Ballas', 'Aaron Courville', 'Chris Pal', 'Li Yao'],\n",
       "  'published': '2015-11-19T22:46:13Z',\n",
       "  'updated': '2016-03-01T18:54:11Z',\n",
       "  'abstract': 'We propose an approach to learn spatio-temporal features in videos fromintermediate visual representations we call \"percepts\" usingGated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on perceptsthat are extracted from all level of a deep convolutional network trained onthe large ImageNet dataset. While high-level percepts contain highlydiscriminative information, they tend to have a low-spatial resolution.Low-level percepts, on the other hand, preserve a higher spatial resolutionfrom which we can model finer motion patterns. Using low-level percepts canleads to high-dimensionality video representations. To mitigate this effect andcontrol the model number of parameters, we introduce a variant of the GRU modelthat leverages the convolution operations to enforce sparse connectivity of themodel units and share parameters across the input spatial locations.  We empirically validate our approach on both Human Action Recognition andVideo Captioning tasks. In particular, we achieve results equivalent tostate-of-art on the YouTube2Text dataset using a simpler text-decoder model andwithout extra 3D CNN features.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'cs.NE'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '303',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.06432v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=18128262244324468077&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 611: {'ID': 611,\n",
       "  'title': 'f-GAN: Training Generative Neural Samplers using Variational Divergence  Minimization',\n",
       "  'authors': ['Sebastian Nowozin', 'Ryota Tomioka', 'Botond Cseke'],\n",
       "  'published': '2016-06-02T14:53:33Z',\n",
       "  'updated': '2016-06-02T14:53:33Z',\n",
       "  'abstract': 'Generative neural samplers are probabilistic models that implement samplingusing feedforward neural networks: they take a random input vector and producea sample from a probability distribution defined by the network weights. Thesemodels are expressive and allow efficient computation of samples andderivatives, but cannot be used for computing likelihoods or formarginalization. The generative-adversarial training method allows to trainsuch models through the use of an auxiliary discriminative neural network. Weshow that the generative-adversarial approach is a special case of an existingmore general variational divergence estimation approach. We show that anyf-divergence can be used for training generative neural samplers. We discussthe benefits of various choices of divergence functions on training complexityand the quality of the obtained generative models.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'stat.ME'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '678',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1606.00709v1',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=11521929775075838473&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 612: {'ID': 612,\n",
       "  'title': 'Deep Learning without Poor Local Minima',\n",
       "  'authors': ['Kenji Kawaguchi'],\n",
       "  'published': '2016-05-23T17:34:20Z',\n",
       "  'updated': '2016-12-27T22:47:50Z',\n",
       "  'abstract': 'In this paper, we prove a conjecture published in 1989 and also partiallyaddress an open problem announced at the Conference on Learning Theory (COLT)2015. With no unrealistic assumption, we first prove the following statementsfor the squared loss function of deep linear neural networks with any depth andany widths: 1) the function is non-convex and non-concave, 2) every localminimum is a global minimum, 3) every critical point that is not a globalminimum is a saddle point, and 4) there exist \"bad\" saddle points (where theHessian has no negative eigenvalue) for the deeper networks (with more thanthree layers), whereas there is no bad saddle point for the shallow networks(with three layers). Moreover, for deep nonlinear neural networks, we prove thesame four statements via a reduction to a deep linear model under theindependence assumption adopted from recent work. As a result, we present aninstance, for which we can answer the following question: how difficult is itto directly train a deep model in theory? It is more difficult than theclassical machine learning models (because of the non-convexity), but not toodifficult (because of the nonexistence of poor local minima). Furthermore, themathematically proven existence of bad saddle points for deeper models wouldsuggest a possible open problem. We note that even though we have advanced thetheoretical foundations of deep learning and non-convex optimization, there isstill a gap between theory and practice.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'math.OC'],\n",
       "  'journal': 'Proceedings of the 30th International Conference on Neural Information\\xa0…',\n",
       "  'citations': '512',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1605.07110v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=16088411110075986174&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 613: {'ID': 613,\n",
       "  'title': 'Additive Margin Softmax for Face Verification',\n",
       "  'authors': ['Weiyang Liu', 'Jian Cheng', 'Haijun Liu', 'Feng Wang'],\n",
       "  'published': '2018-01-17T09:13:05Z',\n",
       "  'updated': '2018-05-30T12:35:03Z',\n",
       "  'abstract': 'In this paper, we propose a conceptually simple and geometricallyinterpretable objective function, i.e. additive margin Softmax (AM-Softmax),for deep face verification. In general, the face verification task can beviewed as a metric learning problem, so learning large-margin face featureswhose intra-class variation is small and inter-class difference is large is ofgreat importance in order to achieve good performance. Recently, Large-marginSoftmax and Angular Softmax have been proposed to incorporate the angularmargin in a multiplicative manner. In this work, we introduce a novel additiveangular margin for the Softmax loss, which is intuitively appealing and moreinterpretable than the existing works. We also emphasize and discuss theimportance of feature normalization in the paper. Most importantly, ourexperiments on LFW BLUFR and MegaFace show that our additive margin softmaxloss consistently performs better than the current state-of-the-art methodsusing the same network architecture and training dataset. Our code has alsobeen made available at https://github.com/happynear/AMSoftmax',\n",
       "  'categories': ['cs.CV'],\n",
       "  'journal': 'ICLR (Workshop)',\n",
       "  'citations': '296',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.05599v4',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=12037509454633593474&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 614: {'ID': 614,\n",
       "  'title': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language  Modeling',\n",
       "  'authors': ['Hakan Inan', 'Richard Socher', 'Khashayar Khosravi'],\n",
       "  'published': '2016-11-04T17:36:20Z',\n",
       "  'updated': '2017-03-11T19:13:52Z',\n",
       "  'abstract': 'Recurrent neural networks have been very successful at predicting sequencesof words in tasks such as language modeling. However, all such models are basedon the conventional classification framework, where the model is trainedagainst one-hot targets, and each word is represented both as an input and asan output in isolation. This causes inefficiencies in learning both in terms ofutilizing all of the information and in terms of the number of parametersneeded to train. We introduce a novel theoretical framework that facilitatesbetter learning in language modeling, and show that our framework leads totying together the input embedding and the output projection matrices, greatlyreducing the number of trainable variables. Our framework leads to state of theart performance on the Penn Treebank with a variety of network models.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'stat.ML'],\n",
       "  'journal': 'ICLR (Poster)',\n",
       "  'citations': '240',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.01462v3',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=14036439381566283404&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 615: {'ID': 615,\n",
       "  'title': 'Self-Attention Generative Adversarial Networks',\n",
       "  'authors': ['Dimitris Metaxas',\n",
       "   'Augustus Odena',\n",
       "   'Han Zhang',\n",
       "   'Ian Goodfellow'],\n",
       "  'published': '2018-05-21T23:10:35Z',\n",
       "  'updated': '2019-06-14T18:20:10Z',\n",
       "  'abstract': 'In this paper, we propose the Self-Attention Generative Adversarial Network(SAGAN) which allows attention-driven, long-range dependency modeling for imagegeneration tasks. Traditional convolutional GANs generate high-resolutiondetails as a function of only spatially local points in lower-resolutionfeature maps. In SAGAN, details can be generated using cues from all featurelocations. Moreover, the discriminator can check that highly detailed featuresin distant portions of the image are consistent with each other. Furthermore,recent work has shown that generator conditioning affects GAN performance.Leveraging this insight, we apply spectral normalization to the GAN generatorand find that this improves training dynamics. The proposed SAGAN achieves thestate-of-the-art results, boosting the best published Inception score from 36.8to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on thechallenging ImageNet dataset. Visualization of the attention layers shows thatthe generator leverages neighborhoods that correspond to object shapes ratherthan local regions of fixed shape.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'journal': 'ICML, 7354-7363',\n",
       "  'citations': '815',\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.08318v2',\n",
       "  'gscholar_url': 'http://scholar.google.com/scholar?oi=bibs&cluster=2966609467730095691&btnI=1&nossl=1&hl=en&oe=ASCII'},\n",
       " 616: {'ID': 616,\n",
       "  'title': 'Deep Reinforcement Learning for Control of Probabilistic Boolean  Networks',\n",
       "  'authors': ['Sotiris Moschoyiannis', 'Georgios Papagiannis'],\n",
       "  'published': '2019-09-07T20:24:41Z',\n",
       "  'updated': '2020-09-07T16:05:20Z',\n",
       "  'abstract': \"Probabilistic Boolean Networks (PBNs) were introduced as a computationalmodel for the study of complex dynamical systems, such as Gene RegulatoryNetworks (GRNs). Controllability in this context is the process of makingstrategic interventions to the state of a network in order to drive it towardssome other state that exhibits favourable biological properties. In this paperwe study the ability of a Double Deep Q-Network with Prioritized ExperienceReplay in learning control strategies within a finite number of time steps thatdrive a PBN towards a target state, typically an attractor. The control methodis model-free and does not require knowledge of the network's underlyingdynamics, making it suitable for applications where inference of such dynamicsis intractable. We present extensive experiment results on two synthetic PBNsand the PBN model constructed directly from gene-expression data of a study onmetastatic-melanoma.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.03331v5'},\n",
       " 617: {'ID': 617,\n",
       "  'title': 'Spherical CNNs on Unstructured Grids',\n",
       "  'authors': ['Prabhat',\n",
       "   'Karthik Kashinath',\n",
       "   'Matthias Niessner',\n",
       "   'Jingwei Huang',\n",
       "   'Chiyu \"Max\" Jiang',\n",
       "   'Philip Marcus'],\n",
       "  'published': '2019-01-07T19:56:19Z',\n",
       "  'updated': '2019-01-07T19:56:19Z',\n",
       "  'abstract': 'We present an efficient convolution kernel for Convolutional Neural Networks(CNNs) on unstructured grids using parameterized differential operators whilefocusing on spherical signals such as panorama images or planetary signals. Tothis end, we replace conventional convolution kernels with linear combinationsof differential operators that are weighted by learnable parameters.Differential operators can be efficiently estimated on unstructured grids usingone-ring neighbors, and learnable parameters can be optimized through standardback-propagation. As a result, we obtain extremely efficient neural networksthat match or outperform state-of-the-art network architectures in terms ofperformance but with a significantly lower number of network parameters. Weevaluate our algorithm in an extensive series of experiments on a variety ofcomputer vision and climate science tasks, including shape classification,climate pattern segmentation, and omnidirectional image semantic segmentation.Overall, we present (1) a novel CNN approach on unstructured grids usingparameterized differential operators for spherical signals, and (2) we showthat our unique kernel parameterization allows our model to achieve the same orhigher accuracy with significantly fewer network parameters.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.02039v1'},\n",
       " 618: {'ID': 618,\n",
       "  'title': 'Sim-to-Real Transfer of Robot Learning with Variable Length Inputs',\n",
       "  'authors': ['Jake Bruce',\n",
       "   'Robert Lee',\n",
       "   'Niko Sünderhauf',\n",
       "   'Vibhavari Dasagi',\n",
       "   'Jürgen Leitner',\n",
       "   'Serena Mou'],\n",
       "  'published': '2018-09-20T05:09:00Z',\n",
       "  'updated': '2019-10-09T00:21:04Z',\n",
       "  'abstract': 'Current end-to-end deep Reinforcement Learning (RL) approaches requirejointly learning perception, decision-making and low-level control from verysparse reward signals and high-dimensional inputs, with little capability ofincorporating prior knowledge. This results in prohibitively long trainingtimes for use on real-world robotic tasks. Existing algorithms capable ofextracting task-level representations from high-dimensional inputs, e.g. objectdetection, often produce outputs of varying lengths, restricting their use inRL methods due to the need for neural networks to have fixed length inputs. Inthis work, we propose a framework that combines deep sets encoding, whichallows for variable-length abstract representations, with modular RL thatutilizes these representations, decoupling high-level decision making fromlow-level control. We successfully demonstrate our approach on the robotmanipulation task of object sorting, showing that this method can learneffective policies within mere minutes of highly simplified simulation. Thelearned policies can be directly deployed on a robot without further training,and generalize to variations of the task unseen during training.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.07480v2'},\n",
       " 619: {'ID': 619,\n",
       "  'title': 'STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention  Network for Next POI Recommendation',\n",
       "  'authors': ['See-Kiong Ng',\n",
       "   'Yong Liang Goh',\n",
       "   'Xueou Wang',\n",
       "   'Bryan Hooi',\n",
       "   'Renrong Weng',\n",
       "   'Nicholas Lim',\n",
       "   'Jagannadan Varadarajan'],\n",
       "  'published': '2020-10-06T04:03:42Z',\n",
       "  'updated': '2020-10-06T04:03:42Z',\n",
       "  'abstract': \"Next Point-of-Interest (POI) recommendation is a longstanding problem acrossthe domains of Location-Based Social Networks (LBSN) and transportation. RecentRecurrent Neural Network (RNN) based approaches learn POI-POI relationships ina local view based on independent user visit sequences. This limits the model'sability to directly connect and learn across users in a global view torecommend semantically trained POIs. In this work, we propose aSpatial-Temporal-Preference User Dimensional Graph Attention Network(STP-UDGAT), a novel explore-exploit model that concurrently exploitspersonalized user preferences and explores new POIs in globalspatial-temporal-preference (STP) neighbourhoods, while allowing users toselectively learn from other users. In addition, we propose random walks as amasked self-attention option to leverage the STP graphs' structures and findnew higher-order POI neighbours during exploration. Experimental results on sixreal-world datasets show that our model significantly outperforms baseline andstate-of-the-art methods.\",\n",
       "  'categories': ['cs.IR', 'cs.LG', 'cs.SI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.07024v1'},\n",
       " 620: {'ID': 620,\n",
       "  'title': 'Attribute-Guided Coupled GAN for Cross-Resolution Face Recognition',\n",
       "  'authors': ['Nasser M Nasrabadi',\n",
       "   'Veeru Talreja',\n",
       "   'Matthew C Valenti',\n",
       "   'Fariborz Taherkhani'],\n",
       "  'published': '2019-08-05T18:10:55Z',\n",
       "  'updated': '2019-08-05T18:10:55Z',\n",
       "  'abstract': 'In this paper, we propose a novel attribute-guided cross-resolution(low-resolution to high-resolution) face recognition framework that leverages acoupled generative adversarial network (GAN) structure with adversarialtraining to find the hidden relationship between the low-resolution andhigh-resolution images in a latent common embedding subspace. The coupled GANframework consists of two sub-networks, one dedicated to the low-resolutiondomain and the other dedicated to the high-resolution domain. Each sub-networkaims to find a projection that maximizes the pair-wise correlation between thetwo feature domains in a common embedding subspace. In addition to projectingthe images into a common subspace, the coupled network also predicts facialattributes to improve the cross-resolution face recognition. Specifically, ourproposed coupled framework exploits facial attributes to further maximize thepair-wise correlation by implicitly matching facial attributes of the low andhigh-resolution images during the training, which leads to a morediscriminative embedding subspace resulting in performance enhancement forcross-resolution face recognition. The efficacy of our approach compared withthe state-of-the-art is demonstrated using the LFWA, Celeb-A, SCFace and UCCSdatasets.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.01790v1'},\n",
       " 621: {'ID': 621,\n",
       "  'title': 'Data Poisoning Attacks on Federated Machine Learning',\n",
       "  'authors': ['Gan Sun', 'Ji Liu', 'Qiang Wang', 'Jiahua Dong', 'Yang Cong'],\n",
       "  'published': '2020-04-19T03:45:05Z',\n",
       "  'updated': '2020-04-19T03:45:05Z',\n",
       "  'abstract': 'Federated machine learning which enables resource constrained node devices(e.g., mobile phones and IoT devices) to learn a shared model while keeping thetraining data local, can provide privacy, security and economic benefits bydesigning an effective communication protocol. However, the communicationprotocol amongst different nodes could be exploited by attackers to launch datapoisoning attacks, which has been demonstrated as a big threat to most machinelearning models. In this paper, we attempt to explore the vulnerability offederated machine learning. More specifically, we focus on attacking afederated multi-task learning framework, which is a federated learningframework via adopting a general multi-task learning framework to handlestatistical challenges. We formulate the problem of computing optimal poisoningattacks on federated multi-task learning as a bilevel program that is adaptiveto arbitrary choice of target nodes and source attacking nodes. Then we proposea novel systems-aware optimization method, ATTack on Federated Learning(AT2FL), which is efficiency to derive the implicit gradients for poisoneddata, and further compute optimal attack strategies in the federated machinelearning. Our work is an earlier study that considers issues of data poisoningattack for federated learning. To the end, experimental results on real-worlddatasets show that federated multi-task learning model is very sensitive topoisoning attacks, when the attackers either directly poison the target nodesor indirectly poison the related nodes by exploiting the communicationprotocol.',\n",
       "  'categories': ['cs.CR', 'cs.LG', 'I.2.11; I.5'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.10020v1'},\n",
       " 622: {'ID': 622,\n",
       "  'title': 'On Infinite-Width Hypernetworks',\n",
       "  'authors': ['Tomer Galanti', 'Etai Littwin', 'Greg Yang', 'Lior Wolf'],\n",
       "  'published': '2020-03-27T00:50:29Z',\n",
       "  'updated': '2020-11-03T08:00:21Z',\n",
       "  'abstract': \"{\\\\em Hypernetworks} are architectures that produce the weights of atask-specific {\\\\em primary network}. A notable application of hypernetworks inthe recent literature involves learning to output functional representations.In these scenarios, the hypernetwork learns a representation corresponding tothe weights of a shallow MLP, which typically encodes shape or imageinformation. While such representations have seen considerable success inpractice, they remain lacking in the theoretical guarantees in the wide regimeof the standard architectures. In this work, we study wide over-parameterizedhypernetworks. We show that unlike typical architectures, infinitely widehypernetworks do not guarantee convergence to a global minima under gradientdescent. We further show that convexity can be achieved by increasing thedimensionality of the hypernetwork's output, to represent wide MLPs. In thedually infinite-width regime, we identify the functional priors of thesearchitectures by deriving their corresponding GP and NTK kernels, the latter ofwhich we refer to as the {\\\\em hyperkernel}. As part of this study, we make amathematical contribution by deriving tight bounds on high order Taylorexpansion terms of standard fully connected ReLU networks.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.12193v6'},\n",
       " 623: {'ID': 623,\n",
       "  'title': 'DialogWAE: Multimodal Response Generation with Conditional Wasserstein  Auto-Encoder',\n",
       "  'authors': ['Jung-Woo Ha', 'Kyunghyun Cho', 'Sunghun Kim', 'Xiaodong Gu'],\n",
       "  'published': '2018-05-31T07:25:04Z',\n",
       "  'updated': '2019-02-26T02:32:44Z',\n",
       "  'abstract': 'Variational autoencoders~(VAEs) have shown a promise in data-drivenconversation modeling. However, most VAE conversation models match theapproximate posterior distribution over the latent variables to a simple priorsuch as standard normal distribution, thereby restricting the generatedresponses to a relatively simple (e.g., unimodal) scope. In this paper, wepropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) speciallydesigned for dialogue modeling. Unlike VAEs that impose a simple distributionover the latent variables, DialogWAE models the distribution of data bytraining a GAN within the latent variable space. Specifically, our modelsamples from the prior and posterior distributions over the latent variables bytransforming context-dependent random noise using neural networks and minimizesthe Wasserstein distance between the two distributions. We further develop aGaussian mixture prior network to enrich the latent space. Experiments on twopopular datasets show that DialogWAE outperforms the state-of-the-artapproaches in generating more coherent, informative and diverse responses.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.12352v2'},\n",
       " 624: {'ID': 624,\n",
       "  'title': 'Improving Accuracy and Diversity in Matching of Recommendation with  Diversified Preference Network',\n",
       "  'authors': ['Ruobing Xie',\n",
       "   'Shukai Liu',\n",
       "   'Ziwei Zhang',\n",
       "   'Bo Zhang',\n",
       "   'Leyu Lin',\n",
       "   'Qi Liu',\n",
       "   'Peng Cui'],\n",
       "  'published': '2021-02-07T12:14:18Z',\n",
       "  'updated': '2021-02-07T12:14:18Z',\n",
       "  'abstract': 'Recently, real-world recommendation systems need to deal with millions ofcandidates. It is extremely challenging to conduct sophisticated end-to-endalgorithms on the entire corpus due to the tremendous computation costs.Therefore, conventional recommendation systems usually contain two modules. Thematching module focuses on the coverage, which aims to efficiently retrievehundreds of items from large corpora, while the ranking module generatesspecific ranks for these items. Recommendation diversity is an essential factorthat impacts user experience. Most efforts have explored recommendationdiversity in ranking, while the matching module should take more responsibilityfor diversity. In this paper, we propose a novel Heterogeneous graph neuralnetwork framework for diversified recommendation (GraphDR) in matching toimprove both recommendation accuracy and diversity. Specifically, GraphDRbuilds a huge heterogeneous preference network to record different types ofuser preferences, and conduct a field-level heterogeneous graph attentionnetwork for node aggregation. We also innovatively conduct aneighbor-similarity based loss to balance both recommendation accuracy anddiversity for the diversified matching task. In experiments, we conductextensive online and offline evaluations on a real-world recommendation systemwith various accuracy and diversity metrics and achieve significantimprovements. We also conduct model analyses and case study for a betterunderstanding of our model. Moreover, GraphDR has been deployed on a well-knownrecommendation system, which affects millions of users. The source code will bereleased.',\n",
       "  'categories': ['cs.IR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.03787v1'},\n",
       " 625: {'ID': 625,\n",
       "  'title': 'Non-Markovian Control with Gated End-to-End Memory Policy Networks',\n",
       "  'authors': ['Tomi Silander', 'Julien Perez'],\n",
       "  'published': '2017-05-31T09:00:44Z',\n",
       "  'updated': '2017-05-31T09:00:44Z',\n",
       "  'abstract': 'Partially observable environments present an important open challenge in thedomain of sequential control learning with delayed rewards. Despite numerousattempts during the two last decades, the majority of reinforcement learningalgorithms and associated approximate models, applied to this context, stillassume Markovian state transitions. In this paper, we explore the use of arecently proposed attention-based model, the Gated End-to-End Memory Network,for sequential control. We call the resulting model the Gated End-to-End MemoryPolicy Network. More precisely, we use a model-free value-based algorithm tolearn policies for partially observed domains using this memory-enhanced neuralnetwork. This model is end-to-end learnable and it features unbounded memory.Indeed, because of its attention mechanism and associated non-parametricmemory, the proposed model allows us to define an attention mechanism over theobservation stream unlike recurrent models. We show encouraging results thatillustrate the capability of our attention-based model in the context of thecontinuous-state non-stationary control problem of stock trading. We alsopresent an OpenAI Gym environment for simulated stock exchange and explain itsrelevance as a benchmark for the field of non-Markovian decision processlearning.',\n",
       "  'categories': ['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1705.10993v1'},\n",
       " 626: {'ID': 626,\n",
       "  'title': 'Hypernetwork Science via High-Order Hypergraph Walks',\n",
       "  'authors': ['Brenda Praggastis',\n",
       "   'Cliff Joslyn',\n",
       "   'Sinan G. Aksoy',\n",
       "   'Carlos Ortiz Marrero',\n",
       "   'Emilie Purvine'],\n",
       "  'published': '2019-06-26T18:52:33Z',\n",
       "  'updated': '2020-06-08T17:02:26Z',\n",
       "  'abstract': 'We propose high-order hypergraph walks as a framework to generalizegraph-based network science techniques to hypergraphs. Edge incidence inhypergraphs is quantitative, yielding hypergraph walks with both length andwidth. Graph methods which then generalize to hypergraphs include connectedcomponent analyses, graph distance-based metrics such as closeness centrality,and motif-based measures such as clustering coefficients. We apply high-orderanalogs of these methods to real world hypernetworks, and show they revealnuanced and interpretable structure that cannot be detected by graph-basedmethods. Lastly, we apply three generative models to the data and find thatbasic hypergraph properties, such as density and degree distributions, do notnecessarily control these new structural measurements. Our work demonstrateshow analyses of hypergraph-structured data are richer when utilizing toolstailored to capture hypergraph-native phenomena, and suggests one possibleavenue towards that end.',\n",
       "  'categories': ['physics.soc-ph', 'cs.SI', 'physics.data-an'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.11295v2'},\n",
       " 627: {'ID': 627,\n",
       "  'title': 'Low-Dose CT via Deep CNN with Skip Connection and Network in Network',\n",
       "  'authors': ['Yi Zhang', 'Chenyu You', 'Linfeng Yang', 'Ge Wang'],\n",
       "  'published': '2018-11-26T18:08:44Z',\n",
       "  'updated': '2019-08-03T02:53:26Z',\n",
       "  'abstract': 'A major challenge in computed tomography (CT) is how to minimize patientradiation exposure without compromising image quality and diagnosticperformance. The use of deep convolutional (Conv) neural networks for noisereduction in Low-Dose CT (LDCT) images has recently shown a great potential inthis important application. In this paper, we present a highly efficient andeffective neural network model for LDCT image noise reduction. Specifically, tocapture local anatomical features we integrate Deep Convolutional NeuralNetworks (CNNs) and Skip connection layers for feature extraction. Also, weintroduce parallelized $1\\\\times 1$ CNN, called Network in Network, to lower thedimensionality of the output from the previous layer, achieving fastercomputational speed at less feature loss. To optimize the performance of thenetwork, we adopt a Wasserstein generative adversarial network (WGAN)framework. Quantitative and qualitative comparisons demonstrate that ourproposed network model can produce images with lower noise and more structuraldetails than state-of-the-art noise-reduction methods.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.10564v2'},\n",
       " 628: {'ID': 628,\n",
       "  'title': 'Efficient Exact Verification of Binarized Neural Networks',\n",
       "  'authors': ['Martin Rinard', 'Kai Jia'],\n",
       "  'published': '2020-05-07T16:34:30Z',\n",
       "  'updated': '2020-10-27T04:00:16Z',\n",
       "  'abstract': 'Concerned with the reliability of neural networks, researchers have developedverification techniques to prove their robustness. Most verifiers work withreal-valued networks. Unfortunately, the exact (complete and sound) verifiersface scalability challenges and provide no correctness guarantees due tofloating point errors. We argue that Binarized Neural Networks (BNNs) providecomparable robustness and allow exact and significantly more efficientverification. We present a new system, EEV, for efficient and exactverification of BNNs. EEV consists of two parts: (i) a novel SAT solver thatspeeds up BNN verification by natively handling the reified cardinalityconstraints arising in BNN encodings; and (ii) strategies to trainsolver-friendly robust BNNs by inducing balanced layer-wise sparsity and lowcardinality bounds, and adaptively cancelling the gradients. We demonstrate theeffectiveness of EEV by presenting the first exact verification results forL-inf-bounded adversarial robustness of nontrivial convolutional BNNs on theMNIST and CIFAR10 datasets. Compared to exact verification of real-valuednetworks of the same architectures on the same tasks, EEV verifies BNNshundreds to thousands of times faster, while delivering comparable verifiableaccuracy in most cases.',\n",
       "  'categories': ['cs.AI', 'cs.CV', 'cs.LG', 'cs.LO', 'cs.SC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.03597v2'},\n",
       " 629: {'ID': 629,\n",
       "  'title': 'Real-Time Workload Classification during Driving using HyperNetworks',\n",
       "  'authors': ['Pierluigi V. Amadori', 'Yiannis Demiris', 'Ruohan Wang'],\n",
       "  'published': '2018-10-07T13:57:25Z',\n",
       "  'updated': '2018-10-07T13:57:25Z',\n",
       "  'abstract': 'Classifying human cognitive states from behavioral and physiological signalsis a challenging problem with important applications in robotics. The problemis challenging due to the data variability among individual users, and sensorartefacts. In this work, we propose an end-to-end framework for real-timecognitive workload classification with mixture Hyper Long Short Term MemoryNetworks, a novel variant of HyperNetworks. Evaluating the proposed approach onan eye-gaze pattern dataset collected from simulated driving scenarios ofdifferent cognitive demands, we show that the proposed framework outperformsprevious baseline methods and achieves 83.9\\\\% precision and 87.8\\\\% recallduring test. We also demonstrate the merit of our proposed architecture byshowing improved performance over other LSTM-based methods.',\n",
       "  'categories': ['cs.HC', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.03145v1'},\n",
       " 630: {'ID': 630,\n",
       "  'title': 'A Generative Model for Sampling High-Performance and Diverse Weights for  Neural Networks',\n",
       "  'authors': ['Lior Deutsch', 'Yu Yang', 'Erik Nijkamp'],\n",
       "  'published': '2019-05-07T04:28:46Z',\n",
       "  'updated': '2019-05-07T04:28:46Z',\n",
       "  'abstract': 'Recent work on mode connectivity in the loss landscape of deep neuralnetworks has demonstrated that the locus of (sub-)optimal weight vectors lieson continuous paths. In this work, we train a neural network that serves as ahypernetwork, mapping a latent vector into high-performance (low-loss) weightvectors, generalizing recent findings of mode connectivity to higherdimensional manifolds. We formulate the training objective as a compromisebetween accuracy and diversity, where the diversity takes into account trivialsymmetry transformations of the target network. We demonstrate how to reducethe number of parameters in the hypernetwork by parameter sharing. Oncelearned, the hypernetwork allows for a computationally efficient, ancestralsampling of neural network weights, which we recruit to form large ensembles.The improvement in classification accuracy obtained by this ensemblingindicates that the generated manifold extends in dimensions other thandirections implied by trivial symmetries. For computational efficiency, wedistill an ensemble into a single classifier while retaining generalization.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.02898v1'},\n",
       " 631: {'ID': 631,\n",
       "  'title': 'Hypernetworks: From Posets to Geometry',\n",
       "  'authors': ['Emil Saucan'],\n",
       "  'published': '2021-01-16T10:57:38Z',\n",
       "  'updated': '2021-01-16T10:57:38Z',\n",
       "  'abstract': 'We show that hypernetworks can be regarded as posets which, in their turn,have a natural interpretation as simplicial complexes and, as such, are endowedwith an intrinsic notion of curvature, namely the Forman Ricci curvature, thatstrongly correlates with the Euler characteristic of the simplicial complex.This approach, inspired by the work of E. Bloch, allows us to canonicallyassociate a simplicial complex structure to a hypernetwork, directed orundirected. In particular, this greatly simplifying the geometric PersistentHomology method we previously proposed.',\n",
       "  'categories': ['math.AT',\n",
       "   'cs.CG',\n",
       "   'cs.SI',\n",
       "   'math.DG',\n",
       "   '53Z50, 57Q70 55N31, 05C82'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.06429v1'},\n",
       " 632: {'ID': 632,\n",
       "  'title': 'Hybrid Deep Learning for Detecting Lung Diseases from X-ray Images',\n",
       "  'authors': ['Prajoy Podder',\n",
       "   'M. Rubaiyat Hossain Mondal',\n",
       "   'Subrato Bharati'],\n",
       "  'published': '2020-03-02T06:07:30Z',\n",
       "  'updated': '2020-07-01T17:31:27Z',\n",
       "  'abstract': 'Lung disease is common throughout the world. These include chronicobstructive pulmonary disease, pneumonia, asthma, tuberculosis, fibrosis, etc.Timely diagnosis of lung disease is essential. Many image processing andmachine learning models have been developed for this purpose. Different formsof existing deep learning techniques including convolutional neural network(CNN), vanilla neural network, visual geometry group based neural network(VGG), and capsule network are applied for lung disease prediction.The basicCNN has poor performance for rotated, tilted, or other abnormal imageorientation. Therefore, we propose a new hybrid deep learning framework bycombining VGG, data augmentation and spatial transformer network (STN) withCNN. This new hybrid method is termed here as VGG Data STN with CNN (VDSNet).As implementation tools, Jupyter Notebook, Tensorflow, and Keras are used. Thenew model is applied to NIH chest X-ray image dataset collected from Kagglerepository. Full and sample versions of the dataset are considered. For bothfull and sample datasets, VDSNet outperforms existing methods in terms of anumber of metrics including precision, recall, F0.5 score and validationaccuracy. For the case of full dataset, VDSNet exhibits a validation accuracyof 73%, while vanilla gray, vanilla RGB, hybrid CNN and VGG, and modifiedcapsule network have accuracy values of 67.8%, 69%, 69.5%, 60.5% and 63.8%,respectively. When sample dataset rather than full dataset is used, VDSNetrequires much lower training time at the expense of a slightly lower validationaccuracy. Hence, the proposed VDSNet framework will simplify the detection oflung disease for experts as well as for doctors.',\n",
       "  'categories': ['eess.IV', 'cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.00682v3'},\n",
       " 633: {'ID': 633,\n",
       "  'title': 'On the Difference Between the Information Bottleneck and the Deep  Information Bottleneck',\n",
       "  'authors': ['Aleksander Wieczorek', 'Volker Roth'],\n",
       "  'published': '2019-12-31T18:31:42Z',\n",
       "  'updated': '2019-12-31T18:31:42Z',\n",
       "  'abstract': 'Combining the Information Bottleneck model with deep learning by replacingmutual information terms with deep neural nets has proved successful in areasranging from generative modelling to interpreting deep neural networks. In thispaper, we revisit the Deep Variational Information Bottleneck and theassumptions needed for its derivation. The two assumed properties of the data$X$, $Y$ and their latent representation $T$ take the form of two Markov chains$T-X-Y$ and $X-T-Y$. Requiring both to hold during the optimisation process canbe limiting for the set of potential joint distributions $P(X,Y,T)$. Wetherefore show how to circumvent this limitation by optimising a lower boundfor $I(T;Y)$ for which only the latter Markov chain has to be satisfied. Theactual mutual information consists of the lower bound which is optimised inDVIB and cognate models in practice and of two terms measuring how much theformer requirement $T-X-Y$ is violated. Finally, we propose to interpret thefamily of information bottleneck models as directed graphical models and showthat in this framework the original and deep information bottlenecks arespecial cases of a fundamental IB model.',\n",
       "  'categories': ['cs.LG', 'cs.IT', 'math.IT', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.13480v1'},\n",
       " 634: {'ID': 634,\n",
       "  'title': 'PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective  Crop Layers',\n",
       "  'authors': ['Helge Rhodin', 'Frank Yu', 'Pascal Fua', 'Mathieu Salzmann'],\n",
       "  'published': '2020-11-27T08:48:43Z',\n",
       "  'updated': '2020-11-27T08:48:43Z',\n",
       "  'abstract': 'Local processing is an essential feature of CNNs and other neural networkarchitectures - it is one of the reasons why they work so well on images whererelevant information is, to a large extent, local. However, perspective effectsstemming from the projection in a conventional camera vary for different globalpositions in the image. We introduce Perspective Crop Layers (PCLs) - a form ofperspective crop of the region of interest based on the camera geometry - andshow that accounting for the perspective consistently improves the accuracy ofstate-of-the-art 3D pose reconstruction methods. PCLs are modular neuralnetwork layers, which, when inserted into existing CNN and MLP architectures,deterministically remove the location-dependent perspective effects whileleaving end-to-end training and the number of parameters of the underlyingneural network unchanged. We demonstrate that PCL leads to improved 3D humanpose reconstruction accuracy for CNN architectures that use croppingoperations, such as spatial transformer networks (STN), and, somewhatsurprisingly, MLPs used for 2D-to-3D keypoint lifting. Our conclusion is thatit is important to utilize camera calibration information when available, forclassical and deep-learning-based computer vision alike. PCL offers an easy wayto improve the accuracy of existing 3D reconstruction networks by making themgeometry-aware.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.13607v1'},\n",
       " 635: {'ID': 635,\n",
       "  'title': 'Fast Adaptation in Generative Models with Generative Matching Networks',\n",
       "  'authors': ['Sergey Bartunov', 'Dmitry P. Vetrov'],\n",
       "  'published': '2016-12-07T10:50:37Z',\n",
       "  'updated': '2017-09-05T07:41:15Z',\n",
       "  'abstract': 'Despite recent advances, the remaining bottlenecks in deep generative modelsare necessity of extensive training and difficulties with generalization fromsmall number of training examples. We develop a new generative model calledGenerative Matching Network which is inspired by the recently proposed matchingnetworks for one-shot learning in discriminative tasks. By conditioning on theadditional input dataset, our model can instantly learn new concepts that werenot available in the training data but conform to a similar generative process.The proposed framework does not explicitly restrict diversity of theconditioning data and also does not require an extensive inference procedurefor training or adaptation. Our experiments on the Omniglot dataset demonstratethat Generative Matching Networks significantly improve predictive performanceon the fly as more additional data is available and outperform existing stateof the art conditional generative models.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'I.2.6; I.5'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1612.02192v2'},\n",
       " 636: {'ID': 636,\n",
       "  'title': 'Deep Networks with Stochastic Depth',\n",
       "  'authors': ['Gao Huang',\n",
       "   'Kilian Weinberger',\n",
       "   'Zhuang Liu',\n",
       "   'Daniel Sedra',\n",
       "   'Yu Sun'],\n",
       "  'published': '2016-03-30T20:58:07Z',\n",
       "  'updated': '2016-07-28T23:24:16Z',\n",
       "  'abstract': 'Very deep convolutional networks with hundreds of layers have led tosignificant reductions in error on competitive benchmarks. Although theunmatched expressiveness of the many layers can be highly desirable at testtime, training very deep networks comes with its own set of challenges. Thegradients can vanish, the forward flow often diminishes, and the training timecan be painfully slow. To address these problems, we propose stochastic depth,a training procedure that enables the seemingly contradictory setup to trainshort networks and use deep networks at test time. We start with very deepnetworks but during training, for each mini-batch, randomly drop a subset oflayers and bypass them with the identity function. This simple approachcomplements the recent success of residual networks. It reduces training timesubstantially and improves the test error significantly on almost all data setsthat we used for evaluation. With stochastic depth we can increase the depth ofresidual networks even beyond 1200 layers and still yield meaningfulimprovements in test error (4.91% on CIFAR-10).',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.09382v3'},\n",
       " 637: {'ID': 637,\n",
       "  'title': 'InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations',\n",
       "  'authors': ['Yunzhu Li', 'Stefano Ermon', 'Jiaming Song'],\n",
       "  'published': '2017-03-26T16:20:36Z',\n",
       "  'updated': '2017-11-14T21:51:21Z',\n",
       "  'abstract': 'The goal of imitation learning is to mimic expert behavior without access toan explicit reward signal. Expert demonstrations provided by humans, however,often show significant variability due to latent factors that are typically notexplicitly modeled. In this paper, we propose a new algorithm that can inferthe latent structure of expert demonstrations in an unsupervised way. Ourmethod, built on top of Generative Adversarial Imitation Learning, can not onlyimitate complex behaviors, but also learn interpretable and meaningfulrepresentations of complex behavioral data, including visual demonstrations. Inthe driving domain, we show that a model learned from human demonstrations isable to both accurately reproduce a variety of behaviors and accuratelyanticipate human actions using raw visual inputs. Compared with variousbaselines, our method can better capture the latent structure underlying expertdemonstrations, often recovering semantically meaningful factors of variationin the data.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1703.08840v2'},\n",
       " 638: {'ID': 638,\n",
       "  'title': 'Graph Attention Networks for Speaker Verification',\n",
       "  'authors': ['Ha-Jin Yu', 'Hee-Soo Heo', 'Joon Son Chung', 'Jee-weon Jung'],\n",
       "  'published': '2020-10-22T09:08:02Z',\n",
       "  'updated': '2021-02-08T08:12:17Z',\n",
       "  'abstract': 'This work presents a novel back-end framework for speaker verification usinggraph attention networks. Segment-wise speaker embeddings extracted frommultiple crops within an utterance are interpreted as node representations of agraph. The proposed framework inputs segment-wise speaker embeddings from anenrollment and a test utterance and directly outputs a similarity score. Wefirst construct a graph using segment-wise speaker embeddings and then inputthese to graph attention networks. After a few graph attention layers withresidual connections, each node is projected into a one-dimensional space usingaffine transform, followed by a readout operation resulting in a scalarsimilarity score. To enable successful adaptation for speaker verification, wepropose techniques such as separating trainable weights for attention mapcalculations between segment-wise speaker embeddings from different utterances.The effectiveness of the proposed framework is validated using three differentspeaker embedding extractors trained with different architectures and objectivefunctions. Experimental results demonstrate consistent improvement over variousbaseline back-end classifiers, with an average equal error rate improvement of20% over the cosine similarity back-end without test time augmentation.',\n",
       "  'categories': ['eess.AS', 'cs.CL', 'cs.SD'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11543v2'},\n",
       " 639: {'ID': 639,\n",
       "  'title': 'SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards',\n",
       "  'authors': ['Anca D. Dragan', 'Siddharth Reddy', 'Sergey Levine'],\n",
       "  'published': '2019-05-27T10:29:31Z',\n",
       "  'updated': '2019-09-25T18:44:47Z',\n",
       "  'abstract': 'Learning to imitate expert behavior from demonstrations can be challenging,especially in environments with high-dimensional, continuous observations andunknown dynamics. Supervised learning methods based on behavioral cloning (BC)suffer from distribution shift: because the agent greedily imitatesdemonstrated actions, it can drift away from demonstrated states due to erroraccumulation. Recent methods based on reinforcement learning (RL), such asinverse RL and generative adversarial imitation learning (GAIL), overcome thisissue by training an RL agent to match the demonstrations over a long horizon.Since the true reward function for the task is unknown, these methods learn areward function from the demonstrations, often using complex and brittleapproximation techniques that involve adversarial training. We propose a simplealternative that still uses RL, but does not require learning a rewardfunction. The key idea is to provide the agent with an incentive to match thedemonstrations over a long horizon, by encouraging it to return to demonstratedstates upon encountering new, out-of-distribution states. We accomplish this bygiving the agent a constant reward of r=+1 for matching the demonstrated actionin a demonstrated state, and a constant reward of r=0 for all other behavior.Our method, which we call soft Q imitation learning (SQIL), can be implementedwith a handful of minor modifications to any standard Q-learning or off-policyactor-critic algorithm. Theoretically, we show that SQIL can be interpreted asa regularized variant of BC that uses a sparsity prior to encouragelong-horizon imitation. Empirically, we show that SQIL outperforms BC andachieves competitive results compared to GAIL, on a variety of image-based andlow-dimensional tasks in Box2D, Atari, and MuJoCo.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.11108v3'},\n",
       " 640: {'ID': 640,\n",
       "  'title': 'Learning to Match Distributions for Domain Adaptation',\n",
       "  'authors': ['Yiqiang Chen',\n",
       "   'Jindong Wang',\n",
       "   'Tie-Yan Liu',\n",
       "   'Tao Qin',\n",
       "   'Chaohui Yu',\n",
       "   'Chang Liu',\n",
       "   'Wenjie Feng',\n",
       "   'Renjun Xu'],\n",
       "  'published': '2020-07-17T03:26:13Z',\n",
       "  'updated': '2020-07-27T01:44:38Z',\n",
       "  'abstract': \"When the training and test data are from different distributions, domainadaptation is needed to reduce dataset bias to improve the model'sgeneralization ability. Since it is difficult to directly match thecross-domain joint distributions, existing methods tend to reduce the marginalor conditional distribution divergence using predefined distances such as MMDand adversarial-based discrepancies. However, it remains challenging todetermine which method is suitable for a given application since they are builtwith certain priors or bias. Thus they may fail to uncover the underlyingrelationship between transferable features and joint distributions. This paperproposes Learning to Match (L2M) to automatically learn the cross-domaindistribution matching without relying on hand-crafted priors on the matchingloss. Instead, L2M reduces the inductive bias by using a meta-network to learnthe distribution matching loss in a data-driven way. L2M is a general frameworkthat unifies task-independent and human-designed matching features. We design anovel optimization algorithm for this challenging objective withself-supervised label propagation. Experiments on public datasets substantiatethe superiority of L2M over SOTA methods. Moreover, we apply L2M to transferfrom pneumonia to COVID-19 chest X-ray images with remarkable performance. L2Mcan also be extended in other distribution matching applications where we showin a trial experiment that L2M generates more realistic and sharper MNISTsamples.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.10791v3'},\n",
       " 641: {'ID': 641,\n",
       "  'title': 'BiDet: An Efficient Binarized Object Detector',\n",
       "  'authors': ['Ziwei Wang', 'Jie Zhou', 'Ziyi Wu', 'Jiwen Lu'],\n",
       "  'published': '2020-03-09T08:16:16Z',\n",
       "  'updated': '2020-03-09T08:16:16Z',\n",
       "  'abstract': 'In this paper, we propose a binarized neural network learning method calledBiDet for efficient object detection. Conventional network binarization methodsdirectly quantize the weights and activations in one-stage or two-stagedetectors with constrained representational capacity, so that the informationredundancy in the networks causes numerous false positives and degrades theperformance significantly. On the contrary, our BiDet fully utilizes therepresentational capacity of the binary neural networks for object detection byredundancy removal, through which the detection precision is enhanced withalleviated false positives. Specifically, we generalize the informationbottleneck (IB) principle to object detection, where the amount of informationin the high-level feature maps is constrained and the mutual informationbetween the feature maps and object detection is maximized. Meanwhile, we learnsparse object priors so that the posteriors are concentrated on informativedetection prediction with false positive elimination. Extensive experiments onthe PASCAL VOC and COCO datasets show that our method outperforms thestate-of-the-art binary neural networks by a sizable margin.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.03961v1'},\n",
       " 642: {'ID': 642,\n",
       "  'title': 'Compact Neural Networks based on the Multiscale Entanglement  Renormalization Ansatz',\n",
       "  'authors': ['Andrew G. Green',\n",
       "   'Andrew Hallam',\n",
       "   'Simone Severini',\n",
       "   'Edward Grant',\n",
       "   'Vid Stojevic'],\n",
       "  'published': '2017-11-09T12:55:59Z',\n",
       "  'updated': '2018-12-12T23:55:50Z',\n",
       "  'abstract': 'This paper demonstrates a method for tensorizing neural networks based uponan efficient way of approximating scale invariant quantum states, theMulti-scale Entanglement Renormalization Ansatz (MERA). We employ MERA as areplacement for the fully connected layers in a convolutional neural networkand test this implementation on the CIFAR-10 and CIFAR-100 datasets. Theproposed method outperforms factorization using tensor trains, providinggreater compression for the same level of accuracy and greater accuracy for thesame level of compression. We demonstrate MERA layers with 14000 times fewerparameters and a reduction in accuracy of less than 1% compared to theequivalent fully connected layers, scaling like O(N).',\n",
       "  'categories': ['cs.NE', 'cs.CV', 'quant-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.03357v3'},\n",
       " 643: {'ID': 643,\n",
       "  'title': 'Which Channel to Ask My Question? Personalized Customer Service Request  Stream Routing using Deep Reinforcement Learning',\n",
       "  'authors': ['Yafang Wang',\n",
       "   'Zehong Hu',\n",
       "   'Zining Liu',\n",
       "   'Chong Long',\n",
       "   'Xiaolu Lu',\n",
       "   'Jie Zhang'],\n",
       "  'published': '2019-11-24T12:57:03Z',\n",
       "  'updated': '2019-11-24T12:57:03Z',\n",
       "  'abstract': \"Customer services are critical to all companies, as they may directly connectto the brand reputation. Due to a great number of customers, e-commercecompanies often employ multiple communication channels to answer customers'questions, for example, chatbot and hotline. On one hand, each channel haslimited capacity to respond to customers' requests, on the other hand,customers have different preferences over these channels. The currentproduction systems are mainly built based on business rules, which merelyconsiders tradeoffs between resources and customers' satisfaction. To achievethe optimal tradeoff between resources and customers' satisfaction, we proposea new framework based on deep reinforcement learning, which directly takes bothresources and user model into account. In addition to the framework, we alsopropose a new deep-reinforcement-learning based routing method-double duelingdeep Q-learning with prioritized experience replay (PER-DoDDQN). We evaluateour proposed framework and method using both synthetic and a real customerservice log data from a large financial technology company. We show that ourproposed deep-reinforcement-learning based framework is superior to theexisting production system. Moreover, we also show our proposed PER-DoDDQN isbetter than all other deep Q-learning variants in practice, which provides amore optimal routing plan. These observations suggest that our proposed methodcan seek the trade-off where both channel resources and customers' satisfactionare optimal.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.10521v1'},\n",
       " 644: {'ID': 644,\n",
       "  'title': 'Deep learning prediction of patient response time course from early data  via neural-pharmacokinetic/pharmacodynamic modeling',\n",
       "  'authors': ['James Lu', 'Yuanfang Guan', 'Jin Y. Jin', 'Brendan Bender'],\n",
       "  'published': '2020-10-22T14:43:22Z',\n",
       "  'updated': '2020-10-22T14:43:22Z',\n",
       "  'abstract': 'The longitudinal analysis of patient response time course following doses oftherapeutics is currently performed using Pharmacokinetic/Pharmacodynamic(PK/PD) methodologies, which requires significant human experience andexpertise in the modeling of dynamical systems. By utilizing recentadvancements in deep learning, we show that the governing differentialequations can be learnt directly from longitudinal patient data. In particular,we propose a novel neural-PK/PD framework that combines key pharmacologicalprinciples with neural ordinary differential equations. We applied it to ananalysis of drug concentration and platelet response from a clinical datasetconsisting of over 600 patients. We show that the neural-PK/PD model improvesupon a state-of-the-art model with respect to metrics for temporal prediction.Furthermore, by incorporating key PK/PD concepts into its architecture, themodel can generalize and enable the simulations of patient responses tountested dosing regimens. These results demonstrate the potential ofneural-PK/PD for automated predictive analytics of patient response timecourse.',\n",
       "  'categories': ['cs.LG', 'q-bio.QM'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11769v1'},\n",
       " 645: {'ID': 645,\n",
       "  'title': 'Distributed Prioritized Experience Replay',\n",
       "  'authors': ['Hado van Hasselt',\n",
       "   'Gabriel Barth-Maron',\n",
       "   'Matteo Hessel',\n",
       "   'John Quan',\n",
       "   'Dan Horgan',\n",
       "   'David Budden',\n",
       "   'David Silver'],\n",
       "  'published': '2018-03-02T16:21:46Z',\n",
       "  'updated': '2018-03-02T16:21:46Z',\n",
       "  'abstract': 'We propose a distributed architecture for deep reinforcement learning atscale, that enables agents to learn effectively from orders of magnitude moredata than previously possible. The algorithm decouples acting from learning:the actors interact with their own instances of the environment by selectingactions according to a shared neural network, and accumulate the resultingexperience in a shared experience replay memory; the learner replays samples ofexperience and updates the neural network. The architecture relies onprioritized experience replay to focus only on the most significant datagenerated by the actors. Our architecture substantially improves the state ofthe art on the Arcade Learning Environment, achieving better final performancein a fraction of the wall-clock training time.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.00933v1'},\n",
       " 646: {'ID': 646,\n",
       "  'title': 'WEST operation with real time feed back control based on wall component  temperature toward machine protection in a steady state tungsten environment',\n",
       "  'authors': ['Victor Moncada',\n",
       "   'Chakib Belaldil',\n",
       "   'Rémy Nouailletas',\n",
       "   'Colette Balorin',\n",
       "   'Xavier Courtois',\n",
       "   'Raphaël Mitteau',\n",
       "   'Benjamin Santraine'],\n",
       "  'published': '2021-01-06T08:14:37Z',\n",
       "  'updated': '2021-01-06T08:14:37Z',\n",
       "  'abstract': \"A real time Wall Monitoring System (WMS) is used on the WEST tokamak duringthe C4 experimental campaign. The WMS uses the wall surface temperatures from 6fields of view of the Infrared viewing system. It extracts the raw digital datafrom selected areas, converts it to temperatures using the calibration andwrite it on the shared memory network being used by the Plasma Control System(PCS). The PCS feeds back to actuators, namely the injected power from 5antennae's of the lower hybrid and ion cyclotron resonance radiofrequency (RF)heating systems. WMS activates feed back control 63 times during C4, which is14% of the plasma discharges. It activates mainly as the result of a direct RFloss to the upper divertor pipes. The feedback control maintains the walltemperature within the operation envelope during 97% of the occurrences, whileenabling plasma discharge continuation. The false positive rate establishes at0.2%. WMS significantly facilitated the operation path to high power operationduring C4, by managing the technical risks to critical wall components.\",\n",
       "  'categories': ['physics.plasm-ph', 'eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.01914v1'},\n",
       " 647: {'ID': 647,\n",
       "  'title': 'Augmented Equivariant Attention Networks for Electron Microscopy Image  Super-Resolution',\n",
       "  'authors': ['Yaochen Xie', 'Shuiwang Ji', 'Yu Ding'],\n",
       "  'published': '2020-11-06T23:37:49Z',\n",
       "  'updated': '2020-12-10T17:29:29Z',\n",
       "  'abstract': 'Taking electron microscopy (EM) images in high-resolution is time-consumingand expensive and could be detrimental to the integrity of the samples underobservation. Advances in deep learning enable us to perform super-resolutioncomputationally, so as to obtain high-resolution images from low-resolutionones. When training super-resolution models on pairs of experimentally acquiredEM images, prior models suffer from performance loss while using thepooled-training strategy due to their inability to capture inter-imagedependencies and common features shared among images. Although there existmethods that take advantage of shared features among input instances in imageclassification tasks, they in the current form cannot be applied tosuper-resolution tasks because they fail to preserve an essential property inimage-to-image transformation problems, which is the equivariance property tospatial permutations. To address these limitations, we propose the augmentedequivariant attention networks (AEANets) with better capability to captureinter-image dependencies and shared features, while preserving the equivarianceto spatial permutations. The proposed AEANets captures inter-image dependenciesand common features shared among images via two augmentations on the attentionmechanism; namely, the shared references and the batch-aware attention duringtraining. We theoretically show the equivariance property of the proposedaugmented attention model and experimentally show that AEANets consistentlyoutperforms the baselines in both quantitative and visual results.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.03633v2'},\n",
       " 648: {'ID': 648,\n",
       "  'title': 'Shallow Univariate ReLu Networks as Splines: Initialization, Loss  Surface, Hessian, &amp; Gradient Flow Dynamics',\n",
       "  'authors': ['Onur Tavaslioglu',\n",
       "   'Justin Sahs',\n",
       "   'Josue Ortega Caro',\n",
       "   'Ankit Patel',\n",
       "   'Aneel Damaraju',\n",
       "   'Andy Lu',\n",
       "   'Ryan Pyle'],\n",
       "  'published': '2020-08-04T19:19:49Z',\n",
       "  'updated': '2020-08-04T19:19:49Z',\n",
       "  'abstract': 'Understanding the learning dynamics and inductive bias of neural networks(NNs) is hindered by the opacity of the relationship between NN parameters andthe function represented. We propose reparametrizing ReLU NNs as continuouspiecewise linear splines. Using this spline lens, we study learning dynamics inshallow univariate ReLU NNs, finding unexpected insights and explanations forseveral perplexing phenomena. We develop a surprisingly simple and transparentview of the structure of the loss surface, including its critical and fixedpoints, Hessian, and Hessian spectrum. We also show that standard weightinitializations yield very flat functions, and that this flatness, togetherwith overparametrization and the initial weight scale, is responsible for thestrength and type of implicit regularization, consistent with recent workarXiv:1906.05827. Our implicit regularization results are complementary torecent work arXiv:1906.07842, done independently, which showed thatinitialization scale critically controls implicit regularization via akernel-based argument. Our spline-based approach reproduces their key implicitregularization results but in a far more intuitive and transparent manner.Going forward, our spline-based approach is likely to extend naturally to themultivariate and deep settings, and will play a foundational role in efforts tounderstand neural networks. Videos of learning dynamics using a spline-basedvisualization are available at http://shorturl.at/tFWZ2.',\n",
       "  'categories': ['cs.LG', 'stat.ML', 'I.2.0'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.01772v1'},\n",
       " 649: {'ID': 649,\n",
       "  'title': 'Quasi-Newton Trust Region Policy Optimization',\n",
       "  'authors': ['Diego Romeres', 'Arvind Raghunathan', 'Devesh Jha'],\n",
       "  'published': '2019-12-26T18:29:38Z',\n",
       "  'updated': '2019-12-26T18:29:38Z',\n",
       "  'abstract': 'We propose a trust region method for policy optimization that employsQuasi-Newton approximation for the Hessian, called Quasi-Newton Trust RegionPolicy Optimization QNTRPO. Gradient descent is the de facto algorithm forreinforcement learning tasks with continuous controls. The algorithm hasachieved state-of-the-art performance when used in reinforcement learningacross a wide range of tasks. However, the algorithm suffers from a number ofdrawbacks including: lack of stepsize selection criterion, and slowconvergence. We investigate the use of a trust region method using dogleg stepand a Quasi-Newton approximation for the Hessian for policy optimization. Wedemonstrate through numerical experiments over a wide range of challengingcontinuous control tasks that our particular choice is efficient in terms ofnumber of samples and improves performance',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.11912v1'},\n",
       " 650: {'ID': 650,\n",
       "  'title': 'Transition-based Semantic Dependency Parsing with Pointer Networks',\n",
       "  'authors': ['Daniel Fernández-González', 'Carlos Gómez-Rodríguez'],\n",
       "  'published': '2020-05-27T13:18:27Z',\n",
       "  'updated': '2020-05-28T11:10:31Z',\n",
       "  'abstract': 'Transition-based parsers implemented with Pointer Networks have become thenew state of the art in dependency parsing, excelling in producing labelledsyntactic trees and outperforming graph-based models in this task. In order tofurther test the capabilities of these powerful neural networks on a harder NLPproblem, we propose a transition system that, thanks to Pointer Networks, canstraightforwardly produce labelled directed acyclic graphs and perform semanticdependency parsing. In addition, we enhance our approach with deepcontextualized word embeddings extracted from BERT. The resulting system notonly outperforms all existing transition-based models, but also matches thebest fully-supervised accuracy to date on the SemEval 2015 Task 18 Englishdatasets among previous state-of-the-art graph-based parsers.',\n",
       "  'categories': ['cs.CL', '68T50', 'I.2.7'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.13344v2'},\n",
       " 651: {'ID': 651,\n",
       "  'title': 'Atlas-ISTN: Joint Segmentation, Registration and Atlas Construction with  Image-and-Spatial Transformer Networks',\n",
       "  'authors': ['James Batten',\n",
       "   'Ben Glocker',\n",
       "   'Ying Bai',\n",
       "   'Kersten Petersen',\n",
       "   'Karl Hahn',\n",
       "   'Andreas Schuh',\n",
       "   'Michiel Schaap',\n",
       "   'Matthew Sinclair'],\n",
       "  'published': '2020-12-18T21:53:09Z',\n",
       "  'updated': '2020-12-18T21:53:09Z',\n",
       "  'abstract': \"Deep learning models for semantic segmentation are able to learn powerfulrepresentations for pixel-wise predictions, but are sensitive to noise at testtime and do not guarantee a plausible topology. Image registration models onthe other hand are able to warp known topologies to target images as a means ofsegmentation, but typically require large amounts of training data, and havenot widely been benchmarked against pixel-wise segmentation models. We proposeAtlas-ISTN, a framework that jointly learns segmentation and registration on 2Dand 3D image data, and constructs a population-derived atlas in the process.Atlas-ISTN learns to segment multiple structures of interest and to registerthe constructed, topologically consistent atlas labelmap to an intermediatepixel-wise segmentation. Additionally, Atlas-ISTN allows for test timerefinement of the model's parameters to optimize the alignment of the atlaslabelmap to an intermediate pixel-wise segmentation. This process bothmitigates for noise in the target image that can result in spurious pixel-wisepredictions, as well as improves upon the one-pass prediction of the model.Benefits of the Atlas-ISTN framework are demonstrated qualitatively andquantitatively on 2D synthetic data and 3D cardiac computed tomography andbrain magnetic resonance image data, out-performing both segmentation andregistration baseline models. Atlas-ISTN also provides inter-subjectcorrespondence of the structures of interest, enabling population-level shapeand motion analysis.\",\n",
       "  'categories': ['eess.IV', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.10533v1'},\n",
       " 652: {'ID': 652,\n",
       "  'title': 'Deep Learning and Density Functional Theory',\n",
       "  'authors': ['Kevin Ryczko', 'David Strubbe', 'Isaac Tamblyn'],\n",
       "  'published': '2018-11-21T20:03:01Z',\n",
       "  'updated': '2018-11-21T20:03:01Z',\n",
       "  'abstract': 'Density functional theory (DFT) is used for quantum mechanical simulations ofelectrons in molecules and materials, for applications in chemistry, physics,materials science, and engineering. However, usage of DFT for large numbers ofatoms is hindered by typical scaling of $\\\\mathcal{O}(N^3)$. Demonstration of asufficiently accurate reduced model with deep neural networks would enablewidespread application of DFT on larger, more complex systems for newscientific discoveries. We show that deep neural networks can be integratedinto, or fully replace, the Kohn-Sham density functional theory scheme formulti-electron systems in simple harmonic oscillator and random externalpotentials. We first show that self-consistent charge densities can be used asinput to an extensive deep neural network to make predictions for correlation,exchange, external, kinetic and total energies simultaneously. Additionally, weshow that one can also make all of the same predictions with the externalpotential rather than the self-consistent charge density, which allows one tocircumvent the Kohn-Sham scheme altogether. We then show that a self-consistentcharge density found from a non-local exchange-correlation functional can beused to make energy predictions for a semi-local exchange-correlationfunctional. Lastly, we use a deep convolutional inverse graphics network topredict the charge density given an external potential and asses the viabilityof the predicted charge densities. This work shows that extensive deep neuralnetworks are generalizable and transferable given the variability of thepotentials and the fact that they can scale to an arbitrary system size with an$\\\\mathcal{O}(N)$ computational cost.',\n",
       "  'categories': ['cond-mat.mtrl-sci', 'physics.comp-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.08928v1'},\n",
       " 653: {'ID': 653,\n",
       "  'title': 'Generative Moment Matching Network-based Random Modulation Post-filter  for DNN-based Singing Voice Synthesis and Neural Double-tracking',\n",
       "  'authors': ['Hiroshi Saruwatari',\n",
       "   'Tomoki Koriyama',\n",
       "   'Hiroki Tamaru',\n",
       "   'Shinnosuke Takamichi',\n",
       "   'Yuki Saito'],\n",
       "  'published': '2019-02-09T07:49:42Z',\n",
       "  'updated': '2019-02-09T07:49:42Z',\n",
       "  'abstract': 'This paper proposes a generative moment matching network (GMMN)-basedpost-filter that provides inter-utterance pitch variation for deep neuralnetwork (DNN)-based singing voice synthesis. The natural pitch variation of ahuman singing voice leads to a richer musical experience and is used indouble-tracking, a recording method in which two performances of the samephrase are recorded and mixed to create a richer, layered sound. However,singing voices synthesized using conventional DNN-based methods never varybecause the synthesis process is deterministic and only one waveform issynthesized from one musical score. To address this problem, we use a GMMN tomodel the variation of the modulation spectrum of the pitch contour of naturalsinging voices and add a randomized inter-utterance variation to the pitchcontour generated by conventional DNN-based singing voice synthesis.Experimental evaluations suggest that 1) our approach can provide perceptibleinter-utterance pitch variation while preserving speech quality. We extend ourapproach to double-tracking, and the evaluation demonstrates that 2) GMMN-basedneural double-tracking is perceptually closer to natural double-tracking thanconventional signal processing-based artificial double-tracking is.',\n",
       "  'categories': ['cs.SD', 'cs.AI', 'cs.LG', 'cs.MM', 'cs.NE', 'eess.AS'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.03389v1'},\n",
       " 654: {'ID': 654,\n",
       "  'title': '3D Quasi-Recurrent Neural Network for Hyperspectral Image Denoising',\n",
       "  'authors': ['Kaixuan Wei', 'Hua Huang', 'Ying Fu'],\n",
       "  'published': '2020-03-10T06:14:53Z',\n",
       "  'updated': '2020-03-10T06:14:53Z',\n",
       "  'abstract': 'In this paper, we propose an alternating directional 3D quasi-recurrentneural network for hyperspectral image (HSI) denoising, which can effectivelyembed the domain knowledge -- structural spatio-spectral correlation and globalcorrelation along spectrum. Specifically, 3D convolution is utilized to extractstructural spatio-spectral correlation in an HSI, while a quasi-recurrentpooling function is employed to capture the global correlation along spectrum.Moreover, alternating directional structure is introduced to eliminate thecausal dependency with no additional computation cost. The proposed model iscapable of modeling spatio-spectral dependency while preserving the flexibilitytowards HSIs with arbitrary number of bands. Extensive experiments on HSIdenoising demonstrate significant improvement over state-of-the-arts undervarious noise settings, in terms of both restoration accuracy and computationtime. Our code is available at https://github.com/Vandermode/QRNN3D.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.04547v1'},\n",
       " 655: {'ID': 655,\n",
       "  'title': 'The JuliaConnectoR: a functionally oriented interface for integrating  Julia in R',\n",
       "  'authors': ['Stefan Lenz', 'Maren Hackenberg', 'Harald Binder'],\n",
       "  'published': '2020-05-13T14:18:34Z',\n",
       "  'updated': '2020-05-13T14:18:34Z',\n",
       "  'abstract': 'Like many groups considering the new programming language Julia, we faced thechallenge of accessing the algorithms that we develop in Julia from R.Therefore, we developed the R package JuliaConnectoR, available from the CRANrepository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), inparticular for making advanced deep learning tools available. Formaintainability and stability, we decided to base communication between R andJulia on TCP, using an optimized binary format for exchanging data. Our packagealso specifically contains features that allow for a convenient interactive usein R. This makes it easy to develop R extensions with Julia or to simply callfunctionality from Julia packages in R. With its functionally oriented design,the JuliaConnectoR enables a clean programming style by avoiding state in Juliathat is not visible in the R workspace. We illustrate the further features ofour package with code examples, and also discuss advantages over the twoalternative packages JuliaCall and XRJulia. Finally, we demonstrate the usageof the package with a more extensive example for employing neural ordinarydifferential equations, a recent deep learning technique that has received muchattention. This example also provides more general guidance for integratingdeep learning techniques from Julia into R.',\n",
       "  'categories': ['cs.MS', 'cs.LG', 'cs.PL', 'stat.CO', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.06334v1'},\n",
       " 656: {'ID': 656,\n",
       "  'title': 'Dual Distribution Alignment Network for Generalizable Person  Re-Identification',\n",
       "  'authors': ['Pingyang Dai',\n",
       "   'Peixian Chen',\n",
       "   'Qi Tian',\n",
       "   'Feng Zheng',\n",
       "   'Rongrong Ji',\n",
       "   'Jianzhuang Liu'],\n",
       "  'published': '2020-07-27T00:08:07Z',\n",
       "  'updated': '2020-07-27T00:08:07Z',\n",
       "  'abstract': 'Domain generalization (DG) serves as a promising solution to handle personRe-Identification (Re-ID), which trains the model using labels from the sourcedomain alone, and then directly adopts the trained model to the target domainwithout model updating. However, existing DG approaches are usually disturbedby serious domain variations due to significant dataset variations.Subsequently, DG highly relies on designing domain-invariant features, which ishowever not well exploited, since most existing approaches directly mixmultiple datasets to train DG based models without considering the localdataset similarities, i.e., examples that are very similar but from differentdomains. In this paper, we present a Dual Distribution Alignment Network(DDAN), which handles this challenge by mapping images into a domain-invariantfeature space by selectively aligning distributions of multiple source domains.Such an alignment is conducted by dual-level constraints, i.e., the domain-wiseadversarial feature learning and the identity-wise similarity enhancement. Weevaluate our DDAN on a large-scale Domain Generalization Re-ID (DG Re-ID)benchmark. Quantitative results demonstrate that the proposed DDAN can wellalign the distributions of various source domains, and significantlyoutperforms all existing domain generalization approaches.',\n",
       "  'categories': ['cs.IR', 'cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.13249v1'},\n",
       " 657: {'ID': 657,\n",
       "  'title': 'Delay Differential Neural Networks',\n",
       "  'authors': ['Srinivas Anumasa', 'P. K. Srijith'],\n",
       "  'published': '2020-12-12T12:20:54Z',\n",
       "  'updated': '2020-12-12T12:20:54Z',\n",
       "  'abstract': 'Neural ordinary differential equations (NODEs) treat computation ofintermediate feature vectors as trajectories of ordinary differential equationparameterized by a neural network. In this paper, we propose a novel model,delay differential neural networks (DDNN), inspired by delay differentialequations (DDEs). The proposed model considers the derivative of the hiddenfeature vector as a function of the current feature vector and past featurevectors (history). The function is modelled as a neural network andconsequently, it leads to continuous depth alternatives to many recent ResNetvariants. We propose two different DDNN architectures, depending on the waycurrent and past feature vectors are considered. For training DDNNs, we providea memory-efficient adjoint method for computing gradients and back-propagatethrough the network. DDNN improves the data efficiency of NODE by furtherreducing the number of parameters without affecting the generalizationperformance. Experiments conducted on synthetic and real-world imageclassification datasets such as Cifar10 and Cifar100 show the effectiveness ofthe proposed models.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.06800v1'},\n",
       " 658: {'ID': 658,\n",
       "  'title': 'Imitation Learning for Human Pose Prediction',\n",
       "  'authors': ['Ehsan Adeli',\n",
       "   'Juan Carlos Niebles',\n",
       "   'Hsu-kuang Chiu',\n",
       "   'Borui Wang',\n",
       "   'De-An Huang'],\n",
       "  'published': '2019-09-08T12:39:31Z',\n",
       "  'updated': '2019-09-08T12:39:31Z',\n",
       "  'abstract': 'Modeling and prediction of human motion dynamics has long been a challengingproblem in computer vision, and most existing methods rely on the end-to-endsupervised training of various architectures of recurrent neural networks.Inspired by the recent success of deep reinforcement learning methods, in thispaper we propose a new reinforcement learning formulation for the problem ofhuman pose prediction, and develop an imitation learning algorithm forpredicting future poses under this formulation through a combination ofbehavioral cloning and generative adversarial imitation learning. Ourexperiments show that our proposed method outperforms all existingstate-of-the-art baseline models by large margins on the task of human poseprediction in both short-term predictions and long-term predictions, while alsoenjoying huge advantage in training speed.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.03449v1'},\n",
       " 659: {'ID': 659,\n",
       "  'title': 'Measuring Visual Generalization in Continuous Control from Pixels',\n",
       "  'authors': ['Yanjun Qi', 'Jake Grigsby'],\n",
       "  'published': '2020-10-13T23:42:40Z',\n",
       "  'updated': '2020-11-27T20:33:03Z',\n",
       "  'abstract': \"Self-supervised learning and data augmentation have significantly reduced theperformance gap between state and image-based reinforcement learning agents incontinuous control tasks. However, it is still unclear whether currenttechniques can face a variety of visual conditions required by real-worldenvironments. We propose a challenging benchmark that tests agents' visualgeneralization by adding graphical variety to existing continuous controldomains. Our empirical analysis shows that current methods struggle togeneralize across a diverse set of visual changes, and we examine the specificfactors of variation that make these tasks difficult. We find that dataaugmentation techniques outperform self-supervised learning approaches and thatmore significant image transformations provide better visual generalization\\\\footnote{The benchmark and our augmented actor-critic implementation areopen-sourced @ https://github.com/QData/dmc_remastered)\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CV', 'cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.06740v2'},\n",
       " 660: {'ID': 660,\n",
       "  'title': 'Radial Deformation Emplacement in Power Transformers Using Long  Short-Term Memory Networks',\n",
       "  'authors': ['Behnam Mohammadi-Ivatloo',\n",
       "   'Kazem Pourhossein',\n",
       "   'Ali Bidram',\n",
       "   'Arash Moradzadeh',\n",
       "   'Tohid Khalili'],\n",
       "  'published': '2020-12-13T06:55:05Z',\n",
       "  'updated': '2020-12-13T06:55:05Z',\n",
       "  'abstract': 'A power transformer winding is usually subject to mechanical stress andtension because of improper transportation or operation. Radial deformation(RD) is an example of mechanical stress that can impact power transformeroperation through short circuit faults and insulation damages. Frequencyresponse analysis (FRA) is a well-known method to diagnose mechanical defectsin transformers. Despite the precision of FRA, the interpretation of thecalculated frequency response curves is not straightforward and requirescomplex calculations. In this paper, a deep learning algorithm called longshort-term memory (LSTM) is used as a feature extraction technique to locate RDfaults in their early stages. The experimental results verify the effectivenessof the proposed method in the diagnosis and locating of RD defects.',\n",
       "  'categories': ['eess.SY', 'cs.LG', 'cs.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.06982v1'},\n",
       " 661: {'ID': 661,\n",
       "  'title': 'MUST-GAN: Multi-level Statistics Transfer for Self-driven Person Image  Generation',\n",
       "  'authors': ['Bo Peng', 'Tianxiang Ma', 'Wei Wang', 'Jing Dong'],\n",
       "  'published': '2020-11-18T04:38:48Z',\n",
       "  'updated': '2020-11-23T02:03:31Z',\n",
       "  'abstract': \"Pose-guided person image generation usually involves using pairedsource-target images to supervise the training, which significantly increasesthe data preparation effort and limits the application of the models. To dealwith this problem, we propose a novel multi-level statistics transfer model,which disentangles and transfers multi-level appearance features from personimages and merges them with pose features to reconstruct the source personimages themselves. So that the source images can be used as supervision forself-driven person image generation. Specifically, our model extractsmulti-level features from the appearance encoder and learns the optimalappearance representation through attention mechanism and attributesstatistics. Then we transfer them to a pose-guided generator for re-fusion ofappearance and pose. Our approach allows for flexible manipulation of personappearance and pose properties to perform pose transfer and clothes styletransfer tasks. Experimental results on the DeepFashion dataset demonstrate ourmethod's superiority compared with state-of-the-art supervised and unsupervisedmethods. In addition, our approach also performs well in the wild.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.09084v2'},\n",
       " 662: {'ID': 662,\n",
       "  'title': 'A Hierarchical Decoding Model For Spoken Language Understanding From  Unaligned Data',\n",
       "  'authors': ['Kai Yu', 'Zijian Zhao', 'Su Zhu'],\n",
       "  'published': '2019-04-09T07:26:25Z',\n",
       "  'updated': '2019-04-09T07:26:25Z',\n",
       "  'abstract': 'Spoken language understanding (SLU) systems can be trained on two types oflabelled data: aligned or unaligned. Unaligned data do not require word by wordannotation and is easier to be obtained. In the paper, we focus on spokenlanguage understanding from unaligned data whose annotation is a set ofact-slot-value triples. Previous works usually focus on improve slot-value pairprediction and estimate dialogue act types separately, which ignores thehierarchical structure of the act-slot-value triples. Here, we propose a novelhierarchical decoding model which dynamically parses act, slot and value in astructured way and employs pointer network to handle out-of-vocabulary (OOV)values. Experiments on DSTC2 dataset, a benchmark unaligned dataset, show thatthe proposed model not only outperforms previous state-of-the-art model, butalso can be generalized effectively and efficiently to unseen act-slot typepairs and OOV values.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.04498v1'},\n",
       " 663: {'ID': 663,\n",
       "  'title': 'Physics-informed semantic inpainting: Application to geostatistical  modeling',\n",
       "  'authors': ['George Em Karniadakis',\n",
       "   'Zhendan Cao',\n",
       "   'Qiang Zheng',\n",
       "   'Lingzao Zeng'],\n",
       "  'published': '2019-09-19T15:50:01Z',\n",
       "  'updated': '2019-12-23T12:21:44Z',\n",
       "  'abstract': 'A fundamental problem in geostatistical modeling is to infer theheterogeneous geological field based on limited measurements and some priorspatial statistics. Semantic inpainting, a technique for image processing usingdeep generative models, has been recently applied for this purpose,demonstrating its effectiveness in dealing with complex spatial patterns.However, the original semantic inpainting framework incorporates onlyinformation from direct measurements, while in geostatistics indirectmeasurements are often plentiful. To overcome this limitation, here we proposea physics-informed semantic inpainting framework, employing the WassersteinGenerative Adversarial Network with Gradient Penalty (WGAN-GP) and jointlyincorporating the direct and indirect measurements by exploiting the underlyingphysical laws. Our simulation results for a high-dimensional problem with 512dimensions show that in the new method, the physical conservation laws aresatisfied and contribute in enhancing the inpainting performance compared tousing only the direct measurements.',\n",
       "  'categories': ['eess.IV', 'cs.LG', 'physics.comp-ph', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.09459v2'},\n",
       " 664: {'ID': 664,\n",
       "  'title': 'Pointer Graph Networks',\n",
       "  'authors': ['Petar Veličković',\n",
       "   'Razvan Pascanu',\n",
       "   'Charles Blundell',\n",
       "   'Oriol Vinyals',\n",
       "   'Matthew C. Overlan',\n",
       "   'Lars Buesing'],\n",
       "  'published': '2020-06-11T12:52:31Z',\n",
       "  'updated': '2020-10-18T20:00:59Z',\n",
       "  'abstract': 'Graph neural networks (GNNs) are typically applied to static graphs that areassumed to be known upfront. This static input structure is often informedpurely by insight of the machine learning practitioner, and might not beoptimal for the actual task the GNN is solving. In absence of reliable domainexpertise, one might resort to inferring the latent graph structure, which isoften difficult due to the vast search space of possible graphs. Here weintroduce Pointer Graph Networks (PGNs) which augment sets or graphs withadditional inferred edges for improved model generalisation ability. PGNs alloweach node to dynamically point to another node, followed by message passingover these pointers. The sparsity of this adaptable graph structure makeslearning tractable while still being sufficiently expressive to simulatecomplex algorithms. Critically, the pointing mechanism is directly supervisedto model long-term sequences of operations on classical data structures,incorporating useful structural inductive biases from theoretical computerscience. Qualitatively, we demonstrate that PGNs can learn parallelisablevariants of pointer-based data structures, namely disjoint set unions andlink/cut trees. PGNs generalise out-of-distribution to 5x larger test inputs ondynamic graph connectivity tasks, outperforming unrestricted GNNs and DeepSets.',\n",
       "  'categories': ['stat.ML', 'cs.DS', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.06380v2'},\n",
       " 665: {'ID': 665,\n",
       "  'title': 'Stochastic Optimization with Laggard Data Pipelines',\n",
       "  'authors': ['Naman Agarwal',\n",
       "   'Cyril Zhang',\n",
       "   'Kunal Talwar',\n",
       "   'Rohan Anil',\n",
       "   'Tomer Koren'],\n",
       "  'published': '2020-10-26T14:55:31Z',\n",
       "  'updated': '2020-10-26T14:55:31Z',\n",
       "  'abstract': 'State-of-the-art optimization is steadily shifting towards massively parallelpipelines with extremely large batch sizes. As a consequence, CPU-boundpreprocessing and disk/memory/network operations have emerged as newperformance bottlenecks, as opposed to hardware-accelerated gradientcomputations. In this regime, a recently proposed approach is data echoing(Choi et al., 2019), which takes repeated gradient steps on the same batchwhile waiting for fresh data to arrive from upstream. We provide the firstconvergence analyses of \"data-echoed\" extensions of common optimizationmethods, showing that they exhibit provable improvements over their synchronouscounterparts. Specifically, we show that in convex optimization with stochasticminibatches, data echoing affords speedups on the curvature-dominated part ofthe convergence rate, while maintaining the optimal statistical rate.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.13639v1'},\n",
       " 666: {'ID': 666,\n",
       "  'title': 'A Test of Relative Similarity For Model Selection in Generative Models',\n",
       "  'authors': ['Eugene Belilovsky',\n",
       "   'Matthew B. Blaschko',\n",
       "   'Arthur Gretton',\n",
       "   'Wacha Bounliphone',\n",
       "   'Ioannis Antonoglou'],\n",
       "  'published': '2015-11-14T17:18:47Z',\n",
       "  'updated': '2016-02-15T15:12:44Z',\n",
       "  'abstract': 'Probabilistic generative models provide a powerful framework for representingdata that avoids the expense of manual annotation typically needed bydiscriminative approaches. Model selection in this generative setting can bechallenging, however, particularly when likelihoods are not easily accessible.To address this issue, we introduce a statistical test of relative similarity,which is used to determine which of two models generates samples that aresignificantly closer to a real-world reference dataset of interest. We use asour test statistic the difference in maximum mean discrepancies (MMDs) betweenthe reference dataset and each model dataset, and derive a powerful,low-variance test based on the joint asymptotic distribution of the MMDsbetween each reference-model pair. In experiments on deep generative models,including the variational auto-encoder and generative moment matching network,the tests provide a meaningful ranking of model performance as a function ofparameter and training settings.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1511.04581v4'},\n",
       " 667: {'ID': 667,\n",
       "  'title': 'Detecting Adversarial Attacks on Neural Network Policies with Visual  Foresight',\n",
       "  'authors': ['Jia-Bin Huang', 'Ming-Yu Liu', 'Yen-Chen Lin', 'Min Sun'],\n",
       "  'published': '2017-10-02T17:56:26Z',\n",
       "  'updated': '2017-10-02T17:56:26Z',\n",
       "  'abstract': 'Deep reinforcement learning has shown promising results in learning controlpolicies for complex sequential decision-making tasks. However, these neuralnetwork-based policies are known to be vulnerable to adversarial examples. Thisvulnerability poses a potentially serious threat to safety-critical systemssuch as autonomous vehicles. In this paper, we propose a defense mechanism todefend reinforcement learning agents from adversarial attacks by leveraging anaction-conditioned frame prediction module. Our core idea is that theadversarial examples targeting at a neural network-based policy are noteffective for the frame prediction model. By comparing the action distributionproduced by a policy from processing the current observed frame to the actiondistribution produced by the same policy from processing the predicted framefrom the action-conditioned frame prediction module, we can detect the presenceof adversarial examples. Beyond detecting the presence of adversarial examples,our method allows the agent to continue performing the task using the predictedframe when the agent is under attack. We evaluate the performance of ouralgorithm using five games in Atari 2600. Our results demonstrate that theproposed defense mechanism achieves favorable performance against baselinealgorithms in detecting adversarial examples and in earning rewards when theagents are under attack.',\n",
       "  'categories': ['cs.CV', 'cs.CR', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.00814v1'},\n",
       " 668: {'ID': 668,\n",
       "  'title': 'A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring  of Answer Transcriptions in Video Job Interviews',\n",
       "  'authors': ['Meng Niu', 'Qingcai Chen', 'Kai Chen'],\n",
       "  'published': '2020-12-22T12:27:45Z',\n",
       "  'updated': '2020-12-22T12:27:45Z',\n",
       "  'abstract': 'We address the task of automatically scoring the competency of candidatesbased on textual features, from the automatic speech recognition (ASR)transcriptions in the asynchronous video job interview (AVI). The key challengeis how to construct the dependency relation between questions and answers, andconduct the semantic level interaction for each question-answer (QA) pair.However, most of the recent studies in AVI focus on how to represent questionsand answers better, but ignore the dependency information and interactionbetween them, which is critical for QA evaluation. In this work, we propose aHierarchical Reasoning Graph Neural Network (HRGNN) for the automaticassessment of question-answer pairs. Specifically, we construct asentence-level relational graph neural network to capture the dependencyinformation of sentences in or between the question and the answer. Based onthese graphs, we employ a semantic-level reasoning graph attention network tomodel the interaction states of the current QA session. Finally, we propose agated recurrent unit encoder to represent the temporal question-answer pairsfor the final prediction. Empirical results conducted on CHNAT (a real-worlddataset) validate that our proposed model significantly outperformstext-matching based benchmark models. Ablation studies and experimental resultswith 10 random seeds also show the effectiveness and stability of our models.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.11960v1'},\n",
       " 669: {'ID': 669,\n",
       "  'title': 'Neural Ordinary Differential Equations for Intervention Modeling',\n",
       "  'authors': ['Michael Poli',\n",
       "   'Daehoon Gwak',\n",
       "   'Edward Choi',\n",
       "   'Jaegul Choo',\n",
       "   'Stefano Massaroli',\n",
       "   'Gyuhyeon Sim'],\n",
       "  'published': '2020-10-16T10:55:12Z',\n",
       "  'updated': '2020-10-16T10:55:12Z',\n",
       "  'abstract': 'By interpreting the forward dynamics of the latent representation of neuralnetworks as an ordinary differential equation, Neural Ordinary DifferentialEquation (Neural ODE) emerged as an effective framework for modeling a systemdynamics in the continuous time domain. However, real-world systems ofteninvolves external interventions that cause changes in the system dynamics suchas a moving ball coming in contact with another ball, or such as a patientbeing administered with particular drug. Neural ODE and a number of its recentvariants, however, are not suitable for modeling such interventions as they donot properly model the observations and the interventions separately. In thispaper, we propose a novel neural ODE-based approach (IMODE) that properly modelthe effect of external interventions by employing two ODE functions toseparately handle the observations and the interventions. Using both syntheticand real-world time-series datasets involving interventions, our experimentalresults consistently demonstrate the superiority of IMODE compared to existingapproaches.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.08304v1'},\n",
       " 670: {'ID': 670,\n",
       "  'title': 'Universal Quantum Control through Deep Reinforcement Learning',\n",
       "  'authors': ['Murphy Yuezhen Niu',\n",
       "   'Hartmut Neven',\n",
       "   'Vadim Smelyanskiy',\n",
       "   'Sergio Boixo'],\n",
       "  'published': '2018-03-05T19:00:01Z',\n",
       "  'updated': '2018-04-16T17:59:37Z',\n",
       "  'abstract': 'Emerging reinforcement learning techniques using deep neural networks haveshown great promise in control optimization. They harness non-localregularities of noisy control trajectories and facilitate transfer learningbetween tasks. To leverage these powerful capabilities for quantum controloptimization, we propose a new control framework to simultaneously optimize thespeed and fidelity of quantum computation against both leakage and stochasticcontrol errors. For a broad family of two-qubit unitary gates that areimportant for quantum simulation of many-electron systems, we improve thecontrol robustness by adding control noise into training environments forreinforcement learning agents trained with trusted-region-policy-optimization.The agent control solutions demonstrate a two-order-of-magnitude reduction inaverage-gate-error over baseline stochastic-gradient-descent solutions and upto a one-order-of-magnitude reduction in gate time from optimal gate synthesiscounterparts.',\n",
       "  'categories': ['quant-ph', 'math.OC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.01857v2'},\n",
       " 671: {'ID': 671,\n",
       "  'title': 'Symmetric Skip Connection Wasserstein GAN for High-Resolution Facial  Image Inpainting',\n",
       "  'authors': ['Moi Hoon Yap',\n",
       "   'Gee-Sern Hsu',\n",
       "   'Vincent Drouard',\n",
       "   'Jireh Jam',\n",
       "   'Connah Kendrick',\n",
       "   'Kevin Walker'],\n",
       "  'published': '2020-01-11T09:09:23Z',\n",
       "  'updated': '2020-09-12T21:16:39Z',\n",
       "  'abstract': 'The state-of-the-art facial image inpainting methods achieved promisingresults but face realism preservation remains a challenge. This is due tolimitations such as; failures in preserving edges and blurry artefacts. Toovercome these limitations, we propose a Symmetric Skip Connection WassersteinGenerative Adversarial Network (S-WGAN) for high-resolution facial imageinpainting. The architecture is an encoder-decoder with convolutional blocks,linked by skip connections. The encoder is a feature extractor that capturesdata abstractions of an input image to learn an end-to-end mapping from aninput (binary masked image) to the ground-truth. The decoder uses learnedabstractions to reconstruct the image. With skip connections, S-WGAN transfersimage details to the decoder. Additionally, we propose a Wasserstein-Perceptualloss function to preserve colour and maintain realism on a reconstructed image.We evaluate our method and the state-of-the-art methods on CelebA-HQ dataset.Our results show S-WGAN produces sharper and more realistic images whenvisually compared with other methods. The quantitative measures show ourproposed S-WGAN achieves the best Structure Similarity Index Measure (SSIM) of0.94.',\n",
       "  'categories': ['cs.CV', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.03725v2'},\n",
       " 672: {'ID': 672,\n",
       "  'title': \"SJTU-NICT's Supervised and Unsupervised Neural Machine Translation  Systems for the WMT20 News Translation Task\",\n",
       "  'authors': ['Zuchao Li',\n",
       "   'Masao Utiyama',\n",
       "   'Hai Zhao',\n",
       "   'Rui Wang',\n",
       "   'Kehai Chen',\n",
       "   'Eiichiro Sumita'],\n",
       "  'published': '2020-10-11T00:40:05Z',\n",
       "  'updated': '2020-10-11T00:40:05Z',\n",
       "  'abstract': \"In this paper, we introduced our joint team SJTU-NICT 's participation in theWMT 2020 machine translation shared task. In this shared task, we participatedin four translation directions of three language pairs: English-Chinese,English-Polish on supervised machine translation track, German-Upper Sorbian onlow-resource and unsupervised machine translation tracks. Based on differentconditions of language pairs, we have experimented with diverse neural machinetranslation (NMT) techniques: document-enhanced NMT, XLM pre-trained languagemodel enhanced NMT, bidirectional translation as a pre-training, referencelanguage based UNMT, data-dependent gaussian prior objective, and BT-BLEUcollaborative filtering self-training. We also used the TF-IDF algorithm tofilter the training set to obtain a domain more similar set with the test setfor finetuning. In our submissions, the primary systems won the first place onEnglish to Chinese, Polish to English, and German to Upper Sorbian translationdirections.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.05122v1'},\n",
       " 673: {'ID': 673,\n",
       "  'title': 'Learning a Layout Transfer Network for Context Aware Object Detection',\n",
       "  'authors': ['Xuming He', 'Yuanzheng Cai', 'Tao Wang', 'Guobao Xiao'],\n",
       "  'published': '2019-12-09T06:07:44Z',\n",
       "  'updated': '2019-12-09T06:07:44Z',\n",
       "  'abstract': 'We present a context aware object detection method based on aretrieve-and-transform scene layout model. Given an input image, our approachfirst retrieves a coarse scene layout from a codebook of typical layouttemplates. In order to handle large layout variations, we use a variant of thespatial transformer network to transform and refine the retrieved layout,resulting in a set of interpretable and semantically meaningful feature maps ofobject locations and scales. The above steps are implemented as a LayoutTransfer Network which we integrate into Faster RCNN to allow for jointreasoning of object detection and scene layout estimation. Extensiveexperiments on three public datasets verified that our approach providesconsistent performance improvements to the state-of-the-art object detectionbaselines on a variety of challenging tasks in the traffic surveillance and theautonomous driving domains.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.03865v1'},\n",
       " 674: {'ID': 674,\n",
       "  'title': 'Note on the equivalence of hierarchical variational models and auxiliary  deep generative models',\n",
       "  'authors': ['Niko Brümmer'],\n",
       "  'published': '2016-03-08T09:46:30Z',\n",
       "  'updated': '2016-03-09T10:54:36Z',\n",
       "  'abstract': 'This note compares two recently published machine learning methods forconstructing flexible, but tractable families of variational hidden-variableposteriors. The first method, called \"hierarchical variational models\" enrichesthe inference model with an extra variable, while the other, called \"auxiliarydeep generative models\", enriches the generative model instead. We concludethat the two methods are mathematically equivalent.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.02443v2'},\n",
       " 675: {'ID': 675,\n",
       "  'title': 'Neural ODE and Holographic QCD',\n",
       "  'authors': ['Koji Hashimoto', 'Yi-Zhuang You', 'Hong-Ye Hu'],\n",
       "  'published': '2020-06-01T04:41:38Z',\n",
       "  'updated': '2020-06-01T04:41:38Z',\n",
       "  'abstract': 'The neural ordinary differential equation (Neural ODE) is a novel machinelearning architecture whose weights are smooth functions of the continuousdepth. We apply the Neural ODE to holographic QCD by regarding the weightfunctions as a bulk metric, and train the machine with lattice QCD data ofchiral condensate at finite temperature. The machine finds consistent bulkgeometry at various values of temperature and discovers the emergent black holehorizon in the holographic bulk automatically. The holographic Wilson loopscalculated with the emergent machine-learned bulk spacetime have consistenttemperature dependence of confinement and Debye-screening behavior. In machinelearning models with physically interpretable weights, the Neural ODE frees usfrom discretization artifact leading to difficult ingenuity of hyperparameters,and improves numerical accuracy to make the model more trustworthy.',\n",
       "  'categories': ['hep-th', 'cond-mat.dis-nn', 'gr-qc', 'hep-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.00712v1'},\n",
       " 676: {'ID': 676,\n",
       "  'title': 'Bias-Reduced Hindsight Experience Replay with Virtual Goal  Prioritization',\n",
       "  'authors': ['Armin Biess', 'Binyamin Manela'],\n",
       "  'published': '2019-05-14T10:12:12Z',\n",
       "  'updated': '2020-03-20T14:45:47Z',\n",
       "  'abstract': 'Hindsight Experience Replay (HER) is a multi-goal reinforcement learningalgorithm for sparse reward functions. The algorithm treats every failure as asuccess for an alternative (virtual) goal that has been achieved in theepisode. Virtual goals are randomly selected, irrespective of which are mostinstructive for the agent. In this paper, we present two improvements over theexisting HER algorithm. First, we prioritize virtual goals from which the agentwill learn more valuable information. We call this property the instructivenessof the virtual goal and define it by a heuristic measure, which expresses howwell the agent will be able to generalize from that virtual goal to actualgoals. Secondly, we reduce existing bias in HER by the removal of misleadingsamples. To test our algorithms, we built two challenging environments withsparse reward functions. Our empirical results in both environments show vastimprovement in the final success rate and sample efficiency when compared tothe original HER algorithm. A video showing experimental results is availableat https://youtu.be/3cZwfK8Nfps .',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.05498v4'},\n",
       " 677: {'ID': 677,\n",
       "  'title': 'Task-Oriented Language Grounding for Language Input with Multiple  Sub-Goals of Non-Linear Order',\n",
       "  'authors': ['Adil Khan', 'Vladislav Kurenkov', 'Bulat Maksudov'],\n",
       "  'published': '2019-10-27T21:11:42Z',\n",
       "  'updated': '2019-10-27T21:11:42Z',\n",
       "  'abstract': 'In this work, we analyze the performance of general deep reinforcementlearning algorithms for a task-oriented language grounding problem, wherelanguage input contains multiple sub-goals and their order of execution isnon-linear.  We generate a simple instructional language for the GridWorld environment,that is built around three language elements (order connectors) defining theorder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"butbefore\". We apply one of the deep reinforcement learning baselines - Double DQNwith frame stacking and ablate several extensions such as PrioritizedExperience Replay and Gated-Attention architecture.  Our results show that the introduction of non-linear order connectorsimproves the success rate on instructions with a higher number of sub-goals in2-3 times, but it still does not exceed 20%. Also, we observe that the usage ofGated-Attention provides no competitive advantage against concatenation in thissetting. Source code and experiments\\' results are available athttps://github.com/vkurenkov/language-grounding-multigoal',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.12354v1'},\n",
       " 678: {'ID': 678,\n",
       "  'title': 'Wasserstein Distance guided Adversarial Imitation Learning with Reward  Shape Exploration',\n",
       "  'authors': ['Li Xia',\n",
       "   'Xiaoteng Ma',\n",
       "   'Yawei Wang',\n",
       "   'Xiu Li',\n",
       "   'Jun Yang',\n",
       "   'Ming Zhang',\n",
       "   'Zhiheng Li'],\n",
       "  'published': '2020-06-05T15:10:00Z',\n",
       "  'updated': '2020-12-08T13:06:20Z',\n",
       "  'abstract': 'The generative adversarial imitation learning (GAIL) has provided anadversarial learning framework for imitating expert policy from demonstrationsin high-dimensional continuous tasks. However, almost all GAIL and itsextensions only design a kind of reward function of logarithmic form in theadversarial training strategy with the Jensen-Shannon (JS) divergence for allcomplex environments. The fixed logarithmic type of reward function may bedifficult to solve all complex tasks, and the vanishing gradients problemcaused by the JS divergence will harm the adversarial learning process. In thispaper, we propose a new algorithm named Wasserstein Distance guided AdversarialImitation Learning (WDAIL) for promoting the performance of imitation learning(IL). There are three improvements in our method: (a) introducing theWasserstein distance to obtain more appropriate measure in the adversarialtraining process, (b) using proximal policy optimization (PPO) in thereinforcement learning stage which is much simpler to implement and makes thealgorithm more efficient, and (c) exploring different reward function shapes tosuit different tasks for improving the performance. The experiment results showthat the learning procedure remains remarkably stable, and achieves significantperformance in the complex continuous control tasks of MuJoCo.',\n",
       "  'categories': ['cs.LG', 'cs.RO', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.03503v2'},\n",
       " 679: {'ID': 679,\n",
       "  'title': 'Variational Graph Recurrent Neural Networks',\n",
       "  'authors': ['Arman Hasanzadeh',\n",
       "   'Nick Duffield',\n",
       "   'Xiaoning Qian',\n",
       "   'Krishna R Narayanan',\n",
       "   'Mingyuan Zhou',\n",
       "   'Ehsan Hajiramezanali'],\n",
       "  'published': '2019-08-26T14:44:47Z',\n",
       "  'updated': '2020-04-23T03:03:40Z',\n",
       "  'abstract': 'Representation learning over graph structured data has been mostly studied instatic graph settings while efforts for modeling dynamic graphs are stillscant. In this paper, we develop a novel hierarchical variational model thatintroduces additional latent random variables to jointly model the hiddenstates of a graph recurrent neural network (GRNN) to capture both topology andnode attribute changes in dynamic graphs. We argue that the use of high-levellatent random variables in this variational GRNN (VGRNN) can better capturepotential variability observed in dynamic graphs as well as the uncertainty ofnode latent representation. With semi-implicit variational inference developedfor this new VGRNN architecture (SI-VGRNN), we show that flexible non-Gaussianlatent representations can further help dynamic graph analytic tasks. Ourexperiments with multiple real-world dynamic graph datasets demonstrate thatSI-VGRNN and VGRNN consistently outperform the existing baseline andstate-of-the-art methods by a significant margin in dynamic link prediction.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.09710v3'},\n",
       " 680: {'ID': 680,\n",
       "  'title': 'Stable Neural Flows',\n",
       "  'authors': ['Michelangelo Bin',\n",
       "   'Jinkyoo Park',\n",
       "   'Michael Poli',\n",
       "   'Atsushi Yamashita',\n",
       "   'Stefano Massaroli',\n",
       "   'Hajime Asama'],\n",
       "  'published': '2020-03-18T06:27:21Z',\n",
       "  'updated': '2020-03-18T06:27:21Z',\n",
       "  'abstract': 'We introduce a provably stable variant of neural ordinary differentialequations (neural ODEs) whose trajectories evolve on an energy functionalparametrised by a neural network. Stable neural flows provide an implicitguarantee on asymptotic stability of the depth-flows, leading to robustnessagainst input perturbations and low computational burden for the numericalsolver. The learning procedure is cast as an optimal control problem, and anapproximate solution is proposed based on adjoint sensivity analysis. Wefurther introduce novel regularizers designed to ease the optimization processand speed up convergence. The proposed model class is evaluated on non-linearclassification and function approximation tasks.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.08063v1'},\n",
       " 681: {'ID': 681,\n",
       "  'title': 'Pathfinder Discovery Networks for Neural Message Passing',\n",
       "  'authors': ['Amol Kapoor',\n",
       "   'Peter Englert',\n",
       "   'Bryan Perozzi',\n",
       "   'Martin Blais',\n",
       "   'Benedek Rozemberczki'],\n",
       "  'published': '2020-10-24T11:28:57Z',\n",
       "  'updated': '2020-10-24T11:28:57Z',\n",
       "  'abstract': 'In this work we propose Pathfinder Discovery Networks (PDNs), a method forjointly learning a message passing graph over a multiplex network with adownstream semi-supervised model. PDNs inductively learn an aggregated weightfor each edge, optimized to produce the best outcome for the downstreamlearning task. PDNs are a generalization of attention mechanisms on graphswhich allow flexible construction of similarity functions between nodes, edgeconvolutions, and cheap multiscale mixing layers. We show that PDNs overcomeweaknesses of existing methods for graph attention (e.g. Graph AttentionNetworks), such as the diminishing weight problem. Our experimental resultsdemonstrate competitive predictive performance on academic node classificationtasks. Additional results from a challenging suite of node classificationexperiments show how PDNs can learn a wider class of functions than existingbaselines. We analyze the relative computational complexity of PDNs, and showthat PDN runtime is not considerably higher than static-graph models. Finally,we discuss how PDNs can be used to construct an easily interpretable attentionmechanism that allows users to understand information propagation in the graph.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.12878v1'},\n",
       " 682: {'ID': 682,\n",
       "  'title': 'Fast &amp; Slow Learning: Incorporating Synthetic Gradients in Neural Memory  Controllers',\n",
       "  'authors': ['Sridha Sridharan',\n",
       "   'Clinton Fookes',\n",
       "   'Tharindu Fernando',\n",
       "   'Simon Denman'],\n",
       "  'published': '2020-11-10T22:44:27Z',\n",
       "  'updated': '2020-11-10T22:44:27Z',\n",
       "  'abstract': 'Neural Memory Networks (NMNs) have received increased attention in recentyears compared to deep architectures that use a constrained memory. Despitetheir new appeal, the success of NMNs hinges on the ability of thegradient-based optimiser to perform incremental training of the NMNcontrollers, determining how to leverage their high capacity for knowledgeretrieval. This means that while excellent performance can be achieved when thetraining data is consistent and well distributed, rare data samples are hard tolearn from as the controllers fail to incorporate them effectively during modeltraining. Drawing inspiration from the human cognition process, in particularthe utilisation of neuromodulators in the human brain, we propose to decouplethe learning process of the NMN controllers to allow them to achieve flexible,rapid adaptation in the presence of new information. This trait is highlybeneficial for meta-learning tasks where the memory controllers must quicklygrasp abstract concepts in the target domain, and adapt stored knowledge. Thisallows the NMN controllers to quickly determine which memories are to beretained and which are to be erased, and swiftly adapt their strategy to thenew task at hand. Through both quantitative and qualitative evaluations onmultiple public benchmarks, including classification and regression tasks, wedemonstrate the utility of the proposed approach. Our evaluations not onlyhighlight the ability of the proposed NMN architecture to outperform thecurrent state-of-the-art methods, but also provide insights on how the proposedaugmentations help achieve such superior results. In addition, we demonstratethe practical implications of the proposed learning strategy, where thefeedback path can be shared among multiple neural memory networks as amechanism for knowledge sharing.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.05438v1'},\n",
       " 683: {'ID': 683,\n",
       "  'title': 'Familia: An Open-Source Toolkit for Industrial Topic Modeling',\n",
       "  'authors': ['Chen Li',\n",
       "   'Rongzhong Lian',\n",
       "   'Di Jiang',\n",
       "   'Siqi Bao',\n",
       "   'Zeyu Chen'],\n",
       "  'published': '2017-07-31T12:48:45Z',\n",
       "  'updated': '2017-07-31T12:48:45Z',\n",
       "  'abstract': 'Familia is an open-source toolkit for pragmatic topic modeling in industry.Familia abstracts the utilities of topic modeling in industry as two paradigms:semantic representation and semantic matching. Efficient implementations of thetwo paradigms are made publicly available for the first time. Furthermore, weprovide off-the-shelf topic models trained on large-scale industrial corpora,including Latent Dirichlet Allocation (LDA), SentenceLDA and Topical WordEmbedding (TWE). We further describe typical applications which aresuccessfully powered by topic modeling, in order to ease the confusions anddifficulties of software engineers during topic model selection andutilization.',\n",
       "  'categories': ['cs.IR', 'cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.09823v1'},\n",
       " 684: {'ID': 684,\n",
       "  'title': 'Optimizing Network Performance for Distributed DNN Training on GPU  Clusters: ImageNet/AlexNet Training in 1.5 Minutes',\n",
       "  'authors': ['Wansen Feng',\n",
       "   'Ruobing Han',\n",
       "   'Shengen Yan',\n",
       "   'Peng Sun',\n",
       "   'Yonggang Wen'],\n",
       "  'published': '2019-02-19T01:18:56Z',\n",
       "  'updated': '2019-10-22T08:52:08Z',\n",
       "  'abstract': 'It is important to scale out deep neural network (DNN) training for reducingmodel training time. The high communication overhead is one of the majorperformance bottlenecks for distributed DNN training across multiple GPUs. Ourinvestigations have shown that popular open-source DNN systems could onlyachieve 2.5 speedup ratio on 64 GPUs connected by 56 Gbps network. To addressthis problem, we propose a communication backend named GradientFlow fordistributed DNN training, and employ a set of network optimization techniques.First, we integrate ring-based allreduce, mixed-precision training, andcomputation/communication overlap into GradientFlow. Second, we propose lazyallreduce to improve network throughput by fusing multiple communicationoperations into a single one, and design coarse-grained sparse communication toreduce network traffic by only transmitting important gradient chunks. Whentraining ImageNet/AlexNet on 512 GPUs, our approach achieves 410.2 speedupratio and completes 95-epoch training in 1.5 minutes, which outperformsexisting approaches.',\n",
       "  'categories': ['cs.DC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.06855v3'},\n",
       " 685: {'ID': 685,\n",
       "  'title': 'Deep Reinforcement Learning for Multi-objective Optimization',\n",
       "  'authors': ['Tao Zhang', 'Kaiwen Li', 'Rui Wang'],\n",
       "  'published': '2019-06-06T02:24:06Z',\n",
       "  'updated': '2020-04-25T04:03:47Z',\n",
       "  'abstract': 'This study proposes an end-to-end framework for solving multi-objectiveoptimization problems (MOPs) using Deep Reinforcement Learning (DRL), that wecall DRL-MOA. The idea of decomposition is adopted to decompose the MOP into aset of scalar optimization subproblems. Then each subproblem is modelled as aneural network. Model parameters of all the subproblems are optimizedcollaboratively according to a neighborhood-based parameter-transfer strategyand the DRL training algorithm. Pareto optimal solutions can be directlyobtained through the trained neural network models. In specific, themulti-objective travelling salesman problem (MOTSP) is solved in this workusing the DRL-MOA method by modelling the subproblem as a Pointer Network.Extensive experiments have been conducted to study the DRL-MOA and variousbenchmark methods are compared with it. It is found that, once the trainedmodel is available, it can scale to newly encountered problems with no need ofre-training the model. The solutions can be directly obtained by a simpleforward calculation of the neural network; thereby, no iteration is requiredand the MOP can be always solved in a reasonable time. The proposed methodprovides a new way of solving the MOP by means of DRL. It has shown a set ofnew characteristics, e.g., strong generalization ability and fast solving speedin comparison with the existing methods for multi-objective optimizations.Experimental results show the effectiveness and competitiveness of the proposedmethod in terms of model performance and running time.',\n",
       "  'categories': ['cs.NE', 'math.OC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.02386v2'},\n",
       " 686: {'ID': 686,\n",
       "  'title': 'Implicit Neural Representations with Periodic Activation Functions',\n",
       "  'authors': ['Vincent Sitzmann',\n",
       "   'Julien N. P. Martel',\n",
       "   'David B. Lindell',\n",
       "   'Alexander W. Bergman',\n",
       "   'Gordon Wetzstein'],\n",
       "  'published': '2020-06-17T05:13:33Z',\n",
       "  'updated': '2020-06-17T05:13:33Z',\n",
       "  'abstract': \"Implicitly defined, continuous, differentiable signal representationsparameterized by neural networks have emerged as a powerful paradigm, offeringmany possible benefits over conventional representations. However, currentnetwork architectures for such implicit neural representations are incapable ofmodeling signals with fine detail, and fail to represent a signal's spatial andtemporal derivatives, despite the fact that these are essential to manyphysical signals defined implicitly as the solution to partial differentialequations. We propose to leverage periodic activation functions for implicitneural representations and demonstrate that these networks, dubbed sinusoidalrepresentation networks or Sirens, are ideally suited for representing complexnatural signals and their derivatives. We analyze Siren activation statisticsto propose a principled initialization scheme and demonstrate therepresentation of images, wavefields, video, sound, and their derivatives.Further, we show how Sirens can be leveraged to solve challenging boundaryvalue problems, such as particular Eikonal equations (yielding signed distancefunctions), the Poisson equation, and the Helmholtz and wave equations. Lastly,we combine Sirens with hypernetworks to learn priors over the space of Sirenfunctions.\",\n",
       "  'categories': ['cs.CV', 'cs.LG', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.09661v1'},\n",
       " 687: {'ID': 687,\n",
       "  'title': 'Deep unfolding-based output feedback control design for linear systems  with input saturation',\n",
       "  'authors': ['Kenji Sugimoto',\n",
       "   'Koki Kobayashi',\n",
       "   'Taisuke Kobayashi',\n",
       "   'Masaki Ogura'],\n",
       "  'published': '2020-11-20T04:08:41Z',\n",
       "  'updated': '2021-01-27T13:52:49Z',\n",
       "  'abstract': 'In this paper, we propose a deep unfolding-based framework for the outputfeedback control of systems with input saturation. Although saturation commonlyarises in several practical control systems, there is still a scarce ofeffective design methodologies that can directly deal with the severenon-linearity of the saturation operator. In this paper, we aim to design ananti-windup controller for enlarging the region of stability of the closed-loopsystem by learning from the numerical simulations of the closed-loop system.The data-driven framework we propose in this paper is based on a deep-learningtechnique called Neural Ordinary Differential Equations. Within our framework,we first obtain a candidate controller by using the deep-learning technique,which is then tested by the existing theoretical results already established inthe literature, thereby avoiding the computational challenge in theconventional design methodologies as well as theoretically guaranteeing theperformance of the system. Our numerical simulation shows that the proposedframework can significantly outperform a conventional design methodology basedon linear matrix inequalities.',\n",
       "  'categories': ['eess.SY', 'cs.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.10196v2'},\n",
       " 688: {'ID': 688,\n",
       "  'title': 'Safe Reinforcement Learning for Autonomous Vehicles through Parallel  Constrained Policy Optimization',\n",
       "  'authors': ['Huei Peng',\n",
       "   'Lu Wen',\n",
       "   'Jingliang Duan',\n",
       "   'Shengbo Eben Li',\n",
       "   'Shaobing Xu'],\n",
       "  'published': '2020-03-03T02:53:30Z',\n",
       "  'updated': '2020-03-03T02:53:30Z',\n",
       "  'abstract': \"Reinforcement learning (RL) is attracting increasing interests in autonomousdriving due to its potential to solve complex classification and controlproblems. However, existing RL algorithms are rarely applied to real vehiclesfor two predominant problems: behaviours are unexplainable, and they cannotguarantee safety under new scenarios. This paper presents a safe RL algorithm,called Parallel Constrained Policy Optimization (PCPO), for two autonomousdriving tasks. PCPO extends today's common actor-critic architecture to athree-component learning framework, in which three neural networks are used toapproximate the policy function, value function and a newly added riskfunction, respectively. Meanwhile, a trust region constraint is added to allowlarge update steps without breaking the monotonic improvement condition. Toensure the feasibility of safety constrained problems, synchronized parallellearners are employed to explore different state spaces, which accelerateslearning and policy-update. The simulations of two scenarios for autonomousvehicles confirm we can ensure safety while achieving fast learning.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.01303v1'},\n",
       " 689: {'ID': 689,\n",
       "  'title': 'Efficient Generalized Spherical CNNs',\n",
       "  'authors': ['Christopher G. R. Wallis',\n",
       "   'Oliver J. Cobb',\n",
       "   'Jason D. McEwen',\n",
       "   'Augustin Marignier',\n",
       "   'Matthew A. Price',\n",
       "   'Augustine N. Mavor-Parker',\n",
       "   \"Mayeul d'Avezac\"],\n",
       "  'published': '2020-10-09T18:00:05Z',\n",
       "  'updated': '2020-10-23T15:52:16Z',\n",
       "  'abstract': 'Many problems across computer vision and the natural sciences require theanalysis of spherical data, for which representations may be learnedefficiently by encoding equivariance to rotational symmetries. We present ageneralized spherical CNN framework that encompasses various existingapproaches and allows them to be leveraged alongside each other. The onlyexisting non-linear spherical CNN layer that is strictly equivariant hascomplexity $\\\\mathcal{O}(C^2L^5)$, where $C$ is a measure of representationalcapacity and $L$ the spherical harmonic bandlimit. Such a high computationalcost often prohibits the use of strictly equivariant spherical CNNs. We developtwo new strictly equivariant layers with reduced complexity $\\\\mathcal{O}(CL^4)$and $\\\\mathcal{O}(CL^3 \\\\log L)$, making larger, more expressive modelscomputationally feasible. Moreover, we adopt efficient sampling theory toachieve further computational savings. We show that these developments allowthe construction of more expressive hybrid models that achieve state-of-the-artaccuracy and parameter efficiency on spherical benchmark problems.',\n",
       "  'categories': ['cs.CV', 'astro-ph.IM', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11661v2'},\n",
       " 690: {'ID': 690,\n",
       "  'title': 'The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020',\n",
       "  'authors': ['Michael Denkowski',\n",
       "   'David Vilar',\n",
       "   'Tobias Domhan',\n",
       "   'Xing Niu',\n",
       "   'Felix Hieber',\n",
       "   'Kenneth Heafield'],\n",
       "  'published': '2020-08-11T17:42:26Z',\n",
       "  'updated': '2020-08-11T17:42:26Z',\n",
       "  'abstract': \"We present Sockeye 2, a modernized and streamlined version of the Sockeyeneural machine translation (NMT) toolkit. New features include a simplifiedcode base through the use of MXNet's Gluon API, a focus on state of the artmodel architectures, distributed mixed precision training, and efficient CPUdecoding with 8-bit quantization. These improvements result in faster trainingand inference, higher automatic metric scores, and a shorter path from researchto production.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.04885v1'},\n",
       " 691: {'ID': 691,\n",
       "  'title': 'Policy Continuation with Hindsight Inverse Dynamics',\n",
       "  'authors': ['Zhizhong Li',\n",
       "   'Dahua Lin',\n",
       "   'Hao Sun',\n",
       "   'Xiaotong Liu',\n",
       "   'Bolei Zhou'],\n",
       "  'published': '2019-10-30T18:00:21Z',\n",
       "  'updated': '2019-11-01T04:18:43Z',\n",
       "  'abstract': 'Solving goal-oriented tasks is an important but challenging problem inreinforcement learning (RL). For such tasks, the rewards are often sparse,making it difficult to learn a policy effectively. To tackle this difficulty,we propose a new approach called Policy Continuation with Hindsight InverseDynamics (PCHID). This approach learns from Hindsight Inverse Dynamics based onHindsight Experience Replay, enabling the learning process in a self-imitatedmanner and thus can be trained with supervised learning. This work also extendsit to multi-step settings with Policy Continuation. The proposed method isgeneral, which can work in isolation or be combined with other on-policy andoff-policy algorithms. On two multi-goal tasks GridWorld and FetchReach, PCHIDsignificantly improves the sample efficiency as well as the final performance.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.14055v2'},\n",
       " 692: {'ID': 692,\n",
       "  'title': 'A Review of Graph Neural Networks and Their Applications in Power  Systems',\n",
       "  'authors': ['Wenlong Liao',\n",
       "   'Yusen Wang',\n",
       "   'Jayakrishnan Radhakrishna Pillai',\n",
       "   'Yuelong Wang',\n",
       "   'Birgitte Bak-Jensen'],\n",
       "  'published': '2021-01-25T11:50:45Z',\n",
       "  'updated': '2021-01-25T11:50:45Z',\n",
       "  'abstract': 'Deep neural networks have revolutionized many machine learning tasks in powersystems, ranging from pattern recognition to signal processing. The data inthese tasks is typically represented in Euclidean domains. Nevertheless, thereis an increasing number of applications in power systems, where data arecollected from non-Euclidean domains and represented as the graph-structureddata with high dimensional features and interdependency among nodes. Thecomplexity of graph-structured data has brought significant challenges to theexisting deep neural networks defined in Euclidean domains. Recently, manystudies on extending deep neural networks for graph-structured data in powersystems have emerged. In this paper, a comprehensive overview of graph neuralnetworks (GNNs) in power systems is proposed. Specifically, several classicalparadigms of GNNs structures (e.g., graph convolutional networks, graphrecurrent neural networks, graph attention networks, graph generative networks,spatial-temporal graph convolutional networks, and hybrid forms of GNNs) aresummarized, and key applications in power systems such as fault diagnosis,power prediction, power flow calculation, and data generation are reviewed indetail. Furthermore, main issues and some research trends about theapplications of GNNs in power systems are discussed.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.10025v1'},\n",
       " 693: {'ID': 693,\n",
       "  'title': 'Preventing Posterior Collapse with Levenshtein Variational Autoencoder',\n",
       "  'authors': ['Ivan Titov', 'Serhii Havrylov'],\n",
       "  'published': '2020-04-30T13:27:26Z',\n",
       "  'updated': '2020-04-30T13:27:26Z',\n",
       "  'abstract': 'Variational autoencoders (VAEs) are a standard framework for inducing latentvariable models that have been shown effective in learning text representationsas well as in text generation. The key challenge with using VAEs is the {\\\\itposterior collapse} problem: learning tends to converge to trivial solutionswhere the generators ignore latent variables. In our Levenstein VAE, we proposeto replace the evidence lower bound (ELBO) with a new objective which is simpleto optimize and prevents posterior collapse. Intuitively, it corresponds togenerating a sequence from the autoencoder and encouraging the model to predictan optimal continuation according to the Levenshtein distance (LD) with thereference sentence at each time step in the generated sequence. We motivate themethod from the probabilistic perspective by showing that it is closely relatedto optimizing a bound on the intractable Kullback-Leibler divergence of anLD-based kernel density estimator from the model distribution. With thisobjective, any generator disregarding latent variables will incur largepenalties and hence posterior collapse does not happen. We relate our approachto policy distillation \\\\cite{RossGB11} and dynamic oracles \\\\cite{GoldbergN12}.By considering Yelp and SNLI benchmarks, we show that Levenstein VAE producesmore informative latent representations than alternative approaches topreventing posterior collapse.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.14758v1'},\n",
       " 694: {'ID': 694,\n",
       "  'title': 'Reinforcement Learning in a Physics-Inspired Semi-Markov Environment',\n",
       "  'authors': ['Mark Crowley',\n",
       "   'Rory Coles',\n",
       "   'Colin Bellinger',\n",
       "   'Isaac Tamblyn'],\n",
       "  'published': '2020-04-15T20:43:29Z',\n",
       "  'updated': '2020-04-15T20:43:29Z',\n",
       "  'abstract': 'Reinforcement learning (RL) has been demonstrated to have great potential inmany applications of scientific discovery and design. Recent work includes, forexample, the design of new structures and compositions of molecules fortherapeutic drugs. Much of the existing work related to the application of RLto scientific domains, however, assumes that the available state representationobeys the Markov property. For reasons associated with time, cost, sensoraccuracy, and gaps in scientific knowledge, many scientific design anddiscovery problems do not satisfy the Markov property. Thus, something otherthan a Markov decision process (MDP) should be used to plan / find the optimalpolicy. In this paper, we present a physics-inspired semi-Markov RLenvironment, namely the phase change environment. In addition, we evaluate theperformance of value-based RL algorithms for both MDPs and partially observableMDPs (POMDPs) on the proposed environment. Our results demonstrate deeprecurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), andthat DRQNs benefit from training with hindsight experience replay. Implicationsfor the use of semi-Markovian RL and POMDPs for scientific laboratories arealso discussed.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'I.2; J.2'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.07333v1'},\n",
       " 695: {'ID': 695,\n",
       "  'title': 'Learning to Memorize in Neural Task-Oriented Dialogue Systems',\n",
       "  'authors': ['Chien-Sheng Wu'],\n",
       "  'published': '2019-05-19T04:00:08Z',\n",
       "  'updated': '2019-05-19T04:00:08Z',\n",
       "  'abstract': 'In this thesis, we leverage the neural copy mechanism and memory-augmentedneural networks (MANNs) to address existing challenge of neural task-orienteddialogue learning. We show the effectiveness of our strategy by achieving goodperformance in multi-domain dialogue state tracking, retrieval-based dialoguesystems, and generation-based dialogue systems. We first propose a transferabledialogue state generator (TRADE) that leverages its copy mechanism to get ridof dialogue ontology and share knowledge between domains. We also evaluateunseen domain dialogue state tracking and show that TRADE enables zero-shotdialogue state tracking and can adapt to new few-shot domains withoutforgetting the previous domains. Second, we utilize MANNs to improveretrieval-based dialogue learning. They are able to capture dialogue sequentialdependencies and memorize long-term information. We also propose a recordeddelexicalization copy strategy to replace real entity values with orderedentity types. Our models are shown to surpass other retrieval baselines,especially when the conversation has a large number of turns. Lastly, we tacklegeneration-based dialogue learning with two proposed models, thememory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP).Mem2Seq is the first model to combine multi-hop memory attention with the ideaof the copy mechanism. GLMP further introduces the concept of responsesketching and double pointers copying. We show that GLMP achieves thestate-of-the-art performance on human evaluation.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.07687v1'},\n",
       " 696: {'ID': 696,\n",
       "  'title': 'Generalizing Across Multi-Objective Reward Functions in Deep  Reinforcement Learning',\n",
       "  'authors': ['Fred Fontaine', 'Eli Friedman'],\n",
       "  'published': '2018-09-17T17:59:13Z',\n",
       "  'updated': '2018-09-17T17:59:13Z',\n",
       "  'abstract': \"Many reinforcement-learning researchers treat the reward function as a partof the environment, meaning that the agent can only know the reward of a stateif it encounters that state in a trial run. However, we argue that this is anunnecessary limitation and instead, the reward function should be provided tothe learning algorithm. The advantage is that the algorithm can then use thereward function to check the reward for states that the agent hasn't evenencountered yet. In addition, the algorithm can simultaneously learn policiesfor multiple reward functions. For each state, the algorithm would calculatethe reward using each of the reward functions and add the rewards to itsexperience replay dataset. The Hindsight Experience Replay algorithm developedby Andrychowicz et al. (2017) does just this, and learns to generalize across adistribution of sparse, goal-based rewards. We extend this algorithm tolinearly-weighted, multi-objective rewards and learn a single policy that cangeneralize across all linear combinations of the multi-objective reward.Whereas other multi-objective algorithms teach the Q-function to generalizeacross the reward weights, our algorithm enables the policy to generalize, andcan thus be used with continuous actions.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.06364v1'},\n",
       " 697: {'ID': 697,\n",
       "  'title': 'Scattering Networks on the Sphere for Scalable and Rotationally  Equivariant Spherical CNNs',\n",
       "  'authors': ['Christopher G. R. Wallis',\n",
       "   'Augustine N. Mavor-Parker',\n",
       "   'Jason D. McEwen'],\n",
       "  'published': '2021-02-04T19:00:01Z',\n",
       "  'updated': '2021-02-04T19:00:01Z',\n",
       "  'abstract': 'Convolutional neural networks (CNNs) constructed natively on the sphere havebeen developed recently and shown to be highly effective for the analysis ofspherical data. While an efficient framework has been formulated, sphericalCNNs are nevertheless highly computationally demanding; typically they cannotscale beyond spherical signals of thousands of pixels. We develop scatteringnetworks constructed natively on the sphere that provide a powerfulrepresentational space for spherical data. Spherical scattering networks arecomputationally scalable and exhibit rotational equivariance, while theirrepresentational space is invariant to isometries and provides efficient andstable signal representations. By integrating scattering networks as anadditional type of layer in the generalized spherical CNN framework, we showhow they can be leveraged to scale spherical CNNs to the high resolution datatypical of many practical applications, with spherical signals of many tens ofmegapixels and beyond.',\n",
       "  'categories': ['cs.CV', 'astro-ph.IM', 'cs.LG', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.02828v1'},\n",
       " 698: {'ID': 698,\n",
       "  'title': 'On- and Off-Policy Monotonic Policy Improvement',\n",
       "  'authors': ['Ryo Iwaki', 'Minoru Asada'],\n",
       "  'published': '2017-10-10T08:18:24Z',\n",
       "  'updated': '2017-11-01T08:37:34Z',\n",
       "  'abstract': 'Monotonic policy improvement and off-policy learning are two main desirableproperties for reinforcement learning algorithms. In this paper, by lowerbounding the performance difference of two policies, we show that the monotonicpolicy improvement is guaranteed from on- and off-policy mixture samples. Anoptimization procedure which applies the proposed bound can be regarded as anoff-policy natural policy gradient method. In order to support the theoreticalresult, we provide a trust region policy optimization method using experiencereplay as a naive application of our bound, and evaluate its performance in twoclassical benchmark problems.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.03442v2'},\n",
       " 699: {'ID': 699,\n",
       "  'title': 'Early Improving Recurrent Elastic Highway Network',\n",
       "  'authors': ['Hyunsin Park', 'Chang D. Yoo'],\n",
       "  'published': '2017-08-14T13:39:28Z',\n",
       "  'updated': '2017-08-14T13:39:28Z',\n",
       "  'abstract': 'To model time-varying nonlinear temporal dynamics in sequential data, arecurrent network capable of varying and adjusting the recurrence depth betweeninput intervals is examined. The recurrence depth is extended by severalintermediate hidden state units, and the weight parameters involved indetermining these units are dynamically calculated. The motivation behind thepaper lies on overcoming a deficiency in Recurrent Highway Networks andimproving their performances which are currently at the forefront of RNNs: 1)Determining the appropriate number of recurrent depth in RHN for differenttasks is a huge burden and just setting it to a large number is computationallywasteful with possible repercussion in terms of performance degradation andhigh latency. Expanding on the idea of adaptive computation time (ACT), withthe use of an elastic gate in the form of a rectified exponentially decreasingfunction taking on as arguments as previous hidden state and input, theproposed model is able to evaluate the appropriate recurrent depth for eachinput. The rectified gating function enables the most significant intermediatehidden state updates to come early such that significant performance gain isachieved early. 2) Updating the weights from that of previous intermediatelayer offers a richer representation than the use of shared weights across allintermediate recurrence layers. The weight update procedure is just anexpansion of the idea underlying hypernetworks. To substantiate theeffectiveness of the proposed network, we conducted three experiments:regression on synthetic data, human activity recognition, and language modelingon the Penn Treebank dataset. The proposed networks showed better performancethan other state-of-the-art recurrent networks in all three experiments.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.04116v1'},\n",
       " 700: {'ID': 700,\n",
       "  'title': 'Multitask Pointer Network for Multi-Representational Parsing',\n",
       "  'authors': ['Daniel Fernández-González', 'Carlos Gómez-Rodríguez'],\n",
       "  'published': '2020-09-21T10:04:07Z',\n",
       "  'updated': '2020-09-21T10:04:07Z',\n",
       "  'abstract': 'We propose a transition-based approach that, by training a single model, canefficiently parse any input sentence with both constituent and dependencytrees, supporting both continuous/projective and discontinuous/non-projectivesyntactic structures. To that end, we develop a Pointer Network architecturewith two separate task-specific decoders and a common encoder, and follow amultitask learning strategy to jointly train them. The resulting quadraticsystem, not only becomes the first parser that can jointly produce bothunrestricted constituent and dependency trees from a single model, but alsoproves that both syntactic formalisms can benefit from each other duringtraining, achieving state-of-the-art accuracies in several widely-usedbenchmarks such as the continuous English and Chinese Penn Treebanks, as wellas the discontinuous German NEGRA and TIGER datasets.',\n",
       "  'categories': ['cs.CL', '68T50', 'I.2.7'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.09730v1'},\n",
       " 701: {'ID': 701,\n",
       "  'title': 'Gated End-to-End Memory Networks',\n",
       "  'authors': ['Julien Perez', 'Fei Liu'],\n",
       "  'published': '2016-10-13T19:38:03Z',\n",
       "  'updated': '2016-11-17T15:09:29Z',\n",
       "  'abstract': 'Machine reading using differentiable reasoning models has recently shownremarkable progress. In this context, End-to-End trainable Memory Networks,MemN2N, have demonstrated promising performance on simple natural languagebased reasoning tasks such as factual reasoning and basic deduction. However,other tasks, namely multi-fact question-answering, positional reasoning ordialog related tasks, remain challenging particularly due to the necessity ofmore complex interactions between the memory and controller modules composingthis family of models. In this paper, we introduce a novel end-to-end memoryaccess regulation mechanism inspired by the current progress on the connectionshort-cutting principle in the field of computer vision. Concretely, we developa Gated End-to-End trainable Memory Network architecture, GMemN2N. From themachine learning perspective, this new capability is learned in an end-to-endfashion without the use of any additional supervision signal which is, as faras our knowledge goes, the first of its kind. Our experiments show significantimprovements on the most challenging tasks in the 20 bAbI dataset, without theuse of any domain knowledge. Then, we show improvements on the dialog bAbItasks including the real human-bot conversion-based Dialog State TrackingChallenge (DSTC-2) dataset. On these two datasets, our model sets the new stateof the art.',\n",
       "  'categories': ['cs.CL', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1610.04211v2'},\n",
       " 702: {'ID': 702,\n",
       "  'title': 'Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory  GANs',\n",
       "  'authors': ['Ilya Kuzovkin',\n",
       "   'Himanshu Sahni',\n",
       "   'Toby Buckley',\n",
       "   'Pieter Abbeel'],\n",
       "  'published': '2019-01-31T18:50:44Z',\n",
       "  'updated': '2019-10-30T02:23:49Z',\n",
       "  'abstract': 'Reinforcement Learning (RL) algorithms typically require millions ofenvironment interactions to learn successful policies in sparse rewardsettings. Hindsight Experience Replay (HER) was introduced as a technique toincrease sample efficiency by reimagining unsuccessful trajectories assuccessful ones by altering the originally intended goals. However, it cannotbe directly applied to visual environments where goal states are oftencharacterized by the presence of distinct visual features. In this work, weshow how visual trajectories can be hallucinated to appear successful byaltering agent observations using a generative model trained on relatively fewsnapshots of the goal. We then use this model in combination with HER to trainRL agents in visual settings. We validate our approach on 3D navigation tasksand a simulated robotics application and show marked improvement over baselinesderived from previous work.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.11529v2'},\n",
       " 703: {'ID': 703,\n",
       "  'title': 'Position-Agnostic Multi-Microphone Speech Dereverberation',\n",
       "  'authors': ['Sharon Gannot',\n",
       "   'Haggai Maron',\n",
       "   'Ethan Fetaya',\n",
       "   'Yochai Yemini'],\n",
       "  'published': '2020-10-22T17:13:12Z',\n",
       "  'updated': '2020-10-22T17:13:12Z',\n",
       "  'abstract': 'Neural networks (NNs) have been widely applied in speech processing tasks,and, in particular, those employing microphone arrays. Nevertheless, most ofthe existing NN architectures can only deal with fixed and position-specificmicrophone arrays. In this paper, we present an NN architecture that can copewith microphone arrays on which no prior knowledge is presumed, and demonstrateits applicability on the speech dereverberation problem. To this end, ourapproach harnesses recent advances in the Deep Sets framework to design anarchitecture that enhances the reverberant log-spectrum. We provide a setup fortraining and testing such a network. Our experiments, using REVERB challengedatasets, show that the proposed position-agnostic setup performs comparablywith the position-aware framework and sometimes slightly better, even withfewer microphones. In addition, it substantially improves performance over asingle microphone architecture.',\n",
       "  'categories': ['eess.AS', 'cs.LG', 'cs.SD'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11875v1'},\n",
       " 704: {'ID': 704,\n",
       "  'title': 'Reinforcement Learning for UAV Attitude Control',\n",
       "  'authors': ['William Koch',\n",
       "   'Renato Mancuso',\n",
       "   'Richard West',\n",
       "   'Azer Bestavros'],\n",
       "  'published': '2018-04-11T18:16:50Z',\n",
       "  'updated': '2018-04-11T18:16:50Z',\n",
       "  'abstract': 'Autopilot systems are typically composed of an \"inner loop\" providingstability and control, while an \"outer loop\" is responsible for mission-levelobjectives, e.g. way-point navigation. Autopilot systems for UAVs arepredominately implemented using Proportional, Integral Derivative (PID) controlsystems, which have demonstrated exceptional performance in stableenvironments. However more sophisticated control is required to operate inunpredictable, and harsh environments. Intelligent flight control systems is anactive area of research addressing limitations of PID control most recentlythrough the use of reinforcement learning (RL) which has had success in otherapplications such as robotics. However previous work has focused primarily onusing RL at the mission-level controller. In this work, we investigate theperformance and accuracy of the inner control loop providing attitude controlwhen using intelligent flight control systems trained with the state-of-the-artRL algorithms, Deep Deterministic Gradient Policy (DDGP), Trust Region PolicyOptimization (TRPO) and Proximal Policy Optimization (PPO). To investigatethese unknowns we first developed an open-source high-fidelity simulationenvironment to train a flight controller attitude control of a quadrotorthrough RL. We then use our environment to compare their performance to that ofa PID controller to identify if using RL is appropriate in high-precision,time-critical flight control.',\n",
       "  'categories': ['cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.04154v1'},\n",
       " 705: {'ID': 705,\n",
       "  'title': 'Hierarchical Approaches for Reinforcement Learning in Parameterized  Action Space',\n",
       "  'authors': ['Drew Wicke', 'Ermo Wei', 'Sean Luke'],\n",
       "  'published': '2018-10-23T04:52:53Z',\n",
       "  'updated': '2018-10-23T04:52:53Z',\n",
       "  'abstract': 'We explore Deep Reinforcement Learning in a parameterized action space.Specifically, we investigate how to achieve sample-efficient end-to-endtraining in these tasks. We propose a new compact architecture for the taskswhere the parameter policy is conditioned on the output of the discrete actionpolicy. We also propose two new methods based on the state-of-the-artalgorithms Trust Region Policy Optimization (TRPO) and Stochastic ValueGradient (SVG) to train such an architecture. We demonstrate that these methodsoutperform the state of the art method, Parameterized Action DDPG, on testdomains.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.09656v1'},\n",
       " 706: {'ID': 706,\n",
       "  'title': 'Sentence Specified Dynamic Video Thumbnail Generation',\n",
       "  'authors': ['Yitian Yuan', 'Lin Ma', 'Wenwu Zhu'],\n",
       "  'published': '2019-08-12T08:35:37Z',\n",
       "  'updated': '2019-10-16T09:47:43Z',\n",
       "  'abstract': \"With the tremendous growth of videos over the Internet, video thumbnails,providing video content previews, are becoming increasingly crucial toinfluencing users' online searching experiences. Conventional video thumbnailsare generated once purely based on the visual characteristics of videos, andthen displayed as requested. Hence, such video thumbnails, without consideringthe users' searching intentions, cannot provide a meaningful snapshot of thevideo contents that users concern. In this paper, we define a distinctively newtask, namely sentence specified dynamic video thumbnail generation, where thegenerated thumbnails not only provide a concise preview of the original videocontents but also dynamically relate to the users' searching intentions withsemantic correspondences to the users' query sentences. To tackle such achallenging task, we propose a novel graph convolved video thumbnail pointer(GTP). Specifically, GTP leverages a sentence specified video graphconvolutional network to model both the sentence-video semantic interaction andthe internal video relationships incorporated with the sentence information,based on which a temporal conditioned pointer network is then introduced tosequentially generate the sentence specified video thumbnails. Moreover, weannotate a new dataset based on ActivityNet Captions for the proposed new task,which consists of 10,000+ video-sentence pairs with each accompanied by anannotated sentence specified video thumbnail. We demonstrate that our proposedGTP outperforms several baseline methods on the created dataset, and thusbelieve that our initial results along with the release of the new dataset willinspire further research on sentence specified dynamic video thumbnailgeneration. Dataset and code are available at https://github.com/yytzsy/GTP.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.04052v2'},\n",
       " 707: {'ID': 707,\n",
       "  'title': 'On Computation and Generalization of Generative Adversarial Imitation  Learning',\n",
       "  'authors': ['Minshuo Chen',\n",
       "   'Xingguo Li',\n",
       "   'Zhaoran Wang',\n",
       "   'Zhuoran Yang',\n",
       "   'Tuo Zhao',\n",
       "   'Tianyi Liu',\n",
       "   'Yizhou Wang'],\n",
       "  'published': '2020-01-09T00:40:19Z',\n",
       "  'updated': '2020-01-12T03:31:31Z',\n",
       "  'abstract': 'Generative Adversarial Imitation Learning (GAIL) is a powerful and practicalapproach for learning sequential decision-making policies. Different fromReinforcement Learning (RL), GAIL takes advantage of demonstration data byexperts (e.g., human), and learns both the policy and reward function of theunknown environment. Despite the significant empirical progresses, the theorybehind GAIL is still largely unknown. The major difficulty comes from theunderlying temporal dependency of the demonstration data and the minimaxcomputational formulation of GAIL without convex-concave structure. To bridgesuch a gap between theory and practice, this paper investigates the theoreticalproperties of GAIL. Specifically, we show: (1) For GAIL with general rewardparameterization, the generalization can be guaranteed as long as the class ofthe reward functions is properly controlled; (2) For GAIL, where the reward isparameterized as a reproducing kernel function, GAIL can be efficiently solvedby stochastic first order optimization algorithms, which attain sublinearconvergence to a stationary solution. To the best of our knowledge, these arethe first results on statistical and computational guarantees of imitationlearning with reward/policy function approximation. Numerical experiments areprovided to support our analysis.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.02792v2'},\n",
       " 708: {'ID': 708,\n",
       "  'title': 'Attention Is All You Need for Chinese Word Segmentation',\n",
       "  'authors': ['Sufeng Duan', 'Hai Zhao'],\n",
       "  'published': '2019-10-31T15:32:19Z',\n",
       "  'updated': '2020-10-06T06:38:42Z',\n",
       "  'abstract': 'Taking greedy decoding algorithm as it should be, this work focuses onfurther strengthening the model itself for Chinese word segmentation (CWS),which results in an even more fast and more accurate CWS model. Our modelconsists of an attention only stacked encoder and a light enough decoder forthe greedy segmentation plus two highway connections for smoother training, inwhich the encoder is composed of a newly proposed Transformer variant,Gaussian-masked Directional (GD) Transformer, and a biaffine attention scorer.With the effective encoder design, our model only needs to take unigramfeatures for scoring. Our model is evaluated on SIGHAN Bakeoff benchmarkdatasets. The experimental results show that with the highest segmentationspeed, the proposed model achieves new state-of-the-art or comparableperformance against strong baselines in terms of strict closed test setting.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.14537v3'},\n",
       " 709: {'ID': 709,\n",
       "  'title': 'Real-time Person Re-identification at the Edge: A Mixed Precision  Approach',\n",
       "  'authors': ['Shrey Mohan', 'Mohammadreza Baharani', 'Hamed Tabkhi'],\n",
       "  'published': '2019-08-19T23:38:53Z',\n",
       "  'updated': '2019-08-19T23:38:53Z',\n",
       "  'abstract': 'A critical part of multi-person multi-camera tracking is personre-identification (re-ID) algorithm, which recognizes and retains identities ofall detected unknown people throughout the video stream. Many re-ID algorithmstoday exemplify state of the art results, but not much work has been done toexplore the deployment of such algorithms for computation and power constrainedreal-time scenarios. In this paper, we study the effect of using a light-weightmodel, MobileNet-v2 for re-ID and investigate the impact of single (FP32)precision versus half (FP16) precision for training on the server and inferenceon the edge nodes. We further compare the results with the baseline model whichuses ResNet-50 on state of the art benchmarks including CUHK03, Market-1501,and Duke-MTMC. The MobileNet-V2 mixed precision training method can improveboth inference throughput on the edge node, and training time on server$3.25\\\\times$ reaching to 27.77fps and $1.75\\\\times$, respectively and decreasespower consumption on the edge node by $1.45\\\\times$, while it deterioratesaccuracy only 5.6\\\\% in respect to ResNet-50 single precision on the average forthree different datasets. The code and pre-trained networks are publiclyavailable at https://github.com/TeCSAR-UNCC/person-reid.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.07842v1'},\n",
       " 710: {'ID': 710,\n",
       "  'title': 'Representations of language in a model of visually grounded speech  signal',\n",
       "  'authors': ['Lieke Gelderloos', 'Grzegorz Chrupała', 'Afra Alishahi'],\n",
       "  'published': '2017-02-07T13:02:09Z',\n",
       "  'updated': '2017-06-30T07:34:55Z',\n",
       "  'abstract': 'We present a visually grounded model of speech perception which projectsspoken utterances and images to a joint semantic space. We use a multi-layerrecurrent highway network to model the temporal nature of spoken speech, andshow that it learns to extract both form and meaning-based linguistic knowledgefrom the input signal. We carry out an in-depth analysis of the representationsused by different components of the trained model and show that encoding ofsemantic aspects tends to become richer as we go up the hierarchy of layers,whereas encoding of form-related aspects of the language input tends toinitially increase and then plateau or decrease.',\n",
       "  'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1702.01991v3'},\n",
       " 711: {'ID': 711,\n",
       "  'title': 'Unfolded Algorithms for Deep Phase Retrieval',\n",
       "  'authors': ['Shahin Khobahi', 'Naveed Naimipour', 'Mojtaba Soltanalian'],\n",
       "  'published': '2020-12-21T03:46:17Z',\n",
       "  'updated': '2020-12-21T03:46:17Z',\n",
       "  'abstract': 'Exploring the idea of phase retrieval has been intriguing researchers fordecades, due to its appearance in a wide range of applications. The task of aphase retrieval algorithm is typically to recover a signal from linearphaseless measurements. In this paper, we approach the problem by proposing ahybrid model-based data-driven deep architecture, referred to as Unfolded PhaseRetrieval (UPR), that exhibits significant potential in improving theperformance of state-of-the art data-driven and model-based phase retrievalalgorithms. The proposed method benefits from versatility and interpretabilityof well-established model-based algorithms, while simultaneously benefitingfrom the expressive power of deep neural networks. In particular, our proposedmodel-based deep architecture is applied to the conventional phase retrievalproblem (via the incremental reshaped Wirtinger flow algorithm) and the sparsephase retrieval problem (via the sparse truncated amplitude flow algorithm),showing immense promise in both cases. Furthermore, we consider a joint designof the sensing matrix and the signal processing algorithm and utilize the deepunfolding technique in the process. Our numerical results illustrate theeffectiveness of such hybrid model-based and data-driven frameworks andshowcase the untapped potential of data-aided methodologies to enhance theexisting phase retrieval algorithms.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.11102v1'},\n",
       " 712: {'ID': 712,\n",
       "  'title': 'Digital twins based on bidirectional LSTM and GAN for modelling COVID-19',\n",
       "  'authors': ['Vinicius Santos Silva',\n",
       "   'Yike Guo',\n",
       "   'Christopher C. Pain',\n",
       "   'Rossella Arcucci',\n",
       "   'Claire E. Heaney',\n",
       "   'César Quilodrán-Casas'],\n",
       "  'published': '2021-02-03T11:54:24Z',\n",
       "  'updated': '2021-02-03T11:54:24Z',\n",
       "  'abstract': 'The outbreak of the coronavirus disease 2019 (COVID-19) has now spreadthroughout the globe infecting over 100 million people and causing the death ofover 2.2 million people. Thus, there is an urgent need to study the dynamics ofepidemiological models to gain a better understanding of how such diseasesspread. While epidemiological models can be computationally expensive, recentadvances in machine learning techniques have given rise to neural networks withthe ability to learn and predict complex dynamics at reduced computationalcosts. Here we introduce two digital twins of a SEIRS model applied to anidealised town. The SEIRS model has been modified to take account of spatialvariation and, where possible, the model parameters are based on official virusspreading data from the UK. We compare predictions from a data-correctedBidirectional Long Short-Term Memory network and a predictive GenerativeAdversarial Network. The predictions given by these two frameworks are accuratewhen compared to the original SEIRS model data. Additionally, these frameworksare data-agnostic and could be applied to towns, idealised or real, in the UKor in other countries. Also, more compartments could be included in the SEIRSmodel, in order to study more realistic epidemiological behaviour.',\n",
       "  'categories': ['cs.LG', 'physics.soc-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.02664v1'},\n",
       " 713: {'ID': 713,\n",
       "  'title': 'Learning Compositional Neural Programs for Continuous Control',\n",
       "  'authors': ['Feryal Behbahani',\n",
       "   'Nando de Freitas',\n",
       "   'Alexandre Laterre',\n",
       "   'Olivier Sigaud',\n",
       "   'Karim Beguir',\n",
       "   'Thomas Pierrot',\n",
       "   'Nicolas Perrin'],\n",
       "  'published': '2020-07-27T08:27:14Z',\n",
       "  'updated': '2020-07-27T08:27:14Z',\n",
       "  'abstract': 'We propose a novel solution to challenging sparse-reward, continuous controlproblems that require hierarchical planning at multiple levels of abstraction.Our solution, dubbed AlphaNPI-X, involves three separate stages of learning.First, we use off-policy reinforcement learning algorithms with experiencereplay to learn a set of atomic goal-conditioned policies, which can be easilyrepurposed for many tasks. Second, we learn self-models describing the effectof the atomic policies on the environment. Third, the self-models are harnessedto learn recursive compositional programs with multiple levels of abstraction.The key insight is that the self-models enable planning by imagination,obviating the need for interaction with the world when learning higher-levelcompositional programs. To accomplish the third stage of learning, we extendthe AlphaNPI algorithm, which applies AlphaZero to learn recursive neuralprogrammer-interpreters. We empirically show that AlphaNPI-X can effectivelylearn to tackle challenging sparse manipulation tasks, such as stackingmultiple blocks, where powerful model-free baselines fail.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.13363v1'},\n",
       " 714: {'ID': 714,\n",
       "  'title': 'Layer-Parallel Training of Deep Residual Neural Networks',\n",
       "  'authors': ['L. Ruthotto',\n",
       "   'S. Günther',\n",
       "   'E. C. Cyr',\n",
       "   'J. B. Schroder',\n",
       "   'N. R. Gauger'],\n",
       "  'published': '2018-12-11T12:26:48Z',\n",
       "  'updated': '2019-07-25T05:58:00Z',\n",
       "  'abstract': 'Residual neural networks (ResNets) are a promising class of deep neuralnetworks that have shown excellent performance for a number of learning tasks,e.g., image classification and recognition. Mathematically, ResNetarchitectures can be interpreted as forward Euler discretizations of anonlinear initial value problem whose time-dependent control variablesrepresent the weights of the neural network. Hence, training a ResNet can becast as an optimal control problem of the associated dynamical system. Forsimilar time-dependent optimal control problems arising in engineeringapplications, parallel-in-time methods have shown notable improvements inscalability. This paper demonstrates the use of those techniques for efficientand effective training of ResNets. The proposed algorithms replace theclassical (sequential) forward and backward propagation through the networklayers by a parallel nonlinear multigrid iteration applied to the layer domain.This adds a new dimension of parallelism across layers that is attractive whentraining very deep networks. From this basic idea, we derive multiplelayer-parallel methods. The most efficient version employs a simultaneousoptimization approach where updates to the network parameters are based oninexact gradient information in order to speed up the training process. Usingnumerical examples from supervised classification, we demonstrate that the newapproach achieves similar training performance to traditional methods, butenables layer-parallelism and thus provides speedup over layer-serial methodsthrough greater concurrency.',\n",
       "  'categories': ['math.OC', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.04352v3'},\n",
       " 715: {'ID': 715,\n",
       "  'title': 'Manipulating the Distributions of Experience used for Self-Play Learning  in Expert Iteration',\n",
       "  'authors': ['Dennis J. N. J. Soemers',\n",
       "   'Éric Piette',\n",
       "   'Cameron Browne',\n",
       "   'Matthew Stephenson'],\n",
       "  'published': '2020-05-30T14:32:46Z',\n",
       "  'updated': '2020-05-30T14:32:46Z',\n",
       "  'abstract': 'Expert Iteration (ExIt) is an effective framework for learning game-playingpolicies from self-play. ExIt involves training a policy to mimic the searchbehaviour of a tree search algorithm - such as Monte-Carlo tree search - andusing the trained policy to guide it. The policy and the tree search can theniteratively improve each other, through experience gathered in self-playbetween instances of the guided tree search algorithm. This paper outlinesthree different approaches for manipulating the distribution of data collectedfrom self-play, and the procedure that samples batches for learning updatesfrom the collected data. Firstly, samples in batches are weighted based on thedurations of the episodes in which they were originally experienced. Secondly,Prioritized Experience Replay is applied within the ExIt framework, toprioritise sampling experience from which we expect to obtain valuable trainingsignals. Thirdly, a trained exploratory policy is used to diversify thetrajectories experienced in self-play. This paper summarises the effects ofthese manipulations on training performance evaluated in fourteen differentboard games. We find major improvements in early training performance in somegames, and minor improvements averaged over fourteen games.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.00283v1'},\n",
       " 716: {'ID': 716,\n",
       "  'title': 'Tiny Transducer: A Highly-efficient Speech Recognition Model on Edge  Devices',\n",
       "  'authors': ['Yuekai Zhang', 'Sining Sun', 'Long Ma'],\n",
       "  'published': '2021-01-18T03:07:57Z',\n",
       "  'updated': '2021-02-07T06:11:04Z',\n",
       "  'abstract': 'This paper proposes an extremely lightweight phone-based transducer modelwith a tiny decoding graph on edge devices. First, a phone synchronous decoding(PSD) algorithm based on blank label skipping is first used to speed up thetransducer decoding process. Then, to decrease the deletion errors introducedby the high blank score, a blank label deweighting approach is proposed. Toreduce parameters and computation, deep feedforward sequential memory network(DFSMN) layers are used in the transducer encoder, and a CNN-based statelesspredictor is adopted. SVD technology compresses the model further. WFST-baseddecoding graph takes the context-independent (CI) phone posteriors as input andallows us to flexibly bias user-specific information. Finally, with only 0.9Mparameters after SVD, our system could give a relative 9.1% - 20.5% improvementcompared with a bigger conventional hybrid system on edge devices.',\n",
       "  'categories': ['eess.AS', 'cs.SD'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.06856v2'},\n",
       " 717: {'ID': 717,\n",
       "  'title': 'Decentralized Deep Reinforcement Learning for Network Level Traffic  Signal Control',\n",
       "  'authors': ['Jin Guo'],\n",
       "  'published': '2020-07-02T06:58:27Z',\n",
       "  'updated': '2020-07-17T23:15:45Z',\n",
       "  'abstract': 'In this thesis, I propose a family of fully decentralized deep multi-agentreinforcement learning (MARL) algorithms to achieve high, real-time performancein network-level traffic signal control. In this approach, each intersection ismodeled as an agent that plays a Markovian Game against the other intersectionnodes in a traffic signal network modeled as an undirected graph, to approachthe optimal reduction in delay. Following Partially Observable Markov DecisionProcesses (POMDPs), there are 3 levels of communication schemes betweenadjacent learning agents: independent deep Q-leaning (IDQL), shared statesreinforcement learning (S2RL) and a shared states &amp; rewards version ofS2RL--S2R2L. In these 3 variants of decentralized MARL schemes, individualagent trains its local deep Q network (DQN) separately, enhanced byconvergence-guaranteed techniques like double DQN, prioritized experiencereplay, multi-step bootstrapping, etc. To test the performance of the proposedthree MARL algorithms, a SUMO-based simulation platform is developed to mimicthe traffic evolution of the real world. Fed with random traffic demand betweenpermitted OD pairs, a 4x4 Manhattan-style grid network is set up as thetestbed, two different vehicle arrival rates are generated for model trainingand testing. The experiment results show that S2R2L has a quicker convergencerate and better convergent performance than IDQL and S2RL in the trainingprocess. Moreover, three MARL schemes all reveal exceptional generalizationabilities. Their testing results surpass the benchmark Max Pressure (MP)algorithm, under the criteria of average vehicle delay, network-level queuelength and fuel consumption rate. Notably, S2R2L has the best testingperformance of reducing 34.55% traffic delay and dissipating 10.91% queuelength compared with MP.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.03433v2'},\n",
       " 718: {'ID': 718,\n",
       "  'title': 'When and Why is Unsupervised Neural Machine Translation Useless?',\n",
       "  'authors': ['Yunsu Kim', 'Miguel Graça', 'Hermann Ney'],\n",
       "  'published': '2020-04-22T14:00:55Z',\n",
       "  'updated': '2020-04-22T14:00:55Z',\n",
       "  'abstract': 'This paper studies the practicality of the current state-of-the-artunsupervised methods in neural machine translation (NMT). In ten translationtasks with various data settings, we analyze the conditions under which theunsupervised methods fail to produce reasonable translations. We show thattheir performance is severely affected by linguistic dissimilarity and domainmismatch between source and target monolingual data. Such conditions are commonfor low-resource language pairs, where unsupervised learning works poorly. Inall of our experiments, supervised and semi-supervised baselines with50k-sentence bilingual data outperform the best unsupervised results. Ouranalyses pinpoint the limits of the current unsupervised NMT and also suggestimmediate research directions.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.10581v1'},\n",
       " 719: {'ID': 719,\n",
       "  'title': 'Pooling of Causal Models under Counterfactual Fairness via Causal  Judgement Aggregation',\n",
       "  'authors': ['Fabio Massimo Zennaro', 'Magdalena Ivanovska'],\n",
       "  'published': '2018-05-24T19:39:20Z',\n",
       "  'updated': '2018-10-01T12:56:06Z',\n",
       "  'abstract': 'In this paper we consider the problem of combining multiple probabilisticcausal models, provided by different experts, under the requirement that theaggregated model satisfy the criterion of counterfactual fairness. We buildupon the work on causal models and fairness in machine learning, and we expressthe problem of combining multiple models within the framework of opinionpooling. We propose two simple algorithms, grounded in the theory ofcounterfactual fairness and causal judgment aggregation, that are guaranteed togenerate aggregated probabilistic causal models respecting the criterion offairness, and we compare their behaviors on a toy case study.',\n",
       "  'categories': ['cs.AI', 'cs.CY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.09866v2'},\n",
       " 720: {'ID': 720,\n",
       "  'title': 'Strong Asymptotic Composition Theorems for Sibson Mutual Information',\n",
       "  'authors': ['Benjamin Wu',\n",
       "   'Ibrahim Issa',\n",
       "   'G. Edward Suh',\n",
       "   'Aaron B. Wagner'],\n",
       "  'published': '2020-05-12T20:08:30Z',\n",
       "  'updated': '2020-05-12T20:08:30Z',\n",
       "  'abstract': 'We characterize the growth of the Sibson mutual information, of any orderthat is at least unity, between a random variable and an increasing set ofnoisy, conditionally independent observations of the random variable. TheSibson mutual information increases to an order-dependent limit exponentiallyfast, with an exponent that is order-independent. The result is contrasted withcomposition theorems in differential privacy.',\n",
       "  'categories': ['cs.IT', 'math.IT'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.06033v1'},\n",
       " 721: {'ID': 721,\n",
       "  'title': 'Long Short Term Memory Networks for Bandwidth Forecasting in Mobile  Broadband Networks under Mobility',\n",
       "  'authors': ['Konstantinos Kousias',\n",
       "   'Antonios Argyriou',\n",
       "   'Apostolos Pappas',\n",
       "   'Michael Riegler',\n",
       "   'Ozgu Alay'],\n",
       "  'published': '2020-11-20T18:59:27Z',\n",
       "  'updated': '2020-11-20T18:59:27Z',\n",
       "  'abstract': 'Bandwidth forecasting in Mobile Broadband (MBB) networks is a challengingtask, particularly when coupled with a degree of mobility. In this work, weintroduce HINDSIGHT++, an open-source R-based framework for bandwidthforecasting experimentation in MBB networks with Long Short Term Memory (LSTM)networks. We instrument HINDSIGHT++ following an Automated Machine Learning(AutoML) paradigm to first, alleviate the burden of data preprocessing, andsecond, enhance performance related aspects. We primarily focus on bandwidthforecasting for Fifth Generation (5G) networks. In particular, we leverage5Gophers, the first open-source attempt to measure network performance onoperational 5G networks in the US. We further explore the LSTM performanceboundaries on Fourth Generation (4G) commercial settings using NYU-METS, anopen-source dataset comprising of hundreds of bandwidth traces spanningdifferent mobility scenarios. Our study aims to investigate the impact ofhyperparameter optimization on achieving state-of-the-art performance andbeyond. Results highlight its significance under 5G scenarios showing anaverage Mean Absolute Error (MAE) decrease of near 30% when compared to priorstate-of-the-art values. Due to its universal design, we argue that HINDSIGHT++can serve as a handy software tool for a multitude of applications in otherscientific fields.',\n",
       "  'categories': ['cs.NI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.10563v1'},\n",
       " 722: {'ID': 722,\n",
       "  'title': 'DUG-RECON: A Framework for Direct Image Reconstruction using  Convolutional Generative Networks',\n",
       "  'authors': ['V. S. S. Kandarpa',\n",
       "   'Dimitris Visvikis',\n",
       "   'Didier Benoit',\n",
       "   'Alexandre Bousse'],\n",
       "  'published': '2020-12-03T15:28:27Z',\n",
       "  'updated': '2020-12-03T15:28:27Z',\n",
       "  'abstract': 'This paper explores convolutional generative networks as an alternative toiterative reconstruction algorithms in medical image reconstruction. The taskof medical image reconstruction involves mapping of projection main datacollected from the detector to the image domain. This mapping is done typicallythrough iterative reconstruction algorithms which are time consuming andcomputationally expensive. Trained deep learning networks provide fasteroutputs as proven in various tasks across computer vision. In this work wepropose a direct reconstruction framework exclusively with deep learningarchitectures. The proposed framework consists of three segments, namelydenoising, reconstruction and super resolution. The denoising and the superresolution segments act as processing steps. The reconstruction segmentconsists of a novel double U-Net generator (DUG) which learns thesinogram-to-image transformation. This entire network was trained on positronemission tomography (PET) and computed tomography (CT) images. Thereconstruction framework approximates two-dimensional (2-D) mapping fromprojection domain to image domain. The architecture proposed in thisproof-of-concept work is a novel approach to direct image reconstruction;further improvement is required to implement it in a clinical setting.',\n",
       "  'categories': ['physics.med-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.02000v1'},\n",
       " 723: {'ID': 723,\n",
       "  'title': 'GeneraLight: Improving Environment Generalization of Traffic Signal  Control via Meta Reinforcement Learning',\n",
       "  'authors': ['Yong Yu',\n",
       "   'Weinan Zhang',\n",
       "   'Guanjie Zheng',\n",
       "   'Chang Liu',\n",
       "   'Huichu Zhang'],\n",
       "  'published': '2020-09-17T04:14:28Z',\n",
       "  'updated': '2020-09-17T04:14:28Z',\n",
       "  'abstract': 'The heavy traffic congestion problem has always been a concern for moderncities. To alleviate traffic congestion, researchers use reinforcement learning(RL) to develop better traffic signal control (TSC) algorithms in recent years.However, most RL models are trained and tested in the same traffic flowenvironment, which results in a serious overfitting problem. Since the trafficflow environment in the real world keeps varying, these models can hardly beapplied due to the lack of generalization ability. Besides, the limited numberof accessible traffic flow data brings extra difficulty in testing thegeneralization ability of the models. In this paper, we design a novel trafficflow generator based on Wasserstein generative adversarial network to generatesufficient diverse and quality traffic flows and use them to build propertraining and testing environments. Then we propose a meta-RL TSC frameworkGeneraLight to improve the generalization ability of TSC models. GeneraLightboosts the generalization performance by combining the idea of flow clusteringand model-agnostic meta-learning. We conduct extensive experiments on multiplereal-world datasets to show the superior performance of GeneraLight ongeneralizing to different traffic flows.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.08052v1'},\n",
       " 724: {'ID': 724,\n",
       "  'title': 'PNEL: Pointer Network based End-To-End Entity Linking over Knowledge  Graphs',\n",
       "  'authors': ['Jens Lehmann',\n",
       "   'Debanjan Chaudhuri',\n",
       "   'Mohnish Dubey',\n",
       "   'Debayan Banerjee'],\n",
       "  'published': '2020-08-31T21:15:28Z',\n",
       "  'updated': '2020-08-31T21:15:28Z',\n",
       "  'abstract': 'Question Answering systems are generally modelled as a pipeline consisting ofa sequence of steps. In such a pipeline, Entity Linking (EL) is often the firststep. Several EL models first perform span detection and then entitydisambiguation. In such models errors from the span detection phase cascade tolater steps and result in a drop of overall accuracy. Moreover, lack of goldentity spans in training data is a limiting factor for span detector training.Hence the movement towards end-to-end EL models began where no separate spandetection step is involved. In this work we present a novel approach toend-to-end EL by applying the popular Pointer Network model, which achievescompetitive performance. We demonstrate this in our evaluation over threedatasets on the Wikidata Knowledge Graph.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.00106v1'},\n",
       " 725: {'ID': 725,\n",
       "  'title': 'Neural Ordinary Differential Equation Control of Dynamics on Graphs',\n",
       "  'authors': ['Lucas Böttcher', 'Nino Antulov-Fantulin', 'Thomas Asikis'],\n",
       "  'published': '2020-06-17T10:47:03Z',\n",
       "  'updated': '2021-01-04T19:05:02Z',\n",
       "  'abstract': 'We study the ability of neural networks to steer or control trajectories ofdynamical systems on graphs, which we represent with neural ordinarydifferential equations (neural ODEs). To do so, we introduce a neural-ODEcontrol (NODEC) framework and find that it can learn control signals that drivegraph dynamical systems into desired target states. While we use loss functionsthat do not constrain the control energy, our results show that NODEC producescontrol signals that are highly correlated with optimal (or minimum energy)control signals. Finally, we empirically showcase the high performance andversatility of NODEC for various (non-)linear dynamics and loss functions ondifferent graphs.',\n",
       "  'categories': ['cs.LG', 'cs.SI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.09773v3'},\n",
       " 726: {'ID': 726,\n",
       "  'title': 'Data-driven prediction and analysis of chaotic origami dynamics',\n",
       "  'authors': ['Koshiro Yamaguchi',\n",
       "   'Jinkyu Yang',\n",
       "   'Hiromi Yasuda',\n",
       "   'Jordan R. Raney',\n",
       "   'Yasuhiro Miyazawa',\n",
       "   'Richard Wiebe'],\n",
       "  'published': '2020-02-26T17:30:38Z',\n",
       "  'updated': '2020-02-26T17:30:38Z',\n",
       "  'abstract': 'Advances in machine learning have revolutionized capabilities in applicationsranging from natural language processing to marketing to health care. Here, wedemonstrate the efficacy of machine learning in predicting chaotic behavior incomplex nonlinear mechanical systems. Specifically, we use quasi-recurrentneural networks to predict extremely chaotic time series data obtained frommultistable origami systems. Additionally, while machine learning is oftenviewed as a \"black box\", in this study we conduct hidden layer analysis tounderstand how the neural network can process not only periodic, but alsochaotic data in an accurate manner. Also, our approach shows its effectivenessin characterizing and predicting chaotic dynamics in a noisy environment ofvibrations without relying on a mathematical model of origami systems.Therefore, our method is fully data-driven and has the potential to be used forcomplex scenarios, such as the nonlinear dynamics of thin-walled structures andbiological membrane systems.',\n",
       "  'categories': ['cond-mat.soft', 'cond-mat.dis-nn', 'physics.class-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.12176v1'},\n",
       " 727: {'ID': 727,\n",
       "  'title': 'MONAS: Multi-Objective Neural Architecture Search using Reinforcement  Learning',\n",
       "  'authors': ['Chun-Hao Liu',\n",
       "   'Shu-Huan Chang',\n",
       "   'Shih-Chieh Chang',\n",
       "   'Jhao-Hong Liang',\n",
       "   'Wei Wei',\n",
       "   'Jia-Yu Pan',\n",
       "   'Chi-Hung Hsu',\n",
       "   'Yu-Ting Chen',\n",
       "   'Hsin-Ping Chou',\n",
       "   'Da-Cheng Juan'],\n",
       "  'published': '2018-06-27T08:12:01Z',\n",
       "  'updated': '2018-12-03T06:54:48Z',\n",
       "  'abstract': 'Recent studies on neural architecture search have shown that automaticallydesigned neural networks perform as good as expert-crafted architectures. Whilemost existing works aim at finding architectures that optimize the predictionaccuracy, these architectures may have complexity and is therefore not suitablebeing deployed on certain computing environment (e.g., with limited powerbudgets). We propose MONAS, a framework for Multi-Objective NeuralArchitectural Search that employs reward functions considering both predictionaccuracy and other important objectives (e.g., power consumption) whensearching for neural network architectures. Experimental results showed that,compared to the state-ofthe-arts, models found by MONAS achieve comparable orbetter classification accuracy on computer vision applications, whilesatisfying the additional objectives such as peak power.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.10332v2'},\n",
       " 728: {'ID': 728,\n",
       "  'title': 'A Gated Hypernet Decoder for Polar Codes',\n",
       "  'authors': ['Lior Wolf', 'Eliya Nachmani'],\n",
       "  'published': '2019-11-08T12:58:43Z',\n",
       "  'updated': '2020-02-10T11:08:54Z',\n",
       "  'abstract': 'Hypernetworks were recently shown to improve the performance of messagepassing algorithms for decoding error correcting codes. In this work, wedemonstrate how hypernetworks can be applied to decode polar codes by employinga new formalization of the polar belief propagation decoding scheme. Wedemonstrate that our method improves the previous results of neural polardecoders and achieves, for large SNRs, the same bit-error-rate performances asthe successive list cancellation method, which is known to be better than anybelief propagation decoders and very close to the maximum likelihood decoder.',\n",
       "  'categories': ['cs.IT', 'cs.LG', 'math.IT'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.03229v2'},\n",
       " 729: {'ID': 729,\n",
       "  'title': 'Multi-Faceted Representation Learning with Hybrid Architecture for Time  Series Classification',\n",
       "  'authors': ['Zhenyu Liu', 'Jian Cheng'],\n",
       "  'published': '2020-12-21T16:42:07Z',\n",
       "  'updated': '2020-12-21T16:42:07Z',\n",
       "  'abstract': 'Time series classification problems exist in many fields and have beenexplored for a couple of decades. However, they still remain challenging, andtheir solutions need to be further improved for real-world applications interms of both accuracy and efficiency. In this paper, we propose a hybridneural architecture, called Self-Attentive Recurrent Convolutional Networks(SARCoN), to learn multi-faceted representations for univariate time series.SARCoN is the synthesis of long short-term memory networks with self-attentivemechanisms and Fully Convolutional Networks, which work in parallel to learnthe representations of univariate time series from different perspectives. Thecomponent modules of the proposed architecture are trained jointly in anend-to-end manner and they classify the input time series in a cooperative way.Due to its domain-agnostic nature, SARCoN is able to generalize a diversity ofdomain tasks. Our experimental results show that, compared to thestate-of-the-art approaches for time series classification, the proposedarchitecture can achieve remarkable improvements for a set of univariate timeseries benchmarks from the UCR repository. Moreover, the self-attention and theglobal average pooling in the proposed architecture enable visibleinterpretability by facilitating the identification of the contribution regionsof the original time series. An overall analysis confirms that multi-facetedrepresentations of time series aid in capturing deep temporal correctionswithin complex time series, which is essential for the improvement of timeseries classification performance. Our work provides a novel angle that deepensthe understanding of time series classification, qualifying our proposed modelas an ideal choice for real-world applications.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.11472v1'},\n",
       " 730: {'ID': 730,\n",
       "  'title': 'A CNN for homogneous Riemannian manifolds with applications to  Neuroimaging',\n",
       "  'authors': ['Baba C. Vemuri', 'Rudrasis Chakraborty', 'Monami Banerjee'],\n",
       "  'published': '2018-05-14T22:56:46Z',\n",
       "  'updated': '2018-08-06T20:46:42Z',\n",
       "  'abstract': 'Convolutional neural networks are ubiquitous in Machine Learning applicationsfor solving a variety of problems. They however can not be used in their nativeform when the domain of the data is commonly encountered manifolds such as thesphere, the special orthogonal group, the Grassmanian, the manifold ofsymmetric positive definite matrices and others. Most recently, generalizationof CNNs to data domains such as the 2-sphere has been reported by some researchgroups, which is referred to as the spherical CNNs (SCNNs). The key property ofSCNNs distinct from CNNs is that they exhibit the rotational equivarianceproperty that allows for sharing learned weights within a layer. In this paper,we theoretically generalize the CNNs to Riemannian homogeneous manifolds, thatinclude but are not limited to the aforementioned example manifolds. Our keycontributions in this work are: (i) A theorem stating that linear groupequivariance systems are fully characterized by correlation of functions on thedomain manifold and vice-versa. This is fundamental to the characterization ofall linear group equivariant systems and parallels the widely used result inlinear system theory for vector spaces. (ii) As a corrolary, we prove theequivariance of the correlation operation to group actions admitted by theinput domains which are Riemannian homogeneous manifolds. (iii) We present thefirst end-to-end deep network architecture for classification of diffusionmagnetic resonance image (dMRI) scans acquired from a cohort of 44 ParkinsonDisease patients and 50 control/normal subjects. (iv) A proof of conceptexperiment involving synthetic data generated on the manifold of symmetricpositive definite matrices is presented to demonstrate the applicability of ournetwork to other types of domains.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.05487v3'},\n",
       " 731: {'ID': 731,\n",
       "  'title': 'condLSTM-Q: A novel deep learning model for predicting Covid-19  mortality in fine geographical Scale',\n",
       "  'authors': ['Tzu-Chen Huang', 'Juhyun Kim', 'HyeongChan Jo', 'Yu-Li Ni'],\n",
       "  'published': '2020-11-23T16:14:48Z',\n",
       "  'updated': '2020-11-23T16:14:48Z',\n",
       "  'abstract': 'Predictive models with a focus on different spatial-temporal scales benefitgovernments and healthcare systems to combat the COVID-19 pandemic. Here wepresent the conditional Long Short-Term Memory networks with Quantile output(condLSTM-Q), a well-performing model for making quantile predictions onCOVID-19 death tolls at the county level with a two-week forecast window. Thisfine geographical scale is a rare but useful feature in publicly availablepredictive models, which would especially benefit state-level officials tocoordinate resources within the state. The quantile predictions from condLSTM-Qinform people about the distribution of the predicted death tolls, allowingbetter evaluation of possible trajectories of the severity. Given thescalability and generalizability of neural network models, this model couldincorporate additional data sources with ease, and could be further developedto generate other useful predictions such as new cases or hospitalizationsintuitively.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.11507v1'},\n",
       " 732: {'ID': 732,\n",
       "  'title': 'Semialgebraic Optimization for Lipschitz Constants of ReLU Networks',\n",
       "  'authors': ['Edouard Pauwels',\n",
       "   'Jean-Bernard Lasserre',\n",
       "   'Tong Chen',\n",
       "   'Victor Magron'],\n",
       "  'published': '2020-02-10T11:09:37Z',\n",
       "  'updated': '2020-10-28T09:19:39Z',\n",
       "  'abstract': \"The Lipschitz constant of a network plays an important role in manyapplications of deep learning, such as robustness certification and WassersteinGenerative Adversarial Network. We introduce a semidefinite programminghierarchy to estimate the global and local Lipschitz constant of a multiplelayer deep neural network. The novelty is to combine a polynomial lifting forReLU functions derivatives with a weak generalization of Putinar's positivitycertificate. This idea could also apply to other, nearly sparse, polynomialoptimization problems in machine learning. We empirically demonstrate that ourmethod provides a trade-off with respect to state of the art linear programmingapproach, and in some cases we obtain better bounds in less time.\",\n",
       "  'categories': ['math.OC', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.03657v4'},\n",
       " 733: {'ID': 733,\n",
       "  'title': 'Local Communication Protocols for Learning Complex Swarm Behaviors with  Deep Reinforcement Learning',\n",
       "  'authors': ['Gerhard Neumann', 'Adrian Šošić', 'Maximilian Hüttenrauch'],\n",
       "  'published': '2017-09-21T09:18:09Z',\n",
       "  'updated': '2018-07-18T08:39:08Z',\n",
       "  'abstract': 'Swarm systems constitute a challenging problem for reinforcement learning(RL) as the algorithm needs to learn decentralized control policies that cancope with limited local sensing and communication abilities of the agents.While it is often difficult to directly define the behavior of the agents,simple communication protocols can be defined more easily using prior knowledgeabout the given task. In this paper, we propose a number of simplecommunication protocols that can be exploited by deep reinforcement learning tofind decentralized control policies in a multi-robot swarm environment. Theprotocols are based on histograms that encode the local neighborhood relationsof the agents and can also transmit task-specific information, such as theshortest distance and direction to a desired target. In our framework, we usean adaptation of Trust Region Policy Optimization to learn complexcollaborative tasks, such as formation building and building a communicationlink. We evaluate our findings in a simulated 2D-physics environment, andcompare the implications of different communication protocols.',\n",
       "  'categories': ['cs.MA', 'cs.AI', 'cs.LG', 'cs.SY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.07224v2'},\n",
       " 734: {'ID': 734,\n",
       "  'title': 'Benchmark Environments for Multitask Learning in Continuous Domains',\n",
       "  'authors': ['Florian Shkurti',\n",
       "   'Gregory Dudek',\n",
       "   'Peter Henderson',\n",
       "   'Johanna Hansen',\n",
       "   'David Meger',\n",
       "   'Wei-Di Chang'],\n",
       "  'published': '2017-08-14T22:55:03Z',\n",
       "  'updated': '2017-08-14T22:55:03Z',\n",
       "  'abstract': 'As demand drives systems to generalize to various domains and problems, thestudy of multitask, transfer and lifelong learning has become an increasinglyimportant pursuit. In discrete domains, performance on the Atari game suite hasemerged as the de facto benchmark for assessing multitask learning. However, incontinuous domains there is a lack of agreement on standard multitaskevaluation environments which makes it difficult to compare differentapproaches fairly. In this work, we describe a benchmark set of tasks that wehave developed in an extendable framework based on OpenAI Gym. We run a simplebaseline using Trust Region Policy Optimization and release the frameworkpublicly to be expanded and used for the systematic comparison of multitask,transfer, and lifelong learning in continuous domains.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.04352v1'},\n",
       " 735: {'ID': 735,\n",
       "  'title': 'Real-time Policy Distillation in Deep Reinforcement Learning',\n",
       "  'authors': ['Pooyan Fazli', 'Yuxiang Sun'],\n",
       "  'published': '2019-12-29T11:10:37Z',\n",
       "  'updated': '2019-12-29T11:10:37Z',\n",
       "  'abstract': \"Policy distillation in deep reinforcement learning provides an effective wayto transfer control policies from a larger network to a smaller untrainednetwork without a significant degradation in performance. However, policydistillation is underexplored in deep reinforcement learning, and existingapproaches are computationally inefficient, resulting in a long distillationtime. In addition, the effectiveness of the distillation process is stilllimited to the model capacity. We propose a new distillation mechanism, calledreal-time policy distillation, in which training the teacher model anddistilling the policy to the student model occur simultaneously. Accordingly,the teacher's latest policy is transferred to the student model in real time.This reduces the distillation time to half the original time or even less andalso makes it possible for extremely small student models to learn skills atthe expert level. We evaluated the proposed algorithm in the Atari 2600 domain.The results show that our approach can achieve full distillation in most games,even with compression ratios up to 1.7%.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.12630v1'},\n",
       " 736: {'ID': 736,\n",
       "  'title': 'Statistical transformer networks: learning shape and appearance models  via self supervision',\n",
       "  'authors': ['William A. P. Smith', 'Anil Bas'],\n",
       "  'published': '2018-04-07T10:18:15Z',\n",
       "  'updated': '2018-04-07T10:18:15Z',\n",
       "  'abstract': 'We generalise Spatial Transformer Networks (STN) by replacing the parametrictransformation of a fixed, regular sampling grid with a deformable, statisticalshape model which is itself learnt. We call this a Statistical TransformerNetwork (StaTN). By training a network containing a StaTN end-to-end for aparticular task, the network learns the optimal nonrigid alignment of the inputdata for the task. Moreover, the statistical shape model is learnt with nodirect supervision (such as landmarks) and can be reused for other tasks.Besides training for a specific task, we also show that a StaTN can learn ashape model using generic loss functions. This includes a loss inspired by theminimum description length principle in which an appearance model is alsolearnt from scratch. In this configuration, our model learns an activeappearance model and a means to fit the model from scratch with no supervisionat all, even identity labels.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.02541v1'},\n",
       " 737: {'ID': 737,\n",
       "  'title': 'Graph Attention Tracking',\n",
       "  'authors': ['Yanyan Shao',\n",
       "   'Chunhua Shen',\n",
       "   'Zhenhua Wang',\n",
       "   'Dongyan Guo',\n",
       "   'Liyan Zhang',\n",
       "   'Ying Cui'],\n",
       "  'published': '2020-11-23T04:26:45Z',\n",
       "  'updated': '2020-11-23T04:26:45Z',\n",
       "  'abstract': 'Siamese network based trackers formulate the visual tracking task as asimilarity matching problem. Almost all popular Siamese trackers realize thesimilarity learning via convolutional feature cross-correlation between atarget branch and a search branch. However, since the size of target featureregion needs to be pre-fixed, these cross-correlation base methods suffer fromeither reserving much adverse background information or missing a great deal offoreground information. Moreover, the global matching between the target andsearch region also largely neglects the target structure and part-levelinformation.  In this paper, to solve the above issues, we propose a simple target-awareSiamese graph attention network for general object tracking. We propose toestablish part-to-part correspondence between the target and the search regionwith a complete bipartite graph, and apply the graph attention mechanism topropagate target information from the template feature to the search feature.Further, instead of using the pre-fixed region cropping fortemplate-feature-area selection, we investigate a target-aware area selectionmechanism to fit the size and aspect ratio variations of different objects.Experiments on challenging benchmarks including GOT-10k, UAV123, OTB-100 andLaSOT demonstrate that the proposed SiamGAT outperforms many state-of-the-arttrackers and achieves leading performance. Code is available at:https://git.io/SiamGAT',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.11204v1'},\n",
       " 738: {'ID': 738,\n",
       "  'title': 'Attention-based Quantum Tomography',\n",
       "  'authors': ['Peter L. McMahon',\n",
       "   'Juan Carrasquilla',\n",
       "   'Peter Cha',\n",
       "   'Paul Ginsparg',\n",
       "   'Felix Wu',\n",
       "   'Eun-Ah Kim'],\n",
       "  'published': '2020-06-22T17:50:12Z',\n",
       "  'updated': '2020-06-22T17:50:12Z',\n",
       "  'abstract': 'With rapid progress across platforms for quantum systems, the problem ofmany-body quantum state reconstruction for noisy quantum states becomes animportant challenge. Recent works found promise in recasting the problem ofquantum state reconstruction to learning the probability distribution ofquantum state measurement vectors using generative neural network models. Herewe propose the \"Attention-based Quantum Tomography\" (AQT), a quantum statereconstruction using an attention mechanism-based generative network thatlearns the mixed state density matrix of a noisy quantum state. The AQT isbased on the model proposed in \"Attention is all you need\" by Vishwani et al(2017) that is designed to learn long-range correlations in natural languagesentences and thereby outperform previous natural language processing models.We demonstrate not only that AQT outperforms earlier neural-network-basedquantum state reconstruction on identical tasks but that AQT can accuratelyreconstruct the density matrix associated with a noisy quantum stateexperimentally realized in an IBMQ quantum computer. We speculate the successof the AQT stems from its ability to model quantum entanglement across theentire quantum system much as the attention model for natural languageprocessing captures the correlations among words in a sentence.',\n",
       "  'categories': ['quant-ph', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.12469v1'},\n",
       " 739: {'ID': 739,\n",
       "  'title': 'PidginUNMT: Unsupervised Neural Machine Translation from West African  Pidgin to English',\n",
       "  'authors': ['Kelechi Ogueji', 'Orevaoghene Ahia'],\n",
       "  'published': '2019-12-07T05:30:09Z',\n",
       "  'updated': '2019-12-07T05:30:09Z',\n",
       "  'abstract': 'Over 800 languages are spoken across West Africa. Despite the obviousdiversity among people who speak these languages, one language significantlyunifies them all - West African Pidgin English. There are at least 80 millionspeakers of West African Pidgin English. However, there is no known naturallanguage processing (NLP) work on this language. In this work, we perform thefirst NLP work on the most popular variant of the language, providing threemajor contributions. First, the provision of a Pidgin corpus of over 56000sentences, which is the largest we know of. Secondly, the training of the firstever cross-lingual embedding between Pidgin and English. This aligned embeddingwill be helpful in the performance of various downstream tasks between Englishand Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translationmodel between Pidgin and English which achieves BLEU scores of 7.93 from Pidginto English, and 5.18 from English to Pidgin. In all, this work greatly reducesthe barrier of entry for future NLP works on West African Pidgin English.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.03444v1'},\n",
       " 740: {'ID': 740,\n",
       "  'title': 'Attentive Group Equivariant Convolutional Networks',\n",
       "  'authors': ['Erik J. Bekkers',\n",
       "   'Mark Hoogendoorn',\n",
       "   'David W. Romero',\n",
       "   'Jakub M. Tomczak'],\n",
       "  'published': '2020-02-07T14:06:24Z',\n",
       "  'updated': '2020-06-30T07:41:35Z',\n",
       "  'abstract': 'Although group convolutional networks are able to learn powerfulrepresentations based on symmetry patterns, they lack explicit means to learnmeaningful relationships among them (e.g., relative positions and poses). Inthis paper, we present attentive group equivariant convolutions, ageneralization of the group convolution, in which attention is applied duringthe course of convolution to accentuate meaningful symmetry combinations andsuppress non-plausible, misleading ones. We indicate that prior work on visualattention can be described as special cases of our proposed framework and showempirically that our attentive group equivariant convolutional networksconsistently outperform conventional group convolutional networks on benchmarkimage datasets. Simultaneously, we provide interpretability to the learnedconcepts through the visualization of equivariant attention maps.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.03830v3'},\n",
       " 741: {'ID': 741,\n",
       "  'title': 'SpatialSim: Recognizing Spatial Configurations of Objects with Graph  Neural Networks',\n",
       "  'authors': ['Laetitia Teodorescu', 'Katja Hofmann', 'Pierre-Yves Oudeyer'],\n",
       "  'published': '2020-04-09T14:13:20Z',\n",
       "  'updated': '2020-07-16T18:16:31Z',\n",
       "  'abstract': 'Recognizing precise geometrical configurations of groups of objects is a keycapability of human spatial cognition, yet little studied in the deep learningliterature so far. In particular, a fundamental problem is how a machine canlearn and compare classes of geometric spatial configurations that areinvariant to the point of view of an external observer. In this paper we maketwo key contributions. First, we propose SpatialSim (Spatial Similarity), anovel geometrical reasoning benchmark, and argue that progress on thisbenchmark would pave the way towards a general solution to address thischallenge in the real world. This benchmark is composed of two tasks:Identification and Comparison, each one instantiated in increasing levels ofdifficulty. Secondly, we study how relational inductive biases exhibited byfully-connected message-passing Graph Neural Networks (MPGNNs) are useful tosolve those tasks, and show their advantages over less relational baselinessuch as Deep Sets and unstructured models such as Multi-Layer Perceptrons.Finally, we highlight the current limits of GNNs in these tasks.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.04546v2'},\n",
       " 742: {'ID': 742,\n",
       "  'title': 'SPAGAN: Shortest Path Graph Attention Network',\n",
       "  'authors': ['Dacheng Tao',\n",
       "   'Xinchao Wang',\n",
       "   'Yiding Yang',\n",
       "   'Mingli Song',\n",
       "   'Junsong Yuan'],\n",
       "  'published': '2021-01-10T03:18:34Z',\n",
       "  'updated': '2021-01-10T03:18:34Z',\n",
       "  'abstract': 'Graph convolutional networks (GCN) have recently demonstrated their potentialin analyzing non-grid structure data that can be represented as graphs. Thecore idea is to encode the local topology of a graph, via convolutions, intothe feature of a center node. In this paper, we propose a novel GCN model,which we term as Shortest Path Graph Attention Network (SPAGAN). Unlikeconventional GCN models that carry out node-based attentions within each layer,the proposed SPAGAN conducts path-based attention that explicitly accounts forthe influence of a sequence of nodes yielding the minimum cost, or shortestpath, between the center node and its higher-order neighbors. SPAGAN thereforeallows for a more informative and intact exploration of the graph structure andfurther {a} more effective aggregation of information from distant neighborsinto the center node, as compared to node-based GCN methods. We test SPAGAN onthe downstream classification task on several standard datasets, and achieveperformances superior to the state of the art. Code is publicly available athttps://github.com/ihollywhy/SPAGAN.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.03464v1'},\n",
       " 743: {'ID': 743,\n",
       "  'title': 'Predicting Human Decision Making in Psychological Tasks with Recurrent  Neural Networks',\n",
       "  'authors': ['Baihan Lin', 'Guillermo Cecchi', 'Djallel Bouneffouf'],\n",
       "  'published': '2020-10-22T03:36:03Z',\n",
       "  'updated': '2020-10-22T03:36:03Z',\n",
       "  'abstract': \"Unlike traditional time series, the action sequences of human decision makingusually involve many cognitive processes such as beliefs, desires, intentionsand theory of mind, i.e. what others are thinking. This makes predicting humandecision making challenging to be treated agnostically to the underlyingpsychological mechanisms. We propose to use a recurrent neural networkarchitecture based on long short-term memory networks (LSTM) to predict thetime series of the actions taken by the human subjects at each step of theirdecision making, the first application of such methods in this research domain.We trained our prediction networks on the behavioral data from severalpublished psychological experiments of human decision making, and demonstrateda clear advantage over the state-of-the-art methods in predicting humandecision making trajectories in both single-agent scenarios such as IowaGambling Task and multi-agent scenarios such as Iterated Prisoner's Dilemma.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'q-bio.NC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11413v1'},\n",
       " 744: {'ID': 744,\n",
       "  'title': 'Automated Discovery of Mathematical Definitions in Text with Deep Neural  Networks',\n",
       "  'authors': ['Marina Litvak',\n",
       "   'Sergey Shevchuk',\n",
       "   'Natalia Vanetik',\n",
       "   'Lior Reznik'],\n",
       "  'published': '2020-11-09T15:57:53Z',\n",
       "  'updated': '2020-11-09T15:57:53Z',\n",
       "  'abstract': 'Automatic definition extraction from texts is an important task that hasnumerous applications in several natural language processing fields such assummarization, analysis of scientific texts, automatic taxonomy generation,ontology generation, concept identification, and question answering. Fordefinitions that are contained within a single sentence, this problem can beviewed as a binary classification of sentences into definitions andnon-definitions. In this paper, we focus on automatic detection of one-sentencedefinitions in mathematical texts, which are difficult to separate fromsurrounding text. We experiment with several data representations, whichinclude sentence syntactic structure and word embeddings, and apply deeplearning methods such as the Convolutional Neural Network (CNN) and the LongShort-Term Memory network (LSTM), in order to identify mathematicaldefinitions. Our experiments demonstrate the superiority of CNN and itscombination with LSTM, when applied on the syntactically-enriched inputrepresentation. We also present a new dataset for definition extraction frommathematical texts. We demonstrate that this dataset is beneficial for trainingsupervised models aimed at extraction of mathematical definitions. Ourexperiments with different domains demonstrate that mathematical definitionsrequire special treatment, and that using cross-domain learning is inefficientfor that task.',\n",
       "  'categories': ['cs.CL', 'cs.IR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.04521v1'},\n",
       " 745: {'ID': 745,\n",
       "  'title': 'A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models',\n",
       "  'authors': ['Yueru Li', 'Shuyu Cheng', 'Bo Zhang', 'Jun Zhu', 'Ziyu Wang'],\n",
       "  'published': '2020-02-18T11:40:26Z',\n",
       "  'updated': '2020-02-18T11:40:26Z',\n",
       "  'abstract': 'Score matching provides an effective approach to learning flexibleunnormalized models, but its scalability is limited by the need to evaluate asecond-order derivative. In this paper, we present a scalable approximation toa general family of learning objectives including score matching, by observinga new connection between these objectives and Wasserstein gradient flows. Wepresent applications with promise in learning neural density estimators onmanifolds, and training implicit variational and Wasserstein auto-encoders witha manifold-valued prior.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.07501v1'},\n",
       " 746: {'ID': 746,\n",
       "  'title': 'Universal Policies to Learn Them All',\n",
       "  'authors': ['Hassam Ullah Sheikh', 'Ladislau Bölöni'],\n",
       "  'published': '2019-08-24T18:36:17Z',\n",
       "  'updated': '2019-08-24T18:36:17Z',\n",
       "  'abstract': 'We explore a collaborative and cooperative multi-agent reinforcement learningsetting where a team of reinforcement learning agents attempt to solve a singlecooperative task in a multi-scenario setting. We propose a novel multi-agentreinforcement learning algorithm inspired by universal value functionapproximators that not only generalizes over state space but also over a set ofdifferent scenarios. Additionally, to prove our claim, we are introducing achallenging 2D multi-agent urban security environment where the learning agentsare trying to protect a person from nearby bystanders in a variety ofscenarios. Our study shows that state-of-the-art multi-agent reinforcementlearning algorithms fail to generalize a single task over multiple scenarioswhile our proposed solution works equally well as scenario-dependent policies.',\n",
       "  'categories': ['cs.MA', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.09184v1'},\n",
       " 747: {'ID': 747,\n",
       "  'title': 'Continuous-Time Model-Based Reinforcement Learning',\n",
       "  'authors': ['Çağatay Yıldız', 'Markus Heinonen', 'Harri Lähdesmäki'],\n",
       "  'published': '2021-02-09T11:30:19Z',\n",
       "  'updated': '2021-02-09T11:30:19Z',\n",
       "  'abstract': 'Model-based reinforcement learning (MBRL) approaches rely on discrete-timestate transition models whereas physical systems and the vast majority ofcontrol tasks operate in continuous-time. To avoid time-discretizationapproximation of the underlying process, we propose a continuous-time MBRLframework based on a novel actor-critic method. Our approach also infers theunknown state evolution differentials with Bayesian neural ordinarydifferential equations (ODE) to account for epistemic uncertainty. We implementand test our method on a new ODE-RL suite that explicitly solvescontinuous-time control systems. Our experiments illustrate that the model isrobust against irregular and noisy data, is sample-efficient, and can solvecontrol problems which pose challenges to discrete-time MBRL methods.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.04764v1'},\n",
       " 748: {'ID': 748,\n",
       "  'title': 'Towards Safer Self-Driving Through Great PAIN (Physically Adversarial  Intelligent Networks)',\n",
       "  'authors': ['Demetris Coleman', 'Joshua E. Siegel', 'Piyush Gupta'],\n",
       "  'published': '2020-03-24T05:04:13Z',\n",
       "  'updated': '2020-03-24T05:04:13Z',\n",
       "  'abstract': 'Automated vehicles\\' neural networks suffer from overfit, poorgeneralizability, and untrained edge cases due to limited data availability.Researchers synthesize randomized edge-case scenarios to assist in the trainingprocess, though simulation introduces potential for overfit to latent rules andfeatures. Automating worst-case scenario generation could yield informativedata for improving self driving. To this end, we introduce a \"PhysicallyAdversarial Intelligent Network\" (PAIN), wherein self-driving vehicles interactaggressively in the CARLA simulation environment. We train two agents, aprotagonist and an adversary, using dueling double deep Q networks (DDDQNs)with prioritized experience replay. The coupled networks alternatelyseek-to-collide and to avoid collisions such that the \"defensive\" avoidancealgorithm increases the mean-time-to-failure and distance traveled undernon-hostile operating conditions. The trained protagonist becomes moreresilient to environmental uncertainty and less prone to corner case failuresresulting in collisions than the agent trained without an adversary.',\n",
       "  'categories': ['cs.LG', 'cs.MA', 'cs.SY', 'eess.SY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.10662v1'},\n",
       " 749: {'ID': 749,\n",
       "  'title': 'Stochastic Computing for Hardware Implementation of Binarized Neural  Networks',\n",
       "  'authors': ['Bogdan Penkovsky',\n",
       "   'Damien Querlioz',\n",
       "   'Jean-Michel Portal',\n",
       "   'Jacques-Olivier Klein',\n",
       "   'Tifenn Hirtzlin',\n",
       "   'Marc Bocquet'],\n",
       "  'published': '2019-06-03T16:34:48Z',\n",
       "  'updated': '2019-06-03T16:34:48Z',\n",
       "  'abstract': 'Binarized Neural Networks, a recently discovered class of neural networkswith minimal memory requirements and no reliance on multiplication, are afantastic opportunity for the realization of compact and energy efficientinference hardware. However, such neural networks are generally not entirelybinarized: their first layer remains with fixed point input. In this work, wepropose a stochastic computing version of Binarized Neural Networks, where theinput is also binarized. Simulations on the example of the Fashion-MNIST andCIFAR-10 datasets show that such networks can approach the performance ofconventional Binarized Neural Networks. We evidence that the training procedureshould be adapted for use with stochastic computing. Finally, the ASICimplementation of our scheme is investigated, in a system that closelyassociates logic and memory, implemented by Spin Torque Magnetoresistive RandomAccess Memory. This analysis shows that the stochastic computing approach canallow considerable savings with regards to conventional Binarized Neuralnetworks in terms of area (62% area reduction on the Fashion-MNIST task). Itcan also allow important savings in terms of energy consumption, if we acceptreasonable reduction of accuracy: for example a factor 2.1 can be saved, withthe cost of 1.4% in Fashion-MNIST test accuracy. These results highlight thehigh potential of Binarized Neural Networks for hardware implementation, andthat adapting them to hardware constrains can provide important benefits.',\n",
       "  'categories': ['cs.ET'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.00915v1'},\n",
       " 750: {'ID': 750,\n",
       "  'title': 'Synaptic Metaplasticity in Binarized Neural Networks',\n",
       "  'authors': ['Damien Querlioz',\n",
       "   'Maxence Ernoult',\n",
       "   'Tifenn Hirtzlin',\n",
       "   'Axel Laborieux'],\n",
       "  'published': '2020-03-07T08:09:34Z',\n",
       "  'updated': '2020-03-07T08:09:34Z',\n",
       "  'abstract': 'While deep neural networks have surpassed human performance in multiplesituations, they are prone to catastrophic forgetting: upon training a newtask, they rapidly forget previously learned ones. Neuroscience studies, basedon idealized tasks, suggest that in the brain, synapses overcome this issue byadjusting their plasticity depending on their past history. However, such\"metaplastic\" behaviour has never been leveraged to mitigate catastrophicforgetting in deep neural networks. In this work, we highlight a connectionbetween metaplasticity models and the training process of binarized neuralnetworks, a low-precision version of deep neural networks. Building on thisidea, we propose and demonstrate experimentally, in situations of multitask andstream learning, a training technique that prevents catastrophic forgettingwithout needing previously presented data, nor formal boundaries betweendatasets. We support our approach with a theoretical analysis on a tractabletask. This work bridges computational neuroscience and deep learning, andpresents significant assets for future embedded and neuromorphic systems.',\n",
       "  'categories': ['cs.NE', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.03533v1'},\n",
       " 751: {'ID': 751,\n",
       "  'title': 'Jelly Bean World: A Testbed for Never-Ending Learning',\n",
       "  'authors': ['Emmanouil Antonios Platanios',\n",
       "   'Abulhair Saparov',\n",
       "   'Tom Mitchell'],\n",
       "  'published': '2020-02-15T02:43:16Z',\n",
       "  'updated': '2020-02-15T02:43:16Z',\n",
       "  'abstract': 'Machine learning has shown growing success in recent years. However, currentmachine learning systems are highly specialized, trained for particularproblems or domains, and typically on a single narrow dataset. Human learning,on the other hand, is highly general and adaptable. Never-ending learning is amachine learning paradigm that aims to bridge this gap, with the goal ofencouraging researchers to design machine learning systems that can learn toperform a wider variety of inter-related tasks in more complex environments. Todate, there is no environment or testbed to facilitate the development andevaluation of never-ending learning systems. To this end, we propose the JellyBean World testbed. The Jelly Bean World allows experimentation overtwo-dimensional grid worlds which are filled with items and in which agents cannavigate. This testbed provides environments that are sufficiently complex andwhere more generally intelligent algorithms ought to perform better thancurrent state-of-the-art reinforcement learning approaches. It does so byproducing non-stationary environments and facilitating experimentation withmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hopethat this new freely-available software will prompt new research and interestin the development and evaluation of never-ending learning systems and morebroadly, general intelligence systems.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.MA', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.06306v1'},\n",
       " 752: {'ID': 752,\n",
       "  'title': 'Domain Adaption for Knowledge Tracing',\n",
       "  'authors': ['Qi Liu', 'Song Cheng', 'Enhong Chen'],\n",
       "  'published': '2020-01-14T15:04:48Z',\n",
       "  'updated': '2020-01-14T15:04:48Z',\n",
       "  'abstract': \"With the rapid development of online education system, knowledge tracingwhich aims at predicting students' knowledge state is becoming a critical andfundamental task in personalized education. Traditionally, existing methods aredomain-specified. However, there are a larger number of domains (e.g.,subjects, schools) in the real world and the lacking of data in some domains,how to utilize the knowledge and information in other domains to help train aknowledge tracing model for target domains is increasingly important. We referto this problem as domain adaptation for knowledge tracing (DAKT) whichcontains two aspects: (1) how to achieve great knowledge tracing performance ineach domain. (2) how to transfer good performed knowledge tracing model betweendomains. To this end, in this paper, we propose a novel adaptable framework,namely adaptable knowledge tracing (AKT) to address the DAKT problem.Specifically, for the first aspect, we incorporate the educationalcharacteristics (e.g., slip, guess, question texts) based on the deep knowledgetracing (DKT) to obtain a good performed knowledge tracing model. For thesecond aspect, we propose and adopt three domain adaptation processes. First,we pre-train an auto-encoder to select useful source instances for target modeltraining. Second, we minimize the domain-specific knowledge state distributiondiscrepancy under maximum mean discrepancy (MMD) measurement to achieve domainadaptation. Third, we adopt fine-tuning to deal with the problem that theoutput dimension of source and target domain are different to make the modelsuitable for target domains. Extensive experimental results on two privatedatasets and seven public datasets clearly prove the effectiveness of AKT forgreat knowledge tracing performance and its superior transferable ability.\",\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.04841v1'},\n",
       " 753: {'ID': 753,\n",
       "  'title': 'A Theoretically Grounded Application of Dropout in Recurrent Neural  Networks',\n",
       "  'authors': ['Zoubin Ghahramani', 'Yarin Gal'],\n",
       "  'published': '2015-12-16T19:18:43Z',\n",
       "  'updated': '2016-10-05T15:09:30Z',\n",
       "  'abstract': 'Recurrent neural networks (RNNs) stand at the forefront of many recentdevelopments in deep learning. Yet a major difficulty with these models istheir tendency to overfit, with dropout shown to fail when applied to recurrentlayers. Recent results at the intersection of Bayesian modelling and deeplearning offer a Bayesian interpretation of common deep learning techniquessuch as dropout. This grounding of dropout in approximate Bayesian inferencesuggests an extension of the theoretical results, offering insights into theuse of dropout with RNN models. We apply this new variational inference baseddropout technique in LSTM and GRU models, assessing it on language modellingand sentiment analysis tasks. The new approach outperforms existing techniques,and to the best of our knowledge improves on the single model state-of-the-artin language modelling with the Penn Treebank (73.4 test perplexity). Thisextends our arsenal of variational tools in deep learning.',\n",
       "  'categories': ['stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1512.05287v5'},\n",
       " 754: {'ID': 754,\n",
       "  'title': 'To Regularize or Not To Regularize? The Bias Variance Trade-off in  Regularized AEs',\n",
       "  'authors': ['Prathosh AP',\n",
       "   'Arnab Kumar Mondal',\n",
       "   'Parag Singla',\n",
       "   'Himanshu Asnani'],\n",
       "  'published': '2020-06-10T14:00:14Z',\n",
       "  'updated': '2020-09-19T10:56:48Z',\n",
       "  'abstract': \"Regularized Auto-Encoders (RAEs) form a rich class of neural generativemodels. They effectively model the joint-distribution between the data and thelatent space using an Encoder-Decoder combination, with regularization imposedin terms of a prior over the latent space. Despite their advantages, such asstability in training, the performance of AE based models has not reached thesuperior standards as that of the other generative models such as GenerativeAdversarial Networks (GANs). Motivated by this, we examine the effect of thelatent prior on the generation quality of deterministic AE models in thispaper. Specifically, we consider the class of RAEs with deterministicEncoder-Decoder pairs, Wasserstein Auto-Encoders (WAE), and show that having afixed prior distribution, \\\\textit{a priori}, oblivious to the dimensionality ofthe `true' latent space, will lead to the infeasibility of the optimizationproblem considered. Further, we show that, in the finite data regime, despiteknowing the correct latent dimensionality, there exists a bias-variancetrade-off with any arbitrary prior imposition. As a remedy to both the issuesmentioned above, we introduce an additional state space in the form of flexiblylearnable latent priors, in the optimization objective of the WAEs. Weimplicitly learn the distribution of the latent prior jointly with the AEtraining, which not only makes the learning objective feasible but alsofacilitates operation on different points of the bias-variance curve. We showthe efficacy of our model, called FlexAE, through several experiments onmultiple datasets, and demonstrate that it is the new state-of-the-art for theAE based generative models.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.05838v2'},\n",
       " 755: {'ID': 755,\n",
       "  'title': 'Hierarchical Importance Weighted Autoencoders',\n",
       "  'authors': ['Chin-Wei Huang',\n",
       "   'Aaron Courville',\n",
       "   'Kris Sankaran',\n",
       "   'Eeshan Dhekane',\n",
       "   'Alexandre Lacoste'],\n",
       "  'published': '2019-05-13T05:27:05Z',\n",
       "  'updated': '2019-05-13T05:27:05Z',\n",
       "  'abstract': 'Importance weighted variational inference (Burda et al., 2015) uses multiplei.i.d. samples to have a tighter variational lower bound. We believe a jointproposal has the potential of reducing the number of redundant samples, andintroduce a hierarchical structure to induce correlation. The hope is that theproposals would coordinate to make up for the error made by one another toreduce the variance of the importance estimator. Theoretically, we analyze thecondition under which convergence of the estimator variance can be connected toconvergence of the lower bound. Empirically, we confirm that maximization ofthe lower bound does implicitly minimize variance. Further analysis shows thatthis is a result of negative correlation induced by the proposed hierarchicalmeta sampling scheme, and performance of inference also improves when thenumber of samples increases.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.04866v1'},\n",
       " 756: {'ID': 756,\n",
       "  'title': 'Neurosymbolic Reinforcement Learning with Formally Verified Exploration',\n",
       "  'authors': ['Isil Dillig',\n",
       "   'Swarat Chaudhuri',\n",
       "   'Abhinav Verma',\n",
       "   'Greg Anderson'],\n",
       "  'published': '2020-09-26T14:51:04Z',\n",
       "  'updated': '2020-10-26T14:02:51Z',\n",
       "  'abstract': 'We present Revel, a partially neural reinforcement learning (RL) frameworkfor provably safe exploration in continuous state and action spaces. A keychallenge for provably safe deep RL is that repeatedly verifying neuralnetworks within a learning loop is computationally infeasible. We address thischallenge using two policy classes: a general, neurosymbolic class withapproximate gradients and a more restricted class of symbolic policies thatallows efficient verification. Our learning algorithm is a mirror descent overpolicies: in each iteration, it safely lifts a symbolic policy into theneurosymbolic space, performs safe gradient updates to the resulting policy,and projects the updated policy into the safe symbolic subset, all withoutrequiring explicit verification of neural networks. Our empirical results showthat Revel enforces safe exploration in many scenarios in which ConstrainedPolicy Optimization does not, and that it can discover policies that outperformthose learned through prior approaches to verified exploration.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.12612v2'},\n",
       " 757: {'ID': 757,\n",
       "  'title': 'Back to the Basics: Bayesian extensions of IRT outperform neural  networks for proficiency estimation',\n",
       "  'authors': ['Kevin H. Wilson',\n",
       "   'Chaitanya Ekanadham',\n",
       "   'Yan Karklin',\n",
       "   'Bojian Han'],\n",
       "  'published': '2016-04-08T12:54:18Z',\n",
       "  'updated': '2016-05-21T18:26:21Z',\n",
       "  'abstract': \"Estimating student proficiency is an important task for computer basedlearning systems. We compare a family of IRT-based proficiency estimationmethods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neuralnetwork model with promising initial results. We evaluate how well each modelpredicts a student's future response given previous responses using twopublicly available and one proprietary data set. We find that IRT-based methodsconsistently matched or outperformed DKT across all data sets at the finestlevel of content granularity that was tractable for them to be trained on. Ahierarchical extension of IRT that captured item grouping structure performedbest overall. When data sets included non-trivial autocorrelations in studentresponse patterns, a temporal extension of IRT improved performance overstandard IRT while the RNN-based method did not. We conclude that IRT-basedmodels provide a simpler, better-performing alternative to existing RNN-basedmodels of student interaction data while also affording more interpretabilityand guarantees due to their formulation as Bayesian probabilistic models.\",\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1604.02336v2'},\n",
       " 758: {'ID': 758,\n",
       "  'title': 'A material decomposition method for dual-energy CT via dual interactive  Wasserstein generative adversarial networks',\n",
       "  'authors': ['Zaifeng Shi',\n",
       "   'Qingjie Cao',\n",
       "   'Ming Cheng',\n",
       "   'Zhongqi Wang',\n",
       "   'Huilong Li'],\n",
       "  'published': '2020-07-22T08:03:24Z',\n",
       "  'updated': '2020-07-22T08:03:24Z',\n",
       "  'abstract': 'Dual-energy computed tomography has great potential in materialcharacterization and identification, whereas the reconstructedmaterial-specific images always suffer from magnified noise and beam hardeningartifacts. In this study, a data-driven approach using dual interactiveWasserstein generative adversarial networks is proposed to improve the materialdecomposition accuracy. Specifically, two interactive generators are used tosynthesize the corresponding material images and different loss functions fortraining the decomposition model are incorporated to preserve texture and edgesin the generated images. Besides, a selector is employed to ensure themodelling ability of two generators. The results from both the simulationphantoms and real data demonstrate the advantages of this method in suppressingthe noise and beam hardening artifacts.',\n",
       "  'categories': ['physics.med-ph', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.11247v1'},\n",
       " 759: {'ID': 759,\n",
       "  'title': 'PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks',\n",
       "  'authors': ['Diana Marculescu', 'Ari S. Morcos', 'Ting-Wu Chin'],\n",
       "  'published': '2020-07-23T02:05:03Z',\n",
       "  'updated': '2020-10-05T01:33:08Z',\n",
       "  'abstract': \"Slimmable neural networks provide a flexible trade-off front betweenprediction error and computational cost (such as the number of floating-pointoperations or FLOPs) with the same storage cost as a single model. They havebeen proposed recently for resource-constrained settings such as mobiledevices. However, current slimmable neural networks use a singlewidth-multiplier for all the layers to arrive at sub-networks with differentperformance profiles, which neglects that different layers affect the network'sprediction accuracy differently and have different FLOP requirements. Hence,developing a principled approach for deciding width-multipliers acrossdifferent layers could potentially improve the performance of slimmablenetworks. To allow for heterogeneous width-multipliers across different layers,we formulate the problem of optimizing slimmable networks from amulti-objective optimization lens, which leads to a novel algorithm foroptimizing both the shared weights and the width-multipliers for thesub-networks. We perform extensive empirical analysis with 14 network anddataset combinations and find that less over-parameterized networks benefitmore from a joint channel and weight optimization than extremelyover-parameterized networks. Quantitatively, improvements up to 1.7% and 1% intop-1 accuracy on the ImageNet dataset can be attained for MobileNetV2 andMobileNetV3, respectively. Our results highlight the potential of optimizingthe channel counts for different layers jointly with the weights for slimmablenetworks.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.11752v2'},\n",
       " 760: {'ID': 760,\n",
       "  'title': 'Context-Sensitive Generation Network for Handing Unknown Slot Values in  Dialogue State Tracking',\n",
       "  'authors': ['Xian-Ling Mao', 'Puhai Yang', 'Heyan Huang'],\n",
       "  'published': '2020-05-08T09:22:33Z',\n",
       "  'updated': '2020-10-16T09:31:38Z',\n",
       "  'abstract': 'As a key component in a dialogue system, dialogue state tracking plays animportant role. It is very important for dialogue state tracking to deal withthe problem of unknown slot values. As far as we known, almost all existingapproaches depend on pointer network to solve the unknown slot value problem.These pointer network-based methods usually have a hidden assumption that thereis at most one out-of-vocabulary word in an unknown slot value because of thecharacter of a pointer network. However, often, there are multipleout-of-vocabulary words in an unknown slot value, and it makes the existingmethods perform bad. To tackle the problem, in this paper, we propose a novelContext-Sensitive Generation network (CSG) which can facilitate therepresentation of out-of-vocabulary words when generating the unknown slotvalue. Extensive experiments show that our proposed method performs better thanthe state-of-the-art baselines.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.03923v3'},\n",
       " 761: {'ID': 761,\n",
       "  'title': 'FairyTED: A Fair Rating Predictor for TED Talk Data',\n",
       "  'authors': ['Ankani Chattoraj',\n",
       "   'Md. Iftekhar Tanveer',\n",
       "   'Shouman Das',\n",
       "   'Rupam Acharyya'],\n",
       "  'published': '2019-11-25T09:55:52Z',\n",
       "  'updated': '2019-11-25T09:55:52Z',\n",
       "  'abstract': 'With the recent trend of applying machine learning in every aspect of humanlife, it is important to incorporate fairness into the core of the predictivealgorithms. We address the problem of predicting the quality of public speecheswhile being fair with respect to sensitive attributes of the speakers, e.g.gender and race. We use the TED talks as an input repository of public speechesbecause it consists of speakers from a diverse community and has a wideoutreach. Utilizing the theories of Causal Models, Counterfactual Fairness andstate-of-the-art neural language models, we propose a mathematical frameworkfor fair prediction of the public speaking quality. We employ groundedassumptions to construct a causal model capturing how different attributesaffect public speaking quality. This causal model contributes in generatingcounterfactual data to train a fair predictive model. Our framework is generalenough to utilize any assumption within the causal model. Experimental resultsshow that while prediction accuracy is comparable to recent work on thisdataset, our predictions are counterfactually fair with respect to a novelmetric when compared to true data labels. The FairyTED setup not only allowsorganizers to make informed and diverse selection of speakers from theunobserved counterfactual possibilities but it also ensures that viewers andnew users are not influenced by unfair and unbalanced ratings from arbitraryvisitors to the www.ted.com website when deciding to view a talk.',\n",
       "  'categories': ['cs.LG', 'cs.CL', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.11558v1'},\n",
       " 762: {'ID': 762,\n",
       "  'title': 'Context-adaptive Entropy Model for End-to-end Optimized Image  Compression',\n",
       "  'authors': ['Seung-Kwon Beack', 'Seunghyun Cho', 'Jooyoung Lee'],\n",
       "  'published': '2018-09-27T10:59:47Z',\n",
       "  'updated': '2019-05-06T05:18:37Z',\n",
       "  'abstract': 'We propose a context-adaptive entropy model for use in end-to-end optimizedimage compression. Our model exploits two types of contexts, bit-consumingcontexts and bit-free contexts, distinguished based upon whether additional bitallocation is required. Based on these contexts, we allow the model to moreaccurately estimate the distribution of each latent representation with a moregeneralized form of the approximation models, which accordingly leads to anenhanced compression performance. Based on the experimental results, theproposed method outperforms the traditional image codecs, such as BPG andJPEG2000, as well as other previous artificial-neural-network (ANN) basedapproaches, in terms of the peak signal-to-noise ratio (PSNR) and multi-scalestructural similarity (MS-SSIM) index.',\n",
       "  'categories': ['eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.10452v4'},\n",
       " 763: {'ID': 763,\n",
       "  'title': 'Language Model-Driven Unsupervised Neural Machine Translation',\n",
       "  'authors': ['Zhen Huang',\n",
       "   'Youyuan Lin',\n",
       "   'Xiaodong Wang',\n",
       "   'Zhenshuang Liang',\n",
       "   'Wei Zhang',\n",
       "   'Ruoran Ren'],\n",
       "  'published': '2019-11-10T14:04:59Z',\n",
       "  'updated': '2019-11-10T14:04:59Z',\n",
       "  'abstract': 'Unsupervised neural machine translation(NMT) is associated with noise anderrors in synthetic data when executing vanilla back-translations. Here, weexplicitly exploits language model(LM) to drive construction of an unsupervisedNMT system. This features two steps. First, we initialize NMT models usingsynthetic data generated via temporary statistical machine translation(SMT).Second, unlike vanilla back-translation, we formulate a weight function, thatscores synthetic data at each step of subsequent iterative training; thisallows unsupervised training to an improved outcome. We present the detailedmathematical construction of our method. Experimental WMT2014 English-French,and WMT2016 English-German and English-Russian translation tasks revealed thatour method outperforms the best prior systems by more than 3 BLEU points.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.03937v1'},\n",
       " 764: {'ID': 764,\n",
       "  'title': 'Zero-shot Learning by Generating Task-specific Adapters',\n",
       "  'authors': ['Xiang Ren', 'Qinyuan Ye'],\n",
       "  'published': '2021-01-02T10:50:23Z',\n",
       "  'updated': '2021-01-02T10:50:23Z',\n",
       "  'abstract': 'Pre-trained text-to-text transformers achieve impressive performance across awide range of NLP tasks, and they naturally support zero-shot learning (ZSL) byusing the task description as prompt in the input. However, this approach haspotential limitations, as it learns from input-output pairs at instance level,instead of learning to solve tasks at task level. Alternatively, applyingexisting ZSL methods to text-to-text transformers is non-trivial due to theirtext generation objective and huge size. To address these issues, we introduceHypter, a framework that improves zero-shot transferability by training ahypernetwork to generate task-specific adapters from task descriptions. Thisformulation enables learning at task level, and greatly reduces the number ofparameters by using light-weight adapters. Experiments on two datasetsdemonstrate Hypter improves upon fine-tuning baselines.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.00420v1'},\n",
       " 765: {'ID': 765,\n",
       "  'title': 'Hypernetwork Science: From Multidimensional Networks to Computational  Topology',\n",
       "  'authors': ['Ignacio J. Tripodi',\n",
       "   'Emilie A. H. Purvine',\n",
       "   'Tiffany J. Callahan',\n",
       "   'Brenda Praggastis',\n",
       "   'Lawrence E. Hunter',\n",
       "   'Brett Jefferson',\n",
       "   'Sinan Aksoy',\n",
       "   'Cliff A. Joslyn'],\n",
       "  'published': '2020-03-26T07:52:04Z',\n",
       "  'updated': '2020-03-26T07:52:04Z',\n",
       "  'abstract': 'As data structures and mathematical objects used for complex systemsmodeling, hypergraphs sit nicely poised between on the one hand the world ofnetwork models, and on the other that of higher-order mathematical abstractionsfrom algebra, lattice theory, and topology. They are able to represent complexsystems interactions more faithfully than graphs and networks, while also beingsome of the simplest classes of systems representing topological structures ascollections of multidimensional objects connected in a particular pattern. Inthis paper we discuss the role of (undirected) hypergraphs in the science ofcomplex networks, and provide a mathematical overview of the core conceptsneeded for hypernetwork modeling, including duality and the relationship tobicolored graphs, quantitative adjacency and incidence, the nature of walks inhypergraphs, and available topological relationships and properties. We closewith a brief discussion of two example applications: biomedical databases fordisease analysis, and domain-name system (DNS) analysis of cyber data.',\n",
       "  'categories': ['cs.DM', '05C65,', 'G.2.2'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.11782v1'},\n",
       " 766: {'ID': 766,\n",
       "  'title': 'LUTNet: Learning FPGA Configurations for Highly Efficient Neural Network  Inference',\n",
       "  'authors': ['Erwei Wang',\n",
       "   'James J. Davis',\n",
       "   'George A. Constantinides',\n",
       "   'Peter Y. K. Cheung'],\n",
       "  'published': '2019-10-24T00:04:56Z',\n",
       "  'updated': '2020-03-02T23:26:43Z',\n",
       "  'abstract': \"Research has shown that deep neural networks contain significant redundancy,and thus that high classification accuracy can be achieved even when weightsand activations are quantized down to binary values. Network binarization onFPGAs greatly increases area efficiency by replacing resource-hungrymultipliers with lightweight XNOR gates. However, an FPGA's fundamentalbuilding block, the K-LUT, is capable of implementing far more than an XNOR: itcan perform any K-input Boolean operation. Inspired by this observation, wepropose LUTNet, an end-to-end hardware-software framework for the constructionof area-efficient FPGA-based neural network accelerators using the native LUTsas inference operators. We describe the realization of both unrolled and tiledLUTNet architectures, with the latter facilitating smaller, less power-hungrydeployment over the former while sacrificing area and energy efficiency alongwith throughput. For both varieties, we demonstrate that the exploitation ofLUT flexibility allows for far heavier pruning than possible in prior works,resulting in significant area savings while achieving comparable accuracy.Against the state-of-the-art binarized neural network implementation, weachieve up to twice the area efficiency for several standard network modelswhen inferencing popular datasets. We also demonstrate that even greater energyefficiency improvements are obtainable.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'eess.SP', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.12625v2'},\n",
       " 767: {'ID': 767,\n",
       "  'title': 'Counterfactual Fairness with Disentangled Causal Effect Variational  Autoencoder',\n",
       "  'authors': ['Il-Chul Moon',\n",
       "   'Wanmo Kang',\n",
       "   'Seungjae Shin',\n",
       "   'JoonHo Jang',\n",
       "   'Weonyoung Joo',\n",
       "   'Kyungwoo Song',\n",
       "   'Hyemi Kim'],\n",
       "  'published': '2020-11-24T03:43:59Z',\n",
       "  'updated': '2020-12-09T09:46:14Z',\n",
       "  'abstract': 'The problem of fair classification can be mollified if we develop a method toremove the embedded sensitive information from the classification features.This line of separating the sensitive information is developed through thecausal inference, and the causal inference enables the counterfactualgenerations to contrast the what-if case of the opposite sensitive attribute.Along with this separation with the causality, a frequent assumption in thedeep latent causal model defines a single latent variable to absorb the entireexogenous uncertainty of the causal graph. However, we claim that suchstructure cannot distinguish the 1) information caused by the intervention(i.e., sensitive variable) and 2) information correlated with the interventionfrom the data. Therefore, this paper proposes Disentangled Causal EffectVariational Autoencoder (DCEVAE) to resolve this limitation by disentanglingthe exogenous uncertainty into two latent variables: either 1) independent tointerventions or 2) correlated to interventions without causality.Particularly, our disentangling approach preserves the latent variablecorrelated to interventions in generating counterfactual examples. We show thatour method estimates the total effect and the counterfactual effect without acomplete causal graph. By adding a fairness regularization, DCEVAE generates acounterfactual fair dataset while losing less original information. Also,DCEVAE generates natural counterfactual images by only flipping sensitiveinformation. Additionally, we theoretically show the differences in thecovariance structures of DCEVAE and prior works from the perspective of thelatent disentanglement.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.11878v2'},\n",
       " 768: {'ID': 768,\n",
       "  'title': 'STDPG: A Spatio-Temporal Deterministic Policy Gradient Agent for Dynamic  Routing in SDN',\n",
       "  'authors': ['Zhiwen Xiao',\n",
       "   'Huanlai Xing',\n",
       "   'Juan Chen',\n",
       "   'Shouxi Luo',\n",
       "   'Muhammad Azhar Iqbal',\n",
       "   'Penglin Dai'],\n",
       "  'published': '2020-04-21T07:19:07Z',\n",
       "  'updated': '2020-04-21T07:19:07Z',\n",
       "  'abstract': 'Dynamic routing in software-defined networking (SDN) can be viewed as acentralized decision-making problem. Most of the existing deep reinforcementlearning (DRL) agents can address it, thanks to the deep neural network(DNN)incorporated. However, fully-connected feed-forward neural network (FFNN)is usually adopted, where spatial correlation and temporal variation of trafficflows are ignored. This drawback usually leads to significantly highcomputational complexity due to large number of training parameters. Toovercome this problem, we propose a novel model-free framework for dynamicrouting in SDN, which is referred to as spatio-temporal deterministic policygradient (STDPG) agent. Both the actor and critic networks are based onidentical DNN structure, where a combination of convolutional neural network(CNN) and long short-term memory network (LSTM) with temporal attentionmechanism, CNN-LSTM-TAM, is devised. By efficiently exploiting spatial andtemporal features, CNNLSTM-TAM helps the STDPG agent learn better from theexperience transitions. Furthermore, we employ the prioritized experiencereplay (PER) method to accelerate the convergence of model training. Theexperimental results show that STDPG can automatically adapt for currentnetwork environment and achieve robust convergence. Compared with a numberstate-ofthe-art DRL agents, STDPG achieves better routing solutions in terms ofthe average end-to-end delay.',\n",
       "  'categories': ['cs.NI', 'cs.LG', 'cs.SY', 'eess.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.09783v1'},\n",
       " 769: {'ID': 769,\n",
       "  'title': 'Robust Physical-World Attacks on Deep Learning Models',\n",
       "  'authors': ['Chaowei Xiao',\n",
       "   'Dawn Song',\n",
       "   'Earlence Fernandes',\n",
       "   'Ivan Evtimov',\n",
       "   'Bo Li',\n",
       "   'Amir Rahmati',\n",
       "   'Kevin Eykholt',\n",
       "   'Atul Prakash',\n",
       "   'Tadayoshi Kohno'],\n",
       "  'published': '2017-07-27T17:37:22Z',\n",
       "  'updated': '2018-04-10T16:22:47Z',\n",
       "  'abstract': 'Recent studies show that the state-of-the-art deep neural networks (DNNs) arevulnerable to adversarial examples, resulting from small-magnitudeperturbations added to the input. Given that that emerging physical systems areusing DNNs in safety-critical situations, adversarial examples could misleadthese systems and cause dangerous situations.Therefore, understandingadversarial examples in the physical world is an important step towardsdeveloping resilient learning algorithms. We propose a general attackalgorithm,Robust Physical Perturbations (RP2), to generate robust visualadversarial perturbations under different physical conditions. Using thereal-world case of road sign classification, we show that adversarial examplesgenerated using RP2 achieve high targeted misclassification rates againststandard-architecture road sign classifiers in the physical world under variousenvironmental conditions, including viewpoints. Due to the current lack of astandardized testing method, we propose a two-stage evaluation methodology forrobust physical adversarial examples consisting of lab and field tests. Usingthis methodology, we evaluate the efficacy of physical adversarialmanipulations on real objects. Witha perturbation in the form of only black andwhite stickers,we attack a real stop sign, causing targeted misclassificationin 100% of the images obtained in lab settings, and in 84.8%of the capturedvideo frames obtained on a moving vehicle(field test) for the targetclassifier.',\n",
       "  'categories': ['cs.CR', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.08945v5'},\n",
       " 770: {'ID': 770,\n",
       "  'title': 'A Training-based Identification Approach to VIN Adversarial Examples',\n",
       "  'authors': ['Tong Chen',\n",
       "   'Yingdi Wang',\n",
       "   'Yingxiao Xiang',\n",
       "   'Wenjia Niu',\n",
       "   'Jiqiang Liu',\n",
       "   'Jingjing Liu',\n",
       "   'Gang Li'],\n",
       "  'published': '2018-10-18T14:17:12Z',\n",
       "  'updated': '2018-10-18T14:17:12Z',\n",
       "  'abstract': 'With the rapid development of Artificial Intelligence (AI), the problem of AIsecurity has gradually emerged. Most existing machine learning algorithms maybe attacked by adversarial examples. An adversarial example is a slightlymodified input sample that can lead to a false result of machine learningalgorithms. The adversarial examples pose a potential security threat for manyAI application areas, especially in the domain of robot path planning. In thisfield, the adversarial examples obstruct the algorithm by adding obstacles tothe normal maps, resulting in multiple effects on the predicted path. However,there is no suitable approach to automatically identify them. To our knowledge,all previous work uses manual observation method to estimate the attack resultsof adversarial maps, which is time-consuming. Aiming at the existing problem,this paper explores a method to automatically identify the adversarial examplesin Value Iteration Networks (VIN), which has a strong generalization ability.We analyze the possible scenarios caused by the adversarial maps. We propose atraining-based identification approach to VIN adversarial examples by combingthe path feature comparison and path image classification. We evaluate ourmethod using the adversarial maps dataset, show that our method can achieve ahigh-accuracy and faster identification than manual observation method.',\n",
       "  'categories': ['cs.CR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.08070v1'},\n",
       " 771: {'ID': 771,\n",
       "  'title': 'On Deep Set Learning and the Choice of Aggregations',\n",
       "  'authors': ['Patrick van der Smagt',\n",
       "   'Adnan Akhundov',\n",
       "   'Maximilian Soelch',\n",
       "   'Justin Bayer'],\n",
       "  'published': '2019-03-18T10:24:10Z',\n",
       "  'updated': '2020-04-08T14:56:07Z',\n",
       "  'abstract': 'Recently, it has been shown that many functions on sets can be represented bysum decompositions. These decompositons easily lend themselves to neuralapproximations, extending the applicability of neural nets to set-valuedinputs---Deep Set learning. This work investigates a core component of Deep Setarchitecture: aggregation functions. We suggest and examine alternatives tocommonly used aggregation functions, including learnable recurrent aggregationfunctions. Empirically, we show that the Deep Set networks are highly sensitiveto the choice of aggregation functions: beyond improved performance, we findthat learnable aggregations lower hyper-parameter sensitivity and generalizebetter to out-of-distribution input size.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.07348v2'},\n",
       " 772: {'ID': 772,\n",
       "  'title': 'Multi-task Learning with Gradient Guided Policy Specialization',\n",
       "  'authors': ['Greg Turk', 'Wenhao Yu', 'C. Karen Liu'],\n",
       "  'published': '2017-09-23T00:54:18Z',\n",
       "  'updated': '2018-03-02T22:23:00Z',\n",
       "  'abstract': 'We present a method for efficient learning of control policies for multiplerelated robotic motor skills. Our approach consists of two stages, jointtraining and specialization training. During the joint training stage, a neuralnetwork policy is trained with minimal information to disambiguate the motorskills. This forces the policy to learn a common representation of thedifferent tasks. Then, during the specialization training stage we selectivelysplit the weights of the policy based on a per-weight metric that measures thedisagreement among the multiple tasks. By splitting part of the control policy,it can be further trained to specialize to each task. To update the controlpolicy during learning, we use Trust Region Policy Optimization withGeneralized Advantage Function (TRPOGAE). We propose a modification to thegradient update stage of TRPO to better accommodate multi-task learningscenarios. We evaluate our approach on three continuous motor skill learningproblems in simulation: 1) a locomotion task where three single legged robotswith considerable difference in shape and size are trained to hop forward, 2) amanipulation task where three robot manipulators with different sizes and jointtypes are trained to reach different locations in 3D space, and 3) locomotionof a two-legged robot, whose range of motion of one leg is constrained indifferent ways. We compare our training method to three baselines. The firstbaseline uses only joint training for the policy, the second trains independentpolicies for each task, and the last randomly selects weights to split. We showthat our approach learns more efficiently than each of the baseline methods.',\n",
       "  'categories': ['cs.RO', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.07979v3'},\n",
       " 773: {'ID': 773,\n",
       "  'title': 'Do we need to go Deep? Knowledge Tracing with Big Data',\n",
       "  'authors': ['Jiaqi Gong', 'Varun Mandalapu', 'Lujie Chen'],\n",
       "  'published': '2021-01-20T22:40:38Z',\n",
       "  'updated': '2021-01-20T22:40:38Z',\n",
       "  'abstract': 'Interactive Educational Systems (IES) enabled researchers to trace studentknowledge in different skills and provide recommendations for a better learningpath. To estimate the student knowledge and further predict their futureperformance, the interest in utilizing the student interaction data captured byIES to develop learner performance models is increasing rapidly. Moreover, withthe advances in computing systems, the amount of data captured by these IESsystems is also increasing that enables deep learning models to compete withtraditional logistic models and Markov processes. However, it is still notempirically evident if these deep models outperform traditional models on thecurrent scale of datasets with millions of student interactions. In this work,we adopt EdNet, the largest student interaction dataset publicly available inthe education domain, to understand how accurately both deep and traditionalmodels predict future student performances. Our work observes that logisticregression models with carefully engineered features outperformed deep modelsfrom extensive experimentation. We follow this analysis with interpretationstudies based on Locally Interpretable Model-agnostic Explanation (LIME) tounderstand the impact of various features on best performing modelpre-dictions.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.08349v1'},\n",
       " 774: {'ID': 774,\n",
       "  'title': 'Liquid Time-constant Networks',\n",
       "  'authors': ['Mathias Lechner',\n",
       "   'Alexander Amini',\n",
       "   'Ramin Hasani',\n",
       "   'Daniela Rus',\n",
       "   'Radu Grosu'],\n",
       "  'published': '2020-06-08T09:53:35Z',\n",
       "  'updated': '2020-12-14T22:23:52Z',\n",
       "  'abstract': \"We introduce a new class of time-continuous recurrent neural network models.Instead of declaring a learning system's dynamics by implicit nonlinearities,we construct networks of linear first-order dynamical systems modulated vianonlinear interlinked gates. The resulting models represent dynamical systemswith varying (i.e., liquid) time-constants coupled to their hidden state, withoutputs being computed by numerical differential equation solvers. These neuralnetworks exhibit stable and bounded behavior, yield superior expressivitywithin the family of neural ordinary differential equations, and give rise toimproved performance on time-series prediction tasks. To demonstrate theseproperties, we first take a theoretical approach to find bounds over theirdynamics and compute their expressive power by the trajectory length measure inlatent trajectory space. We then conduct a series of time-series predictionexperiments to manifest the approximation capability of Liquid Time-ConstantNetworks (LTCs) compared to classical and modern RNNs. Code and data areavailable at https://github.com/raminmh/liquid_time_constant_networks\",\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.04439v4'},\n",
       " 775: {'ID': 775,\n",
       "  'title': 'Online Conversation Disentanglement with Pointer Networks',\n",
       "  'authors': ['Tao Yu', 'Shafiq Joty'],\n",
       "  'published': '2020-10-21T15:43:07Z',\n",
       "  'updated': '2020-10-21T15:43:07Z',\n",
       "  'abstract': 'Huge amounts of textual conversations occur online every day, where multipleconversations take place concurrently. Interleaved conversations lead todifficulties in not only following the ongoing discussions but also extractingrelevant information from simultaneous messages. Conversation disentanglementaims to separate intermingled messages into detached conversations. However,existing disentanglement methods rely mostly on handcrafted features that aredataset specific, which hinders generalization and adaptability. In this work,we propose an end-to-end online framework for conversation disentanglement thatavoids time-consuming domain-specific feature engineering. We design a novelway to embed the whole utterance that comprises timestamp, speaker, and messagetext, and proposes a custom attention mechanism that models disentanglement asa pointing problem while effectively capturing inter-utterance interactions inan end-to-end fashion. We also introduce a joint-learning objective to bettercapture contextual information. Our experiments on the Ubuntu IRC dataset showthat our method achieves state-of-the-art performance in both link andconversation prediction tasks.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.11080v1'},\n",
       " 776: {'ID': 776,\n",
       "  'title': 'Policy Distillation and Value Matching in Multiagent Reinforcement  Learning',\n",
       "  'authors': ['Dong-Ki Kim',\n",
       "   'Jonathan P. How',\n",
       "   'Samir Wadhwania',\n",
       "   'Shayegan Omidshafiei'],\n",
       "  'published': '2019-03-15T15:13:02Z',\n",
       "  'updated': '2019-03-15T15:13:02Z',\n",
       "  'abstract': 'Multiagent reinforcement learning algorithms (MARL) have been demonstrated oncomplex tasks that require the coordination of a team of multiple agents tocomplete. Existing works have focused on sharing information between agents viacentralized critics to stabilize learning or through communication to increaseperformance, but do not generally look at how information can be shared betweenagents to address the curse of dimensionality in MARL. We posit that amultiagent problem can be decomposed into a multi-task problem where each agentexplores a subset of the state space instead of exploring the entire statespace. This paper introduces a multiagent actor-critic algorithm and method forcombining knowledge from homogeneous agents through distillation andvalue-matching that outperforms policy distillation alone and allows furtherlearning in both discrete and continuous action spaces.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.06592v1'},\n",
       " 777: {'ID': 777,\n",
       "  'title': 'Graph Prototypical Networks for Few-shot Learning on Attributed Networks',\n",
       "  'authors': ['Jundong Li',\n",
       "   'Jianling Wang',\n",
       "   'Huan Liu',\n",
       "   'Kai Shu',\n",
       "   'Kaize Ding',\n",
       "   'Chenghao Liu'],\n",
       "  'published': '2020-06-23T04:13:23Z',\n",
       "  'updated': '2020-11-27T05:15:11Z',\n",
       "  'abstract': 'Attributed networks nowadays are ubiquitous in a myriad of high-impactapplications, such as social network analysis, financial fraud detection, anddrug discovery. As a central analytical task on attributed networks, nodeclassification has received much attention in the research community. Inreal-world attributed networks, a large portion of node classes only containlimited labeled instances, rendering a long-tail node class distribution.Existing node classification algorithms are unequipped to handle the\\\\textit{few-shot} node classes. As a remedy, few-shot learning has attracted asurge of attention in the research community. Yet, few-shot node classificationremains a challenging problem as we need to address the following questions:(i) How to extract meta-knowledge from an attributed network for few-shot nodeclassification? (ii) How to identify the informativeness of each labeledinstance for building a robust and effective model? To answer these questions,in this paper, we propose a graph meta-learning framework -- Graph PrototypicalNetworks (GPN). By constructing a pool of semi-supervised node classificationtasks to mimic the real test environment, GPN is able to perform\\\\textit{meta-learning} on an attributed network and derive a highlygeneralizable model for handling the target classification task. Extensiveexperiments demonstrate the superior capability of GPN in few-shot nodeclassification.',\n",
       "  'categories': ['cs.LG', 'cs.SI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.12739v3'},\n",
       " 778: {'ID': 778,\n",
       "  'title': 'CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement  Learning',\n",
       "  'authors': ['Pierre Fournier',\n",
       "   'Pierre-Yves Oudeyer',\n",
       "   'Mohamed Chetouani',\n",
       "   'Olivier Sigaud',\n",
       "   'Cédric Colas'],\n",
       "  'published': '2018-10-15T11:40:28Z',\n",
       "  'updated': '2019-05-29T11:52:20Z',\n",
       "  'abstract': 'In open-ended environments, autonomous learning agents must set their owngoals and build their own curriculum through an intrinsically motivatedexploration. They may consider a large diversity of goals, aiming to discoverwhat is controllable in their environments, and what is not. Because some goalsmight prove easy and some impossible, agents must actively select which goal topractice at any moment, to maximize their overall mastery on the set oflearnable goals. This paper proposes CURIOUS, an algorithm that leverages 1) amodular Universal Value Function Approximator with hindsight learning toachieve a diversity of goals of different kinds within a unique policy and 2)an automated curriculum learning mechanism that biases the attention of theagent towards goals maximizing the absolute learning progress. Agents focussequentially on goals of increasing complexity, and focus back on goals thatare being forgotten. Experiments conducted in a new modular-goal roboticenvironment show the resulting developmental self-organization of a learningcurriculum, and demonstrate properties of robustness to distracting goals,forgetting and changes in body properties.',\n",
       "  'categories': ['cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.06284v4'},\n",
       " 779: {'ID': 779,\n",
       "  'title': 'Deep Reinforcement Learning for Electric Vehicle Routing Problem with  Time Windows',\n",
       "  'authors': ['Bo Lin', 'Bissan Ghaddar', 'Jatin Nathwani'],\n",
       "  'published': '2020-10-05T15:06:02Z',\n",
       "  'updated': '2020-11-14T01:14:31Z',\n",
       "  'abstract': 'The past decade has seen a rapid penetration of electric vehicles (EV) in themarket, more and more logistics and transportation companies start to deployEVs for service provision. In order to model the operations of a commercial EVfleet, we utilize the EV routing problem with time windows (EVRPTW). In thisresearch, we propose an end-to-end deep reinforcement learning framework tosolve the EVRPTW. In particular, we develop an attention model incorporatingthe pointer network and a graph embedding technique to parameterize astochastic policy for solving the EVRPTW. The model is then trained usingpolicy gradient with rollout baseline. Our numerical studies show that theproposed model is able to efficiently solve EVRPTW instances of large sizesthat are not solvable with any existing approaches.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.02068v2'},\n",
       " 780: {'ID': 780,\n",
       "  'title': 'Emergence of Scenario-Appropriate Collaborative Behaviors for Teams of  Robotic Bodyguards',\n",
       "  'authors': ['Hassam Ullah Sheikh', 'Ladislau Boloni'],\n",
       "  'published': '2018-09-12T14:55:19Z',\n",
       "  'updated': '2020-03-25T19:30:21Z',\n",
       "  'abstract': 'We are considering the problem of controlling a team of robotic bodyguardsprotecting a VIP from physical assault in the presence of neutral and/oradversarial bystanders. This task is part of a much larger class of problemsinvolving coordinated robot behavior in the presence of humans. This problem ischallenging due to the large number of active entities with different agendas,the need of cooperation between the robots as well as the requirement to takeinto consideration criteria such as social norms and unobtrusiveness inaddition to the main goal of VIP safety. Furthermore, different settings suchas street, public space or red carpet require very different behavior from therobot. We describe how a multi-agent reinforcement learning approach can evolvebehavior policies for teams of robot bodyguards that compare well withhand-engineered approaches. Furthermore, we show that an algorithm inspired byuniversal value function approximators can learn policies that exhibitappropriate, distinct behavior in environments with different requirements.',\n",
       "  'categories': ['cs.MA'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.04500v3'},\n",
       " 781: {'ID': 781,\n",
       "  'title': 'When are Neural ODE Solutions Proper ODEs?',\n",
       "  'authors': ['Prateek Katiyar',\n",
       "   'Michael Tiemann',\n",
       "   'Katharina Ott',\n",
       "   'Philipp Hennig'],\n",
       "  'published': '2020-07-30T11:24:05Z',\n",
       "  'updated': '2020-07-30T11:24:05Z',\n",
       "  'abstract': 'A key appeal of the recently proposed Neural Ordinary DifferentialEquation(ODE) framework is that it seems to provide a continuous-time extensionof discrete residual neural networks. As we show herein, though, trained NeuralODE models actually depend on the specific numerical method used duringtraining. If the trained model is supposed to be a flow generated from an ODE,it should be possible to choose another numerical solver with equal or smallernumerical error without loss of performance. We observe that if training relieson a solver with overly coarse discretization, then testing with another solverof equal or smaller numerical error results in a sharp drop in accuracy. Insuch cases, the combination of vector field and numerical method cannot beinterpreted as a flow generated from an ODE, which arguably poses a fatalbreakdown of the Neural ODE concept. We observe, however, that there exists acritical step size beyond which the training yields a valid ODE vector field.We propose a method that monitors the behavior of the ODE solver duringtraining to adapt its step size, aiming to ensure a valid ODE withoutunnecessarily increasing computational cost. We verify this adaption algorithmon two common bench mark datasets as well as a synthetic dataset. Furthermore,we introduce a novel synthetic dataset in which the underlying ODE directlygenerates a classification task.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.15386v1'},\n",
       " 782: {'ID': 782,\n",
       "  'title': 'Less Memory, Faster Speed: Refining Self-Attention Module for Image  Reconstruction',\n",
       "  'authors': ['Tieling Li', 'Jianwu Li', 'Ge Song', 'Zheng Wang'],\n",
       "  'published': '2019-05-20T11:43:37Z',\n",
       "  'updated': '2019-05-20T11:43:37Z',\n",
       "  'abstract': 'Self-attention (SA) mechanisms can capture effectively global dependencies indeep neural networks, and have been applied to natural language processing andimage processing successfully. However, SA modules for image reconstructionhave high time and space complexity, which restrict their applications tohigher-resolution images. In this paper, we refine the SA module inself-attention generative adversarial networks (SAGAN) via adapting a non-localoperation, revising the connectivity among the units in SA module andre-implementing its computational pattern, such that its time and spacecomplexity is reduced from $\\\\text{O}(n^2)$ to $\\\\text{O}(n)$, but it is stillequivalent to the original SA module. Further, we explore the principles behindthe module and discover that our module is a special kind of channel attentionmechanisms. Experimental results based on two benchmark datasets of imagereconstruction, verify that under the same computational environment, twomodels can achieve comparable effectiveness for image reconstruction, but theproposed one runs faster and takes up less memory space.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.08008v1'},\n",
       " 783: {'ID': 783,\n",
       "  'title': 'Curiosity-Driven Experience Prioritization via Density Estimation',\n",
       "  'authors': ['Rui Zhao', 'Volker Tresp'],\n",
       "  'published': '2019-02-20T12:31:23Z',\n",
       "  'updated': '2020-05-24T08:15:29Z',\n",
       "  'abstract': 'In Reinforcement Learning (RL), an agent explores the environment andcollects trajectories into the memory buffer for later learning. However, thecollected trajectories can easily be imbalanced with respect to the achievedgoal states. The problem of learning from imbalanced data is a well-knownproblem in supervised learning, but has not yet been thoroughly researched inRL. To address this problem, we propose a novel Curiosity-Driven Prioritization(CDP) framework to encourage the agent to over-sample those trajectories thathave rare achieved goal states. The CDP framework mimics the human learningprocess and focuses more on relatively uncommon events. We evaluate our methodsusing the robotic environment provided by OpenAI Gym. The environment containssix robot manipulation tasks. In our experiments, we combined CDP with DeepDeterministic Policy Gradient (DDPG) with or without Hindsight ExperienceReplay (HER). The experimental results show that CDP improves both performanceand sample-efficiency of reinforcement learning agents, compared tostate-of-the-art methods.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.08039v3'},\n",
       " 784: {'ID': 784,\n",
       "  'title': 'Deep Image Spatial Transformation for Person Image Generation',\n",
       "  'authors': ['Ge Li',\n",
       "   'Thomas H. Li',\n",
       "   'Xiaoming Yu',\n",
       "   'Junming Chen',\n",
       "   'Yurui Ren'],\n",
       "  'published': '2020-03-02T07:31:00Z',\n",
       "  'updated': '2020-03-18T09:42:02Z',\n",
       "  'abstract': 'Pose-guided person image generation is to transform a source person image toa target pose. This task requires spatial manipulations of source data.However, Convolutional Neural Networks are limited by the lack of ability tospatially transform the inputs. In this paper, we propose a differentiableglobal-flow local-attention framework to reassemble the inputs at the featurelevel. Specifically, our model first calculates the global correlations betweensources and targets to predict flow fields. Then, the flowed local patch pairsare extracted from the feature maps to calculate the local attentioncoefficients. Finally, we warp the source features using a content-awaresampling method with the obtained local attention coefficients. The results ofboth subjective and objective experiments demonstrate the superiority of ourmodel. Besides, additional results in video animation and view synthesis showthat our model is applicable to other tasks requiring spatial transformation.Our source code is available athttps://github.com/RenYurui/Global-Flow-Local-Attention.',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.00696v2'},\n",
       " 785: {'ID': 785,\n",
       "  'title': 'DivGraphPointer: A Graph Pointer Network for Extracting Diverse  Keyphrases',\n",
       "  'authors': ['Zhi-Hong Deng',\n",
       "   'Zhiqing Sun',\n",
       "   'Jian-Yun Nie',\n",
       "   'Pan Du',\n",
       "   'Jian Tang'],\n",
       "  'published': '2019-05-19T05:17:12Z',\n",
       "  'updated': '2019-05-19T05:17:12Z',\n",
       "  'abstract': 'Keyphrase extraction from documents is useful to a variety of applicationssuch as information retrieval and document summarization. This paper presentsan end-to-end method called DivGraphPointer for extracting a set of diversifiedkeyphrases from a document. DivGraphPointer combines the advantages oftraditional graph-based ranking methods and recent neural network-basedapproaches. Specifically, given a document, a word graph is constructed fromthe document based on word proximity and is encoded with graph convolutionalnetworks, which effectively capture document-level word salience by modelinglong-range dependency between words in the document and aggregating multipleappearances of identical words into one node. Furthermore, we propose adiversified point network to generate a set of diverse keyphrases out of theword graph in the decoding process. Experimental results on five benchmark datasets show that our proposed method significantly outperforms the existingstate-of-the-art approaches.',\n",
       "  'categories': ['cs.CL', 'cs.IR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.07689v1'},\n",
       " 786: {'ID': 786,\n",
       "  'title': 'Cross-Camera Convolutional Color Constancy',\n",
       "  'authors': ['Yun-Ta Tsai',\n",
       "   'Mahmoud Afifi',\n",
       "   'Jonathan T. Barron',\n",
       "   'Chloe LeGendre',\n",
       "   'Francois Bleibel'],\n",
       "  'published': '2020-11-24T04:37:22Z',\n",
       "  'updated': '2020-11-24T04:37:22Z',\n",
       "  'abstract': 'We present \"Cross-Camera Convolutional Color Constancy\" (C5), alearning-based method, trained on images from multiple cameras, that accuratelyestimates a scene\\'s illuminant color from raw images captured by a new camerapreviously unseen during training. C5 is a hypernetwork-like extension of theconvolutional color constancy (CCC) approach: C5 learns to generate the weightsof a CCC model that is then evaluated on the input image, with the CCC weightsdynamically adapted to different input content. Unlike prior cross-camera colorconstancy models, which are usually designed to be agnostic to the spectralproperties of test-set images from unobserved cameras, C5 approaches thisproblem through the lens of transductive inference: additional unlabeled imagesare provided as input to the model at test time, which allows the model tocalibrate itself to the spectral properties of the test-set camera duringinference. C5 achieves state-of-the-art accuracy for cross-camera colorconstancy on several datasets, is fast to evaluate (~7 and ~90 ms per image ona GPU or CPU, respectively), and requires little memory (~2 MB), and, thus, isa practical solution to the problem of calibration-free automatic white balancefor mobile photography.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.11890v1'},\n",
       " 787: {'ID': 787,\n",
       "  'title': 'EEG-GAN: Generative adversarial networks for electroencephalograhic  (EEG) brain signals',\n",
       "  'authors': ['Kay Gregor Hartmann',\n",
       "   'Robin Tibor Schirrmeister',\n",
       "   'Tonio Ball'],\n",
       "  'published': '2018-06-05T18:10:11Z',\n",
       "  'updated': '2018-06-05T18:10:11Z',\n",
       "  'abstract': 'Generative adversarial networks (GANs) are recently highly successful ingenerative applications involving images and start being applied to time seriesdata. Here we describe EEG-GAN as a framework to generateelectroencephalographic (EEG) brain signals. We introduce a modification to theimproved training of Wasserstein GANs to stabilize training and investigate arange of architectural choices critical for time series generation (mostnotably up- and down-sampling). For evaluation we consider and comparedifferent metrics such as Inception score, Frechet inception distance andsliced Wasserstein distance, together showing that our EEG-GAN frameworkgenerated naturalistic EEG examples. It thus opens up a range of new generativeapplication scenarios in the neuroscientific and neurological context, such asdata augmentation in brain-computer interfacing tasks, EEG super-sampling, orrestoration of corrupted data segments. The possibility to generate signals ofa certain class and/or with specific properties may also open a new avenue forresearch into the underlying structure of brain signals.',\n",
       "  'categories': ['eess.SP', 'cs.LG', 'q-bio.NC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.01875v1'},\n",
       " 788: {'ID': 788,\n",
       "  'title': 'Self-Teaching Machines to Read and Comprehend with Large-Scale  Multi-Subject Question Answering Data',\n",
       "  'authors': ['Kai Sun', 'Dian Yu', 'Dong Yu', 'Claire Cardie'],\n",
       "  'published': '2021-02-01T23:18:58Z',\n",
       "  'updated': '2021-02-01T23:18:58Z',\n",
       "  'abstract': 'In spite of much recent research in the area, it is still unclear whethersubject-area question-answering data is useful for machine readingcomprehension (MRC) tasks. In this paper, we investigate this question. Wecollect a large-scale multi-subject multiple-choice question-answering dataset,ExamQA, and use incomplete and noisy snippets returned by a web search engineas the relevant context for each question-answering instance to convert it intoa weakly-labeled MRC instance. We then propose a self-teaching paradigm tobetter use the generated weakly-labeled MRC instances to improve a target MRCtask. Experimental results show that we can obtain an improvement of 5.1% inaccuracy on a multiple-choice MRC dataset, C^3, demonstrating the effectivenessof our framework and the usefulness of large-scale subject-areaquestion-answering data for machine reading comprehension.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.01226v1'},\n",
       " 789: {'ID': 789,\n",
       "  'title': 'Adaptive Trust Region Policy Optimization: Global Convergence and Faster  Rates for Regularized MDPs',\n",
       "  'authors': ['Lior Shani', 'Shie Mannor', 'Yonathan Efroni'],\n",
       "  'published': '2019-09-06T08:43:38Z',\n",
       "  'updated': '2019-12-12T17:07:53Z',\n",
       "  'abstract': 'Trust region policy optimization (TRPO) is a popular and empiricallysuccessful policy search algorithm in Reinforcement Learning (RL) in which asurrogate problem, that restricts consecutive policies to be \\'close\\' to oneanother, is iteratively solved. Nevertheless, TRPO has been considered aheuristic algorithm inspired by Conservative Policy Iteration (CPI). We showthat the adaptive scaling mechanism used in TRPO is in fact the natural \"RLversion\" of traditional trust-region methods from convex analysis. We firstanalyze TRPO in the planning setting, in which we have access to the model andthe entire state space. Then, we consider sample-based TRPO and establish$\\\\tilde O(1/\\\\sqrt{N})$ convergence rate to the global optimum. Importantly, theadaptive scaling mechanism allows us to analyze TRPO in regularized MDPs forwhich we prove fast rates of $\\\\tilde O(1/N)$, much like results in convexoptimization. This is the first result in RL of better rates when regularizingthe instantaneous cost or reward.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.02769v2'},\n",
       " 790: {'ID': 790,\n",
       "  'title': 'Probabilistic Spatial Transformers for Bayesian Data Augmentation',\n",
       "  'authors': ['Frederik Warburg',\n",
       "   'Pola Schwöbel',\n",
       "   'Kristoffer H. Madsen',\n",
       "   'Søren Hauberg',\n",
       "   'Martin Jørgensen'],\n",
       "  'published': '2020-04-07T18:22:02Z',\n",
       "  'updated': '2020-04-07T18:22:02Z',\n",
       "  'abstract': 'High-capacity models require vast amounts of data, and data augmentation is acommon remedy when this resource is limited. Standard augmentation techniquesapply small hand-tuned transformations to existing data, which is a brittleprocess that realistically only allows for simple transformations. We propose aBayesian interpretation of data augmentation where the transformations aremodelled as latent variables to be marginalized, and show how these can beinferred variationally in an end-to-end fashion. This allows for significantlymore complex transformations than manual tuning, and the marginalizationimplies a form of test-time data augmentation. The resulting model can beinterpreted as a probabilistic extension of spatial transformer networks.Experimentally, we demonstrate improvements in accuracy and uncertaintyquantification in image and time series classification tasks.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.03637v1'},\n",
       " 791: {'ID': 791,\n",
       "  'title': 'Ensemble of Models Trained by Key-based Transformed Images for  Adversarially Robust Defense Against Black-box Attacks',\n",
       "  'authors': ['MaungMaung AprilPyone', 'Hitoshi Kiya'],\n",
       "  'published': '2020-11-16T02:48:37Z',\n",
       "  'updated': '2020-11-16T02:48:37Z',\n",
       "  'abstract': 'We propose a voting ensemble of models trained by using block-wisetransformed images with secret keys for an adversarially robust defense.Key-based adversarial defenses were demonstrated to outperform state-of-the-artdefenses against gradient-based (white-box) attacks. However, the key-baseddefenses are not effective enough against gradient-free (black-box) attackswithout requiring any secret keys. Accordingly, we aim to enhance robustnessagainst black-box attacks by using a voting ensemble of models. In the proposedensemble, a number of models are trained by using images transformed withdifferent keys and block sizes, and then a voting ensemble is applied to themodels. In image classification experiments, the proposed defense isdemonstrated to defend state-of-the-art attacks. The proposed defense achievesa clean accuracy of 95.56 % and an attack success rate of less than 9 % underattacks with a noise distance of 8/255 on the CIFAR-10 dataset.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.07697v1'},\n",
       " 792: {'ID': 792,\n",
       "  'title': 'Hindsight Trust Region Policy Optimization',\n",
       "  'authors': ['Hanbo Zhang',\n",
       "   'Nanning Zheng',\n",
       "   'Site Bai',\n",
       "   'Xuguang Lan',\n",
       "   'David Hsu'],\n",
       "  'published': '2019-07-29T13:59:42Z',\n",
       "  'updated': '2020-02-11T02:00:15Z',\n",
       "  'abstract': \"Reinforcement Learning(RL) with sparse rewards is a major challenge. Wepropose \\\\emph{Hindsight Trust Region Policy Optimization}(HTRPO), a new RLalgorithm that extends the highly successful TRPO algorithm with\\\\emph{hindsight} to tackle the challenge of sparse rewards. Hindsight refers tothe algorithm's ability to learn from information across goals, including onesnot intended for the current task. HTRPO leverages two main ideas. Itintroduces QKL, a quadratic approximation to the KL divergence constraint onthe trust region, leading to reduced variance in KL divergence estimation andimproved stability in policy update. It also presents Hindsight GoalFiltering(HGF) to select conductive hindsight goals. In experiments, weevaluate HTRPO in various sparse reward tasks, including simple benchmarks,image-based Atari games, and simulated robot control. Ablation studies indicatethat QKL and HGF contribute greatly to learning stability and high performance.Comparison results show that in all tasks, HTRPO consistently outperforms bothTRPO and HPG, a state-of-the-art algorithm for RL with sparse rewards.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1907.12439v3'},\n",
       " 793: {'ID': 793,\n",
       "  'title': 'Stochastic Variance Reduction for Policy Gradient Estimation',\n",
       "  'authors': ['Tianbing Xu', 'Jian Peng', 'Qiang Liu'],\n",
       "  'published': '2017-10-17T00:05:06Z',\n",
       "  'updated': '2018-03-29T17:51:14Z',\n",
       "  'abstract': 'Recent advances in policy gradient methods and deep learning havedemonstrated their applicability for complex reinforcement learning problems.However, the variance of the performance gradient estimates obtained from thesimulation is often excessive, leading to poor sample efficiency. In thispaper, we apply the stochastic variance reduced gradient descent (SVRG) tomodel-free policy gradient to significantly improve the sample-efficiency. TheSVRG estimation is incorporated into a trust-region Newton conjugate gradientframework for the policy optimization. On several Mujoco tasks, our methodachieves significantly better performance compared to the state-of-the-artmodel-free policy gradient methods in robotic continuous control such as trustregion policy optimization (TRPO)',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.06034v4'},\n",
       " 794: {'ID': 794,\n",
       "  'title': 'Adaptive Precision CNN Accelerator Using Radix-X Parallel Connected  Memristor Crossbars',\n",
       "  'authors': ['Kyoungrok Cho',\n",
       "   'Kamran Eshraghian',\n",
       "   'Jaeheum Lee',\n",
       "   'Jason K. Eshraghian'],\n",
       "  'published': '2019-06-22T06:14:24Z',\n",
       "  'updated': '2019-06-22T06:14:24Z',\n",
       "  'abstract': 'Neural processor development is reducing our reliance on remote server accessto process deep learning operations in an increasingly edge-driven world. Byemploying in-memory processing, parallelization techniques, andalgorithm-hardware co-design, memristor crossbar arrays are known toefficiently compute large scale matrix-vector multiplications. However,state-of-the-art implementations of negative weights require duplicative columnwires, and high precision weights using single-bit memristors furtherdistributes computations. These constraints dramatically increase chip area andresistive losses, which lead to increased power consumption and reducedaccuracy. In this paper, we develop an adaptive precision method by varying thenumber of memristors at each crosspoint. We also present a weight mappingalgorithm designed for implementation on our crossbar array. This novelalgorithm-hardware solution is described as the radix-X Convolutional NeuralNetwork Crossbar Array, and demonstrate how to efficiently represent negativeweights using a single column line, rather than double the number of additionalcolumns. Using both simulation and experimental results, we verify that ourradix-5 CNN array achieves a validation accuracy of 90.5% on the CIFAR-10dataset, a 4.5% improvement over binarized neural networks whilstsimultaneously reducing crossbar area by 46% over conventional arrays byremoving the need for duplicate columns to represent signed weights.',\n",
       "  'categories': ['eess.SP', 'cs.AR', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.09395v1'},\n",
       " 795: {'ID': 795,\n",
       "  'title': 'Disentangling images with Lie group transformations and sparse coding',\n",
       "  'authors': ['Bruno Olshausen', 'Yubei Chen', 'Frank Qiu', 'Ho Yin Chau'],\n",
       "  'published': '2020-12-11T19:11:32Z',\n",
       "  'updated': '2020-12-11T19:11:32Z',\n",
       "  'abstract': 'Discrete spatial patterns and their continuous transformations are twoimportant regularities contained in natural signals. Lie groups andrepresentation theory are mathematical tools that have been used in previousworks to model continuous image transformations. On the other hand, sparsecoding is an important tool for learning dictionaries of patterns in naturalsignals. In this paper, we combine these ideas in a Bayesian generative modelthat learns to disentangle spatial patterns and their continuoustransformations in a completely unsupervised manner. Images are modeled as asparse superposition of shape components followed by a transformation that isparameterized by n continuous variables. The shape components andtransformations are not predefined, but are instead adapted to learn thesymmetries in the data, with the constraint that the transformations form arepresentation of an n-dimensional torus. Training the model on a datasetconsisting of controlled geometric transformations of specific MNIST digitsshows that it can recover these transformations along with the digits. Trainingon the full MNIST dataset shows that it can learn both the basic digit shapesand the natural transformations such as shearing and stretching that arecontained in this data.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.12071v1'},\n",
       " 796: {'ID': 796,\n",
       "  'title': 'Disentangling Options with Hellinger Distance Regularizer',\n",
       "  'authors': ['Junyoung Choi', 'Minsung Hyun', 'Nojun Kwak'],\n",
       "  'published': '2019-04-15T07:43:17Z',\n",
       "  'updated': '2019-04-15T07:43:17Z',\n",
       "  'abstract': 'In reinforcement learning (RL), temporal abstraction still remains as animportant and unsolved problem. The options framework provided clues totemporal abstraction in the RL, and the option-critic architecture elegantlysolved the two problems of finding options and learning RL agents in anend-to-end manner. However, it is necessary to examine whether the optionslearned through this method play a mutually exclusive role. In this paper, wepropose a Hellinger distance regularizer, a method for disentangling options.In addition, we will shed light on various indicators from the statisticalpoint of view to compare with the options learned through the existingoption-critic architecture.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.06887v1'},\n",
       " 797: {'ID': 797,\n",
       "  'title': 'On Deep Multi-View Representation Learning: Objectives and Optimization',\n",
       "  'authors': ['Jeff Bilmes', 'Weiran Wang', 'Raman Arora', 'Karen Livescu'],\n",
       "  'published': '2016-02-02T17:51:43Z',\n",
       "  'updated': '2016-02-02T17:51:43Z',\n",
       "  'abstract': 'We consider learning representations (features) in the setting in which wehave access to multiple unlabeled views of the data for learning while only oneview is available for downstream tasks. Previous work on this problem hasproposed several techniques based on deep neural networks, typically involvingeither autoencoder-like networks with a reconstruction objective or pairedfeedforward networks with a batch-style correlation-based objective. We analyzeseveral techniques based on prior work, as well as new variants, and comparethem empirically on image, speech, and text tasks. We find an advantage forcorrelation-based representation learning, while the best results on most tasksare obtained with our new variant, deep canonically correlated autoencoders(DCCAE). We also explore a stochastic optimization procedure for minibatchcorrelation-based objectives and discuss the time/performance trade-offs forkernel-based and neural network-based implementations.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1602.01024v1'},\n",
       " 798: {'ID': 798,\n",
       "  'title': 'Policy Optimization With Penalized Point Probability Distance: An  Alternative To Proximal Policy Optimization',\n",
       "  'authors': ['Xiangxiang Chu'],\n",
       "  'published': '2018-07-02T02:49:36Z',\n",
       "  'updated': '2019-02-14T08:51:28Z',\n",
       "  'abstract': 'As the most successful variant and improvement for Trust Region PolicyOptimization (TRPO), proximal policy optimization (PPO) has been widely appliedacross various domains with several advantages: efficient data utilization,easy implementation, and good parallelism. In this paper, a first-ordergradient reinforcement learning algorithm called Policy Optimization withPenalized Point Probability Distance (POP3D), which is a lower bound to thesquare of total variance divergence is proposed as another powerful variant.Firstly, we talk about the shortcomings of several commonly used algorithms, bywhich our method is partly motivated. Secondly, we address to overcome theseshortcomings by applying POP3D. Thirdly, we dive into its mechanism from theperspective of solution manifold. Finally, we make quantitative comparisonsamong several state-of-the-art algorithms based on common benchmarks.Simulation results show that POP3D is highly competitive compared with PPO.Besides, our code is released in https://github.com/paperwithcode/pop3d.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1807.00442v4'},\n",
       " 799: {'ID': 799,\n",
       "  'title': 'PC-Fairness: A Unified Framework for Measuring Causality-based Fairness',\n",
       "  'authors': ['Hanghang Tong', 'Xintao Wu', 'Yongkai Wu', 'Lu Zhang'],\n",
       "  'published': '2019-10-20T23:00:53Z',\n",
       "  'updated': '2019-10-20T23:00:53Z',\n",
       "  'abstract': 'A recent trend of fair machine learning is to define fairness ascausality-based notions which concern the causal connection between protectedattributes and decisions. However, one common challenge of all causality-basedfairness notions is identifiability, i.e., whether they can be uniquelymeasured from observational data, which is a critical barrier to applying thesenotions to real-world situations. In this paper, we develop a framework formeasuring different causality-based fairness. We propose a unified definitionthat covers most of previous causality-based fairness notions, namely thepath-specific counterfactual fairness (PC fairness). Based on that, we proposea general method in the form of a constrained optimization problem for boundingthe path-specific counterfactual fairness under all unidentifiable situations.Experiments on synthetic and real-world datasets show the correctness andeffectiveness of our method.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.12586v1'},\n",
       " 800: {'ID': 800,\n",
       "  'title': 'MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning',\n",
       "  'authors': ['Xin Yang',\n",
       "   'Jian Sun',\n",
       "   'Zichao Guo',\n",
       "   'Xiangyu Zhang',\n",
       "   'Zechun Liu',\n",
       "   'Haoyuan Mu',\n",
       "   'Tim Kwang-Ting Cheng'],\n",
       "  'published': '2019-03-25T12:05:27Z',\n",
       "  'updated': '2019-08-14T03:41:11Z',\n",
       "  'abstract': 'In this paper, we propose a novel meta learning approach for automaticchannel pruning of very deep neural networks. We first train a PruningNet, akind of meta network, which is able to generate weight parameters for anypruned structure given the target network. We use a simple stochastic structuresampling method for training the PruningNet. Then, we apply an evolutionaryprocedure to search for good-performing pruned networks. The search is highlyefficient because the weights are directly generated by the trained PruningNetand we do not need any finetuning at search time. With a single PruningNettrained for the target network, we can search for various Pruned Networks underdifferent constraints with little human participation. Compared to thestate-of-the-art pruning methods, we have demonstrated superior performances onMobileNet V1/V2 and ResNet. Codes are available onhttps://github.com/liuzechun/MetaPruning.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.10258v3'},\n",
       " 801: {'ID': 801,\n",
       "  'title': \"Quantum Earth Mover's Distance: A New Approach to Learning Quantum Data\",\n",
       "  'authors': ['Seth Lloyd',\n",
       "   'Bobak Toussi Kiani',\n",
       "   'Zi-Wen Liu',\n",
       "   'Giacomo De Palma',\n",
       "   'Milad Marvian'],\n",
       "  'published': '2021-01-08T14:33:19Z',\n",
       "  'updated': '2021-01-08T14:33:19Z',\n",
       "  'abstract': \"Quantifying how far the output of a learning algorithm is from its target isan essential task in machine learning. However, in quantum settings, the losslandscapes of commonly used distance metrics often produce undesirable outcomessuch as poor local minima and exponentially decaying gradients. As a newapproach, we consider here the quantum earth mover's (EM) or Wasserstein-1distance, recently proposed in [De Palma et al., arXiv:2009.04469] as a quantumanalog to the classical EM distance. We show that the quantum EM distancepossesses unique properties, not found in other commonly used quantum distancemetrics, that make quantum learning more stable and efficient. We propose aquantum Wasserstein generative adversarial network (qWGAN) which takesadvantage of the quantum EM distance and provides an efficient means ofperforming learning on quantum data. Our qWGAN requires resources polynomial inthe number of qubits, and our numerical experiments demonstrate that it iscapable of learning a diverse set of quantum data.\",\n",
       "  'categories': ['quant-ph', 'cs.AI', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.03037v1'},\n",
       " 802: {'ID': 802,\n",
       "  'title': 'Deep Reinforcement Learning for Traffic Light Control in Vehicular  Networks',\n",
       "  'authors': ['Zhu Han', 'Xunsheng Du', 'Xiaoyuan Liang', 'Guiling Wang'],\n",
       "  'published': '2018-03-29T15:24:28Z',\n",
       "  'updated': '2018-03-29T15:24:28Z',\n",
       "  'abstract': \"Existing inefficient traffic light control causes numerous problems, such aslong delay and waste of energy. To improve efficiency, taking real-time trafficinformation as an input and dynamically adjusting the traffic light durationaccordingly is a must. In terms of how to dynamically adjust traffic signals'duration, existing works either split the traffic signal into equal duration orextract limited traffic information from the real data. In this paper, we studyhow to decide the traffic signals' duration based on the collected data fromdifferent sensors and vehicular networks. We propose a deep reinforcementlearning model to control the traffic light. In the model, we quantify thecomplex traffic scenario as states by collecting data and dividing the wholeintersection into small grids. The timing changes of a traffic light are theactions, which are modeled as a high-dimension Markov decision process. Thereward is the cumulative waiting time difference between two cycles. To solvethe model, a convolutional neural network is employed to map the states torewards. The proposed model is composed of several components to improve theperformance, such as dueling network, target network, double Q-learningnetwork, and prioritized experience replay. We evaluate our model viasimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,and the simulation results show the efficiency of our model in controllingtraffic lights.\",\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1803.11115v1'},\n",
       " 803: {'ID': 803,\n",
       "  'title': 'Molecular Hypergraph Grammar with its Application to Molecular  Optimization',\n",
       "  'authors': ['Hiroshi Kajino'],\n",
       "  'published': '2018-09-08T02:25:52Z',\n",
       "  'updated': '2019-04-23T04:52:44Z',\n",
       "  'abstract': 'Molecular optimization aims to discover novel molecules with desirableproperties. Two fundamental challenges are: (i) it is not trivial to generatevalid molecules in a controllable way due to hard chemical constraints such asthe valency conditions, and (ii) it is often costly to evaluate a property of anovel molecule, and therefore, the number of property evaluations is limited.These challenges are to some extent alleviated by a combination of avariational autoencoder (VAE) and Bayesian optimization (BO). VAE converts amolecule into/from its latent continuous vector, and BO optimizes a latentcontinuous vector (and its corresponding molecule) within a limited number ofproperty evaluations. While the most recent work, for the first time, achieved100% validity, its architecture is rather complex due to auxiliary neuralnetworks other than VAE, making it difficult to train. This paper presents amolecular hypergraph grammar variational autoencoder (MHG-VAE), which uses asingle VAE to achieve 100% validity. Our idea is to develop a graph grammarencoding the hard chemical constraints, called molecular hypergraph grammar(MHG), which guides VAE to always generate valid molecules. We also present analgorithm to construct MHG from a set of molecules.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.02745v2'},\n",
       " 804: {'ID': 804,\n",
       "  'title': 'Using Wasserstein Generative Adversarial Networks for the Design of  Monte Carlo Simulations',\n",
       "  'authors': ['Susan Athey', 'Evan Munro', 'Guido Imbens', 'Jonas Metzger'],\n",
       "  'published': '2019-09-05T05:01:38Z',\n",
       "  'updated': '2020-07-22T03:47:55Z',\n",
       "  'abstract': 'When researchers develop new econometric methods it is common practice tocompare the performance of the new methods to those of existing methods inMonte Carlo studies. The credibility of such Monte Carlo studies is oftenlimited because of the freedom the researcher has in choosing the design. Inrecent years a new class of generative models emerged in the machine learningliterature, termed Generative Adversarial Networks (GANs) that can be used tosystematically generate artificial data that closely mimics real economicdatasets, while limiting the degrees of freedom for the researcher andoptionally satisfying privacy guarantees with respect to their training data.In addition if an applied researcher is concerned with the performance of aparticular statistical method on a specific data set (beyond its theoreticalproperties in large samples), she may wish to assess the performance, e.g., thecoverage rate of confidence intervals or the bias of the estimator, usingsimulated data which resembles her setting. Tol illustrate these methods weapply Wasserstein GANs (WGANs) to compare a number of different estimators foraverage treatment effects under unconfoundedness in three distinct settings(corresponding to three real data sets) and present a methodology for assessingthe robustness of the results. In this example, we find that (i) there is notone estimator that outperforms the others in all three settings, so researchersshould tailor their analytic approach to a given setting, and (ii) systematicsimulation studies can be helpful for selecting among competing methods in thissituation.',\n",
       "  'categories': ['econ.EM', 'stat.ME'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.02210v3'},\n",
       " 805: {'ID': 805,\n",
       "  'title': 'A Stochastic Trust-Region Framework for Policy Optimization',\n",
       "  'authors': ['Mingming Zhao', 'Zaiwen Wen', 'Yongfeng Li'],\n",
       "  'published': '2019-11-26T15:27:13Z',\n",
       "  'updated': '2019-11-26T15:27:13Z',\n",
       "  'abstract': 'In this paper, we study a few challenging theoretical and numerical issues onthe well known trust region policy optimization for deep reinforcementlearning. The goal is to find a policy that maximizes the total expected rewardwhen the agent acts according to the policy. The trust region subproblem isconstructed with a surrogate function coherent to the total expected reward anda general distance constraint around the latest policy. We solve the subproblemusing a preconditioned stochastic gradient method with a line search scheme toensure that each step promotes the model function and stays in the trustregion. To overcome the bias caused by sampling to the function estimationsunder the random settings, we add the empirical standard deviation of the totalexpected reward to the predicted increase in a ratio in order to update thetrust region radius and decide whether the trial point is accepted. Moreover,for a Gaussian policy which is commonly used for continuous action space, themaximization with respect to the mean and covariance is performed separately tocontrol the entropy loss. Our theoretical analysis shows that the deterministicversion of the proposed algorithm tends to generate a monotonic improvement ofthe total expected reward and the global convergence is guaranteed undermoderate assumptions. Comparisons with the state-of-the-art methods demonstratethe effectiveness and robustness of our method over robotic controls and gameplayings from OpenAI Gym.',\n",
       "  'categories': ['math.OC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.11640v1'},\n",
       " 806: {'ID': 806,\n",
       "  'title': 'Are Eliminated Spans Useless for Coreference Resolution? Not at all',\n",
       "  'authors': ['Xin Tan', 'Longyin Zhang', 'Guodong Zhou'],\n",
       "  'published': '2021-01-04T02:02:49Z',\n",
       "  'updated': '2021-01-04T02:02:49Z',\n",
       "  'abstract': 'Various neural-based methods have been proposed so far for joint mentiondetection and coreference resolution. However, existing works on coreferenceresolution are mainly dependent on filtered mention representation, while otherspans are largely neglected. In this paper, we aim at increasing theutilization rate of data and investigating whether those eliminated spans aretotally useless, or to what extent they can improve the performance ofcoreference resolution. To achieve this, we propose a mention representationrefining strategy where spans highly related to mentions are well leveragedusing a pointer network for representation enhancing. Notably, we utilize anadditional loss term in this work to encourage the diversity between entityclusters. Experimental results on the document-level CoNLL-2012 Shared TaskEnglish dataset show that eliminated spans are indeed much effective and ourapproach can achieve competitive results when compared with previousstate-of-the-art in coreference resolution.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.00737v1'},\n",
       " 807: {'ID': 807,\n",
       "  'title': 'ScreenerNet: Learning Self-Paced Curriculum for Deep Neural Networks',\n",
       "  'authors': ['Tae-Hoon Kim', 'Jonghyun Choi'],\n",
       "  'published': '2018-01-03T05:49:37Z',\n",
       "  'updated': '2018-06-06T06:46:02Z',\n",
       "  'abstract': 'We propose to learn a curriculum or a syllabus for supervised learning anddeep reinforcement learning with deep neural networks by an attachable deepneural network, called ScreenerNet. Specifically, we learn a weight for eachsample by jointly training the ScreenerNet and the main network in anend-to-end self-paced fashion. The ScreenerNet neither has sampling bias norrequires to remember the past learning history. We show the networks augmentedwith the ScreenerNet achieve early convergence with better accuracy than thestate-of-the-art curricular learning methods in extensive experiments usingthree popular vision datasets such as MNIST, CIFAR10 and Pascal VOC2012, and aCart-pole task using Deep Q-learning. Moreover, the ScreenerNet can extendother curriculum learning methods such as Prioritized Experience Replay (PER)for further accuracy improvement.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1801.00904v4'},\n",
       " 808: {'ID': 808,\n",
       "  'title': 'DyNODE: Neural Ordinary Differential Equations for Dynamics Modeling in  Continuous Control',\n",
       "  'authors': ['Cristian G. Fălcuţescu',\n",
       "   'Rareş Roşca',\n",
       "   'Victor M. Martinez Alvarez'],\n",
       "  'published': '2020-09-09T12:56:58Z',\n",
       "  'updated': '2020-09-09T12:56:58Z',\n",
       "  'abstract': \"We present a novel approach (DyNODE) that captures the underlying dynamics ofa system by incorporating control in a neural ordinary differential equationframework. We conduct a systematic evaluation and comparison of our method andstandard neural network architectures for dynamics modeling. Our resultsindicate that a simple DyNODE architecture when combined with an actor-criticreinforcement learning (RL) algorithm that uses model predictions to improvethe critic's target values, outperforms canonical neural networks, both insample efficiency and predictive performance across a diverse range ofcontinuous tasks that are frequently used to benchmark RL algorithms. Thisapproach provides a new avenue for the development of models that are moresuited to learn the evolution of dynamical systems, particularly useful in thecontext of model-based reinforcement learning. To assist related work, we havemade code available at https://github.com/vmartinezalvarez/DyNODE .\",\n",
       "  'categories': ['cs.LG', 'cs.SY', 'eess.SY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.04278v1'},\n",
       " 809: {'ID': 809,\n",
       "  'title': 'Program Enhanced Fact Verification with Verbalization and Graph  Attention Network',\n",
       "  'authors': ['Quan Liu',\n",
       "   'Zhigang Chen',\n",
       "   'Xiaodan Zhu',\n",
       "   'Yufei Feng',\n",
       "   'Feng Nie',\n",
       "   'Xiaoyu Yang'],\n",
       "  'published': '2020-10-06T23:29:08Z',\n",
       "  'updated': '2020-11-26T20:27:59Z',\n",
       "  'abstract': 'Performing fact verification based on structured data is important for manyreal-life applications and is a challenging research problem, particularly whenit involves both symbolic operations and informal inference based on languageunderstanding. In this paper, we present a Program-enhanced Verbalization andGraph Attention Network (ProgVGAT) to integrate programs and execution intotextual inference models. Specifically, a verbalization with program executionmodel is proposed to accumulate evidences that are embedded in operations overthe tables. Built on that, we construct the graph attention verificationnetworks, which are designed to fuse different sources of evidences fromverbalized program execution, program structures, and the original statementsand tables, to make the final verification decision. To support the aboveframework, we propose a program selection module optimized with a new trainingstrategy based on margin loss, to produce more accurate programs, which isshown to be effective in enhancing the final verification results. Experimentalresults show that the proposed framework achieves the new state-of-the-artperformance, a 74.4% accuracy, on the benchmark dataset TABFACT.',\n",
       "  'categories': ['cs.AI', 'cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.03084v5'},\n",
       " 810: {'ID': 810,\n",
       "  'title': 'Deep Visual Re-Identification with Confidence',\n",
       "  'authors': ['Alexandre Alahi', 'George Adaimi', 'Sven Kreiss'],\n",
       "  'published': '2019-06-11T16:49:27Z',\n",
       "  'updated': '2020-09-10T08:53:43Z',\n",
       "  'abstract': 'Transportation systems often rely on understanding the flow of vehicles orpedestrian. From traffic monitoring at the city scale, to commuters in trainterminals, recent progress in sensing technology make it possible to usecameras to better understand the demand, i.e., better track moving agents(e.g., vehicles and pedestrians). Whether the cameras are mounted on drones,vehicles, or fixed in the built environments, they inevitably remain scatter.We need to develop the technology to re-identify the same agents across imagescaptured from non-overlapping field-of-views, referred to as the visualre-identification task. State-of-the-art methods learn a neural network basedrepresentation trained with the cross-entropy loss function. We argue that suchloss function is not suited for the visual re-identification task hence proposeto model confidence in the representation learning framework. We show theimpact of our confidence-based learning framework with three methods: labelsmoothing, confidence penalty, and deep variational information bottleneck.They all show a boost in performance validating our claim. Our contribution isgeneric to any agent of interest, i.e., vehicles or pedestrians, and outperformhighly specialized state-of-the-art methods across 5 datasets. The source codeand models are shared towards an open science mission.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.04692v2'},\n",
       " 811: {'ID': 811,\n",
       "  'title': 'Association Rules Enhanced Knowledge Graph Attention Network',\n",
       "  'authors': ['Jianbin Huang', 'Zhenghao Zhang', 'Qinglin Tan'],\n",
       "  'published': '2020-11-14T13:18:55Z',\n",
       "  'updated': '2020-11-14T13:18:55Z',\n",
       "  'abstract': 'Most existing knowledge graphs suffer from incompleteness. Embeddingknowledge graphs into continuous vector spaces has recently attractedincreasing interest in knowledge base completion. However, in most existingembedding methods, only fact triplets are utilized, and logical rules have notbeen thoroughly studied for the knowledge base completion task. To overcome theproblem, we propose an association rules enhanced knowledge graph attentionnetwork (AR-KGAT). The AR-KGAT captures both entity and relation features forhigh-order neighborhoods of any given entity in an end-to-end manner under thegraph attention network framework. The major component of AR-KGAT is an encoderof an effective neighborhood aggregator, which addresses the problems byaggregating neighbors with both association-rules-based and graph-basedattention weights. Additionally, the proposed model also encapsulates therepresentations from multi-hop neighbors of nodes to refine their embeddings.The decoder enables AR-KGAT to be translational between entities and relationswhile keeping the superior link prediction performance. A logic-like inferencepattern is utilized as constraints for knowledge graph embedding. Then, theglobal loss is minimized over both atomic and complex formulas to achieve theembedding task. In this manner, we learn embeddings compatible with tripletsand rules, which are certainly more predictive for knowledge acquisition andinference. We conduct extensive experiments on two benchmark datasets: WN18RRand FB15k-237, for two knowledge graph completion tasks: the link predictionand triplet classification to evaluate the proposed AR-KGAT model. The resultsshow that the proposed AR-KGAT model achieves significant and consistentimprovements over state-of-the-art methods.',\n",
       "  'categories': ['cs.IR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.08431v1'},\n",
       " 812: {'ID': 812,\n",
       "  'title': 'Exploration via Hindsight Goal Generation',\n",
       "  'authors': ['Kefan Dong',\n",
       "   'Yuan Zhou',\n",
       "   'Jian Peng',\n",
       "   'Zhizhou Ren',\n",
       "   'Qiang Liu'],\n",
       "  'published': '2019-06-10T21:21:18Z',\n",
       "  'updated': '2019-12-18T04:31:39Z',\n",
       "  'abstract': 'Goal-oriented reinforcement learning has recently been a practical frameworkfor robotic manipulation tasks, in which an agent is required to reach acertain goal defined by a function on the state space. However, the sparsity ofsuch reward definition makes traditional reinforcement learning algorithms veryinefficient. Hindsight Experience Replay (HER), a recent advance, has greatlyimproved sample efficiency and practical applicability for such problems. Itexploits previous replays by constructing imaginary goals in a simple heuristicway, acting like an implicit curriculum to alleviate the challenge of sparsereward signal. In this paper, we introduce Hindsight Goal Generation (HGG), anovel algorithmic framework that generates valuable hindsight goals which areeasy for an agent to achieve in the short term and are also potential forguiding the agent to reach the actual goal in the long term. We haveextensively evaluated our goal generation algorithm on a number of roboticmanipulation tasks and demonstrated substantially improvement over the originalHER in terms of sample efficiency.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.04279v3'},\n",
       " 813: {'ID': 813,\n",
       "  'title': 'Practical Bayesian Optimization for Transportation Simulators',\n",
       "  'authors': ['Vadim Sokolov', 'Laura Schultz'],\n",
       "  'published': '2018-10-08T20:31:22Z',\n",
       "  'updated': '2019-01-14T06:29:12Z',\n",
       "  'abstract': 'We provide a method to solve optimization problem when objective function isa complex stochastic simulator of an urban transportation system. To reach thisgoal, a Bayesian optimization framework is introduced. We show how the choiceof prior and inference algorithm effect the outcome of our optimizationprocedure. We develop dimensionality reduction techniques that allow for ouroptimization techniques to be applicable for real-life problems. We develop adistributed, Gaussian Process Bayesian regression and active learning modelsthat allow parallel execution of our algorithms and enable usage of highperformance computing. We present a fully Bayesian approach that is more sampleefficient and reduces computational budget. Our framework is supported bytheoretical analysis and an empirical study. We demonstrate our framework onthe problem of calibrating a multi-modal transportation network of city ofBloomington, Illinois. Finally, we discuss directions for further research.',\n",
       "  'categories': ['stat.CO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1810.03688v2'},\n",
       " 814: {'ID': 814,\n",
       "  'title': 'Ternary Compression for Communication-Efficient Federated Learning',\n",
       "  'authors': ['Yaochu Jin', 'Ran Cheng', 'Jinjin Xu', 'Wenli Du', 'Wangli He'],\n",
       "  'published': '2020-03-07T11:55:34Z',\n",
       "  'updated': '2020-03-07T11:55:34Z',\n",
       "  'abstract': 'Learning over massive data stored in different locations is essential in manyreal-world applications. However, sharing data is full of challenges due to theincreasing demands of privacy and security with the growing use of smart mobiledevices and IoT devices. Federated learning provides a potential solution toprivacy-preserving and secure machine learning, by means of jointly training aglobal model without uploading data distributed on multiple devices to acentral server. However, most existing work on federated learning adoptsmachine learning models with full-precision weights, and almost all thesemodels contain a large number of redundant parameters that do not need to betransmitted to the server, consuming an excessive amount of communicationcosts. To address this issue, we propose a federated trained ternaryquantization (FTTQ) algorithm, which optimizes the quantized networks on theclients through a self-learning quantization factor. A convergence proof of thequantization factor and the unbiasedness of FTTQ is given. In addition, wepropose a ternary federated averaging protocol (T-FedAvg) to reduce theupstream and downstream communication of federated learning systems. Empiricalexperiments are conducted to train widely used deep learning models on publiclyavailable datasets, and our results demonstrate the effectiveness of FTTQ andT-FedAvg compared with the canonical federated learning algorithms in reducingcommunication costs and maintaining the learning performance.',\n",
       "  'categories': ['cs.LG', 'cs.DC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.03564v1'},\n",
       " 815: {'ID': 815,\n",
       "  'title': 'TinBiNN: Tiny Binarized Neural Network Overlay in about 5,000 4-LUTs and  5mW',\n",
       "  'authors': ['Joe Edwards',\n",
       "   'Ryan De Iaco',\n",
       "   'Hussein Osman',\n",
       "   'Guy G. F. Lemieux',\n",
       "   'Abdullah Raouf',\n",
       "   'Joel Vandergriendt',\n",
       "   'Tom Watzka',\n",
       "   'Aaron Severance',\n",
       "   'Satwant Singh'],\n",
       "  'published': '2019-03-05T14:51:36Z',\n",
       "  'updated': '2019-03-05T14:51:36Z',\n",
       "  'abstract': \"Reduced-precision arithmetic improves the size, cost, power and performanceof neural networks in digital logic. In convolutional neural networks, the useof 1b weights can achieve state-of-the-art error rates while eliminatingmultiplication, reducing storage and improving power efficiency. TheBinaryConnect binary-weighted system, for example, achieves 9.9% error usingfloating-point activations on the CIFAR-10 dataset. In this paper, we introduceTinBiNN, a lightweight vector processor overlay for accelerating inferencecomputations with 1b weights and 8b activations. The overlay is very small --it uses about 5,000 4-input LUTs and fits into a low cost iCE40 UltraPlus FPGAfrom Lattice Semiconductor. To show this can be useful, we build two embedded'person detector' systems by shrinking the original BinaryConnect network. Thefirst is a 10-category classifier with a 89% smaller network that runs in1,315ms and achieves 13.6% error. The other is a 1-category classifier that iseven smaller, runs in 195ms, and has only 0.4% error. In both classifiers, theerror can be attributed entirely to training and not reduced precision.\",\n",
       "  'categories': ['cs.DC', 'cs.CV', 'cs.OH'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.06630v1'},\n",
       " 816: {'ID': 816,\n",
       "  'title': 'ConsNet: Learning Consistency Graph for Zero-Shot Human-Object  Interaction Detection',\n",
       "  'authors': ['Ye Liu', 'Junsong Yuan', 'Chang Wen Chen'],\n",
       "  'published': '2020-08-14T09:11:18Z',\n",
       "  'updated': '2020-09-15T05:35:03Z',\n",
       "  'abstract': 'We consider the problem of Human-Object Interaction (HOI) Detection, whichaims to locate and recognize HOI instances in the form of &lt;human, action,object&gt; in images. Most existing works treat HOIs as individual interactioncategories, thus can not handle the problem of long-tail distribution andpolysemy of action labels. We argue that multi-level consistencies amongobjects, actions and interactions are strong cues for generating semanticrepresentations of rare or previously unseen HOIs. Leveraging the compositionaland relational peculiarities of HOI labels, we propose ConsNet, aknowledge-aware framework that explicitly encodes the relations among objects,actions and interactions into an undirected graph called consistency graph, andexploits Graph Attention Networks (GATs) to propagate knowledge among HOIcategories as well as their constituents. Our model takes visual features ofcandidate human-object pairs and word embeddings of HOI labels as inputs, mapsthem into visual-semantic joint embedding space and obtains detection resultsby measuring their similarities. We extensively evaluate our model on thechallenging V-COCO and HICO-DET datasets, and results validate that ourapproach outperforms state-of-the-arts under both fully-supervised andzero-shot settings.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.06254v2'},\n",
       " 817: {'ID': 817,\n",
       "  'title': 'ZPD Teaching Strategies for Deep Reinforcement Learning from  Demonstrations',\n",
       "  'authors': ['Chen Tang',\n",
       "   'Roshan Rao',\n",
       "   'Mandi Zhao',\n",
       "   'Daniel Seita',\n",
       "   'John Canny',\n",
       "   'David Chan'],\n",
       "  'published': '2019-10-26T23:05:43Z',\n",
       "  'updated': '2019-10-26T23:05:43Z',\n",
       "  'abstract': 'Learning from demonstrations is a popular tool for accelerating and reducingthe exploration requirements of reinforcement learning. When providing expertdemonstrations to human students, we know that the demonstrations must fallwithin a particular range of difficulties called the \"Zone of ProximalDevelopment (ZPD)\". If they are too easy the student learns nothing, but ifthey are too difficult the student is unable to follow along. This raises thequestion: Given a set of potential demonstrators, which among them is bestsuited for teaching any particular learner? Prior work, such as the popularDeep Q-learning from Demonstrations (DQfD) algorithm has generally focused onsingle demonstrators. In this work we consider the problem of choosing amongmultiple demonstrators of varying skill levels. Our results align withintuition from human learners: it is not always the best policy to drawdemonstrations from the best performing demonstrator (in terms of reward). Weshow that careful selection of teaching strategies can result in sampleefficiency gains in the learner\\'s environment across nine Atari games',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.12154v1'},\n",
       " 818: {'ID': 818,\n",
       "  'title': 'Safe Option-Critic: Learning Safety in the Option-Critic Architecture',\n",
       "  'authors': ['Khimya Khetarpal', 'Arushi Jain', 'Doina Precup'],\n",
       "  'published': '2018-07-21T00:39:23Z',\n",
       "  'updated': '2018-07-21T00:39:23Z',\n",
       "  'abstract': \"Designing hierarchical reinforcement learning algorithms that induce a notionof safety is not only vital for safety-critical applications, but also, bringsbetter understanding of an artificially intelligent agent's decisions. Whilelearning end-to-end options automatically has been fully realized recently, wepropose a solution to learning safe options. We introduce the idea ofcontrollability of states based on the temporal difference errors in theoption-critic framework. We then derive the policy-gradient theorem withcontrollability and propose a novel framework called safe option-critic. Wedemonstrate the effectiveness of our approach in the four-rooms grid-world,cartpole, and three games in the Arcade Learning Environment (ALE): MsPacman,Amidar and Q*Bert. Learning of end-to-end options with the proposed notion ofsafety achieves reduction in the variance of return and boosts the performancein environments with intrinsic variability in the reward structure. Moreimportantly, the proposed algorithm outperforms the vanilla options in all theenvironments and primitive actions in two out of three ALE games.\",\n",
       "  'categories': ['cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1807.08060v1'},\n",
       " 819: {'ID': 819,\n",
       "  'title': 'Hypernetwork approach to generating point clouds',\n",
       "  'authors': ['Tomasz Trzciński',\n",
       "   'Przemysław Spurek',\n",
       "   'Maciej Zamorski',\n",
       "   'Jacek Tabor',\n",
       "   'Maciej Zięba',\n",
       "   'Sebastian Winczowski'],\n",
       "  'published': '2020-02-10T11:09:58Z',\n",
       "  'updated': '2020-10-13T19:18:59Z',\n",
       "  'abstract': 'In this work, we propose a novel method for generating 3D point clouds thatleverage properties of hyper networks. Contrary to the existing methods thatlearn only the representation of a 3D object, our approach simultaneously findsa representation of the object and its 3D surface. The main idea of ourHyperCloud method is to build a hyper network that returns weights of aparticular neural network (target network) trained to map points from a uniformunit ball distribution into a 3D shape. As a consequence, a particular 3D shapecan be generated using point-by-point sampling from the assumed priordistribution and transforming sampled points with the target network. Since thehyper network is based on an auto-encoder architecture trained to reconstructrealistic 3D shapes, the target network weights can be considered aparametrization of the surface of a 3D shape, and not a standard representationof point cloud usually returned by competitive approaches. The proposedarchitecture allows finding mesh-based representation of 3D objects in agenerative manner while providing point clouds en pair in quality with thestate-of-the-art methods.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.00802v2'},\n",
       " 820: {'ID': 820,\n",
       "  'title': 'Improving Multi-turn Dialogue Modelling with Utterance ReWriter',\n",
       "  'authors': ['Jie Zhou',\n",
       "   'Xiaoyu Shen',\n",
       "   'Fei Sun',\n",
       "   'Rongzhi Zhang',\n",
       "   'Hui Su',\n",
       "   'Cheng Niu',\n",
       "   'Pengwei Hu'],\n",
       "  'published': '2019-06-14T06:45:08Z',\n",
       "  'updated': '2019-06-14T06:45:08Z',\n",
       "  'abstract': 'Recent research has made impressive progress in single-turn dialoguemodelling. In the multi-turn setting, however, current models are still farfrom satisfactory. One major challenge is the frequently occurred coreferenceand information omission in our daily conversation, making it hard for machinesto understand the real intention. In this paper, we propose rewriting the humanutterance as a pre-process to help multi-turn dialgoue modelling. Eachutterance is first rewritten to recover all coreferred and omitted information.The next processing steps are then performed based on the rewritten utterance.To properly train the utterance rewriter, we collect a new dataset with humanannotations and introduce a Transformer-based utterance rewriting architectureusing the pointer network. We show the proposed architecture achievesremarkably good performance on the utterance rewriting task. The trainedutterance rewriter can be easily integrated into online chatbots and bringsgeneral improvement over different domains.',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.07004v1'},\n",
       " 821: {'ID': 821,\n",
       "  'title': 'Addressing Challenging Place Recognition Tasks using Generative  Adversarial Networks',\n",
       "  'authors': ['Ian Reid', 'Yasir Latif', 'Michael Milford', 'Ravi Garg'],\n",
       "  'published': '2017-09-26T04:14:52Z',\n",
       "  'updated': '2018-02-27T03:39:05Z',\n",
       "  'abstract': 'Place recognition is an essential component of Simultaneous Localization AndMapping (SLAM). Under severe appearance change, reliable place recognition is adifficult perception task since the same place is perceptually very differentin the morning, at night, or over different seasons. This work addresses placerecognition as a domain translation task. Using a pair of coupled GenerativeAdversarial Networks (GANs), we show that it is possible to generate theappearance of one domain (such as summer) from another (such as winter) withoutrequiring image-to-image correspondences across the domains. Mapping betweendomains is learned from sets of images in each domain without knowing theinstance-to-instance correspondence by enforcing a cyclic consistencyconstraint. In the process, meaningful feature spaces are learned for eachdomain, the distances in which can be used for the task of place recognition.Experiments show that learned features correspond to visual similarity and canbe effectively used for place recognition across seasons.',\n",
       "  'categories': ['cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1709.08810v2'},\n",
       " 822: {'ID': 822,\n",
       "  'title': 'Unsupervised Person Image Generation with Semantic Parsing  Transformation',\n",
       "  'authors': ['Jiaying Liu', 'Tao Mei', 'Sijie Song', 'Wei Zhang'],\n",
       "  'published': '2019-04-06T07:19:03Z',\n",
       "  'updated': '2019-04-18T13:12:53Z',\n",
       "  'abstract': 'In this paper, we address unsupervised pose-guided person image generation,which is known challenging due to non-rigid deformation. Unlike previousmethods learning a rock-hard direct mapping between human bodies, we propose anew pathway to decompose the hard mapping into two more accessible subtasks,namely, semantic parsing transformation and appearance generation. Firstly, asemantic generative network is proposed to transform between semantic parsingmaps, in order to simplify the non-rigid deformation learning. Secondly, anappearance generative network learns to synthesize semantic-aware textures.Thirdly, we demonstrate that training our framework in an end-to-end mannerfurther refines the semantic maps and final results accordingly. Our method isgeneralizable to other semantic-aware person image generation tasks, eg,clothing texture transfer and controlled image manipulation. Experimentalresults demonstrate the superiority of our method on DeepFashion andMarket-1501 datasets, especially in keeping the clothing attributes and betterbody shapes.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.03379v2'},\n",
       " 823: {'ID': 823,\n",
       "  'title': 'Abstracting Influence Paths for Explaining (Contextualization of) BERT  Models',\n",
       "  'authors': ['Piotr Mardziel', 'Anupam Datta', 'Kaiji Lu', 'Zifan Wang'],\n",
       "  'published': '2020-11-02T04:28:16Z',\n",
       "  'updated': '2020-11-02T04:28:16Z',\n",
       "  'abstract': 'While \"attention is all you need\" may be proving true, we do not yet knowwhy: attention-based models such as BERT are superior but how theycontextualize information even for simple grammatical rules such assubject-verb number agreement (SVA) is uncertain. We introduce multi-partitepatterns, abstractions of sets of paths through a neural network model.Patterns quantify and localize the effect of an input concept (e.g., asubject\\'s number) on an output concept (e.g. corresponding verb\\'s number) topaths passing through a sequence of model components, thus surfacing how BERTcontextualizes information. We describe guided pattern refinement, an efficientsearch procedure for finding patterns representative of concept-critical paths.We discover that patterns generate succinct and meaningful explanations forBERT, highlighted by \"copy\" and \"transfer\" operations implemented by skipconnections and attention heads, respectively. We also show how patternvisualizations help us understand how BERT contextualizes various grammaticalconcepts, such as SVA across clauses, and why it makes errors in some caseswhile succeeding in others.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.00740v1'},\n",
       " 824: {'ID': 824,\n",
       "  'title': 'Prediction of rare feature combinations in population synthesis:  Application of deep generative modelling',\n",
       "  'authors': ['Sergio Garrido',\n",
       "   'Francisco C. Pereira',\n",
       "   'Jeppe Rich',\n",
       "   'Stanislav S. Borysov'],\n",
       "  'published': '2019-09-17T09:58:45Z',\n",
       "  'updated': '2019-09-17T09:58:45Z',\n",
       "  'abstract': 'In population synthesis applications, when considering populations with manyattributes, a fundamental problem is the estimation of rare combinations offeature attributes. Unsurprisingly, it is notably more difficult to reliablyrepresentthe sparser regions of such multivariate distributions and inparticular combinations of attributes which are absent from the originalsample. In the literature this is commonly known as sampling zeros for which nosystematic solution has been proposed so far. In this paper, two machinelearning algorithms, from the family of deep generative models,are proposed forthe problem of population synthesis and with particular attention to theproblem of sampling zeros. Specifically, we introduce the WassersteinGenerative Adversarial Network (WGAN) and the Variational Autoencoder(VAE), andadapt these algorithms for a large-scale population synthesis application. Themodels are implemented on a Danish travel survey with a feature-space of morethan 60 variables. The models are validated in a cross-validation scheme and aset of new metrics for the evaluation of the sampling-zero problem is proposed.Results show how these models are able to recover sampling zeros while keepingthe estimation of truly impossible combinations, the structural zeros, at acomparatively low level. Particularly, for a low dimensional experiment, theVAE, the marginal sampler and the fully random sampler generate 5%, 21% and26%, respectively, more structural zeros per sampling zero generated by theWGAN, while for a high dimensional case, these figures escalate to 44%, 2217%and 170440%, respectively. This research directly supports the development ofagent-based systems and in particular cases where detailed socio-economic orgeographical representations are required.',\n",
       "  'categories': ['stat.ML', 'cs.LG', 'stat.AP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.07689v1'},\n",
       " 825: {'ID': 825,\n",
       "  'title': 'Accelerating Binarized Neural Networks via Bit-Tensor-Cores in Turing  GPUs',\n",
       "  'authors': ['Ang Li', 'Simon Su'],\n",
       "  'published': '2020-06-30T07:32:02Z',\n",
       "  'updated': '2020-12-15T00:13:59Z',\n",
       "  'abstract': 'Despite foreseeing tremendous speedups over conventional deep neuralnetworks, the performance advantage of binarized neural networks (BNNs) hasmerely been showcased on general-purpose processors such as CPUs and GPUs. Infact, due to being unable to leverage bit-level-parallelism with a word-basedarchitecture, GPUs have been criticized for extremely low utilization (1%) whenexecuting BNNs. Consequently, the latest tensorcores in NVIDIA Turing GPUsstart to experimentally support bit computation. In this work, we look intothis brand new bit computation capability and characterize its unique features.We show that the stride of memory access can significantly affect performancedelivery and a data-format co-design is highly desired to support thetensorcores for achieving superior performance than existing software solutionswithout tensorcores. We realize the tensorcore-accelerated BNN design,particularly the major functions for fully-connect and convolution layers --bit matrix multiplication and bit convolution. Evaluations on two NVIDIA TuringGPUs show that, with ResNet-18, our BTC-BNN design can process ImageNet at arate of 5.6K images per second, 77% faster than state-of-the-art. Our BNNapproach is released on https://github.com/pnnl/TCBNN.',\n",
       "  'categories': ['cs.DC', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.16578v2'},\n",
       " 826: {'ID': 826,\n",
       "  'title': 'Generative Models For Deep Learning with Very Scarce Data',\n",
       "  'authors': ['Daniel Ramos', 'Roberto Paredes', 'Juan Maroñas'],\n",
       "  'published': '2019-03-21T14:38:45Z',\n",
       "  'updated': '2019-03-21T14:38:45Z',\n",
       "  'abstract': 'The goal of this paper is to deal with a data scarcity scenario where deeplearning techniques use to fail. We compare the use of two well establishedtechniques, Restricted Boltzmann Machines and Variational Auto-encoders, asgenerative models in order to increase the training set in a classificationframework. Essentially, we rely on Markov Chain Monte Carlo (MCMC) algorithmsfor generating new samples. We show that generalization can be improvedcomparing this methodology to other state-of-the-art techniques, e.g.semi-supervised learning with ladder networks. Furthermore, we show that RBM isbetter than VAE generating new samples for training a classifier with goodgeneralization capabilities.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.09030v1'},\n",
       " 827: {'ID': 827,\n",
       "  'title': 'Universal Successor Features Approximators',\n",
       "  'authors': ['Rémi Munos',\n",
       "   'Hado van Hasselt',\n",
       "   'André Barreto',\n",
       "   'Diana Borsa',\n",
       "   'John Quan',\n",
       "   'Tom Schaul',\n",
       "   'David Silver',\n",
       "   'Daniel Mankowitz'],\n",
       "  'published': '2018-12-18T20:01:41Z',\n",
       "  'updated': '2018-12-18T20:01:41Z',\n",
       "  'abstract': 'The ability of a reinforcement learning (RL) agent to learn about many rewardfunctions at the same time has many potential benefits, such as thedecomposition of complex tasks into simpler ones, the exchange of informationbetween tasks, and the reuse of skills. We focus on one aspect in particular,namely the ability to generalise to unseen tasks. Parametric generalisationrelies on the interpolation power of a function approximator that is given thetask description as input; one of its most common form are universal valuefunction approximators (UVFAs). Another way to generalise to new tasks is toexploit structure in the RL problem itself. Generalised policy improvement(GPI) combines solutions of previous tasks into a policy for the unseen task;this relies on instantaneous policy evaluation of old policies under the newreward function, which is made possible through successor features (SFs). Ourproposed universal successor features approximators (USFAs) combine theadvantages of all of these, namely the scalability of UVFAs, the instantinference of SFs, and the strong generalisation of GPI. We discuss thechallenges involved in training a USFA, its generalisation properties anddemonstrate its practical benefits and transfer abilities on a large-scaledomain in which the agent has to navigate in a first-person perspectivethree-dimensional environment.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.07626v1'},\n",
       " 828: {'ID': 828,\n",
       "  'title': 'Universal Approximation Theorems of Fully Connected Binarized Neural  Networks',\n",
       "  'authors': ['Mario Günzel',\n",
       "   'Jian-Jia Chen',\n",
       "   'Burim Ramosaj',\n",
       "   'Mikail Yayla'],\n",
       "  'published': '2021-02-04T14:30:24Z',\n",
       "  'updated': '2021-02-04T14:30:24Z',\n",
       "  'abstract': 'Neural networks (NNs) are known for their high predictive accuracy in complexlearning problems. Beside practical advantages, NNs also indicate favourabletheoretical properties such as universal approximation (UA) theorems. BinarizedNeural Networks (BNNs) significantly reduce time and memory demands byrestricting the weight and activation domains to two values. Despite thepractical advantages, theoretical guarantees based on UA theorems of BNNs arerather sparse in the literature. We close this gap by providing UA theorems forfully connected BNNs under the following scenarios: (1) for binarized inputs,UA can be constructively achieved under one hidden layer; (2) for inputs withreal numbers, UA can not be achieved under one hidden layer but can beconstructively achieved under two hidden layers for Lipschitz-continuousfunctions. Our results indicate that fully connected BNNs can approximatefunctions universally, under certain conditions.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.02631v1'},\n",
       " 829: {'ID': 829,\n",
       "  'title': 'Quantum Wasserstein Generative Adversarial Networks',\n",
       "  'authors': ['Tongyang Li',\n",
       "   'Shouvanik Chakrabarti',\n",
       "   'Yiming Huang',\n",
       "   'Soheil Feizi',\n",
       "   'Xiaodi Wu'],\n",
       "  'published': '2019-10-31T21:11:57Z',\n",
       "  'updated': '2019-10-31T21:11:57Z',\n",
       "  'abstract': 'The study of quantum generative models is well-motivated, not only because ofits importance in quantum machine learning and quantum chemistry but alsobecause of the perspective of its implementation on near-term quantum machines.Inspired by previous studies on the adversarial training of classical andquantum generative models, we propose the first design of quantum WassersteinGenerative Adversarial Networks (WGANs), which has been shown to improve therobustness and the scalability of the adversarial training of quantumgenerative models even on noisy quantum hardware. Specifically, we propose adefinition of the Wasserstein semimetric between quantum data, which inherits afew key theoretical merits of its classical counterpart. We also demonstratehow to turn the quantum Wasserstein semimetric into a concrete design ofquantum WGANs that can be efficiently implemented on quantum machines. Ournumerical study, via classical simulation of quantum systems, shows the morerobust and scalable numerical performance of our quantum WGANs over otherquantum GAN proposals. As a surprising application, our quantum WGAN has beenused to generate a 3-qubit quantum circuit of ~50 gates that well approximatesa 3-qubit 1-d Hamiltonian simulation circuit that requires over 10k gates usingstandard techniques.',\n",
       "  'categories': ['quant-ph', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.00111v1'},\n",
       " 830: {'ID': 830,\n",
       "  'title': 'Modeling System Dynamics with Physics-Informed Neural Networks Based on  Lagrangian Mechanics',\n",
       "  'authors': ['Thomas A. Runkler',\n",
       "   'Manuel A. Roehrl',\n",
       "   'Michel Tokic',\n",
       "   'Stefan Obermayer',\n",
       "   'Veronika Brandtstetter'],\n",
       "  'published': '2020-05-29T15:10:43Z',\n",
       "  'updated': '2020-05-29T15:10:43Z',\n",
       "  'abstract': 'Identifying accurate dynamic models is required for the simulation andcontrol of various technical systems. In many important real-worldapplications, however, the two main modeling approaches often fail to meetrequirements: first principles methods suffer from high bias, whereasdata-driven modeling tends to have high variance. Additionally, purelydata-based models often require large amounts of data and are often difficultto interpret. In this paper, we present physics-informed neural ordinarydifferential equations (PINODE), a hybrid model that combines the two modelingtechniques to overcome the aforementioned problems. This new approach directlyincorporates the equations of motion originating from the Lagrange Mechanicsinto a deep neural network structure. Thus, we can integrate prior physicsknowledge where it is available and use function approximation--e. g., neuralnetworks--where it is not. The method is tested with a forward model of areal-world physical system with large uncertainties. The resulting model isaccurate and data-efficient while ensuring physical plausibility. With this, wedemonstrate a method that beneficially merges physical insight with real data.Our findings are of interest for model-based control and system identificationof mechanical systems.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2005.14617v1'},\n",
       " 831: {'ID': 831,\n",
       "  'title': 'Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency  for Sequence Modeling',\n",
       "  'authors': ['Louis-Philippe Morency', 'Chaitanya Ahuja'],\n",
       "  'published': '2017-10-06T01:52:14Z',\n",
       "  'updated': '2017-11-22T05:11:17Z',\n",
       "  'abstract': 'Recurrent neural networks have shown remarkable success in modelingsequences. However low resource situations still adversely affect thegeneralizability of these models. We introduce a new family of models, calledLattice Recurrent Units (LRU), to address the challenge of learning deepmulti-layer recurrent models with limited resources. LRU models achieve thisgoal by creating distinct (but coupled) flow of information inside the units: afirst flow along time dimension and a second flow along depth dimension. Italso offers a symmetry in how information can flow horizontally and vertically.We analyze the effects of decoupling three different components of our LRUmodel: Reset Gate, Update Gate and Projected State. We evaluate this family onnew LRU models on computational convergence rates and statistical efficiency.Our experiments are performed on four publicly-available datasets, comparingwith Grid-LSTM and Recurrent Highway networks. Our results show that LRU hasbetter empirical computational convergence rates and statistical efficiencyvalues, along with learning more accurate language models.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1710.02254v2'},\n",
       " 832: {'ID': 832,\n",
       "  'title': 'Learning to Zoom: a Saliency-Based Sampling Layer for Neural Networks',\n",
       "  'authors': ['Simon Stent',\n",
       "   'Adrià Recasens',\n",
       "   'Petr Kellnhofer',\n",
       "   'Antonio Torralba',\n",
       "   'Wojciech Matusik'],\n",
       "  'published': '2018-09-10T14:36:15Z',\n",
       "  'updated': '2018-09-10T14:36:15Z',\n",
       "  'abstract': 'We introduce a saliency-based distortion layer for convolutional neuralnetworks that helps to improve the spatial sampling of input data for a giventask. Our differentiable layer can be added as a preprocessing block toexisting task networks and trained altogether in an end-to-end fashion. Theeffect of the layer is to efficiently estimate how to sample from the originaldata in order to boost task performance. For example, for an imageclassification task in which the original data might range in size up toseveral megapixels, but where the desired input images to the task network aremuch smaller, our layer learns how best to sample from the underlying highresolution data in a manner which preserves task-relevant information betterthan uniform downsampling. This has the effect of creating distorted,caricature-like intermediate images, in which idiosyncratic elements of theimage that improve task performance are zoomed and exaggerated. Unlikealternative approaches such as spatial transformer networks, our proposed layeris inspired by image saliency, computed efficiently from uniformly downsampleddata, and degrades gracefully to a uniform sampling strategy under uncertainty.We apply our layer to improve existing networks for the tasks of human gazeestimation and fine-grained object classification. Code for our method isavailable in: http://github.com/recasens/Saliency-Sampler',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.03355v1'},\n",
       " 833: {'ID': 833,\n",
       "  'title': 'Electric Analog Circuit Design with Hypernetworks and a Differential  Simulator',\n",
       "  'authors': ['Michael Rotman', 'Lior Wolf'],\n",
       "  'published': '2019-11-08T05:13:05Z',\n",
       "  'updated': '2020-02-10T13:36:09Z',\n",
       "  'abstract': \"The manual design of analog circuits is a tedious task of parameter tuningthat requires hours of work by human experts. In this work, we make asignificant step towards a fully automatic design method that is based on deeplearning. The method selects the components and their configuration, as well astheir numerical parameters. By contrast, the current literature methods arelimited to the parameter fitting part only. A two-stage network is used, whichfirst generates a chain of circuit components and then predicts theirparameters. A hypernetwork scheme is used in which a weight generating network,which is conditioned on the circuit's power spectrum, produces the parametersof a primal RNN network that places the components. A differential simulator isused for refining the numerical values of the components. We show that ourmodel provides an efficient design solution, and is superior to alternativesolutions.\",\n",
       "  'categories': ['cs.LG', 'eess.SP', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.03053v2'},\n",
       " 834: {'ID': 834,\n",
       "  'title': 'Temporal Dynamic Model for Resting State fMRI Data: A Neural Ordinary  Differential Equation approach',\n",
       "  'authors': ['Zheyu Wen'],\n",
       "  'published': '2020-11-16T18:16:19Z',\n",
       "  'updated': '2020-11-16T18:16:19Z',\n",
       "  'abstract': 'The objective of this paper is to provide a temporal dynamic model forresting state functional Magnetic Resonance Imaging (fMRI) trajectory topredict future brain images based on the given sequence. To this end, we cameup with the model that takes advantage of representation learning and NeuralOrdinary Differential Equation (Neural ODE) to compress the fMRI image datainto latent representation and learn to predict the trajectory followingdifferential equation. Latent space was analyzed by Gaussian Mixture Model. Thelearned fMRI trajectory embedding can be used to explain the variance of thetrajectory and predict human traits for each subject. This method achievesaverage 0.5 spatial correlation for the whole predicted trajectory, and providetrained ODE parameter for further analysis.',\n",
       "  'categories': ['eess.SP', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.08146v1'},\n",
       " 835: {'ID': 835,\n",
       "  'title': 'Importance Weighted Hierarchical Variational Inference',\n",
       "  'authors': ['Dmitry Vetrov', 'Artem Sobolev'],\n",
       "  'published': '2019-05-08T18:38:51Z',\n",
       "  'updated': '2019-05-08T18:38:51Z',\n",
       "  'abstract': 'Variational Inference is a powerful tool in the Bayesian modeling toolkit,however, its effectiveness is determined by the expressivity of the utilizedvariational distributions in terms of their ability to match the true posteriordistribution. In turn, the expressivity of the variational family is largelylimited by the requirement of having a tractable density function. To overcomethis roadblock, we introduce a new family of variational upper bounds on amarginal log density in the case of hierarchical models (also known as latentvariable models). We then give an upper bound on the Kullback-Leiblerdivergence and derive a family of increasingly tighter variational lower boundson the otherwise intractable standard evidence lower bound for hierarchicalvariational distributions, enabling the use of more expressive approximateposteriors. We show that previously known methods, such as HierarchicalVariational Models, Semi-Implicit Variational Inference and DoublySemi-Implicit Variational Inference can be seen as special cases of theproposed approach, and empirically demonstrate superior performance of theproposed method in a set of experiments.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.03290v1'},\n",
       " 836: {'ID': 836,\n",
       "  'title': 'Training data-efficient image transformers &amp; distillation through  attention',\n",
       "  'authors': ['Matthijs Douze',\n",
       "   'Francisco Massa',\n",
       "   'Hervé Jégou',\n",
       "   'Alexandre Sablayrolles',\n",
       "   'Hugo Touvron',\n",
       "   'Matthieu Cord'],\n",
       "  'published': '2020-12-23T18:42:10Z',\n",
       "  'updated': '2021-01-15T15:52:50Z',\n",
       "  'abstract': 'Recently, neural networks purely based on attention were shown to addressimage understanding tasks such as image classification. However, these visualtransformers are pre-trained with hundreds of millions of images using anexpensive infrastructure, thereby limiting their adoption.  In this work, we produce a competitive convolution-free transformer bytraining on Imagenet only. We train them on a single computer in less than 3days. Our reference vision transformer (86M parameters) achieves top-1 accuracyof 83.1% (single-crop evaluation) on ImageNet with no external data.  More importantly, we introduce a teacher-student strategy specific totransformers. It relies on a distillation token ensuring that the studentlearns from the teacher through attention. We show the interest of thistoken-based distillation, especially when using a convnet as a teacher. Thisleads us to report results competitive with convnets for both Imagenet (wherewe obtain up to 85.2% accuracy) and when transferring to other tasks. We shareour code and models.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.12877v2'},\n",
       " 837: {'ID': 837,\n",
       "  'title': 'The Sensitivity of Counterfactual Fairness to Unmeasured Confounding',\n",
       "  'authors': ['Adrian Weller',\n",
       "   'Niki Kilbertus',\n",
       "   'Philip J. Ball',\n",
       "   'Matt J. Kusner',\n",
       "   'Ricardo Silva'],\n",
       "  'published': '2019-07-01T19:47:40Z',\n",
       "  'updated': '2019-07-01T19:47:40Z',\n",
       "  'abstract': 'Causal approaches to fairness have seen substantial recent interest, bothfrom the machine learning community and from wider parties interested inethical prediction algorithms. In no small part, this has been due to the factthat causal models allow one to simultaneously leverage data and expertknowledge to remove discriminatory effects from predictions. However, one ofthe primary assumptions in causal modeling is that you know the causal graph.This introduces a new opportunity for bias, caused by misspecifying the causalmodel. One common way for misspecification to occur is via unmeasuredconfounding: the true causal effect between variables is partially described byunobserved quantities. In this work we design tools to assess the sensitivityof fairness measures to this confounding for the popular class of non-linearadditive noise models (ANMs). Specifically, we give a procedure for computingthe maximum difference between two counterfactually fair predictors, where onehas become biased due to confounding. For the case of bivariate confounding ourtechnique can be swiftly computed via a sequence of closed-form updates. Formultivariate confounding we give an algorithm that can be efficiently solvedvia automatic differentiation. We demonstrate our new sensitivity analysistools in real-world fairness scenarios to assess the bias arising fromconfounding.',\n",
       "  'categories': ['cs.LG', 'cs.CY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1907.01040v1'},\n",
       " 838: {'ID': 838,\n",
       "  'title': 'HOPE-Net: A Graph-based Model for Hand-Object Pose Estimation',\n",
       "  'authors': ['Majid Mirbagheri',\n",
       "   'Bardia Doosti',\n",
       "   'David Crandall',\n",
       "   'Shujon Naha'],\n",
       "  'published': '2020-03-31T19:01:42Z',\n",
       "  'updated': '2020-03-31T19:01:42Z',\n",
       "  'abstract': 'Hand-object pose estimation (HOPE) aims to jointly detect the poses of both ahand and of a held object. In this paper, we propose a lightweight model calledHOPE-Net which jointly estimates hand and object pose in 2D and 3D inreal-time. Our network uses a cascade of two adaptive graph convolutionalneural networks, one to estimate 2D coordinates of the hand joints and objectcorners, followed by another to convert 2D coordinates to 3D. Our experimentsshow that through end-to-end training of the full network, we achieve betteraccuracy for both the 2D and 3D coordinate estimation problems. The proposed 2Dto 3D graph convolution-based model could be applied to other 3D landmarkdetection problems, where it is possible to first predict the 2D keypoints andthen transform them to 3D.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.00060v1'},\n",
       " 839: {'ID': 839,\n",
       "  'title': 'End-to-End Face Parsing via Interlinked Convolutional Neural Networks',\n",
       "  'authors': ['Xiaolin Hu', 'Zi Yin', 'Liang Tang', 'Valentin Yiu'],\n",
       "  'published': '2020-02-12T08:03:03Z',\n",
       "  'updated': '2020-06-23T19:27:52Z',\n",
       "  'abstract': 'Face parsing is an important computer vision task that requires accuratepixel segmentation of facial parts (such as eyes, nose, mouth, etc.), providinga basis for further face analysis, modification, and other applications.Interlinked Convolutional Neural Networks (iCNN) was proved to be an effectivetwo-stage model for face parsing. However, the original iCNN was trainedseparately in two stages, limiting its performance. To solve this problem, weintroduce a simple, end-to-end face parsing framework: STN-aidediCNN(STN-iCNN), which extends the iCNN by adding a Spatial Transformer Network(STN) between the two isolated stages. The STN-iCNN uses the STN to provide atrainable connection to the original two-stage iCNN pipeline, making end-to-endjoint training possible. Moreover, as a by-product, STN also provides moreprecise cropped parts than the original cropper. Due to these two advantages,our approach significantly improves the accuracy of the original model. Ourmodel achieved competitive performance on the Helen Dataset, the standard faceparsing dataset. It also achieved superior performance on CelebAMask-HQdataset, proving its good generalization. Our code has been released athttps://github.com/aod321/STN-iCNN.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.04831v2'},\n",
       " 840: {'ID': 840,\n",
       "  'title': 'Effective Modeling of Encoder-Decoder Architecture for Joint Entity and  Relation Extraction',\n",
       "  'authors': ['Hwee Tou Ng', 'Tapas Nayak'],\n",
       "  'published': '2019-11-22T06:52:21Z',\n",
       "  'updated': '2019-11-22T06:52:21Z',\n",
       "  'abstract': 'A relation tuple consists of two entities and the relation between them, andoften such tuples are found in unstructured text. There may be multiplerelation tuples present in a text and they may share one or both entities amongthem. Extracting such relation tuples from a sentence is a difficult task andsharing of entities or overlapping entities among the tuples makes it morechallenging. Most prior work adopted a pipeline approach where entities wereidentified first followed by finding the relations among them, thus missing theinteraction among the relation tuples in a sentence. In this paper, we proposetwo approaches to use encoder-decoder architecture for jointly extractingentities and relations. In the first approach, we propose a representationscheme for relation tuples which enables the decoder to generate one word at atime like machine translation models and still finds all the tuples present ina sentence with full entity names of different length and with overlappingentities. Next, we propose a pointer network-based decoding approach where anentire tuple is generated at every time step. Experiments on the publiclyavailable New York Times corpus show that our proposed approaches outperformprevious work and achieve significantly higher F1 scores.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.09886v1'},\n",
       " 841: {'ID': 841,\n",
       "  'title': 'Demystifying the MLPerf Benchmark Suite',\n",
       "  'authors': ['Lizy K. John',\n",
       "   'Snehil Verma',\n",
       "   'Eugene B. John',\n",
       "   'Ramesh Radhakrishnan',\n",
       "   'Qinzhe Wu',\n",
       "   'Gunjan Jha',\n",
       "   'Bagus Hanindhito'],\n",
       "  'published': '2019-08-24T20:55:10Z',\n",
       "  'updated': '2019-08-24T20:55:10Z',\n",
       "  'abstract': 'MLPerf, an emerging machine learning benchmark suite strives to cover a broadrange of applications of machine learning. We present a study on itscharacteristics and how the MLPerf benchmarks differ from some of the previousdeep learning benchmarks like DAWNBench and DeepBench. We find that applicationbenchmarks such as MLPerf (although rich in kernels) exhibit different featurescompared to kernel benchmarks such as DeepBench. MLPerf benchmark suitecontains a diverse set of models which allows unveiling various bottlenecks inthe system. Based on our findings, dedicated low latency interconnect betweenGPUs in multi-GPU systems is required for optimal distributed deep learningtraining. We also observe variation in scaling efficiency across the MLPerfmodels. The variation exhibited by the different models highlight theimportance of smart scheduling strategies for multi-GPU training. Anotherobservation is that CPU utilization increases with increase in number of GPUsused for training. Corroborating prior work we also observe and quantifyimprovements possible by compiler optimizations, mixed-precision training anduse of Tensor Cores.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.09207v1'},\n",
       " 842: {'ID': 842,\n",
       "  'title': 'Entropy-Based Modeling for Estimating Soft Errors Impact on Binarized  Neural Network Inference',\n",
       "  'authors': ['Arman Roohi',\n",
       "   'Yu Bi',\n",
       "   'Navid Khoshavi',\n",
       "   'Saman Sargolzaei',\n",
       "   'Connor Broyles'],\n",
       "  'published': '2020-04-10T16:10:24Z',\n",
       "  'updated': '2020-04-21T14:01:53Z',\n",
       "  'abstract': 'Over past years, the easy accessibility to the large scale datasets hassignificantly shifted the paradigm for developing highly accurate predictionmodels that are driven from Neural Network (NN). These models can bepotentially impacted by the radiation-induced transient faults that might leadto the gradual downgrade of the long-running expected NN inference accelerator.The crucial observation from our rigorous vulnerability assessment on the NNinference accelerator demonstrates that the weights and activation functionsare unevenly susceptible to both single-event upset (SEU) and multi-bit upset(MBU), especially in the first five layers of our selected convolution neuralnetwork. In this paper, we present the relatively-accurate statistical modelsto delineate the impact of both undertaken SEU and MBU across layers and pereach layer of the selected NN. These models can be used for evaluating theerror-resiliency magnitude of NN topology before adopting them in thesafety-critical applications.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.05089v2'},\n",
       " 843: {'ID': 843,\n",
       "  'title': 'Distance-aware Molecule Graph Attention Network for Drug-Target Binding  Affinity Prediction',\n",
       "  'authors': ['Jingbo Zhou',\n",
       "   'Shuangli Li',\n",
       "   'Tong Xu',\n",
       "   'Fan Wang',\n",
       "   'Liang Huang',\n",
       "   'Haoyi Xiong',\n",
       "   'Dejing Dou',\n",
       "   'Hui Xiong'],\n",
       "  'published': '2020-12-17T17:44:01Z',\n",
       "  'updated': '2020-12-17T17:44:01Z',\n",
       "  'abstract': 'Accurately predicting the binding affinity between drugs and proteins is anessential step for computational drug discovery. Since graph neural networks(GNNs) have demonstrated remarkable success in various graph-related tasks,GNNs have been considered as a promising tool to improve the binding affinityprediction in recent years. However, most of the existing GNN architectures canonly encode the topological graph structure of drugs and proteins withoutconsidering the relative spatial information among their atoms. Whereas,different from other graph datasets such as social networks and commonsenseknowledge graphs, the relative spatial position and chemical bonds among atomshave significant impacts on the binding affinity. To this end, in this paper,we propose a diStance-aware Molecule graph Attention Network (S-MAN) tailoredto drug-target binding affinity prediction. As a dedicated solution, we firstpropose a position encoding mechanism to integrate the topological structureand spatial position information into the constructed pocket-ligand graph.Moreover, we propose a novel edge-node hierarchical attentive aggregationstructure which has edge-level aggregation and node-level aggregation. Thehierarchical attentive aggregation can capture spatial dependencies amongatoms, as well as fuse the position-enhanced information with the capability ofdiscriminating multiple spatial relations among atoms. Finally, we conductextensive experiments on two standard datasets to demonstrate the effectivenessof S-MAN.',\n",
       "  'categories': ['q-bio.QM', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.09624v1'},\n",
       " 844: {'ID': 844,\n",
       "  'title': 'The Geometry of Deep Generative Image Models and its Applications',\n",
       "  'authors': ['Carlos R. Ponce', 'Binxu Wang'],\n",
       "  'published': '2021-01-15T07:57:33Z',\n",
       "  'updated': '2021-01-15T07:57:33Z',\n",
       "  'abstract': 'Generative adversarial networks (GANs) have emerged as a powerfulunsupervised method to model the statistical patterns of real-world data sets,such as natural images. These networks are trained to map random inputs intheir latent space to new samples representative of the learned data. However,the structure of the latent space is hard to intuit due to its highdimensionality and the non-linearity of the generator, which limits theusefulness of the models. Understanding the latent space requires a way toidentify input codes for existing real-world images (inversion), and a way toidentify directions with known image transformations (interpretability). Here,we use a geometric framework to address both issues simultaneously. We developan architecture-agnostic method to compute the Riemannian metric of the imagemanifold created by GANs. The eigen-decomposition of the metric isolates axesthat account for different levels of image variability. An empirical analysisof several pretrained GANs shows that image variation around each position isconcentrated along surprisingly few major axes (the space is highlyanisotropic) and the directions that create this large variation are similar atdifferent positions in the space (the space is homogeneous). We show that manyof the top eigenvectors correspond to interpretable transforms in the imagespace, with a substantial part of eigenspace corresponding to minor transformswhich could be compressed out. This geometric understanding unifies keyprevious results related to GAN interpretability. We show that the use of thismetric allows for more efficient optimization in the latent space (e.g. GANinversion) and facilitates unsupervised discovery of interpretable axes. Ourresults illustrate that defining the geometry of the GAN image manifold canserve as a general framework for understanding GANs.',\n",
       "  'categories': ['cs.LG',\n",
       "   'cs.NA',\n",
       "   'cs.NE',\n",
       "   'math.NA',\n",
       "   'I.2.10; I.3.3; I.3.5; G.1.4'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.06006v1'},\n",
       " 845: {'ID': 845,\n",
       "  'title': 'Towards Stable Adversarial Feature Learning for LiDAR based Loop Closure  Detection',\n",
       "  'authors': ['Haibo Luo',\n",
       "   'Lingyun Xu',\n",
       "   'Peng Yin',\n",
       "   'Jianda Han',\n",
       "   'Yunhui Liu'],\n",
       "  'published': '2017-11-21T07:33:30Z',\n",
       "  'updated': '2017-11-21T07:33:30Z',\n",
       "  'abstract': 'Stable feature extraction is the key for the Loop closure detection (LCD)task in the simultaneously localization and mapping (SLAM) framework. In ourpaper, the feature extraction is operated by using a generative adversarialnetworks (GANs) based unsupervised learning. GANs are powerful generativemodels, however, GANs based adversarial learning suffers from traininginstability. We find that the data-code joint distribution in the adversariallearning is a more complex manifold than in the original GANs. And the lossfunction that drive the attractive force between synthesis and targetdistributions is unable for efficient latent code learning for LCD task. Torelieve this problem, we combines the original adversarial learning with aninner cycle restriction module and a side updating module. To our bestknowledge, we are the first to extract the adversarial features from the lightdetection and ranging (LiDAR) based inputs, which is invariant to the changescaused by illumination and appearance as in the visual inputs. We use the KITTIodometry datasets to investigate the performance of our method. The extensiveexperiments results shows that, with the same LiDAR projection maps, theproposed features are more stable in training, and could significantly improvethe robustness on viewpoints differences than other state-of-art methods.',\n",
       "  'categories': ['cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.07659v1'},\n",
       " 846: {'ID': 846,\n",
       "  'title': 'Larq Compute Engine: Design, Benchmark, and Deploy State-of-the-Art  Binarized Neural Networks',\n",
       "  'authors': ['Lukas Geiger',\n",
       "   'Koen Helwegen',\n",
       "   'Jelmer Neeven',\n",
       "   'Adam Hillier',\n",
       "   'Tim de Bruin',\n",
       "   'Tom Bannink',\n",
       "   'Leon Overweel'],\n",
       "  'published': '2020-11-18T16:56:14Z',\n",
       "  'updated': '2020-11-18T16:56:14Z',\n",
       "  'abstract': \"We introduce Larq Compute Engine, the world's fastest Binarized NeuralNetwork (BNN) inference engine, and use this framework to investigate severalimportant questions about the efficiency of BNNs and to design a newstate-of-the-art BNN architecture. LCE provides highly optimizedimplementations of binary operations and accelerates binary convolutions by 8.5- 18.5x compared to their full-precision counterparts on Pixel 1 phones. LCE'sintegration with Larq and a sophisticated MLIR-based converter allow users tomove smoothly from training to deployment. By extending TensorFlow andTensorFlow Lite, LCE supports models which combine binary and full-precisionlayers, and can be easily integrated into existing applications. Using LCE, weanalyze the performance of existing BNN computer vision architectures anddevelop QuickNet, a simple, easy-to-reproduce BNN that outperforms existingbinary networks in terms of latency and accuracy on ImageNet. Furthermore, weinvestigate the impact of full-precision shortcuts and the relationship betweennumber of MACs and model latency. We are convinced that empirical performanceshould drive BNN architecture design and hope this work will facilitate othersto design, benchmark and deploy binary models.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.09398v1'},\n",
       " 847: {'ID': 847,\n",
       "  'title': 'Iterative Reinforcement Learning Based Design of Dynamic Locomotion  Skills for Cassie',\n",
       "  'authors': ['Michiel van de Panne',\n",
       "   'Pedro Morais',\n",
       "   'Zhaoming Xie',\n",
       "   'Jeremy Dao',\n",
       "   'Patrick Clary',\n",
       "   'Jonathan Hurst'],\n",
       "  'published': '2019-03-22T14:48:40Z',\n",
       "  'updated': '2019-03-22T14:48:40Z',\n",
       "  'abstract': 'Deep reinforcement learning (DRL) is a promising approach for developinglegged locomotion skills. However, the iterative design process that isinevitable in practice is poorly supported by the default methodology. It isdifficult to predict the outcomes of changes made to the reward functions,policy architectures, and the set of tasks being trained on. In this paper, wepropose a practical method that allows the reward function to be fullyredefined on each successive design iteration while limiting the deviation fromthe previous iteration. We characterize policies via sets of DeterministicAction Stochastic State (DASS) tuples, which represent the deterministic policystate-action pairs as sampled from the states visited by the trained stochasticpolicy. New policies are trained using a policy gradient algorithm which thenmixes RL-based policy gradients with gradient updates defined by the DASStuples. The tuples also allow for robust policy distillation to new networkarchitectures. We demonstrate the effectiveness of this iterative-designapproach on the bipedal robot Cassie, achieving stable walking with differentgait styles at various speeds. We demonstrate the successful transfer ofpolicies learned in simulation to the physical robot without any dynamicsrandomization, and that variable-speed walking policies for the physical robotcan be represented by a small dataset of 5-10k tuples.',\n",
       "  'categories': ['cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.09537v1'},\n",
       " 848: {'ID': 848,\n",
       "  'title': 'Revisiting Reweighted Wake-Sleep for Models with Stochastic Control Flow',\n",
       "  'authors': ['Yee Whye Teh',\n",
       "   'N. Siddharth',\n",
       "   'Frank Wood',\n",
       "   'Tuan Anh Le',\n",
       "   'Adam R. Kosiorek'],\n",
       "  'published': '2018-05-26T12:16:46Z',\n",
       "  'updated': '2019-09-16T13:04:45Z',\n",
       "  'abstract': 'Stochastic control-flow models (SCFMs) are a class of generative models thatinvolve branching on choices from discrete random variables. Amortizedgradient-based learning of SCFMs is challenging as most approaches targetingdiscrete variables rely on their continuous relaxations---which can beintractable in SCFMs, as branching on relaxations requires evaluating all(exponentially many) branching paths. Tractable alternatives mainly combineREINFORCE with complex control-variate schemes to improve the variance of naiveestimators. Here, we revisit the reweighted wake-sleep (RWS) (Bornschein andBengio, 2015) algorithm, and through extensive evaluations, show that itoutperforms current state-of-the-art methods in learning SCFMs. Further, incontrast to the importance weighted autoencoder, we observe that RWS learnsbetter models and inference networks with increasing numbers of particles. Ourresults suggest that RWS is a competitive, often preferable, alternative forlearning SCFMs.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.10469v2'},\n",
       " 849: {'ID': 849,\n",
       "  'title': 'Quantile QT-Opt for Risk-Aware Vision-Based Robotic Grasping',\n",
       "  'authors': ['Mrinal Kalakrishnan',\n",
       "   'Adrian Li',\n",
       "   'Cristian Bodnar',\n",
       "   'Karol Hausman',\n",
       "   'Peter Pastor'],\n",
       "  'published': '2019-10-01T22:12:00Z',\n",
       "  'updated': '2020-06-04T12:56:16Z',\n",
       "  'abstract': 'The distributional perspective on reinforcement learning (RL) has given riseto a series of successful Q-learning algorithms, resulting in state-of-the-artperformance in arcade game environments. However, it has not yet been analyzedhow these findings from a discrete setting translate to complex practicalapplications characterized by noisy, high dimensional and continuousstate-action spaces. In this work, we propose Quantile QT-Opt (Q2-Opt), adistributional variant of the recently introduced distributed Q-learningalgorithm for continuous domains, and examine its behaviour in a series ofsimulated and real vision-based robotic grasping tasks. The absence of an actorin Q2-Opt allows us to directly draw a parallel to the previous discreteexperiments in the literature without the additional complexities induced by anactor-critic architecture. We demonstrate that Q2-Opt achieves a superiorvision-based object grasping success rate, while also being more sampleefficient. The distributional formulation also allows us to experiment withvarious risk distortion metrics that give us an indication of how robots canconcretely manage risk in practice using a Deep RL control policy. As anadditional contribution, we perform batch RL experiments in our virtualenvironment and compare them with the latest findings from discrete settings.Surprisingly, we find that the previous batch RL findings from the literatureobtained on arcade game environments do not generalise to our setup.',\n",
       "  'categories': ['cs.RO', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.02787v3'},\n",
       " 850: {'ID': 850,\n",
       "  'title': 'Towards automated feature engineering for credit card fraud detection  using multi-perspective HMMs',\n",
       "  'authors': ['Michael Granitzer',\n",
       "   'Yvan Lucas',\n",
       "   'Sylvie Calabretto',\n",
       "   'Léa Laporte',\n",
       "   'Liyun He-Guelton',\n",
       "   'Pierre-Edouard Portier',\n",
       "   'Olivier Caelen'],\n",
       "  'published': '2019-09-03T13:53:35Z',\n",
       "  'updated': '2019-09-03T13:53:35Z',\n",
       "  'abstract': \"Machine learning and data mining techniques have been used extensively inorder to detect credit card frauds. However, most studies consider credit cardtransactions as isolated events and not as a sequence of transactions. In thisframework, we model a sequence of credit card transactions from three differentperspectives, namely (i) The sequence contains or doesn't contain a fraud (ii)The sequence is obtained by fixing the card-holder or the payment terminal(iii) It is a sequence of spent amount or of elapsed time between the currentand previous transactions. Combinations of the three binary perspectives giveeight sets of sequences from the (training) set of transactions. Each one ofthese sequences is modelled with a Hidden Markov Model (HMM). Each HMMassociates a likelihood to a transaction given its sequence of previoustransactions. These likelihoods are used as additional features in a RandomForest classifier for fraud detection. Our multiple perspectives HMM-basedapproach offers automated feature engineering to model temporal correlations soas to improve the effectiveness of the classification task and allows for anincrease in the detection of fraudulent transactions when combined with thestate of the art expert based feature engineering strategy for credit cardfraud detection. In extension to previous works, we show that this approachgoes beyond ecommerce transactions and provides a robust feature engineeringover different datasets, hyperparameters and classifiers. Moreover, we comparestrategies to deal with structural missing values.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.01185v1'},\n",
       " 851: {'ID': 851,\n",
       "  'title': 'Value Iteration Networks on Multiple Levels of Abstraction',\n",
       "  'authors': ['Tobias Klamt', 'Daniel Schleich', 'Sven Behnke'],\n",
       "  'published': '2019-05-27T09:17:33Z',\n",
       "  'updated': '2019-07-01T09:11:43Z',\n",
       "  'abstract': 'Learning-based methods are promising to plan robot motion without performingextensive search, which is needed by many non-learning approaches. Recently,Value Iteration Networks (VINs) received much interest since---in contrast tostandard CNN-based architectures---they learn goal-directed behaviors whichgeneralize well to unseen domains. However, VINs are restricted to small andlow-dimensional domains, limiting their applicability to real-world planningproblems.  To address this issue, we propose to extend VINs to representations withmultiple levels of abstraction. While the vicinity of the robot is representedin sufficient detail, the representation gets spatially coarser with increasingdistance from the robot. The information loss caused by the decreasingresolution is compensated by increasing the number of features representing acell. We show that our approach is capable of solving significantly larger 2Dgrid world planning tasks than the original VIN implementation. In contrast toa multiresolution coarse-to-fine VIN implementation which does not employadditional descriptive features, our approach is capable of solving challengingenvironments, which demonstrates that the proposed method learns to encodeuseful information in the additional features. As an application for solvingreal-world planning tasks, we successfully employ our method to planomnidirectional driving for a search-and-rescue robot in cluttered terrain.',\n",
       "  'categories': ['cs.RO', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.11068v2'},\n",
       " 852: {'ID': 852,\n",
       "  'title': 'Towards the cycle structures in complex network: A new perspective',\n",
       "  'authors': ['Linyuan Lü', 'Tianlong Fan', 'Dinghua Shi'],\n",
       "  'published': '2019-03-04T17:47:24Z',\n",
       "  'updated': '2019-03-12T02:05:23Z',\n",
       "  'abstract': \"Stars and cycles are basic structures in network construction. The former hasbeen well studied in network analysis, while the latter attracted rareattention. A node together with its neighbors constitute a neighborhoodstar-structure where the basic assumption is two nodes interact through theirdirect connection. A cycle is a closed loop with many nodes who can influenceeach other even without direct connection. Here we show their difference andrelationship in understanding network structure and function. We define twocycle-based node characteristics, namely cycle number and cycle ratio, whichcan be used to measure a node's importance. Numerical analyses on six disparatereal networks suggest that the nodes with higher cycle ratio are more importantto network connectivity, while cycle number can better quantify a nodeinfluence of cycle-based spreading than the common star-based nodecentralities. We also find that an ordinary network can be converted into ahypernetwork by considering its basic cycles as hyperedges, meanwhile, a newmatrix called the cycle number matrix is captured. We hope that this paper canopen a new direction of understanding both local and global structures ofnetwork and its function.\",\n",
       "  'categories': ['physics.soc-ph', 'physics.data-an'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.01397v3'},\n",
       " 853: {'ID': 853,\n",
       "  'title': 'Multiple perspectives HMM-based feature engineering for credit card  fraud detection',\n",
       "  'authors': ['Michael Granitzer',\n",
       "   'Yvan Lucas',\n",
       "   'Sylvie Calabretto',\n",
       "   'Léa Laporte',\n",
       "   'Liyun He-Guelton',\n",
       "   'Pierre-Edouard Portier',\n",
       "   'Olivier Caelen'],\n",
       "  'published': '2019-05-15T15:29:49Z',\n",
       "  'updated': '2019-05-15T15:29:49Z',\n",
       "  'abstract': 'Machine learning and data mining techniques have been used extensively inorder to detect credit card frauds. However, most studies consider credit cardtransactions as isolated events and not as a sequence of transactions.  In this article, we model a sequence of credit card transactions from threedifferent perspectives, namely (i) does the sequence contain a Fraud? (ii) Isthe sequence obtained by fixing the card-holder or the payment terminal? (iii)Is it a sequence of spent amount or of elapsed time between the current andprevious transactions? Combinations of the three binary perspectives give eightsets of sequences from the (training) set of transactions. Each one of thesesets is modelled with a Hidden Markov Model (HMM). Each HMM associates alikelihood to a transaction given its sequence of previous transactions. Theselikelihoods are used as additional features in a Random Forest classifier forfraud detection. This multiple perspectives HMM-based approach enables anautomatic feature engineering in order to model the sequential properties ofthe dataset with respect to the classification task. This strategy allows for a15% increase in the precision-recall AUC compared to the state of the artfeature engineering strategy for credit card fraud detection.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.06247v1'},\n",
       " 854: {'ID': 854,\n",
       "  'title': 'Knowledge Grounded Conversational Symptom Detection with Graph Memory  Networks',\n",
       "  'authors': ['James Glass', 'Shang-Wen Li', 'Hongyin Luo'],\n",
       "  'published': '2021-01-24T18:50:16Z',\n",
       "  'updated': '2021-01-24T18:50:16Z',\n",
       "  'abstract': \"In this work, we propose a novel goal-oriented dialog task, automatic symptomdetection. We build a system that can interact with patients through dialog todetect and collect clinical symptoms automatically, which can save a doctor'stime interviewing the patient. Given a set of explicit symptoms provided by thepatient to initiate a dialog for diagnosing, the system is trained to collectimplicit symptoms by asking questions, in order to collect more information formaking an accurate diagnosis. After getting the reply from the patient for eachquestion, the system also decides whether current information is enough for ahuman doctor to make a diagnosis. To achieve this goal, we propose two neuralmodels and a training pipeline for the multi-step reasoning task. We also builda knowledge graph as additional inputs to further improve model performance.Experiments show that our model significantly outperforms the baseline by 4%,discovering 67% of implicit symptoms on average with a limited number ofquestions.\",\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.09773v1'},\n",
       " 855: {'ID': 855,\n",
       "  'title': 'Distilling Policy Distillation',\n",
       "  'authors': ['Wojciech Marian Czarnecki',\n",
       "   'Simon Osindero',\n",
       "   'Grzegorz Swirszcz',\n",
       "   'Max Jaderberg',\n",
       "   'Siddhant M. Jayakumar',\n",
       "   'Razvan Pascanu'],\n",
       "  'published': '2019-02-06T14:01:34Z',\n",
       "  'updated': '2019-02-06T14:01:34Z',\n",
       "  'abstract': 'The transfer of knowledge from one policy to another is an important tool inDeep Reinforcement Learning. This process, referred to as distillation, hasbeen used to great success, for example, by enhancing the optimisation ofagents, leading to stronger performance faster, on harder domains [26, 32, 5,8]. Despite the widespread use and conceptual simplicity of distillation, manydifferent formulations are used in practice, and the subtle variations betweenthem can often drastically change the performance and the resulting objectivethat is being optimised. In this work, we rigorously explore the entirelandscape of policy distillation, comparing the motivations and strengths ofeach variant through theoretical and empirical analysis. Our results point tothree distillation techniques, that are preferred depending on specifics of thetask. Specifically a newly proposed expected entropy regularised distillationallows for quicker learning in a wide range of situations, while stillguaranteeing convergence.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.02186v1'},\n",
       " 856: {'ID': 856,\n",
       "  'title': 'GraphNAS: Graph Neural Architecture Search with Reinforcement Learning',\n",
       "  'authors': ['Peng Zhang', 'Yue Hu', 'Chuan Zhou', 'Hong Yang', 'Yang Gao'],\n",
       "  'published': '2019-04-22T07:13:10Z',\n",
       "  'updated': '2019-08-20T03:00:40Z',\n",
       "  'abstract': 'Graph Neural Networks (GNNs) have been popularly used for analyzingnon-Euclidean data such as social network data and biological data. Despitetheir success, the design of graph neural networks requires a lot of manualwork and domain knowledge. In this paper, we propose a Graph NeuralArchitecture Search method (GraphNAS for short) that enables automatic searchof the best graph neural architecture based on reinforcement learning.Specifically, GraphNAS first uses a recurrent network to generatevariable-length strings that describe the architectures of graph neuralnetworks, and then trains the recurrent network with reinforcement learning tomaximize the expected accuracy of the generated architectures on a validationdata set. Extensive experimental results on node classification tasks in bothtransductive and inductive learning settings demonstrate that GraphNAS canachieve consistently better performance on the Cora, Citeseer, Pubmed citationnetwork, and protein-protein interaction network. On node classification tasks,GraphNAS can design a novel network architecture that rivals the besthuman-invented architecture in terms of test set accuracy.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.09981v2'},\n",
       " 857: {'ID': 857,\n",
       "  'title': 'Reduced-order Model for Fluid Flows via Neural Ordinary Differential  Equations',\n",
       "  'authors': ['Carlos J. G. Rojas', 'Andreas Dengel', 'Mateus Dias Ribeiro'],\n",
       "  'published': '2021-02-03T19:33:51Z',\n",
       "  'updated': '2021-02-03T19:33:51Z',\n",
       "  'abstract': 'Reduced order models play an important role in the design, optimization andcontrol of dynamical systems. In recent years, there has been an increasinginterest in the application of data-driven techniques for model reduction thatcan decrease the computational burden of numerical solutions, while preservingthe most important features of complex physical problems. In this paper, we usethe proper orthogonal decomposition to reduce the dimensionality of the modeland introduce a novel generative neural ODE (NODE) architecture to forecast thebehavior of the temporal coefficients. With this methodology, we replace theclassical Galerkin projection with an architecture characterized by the use ofa continuous latent space. We exemplify the methodology on the dynamics of theVon Karman vortex street of the flow past a cylinder generated by a Large-eddySimulation (LES)-based code. We compare the NODE methodology with an LSTMbaseline to assess the extrapolation capabilities of the generative model andpresent some qualitative evaluations of the flow reconstructions.',\n",
       "  'categories': ['physics.flu-dyn', 'physics.comp-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.02248v1'},\n",
       " 858: {'ID': 858,\n",
       "  'title': 'Regularizing Activation Distribution for Training Binarized Deep  Networks',\n",
       "  'authors': ['Diana Marculescu', 'Ruizhou Ding', 'Zeye Liu', 'Ting-Wu Chin'],\n",
       "  'published': '2019-04-04T23:20:09Z',\n",
       "  'updated': '2019-04-04T23:20:09Z',\n",
       "  'abstract': \"Binarized Neural Networks (BNNs) can significantly reduce the inferencelatency and energy consumption in resource-constrained devices due to theirpure-logical computation and fewer memory accesses. However, training BNNs isdifficult since the activation flow encounters degeneration, saturation, andgradient mismatch problems. Prior work alleviates these issues by increasingactivation bits and adding floating-point scaling factors, thereby sacrificingBNN's energy efficiency. In this paper, we propose to use distribution loss toexplicitly regularize the activation flow, and develop a framework tosystematically formulate the loss. Our experiments show that the distributionloss can consistently improve the accuracy of BNNs without losing their energybenefits. Moreover, equipped with the proposed regularization, BNN training isshown to be robust to the selection of hyper-parameters including optimizer andlearning rate.\",\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.02823v1'},\n",
       " 859: {'ID': 859,\n",
       "  'title': 'Unsupervised Multi-Modal Image Registration via Geometry Preserving  Image-to-Image Translation',\n",
       "  'authors': ['Daniel Cohen-Or',\n",
       "   'Amit Bermano',\n",
       "   'Moab Arar',\n",
       "   'Ilya Leizerson',\n",
       "   'Yiftach Ginger',\n",
       "   'Dov Danon'],\n",
       "  'published': '2020-03-18T07:21:09Z',\n",
       "  'updated': '2020-03-18T07:21:09Z',\n",
       "  'abstract': 'Many applications, such as autonomous driving, heavily rely on multi-modaldata where spatial alignment between the modalities is required. Mostmulti-modal registration methods struggle computing the spatial correspondencebetween the images using prevalent cross-modality similarity measures. In thiswork, we bypass the difficulties of developing cross-modality similaritymeasures, by training an image-to-image translation network on the two inputmodalities. This learned translation allows training the registration networkusing simple and reliable mono-modality metrics. We perform multi-modalregistration using two networks - a spatial transformation network and atranslation network. We show that by encouraging our translation network to begeometry preserving, we manage to train an accurate spatial transformationnetwork. Compared to state-of-the-art multi-modal methods our presented methodis unsupervised, requiring no pairs of aligned modalities for training, and canbe adapted to any pair of modalities. We evaluate our method quantitatively andqualitatively on commercial datasets, showing that it performs well on severalmodalities and achieves accurate alignment.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.08073v1'},\n",
       " 860: {'ID': 860,\n",
       "  'title': 'Mixed Precision Training With 8-bit Floating Point',\n",
       "  'authors': ['Naveen Mellempudi',\n",
       "   'Sudarshan Srinivasan',\n",
       "   'Dipankar Das',\n",
       "   'Bharat Kaul'],\n",
       "  'published': '2019-05-29T11:25:09Z',\n",
       "  'updated': '2019-05-29T11:25:09Z',\n",
       "  'abstract': 'Reduced precision computation for deep neural networks is one of the keyareas addressing the widening compute gap driven by an exponential growth inmodel size. In recent years, deep learning training has largely migrated to16-bit precision, with significant gains in performance and energy efficiency.However, attempts to train DNNs at 8-bit precision have met with significantchallenges because of the higher precision and dynamic range requirements ofback-propagation. In this paper, we propose a method to train deep neuralnetworks using 8-bit floating point representation for weights, activations,errors, and gradients. In addition to reducing compute precision, we alsoreduced the precision requirements for the master copy of weights from 32-bitto 16-bit. We demonstrate state-of-the-art accuracy across multiple data sets(imagenet-1K, WMT16) and a broader set of workloads (Resnet-18/34/50, GNMT,Transformer) than previously reported. We propose an enhanced loss scalingmethod to augment the reduced subnormal range of 8-bit floating point forimproved error propagation. We also examine the impact of quantization noise ongeneralization and propose a stochastic rounding technique to address gradientnoise. As a result of applying all these techniques, we report slightly highervalidation accuracy compared to full precision baseline.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.12334v1'},\n",
       " 861: {'ID': 861,\n",
       "  'title': 'Neural networks for Anatomical Therapeutic Chemical (ATC)',\n",
       "  'authors': ['Loris Nanni', 'Alessandra Lumini', 'Sheryl Brahnam'],\n",
       "  'published': '2021-01-22T19:49:47Z',\n",
       "  'updated': '2021-01-22T19:49:47Z',\n",
       "  'abstract': \"Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification isa critical and highly competitive area of research in bioinformatics because ofits potential for expediting drug develop-ment and research. Predicting anunknown compound's therapeutic and chemical characteristics ac-cording to howthese characteristics affect multiple organs/systems makes automatic ATCclassifica-tion a challenging multi-label problem. Results: In this work, wepropose combining multiple multi-label classifiers trained on distinct sets offeatures, including sets extracted from a Bidirectional Long Short-Term MemoryNetwork (BiLSTM). Experiments demonstrate the power of this approach, which isshown to outperform the best methods reported in the literature, including thestate-of-the-art developed by the fast.ai research group. Availability: Allsource code developed for this study is available athttps://github.com/LorisNanni. Contact: loris.nanni@unipd.it\",\n",
       "  'categories': ['q-bio.QM', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.11713v1'},\n",
       " 862: {'ID': 862,\n",
       "  'title': 'Deep Learning for Optoelectronic Properties of Organic Semiconductors',\n",
       "  'authors': ['Chengqiang Lu',\n",
       "   'Liang Shi',\n",
       "   'Shengyu Zhang',\n",
       "   'Chang-Yu Hsieh',\n",
       "   'Qi Liu',\n",
       "   'Chee-Kong Lee',\n",
       "   'Qiming Sun'],\n",
       "  'published': '2019-10-29T21:42:02Z',\n",
       "  'updated': '2019-10-29T21:42:02Z',\n",
       "  'abstract': 'Atomistic modeling of energetic disorder in organic semiconductors (OSCs) andits effects on the optoelectronic properties of OSCs requires a large number ofexcited-state electronic-structure calculations, a computationally dauntingtask for many OSC applications. In this work, we advocate the use of deeplearning to address this challenge and demonstrate that state-of-the-art deepneural networks (DNNs) are capable of predicting the electronic properties ofOSCs at an accuracy comparable with the quantum chemistry methods used forgenerating training data. We extensively investigate the performances of fourrecent DNNs (deep tensor neural network, SchNet, message passing neuralnetwork, and multilevel graph convolutional neural network) in predictingvarious electronic properties of an important class of OSCs, i.e.,oligothiophenes (OTs), including their HOMO and LUMO energies, excited-stateenergies and associated transition dipole moments. We find that SchNet showsthe best performance for OTs of different sizes (from bithiophene tosexithiophene), achieving average prediction errors in the range of 20-80meVcompared to the results from (time-dependent) density functional theory. Weshow that SchNet also consistently outperforms shallow feed-forward neuralnetworks, especially in difficult cases with large molecules or limitedtraining data. We further show that SchNet could predict the transition dipolemoment accurately, a task previously known to be difficult for feed-forwardneural networks, and we ascribe the relatively large errors in transitiondipole prediction seen for some OT configurations to the charge-transfercharacter of their excited states. Finally, we demonstrate the effectiveness ofSchNet by modeling the UV-Vis absorption spectra of OTs in dichloromethane anda good agreement is observed between the calculated and experimental spectra.',\n",
       "  'categories': ['physics.chem-ph', 'cond-mat.mtrl-sci', 'physics.comp-ph'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.13551v1'},\n",
       " 863: {'ID': 863,\n",
       "  'title': 'PS-DeVCEM: Pathology-sensitive deep learning model for video capsule  endoscopy based on weakly labeled data',\n",
       "  'authors': ['M. Pedersen',\n",
       "   'S. Yildirim',\n",
       "   'Ø Hovde',\n",
       "   'A. Mohammed',\n",
       "   'I. Farup'],\n",
       "  'published': '2020-11-22T15:33:37Z',\n",
       "  'updated': '2020-11-22T15:33:37Z',\n",
       "  'abstract': \"We propose a novel pathology-sensitive deep learning model (PS-DeVCEM) forframe-level anomaly detection and multi-label classification of different colondiseases in video capsule endoscopy (VCE) data. Our proposed model is capableof coping with the key challenge of colon apparent heterogeneity caused byseveral types of diseases. Our model is driven by attention-based deep multipleinstance learning and is trained end-to-end on weakly labeled data using videolabels instead of detailed frame-by-frame annotation. The spatial and temporalfeatures are obtained through ResNet50 and residual Long short-term memory(residual LSTM) blocks, respectively. Additionally, the learned temporalattention module provides the importance of each frame to the final labelprediction. Moreover, we developed a self-supervision method to maximize thedistance between classes of pathologies. We demonstrate through qualitative andquantitative experiments that our proposed weakly supervised learning modelgives superior precision and F1-score reaching, 61.6% and 55.1%, as compared tothree state-of-the-art video analysis methods respectively. We also show ourmodel's ability to temporally localize frames with pathologies, without frameannotation information during training. Furthermore, we collected and annotatedthe first and largest VCE dataset with only video labels. The dataset contains455 short video segments with 28,304 frames and 14 classes of colorectaldiseases and artifacts. Dataset and code supporting this publication will bemade available on our home page.\",\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.12957v1'},\n",
       " 864: {'ID': 864,\n",
       "  'title': 'Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural  Architecture Search',\n",
       "  'authors': ['Houwen Peng',\n",
       "   'Hongyuan Yu',\n",
       "   'Qi Li',\n",
       "   'Jianlong Fu',\n",
       "   'Jing Liao',\n",
       "   'Hao Du'],\n",
       "  'published': '2020-10-29T17:55:05Z',\n",
       "  'updated': '2020-11-24T15:37:37Z',\n",
       "  'abstract': 'One-shot weight sharing methods have recently drawn great attention in neuralarchitecture search due to high efficiency and competitive performance.However, weight sharing across models has an inherent deficiency, i.e.,insufficient training of subnetworks in hypernetworks. To alleviate thisproblem, we present a simple yet effective architecture distillation method.The central idea is that subnetworks can learn collaboratively and teach eachother throughout the training process, aiming to boost the convergence ofindividual models. We introduce the concept of prioritized path, which refersto the architecture candidates exhibiting superior performance during training.Distilling knowledge from the prioritized paths is able to boost the trainingof subnetworks. Since the prioritized paths are changed on the fly depending ontheir performance and complexity, the final obtained paths are the cream of thecrop. We directly select the most promising one from the prioritized paths asthe final architecture, without using other complex search methods, such asreinforcement learning or evolution algorithms. The experiments on ImageNetverify such path distillation method can improve the convergence ratio andperformance of the hypernetwork, as well as boosting the training ofsubnetworks. The discovered architectures achieve superior performance comparedto the recent MobileNetV3 and EfficientNet families under aligned settings.Moreover, the experiments on object detection and more challenging search spaceshow the generality and robustness of the proposed method. Code and models areavailable at https://github.com/microsoft/cream.git.',\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.15821v2'},\n",
       " 865: {'ID': 865,\n",
       "  'title': 'A Computing Kernel for Network Binarization on PyTorch',\n",
       "  'authors': ['Marco Pedersoli', 'Xianda Xu'],\n",
       "  'published': '2019-11-11T05:26:04Z',\n",
       "  'updated': '2019-11-11T05:26:04Z',\n",
       "  'abstract': 'Deep Neural Networks have now achieved state-of-the-art results in a widerange of tasks including image classification, object detection and so on.However, they are both computation consuming and memory intensive, making themdifficult to deploy on low-power devices. Network binarization is one of theexisting effective techniques for model compression and acceleration, but thereis no computing kernel yet to support it on PyTorch. In this paper we developeda computing kernel supporting 1-bit xnor and bitcount computation on PyTorch.Experimental results show that our kernel could accelerate the inference of thebinarized neural network by 3 times in GPU and by 4.5 times in CPU comparedwith the control group.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.04477v1'},\n",
       " 866: {'ID': 866,\n",
       "  'title': 'DeepSphere: towards an equivariant graph-based spherical CNN',\n",
       "  'authors': ['Tomasz Kacprzak',\n",
       "   'Michaël Defferrard',\n",
       "   'Nathanaël Perraudin',\n",
       "   'Raphael Sgier'],\n",
       "  'published': '2019-04-08T18:01:04Z',\n",
       "  'updated': '2019-04-08T18:01:04Z',\n",
       "  'abstract': 'Spherical data is found in many applications. By modeling the discretizedsphere as a graph, we can accommodate non-uniformly distributed, partial, andchanging samplings. Moreover, graph convolutions are computationally moreefficient than spherical convolutions. As equivariance is desired to exploitrotational symmetries, we discuss how to approach rotation equivariance usingthe graph neural network introduced in Defferrard et al. (2016). Experimentsshow good performance on rotation-invariant learning problems. Code andexamples are available at https://github.com/SwissDataScienceCenter/DeepSphere',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.05146v1'},\n",
       " 867: {'ID': 867,\n",
       "  'title': 'Hierarchical Attention-Based Recurrent Highway Networks for Time Series  Prediction',\n",
       "  'authors': ['Jian Liu',\n",
       "   'Qiang Du',\n",
       "   'Yunzhe Tao',\n",
       "   'Lin Ma',\n",
       "   'Weizhong Zhang',\n",
       "   'Wei Liu'],\n",
       "  'published': '2018-06-02T18:46:50Z',\n",
       "  'updated': '2018-06-02T18:46:50Z',\n",
       "  'abstract': 'Time series prediction has been studied in a variety of domains. However, itis still challenging to predict future series given historical observations andpast exogenous data. Existing methods either fail to consider the interactionsamong different components of exogenous variables which may affect theprediction accuracy, or cannot model the correlations between exogenous dataand target data. Besides, the inherent temporal dynamics of exogenous data arealso related to the target series prediction, and thus should be considered aswell. To address these issues, we propose an end-to-end deep learning model,i.e., Hierarchical attention-based Recurrent Highway Network (HRHN), whichincorporates spatio-temporal feature extraction of exogenous variables andtemporal dynamics modeling of target variables into a single framework.Moreover, by introducing the hierarchical attention mechanism, HRHN canadaptively select the relevant exogenous features in different semantic levels.We carry out comprehensive empirical evaluations with various methods overseveral datasets, and show that HRHN outperforms the state of the arts in timeseries prediction, especially in capturing sudden changes and suddenoscillations of time series.',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.00685v1'},\n",
       " 868: {'ID': 868,\n",
       "  'title': 'Space-Time Domain Tensor Neural Networks: An Application on Human Pose  Classification',\n",
       "  'authors': ['Athanasios Voulodimos',\n",
       "   'Anastasios Doulamis',\n",
       "   'Nikolaos Bakalos',\n",
       "   'Konstantinos Makantasis',\n",
       "   'Nikolaos Doulamis'],\n",
       "  'published': '2020-04-17T10:20:56Z',\n",
       "  'updated': '2020-10-18T17:52:46Z',\n",
       "  'abstract': 'Recent advances in sensing technologies require the design and development ofpattern recognition models capable of processing spatiotemporal dataefficiently. In this study, we propose a spatially and temporally awaretensor-based neural network for human pose classification usingthree-dimensional skeleton data. Our model employs three novel components.First, an input layer capable of constructing highly discriminativespatiotemporal features. Second, a tensor fusion operation that producescompact yet rich representations of the data, and third, a tensor-based neuralnetwork that processes data representations in their original tensor form. Ourmodel is end-to-end trainable and characterized by a small number of trainableparameters making it suitable for problems where the annotated data is limited.Experimental evaluation of the proposed model indicates that it can achievestate-of-the-art performance.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.08153v2'},\n",
       " 869: {'ID': 869,\n",
       "  'title': 'Hyper-Pairing Network for Multi-Phase Pancreatic Ductal Adenocarcinoma  Segmentation',\n",
       "  'authors': ['Alan Yuille',\n",
       "   'Zhishuai Zhang',\n",
       "   'Yingwei Li',\n",
       "   'Yan Wang',\n",
       "   'Yuyin Zhou',\n",
       "   'Angtian Wang',\n",
       "   'Elliot Fishman',\n",
       "   'Seyoun Park'],\n",
       "  'published': '2019-09-03T00:55:37Z',\n",
       "  'updated': '2019-09-03T00:55:37Z',\n",
       "  'abstract': 'Pancreatic ductal adenocarcinoma (PDAC) is one of the most lethal cancerswith an overall five-year survival rate of 8%. Due to subtle texture changes ofPDAC, pancreatic dual-phase imaging is recommended for better diagnosis ofpancreatic disease. In this study, we aim at enhancing PDAC automaticsegmentation by integrating multi-phase information (i.e., arterial phase andvenous phase). To this end, we present Hyper-Pairing Network (HPN), a 3D fullyconvolution neural network which effectively integrates information fromdifferent phases. The proposed approach consists of a dual path network wherethe two parallel streams are interconnected with hyper-connections forintensive information exchange. Additionally, a pairing loss is added toencourage the commonality between high-level feature representations ofdifferent phases. Compared to prior arts which use single phase data, HPNreports a significant improvement up to 7.73% (from 56.21% to 63.94%) in termsof DSC.',\n",
       "  'categories': ['eess.IV', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.00906v1'},\n",
       " 870: {'ID': 870,\n",
       "  'title': 'Jointly Aligning Millions of Images with Deep Penalised Reconstruction  Congealing',\n",
       "  'authors': ['Jacques Cali', 'Roberto Annunziata', 'Christos Sagonas'],\n",
       "  'published': '2019-08-12T12:55:31Z',\n",
       "  'updated': '2019-10-14T10:24:31Z',\n",
       "  'abstract': 'Extrapolating fine-grained pixel-level correspondences in a fullyunsupervised manner from a large set of misaligned images can benefit severalcomputer vision and graphics problems, e.g. co-segmentation, super-resolution,image edit propagation, structure-from-motion, and 3D reconstruction. Severaljoint image alignment and congealing techniques have been proposed to tacklethis problem, but robustness to initialisation, ability to scale to largedatasets, and alignment accuracy seem to hamper their wide applicability. Toovercome these limitations, we propose an unsupervised joint alignment methodleveraging a densely fused spatial transformer network to estimate the warpingparameters for each image and a low-capacity auto-encoder whose reconstructionerror is used as an auxiliary measure of joint alignment. Experimental resultson digits from multiple versions of MNIST (i.e., original, perturbed, affNISTand infiMNIST) and faces from LFW, show that our approach is capable ofaligning millions of images with high accuracy and robustness to differentlevels and types of perturbation. Moreover, qualitative and quantitativeresults suggest that the proposed method outperforms state-of-the-artapproaches both in terms of alignment quality and robustness to initialisation.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.04130v2'},\n",
       " 871: {'ID': 871,\n",
       "  'title': 'DNN Expression Rate Analysis of High-dimensional PDEs: Application to  Option Pricing',\n",
       "  'authors': ['Philipp Grohs',\n",
       "   'Christoph Schwab',\n",
       "   'Arnulf Jentzen',\n",
       "   'Dennis Elbrächter'],\n",
       "  'published': '2018-09-20T15:17:27Z',\n",
       "  'updated': '2020-11-03T14:24:52Z',\n",
       "  'abstract': 'We analyze approximation rates by deep ReLU networks of a class ofmulti-variate solutions of Kolmogorov equations which arise in option pricing.Key technical devices are deep ReLU architectures capable of efficientlyapproximating tensor products. Combining this with results concerning theapproximation of well behaved (i.e. fulfilling some smoothness properties)univariate functions, this provides insights into rates of deep ReLUapproximation of multi-variate functions with tensor structures. We apply thisin particular to the model problem given by the price of a European maximumoption on a basket of $d$ assets within the Black-Scholes model for Europeanmaximum option pricing. We prove that the solution to the $d$-variate optionpricing problem can be approximated up to an $\\\\varepsilon$-error by a deep ReLUnetwork with depth $\\\\mathcal{O}\\\\big(\\\\ln(d)\\\\ln(\\\\varepsilon^{-1})+\\\\ln(d)^2\\\\big)$and $\\\\mathcal{O}\\\\big(d^{2+\\\\frac{1}{n}}\\\\varepsilon^{-\\\\frac{1}{n}}\\\\big)$ non-zeroweights, where $n\\\\in \\\\mathbb{N}$ is arbitrary (with the constant implied in$\\\\mathcal{O}(\\\\cdot)$ depending on $n$). The techniques developed in theconstructive proof are of independent interest in the analysis of theexpressive power of deep neural networks for solution manifolds of PDEs in highdimension.',\n",
       "  'categories': ['math.FA', '41Axx, 35Kxx, 65-XX, 65D30'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.07669v3'},\n",
       " 872: {'ID': 872,\n",
       "  'title': 'HyperGrid: Efficient Multi-Task Transformers with Grid-wise Decomposable  Hyper Projections',\n",
       "  'authors': ['Dara Bahri',\n",
       "   'Donald Metzler',\n",
       "   'Zhe Zhao',\n",
       "   'Yi Tay',\n",
       "   'Da-Cheng Juan'],\n",
       "  'published': '2020-07-12T02:49:16Z',\n",
       "  'updated': '2020-07-12T02:49:16Z',\n",
       "  'abstract': 'Achieving state-of-the-art performance on natural language understandingtasks typically relies on fine-tuning a fresh model for every task.Consequently, this approach leads to a higher overall parameter cost, alongwith higher technical maintenance for serving multiple models. Learning asingle multi-task model that is able to do well for all the tasks has been achallenging and yet attractive proposition. In this paper, we propose\\\\textsc{HyperGrid}, a new approach for highly effective multi-task learning.The proposed approach is based on a decomposable hypernetwork that learnsgrid-wise projections that help to specialize regions in weight matrices fordifferent tasks. In order to construct the proposed hypernetwork, our methodlearns the interactions and composition between a global (task-agnostic) stateand a local task-specific state. We apply our proposed \\\\textsc{HyperGrid} onthe current state-of-the-art T5 model, demonstrating strong performance acrossthe GLUE and SuperGLUE benchmarks when using only a single multi-task model.Our method helps bridge the gap between fine-tuning and multi-task learningapproaches.',\n",
       "  'categories': ['cs.CL', 'cs.IR', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.05891v1'},\n",
       " 873: {'ID': 873,\n",
       "  'title': 'Reading Industrial Inspection Sheets by Inferring Visual Relations',\n",
       "  'authors': ['Arindam Chowdhury',\n",
       "   'Rohit Rahul',\n",
       "   'Animesh',\n",
       "   'Samarth Mittal',\n",
       "   'Lovekesh Vig'],\n",
       "  'published': '2018-12-11T13:10:14Z',\n",
       "  'updated': '2018-12-11T13:10:14Z',\n",
       "  'abstract': 'The traditional mode of recording faults in heavy factory equipment has beenvia hand marked inspection sheets, wherein a machine engineer manually marksthe faulty machine regions on a paper outline of the machine. Over the years,millions of such inspection sheets have been recorded and the data within thesesheets has remained inaccessible. However, with industries going digital andwaking up to the potential value of fault data for machine health monitoring,there is an increased impetus towards digitization of these hand markedinspection records. To target this digitization, we propose a novel visualpipeline combining state of the art deep learning models, with domain knowledgeand low level vision techniques, followed by inference of visual relationships.Our framework is robust to the presence of both static and non-staticbackground in the document, variability in the machine template diagrams,unstructured shape of graphical objects to be identified and variability in thestrokes of handwritten text. The proposed pipeline incorporates a capsule andspatial transformer network based classifier for accurate text reading, and acustomized CTPN network for text detection in addition to hybrid techniques forarrow detection and dialogue cloud removal. We have tested our approach on areal world dataset of 50 inspection sheets for large containers and boilers.The results are visually appealing and the pipeline achieved an accuracy of87.1% for text detection and 94.6% for text reading.',\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.07104v1'},\n",
       " 874: {'ID': 874,\n",
       "  'title': 'On the estimation of the Wasserstein distance in generative models',\n",
       "  'authors': ['Thomas Pock', 'Thomas Pinetz', 'Daniel Soukup'],\n",
       "  'published': '2019-10-02T11:49:00Z',\n",
       "  'updated': '2019-10-02T11:49:00Z',\n",
       "  'abstract': 'Generative Adversarial Networks (GANs) have been used to model the underlyingprobability distribution of sample based datasets. GANs are notoriuos fortraining difficulties and their dependence on arbitrary hyperparameters. Onerecent improvement in GAN literature is to use the Wasserstein distance as lossfunction leading to Wasserstein Generative Adversarial Networks (WGANs). Usingthis as a basis, we show various ways in which the Wasserstein distance isestimated for the task of generative modelling. Additionally, the secrets intraining such models are shown and summarized at the end of this work. Whereapplicable, we extend current works to different algorithms, different costfunctions, and different regularization schemes to improve generative models.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.00888v1'},\n",
       " 875: {'ID': 875,\n",
       "  'title': 'LinesToFacePhoto: Face Photo Generation from Lines with Conditional  Self-Attention Generative Adversarial Network',\n",
       "  'authors': ['Yuhang Li', 'Feng Wu', 'Xuejin Chen', 'Zheng-Jun Zha'],\n",
       "  'published': '2019-10-20T07:05:24Z',\n",
       "  'updated': '2019-10-20T07:05:24Z',\n",
       "  'abstract': 'In this paper, we explore the task of generating photo-realistic face imagesfrom lines. Previous methods based on conditional generative adversarialnetworks (cGANs) have shown their power to generate visually plausible imageswhen a conditional image and an output image share well-aligned structures.However, these models fail to synthesize face images with a whole set ofwell-defined structures, e.g. eyes, noses, mouths, etc., especially when theconditional line map lacks one or several parts. To address this problem, wepropose a conditional self-attention generative adversarial network (CSAGAN).We introduce a conditional self-attention mechanism to cGANs to capturelong-range dependencies between different regions in faces. We also build amulti-scale discriminator. The large-scale discriminator enforces thecompleteness of global structures and the small-scale discriminator encouragesfine details, thereby enhancing the realism of generated face images. Weevaluate the proposed model on the CelebA-HD dataset by two perceptual userstudies and three quantitative metrics. The experiment results demonstrate thatour method generates high-quality facial images while preserving facialstructures. Our results outperform state-of-the-art methods both quantitativelyand qualitatively.',\n",
       "  'categories': ['cs.CV', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.08914v1'},\n",
       " 876: {'ID': 876,\n",
       "  'title': 'An Empirical Study of Propagation-based Methods for Video Object  Segmentation',\n",
       "  'authors': ['Qian He',\n",
       "   'Huaxia Li',\n",
       "   'Guanjun Guo',\n",
       "   'Hengkai Guo',\n",
       "   'Xuefeng Xiao',\n",
       "   'Wenji Wang',\n",
       "   'Jiachen Liu'],\n",
       "  'published': '2019-07-30T08:00:47Z',\n",
       "  'updated': '2019-07-30T08:00:47Z',\n",
       "  'abstract': 'While propagation-based approaches have achieved state-of-the-art performancefor video object segmentation, the literature lacks a fair comparison ofdifferent methods using the same settings. In this paper, we carry out anempirical study for propagation-based methods. We view these approaches from aunified perspective and conduct detailed ablation study for core methods, inputcues, multi-object combination and training strategies. With careful designs,our improved end-to-end memory networks achieve a global mean of 76.1 on DAVIS2017 val set.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1907.12769v1'},\n",
       " 877: {'ID': 877,\n",
       "  'title': 'Stable Tensor Neural Networks for Rapid Deep Learning',\n",
       "  'authors': ['Elizabeth Newman', 'Haim Avron', 'Lior Horesh', 'Misha Kilmer'],\n",
       "  'published': '2018-11-15T19:37:24Z',\n",
       "  'updated': '2018-11-15T19:37:24Z',\n",
       "  'abstract': 'We propose a tensor neural network ($t$-NN) framework that offers an excitingnew paradigm for designing neural networks with multidimensional (tensor) data.Our network architecture is based on the $t$-product (Kilmer and Martin, 2011),an algebraic formulation to multiply tensors via circulant convolution. In this$t$-product algebra, we interpret tensors as $t$-linear operators analogous tomatrices as linear operators, and hence our framework inherits mimetic matrixproperties. To exemplify the elegant, matrix-mimetic algebraic structure of our$t$-NNs, we expand on recent work (Haber and Ruthotto, 2017) which interpretsdeep neural networks as discretizations of non-linear differential equationsand introduces stable neural networks which promote superior generalization.Motivated by this dynamic framework, we introduce a stable $t$-NN whichfacilitates more rapid learning because of its reduced, more powerfulparameterization. Through our high-dimensional design, we create a more compactparameter space and extract multidimensional correlations otherwise latent intraditional algorithms. We further generalize our $t$-NN framework to a familyof tensor-tensor products (Kernfeld, Kilmer, and Aeron, 2015) which stillinduce a matrix-mimetic algebraic structure. Through numerical experiments onthe MNIST and CIFAR-10 datasets, we demonstrate the more powerfulparameterizations and improved generalizability of stable $t$-NNs.',\n",
       "  'categories': ['cs.LG', 'cs.NA', 'math.NA', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.06569v1'},\n",
       " 878: {'ID': 878,\n",
       "  'title': 'ReLGAN: Generalization of Consistency for GAN with Disjoint Constraints  and Relative Learning of Generative Processes for Multiple Transformation  Learning',\n",
       "  'authors': ['Chiranjib Sur'],\n",
       "  'published': '2020-06-14T06:03:30Z',\n",
       "  'updated': '2020-06-14T06:03:30Z',\n",
       "  'abstract': 'Image to image transformation has gained popularity from different researchcommunities due to its enormous impact on different applications, includingmedical. In this work, we have introduced a generalized scheme for consistencyfor GAN architectures with two new concepts of Transformation Learning (TL) andRelative Learning (ReL) for enhanced learning image transformations.Consistency for GAN architectures suffered from inadequate constraints andfailed to learn multiple and multi-modal transformations, which is inevitablefor many medical applications. The main drawback is that it focused on creatingan intermediate and workable hybrid, which is not permissible for the medicalapplications which focus on minute details. Another drawback is the weakinterrelation between the two learning phases and TL and ReL have introducedimproved coordination among them. We have demonstrated the capability of thenovel network framework on public datasets. We emphasized that our novelarchitecture produced an improved neural image transformation version for theimage, which is more acceptable to the medical community. Experiments andresults demonstrated the effectiveness of our framework with enhancementcompared to the previous works.',\n",
       "  'categories': ['cs.CV', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.07809v1'},\n",
       " 879: {'ID': 879,\n",
       "  'title': 'Language Expansion In Text-Based Games',\n",
       "  'authors': ['Ghulam Ahmed Ansari',\n",
       "   'Balaraman Ravindran',\n",
       "   'Sarath Chandar',\n",
       "   'Sagar J P'],\n",
       "  'published': '2018-05-17T10:43:04Z',\n",
       "  'updated': '2018-05-17T10:43:04Z',\n",
       "  'abstract': \"Text-based games are suitable test-beds for designing agents that can learnby interaction with the environment in the form of natural language text. Veryrecently, deep reinforcement learning based agents have been successfullyapplied for playing text-based games. In this paper, we explore the possibilityof designing a single agent to play several text-based games and of expandingthe agent's vocabulary using the vocabulary of agents trained for multiplegames. To this extent, we explore the application of recently proposed policydistillation method for video games to the text-based game setting. We also usetext-based games as a test-bed to analyze and hence understand policydistillation approach in detail.\",\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.07274v1'},\n",
       " 880: {'ID': 880,\n",
       "  'title': 'Analog Weights in ReRAM DNN Accelerators',\n",
       "  'authors': ['Herbert Ho-Ching Iu',\n",
       "   'Wen Lei',\n",
       "   'Sung-Mo Kang',\n",
       "   'Garrick Orchard',\n",
       "   'Jason K. Eshraghian',\n",
       "   'Seungbum Baek'],\n",
       "  'published': '2019-04-26T18:25:16Z',\n",
       "  'updated': '2019-04-26T18:25:16Z',\n",
       "  'abstract': 'Artificial neural networks have become ubiquitous in modern life, which hastriggered the emergence of a new class of application specific integratedcircuits for their acceleration. ReRAM-based accelerators have gainedsignificant traction due to their ability to leverage in-memory computations.In a crossbar structure, they can perform multiply-and-accumulate operationsmore efficiently than standard CMOS logic. By virtue of being resistiveswitches, ReRAM switches can only reliably store one of two states. This is asevere limitation on the range of values in a computational kernel. This paperpresents a novel scheme in alleviating the single-bit-per-device restriction byexploiting frequency dependence of v-i plane hysteresis, and assigning kernelinformation not only to the device conductance but also partially distributingit to the frequency of a time-varying input. We show this approach reducesaverage power consumption for a single crossbar convolution by up to a factorof x16 for an unsigned 8-bit input image, where each convolutional processconsumes a worst-case of 1.1mW, and reduces area by a factor of x8, withoutreducing accuracy to the level of binarized neural networks. This presents amassive saving in computing cost when there are many simultaneous in-situmultiply-and-accumulate processes occurring across different crossbars.',\n",
       "  'categories': ['eess.SP', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.12008v1'},\n",
       " 881: {'ID': 881,\n",
       "  'title': 'Explain by Evidence: An Explainable Memory-based Neural Network for  Question Answering',\n",
       "  'authors': ['Nhan Dam',\n",
       "   'Tuan Lai',\n",
       "   'Franck Dernoncourt',\n",
       "   'Dinh Phung',\n",
       "   'Quan Tran',\n",
       "   'Nham Le',\n",
       "   'Trung Le'],\n",
       "  'published': '2020-11-05T21:18:21Z',\n",
       "  'updated': '2020-11-05T21:18:21Z',\n",
       "  'abstract': 'Interpretability and explainability of deep neural networks are challengingdue to their scale, complexity, and the agreeable notions on which theexplaining process rests. Previous work, in particular, has focused onrepresenting internal components of neural networks through human-friendlyvisuals and concepts. On the other hand, in real life, when making a decision,human tends to rely on similar situations and/or associations in the past.Hence arguably, a promising approach to make the model transparent is to designit in a way such that the model explicitly connects the current sample with theseen ones, and bases its decision on these samples. Grounded on that principle,we propose in this paper an explainable, evidence-based memory networkarchitecture, which learns to summarize the dataset and extract supportingevidences to make its decision. Our model achieves state-of-the-art performanceon two popular question answering datasets (i.e. TrecQA and WikiQA). Viafurther analysis, we show that this model can reliably trace the errors it hasmade in the validation step to the training instances that might have causedthese errors. We believe that this error-tracing capability providessignificant benefit in improving dataset quality in many applications.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.03096v1'},\n",
       " 882: {'ID': 882,\n",
       "  'title': 'Revisiting \"Qualitatively Characterizing Neural Network Optimization  Problems\"',\n",
       "  'authors': ['Jonathan Frankle'],\n",
       "  'published': '2020-12-12T20:01:33Z',\n",
       "  'updated': '2020-12-12T20:01:33Z',\n",
       "  'abstract': 'We revisit and extend the experiments of Goodfellow et al. (2014), who showedthat - for then state-of-the-art networks - \"the objective function has asimple, approximately convex shape\" along the linear path betweeninitialization and the trained weights. We do not find this to be the case formodern networks on CIFAR-10 and ImageNet. Instead, although loss is roughlymonotonically non-increasing along this path, it remains high until close tothe optimum. In addition, training quickly becomes linearly separated from theoptimum by loss barriers. We conclude that, although Goodfellow et al.\\'sfindings describe the \"relatively easy to optimize\" MNIST setting, behavior isqualitatively different in modern settings.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.06898v1'},\n",
       " 883: {'ID': 883,\n",
       "  'title': 'Low Precision Policy Distillation with Application to Low-Power,  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing',\n",
       "  'authors': ['Davis R. Barch',\n",
       "   'Michael V. Debole',\n",
       "   'Jeffrey L Mckinstry',\n",
       "   'Dharmendra S. Modha',\n",
       "   'Steven K. Esser',\n",
       "   'John V. Arthur',\n",
       "   'Deepika Bablani',\n",
       "   'Jeffrey A. Kusnitz'],\n",
       "  'published': '2018-09-25T00:03:33Z',\n",
       "  'updated': '2018-09-25T00:03:33Z',\n",
       "  'abstract': 'Low precision networks in the reinforcement learning (RL) setting arerelatively unexplored because of the limitations of binary activations forfunction approximation. Here, in the discrete action ATARI domain, wedemonstrate, for the first time, that low precision policy distillation from ahigh precision network provides a principled, practical way to train an RLagent. As an application, on 10 different ATARI games, we demonstrate real-timeend-to-end game playing on low-power neuromorphic hardware by converting asequence of game frames into discrete actions.',\n",
       "  'categories': ['cs.LG', 'cs.NE', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.09260v1'},\n",
       " 884: {'ID': 884,\n",
       "  'title': 'A Unified Linear-Time Framework for Sentence-Level Discourse Parsing',\n",
       "  'authors': ['M Saiful Bari',\n",
       "   'Prathyusha Jwalapuram',\n",
       "   'Xiang Lin',\n",
       "   'Shafiq Joty'],\n",
       "  'published': '2019-05-14T15:54:57Z',\n",
       "  'updated': '2019-06-12T05:05:06Z',\n",
       "  'abstract': 'We propose an efficient neural framework for sentence-level discourseanalysis in accordance with Rhetorical Structure Theory (RST). Our frameworkcomprises a discourse segmenter to identify the elementary discourse units(EDU) in a text, and a discourse parser that constructs a discourse tree in atop-down fashion. Both the segmenter and the parser are based on PointerNetworks and operate in linear time. Our segmenter yields an $F_1$ score of95.4, and our parser achieves an $F_1$ score of 81.7 on the aggregated labeled(relation) metric, surpassing previous approaches by a good margin andapproaching human agreement on both tasks (98.3 and 83.0 $F_1$).',\n",
       "  'categories': ['cs.CL', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.05682v2'},\n",
       " 885: {'ID': 885,\n",
       "  'title': 'Deep Learning-Based FPGA Function Block Detection Method using an  Image-Coded Representation of Bitstream',\n",
       "  'authors': ['Peng Liu', 'Minzhen Chen'],\n",
       "  'published': '2020-07-20T07:45:05Z',\n",
       "  'updated': '2020-07-20T07:45:05Z',\n",
       "  'abstract': \"Examining field-programmable gate array (FPGA) bitstream is found to helpdetect known function blocks, which offers assistance and insight to analyzethe circuit's system function. Our goal is to detect one or more than onefunction block in FPGA design from a complete bitstream by utilizing the latestdeep learning techniques, which do not require manually designing features. Tothis end, in this paper, we propose a deep learning-based FPGA function blockdetection method by transforming the bitstream into a three-channel colorimage. In specific, we first analyze the format of the bitstream to find themapping relationship between the configuration bits and configurable logicblocks. Next, an image-coded representation of bitstream is proposed suitablefor deep learning processing. This bitstream-to-image transformation takes intoaccount of the adjacency nature of the programmable logic as well as highdegree of redundancy of configuration information. With the color imagestransformed from bitstreams as the training dataset, a deep learning-basedobject detection algorithm is applied for generating the function blockdetection results. The effects of EDA tools, input size of the deep neuralnetwork, and the data arrangement of representation on the detection accuracyare explored. The Xilinx Zynq-7000 SoCs and Xilinx Zynq UltraScale+ MPSoCs areadopted to verify the proposed method, and the results show that the meanAverage Precision (IoU=0.5) for 10 function blocks is as high as 97.72% forYOLOv3 detector.\",\n",
       "  'categories': ['cs.OH', 'eess.IV', 'eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.11434v1'},\n",
       " 886: {'ID': 886,\n",
       "  'title': 'Bridging In- and Out-of-distribution Samples for Their Better  Discriminability',\n",
       "  'authors': ['Takayuki Okatani', 'Engkarat Techapanurak', 'Anh-Chuong Dang'],\n",
       "  'published': '2021-01-07T11:34:18Z',\n",
       "  'updated': '2021-01-07T11:34:18Z',\n",
       "  'abstract': 'This paper proposes a method for OOD detection. Questioning the premise ofprevious studies that ID and OOD samples are separated distinctly, we considersamples lying in the intermediate of the two and use them for training anetwork. We generate such samples using multiple image transformations thatcorrupt inputs in various ways and with different severity levels. We estimatewhere the generated samples by a single image transformation lie between ID andOOD using a network trained on clean ID samples. To be specific, we make thenetwork classify the generated samples and calculate their mean classificationaccuracy, using which we create a soft target label for them. We train the samenetwork from scratch using the original ID samples and the generated sampleswith the soft labels created for them. We detect OOD samples by thresholdingthe entropy of the predicted softmax probability. The experimental results showthat our method outperforms the previous state-of-the-art in the standardbenchmark tests. We also analyze the effect of the number and particularcombinations of image corrupting transformations on the performance.',\n",
       "  'categories': ['cs.CV', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.02500v1'},\n",
       " 887: {'ID': 887,\n",
       "  'title': 'Multivariate time-series modeling with generative neural networks',\n",
       "  'authors': ['Marius Hofert', 'Avinash Prasad', 'Mu Zhu'],\n",
       "  'published': '2020-02-25T03:26:52Z',\n",
       "  'updated': '2020-10-02T14:54:36Z',\n",
       "  'abstract': 'Generative moment matching networks (GMMNs) are introduced as dependencemodels for the joint innovation distribution of multivariate time series (MTS).Following the popular copula-GARCH approach for modeling dependent MTS data, aframework based on a GMMN-GARCH approach is presented. First, ARMA-GARCH modelsare utilized to capture the serial dependence within each univariate marginaltime series. Second, if the number of marginal time series is large, principalcomponent analysis (PCA) is used as a dimension-reduction step. Last, theremaining cross-sectional dependence is modeled via a GMMN, the maincontribution of this work. GMMNs are highly flexible and easy to simulate from,which is a major advantage over the copula--GARCH approach. Applicationsinvolving yield curve modeling and the analysis of foreign exchange ratereturns demonstrate the utility of the GMMN-GARCH approach, especially in termsof producing better empirical predictive distributions and making betterprobabilistic forecasts. All results are reproducible with the demoGMMN_MTS_paper of the R package gnn.',\n",
       "  'categories': ['stat.ME',\n",
       "   'cs.LG',\n",
       "   'stat.ML',\n",
       "   '62H99, 65C60, 60E05, 00A72, 65C10, 62M10'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.10645v2'},\n",
       " 888: {'ID': 888,\n",
       "  'title': 'Learning Strict Identity Mappings in Deep Residual Networks',\n",
       "  'authors': ['Xin Yu', 'Zhiding Yu', 'Srikumar Ramalingam'],\n",
       "  'published': '2018-04-05T03:19:53Z',\n",
       "  'updated': '2019-06-16T00:03:19Z',\n",
       "  'abstract': 'A family of super deep networks, referred to as residual networks or ResNet,achieved record-beating performance in various visual tasks such as imagerecognition, object detection, and semantic segmentation. The ability to trainvery deep networks naturally pushed the researchers to use enormous resourcesto achieve the best performance. Consequently, in many applications super deepresidual networks were employed for just a marginal improvement in performance.In this paper, we propose epsilon-ResNet that allows us to automaticallydiscard redundant layers, which produces responses that are smaller than athreshold epsilon, with a marginal or no loss in performance. Theepsilon-ResNet architecture can be achieved using a few additional rectifiedlinear units in the original ResNet. Our method does not use any additionalvariables nor numerous trials like other hyper-parameter optimizationtechniques. The layer selection is achieved using a single training process andthe evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNetdatasets. In some instances, we achieve about 80% reduction in the number ofparameters.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.01661v5'},\n",
       " 889: {'ID': 889,\n",
       "  'title': 'Deep Learning Assisted mmWave Beam Prediction with Prior Low-frequency  Information',\n",
       "  'authors': ['Dongxuan He', 'Zhaocheng Wang', 'Ke Ma', 'Hancun Sun'],\n",
       "  'published': '2020-10-30T08:59:58Z',\n",
       "  'updated': '2021-02-08T08:53:58Z',\n",
       "  'abstract': 'Huge overhead of beam training poses a significant challenge to mmWavecommunications. To address this issue, beam tracking has been widelyinvestigated whereas existing methods are hard to handle serious multipathinterference and non-stationary scenarios. Inspired by the spatial similaritybetween low-frequency and mmWave channels in non-standalone architectures, thispaper proposes to utilize prior low-frequency information to predict theoptimal mmWave beam, where deep learning is adopted to enhance the predictionaccuracy. Specifically, periodically estimated low-frequency channel stateinformation (CSI) is applied to track the movement of user equipment, andtiming offset indicator is proposed to indicate the instant of mmWave beamtraining relative to low-frequency CSI estimation. Meanwhile, long-short termmemory networks based dedicated models are designed to implement theprediction. Simulation results show that our proposed scheme can achieve higherbeamforming gain than the conventional methods while requiring little overheadof mmWave beam training.',\n",
       "  'categories': ['eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.02332v2'},\n",
       " 890: {'ID': 890,\n",
       "  'title': 'Clustered Federated Learning: Model-Agnostic Distributed Multi-Task  Optimization under Privacy Constraints',\n",
       "  'authors': ['Klaus-Robert Müller', 'Wojciech Samek', 'Felix Sattler'],\n",
       "  'published': '2019-10-04T15:31:09Z',\n",
       "  'updated': '2019-10-04T15:31:09Z',\n",
       "  'abstract': \"Federated Learning (FL) is currently the most widely adopted framework forcollaborative training of (deep) machine learning models under privacyconstraints. Albeit it's popularity, it has been observed that FederatedLearning yields suboptimal results if the local clients' data distributionsdiverge. To address this issue, we present Clustered Federated Learning (CFL),a novel Federated Multi-Task Learning (FMTL) framework, which exploitsgeometric properties of the FL loss surface, to group the client populationinto clusters with jointly trainable data distributions. In contrast toexisting FMTL approaches, CFL does not require any modifications to the FLcommunication protocol to be made, is applicable to general non-convexobjectives (in particular deep neural networks) and comes with strongmathematical guarantees on the clustering quality. CFL is flexible enough tohandle client populations that vary over time and can be implemented in aprivacy preserving way. As clustering is only performed after FederatedLearning has converged to a stationary point, CFL can be viewed as apost-processing method that will always achieve greater or equal performancethan conventional FL by allowing clients to arrive at more specialized models.We verify our theoretical analysis in experiments with deep convolutional andrecurrent neural networks on commonly used Federated Learning datasets.\",\n",
       "  'categories': ['cs.LG', 'cs.DC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.01991v1'},\n",
       " 891: {'ID': 891,\n",
       "  'title': 'Transfer Value Iteration Networks',\n",
       "  'authors': ['Sinno Jialin Pan',\n",
       "   'Jin Xu',\n",
       "   'Bin Zhong',\n",
       "   'Hankz Hankui Zhuo',\n",
       "   'Junyi Shen'],\n",
       "  'published': '2019-11-11T08:07:49Z',\n",
       "  'updated': '2019-11-27T01:55:19Z',\n",
       "  'abstract': 'Value iteration networks (VINs) have been demonstrated to have a goodgeneralization ability for reinforcement learning tasks across similar domains.However, based on our experiments, a policy learned by VINs still fail togeneralize well on the domain whose action space and feature space are notidentical to those in the domain where it is trained. In this paper, we proposea transfer learning approach on top of VINs, termed Transfer VINs (TVINs), suchthat a learned policy from a source domain can be generalized to a targetdomain with only limited training data, even if the source domain and thetarget domain have domain-specific actions and features. We empirically verifythat our proposed TVINs outperform VINs when the source and the target domainshave similar but not identical action and feature spaces. Furthermore, we showthat the performance improvement is consistent across different environments,maze sizes, dataset sizes as well as different values of hyperparameters suchas number of iteration and kernel size.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.05701v2'},\n",
       " 892: {'ID': 892,\n",
       "  'title': 'Continuous Relaxation of Symbolic Planner for One-Shot Imitation  Learning',\n",
       "  'authors': ['De-An Huang',\n",
       "   'Danfei Xu',\n",
       "   'Juan Carlos Niebles',\n",
       "   'Animesh Garg',\n",
       "   'Li Fei-Fei',\n",
       "   'Yuke Zhu',\n",
       "   'Silvio Savarese'],\n",
       "  'published': '2019-08-16T16:28:12Z',\n",
       "  'updated': '2019-11-05T02:58:19Z',\n",
       "  'abstract': 'We address one-shot imitation learning, where the goal is to execute apreviously unseen task based on a single demonstration. While there has beenexciting progress in this direction, most of the approaches still require a fewhundred tasks for meta-training, which limits the scalability of theapproaches. Our main contribution is to formulate one-shot imitation learningas a symbolic planning problem along with the symbol grounding problem. Thisformulation disentangles the policy execution from the inter-taskgeneralization and leads to better data efficiency. The key technical challengeis that the symbol grounding is prone to error with limited training data andleads to subsequent symbolic planning failures. We address this challenge byproposing a continuous relaxation of the discrete symbolic planner thatdirectly plans on the probabilistic outputs of the symbol grounding model. Ourcontinuous relaxation of the planner can still leverage the informationcontained in the probabilistic symbol grounding and significantly improve overthe baseline planner for the one-shot imitation learning tasks without usinglarge training data.',\n",
       "  'categories': ['cs.AI', 'cs.LG', 'cs.RO'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.06769v2'},\n",
       " 893: {'ID': 893,\n",
       "  'title': \"Benford's law: what does it say on adversarial images?\",\n",
       "  'authors': ['Eric A. Antonelo',\n",
       "   'Fabio L. Baldissera',\n",
       "   'João G. Zago',\n",
       "   'Rodrigo T. Saad'],\n",
       "  'published': '2021-02-09T02:50:29Z',\n",
       "  'updated': '2021-02-09T02:50:29Z',\n",
       "  'abstract': \"Convolutional neural networks (CNNs) are fragile to small perturbations inthe input images. These networks are thus prone to malicious attacks thatperturb the inputs to force a misclassification. Such slightly manipulatedimages aimed at deceiving the classifier are known as adversarial images. Inthis work, we investigate statistical differences between natural images andadversarial ones. More precisely, we show that employing a proper imagetransformation and for a class of adversarial attacks, the distribution of theleading digit of the pixels in adversarial images deviates from Benford's law.The stronger the attack, the more distant the resulting distribution is fromBenford's law. Our analysis provides a detailed investigation of this newapproach that can serve as a basis for alternative adversarial exampledetection methods that do not need to modify the original CNN classifierneither work on the raw high-dimensional pixels as features to defend againstattacks.\",\n",
       "  'categories': ['cs.CV', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.04615v1'},\n",
       " 894: {'ID': 894,\n",
       "  'title': 'Parametric machines: a fresh approach to architecture search',\n",
       "  'authors': ['Patrizio Frosini', 'Mattia G. Bergomi', 'Pietro Vertechi'],\n",
       "  'published': '2020-07-06T14:27:06Z',\n",
       "  'updated': '2020-07-08T16:24:55Z',\n",
       "  'abstract': 'Using tools from category theory, we provide a framework where artificialneural networks, and their architectures, can be formally described. We firstdefine the notion of machine in a general categorical context, and show howsimple machines can be combined into more complex ones. We explore finite- andinfinite-depth machines, which generalize neural networks and neural ordinarydifferential equations. Borrowing ideas from functional analysis and kernelmethods, we build complete, normed, infinite-dimensional spaces of machines,and discuss how to find optimal architectures and parameters -- within thosespaces -- to solve a given computational problem. In our numerical experiments,these kernel-inspired networks can outperform classical neural networks whenthe training dataset is small.',\n",
       "  'categories': ['cs.LG', 'stat.ML', '18A20, 47L05', 'I.2.6'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.02777v2'},\n",
       " 895: {'ID': 895,\n",
       "  'title': 'ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image  Compression',\n",
       "  'authors': ['Andrey Norkin',\n",
       "   'Li-Heng Chen',\n",
       "   'Zhi Li',\n",
       "   'Alan C. Bovik',\n",
       "   'Christos G. Bampis'],\n",
       "  'published': '2019-10-19T21:07:33Z',\n",
       "  'updated': '2020-10-29T15:48:02Z',\n",
       "  'abstract': 'The use of $\\\\ell_p$ $(p=1,2)$ norms has largely dominated the measurement ofloss in neural networks due to their simplicity and analytical properties.However, when used to assess the loss of visual information, these simple normsare not very consistent with human perception. Here, we describe a different\"proximal\" approach to optimize image analysis networks against quantitativeperceptual models. Specifically, we construct a proxy network, broadly termedProxIQA, which mimics the perceptual model while serving as a loss layer of thenetwork. We experimentally demonstrate how this optimization framework can beapplied to train an end-to-end optimized image compression network. By buildingon top of an existing deep image compression model, we are able to demonstratea bitrate reduction of as much as $31\\\\%$ over MSE optimization, given aspecified perceptual quality (VMAF) level.',\n",
       "  'categories': ['eess.IV', 'cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.08845v2'},\n",
       " 896: {'ID': 896,\n",
       "  'title': 'Latent Weights Do Not Exist: Rethinking Binarized Neural Network  Optimization',\n",
       "  'authors': ['Lukas Geiger',\n",
       "   'Roeland Nusselder',\n",
       "   'James Widdicombe',\n",
       "   'Kwang-Ting Cheng',\n",
       "   'Zechun Liu',\n",
       "   'Koen Helwegen'],\n",
       "  'published': '2019-06-05T16:32:39Z',\n",
       "  'updated': '2019-11-06T16:40:41Z',\n",
       "  'abstract': 'Optimization of Binarized Neural Networks (BNNs) currently relies onreal-valued latent weights to accumulate small update steps. In this paper, weargue that these latent weights cannot be treated analogously to weights inreal-valued networks. Instead their main role is to provide inertia duringtraining. We interpret current methods in terms of inertia and provide novelinsights into the optimization of BNNs. We subsequently introduce the firstoptimizer specifically designed for BNNs, Binary Optimizer (Bop), anddemonstrate its performance on CIFAR-10 and ImageNet. Together, theredefinition of latent weights as inertia and the introduction of Bop enable abetter understanding of BNN optimization and open up the way for furtherimprovements in training methodologies for BNNs. Code is available at:https://github.com/plumerai/rethinking-bnn-optimization',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.02107v2'},\n",
       " 897: {'ID': 897,\n",
       "  'title': 'Bit Error Tolerance Metrics for Binarized Neural Networks',\n",
       "  'authors': ['Kuan-Hsun Chen',\n",
       "   'Mario Günzel',\n",
       "   'Jian-Jia Chen',\n",
       "   'Lukas Pfahler',\n",
       "   'Katharina Morik',\n",
       "   'Rodion Novkin',\n",
       "   'Sebastian Buschjäger',\n",
       "   'Mikail Yayla'],\n",
       "  'published': '2021-02-02T06:44:55Z',\n",
       "  'updated': '2021-02-02T06:44:55Z',\n",
       "  'abstract': 'To reduce the resource demand of neural network (NN) inference systems, ithas been proposed to use approximate memory, in which the supply voltage andthe timing parameters are tuned trading accuracy with energy consumption andperformance. Tuning these parameters aggressively leads to bit errors, whichcan be tolerated by NNs when bit flips are injected during training. However,bit flip training, which is the state of the art for achieving bit errortolerance, does not scale well; it leads to massive overheads and cannot beapplied for high bit error rates (BERs). Alternative methods to achieve biterror tolerance in NNs are needed, but the underlying principles behind the biterror tolerance of NNs have not been reported yet. With this lack ofunderstanding, further progress in the research on NN bit error tolerance willbe restrained.  In this study, our objective is to investigate the internal changes in theNNs that bit flip training causes, with a focus on binarized NNs (BNNs). Tothis end, we quantify the properties of bit error tolerant BNNs with twometrics. First, we propose a neuron-level bit error tolerance metric, whichcalculates the margin between the pre-activation values and batch normalizationthresholds. Secondly, to capture the effects of bit error tolerance on theinterplay of neurons, we propose an inter-neuron bit error tolerance metric,which measures the importance of each neuron and computes the variance over allimportance values. Our experimental results support that these two metrics arestrongly related to bit error tolerance.',\n",
       "  'categories': ['cs.LG', 'cs.NE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.01344v1'},\n",
       " 898: {'ID': 898,\n",
       "  'title': 'Explainable Tensorized Neural Ordinary Differential Equations  forArbitrary-step Time Series Prediction',\n",
       "  'authors': ['Xi Yang', 'Rui Zhang', 'Kaizhu Huang', 'Penglei Gao'],\n",
       "  'published': '2020-11-26T08:29:50Z',\n",
       "  'updated': '2020-11-26T08:29:50Z',\n",
       "  'abstract': 'We propose a continuous neural network architecture, termed ExplainableTensorized Neural Ordinary Differential Equations (ETN-ODE), for multi-steptime series prediction at arbitrary time points. Unlike the existingapproaches, which mainly handle univariate time series for multi-stepprediction or multivariate time series for single-step prediction, ETN-ODEcould model multivariate time series for arbitrary-step prediction. Inaddition, it enjoys a tandem attention, w.r.t. temporal attention and variableattention, being able to provide explainable insights into the data.Specifically, ETN-ODE combines an explainable Tensorized Gated Recurrent Unit(Tensorized GRU or TGRU) with Ordinary Differential Equations (ODE). Thederivative of the latent states is parameterized with a neural network. Thiscontinuous-time ODE network enables a multi-step prediction at arbitrary timepoints. We quantitatively and qualitatively demonstrate the effectiveness andthe interpretability of ETN-ODE on five different multi-step prediction tasksand one arbitrary-step prediction task. Extensive experiments show that ETN-ODEcan lead to accurate predictions at arbitrary time points while attaining bestperformance against the baseline methods in standard multi-step time seriesprediction.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.13174v1'},\n",
       " 899: {'ID': 899,\n",
       "  'title': 'Performing Deep Recurrent Double Q-Learning for Atari Games',\n",
       "  'authors': ['Felipe Moreno-Vera'],\n",
       "  'published': '2019-08-16T15:56:16Z',\n",
       "  'updated': '2019-10-17T21:45:01Z',\n",
       "  'abstract': 'Currently, many applications in Machine Learning are based on define newmodels to extract more information about data, In this case Deep ReinforcementLearning with the most common application in video games like Atari, Mario, andothers causes an impact in how to computers can learning by himself with onlyinformation called rewards obtained from any action. There is a lot ofalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposedby DeepMind used in AlphaZero and Go. In this document, We proposed DeepRecurrent Double Q-Learning that is an implementation of Deep ReinforcementLearning using Double Q-Learning algorithms and Recurrent Networks like LSTMand DRQN.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1908.06040v2'},\n",
       " 900: {'ID': 900,\n",
       "  'title': 'Composite Shape Modeling via Latent Space Factorization',\n",
       "  'authors': ['Anastasia Dubrovina',\n",
       "   'Panos Achlioptas',\n",
       "   'Leonidas Guibas',\n",
       "   'Fei Xia',\n",
       "   'Mira Shalah',\n",
       "   'Raphael Groscot'],\n",
       "  'published': '2019-01-09T23:25:38Z',\n",
       "  'updated': '2019-10-30T13:53:56Z',\n",
       "  'abstract': 'We present a novel neural network architecture, termed Decomposer-Composer,for semantic structure-aware 3D shape modeling. Our method utilizes anauto-encoder-based pipeline, and produces a novel factorized shape embeddingspace, where the semantic structure of the shape collection translates into adata-dependent sub-space factorization, and where shape composition anddecomposition become simple linear operations on the embedding coordinates. Wefurther propose to model shape assembly using an explicit learned partdeformation module, which utilizes a 3D spatial transformer network to performan in-network volumetric grid deformation, and which allows us to train thewhole system end-to-end. The resulting network allows us to perform part-levelshape manipulation, unattainable by existing approaches. Our extensive ablationstudy, comparison to baseline methods and qualitative analysis demonstrate theimproved performance of the proposed method.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.02968v2'},\n",
       " 901: {'ID': 901,\n",
       "  'title': 'Enhancing Human-Machine Teaming for Medical Prognosis Through Neural  Ordinary Differential Equations (NODEs)',\n",
       "  'authors': ['N. Ricka',\n",
       "   'G. Pellegrin',\n",
       "   'F. Rose',\n",
       "   'D. Fompeyrine',\n",
       "   'E. S. Vorm'],\n",
       "  'published': '2021-02-08T10:52:23Z',\n",
       "  'updated': '2021-02-08T10:52:23Z',\n",
       "  'abstract': \"Machine Learning (ML) has recently been demonstrated to rival expert-levelhuman accuracy in prediction and detection tasks in a variety of domains,including medicine. Despite these impressive findings, however, a key barrierto the full realization of ML's potential in medical prognoses is technologyacceptance. Recent efforts to produce explainable AI (XAI) have made progressin improving the interpretability of some ML models, but these efforts sufferfrom limitations intrinsic to their design: they work best at identifying why asystem fails, but do poorly at explaining when and why a model's prediction iscorrect. We posit that the acceptability of ML predictions in expert domains islimited by two key factors: the machine's horizon of prediction that extendsbeyond human capability, and the inability for machine predictions toincorporate human intuition into their models. We propose the use of a novel MLarchitecture, Neural Ordinary Differential Equations (NODEs) to enhance humanunderstanding and encourage acceptability. Our approach prioritizes humancognitive intuition at the center of the algorithm design, and offers adistribution of predictions rather than single outputs. We explain how thisapproach may significantly improve human-machine collaboration in predictiontasks in expert domains such as medical prognoses. We propose a model anddemonstrate, by expanding a concrete example from the literature, how our modeladvances the vision of future hybrid Human-AI systems.\",\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.04121v1'},\n",
       " 902: {'ID': 902,\n",
       "  'title': 'Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning  in Autonomous Driving',\n",
       "  'authors': ['Maria Huegle',\n",
       "   'Joschka Boedecker',\n",
       "   'Gabriel Kalweit',\n",
       "   'Moritz Werling'],\n",
       "  'published': '2019-09-30T10:59:11Z',\n",
       "  'updated': '2019-09-30T10:59:11Z',\n",
       "  'abstract': 'The common pipeline in autonomous driving systems is highly modular andincludes a perception component which extracts lists of surrounding objects andpasses these lists to a high-level decision component. In this case, leveragingthe benefits of deep reinforcement learning for high-level decision makingrequires special architectures to deal with multiple variable-length sequencesof different object types, such as vehicles, lanes or traffic signs. At thesame time, the architecture has to be able to cover interactions betweentraffic participants in order to find the optimal action to be taken. In thiswork, we propose the novel Deep Scenes architecture, that can learn complexinteraction-aware scene representations based on extensions of either 1) DeepSets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Qoff-policy reinforcement learning algorithms, both outperformingstate-of-the-art methods in evaluations with the publicly available trafficsimulator SUMO.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.RO', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.13582v1'},\n",
       " 903: {'ID': 903,\n",
       "  'title': 'Meta-Learning with Adaptive Hyperparameters',\n",
       "  'authors': ['Sungyong Baik',\n",
       "   'Heewon Kim',\n",
       "   'Kyoung Mu Lee',\n",
       "   'Myungsub Choi',\n",
       "   'Janghoon Choi'],\n",
       "  'published': '2020-10-31T08:05:34Z',\n",
       "  'updated': '2020-12-08T06:53:01Z',\n",
       "  'abstract': 'Despite its popularity, several recent works question the effectiveness ofMAML when test tasks are different from training tasks, thus suggesting varioustask-conditioned methodology to improve the initialization. Instead ofsearching for better task-aware initialization, we focus on a complementaryfactor in MAML framework, inner-loop optimization (or fast adaptation).Consequently, we propose a new weight update rule that greatly enhances thefast adaptation process. Specifically, we introduce a small meta-network thatcan adaptively generate per-step hyperparameters: learning rate and weightdecay coefficients. The experimental results validate that the AdaptiveLearning of hyperparameters for Fast Adaptation (ALFA) is the equally importantingredient that was often neglected in the recent few-shot learning approaches.Surprisingly, fast adaptation from random initialization with ALFA can alreadyoutperform MAML.',\n",
       "  'categories': ['cs.LG', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.00209v2'},\n",
       " 904: {'ID': 904,\n",
       "  'title': 'Evaluating Computational Language Models with Scaling Properties of  Natural Language',\n",
       "  'authors': ['Shuntaro Takahashi', 'Kumiko Tanaka-Ishii'],\n",
       "  'published': '2019-06-22T03:24:32Z',\n",
       "  'updated': '2019-06-22T03:24:32Z',\n",
       "  'abstract': \"In this article, we evaluate computational models of natural language withrespect to the universal statistical behaviors of natural language. Statisticalmechanical analyses have revealed that natural language text is characterizedby scaling properties, which quantify the global structure in the vocabularypopulation and the long memory of a text. We study whether five scalingproperties (given by Zipf's law, Heaps' law, Ebeling's method, Taylor's law,and long-range correlation analysis) can serve for evaluation of computationalmodels. Specifically, we test $n$-gram language models, a probabilisticcontext-free grammar (PCFG), language models based on Simon/Pitman-Yorprocesses, neural language models, and generative adversarial networks (GANs)for text generation. Our analysis reveals that language models based onrecurrent neural networks (RNNs) with a gating mechanism (i.e., long short-termmemory, LSTM; a gated recurrent unit, GRU; and quasi-recurrent neural networks,QRNNs) are the only computational models that can reproduce the long memorybehavior of natural language. Furthermore, through comparison with recentlyproposed model-based evaluation methods, we find that the exponent of Taylor'slaw is a good indicator of model quality.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.09379v1'},\n",
       " 905: {'ID': 905,\n",
       "  'title': 'Neural Ordinary Differential Equations on Manifolds',\n",
       "  'authors': ['Luca Falorsi', 'Patrick Forré'],\n",
       "  'published': '2020-06-11T17:56:34Z',\n",
       "  'updated': '2020-06-11T17:56:34Z',\n",
       "  'abstract': 'Normalizing flows are a powerful technique for obtaining reparameterizablesamples from complex multimodal distributions. Unfortunately current approachesfall short when the underlying space has a non trivial topology, and are onlyavailable for the most basic geometries. Recently normalizing flows inEuclidean space based on Neural ODEs show great promise, yet suffer the samelimitations. Using ideas from differential geometry and geometric controltheory, we describe how neural ODEs can be extended to smooth manifolds. Weshow how vector fields provide a general framework for parameterizing aflexible class of invertible mapping on these spaces and we illustrate howgradient based learning can be performed. As a result we define a generalmethodology for building normalizing flows on manifolds.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.06663v1'},\n",
       " 906: {'ID': 906,\n",
       "  'title': 'ADWPNAS: Architecture-Driven Weight Prediction for Neural Architecture  Search',\n",
       "  'authors': ['ChenjunZhou', 'XuZhang', 'BoGu'],\n",
       "  'published': '2020-03-03T05:06:20Z',\n",
       "  'updated': '2020-03-03T05:06:20Z',\n",
       "  'abstract': 'How to discover and evaluate the true strength of models quickly andaccurately is one of the key challenges in Neural Architecture Search (NAS). Tocope with this problem, we propose an Architecture-Driven Weight Prediction(ADWP) approach for neural architecture search (NAS). In our approach, we firstdesign an architecture-intensive search space and then train a HyperNetwork byinputting stochastic encoding architecture parameters. In the trainedHyperNetwork, weights of convolution kernels can be well predicted for neuralarchitectures in the search space. Consequently, the target architectures canbe evaluated efficiently without any finetuning, thus enabling us to searchfortheoptimalarchitectureinthespaceofgeneralnetworks (macro-search). Throughreal experiments, we evaluate the performance of the models discovered by theproposed AD-WPNAS and results show that one search procedure can be completedin 4.0 GPU hours on CIFAR-10. Moreover, the discovered model obtains a testerror of 2.41% with only 1.52M parameters which is superior to the bestexisting models.',\n",
       "  'categories': ['cs.NE', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.01335v1'},\n",
       " 907: {'ID': 907,\n",
       "  'title': 'Event Extraction with Generative Adversarial Imitation Learning',\n",
       "  'authors': ['Tongtao Zhang', 'Heng Ji'],\n",
       "  'published': '2018-04-21T02:43:00Z',\n",
       "  'updated': '2018-04-21T02:43:00Z',\n",
       "  'abstract': 'We propose a new method for event extraction (EE) task based on an imitationlearning framework, specifically, inverse reinforcement learning (IRL) viagenerative adversarial network (GAN). The GAN estimates proper rewardsaccording to the difference between the actions committed by the expert (orground truth) and the agent among complicated states in the environment. EEtask benefits from these dynamic rewards because instances and labels yield tovarious extents of difficulty and the gains are expected to be diverse -- e.g.,an ambiguous but correctly detected trigger or argument should receive highgains -- while the traditional RL models usually neglect such differences andpay equal attention on all instances. Moreover, our experiments alsodemonstrate that the proposed framework outperforms state-of-the-art methods,without explicit feature engineering.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1804.07881v1'},\n",
       " 908: {'ID': 908,\n",
       "  'title': 'Improved training of binary networks for human pose estimation and image  recognition',\n",
       "  'authors': ['Georgios Tzimiropoulos',\n",
       "   'Adrian Bulat',\n",
       "   'Maja Pantic',\n",
       "   'Jean Kossaifi'],\n",
       "  'published': '2019-04-11T17:55:06Z',\n",
       "  'updated': '2019-04-11T17:55:06Z',\n",
       "  'abstract': 'Big neural networks trained on large datasets have advanced thestate-of-the-art for a large variety of challenging problems, improvingperformance by a large margin. However, under low memory and limitedcomputational power constraints, the accuracy on the same problems dropsconsiderable. In this paper, we propose a series of techniques thatsignificantly improve the accuracy of binarized neural networks (i.e networkswhere both the features and the weights are binary). We evaluate the proposedimprovements on two diverse tasks: fine-grained recognition (human poseestimation) and large-scale image recognition (ImageNet classification).Specifically, we introduce a series of novel methodological changes including:(a) more appropriate activation functions, (b) reverse-order initialization,(c) progressive quantization, and (d) network stacking and show that theseadditions improve existing state-of-the-art network binarization techniques,significantly. Additionally, for the first time, we also investigate the extentto which network binarization and knowledge distillation can be combined. Whentested on the challenging MPII dataset, our method shows a performanceimprovement of more than 4% in absolute terms. Finally, we further validate ourfindings by applying the proposed techniques for large-scale object recognitionon the Imagenet dataset, on which we report a reduction of error rate by 4%.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.05868v1'},\n",
       " 909: {'ID': 909,\n",
       "  'title': 'HIGAN: Cosmic Neutral Hydrogen with Generative Adversarial Networks',\n",
       "  'authors': ['Laurence Perreault Levasseur',\n",
       "   'Atakan Okan',\n",
       "   'Asena Derin Cengiz',\n",
       "   'Juan Zamudio-Fernandez',\n",
       "   'Shirley Ho',\n",
       "   'Seda Bilaloglu',\n",
       "   'Siyu He',\n",
       "   'Francisco Villaescusa-Navarro'],\n",
       "  'published': '2019-04-29T17:56:01Z',\n",
       "  'updated': '2019-04-29T17:56:01Z',\n",
       "  'abstract': 'One of the most promising ways to observe the Universe is by detecting the21cm emission from cosmic neutral hydrogen (HI) through radio-telescopes. Thoseobservations can shed light on fundamental astrophysical questions only ifaccurate theoretical predictions are available. In order to maximize thescientific return of these surveys, those predictions need to include differentobservables and be precise on non-linear scales. Currently, one of the bestways to achieve this is via cosmological hydrodynamic simulations; however, thecomputational cost of these simulations is high -- tens of millions of CPUhours. In this work, we use Wasserstein Generative Adversarial Networks (WGANs)to generate new high-resolution ($35~h^{-1}{\\\\rm kpc}$) 3D realizations ofcosmic HI at $z=5$. We do so by sampling from a 100-dimension manifold, learnedby the generator, that characterizes the fully non-linear abundance andclustering of cosmic HI from the state-of-the-art simulation IllustrisTNG. Weshow that different statistical properties of the produced samples -- 1D PDF,power spectrum, bispectrum, and void size function -- match very well those ofIllustrisTNG, and outperform state-of-the-art models such as Halo OccupationDistributions (HODs). Our WGAN samples reproduce the abundance of HI across 9orders of magnitude, from the Ly$\\\\alpha$ forest to Damped Lyman Absorbers. WGANcan produce new samples orders of magnitude faster than hydrodynamicsimulations.',\n",
       "  'categories': ['astro-ph.CO', 'astro-ph.IM', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.12846v1'},\n",
       " 910: {'ID': 910,\n",
       "  'title': 'MIST: Multiple Instance Spatial Transformer Network',\n",
       "  'authors': ['Yuhe Jin',\n",
       "   'Baptiste Angles',\n",
       "   'Kwang Moo Yi',\n",
       "   'Simon Kornblith',\n",
       "   'Andrea Tagliasacchi'],\n",
       "  'published': '2018-11-26T22:49:20Z',\n",
       "  'updated': '2020-12-04T19:19:05Z',\n",
       "  'abstract': 'We propose a deep network that can be trained to tackle image reconstructionand classification problems that involve detection of multiple objectinstances, without any supervision regarding their whereabouts. The networklearns to extract the most significant top-K patches, and feeds these patchesto a task-specific network -- e.g., auto-encoder or classifier -- to solve adomain specific problem. The challenge in training such a network is thenon-differentiable top-K selection process. To address this issue, we lift thetraining optimization problem by treating the result of top-K selection as aslack variable, resulting in a simple, yet effective, multi-stage training. Ourmethod is able to learn to detect recurrent structures in the training datasetby learning to reconstruct images. It can also learn to localize structureswhen only knowledge on the occurrence of the object is provided, and in doingso it outperforms the state-of-the-art.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.10725v5'},\n",
       " 911: {'ID': 911,\n",
       "  'title': 'Flow-based Generative Models for Learning Manifold to Manifold Mappings',\n",
       "  'authors': ['Xingjian Zhen',\n",
       "   'Vikas Singh',\n",
       "   'Rudrasis Chakraborty',\n",
       "   'Liu Yang'],\n",
       "  'published': '2020-12-18T02:19:18Z',\n",
       "  'updated': '2020-12-18T02:19:18Z',\n",
       "  'abstract': 'Many measurements or observations in computer vision and machine learningmanifest as non-Euclidean data. While recent proposals (like spherical CNN)have extended a number of deep neural network architectures to manifold-valueddata, and this has often provided strong improvements in performance, theliterature on generative models for manifold data is quite sparse. Partly dueto this gap, there are also no modality transfer/translation models formanifold-valued data whereas numerous such methods based on generative modelsare available for natural images. This paper addresses this gap, motivated by aneed in brain imaging -- in doing so, we expand the operating range of certaingenerative models (as well as generative models for modality transfer) fromnatural images to images with manifold-valued measurements. Our main result isthe design of a two-stream version of GLOW (flow-based invertible generativemodels) that can synthesize information of a field of one type ofmanifold-valued measurements given another. On the theoretical side, weintroduce three kinds of invertible layers for manifold-valued data, which arenot only analogous to their functionality in flow-based generative models(e.g., GLOW) but also preserve the key benefits (determinants of the Jacobianare easy to calculate). For experiments, on a large dataset from the HumanConnectome Project (HCP), we show promising results where we can reliably andaccurately reconstruct brain images of a field of orientation distributionfunctions (ODF) from diffusion tensor images (DTI), where the latter has a$5\\\\times$ faster acquisition time but at the expense of worse angularresolution.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.10013v1'},\n",
       " 912: {'ID': 912,\n",
       "  'title': 'Spectral Unmixing With Multinomial Mixture Kernel and Wasserstein  Generative Adversarial Loss',\n",
       "  'authors': ['Savas Ozkan', 'Gozde Bozdagi Akar'],\n",
       "  'published': '2020-12-12T16:49:01Z',\n",
       "  'updated': '2020-12-12T16:49:01Z',\n",
       "  'abstract': 'This study proposes a novel framework for spectral unmixing by using 1Dconvolution kernels and spectral uncertainty. High-level representations arecomputed from data, and they are further modeled with the Multinomial MixtureModel to estimate fractions under severe spectral uncertainty. Furthermore, anew trainable uncertainty term based on a nonlinear neural network model isintroduced in the reconstruction step. All uncertainty models are optimized byWasserstein Generative Adversarial Network (WGAN) to improve stability andcapture uncertainty. Experiments are performed on both real and syntheticdatasets. The results validate that the proposed method obtainsstate-of-the-art performance, especially for the real datasets compared to thebaselines. Project page at: https://github.com/savasozkan/dscn.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.06859v1'},\n",
       " 913: {'ID': 913,\n",
       "  'title': 'Improving Deep Image Clustering With Spatial Transformer Layers',\n",
       "  'authors': ['Cleber Zanchettin', 'Thiago V. M. Souza'],\n",
       "  'published': '2019-02-09T01:56:24Z',\n",
       "  'updated': '2019-10-24T13:43:23Z',\n",
       "  'abstract': 'Image clustering is an important but challenging task in machine learning. Asin most image processing areas, the latest improvements came from models basedon the deep learning approach. However, classical deep learning methods haveproblems to deal with spatial image transformations like scale and rotation. Inthis paper, we propose the use of visual attention techniques to reduce thisproblem in image clustering methods. We evaluate the combination of a deepimage clustering model called Deep Adaptive Clustering (DAC) with the SpatialTransformer Networks (STN). The proposed model is evaluated in the datasetsMNIST and FashionMNIST and outperformed the baseline model.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1902.05401v2'},\n",
       " 914: {'ID': 914,\n",
       "  'title': 'Adversarial NLI: A New Benchmark for Natural Language Understanding',\n",
       "  'authors': ['Adina Williams',\n",
       "   'Jason Weston',\n",
       "   'Mohit Bansal',\n",
       "   'Douwe Kiela',\n",
       "   'Yixin Nie',\n",
       "   'Emily Dinan'],\n",
       "  'published': '2019-10-31T16:50:43Z',\n",
       "  'updated': '2020-05-06T17:01:56Z',\n",
       "  'abstract': 'We introduce a new large-scale NLI benchmark dataset, collected via aniterative, adversarial human-and-model-in-the-loop procedure. We show thattraining models on this new dataset leads to state-of-the-art performance on avariety of popular NLI benchmarks, while posing a more difficult challenge withits new test set. Our analysis sheds light on the shortcomings of currentstate-of-the-art models, and shows that non-expert annotators are successful atfinding their weaknesses. The data collection method can be applied in anever-ending learning scenario, becoming a moving target for NLU, rather than astatic benchmark that will quickly saturate.',\n",
       "  'categories': ['cs.CL', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.14599v2'},\n",
       " 915: {'ID': 915,\n",
       "  'title': 'Multi-Sense Language Modelling',\n",
       "  'authors': ['Peter Schneider-Kamp', 'Andrea Lekkas', 'Isabelle Augenstein'],\n",
       "  'published': '2020-12-10T16:06:05Z',\n",
       "  'updated': '2020-12-10T16:06:05Z',\n",
       "  'abstract': 'The effectiveness of a language model is influenced by its tokenrepresentations, which must encode contextual information and handle the sameword form having a plurality of meanings (polysemy). Currently, none of thecommon language modelling architectures explicitly model polysemy. We propose alanguage model which not only predicts the next word, but also its sense incontext. We argue that this higher prediction granularity may be useful for endtasks such as assistive writing, and allow for more a precise linking oflanguage models with knowledge bases. We find that multi-sense languagemodelling requires architectures that go beyond standard language models, andhere propose a structured prediction framework that decomposes the task into aword followed by a sense prediction task. For sense prediction, we utilise aGraph Attention Network, which encodes definitions and example uses of wordsenses. Overall, we find that multi-sense language modelling is a highlychallenging task, and suggest that future work focus on the creation of moreannotated training datasets.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.05776v1'},\n",
       " 916: {'ID': 916,\n",
       "  'title': 'ROS2Learn: a reinforcement learning framework for ROS 2',\n",
       "  'authors': ['Lander Usategui San Juan',\n",
       "   'Alejandro Solano Rueda',\n",
       "   'Elias Barba Moral',\n",
       "   'Nestor Gonzalez Lopez',\n",
       "   'Yue Leire Erro Nuin',\n",
       "   'Víctor Mayoral Vilches',\n",
       "   'Risto Kojcev'],\n",
       "  'published': '2019-03-14T22:13:23Z',\n",
       "  'updated': '2019-03-18T05:27:29Z',\n",
       "  'abstract': 'We propose a novel framework for Deep Reinforcement Learning (DRL) in modularrobotics to train a robot directly from joint states, using traditional robotictools. We use an state-of-the-art implementation of the Proximal PolicyOptimization, Trust Region Policy Optimization and Actor-CriticKronecker-Factored Trust Region algorithms to learn policies in four differentModular Articulated Robotic Arm (MARA) environments. We support this processusing a framework that communicates with typical tools used in robotics, suchas Gazebo and Robot Operating System 2 (ROS 2). We evaluate several algorithmsin modular robots with an empirical study in simulation.',\n",
       "  'categories': ['cs.RO', 'cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1903.06282v2'},\n",
       " 917: {'ID': 917,\n",
       "  'title': 'Multi-Path Policy Optimization',\n",
       "  'authors': ['Longbo Huang', 'Qingpeng Cai', 'Ling Pan'],\n",
       "  'published': '2019-11-11T12:19:23Z',\n",
       "  'updated': '2020-02-14T15:17:23Z',\n",
       "  'abstract': 'Recent years have witnessed a tremendous improvement of deep reinforcementlearning. However, a challenging problem is that an agent may suffer frominefficient exploration, particularly for on-policy methods. Previousexploration methods either rely on complex structure to estimate the novelty ofstates, or incur sensitive hyper-parameters causing instability. We propose anefficient exploration method, Multi-Path Policy Optimization (MPPO), which doesnot incur high computation cost and ensures stability. MPPO maintains anefficient mechanism that effectively utilizes a population of diverse policiesto enable better exploration, especially in sparse environments. We also give atheoretical guarantee of the stable performance. We build our scheme upon twowidely-adopted on-policy methods, the Trust-Region Policy Optimizationalgorithm and Proximal Policy Optimization algorithm. We conduct extensiveexperiments on several MuJoCo tasks and their sparsified variants to fairlyevaluate the proposed method. Results show that MPPO significantly outperformsstate-of-the-art exploration methods in terms of both sample efficiency andfinal performance.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1911.04207v3'},\n",
       " 918: {'ID': 918,\n",
       "  'title': 'Class-Conditional Compression and Disentanglement: Bridging the Gap  between Neural Networks and Naive Bayes Classifiers',\n",
       "  'authors': ['Rana Ali Amjad', 'Bernhard C. Geiger'],\n",
       "  'published': '2019-06-06T13:32:54Z',\n",
       "  'updated': '2019-06-06T13:32:54Z',\n",
       "  'abstract': 'In this draft, which reports on work in progress, we 1) adapt the informationbottleneck functional by replacing the compression term by class-conditionalcompression, 2) relax this functional using a variational bound related toclass-conditional disentanglement, 3) consider this functional as a trainingobjective for stochastic neural networks, and 4) show that the latentrepresentations are learned such that they can be used in a naive Bayesclassifier. We continue by suggesting a series of experiments along the linesof Nonlinear In-formation Bottleneck [Kolchinsky et al., 2018], DeepVariational Information Bottleneck [Alemi et al., 2017], and InformationDropout [Achille and Soatto, 2018]. We furthermore suggest a neural networkwhere the decoder architecture is a parameterized naive Bayes decoder.',\n",
       "  'categories': ['cs.LG', 'cs.IT', 'math.IT', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.02576v1'},\n",
       " 919: {'ID': 919,\n",
       "  'title': 'A Self-Attentive model for Knowledge Tracing',\n",
       "  'authors': ['Shalini Pandey', 'George Karypis'],\n",
       "  'published': '2019-07-16T04:47:35Z',\n",
       "  'updated': '2019-07-16T04:47:35Z',\n",
       "  'abstract': \"Knowledge tracing is the task of modeling each student's mastery of knowledgeconcepts (KCs) as (s)he engages with a sequence of learning activities. Eachstudent's knowledge is modeled by estimating the performance of the student onthe learning activities. It is an important research area for providing apersonalized learning platform to students. In recent years, methods based onRecurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) andDynamic Key-Value Memory Network (DKVMN) outperformed all the traditionalmethods because of their ability to capture complex representation of humanlearning. However, these methods face the issue of not generalizing well whiledealing with sparse data which is the case with real-world data as studentsinteract with few KCs. In order to address this issue, we develop an approachthat identifies the KCs from the student's past activities that are\\\\textit{relevant} to the given KC and predicts his/her mastery based on therelatively few KCs that it picked. Since predictions are made based onrelatively few past activities, it handles the data sparsity problem betterthan the methods based on RNN. For identifying the relevance between the KCs,we propose a self-attention based approach, Self Attentive Knowledge Tracing(SAKT). Extensive experimentation on a variety of real-world dataset shows thatour model outperforms the state-of-the-art models for knowledge tracing,improving AUC by 4.43% on average.\",\n",
       "  'categories': ['cs.LG', 'cs.CY', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1907.06837v1'},\n",
       " 920: {'ID': 920,\n",
       "  'title': 'Fast Global Convergence of Natural Policy Gradient Methods with Entropy  Regularization',\n",
       "  'authors': ['Shicong Cen',\n",
       "   'Chen Cheng',\n",
       "   'Yuxin Chen',\n",
       "   'Yuting Wei',\n",
       "   'Yuejie Chi'],\n",
       "  'published': '2020-07-13T17:58:41Z',\n",
       "  'updated': '2020-09-24T19:16:41Z',\n",
       "  'abstract': 'Natural policy gradient (NPG) methods are among the most widely used policyoptimization algorithms in contemporary reinforcement learning. This class ofmethods is often applied in conjunction with entropy regularization -- analgorithmic scheme that encourages exploration -- and is closely related tosoft policy iteration and trust region policy optimization. Despite theempirical success, the theoretical underpinnings for NPG methods remain limitedeven for the tabular setting. This paper develops $\\\\textit{non-asymptotic}$convergence guarantees for entropy-regularized NPG methods under softmaxparameterization, focusing on discounted Markov decision processes (MDPs).Assuming access to exact policy evaluation, we demonstrate that the algorithmconverges linearly -- or even quadratically once it enters a local regionaround the optimal policy -- when computing optimal value functions of theregularized MDP. Moreover, the algorithm is provably stable vis-\\\\`a-visinexactness of policy evaluation. Our convergence results accommodate a widerange of learning rates, and shed light upon the role of entropy regularizationin enabling fast convergence.',\n",
       "  'categories': ['stat.ML', 'cs.IT', 'cs.LG', 'math.IT', 'math.OC'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.06558v4'},\n",
       " 921: {'ID': 921,\n",
       "  'title': 'A GAN-Based Image Transformation Scheme for Privacy-Preserving Deep  Neural Networks',\n",
       "  'authors': ['Hitoshi Kiya', 'Warit Sirichotedumrong'],\n",
       "  'published': '2020-06-02T01:57:21Z',\n",
       "  'updated': '2020-06-02T01:57:21Z',\n",
       "  'abstract': 'We propose a novel image transformation scheme using generative adversarialnetworks (GANs) for privacy-preserving deep neural networks (DNNs). Theproposed scheme enables us not only to apply images without visual informationto DNNs, but also to enhance robustness against ciphertext-only attacks (COAs)including DNN-based attacks. In this paper, the proposed transformation schemeis demonstrated to be able to protect visual information on plain images, andthe visually-protected images are directly applied to DNNs forprivacy-preserving image classification. Since the proposed scheme utilizesGANs, there is no need to manage encryption keys. In an image classificationexperiment, we evaluate the effectiveness of the proposed scheme in terms ofclassification accuracy and robustness against COAs.',\n",
       "  'categories': ['cs.CR', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.01342v1'},\n",
       " 922: {'ID': 922,\n",
       "  'title': 'DeSTNet: Densely Fused Spatial Transformer Networks',\n",
       "  'authors': ['Roberto Annunziata', 'Christos Sagonas', 'Jacques Calì'],\n",
       "  'published': '2018-07-11T10:06:32Z',\n",
       "  'updated': '2018-07-16T10:27:31Z',\n",
       "  'abstract': 'Modern Convolutional Neural Networks (CNN) are extremely powerful on a rangeof computer vision tasks. However, their performance may degrade when the datais characterised by large intra-class variability caused by spatialtransformations. The Spatial Transformer Network (STN) is currently the methodof choice for providing CNNs the ability to remove those transformations andimprove performance in an end-to-end learning framework. In this paper, wepropose Densely Fused Spatial Transformer Network (DeSTNet), which, to our bestknowledge, is the first dense fusion pattern for combining multiple STNs.Specifically, we show how changing the connectivity pattern of multiple STNsfrom sequential to dense leads to more powerful alignment modules. Extensiveexperiments on three benchmarks namely, MNIST, GTSRB, and IDocDB show that theproposed technique outperforms related state-of-the-art methods (i.e., STNs andCSTNs) both in terms of accuracy and robustness.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1807.04050v2'},\n",
       " 923: {'ID': 923,\n",
       "  'title': \"Visualization of AE's Training on Credit Card Transactions with  Persistent Homology\",\n",
       "  'authors': ['Jean Hilger',\n",
       "   'Francois Petit',\n",
       "   'Radu State',\n",
       "   'Jeremy Charlier',\n",
       "   'Gaston Ormazabal'],\n",
       "  'published': '2019-05-24T06:48:11Z',\n",
       "  'updated': '2019-08-12T06:16:58Z',\n",
       "  'abstract': 'Auto-encoders are among the most popular neural network architecture fordimension reduction. They are composed of two parts: the encoder which maps themodel distribution to a latent manifold and the decoder which maps the latentmanifold to a reconstructed distribution. However, auto-encoders are known toprovoke chaotically scattered data distribution in the latent manifoldresulting in an incomplete reconstructed distribution. Current distancemeasures fail to detect this problem because they are not able to acknowledgethe shape of the data manifolds, i.e. their topological features, and the scaleat which the manifolds should be analyzed. We propose Persistent Homology forWasserstein Auto-Encoders, called PHom-WAE, a new methodology to assess andmeasure the data distribution of a generative model. PHom-WAE minimizes theWasserstein distance between the true distribution and the reconstructeddistribution and uses persistent homology, the study of the topologicalfeatures of a space at different spatial resolutions, to compare the nature ofthe latent manifold and the reconstructed distribution. Our experimentsunderline the potential of persistent homology for Wasserstein Auto-Encoders incomparison to Variational Auto-Encoders, another type of generative model. Theexperiments are conducted on a real-world data set particularly challenging fortraditional distance measures and auto-encoders. PHom-WAE is the firstmethodology to propose a topological distance measure, the bottleneck distance,for Wasserstein Auto-Encoders used to compare decoded samples of high qualityin the context of credit card transactions.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.13020v2'},\n",
       " 924: {'ID': 924,\n",
       "  'title': 'Constrained Neural Ordinary Differential Equations with Stability  Guarantees',\n",
       "  'authors': ['Draguna Vrabie', 'Jan Drgona', 'Aaron Tuor'],\n",
       "  'published': '2020-04-22T22:07:57Z',\n",
       "  'updated': '2020-04-22T22:07:57Z',\n",
       "  'abstract': \"Differential equations are frequently used in engineering domains, such asmodeling and control of industrial systems, where safety and performanceguarantees are of paramount importance. Traditional physics-based modelingapproaches require domain expertise and are often difficult to tune or adapt tonew systems. In this paper, we show how to model discrete ordinary differentialequations (ODE) with algebraic nonlinearities as deep neural networks withvarying degrees of prior knowledge. We derive the stability guarantees of thenetwork layers based on the implicit constraints imposed on the weight'seigenvalues. Moreover, we show how to use barrier methods to generically handleadditional inequality constraints. We demonstrate the prediction accuracy oflearned neural ODEs evaluated on open-loop simulations compared to ground truthdynamics with bi-linear terms.\",\n",
       "  'categories': ['eess.SY', 'cs.LG', 'cs.NE', 'cs.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.10883v1'},\n",
       " 925: {'ID': 925,\n",
       "  'title': 'Optimal Transport driven CycleGAN for Unsupervised Learning in Inverse  Problems',\n",
       "  'authors': ['Byeongsu Sim',\n",
       "   'Gyutaek Oh',\n",
       "   'Chanyong Jung',\n",
       "   'Jong Chul Ye',\n",
       "   'Jeongsol Kim'],\n",
       "  'published': '2019-09-25T11:28:49Z',\n",
       "  'updated': '2020-08-30T12:14:48Z',\n",
       "  'abstract': 'To improve the performance of classical generative adversarial network (GAN),Wasserstein generative adversarial networks (W-GAN) was developed as aKantorovich dual formulation of the optimal transport (OT) problem usingWasserstein-1 distance. However, it was not clear how cycleGAN-type generativemodels can be derived from the optimal transport theory. Here we show that anovel cycleGAN architecture can be derived as a Kantorovich dual OT formulationif a penalized least square (PLS) cost with deep learning-based inverse pathpenalty is used as a transportation cost. One of the most important advantagesof this formulation is that depending on the knowledge of the forward problem,distinct variations of cycleGAN architecture can be derived: for example, onewith two pairs of generators and discriminators, and the other with only asingle pair of generator and discriminator. Even for the two generator cases,we show that the structural knowledge of the forward operator can lead to asimpler generator architecture which significantly simplifies the neuralnetwork training. The new cycleGAN formulation, what we call the OT-cycleGAN,have been applied for various biomedical imaging problems, such as acceleratedmagnetic resonance imaging (MRI), super-resolution microscopy, and low-dosex-ray computed tomography (CT). Experimental results confirm the efficacy andflexibility of the theory.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'eess.IV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1909.12116v4'},\n",
       " 926: {'ID': 926,\n",
       "  'title': 'Meta Architecture Search',\n",
       "  'authors': ['Bo Dai', 'Weiyang Liu', 'Wei Wei', 'Albert Shaw', 'Le Song'],\n",
       "  'published': '2018-12-22T19:25:08Z',\n",
       "  'updated': '2019-11-15T16:06:14Z',\n",
       "  'abstract': 'Neural Architecture Search (NAS) has been quite successful in constructingstate-of-the-art models on a variety of tasks. Unfortunately, the computationalcost can make it difficult to scale. In this paper, we make the first attemptto study Meta Architecture Search which aims at learning a task-agnosticrepresentation that can be used to speed up the process of architecture searchon a large number of tasks. We propose the Bayesian Meta Architecture SEarch(BASE) framework which takes advantage of a Bayesian formulation of thearchitecture search problem to learn over an entire set of taskssimultaneously. We show that on Imagenet classification, we can find a modelthat achieves 25.7% top-1 error and 8.1% top-5 error by adapting thearchitecture in less than an hour from an 8 GPU days pretrained meta-network.By learning a good prior for NAS, our method dramatically decreases therequired computation cost while achieving comparable performance to currentstate-of-the-art methods - even finding competitive models for unseen datasetswith very quick adaptation. We believe our framework will open up newpossibilities for efficient and massively scalable architecture search researchacross multiple tasks.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1812.09584v2'},\n",
       " 927: {'ID': 927,\n",
       "  'title': 'Variation-aware Binarized Memristive Networks',\n",
       "  'authors': ['Olga Krestinskaya',\n",
       "   'Alex James',\n",
       "   'Mostafa Rahimi Azghadi',\n",
       "   'Corey Lammie'],\n",
       "  'published': '2019-10-14T05:46:12Z',\n",
       "  'updated': '2019-10-14T05:46:12Z',\n",
       "  'abstract': 'The quantization of weights to binary states in Deep Neural Networks (DNNs)can replace resource-hungry multiply accumulate operations with simpleaccumulations. Such Binarized Neural Networks (BNNs) exhibit greatly reducedresource and power requirements. In addition, memristors have been shown aspromising synaptic weight elements in DNNs. In this paper, we propose andsimulate novel Binarized Memristive Convolutional Neural Network (BMCNN)architectures employing hybrid weight and parameter representations. We trainthe proposed architectures offline and then map the trained parameters to ourbinarized memristive devices for inference. To take into account the variationsin memristive devices, and to study their effect on the performance, weintroduce variations in $R_{ON}$ and $R_{OFF}$. Moreover, we introduce means tomitigate the adverse effect of memristive variations in our proposed networks.Finally, we benchmark our BMCNNs and variation-aware BMCNNs using the MNISTdataset.',\n",
       "  'categories': ['cs.ET', 'cs.NE', 'eess.SP'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.05920v1'},\n",
       " 928: {'ID': 928,\n",
       "  'title': 'Perceptually Optimizing Deep Image Compression',\n",
       "  'authors': ['Andrey Norkin',\n",
       "   'Li-Heng Chen',\n",
       "   'Zhi Li',\n",
       "   'Alan C. Bovik',\n",
       "   'Christos G. Bampis'],\n",
       "  'published': '2020-07-03T14:33:28Z',\n",
       "  'updated': '2020-07-09T15:04:06Z',\n",
       "  'abstract': 'Mean squared error (MSE) and $\\\\ell_p$ norms have largely dominated themeasurement of loss in neural networks due to their simplicity and analyticalproperties. However, when used to assess visual information loss, these simplenorms are not highly consistent with human perception. Here, we propose adifferent proxy approach to optimize image analysis networks againstquantitative perceptual models. Specifically, we construct a proxy network,which mimics the perceptual model while serving as a loss layer of thenetwork.We experimentally demonstrate how this optimization framework can beapplied to train an end-to-end optimized image compression network. By buildingon top of a modern deep image compression models, we are able to demonstrate anaveraged bitrate reduction of $28.7\\\\%$ over MSE optimization, given a specifiedperceptual quality (VMAF) level.',\n",
       "  'categories': ['eess.IV', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2007.02711v2'},\n",
       " 929: {'ID': 929,\n",
       "  'title': 'Interpretable Set Functions',\n",
       "  'authors': ['Taman Narayan',\n",
       "   'Maya Gupta',\n",
       "   'Serena Wang',\n",
       "   'Tao Zhu',\n",
       "   'James Muller',\n",
       "   'Heinrich Jiang',\n",
       "   'Andrew Cotter'],\n",
       "  'published': '2018-05-31T18:53:15Z',\n",
       "  'updated': '2018-05-31T18:53:15Z',\n",
       "  'abstract': 'We propose learning flexible but interpretable functions that aggregate avariable-length set of permutation-invariant feature vectors to predict alabel. We use a deep lattice network model so we can architect the modelstructure to enhance interpretability, and add monotonicity constraints betweeninputs-and-outputs. We then use the proposed set function to automate theengineering of dense, interpretable features from sparse categorical features,which we call semantic feature engine. Experiments on real-world data show theachieved accuracy is similar to deep sets or deep neural networks, and iseasier to debug and understand.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.00050v1'},\n",
       " 930: {'ID': 930,\n",
       "  'title': 'Dynamic Key-Value Memory Networks for Knowledge Tracing',\n",
       "  'authors': ['Jiani Zhang', 'Dit-Yan Yeung', 'Xingjian Shi', 'Irwin King'],\n",
       "  'published': '2016-11-24T09:12:47Z',\n",
       "  'updated': '2017-02-17T06:09:27Z',\n",
       "  'abstract': \"Knowledge Tracing (KT) is a task of tracing evolving knowledge state ofstudents with respect to one or more concepts as they engage in a sequence oflearning activities. One important purpose of KT is to personalize the practicesequence to help students learn knowledge concepts efficiently. However,existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracingeither model knowledge state for each predefined concept separately or fail topinpoint exactly which concepts a student is good at or unfamiliar with. Tosolve these problems, this work introduces a new model called Dynamic Key-ValueMemory Networks (DKVMN) that can exploit the relationships between underlyingconcepts and directly output a student's mastery level of each concept. Unlikestandard memory-augmented neural networks that facilitate a single memorymatrix or two static memory matrices, our model has one static matrix calledkey, which stores the knowledge concepts and the other dynamic matrix calledvalue, which stores and updates the mastery levels of corresponding concepts.Experiments show that our model consistently outperforms the state-of-the-artmodel in a range of KT datasets. Moreover, the DKVMN model can automaticallydiscover underlying concepts of exercises typically performed by humanannotations and depict the changing knowledge state of a student.\",\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1611.08108v2'},\n",
       " 931: {'ID': 931,\n",
       "  'title': 'Unsupervised Pidgin Text Generation By Pivoting English Data and  Self-Training',\n",
       "  'authors': ['Vera Demberg',\n",
       "   'David Ifeoluwa Adelani',\n",
       "   'Ernie Chang',\n",
       "   'Xiaoyu Shen'],\n",
       "  'published': '2020-03-18T15:27:35Z',\n",
       "  'updated': '2020-03-18T15:27:35Z',\n",
       "  'abstract': 'West African Pidgin English is a language that is significantly spoken inWest Africa, consisting of at least 75 million speakers. Nevertheless, propermachine translation systems and relevant NLP datasets for pidgin English arevirtually absent. In this work, we develop techniques targeted at bridging thegap between Pidgin English and English in the context of natural languagegeneration. %As a proof of concept, we explore the proposed techniques in thearea of data-to-text generation. By building upon the previously releasedmonolingual Pidgin English text and parallel English data-to-text corpus, wehope to build a system that can automatically generate Pidgin Englishdescriptions from structured data. We first train a data-to-English textgeneration system, before employing techniques in unsupervised neural machinetranslation and self-training to establish the Pidgin-to-English cross-lingualalignment. The human evaluation performed on the generated Pidgin texts showsthat, though still far from being practically usable, the pivoting +self-training technique improves both Pidgin text fluency and relevance.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.08272v1'},\n",
       " 932: {'ID': 932,\n",
       "  'title': 'EditNTS: An Neural Programmer-Interpreter Model for Sentence  Simplification through Explicit Editing',\n",
       "  'authors': ['Zichao Li',\n",
       "   'Yue Dong',\n",
       "   'Jackie Chi Kit Cheung',\n",
       "   'Mehdi Rezagholizadeh'],\n",
       "  'published': '2019-06-19T14:00:15Z',\n",
       "  'updated': '2019-06-19T14:00:15Z',\n",
       "  'abstract': 'We present the first sentence simplification model that learns explicit editoperations (ADD, DELETE, and KEEP) via a neural programmer-interpreterapproach. Most current neural sentence simplification systems are variants ofsequence-to-sequence models adopted from machine translation. These methodslearn to simplify sentences as a byproduct of the fact that they are trained oncomplex-simple sentence pairs. By contrast, our neural programmer-interpreteris directly trained to predict explicit edit operations on targeted parts ofthe input sentence, resembling the way that humans might perform simplificationand revision. Our model outperforms previous state-of-the-art neural sentencesimplification models (without external knowledge) by large margins on threebenchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89WikiSmall, +1.41 Newsela), and is judged by humans to produce overall betterand simpler output sentences.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.08104v1'},\n",
       " 933: {'ID': 933,\n",
       "  'title': 'VAW-GAN for Singing Voice Conversion with Non-parallel Training Data',\n",
       "  'authors': ['Haizhou Li', 'Junchen Lu', 'Berrak Sisman', 'Kun Zhou'],\n",
       "  'published': '2020-08-10T09:44:10Z',\n",
       "  'updated': '2020-11-03T10:58:10Z',\n",
       "  'abstract': \"Singing voice conversion aims to convert singer's voice from source to targetwithout changing singing content. Parallel training data is typically requiredfor the training of singing voice conversion system, that is however notpractical in real-life applications. Recent encoder-decoder structures, such asvariational autoencoding Wasserstein generative adversarial network (VAW-GAN),provide an effective way to learn a mapping through non-parallel training data.In this paper, we propose a singing voice conversion framework that is based onVAW-GAN. We train an encoder to disentangle singer identity and singing prosody(F0 contour) from phonetic content. By conditioning on singer identity and F0,the decoder generates output spectral features with unseen target singeridentity, and improves the F0 rendering. Experimental results show that theproposed framework achieves better performance than the baseline frameworks.\",\n",
       "  'categories': ['eess.AS', 'cs.CL', 'cs.SD'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.03992v3'},\n",
       " 934: {'ID': 934,\n",
       "  'title': 'Classification Confidence Estimation with Test-Time Data-Augmentation',\n",
       "  'authors': ['Yuval Bahat', 'Gregory Shakhnarovich'],\n",
       "  'published': '2020-06-30T11:59:53Z',\n",
       "  'updated': '2020-06-30T11:59:53Z',\n",
       "  'abstract': \"Machine learning plays an increasingly significant role in many aspects ofour lives (including medicine, transportation, security, justice and otherdomains), making the potential consequences of false predictions increasinglydevastating. These consequences may be mitigated if we can automatically flagsuch false predictions and potentially assign them to alternative, morereliable mechanisms, that are possibly more costly and involve human attention.This suggests the task of detecting errors, which we tackle in this paper forthe case of visual classification. To this end, we propose a novel approach forclassification confidence estimation. We apply a set of semantics-preservingimage transformations to the input image, and show how the resulting image setscan be used to estimate confidence in the classifier's prediction. Wedemonstrate the potential of our approach by extensively evaluating it on awide variety of classifier architectures and datasets, includingResNext/ImageNet, achieving state of the art performance. This paperconstitutes a significant revision of our earlier work in this direction (Bahat&amp; Shakhnarovich, 2018).\",\n",
       "  'categories': ['cs.CV', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.16705v1'},\n",
       " 935: {'ID': 935,\n",
       "  'title': 'From Unsupervised Machine Translation To Adversarial Text Generation',\n",
       "  'authors': ['Alan Do-Omri',\n",
       "   'Ahmad Rashid',\n",
       "   'Qun Liu',\n",
       "   'Md. Akmal Haidar',\n",
       "   'Mehdi Rezagholizadeh'],\n",
       "  'published': '2020-11-10T23:03:50Z',\n",
       "  'updated': '2020-11-10T23:03:50Z',\n",
       "  'abstract': 'We present a self-attention based bilingual adversarial text generator(B-GAN) which can learn to generate text from the encoder representation of anunsupervised neural machine translation system. B-GAN is able to generate adistributed latent space representation which can be paired with an attentionbased decoder to generate fluent sentences. When trained on an encoder sharedbetween two languages and paired with the appropriate decoder, it can generatesentences in either language. B-GAN is trained using a combination ofreconstruction loss for auto-encoder, a cross domain loss for translation and aGAN based adversarial loss for text generation. We demonstrate that B-GAN,trained on monolingual corpora only using multiple losses, generates morefluent sentences compared to monolingual baselines while effectively using halfthe number of parameters.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.05449v1'},\n",
       " 936: {'ID': 936,\n",
       "  'title': 'A New Framework for Multi-Agent Reinforcement Learning -- Centralized  Training and Exploration with Decentralized Execution via Policy Distillation',\n",
       "  'authors': ['Gang Chen'],\n",
       "  'published': '2019-10-21T05:07:42Z',\n",
       "  'updated': '2019-10-21T05:07:42Z',\n",
       "  'abstract': \"Deep reinforcement learning (DRL) is a booming area of artificialintelligence. Many practical applications of DRL naturally involve more thanone collaborative learners, making it important to study DRL in a multi-agentcontext. Previous research showed that effective learning in complexmulti-agent systems demands for highly coordinated environment explorationamong all the participating agents. Many researchers attempted to cope withthis challenge through learning centralized value functions. However, thecommon strategy for every agent to learn their local policies directly oftenfail to nurture strong inter-agent collaboration and can be sample inefficientwhenever agents alter their communication channels. To address these issues, wepropose a new framework known as centralized training and exploration withdecentralized execution via policy distillation. Guided by this framework andthe maximum-entropy learning technique, we will first train agents' policieswith shared global component to foster coordinated and effective learning.Locally executable policies will be derived subsequently from the trainedglobal policies via policy distillation. Experiments show that our newframework and algorithm can achieve significantly better performance and highersample efficiency than a cutting-edge baseline on several multi-agent DRLbenchmarks.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.09152v1'},\n",
       " 937: {'ID': 937,\n",
       "  'title': 'Linearized Multi-Sampling for Differentiable Image Transformation',\n",
       "  'authors': ['Weiwei Sun',\n",
       "   'Kwang Moo Yi',\n",
       "   'Wei Jiang',\n",
       "   'Eduard Trulls',\n",
       "   'Andrea Tagliasacchi'],\n",
       "  'published': '2019-01-22T00:07:12Z',\n",
       "  'updated': '2019-09-10T17:17:32Z',\n",
       "  'abstract': 'We propose a novel image sampling method for differentiable imagetransformation in deep neural networks. The sampling schemes currently used indeep learning, such as Spatial Transformer Networks, rely on bilinearinterpolation, which performs poorly under severe scale changes, and moreimportantly, results in poor gradient propagation. This is due to their strictreliance on direct neighbors. Instead, we propose to generate random auxiliarysamples in the vicinity of each pixel in the sampled image, and create a linearapproximation with their intensity values. We then use this approximation as adifferentiable formula for the transformed image. We demonstrate that ourapproach produces more representative gradients with a wider basin ofconvergence for image alignment, which leads to considerable performanceimprovements when training networks for classification tasks. This is not onlytrue under large downsampling, but also when there are no scale changes. Wecompare our approach with multi-scale sampling and show that we outperform it.We then demonstrate that our improvements to the sampler are compatible withother tangential improvements to Spatial Transformer Networks and that itfurther improves their performance.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.07124v3'},\n",
       " 938: {'ID': 938,\n",
       "  'title': 'One-Shot Learning for Text-to-SQL Generation',\n",
       "  'authors': ['Sungroh Yoon',\n",
       "   'Jongyun Song',\n",
       "   'Jaesik Yoon',\n",
       "   'Dongjun Lee',\n",
       "   'Sanggil Lee'],\n",
       "  'published': '2019-04-26T06:29:29Z',\n",
       "  'updated': '2019-04-26T06:29:29Z',\n",
       "  'abstract': 'Most deep learning approaches for text-to-SQL generation are limited to theWikiSQL dataset, which only supports very simple queries. Recently,template-based and sequence-to-sequence approaches were proposed to supportcomplex queries, which contain join queries, nested queries, and other types.However, Finegan-Dollak et al. (2018) demonstrated that both the approacheslack the ability to generate SQL of unseen templates. In this paper, we proposea template-based one-shot learning model for the text-to-SQL generation so thatthe model can generate SQL of an untrained template based on a single example.First, we classify the SQL template using the Matching Network that isaugmented by our novel architecture Candidate Search Network. Then, we fill thevariable slots in the predicted template using the Pointer Network. We showthat our model outperforms state-of-the-art approaches for various text-to-SQLdatasets in two aspects: 1) the SQL generation accuracy for the trainedtemplates, and 2) the adaptability to the unseen SQL templates based on asingle example without any additional training.',\n",
       "  'categories': ['cs.CL', 'cs.DB'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.11499v1'},\n",
       " 939: {'ID': 939,\n",
       "  'title': 'Decorrelated Double Q-learning',\n",
       "  'authors': ['Gang Chen'],\n",
       "  'published': '2020-06-12T05:59:05Z',\n",
       "  'updated': '2020-06-12T05:59:05Z',\n",
       "  'abstract': 'Q-learning with value function approximation may have the poor performancebecause of overestimation bias and imprecise estimate. Specifically,overestimation bias is from the maximum operator over noise estimate, which isexaggerated using the estimate of a subsequent state. Inspired by the recentadvance of deep reinforcement learning and Double Q-learning, we introduce thedecorrelated double Q-learning (D2Q). Specifically, we introduce thedecorrelated regularization item to reduce the correlation between valuefunction approximators, which can lead to less biased estimation and lowvariance. The experimental results on a suite of MuJoCo continuous controltasks demonstrate that our decorrelated double Q-learning can effectivelyimprove the performance.',\n",
       "  'categories': ['cs.LG', 'cs.AI', '68T01', 'I.2.9'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.06956v1'},\n",
       " 940: {'ID': 940,\n",
       "  'title': 'On the Global Convergence of Imitation Learning: A Case for Linear  Quadratic Regulator',\n",
       "  'authors': ['Qi Cai', 'Mingyi Hong', 'Zhaoran Wang', 'Yongxin Chen'],\n",
       "  'published': '2019-01-11T17:54:47Z',\n",
       "  'updated': '2019-01-11T17:54:47Z',\n",
       "  'abstract': 'We study the global convergence of generative adversarial imitation learningfor linear quadratic regulators, which is posed as minimax optimization. Toaddress the challenges arising from non-convex-concave geometry, we analyze thealternating gradient algorithm and establish its Q-linear rate of convergenceto a unique saddle point, which simultaneously recovers the globally optimalpolicy and reward function. We hope our results may serve as a small steptowards understanding and taming the instability in imitation learning as wellas in more general non-convex-concave alternating minimax optimization thatarises from reinforcement learning and generative adversarial learning.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1901.03674v1'},\n",
       " 941: {'ID': 941,\n",
       "  'title': 'Denoising of 3-D Magnetic Resonance Images Using a Residual  Encoder-Decoder Wasserstein Generative Adversarial Network',\n",
       "  'authors': ['Yang Chen',\n",
       "   'Jinrong Hu',\n",
       "   'Yi Zhang',\n",
       "   'Hu Chen',\n",
       "   'Jiliu Zhou',\n",
       "   'Huaiqiang Sun',\n",
       "   'Maosong Ran'],\n",
       "  'published': '2018-08-12T13:30:27Z',\n",
       "  'updated': '2019-05-05T03:42:19Z',\n",
       "  'abstract': 'Structure-preserved denoising of 3D magnetic resonance imaging (MRI) imagesis a critical step in medical image analysis. Over the past few years, manyalgorithms with impressive performances have been proposed. In this paper,inspired by the idea of deep learning, we introduce an MRI denoising methodbased on the residual encoder-decoder Wasserstein generative adversarialnetwork (RED-WGAN). Specifically, to explore the structure similarity betweenneighboring slices, a 3D configuration is utilized as the basic processingunit. Residual autoencoders combined with deconvolution operations areintroduced into the generator network. Furthermore, to alleviate theoversmoothing shortcoming of the traditional mean squared error (MSE) lossfunction, the perceptual similarity, which is implemented by calculating thedistances in the feature space extracted by a pretrained VGG-19 network, isincorporated with the MSE and adversarial losses to form the new loss function.Extensive experiments are implemented to assess the performance of the proposedmethod. The experimental results show that the proposed RED-WGAN achievesperformance superior to several state-of-the-art methods in both simulated andreal clinical data. In particular, our method demonstrates powerful abilitiesin both noise suppression and structure preservation.',\n",
       "  'categories': ['physics.med-ph', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1808.03941v2'},\n",
       " 942: {'ID': 942,\n",
       "  'title': 'A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for  Neural Networks',\n",
       "  'authors': ['Srinadh Bhojanapalli', 'Behnam Neyshabur', 'Nathan Srebro'],\n",
       "  'published': '2017-07-29T22:36:35Z',\n",
       "  'updated': '2018-02-23T22:30:45Z',\n",
       "  'abstract': 'We present a generalization bound for feedforward neural networks in terms ofthe product of the spectral norm of the layers and the Frobenius norm of theweights. The generalization bound is derived using a PAC-Bayes analysis.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.09564v2'},\n",
       " 943: {'ID': 943,\n",
       "  'title': 'Auxiliary-task Based Deep Reinforcement Learning for Participant  Selection Problem in Mobile Crowdsourcing',\n",
       "  'authors': ['Qiang Ni',\n",
       "   'Wanchun Dou',\n",
       "   'Chuheng Zhang',\n",
       "   'Xiaonan He',\n",
       "   'Yan Wang',\n",
       "   'Wei Shen'],\n",
       "  'published': '2020-08-25T15:02:54Z',\n",
       "  'updated': '2020-08-26T00:55:05Z',\n",
       "  'abstract': 'In mobile crowdsourcing (MCS), the platform selects participants to completelocation-aware tasks from the recruiters aiming to achieve multiple goals(e.g., profit maximization, energy efficiency, and fairness). However,different MCS systems have different goals and there are possibly conflictinggoals even in one MCS system. Therefore, it is crucial to design a participantselection algorithm that applies to different MCS systems to achieve multiplegoals. To deal with this issue, we formulate the participant selection problemas a reinforcement learning problem and propose to solve it with a novelmethod, which we call auxiliary-task based deep reinforcement learning (ADRL).We use transformers to extract representations from the context of the MCSsystem and a pointer network to deal with the combinatorial optimizationproblem. To improve the sample efficiency, we adopt an auxiliary-task trainingprocess that trains the network to predict the imminent tasks from therecruiters, which facilitates the embedding learning of the deep learningmodel. Additionally, we release a simulated environment on a specific MCS task,the ride-sharing task, and conduct extensive performance evaluations in thisenvironment. The experimental results demonstrate that ADRL outperforms andimproves sample efficiency over other well-recognized baselines in varioussettings.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.11087v2'},\n",
       " 944: {'ID': 944,\n",
       "  'title': 'ReenactNet: Real-time Full Head Reenactment',\n",
       "  'authors': ['Stefanos Zafeiriou',\n",
       "   'Mohammad Rami Koujan',\n",
       "   'Anastasios Roussos',\n",
       "   'Michail Christos Doukas'],\n",
       "  'published': '2020-05-22T00:51:38Z',\n",
       "  'updated': '2020-05-22T00:51:38Z',\n",
       "  'abstract': 'Video-to-video synthesis is a challenging problem aiming at learning atranslation function between a sequence of semantic maps and a photo-realisticvideo depicting the characteristics of a driving video. We propose ahead-to-head system of our own implementation capable of fully transferring thehuman head 3D pose, facial expressions and eye gaze from a source to a targetactor, while preserving the identity of the target actor. Our system produceshigh-fidelity, temporally-smooth and photo-realistic synthetic videosfaithfully transferring the human time-varying head attributes from the sourceto the target actor. Our proposed implementation: 1) works in real time ($\\\\sim20$ fps), 2) runs on a commodity laptop with a webcam as the only input, 3) isinteractive, allowing the participant to drive a target person, e.g. acelebrity, politician, etc, instantly by varying their expressions, head pose,and eye gaze, and visualising the synthesised video concurrently.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.10500v1'},\n",
       " 945: {'ID': 945,\n",
       "  'title': 'Training Distributed Deep Recurrent Neural Networks with Mixed Precision  on GPU Clusters',\n",
       "  'authors': ['Julian Kates-Harbeck', 'William Tang', 'Alexey Svyatkovskiy'],\n",
       "  'published': '2019-11-30T23:57:48Z',\n",
       "  'updated': '2019-11-30T23:57:48Z',\n",
       "  'abstract': 'In this paper, we evaluate training of deep recurrent neural networks withhalf-precision floats. We implement a distributed, data-parallel, synchronoustraining algorithm by integrating TensorFlow and CUDA-aware MPI to enableexecution across multiple GPU nodes and making use of high-speed interconnects.We introduce a learning rate schedule facilitating neural network convergenceat up to $O(100)$ workers.  Strong scaling tests performed on clusters of NVIDIA Pascal P100 GPUs showlinear runtime and logarithmic communication time scaling for both single andmixed precision training modes. Performance is evaluated on a scientificdataset taken from the Joint European Torus (JET) tokamak, containingmulti-modal time series of sensory measurements leading up to deleteriousevents called plasma disruptions, and the benchmark Large Movie ReviewDataset~\\\\cite{imdb}. Half-precision significantly reduces memory and networkbandwidth, allowing training of state-of-the-art models with over 70 milliontrainable parameters while achieving a comparable test set performance assingle precision.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.00286v1'},\n",
       " 946: {'ID': 946,\n",
       "  'title': 'Semi-Automatic RECIST Labeling on CT Scans with Cascaded Convolutional  Neural Networks',\n",
       "  'authors': ['Jing Xiao',\n",
       "   'Youbao Tang',\n",
       "   'Adam P. Harrison',\n",
       "   'Mohammadhadi Bagheri',\n",
       "   'Ronald M. Summers'],\n",
       "  'published': '2018-06-25T14:52:07Z',\n",
       "  'updated': '2018-06-25T14:52:07Z',\n",
       "  'abstract': 'Response evaluation criteria in solid tumors (RECIST) is the standardmeasurement for tumor extent to evaluate treatment responses in cancerpatients. As such, RECIST annotations must be accurate. However, RECISTannotations manually labeled by radiologists require professional knowledge andare time-consuming, subjective, and prone to inconsistency among differentobservers. To alleviate these problems, we propose a cascaded convolutionalneural network based method to semi-automatically label RECIST annotations anddrastically reduce annotation time. The proposed method consists of two stages:lesion region normalization and RECIST estimation. We employ the spatialtransformer network (STN) for lesion region normalization, where a localizationnetwork is designed to predict the lesion region and the transformationparameters with a multi-task learning strategy. For RECIST estimation, we adaptthe stacked hourglass network (SHN), introducing a relationship constraint lossto improve the estimation precision. STN and SHN can both be learned in anend-to-end fashion. We train our system on the DeepLesion dataset, obtaining aconsensus model trained on RECIST annotations performed by multipleradiologists over a multi-year period. Importantly, when judged against theinter-reader variability of two additional radiologist raters, our systemperforms more stably and with less variability, suggesting that RECISTannotations can be reliably obtained with reduced labor and time.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1806.09507v1'},\n",
       " 947: {'ID': 947,\n",
       "  'title': 'Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for  Continuous Control',\n",
       "  'authors': ['Maziar Gomrokchi',\n",
       "   'Peter Henderson',\n",
       "   'Riashat Islam',\n",
       "   'Doina Precup'],\n",
       "  'published': '2017-08-10T19:20:15Z',\n",
       "  'updated': '2017-08-10T19:20:15Z',\n",
       "  'abstract': 'Policy gradient methods in reinforcement learning have become increasinglyprevalent for state-of-the-art performance in continuous control tasks. Novelmethods typically benchmark against a few key algorithms such as deepdeterministic policy gradients and trust region policy optimization. As such,it is important to present and use consistent baselines experiments. However,this can be difficult due to general variance in the algorithms,hyper-parameter tuning, and environment stochasticity. We investigate anddiscuss: the significance of hyper-parameters in policy gradients forcontinuous control, general variance in the algorithms, and reproducibility ofreported results. We provide guidelines on reporting novel results ascomparisons against baseline methods such that future researchers can makeinformed decisions when investigating novel methods.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.04133v1'},\n",
       " 948: {'ID': 948,\n",
       "  'title': 'Multivariate Time-series Anomaly Detection via Graph Attention Network',\n",
       "  'authors': ['Jie Tong',\n",
       "   'Jing Bai',\n",
       "   'Hang Zhao',\n",
       "   'Congrui Huang',\n",
       "   'Defu Cao',\n",
       "   'Qi Zhang',\n",
       "   'Yujing Wang',\n",
       "   'Bixiong Xu',\n",
       "   'Yunhai Tong',\n",
       "   'Juanyong Duan'],\n",
       "  'published': '2020-09-04T07:46:19Z',\n",
       "  'updated': '2020-09-04T07:46:19Z',\n",
       "  'abstract': 'Anomaly detection on multivariate time-series is of great importance in bothdata mining research and industrial applications. Recent approaches haveachieved significant progress in this topic, but there is remaininglimitations. One major limitation is that they do not capture the relationshipsbetween different time-series explicitly, resulting in inevitable false alarms.In this paper, we propose a novel self-supervised framework for multivariatetime-series anomaly detection to address this issue. Our framework considerseach univariate time-series as an individual feature and includes two graphattention layers in parallel to learn the complex dependencies of multivariatetime-series in both temporal and feature dimensions. In addition, our approachjointly optimizes a forecasting-based model and are construction-based model,obtaining better time-series representations through a combination ofsingle-timestamp prediction and reconstruction of the entire time-series. Wedemonstrate the efficacy of our model through extensive experiments. Theproposed method outperforms other state-of-the-art models on three real-worlddatasets. Further analysis shows that our method has good interpretability andis useful for anomaly diagnosis.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2009.02040v1'},\n",
       " 949: {'ID': 949,\n",
       "  'title': 'Detecting Adversarial Examples by Input Transformations, Defense  Perturbations, and Voting',\n",
       "  'authors': ['Giorgio Buttazzo', 'Federico Nesti', 'Alessandro Biondi'],\n",
       "  'published': '2021-01-27T14:50:41Z',\n",
       "  'updated': '2021-01-27T14:50:41Z',\n",
       "  'abstract': 'Over the last few years, convolutional neural networks (CNNs) have proved toreach super-human performance in visual recognition tasks. However, CNNs caneasily be fooled by adversarial examples, i.e., maliciously-crafted images thatforce the networks to predict an incorrect output while being extremely similarto those for which a correct output is predicted. Regular adversarial examplesare not robust to input image transformations, which can then be used to detectwhether an adversarial example is presented to the network. Nevertheless, it isstill possible to generate adversarial examples that are robust to suchtransformations.  This paper extensively explores the detection of adversarial examples viaimage transformations and proposes a novel methodology, called \\\\textit{defenseperturbation}, to detect robust adversarial examples with the same inputtransformations the adversarial examples are robust to. Such a \\\\textit{defenseperturbation} is shown to be an effective counter-measure to robust adversarialexamples.  Furthermore, multi-network adversarial examples are introduced. This kind ofadversarial examples can be used to simultaneously fool multiple networks,which is critical in systems that use network redundancy, such as those basedon architectures with majority voting over multiple CNNs. An extensive set ofexperiments based on state-of-the-art CNNs trained on the Imagenet dataset isfinally reported.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.11466v1'},\n",
       " 950: {'ID': 950,\n",
       "  'title': 'Bayesian Tensorized Neural Networks with Automatic Rank Selection',\n",
       "  'authors': ['Cole Hawkins', 'Zheng Zhang'],\n",
       "  'published': '2019-05-24T23:18:17Z',\n",
       "  'updated': '2019-05-24T23:18:17Z',\n",
       "  'abstract': 'Tensor decomposition is an effective approach to compress over-parameterizedneural networks and to enable their deployment on resource-constrained hardwareplatforms. However, directly applying tensor compression in the trainingprocess is a challenging task due to the difficulty of choosing a proper tensorrank. In order to achieve this goal, this paper proposes a Bayesian tensorizedneural network. Our Bayesian method performs automatic model compression via anadaptive tensor rank determination. We also present approaches for posteriordensity calculation and maximum a posteriori (MAP) estimation for theend-to-end training of our tensorized neural network. We provide experimentalvalidation on a fully connected neural network, a CNN and a residual neuralnetwork where our work produces $7.4\\\\times$ to $137\\\\times$ more compact neuralnetworks directly from the training.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.10478v1'},\n",
       " 951: {'ID': 951,\n",
       "  'title': 'Prioritized Sequence Experience Replay',\n",
       "  'authors': ['Marc Brittain', 'Josh Bertram', 'Xuxi Yang', 'Peng Wei'],\n",
       "  'published': '2019-05-25T15:38:00Z',\n",
       "  'updated': '2020-02-19T16:04:29Z',\n",
       "  'abstract': 'Experience replay is widely used in deep reinforcement learning algorithmsand allows agents to remember and learn from experiences from the past. In aneffort to learn more efficiently, researchers proposed prioritized experiencereplay (PER) which samples important transitions more frequently. In thispaper, we propose Prioritized Sequence Experience Replay (PSER) a framework forprioritizing sequences of experience in an attempt to both learn moreefficiently and to obtain better performance. We compare the performance of PERand PSER sampling techniques in a tabular Q-learning environment and in DQN onthe Atari 2600 benchmark. We prove theoretically that PSER is guaranteed toconverge faster than PER and empirically show PSER substantially improves uponPER.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.12726v2'},\n",
       " 952: {'ID': 952,\n",
       "  'title': 'Weight Sharing is Crucial to Succesful Optimization',\n",
       "  'authors': ['Shaked Shammah', 'Shai Shalev-Shwartz', 'Ohad Shamir'],\n",
       "  'published': '2017-06-02T13:56:59Z',\n",
       "  'updated': '2017-06-02T13:56:59Z',\n",
       "  'abstract': 'Exploiting the great expressive power of Deep Neural Network architectures,relies on the ability to train them. While current theoretical work provides,mostly, results showing the hardness of this task, empirical evidence usuallydiffers from this line, with success stories in abundance. A strong positionamong empirically successful architectures is captured by networks whereextensive weight sharing is used, either by Convolutional or Recurrent layers.Additionally, characterizing specific aspects of different tasks, making them\"harder\" or \"easier\", is an interesting direction explored both theoreticallyand empirically. We consider a family of ConvNet architectures, and prove thatweight sharing can be crucial, from an optimization point of view. We exploredifferent notions of the frequency, of the target function, proving necessityof the target function having some low frequency components. This necessity isnot sufficient - only with weight sharing can it be exploited, thustheoretically separating architectures using it, from others which do not. Ourtheoretical results are aligned with empirical experiments in an even moregeneral setting, suggesting viability of examination of the role played byinterleaving those aspects in broader families of tasks.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1706.00687v1'},\n",
       " 953: {'ID': 953,\n",
       "  'title': 'HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation',\n",
       "  'authors': ['Yuval Nirkin', 'Tal Hassner', 'Lior Wolf'],\n",
       "  'published': '2020-12-21T18:58:18Z',\n",
       "  'updated': '2020-12-21T18:58:18Z',\n",
       "  'abstract': 'We present a novel, real-time, semantic segmentation network in which theencoder both encodes and generates the parameters (weights) of the decoder.Furthermore, to allow maximal adaptivity, the weights at each decoder blockvary spatially. For this purpose, we design a new type of hypernetwork,composed of a nested U-Net for drawing higher level context features, amulti-headed weight generating module which generates the weights of each blockin the decoder immediately before they are consumed, for efficient memoryutilization, and a primary network that is composed of novel dynamic patch-wiseconvolutions. Despite the usage of less-conventional blocks, our architectureobtains real-time performance. In terms of the runtime vs. accuracy trade-off,we surpass state of the art (SotA) results on popular semantic segmentationbenchmarks: PASCAL VOC 2012 (val. set) and real-time semantic segmentation onCityscapes, and CamVid.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.11582v1'},\n",
       " 954: {'ID': 954,\n",
       "  'title': 'Information Theoretic-Learning Auto-Encoder',\n",
       "  'authors': ['Matthew Emigh', 'Eder Santana', 'Jose C Principe'],\n",
       "  'published': '2016-03-22T01:05:47Z',\n",
       "  'updated': '2016-03-22T01:05:47Z',\n",
       "  'abstract': 'We propose Information Theoretic-Learning (ITL) divergence measures forvariational regularization of neural networks. We also explore ITL-regularizedautoencoders as an alternative to variational autoencoding bayes, adversarialautoencoders and generative adversarial networks for randomly generating sampledata without explicitly defining a partition function. This paper alsoformalizes, generative moment matching networks under the ITL framework.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1603.06653v1'},\n",
       " 955: {'ID': 955,\n",
       "  'title': 'Goal-Conditioned End-to-End Visuomotor Control for Versatile Skill  Primitives',\n",
       "  'authors': ['Ingmar Posner',\n",
       "   'Chia-Man Hung',\n",
       "   'Oliver Groth',\n",
       "   'Andrea Vedaldi'],\n",
       "  'published': '2020-03-19T15:04:37Z',\n",
       "  'updated': '2020-11-08T17:58:17Z',\n",
       "  'abstract': \"Visuomotor control (VMC) is an effective means of achieving basicmanipulation tasks such as pushing or pick-and-place from raw images.Conditioning VMC on desired goal states is a promising way of achievingversatile skill primitives. However, common conditioning schemes either rely ontask-specific fine tuning - e.g. using one-shot imitation learning (IL) - or onsampling approaches using a forward model of scene dynamics i.e.model-predictive control (MPC), leaving deployability and planning horizonseverely limited. In this paper we propose a conditioning scheme which avoidsthese pitfalls by learning the controller and its conditioning in an end-to-endmanner. Our model predicts complex action sequences based directly on a dynamicimage representation of the robot motion and the distance to a given targetobservation. In contrast to related works, this enables our approach toefficiently perform complex manipulation tasks from raw image observationswithout predefined control primitives or test time demonstrations. We reportsignificant improvements in task success over representative MPC and ILbaselines. We also demonstrate our model's generalisation capabilities inchallenging, unseen tasks featuring visual noise, cluttered scenes and unseenobject geometries.\",\n",
       "  'categories': ['cs.RO', 'cs.CV', 'cs.LG', 'I.2.9; I.2.10'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.08854v2'},\n",
       " 956: {'ID': 956,\n",
       "  'title': 'Convolutional Conditional Neural Processes',\n",
       "  'authors': ['Richard E. Turner',\n",
       "   'Jonathan Gordon',\n",
       "   'Wessel P. Bruinsma',\n",
       "   'James Requeima',\n",
       "   'Yann Dubois',\n",
       "   'Andrew Y. K. Foong'],\n",
       "  'published': '2019-10-29T21:56:00Z',\n",
       "  'updated': '2020-06-25T13:20:06Z',\n",
       "  'abstract': 'We introduce the Convolutional Conditional Neural Process (ConvCNP), a newmember of the Neural Process family that models translation equivariance in thedata. Translation equivariance is an important inductive bias for many learningproblems including time series modelling, spatial data, and images. The modelembeds data sets into an infinite-dimensional function space as opposed to afinite-dimensional vector space. To formalize this notion, we extend the theoryof neural representations of sets to include functional representations, anddemonstrate that any translation-equivariant embedding can be represented usinga convolutional deep set. We evaluate ConvCNPs in several settings,demonstrating that they achieve state-of-the-art performance compared toexisting NPs. We demonstrate that building in translation equivariance enableszero-shot generalization to challenging, out-of-domain tasks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.13556v5'},\n",
       " 957: {'ID': 957,\n",
       "  'title': 'High-Level Plan for Behavioral Robot Navigation with Natural Language  Directions and R-NET',\n",
       "  'authors': ['Qinru Qiu',\n",
       "   'Amar Shrestha',\n",
       "   'Haowen Fang',\n",
       "   'Krittaphat Pugdeethosapol'],\n",
       "  'published': '2020-01-08T01:14:11Z',\n",
       "  'updated': '2020-01-08T01:14:11Z',\n",
       "  'abstract': 'When the navigational environment is known, it can be represented as a graphwhere landmarks are nodes, the robot behaviors that move from node to node areedges, and the route is a set of behavioral instructions. The route path fromsource to destination can be viewed as a class of combinatorial optimizationproblems where the path is a sequential subset from a set of discrete items.The pointer network is an attention-based recurrent network that is suitablefor such a task. In this paper, we utilize a modified R-NET with gatedattention and self-matching attention translating natural language instructionsto a high-level plan for behavioral robot navigation by developing anunderstanding of the behavioral navigational graph to enable the pointernetwork to produce a sequence of behaviors representing the path. Tests on thenavigation graph dataset show that our model outperforms the state-of-the-artapproach for both known and unknown environments.',\n",
       "  'categories': ['cs.AI', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.02330v1'},\n",
       " 958: {'ID': 958,\n",
       "  'title': 'SwitchX- Gmin-Gmax Switching for Energy-Efficient and Robust  Implementation of Binary Neural Networks on Memristive Xbars',\n",
       "  'authors': ['Abhiroop Bhattacharjee', 'Priyadarshini Panda'],\n",
       "  'published': '2020-11-30T01:48:06Z',\n",
       "  'updated': '2020-11-30T01:48:06Z',\n",
       "  'abstract': 'Memristive crossbars can efficiently implement Binarized Neural Networks(BNNs) wherein the weights are stored in high-resistance states (HRS) andlow-resistance states (LRS) of the synapses. We propose SwitchX mapping ofweights onto crossbars such that the power consumed by the crossbars and theimpact of crossbar non-idealities, that lead to degradation in computationalaccuracy, are minimized. Essentially, SwitchX maps the binary weights in suchmanner that the crossbar comprises of more HRS than LRS synapses. Increased HRSin a crossbar will decrease the overall output dot-product current and thuslead to power savings. Interestingly, BNNs mapped onto crossbars with SwitchXalso exhibit better robustness against adversarial attacks than thecorresponding software BNN baseline as well as the standard crossbar mappedBNNs. Finally, we combine SwitchX with state-aware training (that furtherincreases the feasibility of HRS states during weight mapping) to boost therobustness and energy-efficiency of BNN on hardware. We find that this approachyields stronger defense against adversarial attacks than Adversarial training,a state-of-the-art software defense. We perform experiments using benchmarkdatasets (CIFAR-100 &amp; CIFAR-10) and show that SwitchX combined with state-awaretraining can yield upto ~35% improvements in clean accuracy and ~6-16% inadversarial accuracies against conventional BNNs on a 32x32 crossbar, whilegaining ~22% savings in overall crossbar power consumption.',\n",
       "  'categories': ['cs.ET'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.14498v1'},\n",
       " 959: {'ID': 959,\n",
       "  'title': 'Learning Temporal Strategic Relationships using Generative Adversarial  Imitation Learning',\n",
       "  'authors': ['Sridha Sridharan',\n",
       "   'Clinton Fookes',\n",
       "   'Tharindu Fernando',\n",
       "   'Simon Denman'],\n",
       "  'published': '2018-05-13T22:56:58Z',\n",
       "  'updated': '2018-05-13T22:56:58Z',\n",
       "  'abstract': 'This paper presents a novel framework for automatic learning of complexstrategies in human decision making. The task that we are interested in is tobetter facilitate long term planning for complex, multi-step events. We observetemporal relationships at the subtask level of expert demonstrations, anddetermine the different strategies employed in order to successfully complete atask. To capture the relationship between the subtasks and the overall goal, weutilise two external memory modules, one for capturing dependencies within asingle expert demonstration, such as the sequential relationship amongdifferent sub tasks, and a global memory module for modelling task levelcharacteristics such as best practice employed by different humans based ontheir domain expertise. Furthermore, we demonstrate how the hidden staterepresentation of the memory can be used as a reward signal to smooth the statetransitions, eradicating subtle changes. We evaluate the effectiveness of theproposed model for an autonomous highway driving application, where wedemonstrate its capability to learn different expert policies and outperformstate-of-the-art methods. The scope in industrial applications extends to anyrobotics and automation application which requires learning from complexdemonstrations containing series of subtasks.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.04969v1'},\n",
       " 960: {'ID': 960,\n",
       "  'title': 'Asymptotic Guarantees for Learning Generative Models with the  Sliced-Wasserstein Distance',\n",
       "  'authors': ['Alain Durmus',\n",
       "   'Roland Badeau',\n",
       "   'Umut Şimşekli',\n",
       "   'Kimia Nadjahi'],\n",
       "  'published': '2019-06-11T12:13:12Z',\n",
       "  'updated': '2020-03-24T13:56:43Z',\n",
       "  'abstract': 'Minimum expected distance estimation (MEDE) algorithms have been widely usedfor probabilistic models with intractable likelihood functions and they havebecome increasingly popular due to their use in implicit generative modeling(e.g. Wasserstein generative adversarial networks, Wasserstein autoencoders).Emerging from computational optimal transport, the Sliced-Wasserstein (SW)distance has become a popular choice in MEDE thanks to its simplicity andcomputational benefits. While several studies have reported empirical successon generative modeling with SW, the theoretical properties of such estimatorshave not yet been established. In this study, we investigate the asymptoticproperties of estimators that are obtained by minimizing SW. We first show thatconvergence in SW implies weak convergence of probability measures in generalWasserstein spaces. Then we show that estimators obtained by minimizing SW (andalso an approximate version of SW) are asymptotically consistent. We finallyprove a central limit theorem, which characterizes the asymptotic distributionof the estimators and establish a convergence rate of $\\\\sqrt{n}$, where $n$denotes the number of observed data points. We illustrate the validity of ourtheory on both synthetic data and neural networks.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1906.04516v2'},\n",
       " 961: {'ID': 961,\n",
       "  'title': 'Symbolic Tensor Neural Networks for Digital Media - from Tensor  Processing via BNF Graph Rules to CREAMS Applications',\n",
       "  'authors': ['Wladyslaw Skarbek'],\n",
       "  'published': '2018-09-18T08:25:01Z',\n",
       "  'updated': '2018-12-12T09:16:30Z',\n",
       "  'abstract': 'This tutorial material on Convolutional Neural Networks (CNN) and itsapplications in digital media research is based on the concept of SymbolicTensor Neural Networks. The set of STNN expressions is specified in Backus-NaurForm (BNF) which is annotated by constraints typical for labeled acyclicdirected graphs (DAG). The BNF induction begins from a collection of neuralunit symbols with extra (up to five) decoration fields (including tensor depthand sharing fields). The inductive rules provide not only the general graphstructure but also the specific shortcuts for residual blocks of units. Asyntactic mechanism for network fragments modularization is introduced via userdefined units and their instances. Moreover, the dual BNF rules are specifiedin order to generate the Dual Symbolic Tensor Neural Network (DSTNN). Thejoined interpretation of STNN and DSTNN provides the correct flow of gradienttensors, back propagated at the training stage. The proposed symbolicrepresentation of CNNs is illustrated for six generic digital mediaapplications (CREAMS): Compression, Recognition, Embedding, Annotation, 3DModeling for human-computer interfacing, and data Security based on digitalmedia objects. In order to make the CNN description and its gradient flowcomplete, for all presented applications, the symbolic representations ofmathematically defined loss/gain functions and gradient flow equations for allused core units, are given. The tutorial is to convince the reader that STNN isnot only a convenient symbolic notation for public presentations of CNN basedsolutions for CREAMS problems but also that it is a design blueprint with apotential for automatic generation of application source code.',\n",
       "  'categories': ['cs.CV', 'cs.MM'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.06582v2'},\n",
       " 962: {'ID': 962,\n",
       "  'title': 'Counterfactual fairness: removing direct effects through regularization',\n",
       "  'authors': ['Vlasios Vasileiou', 'James M. Hickey', 'Pietro G. Di Stefano'],\n",
       "  'published': '2020-02-25T10:13:55Z',\n",
       "  'updated': '2020-02-26T11:28:34Z',\n",
       "  'abstract': 'Building machine learning models that are fair with respect to anunprivileged group is a topical problem. Modern fairness-aware algorithms oftenignore causal effects and enforce fairness through modifications applicable toonly a subset of machine learning models. In this work, we propose a newdefinition of fairness that incorporates causality through the ControlledDirect Effect (CDE). We develop regularizations to tackle classical fairnessmeasures and present a causal regularization that satisfies our new fairnessdefinition by removing the impact of unprivileged group variables on the modeloutcomes as measured by the CDE. These regularizations are applicable to anymodel trained using by iteratively minimizing a loss through differentiation.We demonstrate our approaches using both gradient boosting and logisticregression on: a synthetic dataset, the UCI Adult (Census) Dataset, and areal-world credit-risk dataset. Our results were found to mitigate unfairnessfrom the predictions with small reductions in model performance.',\n",
       "  'categories': ['cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.10774v2'},\n",
       " 963: {'ID': 963,\n",
       "  'title': 'Code Completion using Neural Attention and Byte Pair Encoding',\n",
       "  'authors': ['Bastijn Kostense', 'Nikhil Saldanha', 'Youri Arkesteijn'],\n",
       "  'published': '2020-04-14T08:00:40Z',\n",
       "  'updated': '2020-04-14T08:00:40Z',\n",
       "  'abstract': 'In this paper, we aim to do code completion based on implementing a NeuralNetwork from Li et. al.. Our contribution is that we use an encoding that isin-between character and word encoding called Byte Pair Encoding (BPE). We usethis on the source code files treating them as natural text without first goingthrough the abstract syntax tree (AST). We have implemented two models: anattention-enhanced LSTM and a pointer network, where the pointer network wasoriginally introduced to solve out of vocabulary problems. We are interested tosee if BPE can replace the need for the pointer network for code completion.',\n",
       "  'categories': ['cs.CL', 'cs.LG', 'cs.SE'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.06343v1'},\n",
       " 964: {'ID': 964,\n",
       "  'title': 'Robust Unsupervised Neural Machine Translation with Adversarial  Denoising Training',\n",
       "  'authors': ['Xugang Lu',\n",
       "   'Masao Utiyama',\n",
       "   'Rui Wang',\n",
       "   'Kehai Chen',\n",
       "   'Haipeng Sun',\n",
       "   'Eiichiro Sumita',\n",
       "   'Tiejun Zhao'],\n",
       "  'published': '2020-02-28T05:17:55Z',\n",
       "  'updated': '2020-12-03T03:19:36Z',\n",
       "  'abstract': 'Unsupervised neural machine translation (UNMT) has recently attracted greatinterest in the machine translation community. The main advantage of the UNMTlies in its easy collection of required large training text sentences whilewith only a slightly worse performance than supervised neural machinetranslation which requires expensive annotated translation pairs on sometranslation tasks. In most studies, the UMNT is trained with clean data withoutconsidering its robustness to the noisy data. However, in real-world scenarios,there usually exists noise in the collected input sentences which degrades theperformance of the translation system since the UNMT is sensitive to the smallperturbations of the input sentences. In this paper, we first time explicitlytake the noisy data into consideration to improve the robustness of the UNMTbased systems. First of all, we clearly defined two types of noises in trainingsentences, i.e., word noise and word order noise, and empirically investigateits effect in the UNMT, then we propose adversarial training methods withdenoising process in the UNMT. Experimental results on several language pairsshow that our proposed methods substantially improved the robustness of theconventional UNMT systems in noisy scenarios.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.12549v2'},\n",
       " 965: {'ID': 965,\n",
       "  'title': 'k-Same-Siamese-GAN: k-Same Algorithm with Generative Adversarial Network  for Facial Image De-identification with Hyperparameter Tuning and Mixed  Precision Training',\n",
       "  'authors': ['Jyh-Shing Jang',\n",
       "   'Yi-Lun Pan',\n",
       "   'Min-Jhih Huang',\n",
       "   'Kuo-Teng Ding',\n",
       "   'Ja-Ling Wu'],\n",
       "  'published': '2019-03-27T14:27:07Z',\n",
       "  'updated': '2019-09-17T05:24:19Z',\n",
       "  'abstract': 'For a data holder, such as a hospital or a government entity, who has aprivately held collection of personal data, in which the revealing and/orprocessing of the personal identifiable data is restricted and prohibited bylaw. Then, \"how can we ensure the data holder does conceal the identity of eachindividual in the imagery of personal data while still preserving certainuseful aspects of the data after de-identification?\" becomes a challenge issue.In this work, we propose an approach towards high-resolution facial imagede-identification, called k-Same-Siamese-GAN, which leverages thek-Same-Anonymity mechanism, the Generative Adversarial Network, and thehyperparameter tuning methods. Moreover, to speed up model training and reducememory consumption, the mixed precision training technique is also applied tomake kSS-GAN provide guarantees regarding privacy protection on close-formidentities and be trained much more efficiently as well. Finally, to validateits applicability, the proposed work has been applied to actual datasets - RafDand CelebA for performance testing. Besides protecting privacy ofhigh-resolution facial images, the proposed system is also justified for itsability in automating parameter tuning and breaking through the limitation ofthe number of adjustable parameters.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1904.00816v2'},\n",
       " 966: {'ID': 966,\n",
       "  'title': 'AutoGraph: Automated Graph Neural Network',\n",
       "  'authors': ['Irwin King', 'Yaoman Li'],\n",
       "  'published': '2020-11-23T09:04:17Z',\n",
       "  'updated': '2020-11-23T09:04:17Z',\n",
       "  'abstract': 'Graphs play an important role in many applications. Recently, Graph NeuralNetworks (GNNs) have achieved promising results in graph analysis tasks. Somestate-of-the-art GNN models have been proposed, e.g., Graph ConvolutionalNetworks (GCNs), Graph Attention Networks (GATs), etc. Despite these successes,most of the GNNs only have shallow structure. This causes the low expressivepower of the GNNs. To fully utilize the power of the deep neural network, somedeep GNNs have been proposed recently. However, the design of deep GNNsrequires significant architecture engineering. In this work, we propose amethod to automate the deep GNNs design. In our proposed method, we add a newtype of skip connection to the GNNs search space to encourage feature reuse andalleviate the vanishing gradient problem. We also allow our evolutionaryalgorithm to increase the layers of GNNs during the evolution to generatedeeper networks. We evaluate our method in the graph node classification task.The experiments show that the GNNs generated by our method can obtainstate-of-the-art results in Cora, Citeseer, Pubmed and PPI datasets.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.SI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2011.11288v1'},\n",
       " 967: {'ID': 967,\n",
       "  'title': 'The problems with using STNs to align CNN feature maps',\n",
       "  'authors': ['Ylva Jansson', 'Lukas Finnveden', 'Tony Lindeberg'],\n",
       "  'published': '2020-01-14T12:59:56Z',\n",
       "  'updated': '2020-01-14T12:59:56Z',\n",
       "  'abstract': 'Spatial transformer networks (STNs) were designed to enable CNNs to learninvariance to image transformations. STNs were originally proposed to transformCNN feature maps as well as input images. This enables the use of more complexfeatures when predicting transformation parameters. However, since STNs performa purely spatial transformation, they do not, in the general case, have theability to align the feature maps of a transformed image and its original. Wepresent a theoretical argument for this and investigate the practicalimplications, showing that this inability is coupled with decreasedclassification accuracy. We advocate taking advantage of more complex featuresin deeper layers by instead sharing parameters between the classification andthe localisation network.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2001.05858v1'},\n",
       " 968: {'ID': 968,\n",
       "  'title': 'Intriguing Properties of Adversarial Examples',\n",
       "  'authors': ['Samuel S. Schoenholz',\n",
       "   'Quoc V. Le',\n",
       "   'Ekin D. Cubuk',\n",
       "   'Barret Zoph'],\n",
       "  'published': '2017-11-08T06:54:49Z',\n",
       "  'updated': '2017-11-08T06:54:49Z',\n",
       "  'abstract': 'It is becoming increasingly clear that many machine learning classifiers arevulnerable to adversarial examples. In attempting to explain the origin ofadversarial examples, previous studies have typically focused on the fact thatneural networks operate on high dimensional data, they overfit, or they are toolinear. Here we argue that the origin of adversarial examples is primarily dueto an inherent uncertainty that neural networks have about their predictions.We show that the functional form of this uncertainty is independent ofarchitecture, dataset, and training protocol; and depends only on thestatistics of the logit differences of the network, which do not changesignificantly during training. This leads to adversarial error having auniversal scaling, as a power-law, with respect to the size of the adversarialperturbation. We show that this universality holds for a broad range ofdatasets (MNIST, CIFAR10, ImageNet, and random data), models (includingstate-of-the-art deep networks, linear models, adversarially trained networks,and networks trained on randomly shuffled labels), and attacks (FGSM, stepl.l., PGD). Motivated by these results, we study the effects of reducingprediction entropy on adversarial robustness. Finally, we study the effect ofnetwork architectures on adversarial sensitivity. To do this, we use neuralarchitecture search with reinforcement learning to find adversarially robustarchitectures on CIFAR10. Our resulting architecture is more robust to white\\\\emph{and} black box attacks compared to previous attempts.',\n",
       "  'categories': ['stat.ML', 'cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1711.02846v1'},\n",
       " 969: {'ID': 969,\n",
       "  'title': 'Adversarial Feature Learning and Unsupervised Clustering based Speech  Synthesis for Found Data with Acoustic and Textual Noise',\n",
       "  'authors': ['Lei Xie', 'Yuxuan Wang', 'Shan Yang'],\n",
       "  'published': '2020-04-28T15:32:45Z',\n",
       "  'updated': '2020-04-28T15:32:45Z',\n",
       "  'abstract': 'Attention-based sequence-to-sequence (seq2seq) speech synthesis has achievedextraordinary performance. But a studio-quality corpus with manualtranscription is necessary to train such seq2seq systems. In this paper, wepropose an approach to build high-quality and stable seq2seq based speechsynthesis system using challenging found data, where training speech containsnoisy interferences (acoustic noise) and texts are imperfect speech recognitiontranscripts (textual noise). To deal with text-side noise, we propose a VQVAEbased heuristic method to compensate erroneous linguistic feature with phoneticinformation learned directly from speech. As for the speech-side noise, wepropose to learn a noise-independent feature in the auto-regressive decoderthrough adversarial training and data augmentation, which does not need anextra speech enhancement model. Experiments show the effectiveness of theproposed approach in dealing with text-side and speech-side noise. Surpassingthe denoising approach based on a state-of-the-art speech enhancement model,our system built on noisy found data can synthesize clean and high-qualityspeech with MOS close to the system built on the clean counterpart.',\n",
       "  'categories': ['cs.SD', 'cs.LG', 'eess.AS'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.13595v1'},\n",
       " 970: {'ID': 970,\n",
       "  'title': 'HyperFlow: Representing 3D Objects as Surfaces',\n",
       "  'authors': ['Jacek Tabor',\n",
       "   'Przemysław Spurek',\n",
       "   'Tomasz Trzciński',\n",
       "   'Maciej Zięba'],\n",
       "  'published': '2020-06-15T19:18:02Z',\n",
       "  'updated': '2020-06-15T19:18:02Z',\n",
       "  'abstract': 'In this work, we present HyperFlow - a novel generative model that leverageshypernetworks to create continuous 3D object representations in a form oflightweight surfaces (meshes), directly out of point clouds. Efficient objectrepresentations are essential for many computer vision applications, includingrobotic manipulation and autonomous driving. However, creating thoserepresentations is often cumbersome, because it requires processing unorderedsets of point clouds. Therefore, it is either computationally expensive, due toadditional optimization constraints such as permutation invariance, or leads toquantization losses introduced by binning point clouds into discrete voxels.Inspired by mesh-based representations of objects used in computer graphics, wepostulate a fundamentally different approach and represent 3D objects as afamily of surfaces. To that end, we devise a generative model that uses ahypernetwork to return the weights of a Continuous Normalizing Flows (CNF)target network. The goal of this target network is to map points from aprobability distribution into a 3D mesh. To avoid numerical instability of theCNF on compact support distributions, we propose a new Spherical Log-Normalfunction which models density of 3D points around object surfaces mimickingnoise introduced by 3D capturing devices. As a result, we obtain continuousmesh-based object representations that yield better qualitative results thancompeting approaches, while reducing training time by over an order ofmagnitude.',\n",
       "  'categories': ['cs.CV', 'cs.LG', 'eess.IV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.08710v1'},\n",
       " 971: {'ID': 971,\n",
       "  'title': 'Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds  Globally Optimal Policy',\n",
       "  'authors': ['Han Zhong', 'Zhaoran Wang', 'Zhuoran Yang', 'Ethan X. Fang'],\n",
       "  'published': '2020-12-28T05:02:26Z',\n",
       "  'updated': '2020-12-28T05:02:26Z',\n",
       "  'abstract': 'While deep reinforcement learning has achieved tremendous successes invarious applications, most existing works only focus on maximizing the expectedvalue of total return and thus ignore its inherent stochasticity. Suchstochasticity is also known as the aleatoric uncertainty and is closely relatedto the notion of risk. In this work, we make the first attempt to studyrisk-sensitive deep reinforcement learning under the average reward settingwith the variance risk criteria. In particular, we focus on avariance-constrained policy optimization problem where the goal is to find apolicy that maximizes the expected value of the long-run average reward,subject to a constraint that the long-run variance of the average reward isupper bounded by a threshold. Utilizing Lagrangian and Fenchel dualities, wetransform the original problem into an unconstrained saddle-point policyoptimization problem, and propose an actor-critic algorithm that iterativelyand efficiently updates the policy, the Lagrange multiplier, and the Fencheldual variable. When both the value and policy functions are represented bymulti-layer overparameterized neural networks, we prove that our actor-criticalgorithm generates a sequence of policies that finds a globally optimal policyat a sublinear rate.',\n",
       "  'categories': ['cs.LG', 'math.OC', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.14098v1'},\n",
       " 972: {'ID': 972,\n",
       "  'title': 'CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement  Learning problem',\n",
       "  'authors': ['Arpan Kusari'],\n",
       "  'published': '2019-10-02T14:06:23Z',\n",
       "  'updated': '2019-10-02T14:06:23Z',\n",
       "  'abstract': 'Inverse reinforcement learning (IRL) is used to infer the reward functionfrom the actions of an expert running a Markov Decision Process (MDP). A novelapproach using variational inference for learning the reward function isproposed in this research. Using this technique, the intractable posteriordistribution of the continuous latent variable (the reward function in thiscase) is analytically approximated to appear to be as close to the prior beliefwhile trying to reconstruct the future state conditioned on the current stateand action. The reward function is derived using a well-known deep generativemodel known as Conditional Variational Auto-encoder (CVAE) with Wassersteinloss function, thus referred to as Conditional Wasserstein Auto-encoder-IRL(CWAE-IRL), which can be analyzed as a combination of the backward and forwardinference. This can then form an efficient alternative to the previousapproaches to IRL while having no knowledge of the system dynamics of theagent. Experimental results on standard benchmarks such as objectworld andpendulum show that the proposed algorithm can effectively learn the latentreward function in complex, high-dimensional environments.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.00584v1'},\n",
       " 973: {'ID': 973,\n",
       "  'title': 'Molecule Property Prediction and Classification with Graph Hypernetworks',\n",
       "  'authors': ['Lior Wolf', 'Eliya Nachmani'],\n",
       "  'published': '2020-02-01T16:44:34Z',\n",
       "  'updated': '2020-02-01T16:44:34Z',\n",
       "  'abstract': 'Graph neural networks are currently leading the performance charts inlearning-based molecule property prediction and classification. Computationalchemistry has, therefore, become the a prominent testbed for generic graphneural networks, as well as for specialized message passing methods. In thiswork, we demonstrate that the replacement of the underlying networks withhypernetworks leads to a boost in performance, obtaining state of the artresults in various benchmarks. A major difficulty in the application ofhypernetworks is their lack of stability. We tackle this by combining thecurrent message and the first message. A recent work has tackled the traininginstability of hypernetworks in the context of error correcting codes, byreplacing the activation function of the message passing network with alow-order Taylor approximation of it. We demonstrate that our generic solutioncan replace this domain-specific solution.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.00240v1'},\n",
       " 974: {'ID': 974,\n",
       "  'title': 'Multimodal Storytelling via Generative Adversarial Imitation Learning',\n",
       "  'authors': ['Chang-Tien Lu',\n",
       "   'Jing Dai',\n",
       "   'Arnold P. Boedihardjo',\n",
       "   'Xuchao Zhang',\n",
       "   'Zhiqian Chen'],\n",
       "  'published': '2017-12-05T02:51:35Z',\n",
       "  'updated': '2017-12-05T02:51:35Z',\n",
       "  'abstract': \"Deriving event storylines is an effective summarization method to succinctlyorganize extensive information, which can significantly alleviate the pain ofinformation overload. The critical challenge is the lack of widely recognizeddefinition of storyline metric. Prior studies have developed various approachesbased on different assumptions about users' interests. These works can extractinteresting patterns, but their assumptions do not guarantee that the derivedpatterns will match users' preference. On the other hand, their exclusivenessof single modality source misses cross-modality information. This paperproposes a method, multimodal imitation learning via generative adversarialnetworks(MIL-GAN), to directly model users' interests as reflected by variousdata. In particular, the proposed model addresses the critical challenge byimitating users' demonstrated storylines. Our proposed model is designed tolearn the reward patterns given user-provided storylines and then applies thelearned policy to unseen data. The proposed approach is demonstrated to becapable of acquiring the user's implicit intent and outperforming competingmethods by a substantial margin with a user study.\",\n",
       "  'categories': ['cs.AI', 'cs.CL', 'cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1712.01455v1'},\n",
       " 975: {'ID': 975,\n",
       "  'title': 'An Efficient Approach for Using Expectation Maximization Algorithm in  Capsule Networks',\n",
       "  'authors': ['Moein Hasani', 'Amin Nasim Saravi', 'Hassan Khotanlou'],\n",
       "  'published': '2019-12-11T14:13:15Z',\n",
       "  'updated': '2020-07-31T13:10:16Z',\n",
       "  'abstract': 'Capsule Networks (CapsNets) are brand-new architectures that have shownground-breaking results in certain areas of Computer Vision (CV). In 2017,Hinton and his team introduced CapsNets with routing-by-agreement in \"Sabour etal\" and in a more recent paper \"Matrix Capsules with EM Routing\" they proposeda more complete architecture with Expectation-Maximization (EM) algorithm.Unlike the traditional convolutional neural networks (CNNs), this architectureis able to preserve the pose of the objects in the picture. Due to thischaracteristic, it has been able to beat the previous state-of-theart resultson the smallNORB dataset, which includes samples with various view points.Also, this architecture is more robust to white box adversarial attacks.However, CapsNets have two major drawbacks. They can\\'t perform as well as CNNson complex datasets and, they need a huge amount of time for training. We tryto mitigate these shortcomings by finding optimum settings of EM routingiterations for training CapsNets. Unlike the past studies, we use un-equalnumbers of EM routing iterations for different stages of the CapsNet. For ourresearch, we use three datasets: Yale face dataset, Belgium Traffic Signdataset, and Fashion-MNIST dataset.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1912.05333v3'},\n",
       " 976: {'ID': 976,\n",
       "  'title': 'Optimistic Policy Optimization with Bandit Feedback',\n",
       "  'authors': ['Aviv Rosenberg',\n",
       "   'Lior Shani',\n",
       "   'Shie Mannor',\n",
       "   'Yonathan Efroni'],\n",
       "  'published': '2020-02-19T15:41:18Z',\n",
       "  'updated': '2020-06-18T17:13:53Z',\n",
       "  'abstract': 'Policy optimization methods are one of the most widely used classes ofReinforcement Learning (RL) algorithms. Yet, so far, such methods have beenmostly analyzed from an optimization perspective, without addressing theproblem of exploration, or by making strong assumptions on the interaction withthe environment. In this paper we consider model-based RL in the tabularfinite-horizon MDP setting with unknown transitions and bandit feedback. Forthis setting, we propose an optimistic trust region policy optimization (TRPO)algorithm for which we establish $\\\\tilde O(\\\\sqrt{S^2 A H^4 K})$ regret forstochastic rewards. Furthermore, we prove $\\\\tilde O( \\\\sqrt{ S^2 A H^4 } K^{2/3}) $ regret for adversarial rewards. Interestingly, this result matches previousbounds derived for the bandit feedback case, yet with known transitions. To thebest of our knowledge, the two results are the first sub-linear regret boundsobtained for policy optimization algorithms with unknown transitions and banditfeedback.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.08243v2'},\n",
       " 977: {'ID': 977,\n",
       "  'title': 'Multi-function Convolutional Neural Networks for Improving Image  Classification Performance',\n",
       "  'authors': ['Luna M. Zhang'],\n",
       "  'published': '2018-05-30T03:14:03Z',\n",
       "  'updated': '2018-05-30T03:14:03Z',\n",
       "  'abstract': 'Traditional Convolutional Neural Networks (CNNs) typically use the sameactivation function (usually ReLU) for all neurons with non-linear mappingoperations. For example, the deep convolutional architecture Inception-v4 usesReLU. To improve the classification performance of traditional CNNs, a new\"Multi-function Convolutional Neural Network\" (MCNN) is created by usingdifferent activation functions for different neurons. For $n$ neurons and $m$different activation functions, there are a total of $m^n-m$ MCNNs and only $m$traditional CNNs. Therefore, the best model is very likely to be chosen fromMCNNs because there are $m^n-2m$ more MCNNs than traditional CNNs. Forperformance analysis, two different datasets for two applications (classifyinghandwritten digits from the MNIST database and classifying brain MRI imagesinto one of the four stages of Alzheimer\\'s disease (AD)) are used. For bothapplications, an activation function is randomly selected for each layer of aMCNN. For the AD diagnosis application, MCNNs using a newly createdmulti-function Inception-v4 architecture are constructed. Overall, simulationsshow that MCNNs can outperform traditional CNNs in terms of multi-classclassification accuracy for both applications. An important future researchwork will be to efficiently select the best MCNN from $m^n-m$ candidate MCNNs.Current CNN software only provides users with partial functionality of MCNNssince different layers can use different activation functions but notindividual neurons in the same layer. Thus, modifying current CNN softwaresystems such as ResNets, DenseNets, and Dual Path Networks by using multipleactivation functions and developing more effective and faster MCNN softwaresystems and tools would be very useful to solve difficult practical imageclassification problems.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1805.11788v1'},\n",
       " 978: {'ID': 978,\n",
       "  'title': 'GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially  Private Generators',\n",
       "  'authors': ['Dingfan Chen', 'Mario Fritz', 'Tribhuvanesh Orekondy'],\n",
       "  'published': '2020-06-15T10:01:01Z',\n",
       "  'updated': '2020-06-15T10:01:01Z',\n",
       "  'abstract': 'The wide-spread availability of rich data has fueled the growth of machinelearning applications in numerous domains. However, growth in domains withhighly-sensitive data (e.g., medical) is largely hindered as the private natureof data prohibits it from being shared. To this end, we proposeGradient-sanitized Wasserstein Generative Adversarial Networks (GS-WGAN), whichallows releasing a sanitized form of the sensitive data with rigorous privacyguarantees. In contrast to prior work, our approach is able to distort gradientinformation more precisely, and thereby enabling training deeper models whichgenerate more informative samples. Moreover, our formulation naturally allowsfor training GANs in both centralized and federated (i.e., decentralized) datascenarios. Through extensive experiments, we find our approach consistentlyoutperforms state-of-the-art approaches across multiple metrics (e.g., samplequality) and datasets.',\n",
       "  'categories': ['cs.LG', 'cs.CR', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2006.08265v1'},\n",
       " 979: {'ID': 979,\n",
       "  'title': 'Self-Training for Unsupervised Neural Machine Translation in Unbalanced  Training Data Scenarios',\n",
       "  'authors': ['Masao Utiyama',\n",
       "   'Rui Wang',\n",
       "   'Kehai Chen',\n",
       "   'Haipeng Sun',\n",
       "   'Eiichiro Sumita',\n",
       "   'Tiejun Zhao'],\n",
       "  'published': '2020-04-09T12:07:17Z',\n",
       "  'updated': '2020-04-09T12:07:17Z',\n",
       "  'abstract': 'Unsupervised neural machine translation (UNMT) that relies solely on massivemonolingual corpora has achieved remarkable results in several translationtasks. However, in real-world scenarios, massive monolingual corpora do notexist for some extremely low-resource languages such as Estonian, and UNMTsystems usually perform poorly when there is not an adequate training corpusfor one language. In this paper, we first define and analyze the unbalancedtraining data scenario for UNMT. Based on this scenario, we propose UNMTself-training mechanisms to train a robust UNMT system and improve itsperformance in this case. Experimental results on several language pairs showthat the proposed methods substantially outperform conventional UNMT systems.',\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2004.04507v1'},\n",
       " 980: {'ID': 980,\n",
       "  'title': 'ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search',\n",
       "  'authors': ['Shangtong Zhang', 'Hengshuai Yao', 'Hao Chen'],\n",
       "  'published': '2018-11-06T22:32:55Z',\n",
       "  'updated': '2018-11-06T22:32:55Z',\n",
       "  'abstract': 'In this paper, we propose an actor ensemble algorithm, named ACE, forcontinuous control with a deterministic policy in reinforcement learning. InACE, we use actor ensemble (i.e., multiple actors) to search the global maximaof the critic. Besides the ensemble perspective, we also formulate ACE in theoption framework by extending the option-critic architecture with deterministicintra-option policies, revealing a relationship between ensemble and options.Furthermore, we perform a look-ahead tree search with those actors and alearned value prediction model, resulting in a refined value estimation. Wedemonstrate a significant performance boost of ACE over DDPG and its variantsin challenging physical robot simulators.',\n",
       "  'categories': ['cs.LG', 'cs.AI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1811.02696v1'},\n",
       " 981: {'ID': 981,\n",
       "  'title': 'Pillar Networks++: Distributed non-parametric deep and wide networks',\n",
       "  'authors': ['Yu Qian', 'Biswa Sengupta'],\n",
       "  'published': '2017-08-18T07:51:43Z',\n",
       "  'updated': '2017-08-18T07:51:43Z',\n",
       "  'abstract': 'In recent work, it was shown that combining multi-kernel based support vectormachines (SVMs) can lead to near state-of-the-art performance on an actionrecognition dataset (HMDB-51 dataset). This was 0.4\\\\% lower than frameworksthat used hand-crafted features in addition to the deep convolutional featureextractors. In the present work, we show that combining distributed GaussianProcesses with multi-stream deep convolutional neural networks (CNN) alleviatethe need to augment a neural network with hand-crafted features. In contrast toprior work, we treat each deep neural convolutional network as an expertwherein the individual predictions (and their respective uncertainties) arecombined into a Product of Experts (PoE) framework.',\n",
       "  'categories': ['cs.CV', 'cs.NE', 'stat.CO', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1708.06250v1'},\n",
       " 982: {'ID': 982,\n",
       "  'title': 'Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G  Handover',\n",
       "  'authors': ['Cory Beard', 'Anurag Thantharate', 'Rahul Arun Paropkari'],\n",
       "  'published': '2021-01-17T00:31:37Z',\n",
       "  'updated': '2021-01-19T01:19:11Z',\n",
       "  'abstract': \"5G cellular networks are being deployed all over the world and thisarchitecture supports ultra-dense network (UDN) deployment. Small cells have avery important role in providing 5G connectivity to the end users. Exponentialincreases in devices, data and network demands make it mandatory for theservice providers to manage handovers better, to cater to the services that auser desire. In contrast to any traditional handover improvement scheme, wedevelop a 'Deep-Mobility' model by implementing a deep learning neural network(DLNN) to manage network mobility, utilizing in-network deep learning andprediction. We use network key performance indicators (KPIs) to train our modelto analyze network traffic and handover requirements. In this method, RF signalconditions are continuously observed and tracked using deep learning neuralnetworks such as the Recurrent neural network (RNN) or Long Short-Term Memorynetwork (LSTM) and system level inputs are also considered in conjunction, totake a collective decision for a handover. We can study multiple parameters andinteractions between system events along with the user mobility, which wouldthen trigger a handoff in any given scenario. Here, we show the fundamentalmodeling approach and demonstrate usefulness of our model while investigatingimpacts and sensitivities of certain KPIs from the user equipment (UE) andnetwork side.\",\n",
       "  'categories': ['cs.LG', 'cs.DC', 'cs.NE', 'C.2; H.2; I.4; J.6'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.06558v2'},\n",
       " 983: {'ID': 983,\n",
       "  'title': 'Effectiveness of Self Normalizing Neural Networks for Text  Classification',\n",
       "  'authors': ['Vijjini Anvesh Rao', 'Avinash Madasu'],\n",
       "  'published': '2019-05-03T18:38:39Z',\n",
       "  'updated': '2019-05-03T18:38:39Z',\n",
       "  'abstract': \"Self Normalizing Neural Networks(SNN) proposed on Feed Forward NeuralNetworks(FNN) outperform regular FNN architectures in various machine learningtasks. Particularly in the domain of Computer Vision, the activation functionScaled Exponential Linear Units (SELU) proposed for SNNs, perform better thanother non linear activations such as ReLU. The goal of SNN is to produce anormalized output for a normalized input. Established neural networkarchitectures like feed forward networks and Convolutional Neural Networks(CNN)lack the intrinsic nature of normalizing outputs. Hence, requiring additionallayers such as Batch Normalization. Despite the success of SNNs, theircharacteristic features on other network architectures like CNN haven't beenexplored, especially in the domain of Natural Language Processing. In thispaper we aim to show the effectiveness of proposed, Self NormalizingConvolutional Neural Networks(SCNN) on text classification. We analyze theirperformance with the standard CNN architecture used on several textclassification datasets. Our experiments demonstrate that SCNN achievescomparable results to standard CNN model with significantly fewer parameters.Furthermore it also outperforms CNN with equal number of parameters.\",\n",
       "  'categories': ['cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.01338v1'},\n",
       " 984: {'ID': 984,\n",
       "  'title': 'Submodular Mini-Batch Training in Generative Moment Matching Networks',\n",
       "  'authors': ['Jun Qi'],\n",
       "  'published': '2017-07-18T16:04:08Z',\n",
       "  'updated': '2017-08-03T14:32:30Z',\n",
       "  'abstract': \"This article was withdrawn because (1) it was uploaded without theco-authors' knowledge or consent, and (2) there are allegations of plagiarism.\",\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.05721v3'},\n",
       " 985: {'ID': 985,\n",
       "  'title': 'Learning human behaviors from motion capture by adversarial imitation',\n",
       "  'authors': ['Yuval Tassa',\n",
       "   'Greg Wayne',\n",
       "   'Dhruva TB',\n",
       "   'Nicolas Heess',\n",
       "   'Sriram Srinivasan',\n",
       "   'Jay Lemmon',\n",
       "   'Ziyu Wang',\n",
       "   'Josh Merel'],\n",
       "  'published': '2017-07-07T14:46:45Z',\n",
       "  'updated': '2017-07-10T14:02:39Z',\n",
       "  'abstract': 'Rapid progress in deep reinforcement learning has made it increasinglyfeasible to train controllers for high-dimensional humanoid bodies. However,methods that use pure reinforcement learning with simple reward functions tendto produce non-humanlike and overly stereotyped movement behaviors. In thiswork, we extend generative adversarial imitation learning to enable training ofgeneric neural network policies to produce humanlike movement patterns fromlimited demonstrations consisting only of partially observed state features,without access to actions, even when the demonstrations come from a body withdifferent and unknown physical parameters. We leverage this approach to buildsub-skill policies from motion capture data and show that they can be reused tosolve tasks when controlled by a higher level controller.',\n",
       "  'categories': ['cs.RO', 'cs.LG', 'cs.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.02201v2'},\n",
       " 986: {'ID': 986,\n",
       "  'title': 'Goal-oriented Dialogue Policy Learning from Failures',\n",
       "  'authors': ['Shiqi Zhang', 'Keting Lu', 'Xiaoping Chen'],\n",
       "  'published': '2018-08-20T15:04:30Z',\n",
       "  'updated': '2018-11-22T13:51:34Z',\n",
       "  'abstract': 'Reinforcement learning methods have been used for learning dialogue policies.However, learning an effective dialogue policy frequently requiresprohibitively many conversations. This is partly because of the sparse rewardsin dialogues, and the very few successful dialogues in early learning phase.Hindsight experience replay (HER) enables learning from failures, but thevanilla HER is inapplicable to dialogue learning due to the implicit goals. Inthis work, we develop two complex HER methods providing different trade-offsbetween complexity and performance, and, for the first time, enabled HER-baseddialogue policy learning. Experiments using a realistic user simulator showthat our HER methods perform better than existing experience replay methods (asapplied to deep Q-networks) in learning rate.',\n",
       "  'categories': ['cs.AI', 'cs.CL'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1808.06497v2'},\n",
       " 987: {'ID': 987,\n",
       "  'title': 'DeepSphere: a graph-based spherical CNN',\n",
       "  'authors': ['Nathanaël Perraudin',\n",
       "   'Michaël Defferrard',\n",
       "   'Martino Milani',\n",
       "   'Frédérick Gusset'],\n",
       "  'published': '2020-12-30T01:35:27Z',\n",
       "  'updated': '2020-12-30T01:35:27Z',\n",
       "  'abstract': 'Designing a convolution for a spherical neural network requires a delicatetradeoff between efficiency and rotation equivariance. DeepSphere, a methodbased on a graph representation of the sampled sphere, strikes a controllablebalance between these two desiderata. This contribution is twofold. First, westudy both theoretically and empirically how equivariance is affected by theunderlying graph with respect to the number of vertices and neighbors. Second,we evaluate DeepSphere on relevant problems. Experiments show state-of-the-artperformance and demonstrates the efficiency and flexibility of thisformulation. Perhaps surprisingly, comparison with previous work suggests thatanisotropic filters might be an unnecessary price to pay. Our code is availableat https://github.com/deepsphere',\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2012.15000v1'},\n",
       " 988: {'ID': 988,\n",
       "  'title': 'Continual Learning in Neural Networks',\n",
       "  'authors': ['Rahaf Aljundi'],\n",
       "  'published': '2019-10-07T10:52:14Z',\n",
       "  'updated': '2019-10-18T09:48:14Z',\n",
       "  'abstract': \"Artificial neural networks have exceeded human-level performance inaccomplishing several individual tasks (e.g. voice recognition, objectrecognition, and video games). However, such success remains modest compared tohuman intelligence that can learn and perform an unlimited number of tasks.Humans' ability of learning and accumulating knowledge over their lifetime isan essential aspect of their intelligence. Continual machine learning aims at ahigher level of machine intelligence through providing the artificial agentswith the ability to learn online from a non-stationary and never-ending streamof data. A key component of such a never-ending learning process is to overcomethe catastrophic forgetting of previously seen data, a problem that neuralnetworks are well known to suffer from. The work described in this thesis hasbeen dedicated to the investigation of continual learning and solutions tomitigate the forgetting phenomena in neural networks. To approach the continuallearning problem, we first assume a task incremental setting where tasks arereceived one at a time and data from previous tasks are not stored. Since thetask incremental setting can't be assumed in all continual learning scenarios,we also study the more general online continual setting. We consider aninfinite stream of data drawn from a non-stationary distribution with asupervisory or self-supervisory training signal. The proposed methods in thisthesis have tackled important aspects of continual learning. They wereevaluated on different benchmarks and over various learning sequences. Advancesin the state of the art of continual learning have been shown and challengesfor bringing continual learning into application were critically identified.\",\n",
       "  'categories': ['cs.LG', 'cs.CV', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1910.02718v2'},\n",
       " 989: {'ID': 989,\n",
       "  'title': 'Learning Stochastic Behaviour from Aggregate Data',\n",
       "  'authors': ['Shu Liu', 'Haomin Zhou', 'Hongyuan Zha', 'Shaojun Ma'],\n",
       "  'published': '2020-02-10T03:20:13Z',\n",
       "  'updated': '2021-02-08T03:32:07Z',\n",
       "  'abstract': 'Learning nonlinear dynamics from aggregate datais a challenging problembecause the full trajectory of each individual is not available, namely, theindividual observed at one time may not beobserved at the next time point, orthe identity ofindividual is unavailable. This is in sharp contrastto learningdynamics with full trajectory data, on which the majority of existing methodsare based. We propose a novel method using the weak form of Fokker PlanckEquation(FPE) -- a partial differential equation -- to describe the densityevolution of data in a sampled form, which is then combined with Wassersteingenerative adversarial network (WGAN) in the training process. Insuch a samplebased framework we are able to learn the nonlinear dynamics from aggregate datawithout explicitly solving FPE. More importantly, our model can also readilyhandle high dimensional cases by leveraging deep neural networks. Wedemonstrate our approach in the context of aseries of synthetic and real-worlddata sets.',\n",
       "  'categories': ['cs.LG', 'math.AP', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.03513v4'},\n",
       " 990: {'ID': 990,\n",
       "  'title': 'Curriculum goal masking for continuous deep reinforcement learning',\n",
       "  'authors': ['Stefan Wermter', 'Sven Magg', 'Manfred Eppe'],\n",
       "  'published': '2018-09-17T12:01:02Z',\n",
       "  'updated': '2019-02-13T12:02:59Z',\n",
       "  'abstract': 'Deep reinforcement learning has recently gained a focus on problems wherepolicy or value functions are independent of goals. Evidence exists that thesampling of goals has a strong effect on the learning performance, but there isa lack of general mechanisms that focus on optimizing the goal samplingprocess. In this work, we present a simple and general goal masking method thatalso allows us to estimate a goal\\'s difficulty level and thus realize acurriculum learning approach for deep RL. Our results indicate that focusing ongoals with a medium difficulty level is appropriate for deep deterministicpolicy gradient (DDPG) methods, while an \"aim for the stars and reach themoon-strategy\", where hard goals are sampled much more often than simple goals,leads to the best learning performance in cases where DDPG is combined with forhindsight experience replay (HER). We demonstrate that the approachsignificantly outperforms standard goal sampling for different robotic objectmanipulation problems.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1809.06146v2'},\n",
       " 991: {'ID': 991,\n",
       "  'title': 'SAR-NAS: Skeleton-based Action Recognition via Neural Architecture  Searching',\n",
       "  'authors': ['Zihui Guo',\n",
       "   'Wanqing Li',\n",
       "   'Pichao Wang',\n",
       "   'Yonghong Hou',\n",
       "   'Haoyuan Zhang'],\n",
       "  'published': '2020-10-29T03:24:15Z',\n",
       "  'updated': '2020-10-29T03:24:15Z',\n",
       "  'abstract': 'This paper presents a study of automatic design of neural networkarchitectures for skeleton-based action recognition. Specifically, we encode askeleton-based action instance into a tensor and carefully define a set ofoperations to build two types of network cells: normal cells and reductioncells. The recently developed DARTS (Differentiable Architecture Search) isadopted to search for an effective network architecture that is built upon thetwo types of cells. All operations are 2D based in order to reduce the overallcomputation and search space. Experiments on the challenging NTU RGB+D andKinectics datasets have verified that most of the networks developed to datefor skeleton-based action recognition are likely not compact and efficient. Theproposed method provides an approach to search for such a compact network thatis able to achieve comparative or even better performance than thestate-of-the-art methods.',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.15336v1'},\n",
       " 992: {'ID': 992,\n",
       "  'title': 'Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot  Locomotion',\n",
       "  'authors': ['Ioannis Havoutis',\n",
       "   'Siddhant Gangapurwala',\n",
       "   'Alexander Mitchell'],\n",
       "  'published': '2020-02-22T10:15:53Z',\n",
       "  'updated': '2020-02-22T10:15:53Z',\n",
       "  'abstract': 'Deep reinforcement learning (RL) uses model-free techniques to optimizetask-specific control policies. Despite having emerged as a promising approachfor complex problems, RL is still hard to use reliably for real-worldapplications. Apart from challenges such as precise reward function tuning,inaccurate sensing and actuation, and non-deterministic response, existing RLmethods do not guarantee behavior within required safety constraints that arecrucial for real robot scenarios. In this regard, we introduce guidedconstrained policy optimization (GCPO), an RL framework based upon ourimplementation of constrained proximal policy optimization (CPPO) for trackingbase velocity commands while following the defined constraints. We alsointroduce schemes which encourage state recovery into constrained regions incase of constraint violations. We present experimental results of our trainingmethod and test it on the real ANYmal quadruped robot. We compare our approachagainst the unconstrained RL method and show that guided constrained RL offersfaster convergence close to the desired optimum resulting in an optimal, yetphysically feasible, robotic control behavior without the need for precisereward function tuning.',\n",
       "  'categories': ['cs.RO', 'cs.LG', 'cs.SY', 'eess.SY'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2002.09676v1'},\n",
       " 993: {'ID': 993,\n",
       "  'title': 'Nonlinear Approximation and (Deep) ReLU Networks',\n",
       "  'authors': ['S. Foucart',\n",
       "   'G. Petrova',\n",
       "   'B. Hanin',\n",
       "   'I. Daubechies',\n",
       "   'R. DeVore'],\n",
       "  'published': '2019-05-05T12:54:35Z',\n",
       "  'updated': '2019-05-05T12:54:35Z',\n",
       "  'abstract': 'This article is concerned with the approximation and expressive powers ofdeep neural networks. This is an active research area currently producing manyinteresting papers. The results most commonly found in the literature provethat neural networks approximate functions with classical smoothness to thesame accuracy as classical linear methods of approximation, e.g. approximationby polynomials or by piecewise polynomials on prescribed partitions. However,approximation by neural networks depending on n parameters is a form ofnonlinear approximation and as such should be compared with other nonlinearmethods such as variable knot splines or n-term approximation fromdictionaries. The performance of neural networks in targeted applications suchas machine learning indicate that they actually possess even greaterapproximation power than these traditional methods of nonlinear approximation.The main results of this article prove that this is indeed the case. This isdone by exhibiting large classes of functions which can be efficiently capturedby neural networks where classical nonlinear methods fall short of the task.The present article purposefully limits itself to studying the approximation ofunivariate functions by ReLU networks. Many generalizations to functions ofseveral variables and other activation functions can be envisioned. However,even in this simplest of settings considered here, a theory that completelyquantifies the approximation power of neural networks is still lacking.',\n",
       "  'categories': ['cs.LG', '41A25, 41A30, 41A46, 68T99, 82C32, 92B20,'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1905.02199v1'},\n",
       " 994: {'ID': 994,\n",
       "  'title': 'Block-wise Image Transformation with Secret Key for Adversarially Robust  Defense',\n",
       "  'authors': ['MaungMaung AprilPyone', 'Hitoshi Kiya'],\n",
       "  'published': '2020-10-02T06:07:12Z',\n",
       "  'updated': '2020-10-02T06:07:12Z',\n",
       "  'abstract': 'In this paper, we propose a novel defensive transformation that enables us tomaintain a high classification accuracy under the use of both clean images andadversarial examples for adversarially robust defense. The proposedtransformation is a block-wise preprocessing technique with a secret key toinput images. We developed three algorithms to realize the proposedtransformation: Pixel Shuffling, Bit Flipping, and FFX Encryption. Experimentswere carried out on the CIFAR-10 and ImageNet datasets by using both black-boxand white-box attacks with various metrics including adaptive ones. The resultsshow that the proposed defense achieves high accuracy close to that of usingclean images even under adaptive attacks for the first time. In the best-casescenario, a model trained by using images transformed by FFX Encryption (blocksize of 4) yielded an accuracy of 92.30% on clean images and 91.48% under PGDattack with a noise distance of 8/255, which is close to the non-robustaccuracy (95.45%) for the CIFAR-10 dataset, and it yielded an accuracy of72.18% on clean images and 71.43% under the same attack, which is also close tothe standard accuracy (73.70%) for the ImageNet dataset. Overall, all threeproposed algorithms are demonstrated to outperform state-of-the-art defensesincluding adversarial training whether or not a model is under attack.',\n",
       "  'categories': ['cs.CV', 'cs.CR'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2010.00801v1'},\n",
       " 995: {'ID': 995,\n",
       "  'title': 'DiPSeN: Differentially Private Self-normalizing Neural Networks For  Adversarial Robustness in Federated Learning',\n",
       "  'authors': ['M. Omair Shafiq', 'Olakunle Ibitoye', 'Ashraf Matrawy'],\n",
       "  'published': '2021-01-08T20:49:56Z',\n",
       "  'updated': '2021-01-08T20:49:56Z',\n",
       "  'abstract': 'The need for robust, secure and private machine learning is an important goalfor realizing the full potential of the Internet of Things (IoT). Federatedlearning has proven to help protect against privacy violations and informationleakage. However, it introduces new risk vectors which make machine learningmodels more difficult to defend against adversarial samples. In this study, weexamine the role of differential privacy and self-normalization in mitigatingthe risk of adversarial samples specifically in a federated learningenvironment. We introduce DiPSeN, a Differentially Private Self-normalizingNeural Network which combines elements of differential privacy noise withself-normalizing techniques. Our empirical results on three publicly availabledatasets show that DiPSeN successfully improves the adversarial robustness of adeep learning classifier in a federated learning environment based on severalevaluation metrics.',\n",
       "  'categories': ['cs.LG', 'cs.AI', 'cs.CY', 'cs.NI'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2101.03218v1'},\n",
       " 996: {'ID': 996,\n",
       "  'title': 'Detecting Lane and Road Markings at A Distance with Perspective  Transformer Layers',\n",
       "  'authors': ['Junqiao Zhao',\n",
       "   'Yuyao Huang',\n",
       "   'Zhuoping Yu',\n",
       "   'Wei Tian',\n",
       "   'Xiaozhou Ren'],\n",
       "  'published': '2020-03-19T03:22:52Z',\n",
       "  'updated': '2020-10-25T06:38:46Z',\n",
       "  'abstract': 'Accurate detection of lane and road markings is a task of great importancefor intelligent vehicles. In existing approaches, the detection accuracy oftendegrades with the increasing distance. This is due to the fact that distantlane and road markings occupy a small number of pixels in the image, and scalesof lane and road markings are inconsistent at various distances andperspectives. The Inverse Perspective Mapping (IPM) can be used to eliminatethe perspective distortion, but the inherent interpolation can lead toartifacts especially around distant lane and road markings and thus has anegative impact on the accuracy of lane marking detection and segmentation. Tosolve this problem, we adopt the Encoder-Decoder architecture in FullyConvolutional Networks and leverage the idea of Spatial Transformer Networks tointroduce a novel semantic segmentation neural network. This approachdecomposes the IPM process into multiple consecutive differentiable homographictransform layers, which are called \"Perspective Transformer Layers\".Furthermore, the interpolated feature map is refined by subsequentconvolutional layers thus reducing the artifacts and improving the accuracy.The effectiveness of the proposed method in lane marking detection is validatedon two public datasets: TuSimple and ApolloScape',\n",
       "  'categories': ['cs.CV'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2003.08550v2'},\n",
       " 997: {'ID': 997,\n",
       "  'title': 'Towards adversarial robustness with 01 loss neural networks',\n",
       "  'authors': ['Meiyan Xie', 'Usman Roshan', 'Yunzhe Xue'],\n",
       "  'published': '2020-08-20T18:18:49Z',\n",
       "  'updated': '2020-08-20T18:18:49Z',\n",
       "  'abstract': \"Motivated by the general robustness properties of the 01 loss we propose asingle hidden layer 01 loss neural network trained with stochastic coordinatedescent as a defense against adversarial attacks in machine learning. Onemeasure of a model's robustness is the minimum distortion required to make theinput adversarial. This can be approximated with the Boundary Attack (Brendelet. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare theminimum distortion of the 01 loss network to the binarized neural network andthe standard sigmoid activation network with cross-entropy loss all trainedwith and without Gaussian noise on the CIFAR10 benchmark binary classificationbetween classes 0 and 1. Both with and without noise training we find our 01loss network to have the largest adversarial distortion of the three models bynon-trivial margins. To further validate these results we subject all models tosubstitute model black box attacks under different distortion thresholds andfind that the 01 loss network is the hardest to attack across all distortions.At a distortion of 0.125 both sigmoid activated cross-entropy loss andbinarized networks have almost 0% accuracy on adversarial examples whereas the01 loss network is at 40%. Even though both 01 loss and the binarized networkuse sign activations their training algorithms are different which in turn givedifferent solutions for robustness. Finally we compare our network to simpleconvolutional models under substitute model black box attacks and find theiraccuracies to be comparable. Our work shows that the 01 loss network has thepotential to defend against black box adversarial attacks better than convexloss and binarized networks.\",\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2008.09148v1'},\n",
       " 998: {'ID': 998,\n",
       "  'title': 'Complex and Holographic Embeddings of Knowledge Graphs: A Comparison',\n",
       "  'authors': ['Maximilian Nickel', 'Théo Trouillon'],\n",
       "  'published': '2017-07-05T17:17:34Z',\n",
       "  'updated': '2017-07-23T04:30:21Z',\n",
       "  'abstract': 'Embeddings of knowledge graphs have received significant attention due totheir excellent performance for tasks like link prediction and entityresolution. In this short paper, we are providing a comparison of twostate-of-the-art knowledge graph embeddings for which their equivalence hasrecently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio,2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we brieflyreview both models and discuss how their scoring functions are equivalent. Wethen analyze the discrepancy of results reported in the original articles, andshow experimentally that they are likely due to the use of different lossfunctions. In further experiments, we evaluate the ability of both models toembed symmetric and antisymmetric patterns. Finally, we discuss advantages anddisadvantages of both models and under which conditions one would be preferableto the other.',\n",
       "  'categories': ['cs.LG', 'stat.ML'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/1707.01475v2'},\n",
       " 999: {'ID': 999,\n",
       "  'title': 'MALI: A memory efficient and reverse accurate integrator for Neural ODEs',\n",
       "  'authors': ['Sekhar Tatikonda',\n",
       "   'James S. Duncan',\n",
       "   'Juntang Zhuang',\n",
       "   'Nicha C. Dvornek'],\n",
       "  'published': '2021-02-09T06:33:47Z',\n",
       "  'updated': '2021-02-09T06:33:47Z',\n",
       "  'abstract': 'Neural ordinary differential equations (Neural ODEs) are a new family ofdeep-learning models with continuous depth. However, the numerical estimationof the gradient in the continuous case is not well solved: existingimplementations of the adjoint method suffer from inaccuracy in reverse-timetrajectory, while the naive method and the adaptive checkpoint adjoint method(ACA) have a memory cost that grows with integration time. In this project,based on the asynchronous leapfrog (ALF) solver, we propose theMemory-efficient ALF Integrator (MALI), which has a constant memory cost\\\\textit{w.r.t} number of solver steps in integration similar to the adjointmethod, and guarantees accuracy in reverse-time trajectory (hence accuracy ingradient estimation). We validate MALI in various tasks: on image recognitiontasks, to our knowledge, MALI is the first to enable feasible training of aNeural ODE on ImageNet and outperform a well-tuned ResNet, while existingmethods fail due to either heavy memory burden or inaccuracy; for time seriesmodeling, MALI significantly outperforms the adjoint method; and for continuousgenerative models, MALI achieves new state-of-the-art performance.',\n",
       "  'categories': ['cs.LG'],\n",
       "  'arxiv_url': 'http://arxiv.org/abs/2102.04668v1'},\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-samoa",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
